{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lb9q2_QZgdNk"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Tutorials/blob/master/2-Advance/FinRL_Ensemble_StockTrading_ICAIF_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXaoZs2lh1hi"
      },
      "source": [
        "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading Using Ensemble Strategy\n",
        "\n",
        "Tutorials to use OpenAI DRL to trade multiple stocks using ensemble strategy in one Jupyter Notebook | Presented at ICAIF 2020\n",
        "\n",
        "* This notebook is the reimplementation of our paper: Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, using FinRL.\n",
        "* Check out medium blog for detailed explanations: https://medium.com/@ai4finance/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02\n",
        "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
        "* **Pytorch Version** \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGunVt8oLCVS"
      },
      "source": [
        "# Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOzAKQ-SLGX6"
      },
      "source": [
        "* [1. Problem Definition](#0)\n",
        "* [2. Getting Started - Load Python packages](#1)\n",
        "    * [2.1. Install Packages](#1.1)    \n",
        "    * [2.2. Check Additional Packages](#1.2)\n",
        "    * [2.3. Import Packages](#1.3)\n",
        "    * [2.4. Create Folders](#1.4)\n",
        "* [3. Download Data](#2)\n",
        "* [4. Preprocess Data](#3)        \n",
        "    * [4.1. Technical Indicators](#3.1)\n",
        "    * [4.2. Perform Feature Engineering](#3.2)\n",
        "* [5.Build Environment](#4)  \n",
        "    * [5.1. Training & Trade Data Split](#4.1)\n",
        "    * [5.2. User-defined Environment](#4.2)   \n",
        "    * [5.3. Initialize Environment](#4.3)    \n",
        "* [6.Implement DRL Algorithms](#5)  \n",
        "* [7.Backtesting Performance](#6)  \n",
        "    * [7.1. BackTestStats](#6.1)\n",
        "    * [7.2. BackTestPlot](#6.2)   \n",
        "    * [7.3. Baseline Stats](#6.3)   \n",
        "    * [7.3. Compare to Stock Market Index](#6.4)             "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sApkDlD9LIZv"
      },
      "source": [
        "<a id='0'></a>\n",
        "# Part 1. Problem Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjLD2TZSLKZ-"
      },
      "source": [
        "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
        "\n",
        "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
        "\n",
        "\n",
        "* Action: The action space describes the allowed actions that the agent interacts with the\n",
        "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
        "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
        "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
        "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
        "\n",
        "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
        "values at state s′ and s, respectively\n",
        "\n",
        "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
        "our trading agent observes many different features to better learn in an interactive environment.\n",
        "\n",
        "* Environment: Dow 30 consituents\n",
        "\n",
        "\n",
        "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffsre789LY08"
      },
      "source": [
        "<a id='1'></a>\n",
        "# Part 2. Getting Started- Load Python Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy5_PTmOh1hj"
      },
      "source": [
        "<a id='1.1'></a>\n",
        "## 2.1. Install all the packages through FinRL library\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mPT0ipYE28wL",
        "outputId": "4352663d-20eb-4080-a83e-bf6b97183bf4"
      },
      "outputs": [],
      "source": [
        "# # ## install finrl library\n",
        "# !pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osBHhVysOEzi"
      },
      "source": [
        "\n",
        "<a id='1.2'></a>\n",
        "## 2.2. Check if the additional packages needed are present, if not install them. \n",
        "* Yahoo Finance API\n",
        "* pandas\n",
        "* numpy\n",
        "* matplotlib\n",
        "* stockstats\n",
        "* OpenAI gym\n",
        "* stable-baselines\n",
        "* tensorflow\n",
        "* pyfolio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGv01K8Sh1hn"
      },
      "source": [
        "<a id='1.3'></a>\n",
        "## 2.3. Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EeMK7Uentj1V"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lPqeTTwoh1hn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# matplotlib.use('Agg')\n",
        "import datetime\n",
        "\n",
        "%matplotlib inline\n",
        "from finrl.config_tickers import DOW_30_TICKER\n",
        "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from finrl.meta.env_stock_trading.env_stocktrading_pair_trading_Prices import StockPairTradingEnv\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent,DRLEnsembleAgent, DRLEnsembleAgentOne\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../FinRL-Library\")\n",
        "\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2owTj985RW4"
      },
      "source": [
        "<a id='1.4'></a>\n",
        "## 2.4. Create Folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "w9A8CN5R5PuZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from finrl.main import check_and_make_directories\n",
        "from finrl.config import (\n",
        "    DATA_SAVE_DIR,\n",
        "    TRAINED_MODEL_DIR,\n",
        "    TENSORBOARD_LOG_DIR,\n",
        "    RESULTS_DIR,\n",
        "    INDICATORS,\n",
        "    TRAIN_START_DATE,\n",
        "    TRAIN_END_DATE,\n",
        "    TEST_START_DATE,\n",
        "    TEST_END_DATE,\n",
        "    TRADE_START_DATE,\n",
        "    TRADE_END_DATE,\n",
        ")\n",
        "\n",
        "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A289rQWMh1hq"
      },
      "source": [
        "<a id='2'></a>\n",
        "# Part 3. Download Data\n",
        "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
        "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
        "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPeQ7iS-LoMm"
      },
      "source": [
        "\n",
        "\n",
        "-----\n",
        "class YahooDownloader:\n",
        "    Provides methods for retrieving daily stock data from\n",
        "    Yahoo Finance API\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        start_date : str\n",
        "            start date of the data (modified from config.py)\n",
        "        end_date : str\n",
        "            end date of the data (modified from config.py)\n",
        "        ticker_list : list\n",
        "            a list of stock tickers (modified from config.py)\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    fetch_data()\n",
        "        Fetches data from yahoo API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzqRRTOX6aFu",
        "outputId": "cd002c5d-2490-4947-9bd3-2b0696cb0f69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['AMCR', 'JNPR']\n"
          ]
        }
      ],
      "source": [
        "DOW_30_TICKER = ['AMCR','JNPR']\n",
        "print(DOW_30_TICKER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCKm4om-s9kE",
        "outputId": "743f675b-6126-44ea-bf39-7b3333d15044"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (5591, 8)\n"
          ]
        }
      ],
      "source": [
        "TRAIN_START_DATE = '2010-04-01'\n",
        "TRAIN_END_DATE = '2021-01-01'\n",
        "TEST_START_DATE = '2021-01-01'\n",
        "TEST_END_DATE = '2022-06-01'\n",
        "\n",
        "df = YahooDownloader(start_date = TRAIN_START_DATE,\n",
        "                     end_date = TEST_END_DATE,\n",
        "                     ticker_list = DOW_30_TICKER).fetch_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GiRuFOTOtj1Y",
        "outputId": "632ce1e6-ad27-4f50-fec7-0ca27c8e3c96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "JNPR    3063\n",
              "AMCR    2528\n",
              "Name: tic, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['tic'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DSw4ZEzVtj1Z",
        "outputId": "0015b377-84ec-4a6d-ac4e-e138c2c9bac8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5586</th>\n",
              "      <td>2022-05-26</td>\n",
              "      <td>30.190001</td>\n",
              "      <td>30.940001</td>\n",
              "      <td>30.18</td>\n",
              "      <td>29.994238</td>\n",
              "      <td>3476800</td>\n",
              "      <td>JNPR</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5587</th>\n",
              "      <td>2022-05-27</td>\n",
              "      <td>13.190000</td>\n",
              "      <td>13.310000</td>\n",
              "      <td>13.12</td>\n",
              "      <td>13.040057</td>\n",
              "      <td>8531400</td>\n",
              "      <td>AMCR</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5588</th>\n",
              "      <td>2022-05-27</td>\n",
              "      <td>30.980000</td>\n",
              "      <td>31.230000</td>\n",
              "      <td>30.77</td>\n",
              "      <td>30.581974</td>\n",
              "      <td>2867000</td>\n",
              "      <td>JNPR</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5589</th>\n",
              "      <td>2022-05-31</td>\n",
              "      <td>13.170000</td>\n",
              "      <td>13.260000</td>\n",
              "      <td>13.01</td>\n",
              "      <td>12.834316</td>\n",
              "      <td>35769100</td>\n",
              "      <td>AMCR</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5590</th>\n",
              "      <td>2022-05-31</td>\n",
              "      <td>30.860001</td>\n",
              "      <td>30.950001</td>\n",
              "      <td>30.41</td>\n",
              "      <td>30.256529</td>\n",
              "      <td>5073000</td>\n",
              "      <td>JNPR</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            date       open       high    low      close    volume   tic  day\n",
              "5586  2022-05-26  30.190001  30.940001  30.18  29.994238   3476800  JNPR    3\n",
              "5587  2022-05-27  13.190000  13.310000  13.12  13.040057   8531400  AMCR    4\n",
              "5588  2022-05-27  30.980000  31.230000  30.77  30.581974   2867000  JNPR    4\n",
              "5589  2022-05-31  13.170000  13.260000  13.01  12.834316  35769100  AMCR    1\n",
              "5590  2022-05-31  30.860001  30.950001  30.41  30.256529   5073000  JNPR    1"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV3HrZHLh1hy",
        "outputId": "42781af6-4cee-4277-8a00-cf46052f991c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5591, 8)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4hYkeaPiICHS",
        "outputId": "59c51c93-f786-469b-c008-4e4416a041b4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-04-01</td>\n",
              "      <td>30.809999</td>\n",
              "      <td>31.080000</td>\n",
              "      <td>30.209999</td>\n",
              "      <td>24.890251</td>\n",
              "      <td>3832100</td>\n",
              "      <td>JNPR</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-04-05</td>\n",
              "      <td>30.780001</td>\n",
              "      <td>30.930000</td>\n",
              "      <td>30.430000</td>\n",
              "      <td>25.225386</td>\n",
              "      <td>7685900</td>\n",
              "      <td>JNPR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-04-06</td>\n",
              "      <td>30.610001</td>\n",
              "      <td>31.770000</td>\n",
              "      <td>30.430000</td>\n",
              "      <td>25.862967</td>\n",
              "      <td>8171100</td>\n",
              "      <td>JNPR</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-04-07</td>\n",
              "      <td>31.520000</td>\n",
              "      <td>31.870001</td>\n",
              "      <td>31.320000</td>\n",
              "      <td>25.740356</td>\n",
              "      <td>6328300</td>\n",
              "      <td>JNPR</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-04-08</td>\n",
              "      <td>31.420000</td>\n",
              "      <td>31.490000</td>\n",
              "      <td>30.670000</td>\n",
              "      <td>25.560526</td>\n",
              "      <td>6908900</td>\n",
              "      <td>JNPR</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date       open       high        low      close   volume   tic  day\n",
              "0  2010-04-01  30.809999  31.080000  30.209999  24.890251  3832100  JNPR    3\n",
              "1  2010-04-05  30.780001  30.930000  30.430000  25.225386  7685900  JNPR    0\n",
              "2  2010-04-06  30.610001  31.770000  30.430000  25.862967  8171100  JNPR    1\n",
              "3  2010-04-07  31.520000  31.870001  31.320000  25.740356  6328300  JNPR    2\n",
              "4  2010-04-08  31.420000  31.490000  30.670000  25.560526  6908900  JNPR    3"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sort_values(['date','tic']).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2vryMsdNL9H",
        "outputId": "dff3babf-4aba-44dd-ad61-8845df60243e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df.tic.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcNyXa7RNPrF",
        "outputId": "fd13ad85-36fd-4a55-9084-dbf807bbeb02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "JNPR    3063\n",
              "AMCR    2528\n",
              "Name: tic, dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.tic.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqC6c40Zh1iH"
      },
      "source": [
        "# Part 4: Preprocess Data\n",
        "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
        "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
        "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kM5bH9uroCeg"
      },
      "outputs": [],
      "source": [
        "#  INDICATORS = ['macd',\n",
        "#                'rsi_30',\n",
        "#                'cci_30',\n",
        "#                'dx_30']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgXfBcjxtj1a",
        "outputId": "aa687295-c857-4366-d9af-96ea233c6463",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully added technical indicators\n",
            "Successfully added turbulence index\n"
          ]
        }
      ],
      "source": [
        "fe = FeatureEngineer(use_technical_indicator=True,\n",
        "                     tech_indicator_list = INDICATORS,\n",
        "                     use_turbulence=True,\n",
        "                     user_defined_feature = False)\n",
        "\n",
        "processed = fe.preprocess_data(df)\n",
        "processed = processed.copy()\n",
        "processed = processed.fillna(0)\n",
        "processed = processed.replace(np.inf,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "grvhGJJII3Xn",
        "outputId": "6dd919fa-032b-4180-adf4-1f732777cedc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "JNPR    3063\n",
              "Name: tic, dtype: int64"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processed.tic.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QsYaY0Dh1iw"
      },
      "source": [
        "<a id='4'></a>\n",
        "# Part 5. Design Environment\n",
        "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
        "\n",
        "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
        "\n",
        "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2zqII8rMIqn",
        "outputId": "0194749d-62ec-420f-9b54-492873c266a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stock Dimension: 1, State Space: 11\n"
          ]
        }
      ],
      "source": [
        "stock_dimension = len(processed.tic.unique())\n",
        "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "AWyp84Ltto19"
      },
      "outputs": [],
      "source": [
        "env_kwargs = {\n",
        "    \"hmax\": 100, \n",
        "    \"initial_amount\": 10000, \n",
        "    \"buy_cost_pct\": 0.001, \n",
        "    \"sell_cost_pct\": 0.001, \n",
        "    \"state_space\": state_space, \n",
        "    \"stock_dim\": stock_dimension, \n",
        "    \"tech_indicator_list\": INDICATORS,\n",
        "    \"action_space\": stock_dimension, \n",
        "    \"reward_scaling\": 1e-4,\n",
        "    \"print_verbosity\":5\n",
        "    \n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMNR5nHjh1iz"
      },
      "source": [
        "<a id='5'></a>\n",
        "# Part 6: Implement DRL Algorithms\n",
        "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
        "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
        "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
        "design their own DRL algorithms by adapting these DRL algorithms.\n",
        "\n",
        "* In this notebook, we are training and validating 3 agents (A2C, PPO, DDPG) using Rolling-window Ensemble Method ([reference code](https://github.com/AI4Finance-LLC/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020/blob/80415db8fa7b2179df6bd7e81ce4fe8dbf913806/model/models.py#L92))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "v-gthCxMtj1d"
      },
      "outputs": [],
      "source": [
        "rebalance_window = 21 # rebalance_window is the number of days to retrain the model\n",
        "validation_window = 21 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
        "\n",
        "ensemble_agent = DRLEnsembleAgentOne(df=processed,\n",
        "                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n",
        "                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n",
        "                 rebalance_window=rebalance_window, \n",
        "                 validation_window=validation_window, \n",
        "                 **env_kwargs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "KsfEHa_Etj1d",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "A2C_model_kwargs = {\n",
        "                    'n_steps': 5,\n",
        "                    'ent_coef': 0.005,\n",
        "                    'learning_rate': 0.0007\n",
        "                    }\n",
        "\n",
        "PPO_model_kwargs = {\n",
        "                    \"ent_coef\":0.01,\n",
        "                    \"n_steps\": 2048,\n",
        "                    \"learning_rate\": 0.00025,\n",
        "                    \"batch_size\": 128\n",
        "                    }\n",
        "\n",
        "DDPG_model_kwargs = {\n",
        "                      #\"action_noise\":\"ornstein_uhlenbeck\",\n",
        "                      \"buffer_size\": 10_000,\n",
        "                      \"learning_rate\": 0.0005,\n",
        "                      \"batch_size\": 64\n",
        "                    }\n",
        "\n",
        "timesteps_dict = {'a2c' : 55_000, \n",
        "                 'ppo' : 0, \n",
        "                 'ddpg' : 0\n",
        "                 }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1lyCECstj1e",
        "outputId": "b2a1cfbc-ced9-4d06-dd9a-4300845e1113",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============Start Ensemble Strategy============\n",
            "============================================\n",
            "turbulence_threshold:  12.04306128869847\n",
            "======Model training from:  2010-04-01 to  2021-01-04\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c\\a2c_42_1\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 147           |\n",
            "|    iterations         | 100           |\n",
            "|    time_elapsed       | 3             |\n",
            "|    total_timesteps    | 500           |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.48         |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 99            |\n",
            "|    policy_loss        | -0.0131       |\n",
            "|    reward             | -0.0056525636 |\n",
            "|    std                | 1.06          |\n",
            "|    value_loss         | 0.000128      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 229          |\n",
            "|    iterations         | 200          |\n",
            "|    time_elapsed       | 4            |\n",
            "|    total_timesteps    | 1000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.51        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 199          |\n",
            "|    policy_loss        | 0.0109       |\n",
            "|    reward             | 0.0021337867 |\n",
            "|    std                | 1.1          |\n",
            "|    value_loss         | 6.32e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 279          |\n",
            "|    iterations         | 300          |\n",
            "|    time_elapsed       | 5            |\n",
            "|    total_timesteps    | 1500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.54        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 299          |\n",
            "|    policy_loss        | -0.00228     |\n",
            "|    reward             | -0.008685507 |\n",
            "|    std                | 1.13         |\n",
            "|    value_loss         | 2.93e-06     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 313          |\n",
            "|    iterations         | 400          |\n",
            "|    time_elapsed       | 6            |\n",
            "|    total_timesteps    | 2000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.56        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 399          |\n",
            "|    policy_loss        | -0.00441     |\n",
            "|    reward             | -0.001212588 |\n",
            "|    std                | 1.16         |\n",
            "|    value_loss         | 2.43e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 339         |\n",
            "|    iterations         | 500         |\n",
            "|    time_elapsed       | 7           |\n",
            "|    total_timesteps    | 2500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.6        |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 499         |\n",
            "|    policy_loss        | -0.00152    |\n",
            "|    reward             | 0.024810677 |\n",
            "|    std                | 1.2         |\n",
            "|    value_loss         | 7.01e-05    |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 358            |\n",
            "|    iterations         | 600            |\n",
            "|    time_elapsed       | 8              |\n",
            "|    total_timesteps    | 3000           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -1.63          |\n",
            "|    explained_variance | -1.19e-07      |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 599            |\n",
            "|    policy_loss        | 0.00541        |\n",
            "|    reward             | -0.00080138346 |\n",
            "|    std                | 1.23           |\n",
            "|    value_loss         | 3.95e-05       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 376           |\n",
            "|    iterations         | 700           |\n",
            "|    time_elapsed       | 9             |\n",
            "|    total_timesteps    | 3500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.67         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 699           |\n",
            "|    policy_loss        | -0.0195       |\n",
            "|    reward             | -0.0014261306 |\n",
            "|    std                | 1.28          |\n",
            "|    value_loss         | 0.000109      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 385           |\n",
            "|    iterations         | 800           |\n",
            "|    time_elapsed       | 10            |\n",
            "|    total_timesteps    | 4000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.69         |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 799           |\n",
            "|    policy_loss        | 0.000801      |\n",
            "|    reward             | -0.0011847131 |\n",
            "|    std                | 1.31          |\n",
            "|    value_loss         | 1.64e-06      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 396            |\n",
            "|    iterations         | 900            |\n",
            "|    time_elapsed       | 11             |\n",
            "|    total_timesteps    | 4500           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -1.72          |\n",
            "|    explained_variance | -2.38e-07      |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 899            |\n",
            "|    policy_loss        | 0.0111         |\n",
            "|    reward             | -0.00027847904 |\n",
            "|    std                | 1.36           |\n",
            "|    value_loss         | 5.33e-05       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 403           |\n",
            "|    iterations         | 1000          |\n",
            "|    time_elapsed       | 12            |\n",
            "|    total_timesteps    | 5000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.76         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 999           |\n",
            "|    policy_loss        | -0.000424     |\n",
            "|    reward             | 0.00026155336 |\n",
            "|    std                | 1.4           |\n",
            "|    value_loss         | 1.46e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 411          |\n",
            "|    iterations         | 1100         |\n",
            "|    time_elapsed       | 13           |\n",
            "|    total_timesteps    | 5500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.8         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1099         |\n",
            "|    policy_loss        | -0.0349      |\n",
            "|    reward             | -0.004660521 |\n",
            "|    std                | 1.46         |\n",
            "|    value_loss         | 0.00067      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 417         |\n",
            "|    iterations         | 1200        |\n",
            "|    time_elapsed       | 14          |\n",
            "|    total_timesteps    | 6000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.83       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1199        |\n",
            "|    policy_loss        | -0.0365     |\n",
            "|    reward             | -0.03611781 |\n",
            "|    std                | 1.51        |\n",
            "|    value_loss         | 0.000429    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 422         |\n",
            "|    iterations         | 1300        |\n",
            "|    time_elapsed       | 15          |\n",
            "|    total_timesteps    | 6500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.86       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1299        |\n",
            "|    policy_loss        | 0.0124      |\n",
            "|    reward             | 0.035163045 |\n",
            "|    std                | 1.56        |\n",
            "|    value_loss         | 3.96e-05    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 426           |\n",
            "|    iterations         | 1400          |\n",
            "|    time_elapsed       | 16            |\n",
            "|    total_timesteps    | 7000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.9          |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1399          |\n",
            "|    policy_loss        | -0.0249       |\n",
            "|    reward             | -0.0011009094 |\n",
            "|    std                | 1.62          |\n",
            "|    value_loss         | 0.000183      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 430           |\n",
            "|    iterations         | 1500          |\n",
            "|    time_elapsed       | 17            |\n",
            "|    total_timesteps    | 7500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.95         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1499          |\n",
            "|    policy_loss        | -0.00797      |\n",
            "|    reward             | -0.0047228024 |\n",
            "|    std                | 1.69          |\n",
            "|    value_loss         | 4.32e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 434          |\n",
            "|    iterations         | 1600         |\n",
            "|    time_elapsed       | 18           |\n",
            "|    total_timesteps    | 8000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.98        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1599         |\n",
            "|    policy_loss        | -0.0139      |\n",
            "|    reward             | 0.0037566177 |\n",
            "|    std                | 1.76         |\n",
            "|    value_loss         | 7.75e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 438          |\n",
            "|    iterations         | 1700         |\n",
            "|    time_elapsed       | 19           |\n",
            "|    total_timesteps    | 8500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.03        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1699         |\n",
            "|    policy_loss        | 0.000555     |\n",
            "|    reward             | -0.016286004 |\n",
            "|    std                | 1.83         |\n",
            "|    value_loss         | 5.25e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 441          |\n",
            "|    iterations         | 1800         |\n",
            "|    time_elapsed       | 20           |\n",
            "|    total_timesteps    | 9000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.05        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1799         |\n",
            "|    policy_loss        | -0.00922     |\n",
            "|    reward             | 0.0071931756 |\n",
            "|    std                | 1.87         |\n",
            "|    value_loss         | 4.16e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 444          |\n",
            "|    iterations         | 1900         |\n",
            "|    time_elapsed       | 21           |\n",
            "|    total_timesteps    | 9500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.08        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1899         |\n",
            "|    policy_loss        | 0.00459      |\n",
            "|    reward             | 0.0066655925 |\n",
            "|    std                | 1.94         |\n",
            "|    value_loss         | 3.28e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 447           |\n",
            "|    iterations         | 2000          |\n",
            "|    time_elapsed       | 22            |\n",
            "|    total_timesteps    | 10000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.11         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1999          |\n",
            "|    policy_loss        | 0.00207       |\n",
            "|    reward             | -0.0017746637 |\n",
            "|    std                | 2             |\n",
            "|    value_loss         | 3.25e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 449          |\n",
            "|    iterations         | 2100         |\n",
            "|    time_elapsed       | 23           |\n",
            "|    total_timesteps    | 10500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.14        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2099         |\n",
            "|    policy_loss        | 0.00142      |\n",
            "|    reward             | -0.012347242 |\n",
            "|    std                | 2.07         |\n",
            "|    value_loss         | 2.83e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 451          |\n",
            "|    iterations         | 2200         |\n",
            "|    time_elapsed       | 24           |\n",
            "|    total_timesteps    | 11000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.18        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2199         |\n",
            "|    policy_loss        | -0.00778     |\n",
            "|    reward             | -0.001071524 |\n",
            "|    std                | 2.13         |\n",
            "|    value_loss         | 6.86e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 453           |\n",
            "|    iterations         | 2300          |\n",
            "|    time_elapsed       | 25            |\n",
            "|    total_timesteps    | 11500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.21         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2299          |\n",
            "|    policy_loss        | 0.0509        |\n",
            "|    reward             | -0.0026823191 |\n",
            "|    std                | 2.2           |\n",
            "|    value_loss         | 0.000579      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 454          |\n",
            "|    iterations         | 2400         |\n",
            "|    time_elapsed       | 26           |\n",
            "|    total_timesteps    | 12000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.23        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2399         |\n",
            "|    policy_loss        | 0.0273       |\n",
            "|    reward             | 0.0029519508 |\n",
            "|    std                | 2.25         |\n",
            "|    value_loss         | 0.000336     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 454          |\n",
            "|    iterations         | 2500         |\n",
            "|    time_elapsed       | 27           |\n",
            "|    total_timesteps    | 12500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.27        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2499         |\n",
            "|    policy_loss        | 0.00315      |\n",
            "|    reward             | -0.014083579 |\n",
            "|    std                | 2.34         |\n",
            "|    value_loss         | 0.000274     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 457           |\n",
            "|    iterations         | 2600          |\n",
            "|    time_elapsed       | 28            |\n",
            "|    total_timesteps    | 13000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.29         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2599          |\n",
            "|    policy_loss        | -0.0561       |\n",
            "|    reward             | -0.0061199768 |\n",
            "|    std                | 2.4           |\n",
            "|    value_loss         | 0.000913      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 458          |\n",
            "|    iterations         | 2700         |\n",
            "|    time_elapsed       | 29           |\n",
            "|    total_timesteps    | 13500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.33        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2699         |\n",
            "|    policy_loss        | 0.106        |\n",
            "|    reward             | 0.0018291001 |\n",
            "|    std                | 2.48         |\n",
            "|    value_loss         | 0.00208      |\n",
            "----------------------------------------\n",
            "day: 2707, episode: 5\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 9842.95\n",
            "total_reward: -157.05\n",
            "total_cost: 97.22\n",
            "total_trades: 2707\n",
            "Sharpe: 0.083\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 460        |\n",
            "|    iterations         | 2800       |\n",
            "|    time_elapsed       | 30         |\n",
            "|    total_timesteps    | 14000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.35      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2799       |\n",
            "|    policy_loss        | -0.103     |\n",
            "|    reward             | 0.02289876 |\n",
            "|    std                | 2.53       |\n",
            "|    value_loss         | 0.0028     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 461         |\n",
            "|    iterations         | 2900        |\n",
            "|    time_elapsed       | 31          |\n",
            "|    total_timesteps    | 14500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.36       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2899        |\n",
            "|    policy_loss        | -0.0786     |\n",
            "|    reward             | -0.06066592 |\n",
            "|    std                | 2.57        |\n",
            "|    value_loss         | 0.00318     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 462         |\n",
            "|    iterations         | 3000        |\n",
            "|    time_elapsed       | 32          |\n",
            "|    total_timesteps    | 15000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.39       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2999        |\n",
            "|    policy_loss        | 0.0204      |\n",
            "|    reward             | 0.005723242 |\n",
            "|    std                | 2.64        |\n",
            "|    value_loss         | 0.000677    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 463           |\n",
            "|    iterations         | 3100          |\n",
            "|    time_elapsed       | 33            |\n",
            "|    total_timesteps    | 15500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.41         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3099          |\n",
            "|    policy_loss        | 0.0382        |\n",
            "|    reward             | -0.0051877126 |\n",
            "|    std                | 2.69          |\n",
            "|    value_loss         | 0.000229      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 464          |\n",
            "|    iterations         | 3200         |\n",
            "|    time_elapsed       | 34           |\n",
            "|    total_timesteps    | 16000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.43        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3199         |\n",
            "|    policy_loss        | -0.0286      |\n",
            "|    reward             | -0.012725413 |\n",
            "|    std                | 2.74         |\n",
            "|    value_loss         | 0.00011      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 465           |\n",
            "|    iterations         | 3300          |\n",
            "|    time_elapsed       | 35            |\n",
            "|    total_timesteps    | 16500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.45         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3299          |\n",
            "|    policy_loss        | -0.0238       |\n",
            "|    reward             | -0.0038695736 |\n",
            "|    std                | 2.8           |\n",
            "|    value_loss         | 0.000221      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 466          |\n",
            "|    iterations         | 3400         |\n",
            "|    time_elapsed       | 36           |\n",
            "|    total_timesteps    | 17000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.46        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3399         |\n",
            "|    policy_loss        | 0.0514       |\n",
            "|    reward             | 0.0028568504 |\n",
            "|    std                | 2.83         |\n",
            "|    value_loss         | 0.000605     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 467         |\n",
            "|    iterations         | 3500        |\n",
            "|    time_elapsed       | 37          |\n",
            "|    total_timesteps    | 17500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.49       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3499        |\n",
            "|    policy_loss        | 0.00414     |\n",
            "|    reward             | 0.010767339 |\n",
            "|    std                | 2.91        |\n",
            "|    value_loss         | 5.88e-06    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 467          |\n",
            "|    iterations         | 3600         |\n",
            "|    time_elapsed       | 38           |\n",
            "|    total_timesteps    | 18000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.51        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3599         |\n",
            "|    policy_loss        | 0.00381      |\n",
            "|    reward             | -0.004227005 |\n",
            "|    std                | 2.97         |\n",
            "|    value_loss         | 4.85e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 468          |\n",
            "|    iterations         | 3700         |\n",
            "|    time_elapsed       | 39           |\n",
            "|    total_timesteps    | 18500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.54        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3699         |\n",
            "|    policy_loss        | 0.0667       |\n",
            "|    reward             | -0.007946623 |\n",
            "|    std                | 3.06         |\n",
            "|    value_loss         | 0.000819     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 469         |\n",
            "|    iterations         | 3800        |\n",
            "|    time_elapsed       | 40          |\n",
            "|    total_timesteps    | 19000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.56       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3799        |\n",
            "|    policy_loss        | -0.0476     |\n",
            "|    reward             | 0.014907497 |\n",
            "|    std                | 3.13        |\n",
            "|    value_loss         | 0.000297    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 469          |\n",
            "|    iterations         | 3900         |\n",
            "|    time_elapsed       | 41           |\n",
            "|    total_timesteps    | 19500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.58        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3899         |\n",
            "|    policy_loss        | -0.0498      |\n",
            "|    reward             | -0.005656156 |\n",
            "|    std                | 3.19         |\n",
            "|    value_loss         | 0.00027      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 470           |\n",
            "|    iterations         | 4000          |\n",
            "|    time_elapsed       | 42            |\n",
            "|    total_timesteps    | 20000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.6          |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3999          |\n",
            "|    policy_loss        | 0.00282       |\n",
            "|    reward             | -0.0051441262 |\n",
            "|    std                | 3.27          |\n",
            "|    value_loss         | 1.45e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 470         |\n",
            "|    iterations         | 4100        |\n",
            "|    time_elapsed       | 43          |\n",
            "|    total_timesteps    | 20500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.63       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4099        |\n",
            "|    policy_loss        | -0.00853    |\n",
            "|    reward             | 0.001994923 |\n",
            "|    std                | 3.37        |\n",
            "|    value_loss         | 4.13e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 470          |\n",
            "|    iterations         | 4200         |\n",
            "|    time_elapsed       | 44           |\n",
            "|    total_timesteps    | 21000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.66        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4199         |\n",
            "|    policy_loss        | -0.0264      |\n",
            "|    reward             | -0.001408895 |\n",
            "|    std                | 3.48         |\n",
            "|    value_loss         | 0.000183     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 471           |\n",
            "|    iterations         | 4300          |\n",
            "|    time_elapsed       | 45            |\n",
            "|    total_timesteps    | 21500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.71         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4299          |\n",
            "|    policy_loss        | 0.075         |\n",
            "|    reward             | -0.0024569407 |\n",
            "|    std                | 3.65          |\n",
            "|    value_loss         | 0.00132       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 472          |\n",
            "|    iterations         | 4400         |\n",
            "|    time_elapsed       | 46           |\n",
            "|    total_timesteps    | 22000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.75        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4399         |\n",
            "|    policy_loss        | -0.00358     |\n",
            "|    reward             | 0.0059103062 |\n",
            "|    std                | 3.79         |\n",
            "|    value_loss         | 6.68e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 472           |\n",
            "|    iterations         | 4500          |\n",
            "|    time_elapsed       | 47            |\n",
            "|    total_timesteps    | 22500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.79         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4499          |\n",
            "|    policy_loss        | 0.0077        |\n",
            "|    reward             | 0.00041025568 |\n",
            "|    std                | 3.93          |\n",
            "|    value_loss         | 2.25e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 472          |\n",
            "|    iterations         | 4600         |\n",
            "|    time_elapsed       | 48           |\n",
            "|    total_timesteps    | 23000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.82        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4599         |\n",
            "|    policy_loss        | -0.0134      |\n",
            "|    reward             | -0.005387716 |\n",
            "|    std                | 4.04         |\n",
            "|    value_loss         | 2.26e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 473         |\n",
            "|    iterations         | 4700        |\n",
            "|    time_elapsed       | 49          |\n",
            "|    total_timesteps    | 23500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.85       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4699        |\n",
            "|    policy_loss        | -0.0553     |\n",
            "|    reward             | 0.005686498 |\n",
            "|    std                | 4.18        |\n",
            "|    value_loss         | 0.000452    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 474           |\n",
            "|    iterations         | 4800          |\n",
            "|    time_elapsed       | 50            |\n",
            "|    total_timesteps    | 24000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.88         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4799          |\n",
            "|    policy_loss        | 0.0308        |\n",
            "|    reward             | -0.0020513404 |\n",
            "|    std                | 4.33          |\n",
            "|    value_loss         | 0.000162      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 474          |\n",
            "|    iterations         | 4900         |\n",
            "|    time_elapsed       | 51           |\n",
            "|    total_timesteps    | 24500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.92        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4899         |\n",
            "|    policy_loss        | -0.0332      |\n",
            "|    reward             | -0.006258198 |\n",
            "|    std                | 4.47         |\n",
            "|    value_loss         | 0.000206     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 475         |\n",
            "|    iterations         | 5000        |\n",
            "|    time_elapsed       | 52          |\n",
            "|    total_timesteps    | 25000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.95       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4999        |\n",
            "|    policy_loss        | 0.0303      |\n",
            "|    reward             | 0.011377055 |\n",
            "|    std                | 4.63        |\n",
            "|    value_loss         | 7.82e-05    |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 475            |\n",
            "|    iterations         | 5100           |\n",
            "|    time_elapsed       | 53             |\n",
            "|    total_timesteps    | 25500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -2.97          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 5099           |\n",
            "|    policy_loss        | 0.0302         |\n",
            "|    reward             | -0.00044837975 |\n",
            "|    std                | 4.73           |\n",
            "|    value_loss         | 0.000204       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 475          |\n",
            "|    iterations         | 5200         |\n",
            "|    time_elapsed       | 54           |\n",
            "|    total_timesteps    | 26000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3           |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5199         |\n",
            "|    policy_loss        | 0.00516      |\n",
            "|    reward             | -0.005938096 |\n",
            "|    std                | 4.87         |\n",
            "|    value_loss         | 1.08e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 476          |\n",
            "|    iterations         | 5300         |\n",
            "|    time_elapsed       | 55           |\n",
            "|    total_timesteps    | 26500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.04        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5299         |\n",
            "|    policy_loss        | 0.0415       |\n",
            "|    reward             | -0.004663387 |\n",
            "|    std                | 5.04         |\n",
            "|    value_loss         | 0.000178     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 476          |\n",
            "|    iterations         | 5400         |\n",
            "|    time_elapsed       | 56           |\n",
            "|    total_timesteps    | 27000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.07        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5399         |\n",
            "|    policy_loss        | -0.033       |\n",
            "|    reward             | -0.010175882 |\n",
            "|    std                | 5.2          |\n",
            "|    value_loss         | 0.000278     |\n",
            "----------------------------------------\n",
            "day: 2707, episode: 10\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 9302.37\n",
            "total_reward: -697.63\n",
            "total_cost: 98.72\n",
            "total_trades: 2707\n",
            "Sharpe: 0.033\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 477         |\n",
            "|    iterations         | 5500        |\n",
            "|    time_elapsed       | 57          |\n",
            "|    total_timesteps    | 27500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.1        |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5499        |\n",
            "|    policy_loss        | 0.153       |\n",
            "|    reward             | 0.010114478 |\n",
            "|    std                | 5.37        |\n",
            "|    value_loss         | 0.00351     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 477          |\n",
            "|    iterations         | 5600         |\n",
            "|    time_elapsed       | 58           |\n",
            "|    total_timesteps    | 28000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.12        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5599         |\n",
            "|    policy_loss        | -0.00753     |\n",
            "|    reward             | 0.0016558662 |\n",
            "|    std                | 5.5          |\n",
            "|    value_loss         | 5.45e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 478          |\n",
            "|    iterations         | 5700         |\n",
            "|    time_elapsed       | 59           |\n",
            "|    total_timesteps    | 28500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.16        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5699         |\n",
            "|    policy_loss        | 0.0576       |\n",
            "|    reward             | -0.005008479 |\n",
            "|    std                | 5.69         |\n",
            "|    value_loss         | 0.00077      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 478          |\n",
            "|    iterations         | 5800         |\n",
            "|    time_elapsed       | 60           |\n",
            "|    total_timesteps    | 29000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.18        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5799         |\n",
            "|    policy_loss        | 0.00511      |\n",
            "|    reward             | -0.015094124 |\n",
            "|    std                | 5.84         |\n",
            "|    value_loss         | 8.15e-06     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 478           |\n",
            "|    iterations         | 5900          |\n",
            "|    time_elapsed       | 61            |\n",
            "|    total_timesteps    | 29500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.21         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5899          |\n",
            "|    policy_loss        | -0.00108      |\n",
            "|    reward             | -0.0020872583 |\n",
            "|    std                | 6.03          |\n",
            "|    value_loss         | 1.94e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 479          |\n",
            "|    iterations         | 6000         |\n",
            "|    time_elapsed       | 62           |\n",
            "|    total_timesteps    | 30000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.26        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5999         |\n",
            "|    policy_loss        | -0.157       |\n",
            "|    reward             | -0.019947741 |\n",
            "|    std                | 6.31         |\n",
            "|    value_loss         | 0.00352      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 479           |\n",
            "|    iterations         | 6100          |\n",
            "|    time_elapsed       | 63            |\n",
            "|    total_timesteps    | 30500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.29         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6099          |\n",
            "|    policy_loss        | 0.00442       |\n",
            "|    reward             | -1.763979e-06 |\n",
            "|    std                | 6.47          |\n",
            "|    value_loss         | 4.29e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 480         |\n",
            "|    iterations         | 6200        |\n",
            "|    time_elapsed       | 64          |\n",
            "|    total_timesteps    | 31000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.32       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6199        |\n",
            "|    policy_loss        | 0.0722      |\n",
            "|    reward             | -0.00441222 |\n",
            "|    std                | 6.66        |\n",
            "|    value_loss         | 0.00081     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 481          |\n",
            "|    iterations         | 6300         |\n",
            "|    time_elapsed       | 65           |\n",
            "|    total_timesteps    | 31500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.33        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6299         |\n",
            "|    policy_loss        | 0.081        |\n",
            "|    reward             | -0.002387418 |\n",
            "|    std                | 6.77         |\n",
            "|    value_loss         | 0.000746     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 481          |\n",
            "|    iterations         | 6400         |\n",
            "|    time_elapsed       | 66           |\n",
            "|    total_timesteps    | 32000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.37        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6399         |\n",
            "|    policy_loss        | -0.116       |\n",
            "|    reward             | -0.007705562 |\n",
            "|    std                | 7.01         |\n",
            "|    value_loss         | 0.00142      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 481           |\n",
            "|    iterations         | 6500          |\n",
            "|    time_elapsed       | 67            |\n",
            "|    total_timesteps    | 32500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.38         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6499          |\n",
            "|    policy_loss        | -0.0138       |\n",
            "|    reward             | -7.450626e-05 |\n",
            "|    std                | 7.13          |\n",
            "|    value_loss         | 4.35e-05      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 481            |\n",
            "|    iterations         | 6600           |\n",
            "|    time_elapsed       | 68             |\n",
            "|    total_timesteps    | 33000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -3.4           |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 6599           |\n",
            "|    policy_loss        | 0.0142         |\n",
            "|    reward             | -0.00031044052 |\n",
            "|    std                | 7.22           |\n",
            "|    value_loss         | 7.5e-05        |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 481          |\n",
            "|    iterations         | 6700         |\n",
            "|    time_elapsed       | 69           |\n",
            "|    total_timesteps    | 33500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.41        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6699         |\n",
            "|    policy_loss        | 0.016        |\n",
            "|    reward             | -0.008417517 |\n",
            "|    std                | 7.31         |\n",
            "|    value_loss         | 0.000139     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 481         |\n",
            "|    iterations         | 6800        |\n",
            "|    time_elapsed       | 70          |\n",
            "|    total_timesteps    | 34000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.44       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6799        |\n",
            "|    policy_loss        | -0.00443    |\n",
            "|    reward             | 0.008842922 |\n",
            "|    std                | 7.52        |\n",
            "|    value_loss         | 0.00013     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 481        |\n",
            "|    iterations         | 6900       |\n",
            "|    time_elapsed       | 71         |\n",
            "|    total_timesteps    | 34500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -3.47      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6899       |\n",
            "|    policy_loss        | -0.0329    |\n",
            "|    reward             | 0.03248672 |\n",
            "|    std                | 7.76       |\n",
            "|    value_loss         | 0.000163   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 482         |\n",
            "|    iterations         | 7000        |\n",
            "|    time_elapsed       | 72          |\n",
            "|    total_timesteps    | 35000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.49       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6999        |\n",
            "|    policy_loss        | 0.043       |\n",
            "|    reward             | -0.03841668 |\n",
            "|    std                | 7.94        |\n",
            "|    value_loss         | 0.000396    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 482         |\n",
            "|    iterations         | 7100        |\n",
            "|    time_elapsed       | 73          |\n",
            "|    total_timesteps    | 35500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.5        |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7099        |\n",
            "|    policy_loss        | 0.0879      |\n",
            "|    reward             | 0.041121434 |\n",
            "|    std                | 8           |\n",
            "|    value_loss         | 0.00196     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 482         |\n",
            "|    iterations         | 7200        |\n",
            "|    time_elapsed       | 74          |\n",
            "|    total_timesteps    | 36000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.51       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7199        |\n",
            "|    policy_loss        | 0.0334      |\n",
            "|    reward             | 0.009564037 |\n",
            "|    std                | 8.13        |\n",
            "|    value_loss         | 9.76e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 483         |\n",
            "|    iterations         | 7300        |\n",
            "|    time_elapsed       | 75          |\n",
            "|    total_timesteps    | 36500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.54       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7299        |\n",
            "|    policy_loss        | -0.00998    |\n",
            "|    reward             | -0.02832216 |\n",
            "|    std                | 8.32        |\n",
            "|    value_loss         | 2.08e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 483          |\n",
            "|    iterations         | 7400         |\n",
            "|    time_elapsed       | 76           |\n",
            "|    total_timesteps    | 37000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.55        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7399         |\n",
            "|    policy_loss        | 0.0148       |\n",
            "|    reward             | 0.0020851865 |\n",
            "|    std                | 8.44         |\n",
            "|    value_loss         | 3.46e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 483           |\n",
            "|    iterations         | 7500          |\n",
            "|    time_elapsed       | 77            |\n",
            "|    total_timesteps    | 37500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.58         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7499          |\n",
            "|    policy_loss        | 0.0948        |\n",
            "|    reward             | -0.0050326902 |\n",
            "|    std                | 8.67          |\n",
            "|    value_loss         | 0.00113       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 482         |\n",
            "|    iterations         | 7600        |\n",
            "|    time_elapsed       | 78          |\n",
            "|    total_timesteps    | 38000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.59       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7599        |\n",
            "|    policy_loss        | 0.0384      |\n",
            "|    reward             | 0.009989732 |\n",
            "|    std                | 8.76        |\n",
            "|    value_loss         | 0.000241    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 483          |\n",
            "|    iterations         | 7700         |\n",
            "|    time_elapsed       | 79           |\n",
            "|    total_timesteps    | 38500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.62        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7699         |\n",
            "|    policy_loss        | 0.0223       |\n",
            "|    reward             | 0.0006280488 |\n",
            "|    std                | 9            |\n",
            "|    value_loss         | 0.000409     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 483          |\n",
            "|    iterations         | 7800         |\n",
            "|    time_elapsed       | 80           |\n",
            "|    total_timesteps    | 39000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.64        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7799         |\n",
            "|    policy_loss        | -0.0901      |\n",
            "|    reward             | 0.0003066233 |\n",
            "|    std                | 9.17         |\n",
            "|    value_loss         | 0.000616     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 485          |\n",
            "|    iterations         | 7900         |\n",
            "|    time_elapsed       | 81           |\n",
            "|    total_timesteps    | 39500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.66        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7899         |\n",
            "|    policy_loss        | -0.00853     |\n",
            "|    reward             | -0.012057186 |\n",
            "|    std                | 9.42         |\n",
            "|    value_loss         | 2.88e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 485         |\n",
            "|    iterations         | 8000        |\n",
            "|    time_elapsed       | 82          |\n",
            "|    total_timesteps    | 40000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.68       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7999        |\n",
            "|    policy_loss        | -0.0348     |\n",
            "|    reward             | -0.01017442 |\n",
            "|    std                | 9.61        |\n",
            "|    value_loss         | 0.000209    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 486          |\n",
            "|    iterations         | 8100         |\n",
            "|    time_elapsed       | 83           |\n",
            "|    total_timesteps    | 40500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.69        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8099         |\n",
            "|    policy_loss        | 0.0187       |\n",
            "|    reward             | -0.012565887 |\n",
            "|    std                | 9.67         |\n",
            "|    value_loss         | 8.38e-05     |\n",
            "----------------------------------------\n",
            "day: 2707, episode: 15\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 11606.12\n",
            "total_reward: 1606.12\n",
            "total_cost: 95.84\n",
            "total_trades: 2707\n",
            "Sharpe: 0.176\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 486          |\n",
            "|    iterations         | 8200         |\n",
            "|    time_elapsed       | 84           |\n",
            "|    total_timesteps    | 41000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.72        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8199         |\n",
            "|    policy_loss        | 0.0083       |\n",
            "|    reward             | 0.0035138135 |\n",
            "|    std                | 9.95         |\n",
            "|    value_loss         | 4.54e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 483          |\n",
            "|    iterations         | 8300         |\n",
            "|    time_elapsed       | 85           |\n",
            "|    total_timesteps    | 41500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.74        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8299         |\n",
            "|    policy_loss        | 0.0689       |\n",
            "|    reward             | 0.0020346872 |\n",
            "|    std                | 10.2         |\n",
            "|    value_loss         | 0.000371     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 483          |\n",
            "|    iterations         | 8400         |\n",
            "|    time_elapsed       | 86           |\n",
            "|    total_timesteps    | 42000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.77        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8399         |\n",
            "|    policy_loss        | -0.0195      |\n",
            "|    reward             | 0.0011534069 |\n",
            "|    std                | 10.5         |\n",
            "|    value_loss         | 7.6e-05      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 483          |\n",
            "|    iterations         | 8500         |\n",
            "|    time_elapsed       | 87           |\n",
            "|    total_timesteps    | 42500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.8         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8499         |\n",
            "|    policy_loss        | -0.039       |\n",
            "|    reward             | 0.0019559385 |\n",
            "|    std                | 10.8         |\n",
            "|    value_loss         | 0.00016      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 484           |\n",
            "|    iterations         | 8600          |\n",
            "|    time_elapsed       | 88            |\n",
            "|    total_timesteps    | 43000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.83         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8599          |\n",
            "|    policy_loss        | -0.0641       |\n",
            "|    reward             | -0.0019657062 |\n",
            "|    std                | 11.1          |\n",
            "|    value_loss         | 0.000307      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 484          |\n",
            "|    iterations         | 8700         |\n",
            "|    time_elapsed       | 89           |\n",
            "|    total_timesteps    | 43500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.87        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8699         |\n",
            "|    policy_loss        | 0.0768       |\n",
            "|    reward             | 0.0055827685 |\n",
            "|    std                | 11.6         |\n",
            "|    value_loss         | 0.00065      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 484          |\n",
            "|    iterations         | 8800         |\n",
            "|    time_elapsed       | 90           |\n",
            "|    total_timesteps    | 44000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.88        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8799         |\n",
            "|    policy_loss        | -0.0547      |\n",
            "|    reward             | 0.0014241873 |\n",
            "|    std                | 11.7         |\n",
            "|    value_loss         | 0.000251     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 485           |\n",
            "|    iterations         | 8900          |\n",
            "|    time_elapsed       | 91            |\n",
            "|    total_timesteps    | 44500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.9          |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8899          |\n",
            "|    policy_loss        | -0.103        |\n",
            "|    reward             | -0.0068976386 |\n",
            "|    std                | 12            |\n",
            "|    value_loss         | 0.000995      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 485           |\n",
            "|    iterations         | 9000          |\n",
            "|    time_elapsed       | 92            |\n",
            "|    total_timesteps    | 45000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.93         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8999          |\n",
            "|    policy_loss        | -0.0221       |\n",
            "|    reward             | -0.0037346126 |\n",
            "|    std                | 12.3          |\n",
            "|    value_loss         | 8.27e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 485          |\n",
            "|    iterations         | 9100         |\n",
            "|    time_elapsed       | 93           |\n",
            "|    total_timesteps    | 45500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.95        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9099         |\n",
            "|    policy_loss        | -0.0765      |\n",
            "|    reward             | 0.0051525515 |\n",
            "|    std                | 12.5         |\n",
            "|    value_loss         | 0.00043      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 486           |\n",
            "|    iterations         | 9200          |\n",
            "|    time_elapsed       | 94            |\n",
            "|    total_timesteps    | 46000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.97         |\n",
            "|    explained_variance | -2.38e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9199          |\n",
            "|    policy_loss        | 0.0212        |\n",
            "|    reward             | -0.0021742925 |\n",
            "|    std                | 12.8          |\n",
            "|    value_loss         | 0.000951      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 486          |\n",
            "|    iterations         | 9300         |\n",
            "|    time_elapsed       | 95           |\n",
            "|    total_timesteps    | 46500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.98        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9299         |\n",
            "|    policy_loss        | 0.0741       |\n",
            "|    reward             | 0.0020448116 |\n",
            "|    std                | 13           |\n",
            "|    value_loss         | 0.000551     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 487           |\n",
            "|    iterations         | 9400          |\n",
            "|    time_elapsed       | 96            |\n",
            "|    total_timesteps    | 47000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.99         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9399          |\n",
            "|    policy_loss        | 0.0271        |\n",
            "|    reward             | -0.0041910135 |\n",
            "|    std                | 13.1          |\n",
            "|    value_loss         | 3.88e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 487          |\n",
            "|    iterations         | 9500         |\n",
            "|    time_elapsed       | 97           |\n",
            "|    total_timesteps    | 47500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.02        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9499         |\n",
            "|    policy_loss        | 0.0186       |\n",
            "|    reward             | -0.012557133 |\n",
            "|    std                | 13.5         |\n",
            "|    value_loss         | 4.69e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 487          |\n",
            "|    iterations         | 9600         |\n",
            "|    time_elapsed       | 98           |\n",
            "|    total_timesteps    | 48000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.05        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9599         |\n",
            "|    policy_loss        | -0.0106      |\n",
            "|    reward             | -0.005087637 |\n",
            "|    std                | 13.9         |\n",
            "|    value_loss         | 2.57e-05     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 487            |\n",
            "|    iterations         | 9700           |\n",
            "|    time_elapsed       | 99             |\n",
            "|    total_timesteps    | 48500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -4.08          |\n",
            "|    explained_variance | -1.19e-07      |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 9699           |\n",
            "|    policy_loss        | 0.0393         |\n",
            "|    reward             | -0.00056826364 |\n",
            "|    std                | 14.3           |\n",
            "|    value_loss         | 0.00012        |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 488         |\n",
            "|    iterations         | 9800        |\n",
            "|    time_elapsed       | 100         |\n",
            "|    total_timesteps    | 49000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.11       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9799        |\n",
            "|    policy_loss        | -0.0746     |\n",
            "|    reward             | 0.007774502 |\n",
            "|    std                | 14.7        |\n",
            "|    value_loss         | 0.000356    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 488          |\n",
            "|    iterations         | 9900         |\n",
            "|    time_elapsed       | 101          |\n",
            "|    total_timesteps    | 49500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.14        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9899         |\n",
            "|    policy_loss        | 0.0143       |\n",
            "|    reward             | 0.0032110158 |\n",
            "|    std                | 15.1         |\n",
            "|    value_loss         | 3.65e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 489          |\n",
            "|    iterations         | 10000        |\n",
            "|    time_elapsed       | 102          |\n",
            "|    total_timesteps    | 50000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.17        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9999         |\n",
            "|    policy_loss        | -0.0088      |\n",
            "|    reward             | -0.005288533 |\n",
            "|    std                | 15.6         |\n",
            "|    value_loss         | 8.78e-06     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 489          |\n",
            "|    iterations         | 10100        |\n",
            "|    time_elapsed       | 103          |\n",
            "|    total_timesteps    | 50500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.2         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10099        |\n",
            "|    policy_loss        | -0.0435      |\n",
            "|    reward             | 0.0043215724 |\n",
            "|    std                | 16.1         |\n",
            "|    value_loss         | 0.000129     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 490            |\n",
            "|    iterations         | 10200          |\n",
            "|    time_elapsed       | 104            |\n",
            "|    total_timesteps    | 51000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -4.23          |\n",
            "|    explained_variance | 1.19e-07       |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 10199          |\n",
            "|    policy_loss        | -0.0372        |\n",
            "|    reward             | -0.00056108536 |\n",
            "|    std                | 16.6           |\n",
            "|    value_loss         | 0.000138       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 490          |\n",
            "|    iterations         | 10300        |\n",
            "|    time_elapsed       | 104          |\n",
            "|    total_timesteps    | 51500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.24        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10299        |\n",
            "|    policy_loss        | 0.014        |\n",
            "|    reward             | -0.019062668 |\n",
            "|    std                | 16.8         |\n",
            "|    value_loss         | 0.000779     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 490          |\n",
            "|    iterations         | 10400        |\n",
            "|    time_elapsed       | 105          |\n",
            "|    total_timesteps    | 52000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.26        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10399        |\n",
            "|    policy_loss        | 0.0419       |\n",
            "|    reward             | 0.0034321595 |\n",
            "|    std                | 17.1         |\n",
            "|    value_loss         | 0.000195     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 491           |\n",
            "|    iterations         | 10500         |\n",
            "|    time_elapsed       | 106           |\n",
            "|    total_timesteps    | 52500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.27         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10499         |\n",
            "|    policy_loss        | -0.032        |\n",
            "|    reward             | -0.0012050633 |\n",
            "|    std                | 17.4          |\n",
            "|    value_loss         | 7.33e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 491          |\n",
            "|    iterations         | 10600        |\n",
            "|    time_elapsed       | 107          |\n",
            "|    total_timesteps    | 53000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.3         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10599        |\n",
            "|    policy_loss        | 0.0294       |\n",
            "|    reward             | -0.005219434 |\n",
            "|    std                | 17.8         |\n",
            "|    value_loss         | 6.82e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 491          |\n",
            "|    iterations         | 10700        |\n",
            "|    time_elapsed       | 108          |\n",
            "|    total_timesteps    | 53500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.32        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10699        |\n",
            "|    policy_loss        | -0.0852      |\n",
            "|    reward             | -0.010133128 |\n",
            "|    std                | 18.1         |\n",
            "|    value_loss         | 0.000478     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 492           |\n",
            "|    iterations         | 10800         |\n",
            "|    time_elapsed       | 109           |\n",
            "|    total_timesteps    | 54000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.34         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10799         |\n",
            "|    policy_loss        | -0.216        |\n",
            "|    reward             | -0.0010657229 |\n",
            "|    std                | 18.7          |\n",
            "|    value_loss         | 0.00344       |\n",
            "-----------------------------------------\n",
            "day: 2707, episode: 20\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 11354.79\n",
            "total_reward: 1354.79\n",
            "total_cost: 95.98\n",
            "total_trades: 2707\n",
            "Sharpe: 0.173\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 492          |\n",
            "|    iterations         | 10900        |\n",
            "|    time_elapsed       | 110          |\n",
            "|    total_timesteps    | 54500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.36        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10899        |\n",
            "|    policy_loss        | 0.419        |\n",
            "|    reward             | -0.001252636 |\n",
            "|    std                | 19           |\n",
            "|    value_loss         | 0.00775      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 492          |\n",
            "|    iterations         | 11000        |\n",
            "|    time_elapsed       | 111          |\n",
            "|    total_timesteps    | 55000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.37        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10999        |\n",
            "|    policy_loss        | -0.00439     |\n",
            "|    reward             | 0.0043616043 |\n",
            "|    std                | 19.1         |\n",
            "|    value_loss         | 0.000109     |\n",
            "----------------------------------------\n",
            "======A2C Validation from:  2021-01-04 to  2021-02-03\n",
            "A2C Sharpe Ratio:  -0.10127737498854991\n",
            "======Best Model Retraining from:  2010-04-01 to  2021-02-03\n",
            "======Trading from:  2021-02-03 to  2021-03-05\n",
            "[[1.0000000e+04 2.3006052e+01 0.0000000e+00 5.1831186e-01 2.5277428e+01\n",
            "  2.1408876e+01 5.4136814e+01 1.9200577e+01 1.9295473e+01 2.2654924e+01\n",
            "  2.1628794e+01]]\n",
            "============================================\n",
            "turbulence_threshold:  12.04306128869847\n",
            "======Model training from:  2010-04-01 to  2021-02-03\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c\\a2c_63_1\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 535          |\n",
            "|    iterations         | 100          |\n",
            "|    time_elapsed       | 0            |\n",
            "|    total_timesteps    | 500          |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.46        |\n",
            "|    explained_variance | -2.38e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 99           |\n",
            "|    policy_loss        | -0.0399      |\n",
            "|    reward             | -0.018957831 |\n",
            "|    std                | 1.04         |\n",
            "|    value_loss         | 0.00116      |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 531        |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 1          |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.47      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | 0.0134     |\n",
            "|    reward             | 0.01259868 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 0.00246    |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 534          |\n",
            "|    iterations         | 300          |\n",
            "|    time_elapsed       | 2            |\n",
            "|    total_timesteps    | 1500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.46        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 299          |\n",
            "|    policy_loss        | -0.055       |\n",
            "|    reward             | -0.085458994 |\n",
            "|    std                | 1.05         |\n",
            "|    value_loss         | 0.0012       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 531          |\n",
            "|    iterations         | 400          |\n",
            "|    time_elapsed       | 3            |\n",
            "|    total_timesteps    | 2000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.47        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 399          |\n",
            "|    policy_loss        | -0.114       |\n",
            "|    reward             | -0.012509877 |\n",
            "|    std                | 1.05         |\n",
            "|    value_loss         | 0.00435      |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 533        |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 4          |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.48      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | 0.0929     |\n",
            "|    reward             | 0.31499726 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 0.0265     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 536         |\n",
            "|    iterations         | 600         |\n",
            "|    time_elapsed       | 5           |\n",
            "|    total_timesteps    | 3000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.49       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 599         |\n",
            "|    policy_loss        | -0.046      |\n",
            "|    reward             | 0.009413286 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 0.000697    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 534          |\n",
            "|    iterations         | 700          |\n",
            "|    time_elapsed       | 6            |\n",
            "|    total_timesteps    | 3500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.51        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 699          |\n",
            "|    policy_loss        | 0.071        |\n",
            "|    reward             | -0.013597755 |\n",
            "|    std                | 1.09         |\n",
            "|    value_loss         | 0.00327      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 535           |\n",
            "|    iterations         | 800           |\n",
            "|    time_elapsed       | 7             |\n",
            "|    total_timesteps    | 4000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.51         |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 799           |\n",
            "|    policy_loss        | -0.0298       |\n",
            "|    reward             | -0.0024242846 |\n",
            "|    std                | 1.1           |\n",
            "|    value_loss         | 0.000672      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 538          |\n",
            "|    iterations         | 900          |\n",
            "|    time_elapsed       | 8            |\n",
            "|    total_timesteps    | 4500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.51        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 899          |\n",
            "|    policy_loss        | 0.00349      |\n",
            "|    reward             | 0.0068219528 |\n",
            "|    std                | 1.1          |\n",
            "|    value_loss         | 7.78e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 538          |\n",
            "|    iterations         | 1000         |\n",
            "|    time_elapsed       | 9            |\n",
            "|    total_timesteps    | 5000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.52        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 999          |\n",
            "|    policy_loss        | -0.0994      |\n",
            "|    reward             | -0.032487676 |\n",
            "|    std                | 1.1          |\n",
            "|    value_loss         | 0.0084       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 538          |\n",
            "|    iterations         | 1100         |\n",
            "|    time_elapsed       | 10           |\n",
            "|    total_timesteps    | 5500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.52        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1099         |\n",
            "|    policy_loss        | 0.00115      |\n",
            "|    reward             | -0.006619855 |\n",
            "|    std                | 1.11         |\n",
            "|    value_loss         | 7.01e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 536         |\n",
            "|    iterations         | 1200        |\n",
            "|    time_elapsed       | 11          |\n",
            "|    total_timesteps    | 6000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.53       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1199        |\n",
            "|    policy_loss        | 0.0141      |\n",
            "|    reward             | 0.004604678 |\n",
            "|    std                | 1.12        |\n",
            "|    value_loss         | 0.000123    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 536           |\n",
            "|    iterations         | 1300          |\n",
            "|    time_elapsed       | 12            |\n",
            "|    total_timesteps    | 6500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.55         |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1299          |\n",
            "|    policy_loss        | 0.00191       |\n",
            "|    reward             | -0.0019282274 |\n",
            "|    std                | 1.14          |\n",
            "|    value_loss         | 4.97e-06      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 534         |\n",
            "|    iterations         | 1400        |\n",
            "|    time_elapsed       | 13          |\n",
            "|    total_timesteps    | 7000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.58       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1399        |\n",
            "|    policy_loss        | -0.0188     |\n",
            "|    reward             | 0.005511158 |\n",
            "|    std                | 1.17        |\n",
            "|    value_loss         | 0.000136    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 534           |\n",
            "|    iterations         | 1500          |\n",
            "|    time_elapsed       | 14            |\n",
            "|    total_timesteps    | 7500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.61         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1499          |\n",
            "|    policy_loss        | -0.0293       |\n",
            "|    reward             | -0.0028489546 |\n",
            "|    std                | 1.21          |\n",
            "|    value_loss         | 0.00023       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 535          |\n",
            "|    iterations         | 1600         |\n",
            "|    time_elapsed       | 14           |\n",
            "|    total_timesteps    | 8000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.65        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1599         |\n",
            "|    policy_loss        | 0.0791       |\n",
            "|    reward             | -0.009476329 |\n",
            "|    std                | 1.26         |\n",
            "|    value_loss         | 0.0013       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 536           |\n",
            "|    iterations         | 1700          |\n",
            "|    time_elapsed       | 15            |\n",
            "|    total_timesteps    | 8500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.67         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1699          |\n",
            "|    policy_loss        | -0.023        |\n",
            "|    reward             | 0.00065461517 |\n",
            "|    std                | 1.29          |\n",
            "|    value_loss         | 0.00012       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 537          |\n",
            "|    iterations         | 1800         |\n",
            "|    time_elapsed       | 16           |\n",
            "|    total_timesteps    | 9000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.71        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1799         |\n",
            "|    policy_loss        | -0.0119      |\n",
            "|    reward             | 0.0015286952 |\n",
            "|    std                | 1.34         |\n",
            "|    value_loss         | 0.000129     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 537         |\n",
            "|    iterations         | 1900        |\n",
            "|    time_elapsed       | 17          |\n",
            "|    total_timesteps    | 9500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.74       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1899        |\n",
            "|    policy_loss        | 0.00571     |\n",
            "|    reward             | 0.009788888 |\n",
            "|    std                | 1.38        |\n",
            "|    value_loss         | 2.78e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 535         |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 18          |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.78       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | 0.0148      |\n",
            "|    reward             | 0.005288105 |\n",
            "|    std                | 1.43        |\n",
            "|    value_loss         | 8.41e-05    |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 534            |\n",
            "|    iterations         | 2100           |\n",
            "|    time_elapsed       | 19             |\n",
            "|    total_timesteps    | 10500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -1.82          |\n",
            "|    explained_variance | -1.19e-07      |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 2099           |\n",
            "|    policy_loss        | -0.0249        |\n",
            "|    reward             | -0.00089183287 |\n",
            "|    std                | 1.49           |\n",
            "|    value_loss         | 0.000284       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 535          |\n",
            "|    iterations         | 2200         |\n",
            "|    time_elapsed       | 20           |\n",
            "|    total_timesteps    | 11000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.87        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2199         |\n",
            "|    policy_loss        | -0.089       |\n",
            "|    reward             | -0.008976458 |\n",
            "|    std                | 1.57         |\n",
            "|    value_loss         | 0.00286      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 534          |\n",
            "|    iterations         | 2300         |\n",
            "|    time_elapsed       | 21           |\n",
            "|    total_timesteps    | 11500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.89        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2299         |\n",
            "|    policy_loss        | -0.032       |\n",
            "|    reward             | -0.030212816 |\n",
            "|    std                | 1.61         |\n",
            "|    value_loss         | 0.000295     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 533         |\n",
            "|    iterations         | 2400        |\n",
            "|    time_elapsed       | 22          |\n",
            "|    total_timesteps    | 12000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.92       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2399        |\n",
            "|    policy_loss        | 0.0101      |\n",
            "|    reward             | 0.031060454 |\n",
            "|    std                | 1.65        |\n",
            "|    value_loss         | 3.3e-05     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 533           |\n",
            "|    iterations         | 2500          |\n",
            "|    time_elapsed       | 23            |\n",
            "|    total_timesteps    | 12500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.95         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2499          |\n",
            "|    policy_loss        | -0.0385       |\n",
            "|    reward             | -0.0012978347 |\n",
            "|    std                | 1.7           |\n",
            "|    value_loss         | 0.000211      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 533          |\n",
            "|    iterations         | 2600         |\n",
            "|    time_elapsed       | 24           |\n",
            "|    total_timesteps    | 13000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.98        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2599         |\n",
            "|    policy_loss        | -0.0103      |\n",
            "|    reward             | -0.004889012 |\n",
            "|    std                | 1.76         |\n",
            "|    value_loss         | 4.55e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 533          |\n",
            "|    iterations         | 2700         |\n",
            "|    time_elapsed       | 25           |\n",
            "|    total_timesteps    | 13500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.02        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2699         |\n",
            "|    policy_loss        | -0.0195      |\n",
            "|    reward             | 0.0036330232 |\n",
            "|    std                | 1.83         |\n",
            "|    value_loss         | 6.89e-05     |\n",
            "----------------------------------------\n",
            "day: 2728, episode: 5\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 9435.93\n",
            "total_reward: -564.07\n",
            "total_cost: 116.94\n",
            "total_trades: 2728\n",
            "Sharpe: 0.039\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 532          |\n",
            "|    iterations         | 2800         |\n",
            "|    time_elapsed       | 26           |\n",
            "|    total_timesteps    | 14000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.04        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2799         |\n",
            "|    policy_loss        | 0.0505       |\n",
            "|    reward             | -0.009182716 |\n",
            "|    std                | 1.86         |\n",
            "|    value_loss         | 0.00089      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 532         |\n",
            "|    iterations         | 2900        |\n",
            "|    time_elapsed       | 27          |\n",
            "|    total_timesteps    | 14500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.06       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2899        |\n",
            "|    policy_loss        | 0.0194      |\n",
            "|    reward             | 0.003361248 |\n",
            "|    std                | 1.9         |\n",
            "|    value_loss         | 0.00013     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 531          |\n",
            "|    iterations         | 3000         |\n",
            "|    time_elapsed       | 28           |\n",
            "|    total_timesteps    | 15000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.11        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2999         |\n",
            "|    policy_loss        | 6.9e-05      |\n",
            "|    reward             | 0.0007887793 |\n",
            "|    std                | 1.99         |\n",
            "|    value_loss         | 4.8e-06      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 531           |\n",
            "|    iterations         | 3100          |\n",
            "|    time_elapsed       | 29            |\n",
            "|    total_timesteps    | 15500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.14         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3099          |\n",
            "|    policy_loss        | -0.00438      |\n",
            "|    reward             | -0.0056835753 |\n",
            "|    std                | 2.06          |\n",
            "|    value_loss         | 4.1e-06       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 531         |\n",
            "|    iterations         | 3200        |\n",
            "|    time_elapsed       | 30          |\n",
            "|    total_timesteps    | 16000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.19       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3199        |\n",
            "|    policy_loss        | 0.025       |\n",
            "|    reward             | 0.003346098 |\n",
            "|    std                | 2.15        |\n",
            "|    value_loss         | 0.000173    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 529         |\n",
            "|    iterations         | 3300        |\n",
            "|    time_elapsed       | 31          |\n",
            "|    total_timesteps    | 16500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.23       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3299        |\n",
            "|    policy_loss        | 0.0335      |\n",
            "|    reward             | 0.015745552 |\n",
            "|    std                | 2.24        |\n",
            "|    value_loss         | 0.000321    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 529         |\n",
            "|    iterations         | 3400        |\n",
            "|    time_elapsed       | 32          |\n",
            "|    total_timesteps    | 17000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.24       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3399        |\n",
            "|    policy_loss        | -0.0335     |\n",
            "|    reward             | 0.005483175 |\n",
            "|    std                | 2.28        |\n",
            "|    value_loss         | 0.000272    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 528           |\n",
            "|    iterations         | 3500          |\n",
            "|    time_elapsed       | 33            |\n",
            "|    total_timesteps    | 17500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.27         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3499          |\n",
            "|    policy_loss        | 0.0177        |\n",
            "|    reward             | 0.00043897776 |\n",
            "|    std                | 2.35          |\n",
            "|    value_loss         | 4.81e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 527          |\n",
            "|    iterations         | 3600         |\n",
            "|    time_elapsed       | 34           |\n",
            "|    total_timesteps    | 18000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.3         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3599         |\n",
            "|    policy_loss        | -0.00727     |\n",
            "|    reward             | -0.004927355 |\n",
            "|    std                | 2.43         |\n",
            "|    value_loss         | 1.9e-05      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 526          |\n",
            "|    iterations         | 3700         |\n",
            "|    time_elapsed       | 35           |\n",
            "|    total_timesteps    | 18500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.34        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3699         |\n",
            "|    policy_loss        | 0.00891      |\n",
            "|    reward             | 0.0015196066 |\n",
            "|    std                | 2.51         |\n",
            "|    value_loss         | 1.27e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 526           |\n",
            "|    iterations         | 3800          |\n",
            "|    time_elapsed       | 36            |\n",
            "|    total_timesteps    | 19000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.37         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3799          |\n",
            "|    policy_loss        | -0.00613      |\n",
            "|    reward             | -0.0023439256 |\n",
            "|    std                | 2.59          |\n",
            "|    value_loss         | 1.41e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 525         |\n",
            "|    iterations         | 3900        |\n",
            "|    time_elapsed       | 37          |\n",
            "|    total_timesteps    | 19500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.41       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3899        |\n",
            "|    policy_loss        | 0.0228      |\n",
            "|    reward             | -0.00808457 |\n",
            "|    std                | 2.69        |\n",
            "|    value_loss         | 0.000235    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 525        |\n",
            "|    iterations         | 4000       |\n",
            "|    time_elapsed       | 38         |\n",
            "|    total_timesteps    | 20000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.44      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3999       |\n",
            "|    policy_loss        | -0.0384    |\n",
            "|    reward             | 0.02516258 |\n",
            "|    std                | 2.78       |\n",
            "|    value_loss         | 0.000273   |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 525           |\n",
            "|    iterations         | 4100          |\n",
            "|    time_elapsed       | 38            |\n",
            "|    total_timesteps    | 20500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.47         |\n",
            "|    explained_variance | -2.38e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4099          |\n",
            "|    policy_loss        | -0.00971      |\n",
            "|    reward             | -0.0014984669 |\n",
            "|    std                | 2.87          |\n",
            "|    value_loss         | 6.2e-05       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 526         |\n",
            "|    iterations         | 4200        |\n",
            "|    time_elapsed       | 39          |\n",
            "|    total_timesteps    | 21000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.52       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4199        |\n",
            "|    policy_loss        | -0.0111     |\n",
            "|    reward             | 0.016253524 |\n",
            "|    std                | 3           |\n",
            "|    value_loss         | 2.87e-05    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 526           |\n",
            "|    iterations         | 4300          |\n",
            "|    time_elapsed       | 40            |\n",
            "|    total_timesteps    | 21500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.55         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4299          |\n",
            "|    policy_loss        | 0.0349        |\n",
            "|    reward             | -0.0032640414 |\n",
            "|    std                | 3.1           |\n",
            "|    value_loss         | 0.000281      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 526            |\n",
            "|    iterations         | 4400           |\n",
            "|    time_elapsed       | 41             |\n",
            "|    total_timesteps    | 22000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -2.59          |\n",
            "|    explained_variance | 5.96e-08       |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 4399           |\n",
            "|    policy_loss        | -0.00619       |\n",
            "|    reward             | -0.00094072946 |\n",
            "|    std                | 3.22           |\n",
            "|    value_loss         | 5.11e-05       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 526           |\n",
            "|    iterations         | 4500          |\n",
            "|    time_elapsed       | 42            |\n",
            "|    total_timesteps    | 22500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.61         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4499          |\n",
            "|    policy_loss        | 0.0521        |\n",
            "|    reward             | -0.0020425285 |\n",
            "|    std                | 3.29          |\n",
            "|    value_loss         | 0.000342      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 526          |\n",
            "|    iterations         | 4600         |\n",
            "|    time_elapsed       | 43           |\n",
            "|    total_timesteps    | 23000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.64        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4599         |\n",
            "|    policy_loss        | 0.0263       |\n",
            "|    reward             | 0.0021163323 |\n",
            "|    std                | 3.41         |\n",
            "|    value_loss         | 0.00019      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 524          |\n",
            "|    iterations         | 4700         |\n",
            "|    time_elapsed       | 44           |\n",
            "|    total_timesteps    | 23500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.68        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4699         |\n",
            "|    policy_loss        | 0.00551      |\n",
            "|    reward             | -0.009234346 |\n",
            "|    std                | 3.54         |\n",
            "|    value_loss         | 0.000127     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 524           |\n",
            "|    iterations         | 4800          |\n",
            "|    time_elapsed       | 45            |\n",
            "|    total_timesteps    | 24000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.72         |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4799          |\n",
            "|    policy_loss        | -0.0385       |\n",
            "|    reward             | -0.0032827063 |\n",
            "|    std                | 3.69          |\n",
            "|    value_loss         | 0.000283      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 524          |\n",
            "|    iterations         | 4900         |\n",
            "|    time_elapsed       | 46           |\n",
            "|    total_timesteps    | 24500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.76        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4899         |\n",
            "|    policy_loss        | 0.0714       |\n",
            "|    reward             | 0.0010700907 |\n",
            "|    std                | 3.83         |\n",
            "|    value_loss         | 0.0007       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 524           |\n",
            "|    iterations         | 5000          |\n",
            "|    time_elapsed       | 47            |\n",
            "|    total_timesteps    | 25000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.79         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4999          |\n",
            "|    policy_loss        | 0.0474        |\n",
            "|    reward             | 0.00080081675 |\n",
            "|    std                | 3.95          |\n",
            "|    value_loss         | 0.000275      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 524          |\n",
            "|    iterations         | 5100         |\n",
            "|    time_elapsed       | 48           |\n",
            "|    total_timesteps    | 25500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.82        |\n",
            "|    explained_variance | -2.38e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5099         |\n",
            "|    policy_loss        | 0.0115       |\n",
            "|    reward             | 0.0015119489 |\n",
            "|    std                | 4.08         |\n",
            "|    value_loss         | 9.97e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 524          |\n",
            "|    iterations         | 5200         |\n",
            "|    time_elapsed       | 49           |\n",
            "|    total_timesteps    | 26000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.86        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5199         |\n",
            "|    policy_loss        | 0.028        |\n",
            "|    reward             | 0.0048281914 |\n",
            "|    std                | 4.22         |\n",
            "|    value_loss         | 0.000159     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 524         |\n",
            "|    iterations         | 5300        |\n",
            "|    time_elapsed       | 50          |\n",
            "|    total_timesteps    | 26500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.89       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5299        |\n",
            "|    policy_loss        | 0.0273      |\n",
            "|    reward             | -0.00645372 |\n",
            "|    std                | 4.35        |\n",
            "|    value_loss         | 0.000161    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 524           |\n",
            "|    iterations         | 5400          |\n",
            "|    time_elapsed       | 51            |\n",
            "|    total_timesteps    | 27000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.92         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5399          |\n",
            "|    policy_loss        | 0.0249        |\n",
            "|    reward             | 0.00082196604 |\n",
            "|    std                | 4.5           |\n",
            "|    value_loss         | 0.000103      |\n",
            "-----------------------------------------\n",
            "day: 2728, episode: 10\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 8735.42\n",
            "total_reward: -1264.58\n",
            "total_cost: 106.72\n",
            "total_trades: 2728\n",
            "Sharpe: -0.022\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 524          |\n",
            "|    iterations         | 5500         |\n",
            "|    time_elapsed       | 52           |\n",
            "|    total_timesteps    | 27500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.95        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5499         |\n",
            "|    policy_loss        | 0.0852       |\n",
            "|    reward             | -0.011953032 |\n",
            "|    std                | 4.62         |\n",
            "|    value_loss         | 0.0015       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 525         |\n",
            "|    iterations         | 5600        |\n",
            "|    time_elapsed       | 53          |\n",
            "|    total_timesteps    | 28000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.97       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5599        |\n",
            "|    policy_loss        | -0.02       |\n",
            "|    reward             | 0.007617959 |\n",
            "|    std                | 4.74        |\n",
            "|    value_loss         | 7.02e-05    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 525           |\n",
            "|    iterations         | 5700          |\n",
            "|    time_elapsed       | 54            |\n",
            "|    total_timesteps    | 28500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3            |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5699          |\n",
            "|    policy_loss        | 0.0215        |\n",
            "|    reward             | -0.0035519444 |\n",
            "|    std                | 4.88          |\n",
            "|    value_loss         | 7.44e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 524         |\n",
            "|    iterations         | 5800        |\n",
            "|    time_elapsed       | 55          |\n",
            "|    total_timesteps    | 29000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.04       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5799        |\n",
            "|    policy_loss        | 0.0177      |\n",
            "|    reward             | 0.005632067 |\n",
            "|    std                | 5.05        |\n",
            "|    value_loss         | 4.79e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 525          |\n",
            "|    iterations         | 5900         |\n",
            "|    time_elapsed       | 56           |\n",
            "|    total_timesteps    | 29500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.08        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5899         |\n",
            "|    policy_loss        | -0.0179      |\n",
            "|    reward             | 0.0018052692 |\n",
            "|    std                | 5.24         |\n",
            "|    value_loss         | 5.26e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 524           |\n",
            "|    iterations         | 6000          |\n",
            "|    time_elapsed       | 57            |\n",
            "|    total_timesteps    | 30000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.12         |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5999          |\n",
            "|    policy_loss        | 0.0166        |\n",
            "|    reward             | -0.0042897714 |\n",
            "|    std                | 5.48          |\n",
            "|    value_loss         | 2.33e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 525           |\n",
            "|    iterations         | 6100          |\n",
            "|    time_elapsed       | 58            |\n",
            "|    total_timesteps    | 30500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.15         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6099          |\n",
            "|    policy_loss        | -0.0193       |\n",
            "|    reward             | -0.0037913416 |\n",
            "|    std                | 5.67          |\n",
            "|    value_loss         | 0.000335      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 525         |\n",
            "|    iterations         | 6200        |\n",
            "|    time_elapsed       | 59          |\n",
            "|    total_timesteps    | 31000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.17       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6199        |\n",
            "|    policy_loss        | 0.017       |\n",
            "|    reward             | 0.007808078 |\n",
            "|    std                | 5.79        |\n",
            "|    value_loss         | 4.34e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 525          |\n",
            "|    iterations         | 6300         |\n",
            "|    time_elapsed       | 59           |\n",
            "|    total_timesteps    | 31500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.21        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6299         |\n",
            "|    policy_loss        | 0.0197       |\n",
            "|    reward             | -0.009401337 |\n",
            "|    std                | 5.98         |\n",
            "|    value_loss         | 0.000163     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 525           |\n",
            "|    iterations         | 6400          |\n",
            "|    time_elapsed       | 60            |\n",
            "|    total_timesteps    | 32000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.25         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6399          |\n",
            "|    policy_loss        | 0.0488        |\n",
            "|    reward             | -0.0054880497 |\n",
            "|    std                | 6.23          |\n",
            "|    value_loss         | 0.000411      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 526          |\n",
            "|    iterations         | 6500         |\n",
            "|    time_elapsed       | 61           |\n",
            "|    total_timesteps    | 32500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.29        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6499         |\n",
            "|    policy_loss        | 0.000642     |\n",
            "|    reward             | -0.006060642 |\n",
            "|    std                | 6.51         |\n",
            "|    value_loss         | 8.24e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 525          |\n",
            "|    iterations         | 6600         |\n",
            "|    time_elapsed       | 62           |\n",
            "|    total_timesteps    | 33000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.33        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6599         |\n",
            "|    policy_loss        | -0.0418      |\n",
            "|    reward             | -0.005523927 |\n",
            "|    std                | 6.75         |\n",
            "|    value_loss         | 0.000433     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 525          |\n",
            "|    iterations         | 6700         |\n",
            "|    time_elapsed       | 63           |\n",
            "|    total_timesteps    | 33500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.36        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6699         |\n",
            "|    policy_loss        | 0.0782       |\n",
            "|    reward             | 0.0028249724 |\n",
            "|    std                | 6.94         |\n",
            "|    value_loss         | 0.000612     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 525          |\n",
            "|    iterations         | 6800         |\n",
            "|    time_elapsed       | 64           |\n",
            "|    total_timesteps    | 34000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.39        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6799         |\n",
            "|    policy_loss        | 0.00402      |\n",
            "|    reward             | 0.0076724463 |\n",
            "|    std                | 7.15         |\n",
            "|    value_loss         | 3.4e-06      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 526           |\n",
            "|    iterations         | 6900          |\n",
            "|    time_elapsed       | 65            |\n",
            "|    total_timesteps    | 34500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.42         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6899          |\n",
            "|    policy_loss        | 0.0045        |\n",
            "|    reward             | -0.0022433093 |\n",
            "|    std                | 7.37          |\n",
            "|    value_loss         | 1.52e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 526          |\n",
            "|    iterations         | 7000         |\n",
            "|    time_elapsed       | 66           |\n",
            "|    total_timesteps    | 35000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.45        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6999         |\n",
            "|    policy_loss        | 0.0418       |\n",
            "|    reward             | -0.003363219 |\n",
            "|    std                | 7.65         |\n",
            "|    value_loss         | 0.000138     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 526           |\n",
            "|    iterations         | 7100          |\n",
            "|    time_elapsed       | 67            |\n",
            "|    total_timesteps    | 35500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.49         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7099          |\n",
            "|    policy_loss        | 0.0566        |\n",
            "|    reward             | -0.0073397304 |\n",
            "|    std                | 7.97          |\n",
            "|    value_loss         | 0.000341      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 526           |\n",
            "|    iterations         | 7200          |\n",
            "|    time_elapsed       | 68            |\n",
            "|    total_timesteps    | 36000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.53         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7199          |\n",
            "|    policy_loss        | 0.0425        |\n",
            "|    reward             | 0.00096932886 |\n",
            "|    std                | 8.23          |\n",
            "|    value_loss         | 0.000121      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 526         |\n",
            "|    iterations         | 7300        |\n",
            "|    time_elapsed       | 69          |\n",
            "|    total_timesteps    | 36500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.55       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7299        |\n",
            "|    policy_loss        | -0.0205     |\n",
            "|    reward             | 0.012733252 |\n",
            "|    std                | 8.4         |\n",
            "|    value_loss         | 5.47e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 526          |\n",
            "|    iterations         | 7400         |\n",
            "|    time_elapsed       | 70           |\n",
            "|    total_timesteps    | 37000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.58        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7399         |\n",
            "|    policy_loss        | 0.0437       |\n",
            "|    reward             | 0.0028923824 |\n",
            "|    std                | 8.65         |\n",
            "|    value_loss         | 0.000266     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 526           |\n",
            "|    iterations         | 7500          |\n",
            "|    time_elapsed       | 71            |\n",
            "|    total_timesteps    | 37500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.61         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7499          |\n",
            "|    policy_loss        | -0.00642      |\n",
            "|    reward             | -0.0022406373 |\n",
            "|    std                | 8.96          |\n",
            "|    value_loss         | 1.01e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 526         |\n",
            "|    iterations         | 7600        |\n",
            "|    time_elapsed       | 72          |\n",
            "|    total_timesteps    | 38000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.65       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7599        |\n",
            "|    policy_loss        | -0.00279    |\n",
            "|    reward             | 0.010684643 |\n",
            "|    std                | 9.3         |\n",
            "|    value_loss         | 7.18e-05    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 526        |\n",
            "|    iterations         | 7700       |\n",
            "|    time_elapsed       | 73         |\n",
            "|    total_timesteps    | 38500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -3.69      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7699       |\n",
            "|    policy_loss        | 0.195      |\n",
            "|    reward             | 0.09609873 |\n",
            "|    std                | 9.66       |\n",
            "|    value_loss         | 0.00323    |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 526          |\n",
            "|    iterations         | 7800         |\n",
            "|    time_elapsed       | 74           |\n",
            "|    total_timesteps    | 39000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.71        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7799         |\n",
            "|    policy_loss        | -0.0143      |\n",
            "|    reward             | -0.010840343 |\n",
            "|    std                | 9.91         |\n",
            "|    value_loss         | 5.41e-05     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 526            |\n",
            "|    iterations         | 7900           |\n",
            "|    time_elapsed       | 75             |\n",
            "|    total_timesteps    | 39500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -3.75          |\n",
            "|    explained_variance | 1.19e-07       |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 7899           |\n",
            "|    policy_loss        | -0.00204       |\n",
            "|    reward             | -0.00015105438 |\n",
            "|    std                | 10.2           |\n",
            "|    value_loss         | 2.3e-06        |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 526         |\n",
            "|    iterations         | 8000        |\n",
            "|    time_elapsed       | 76          |\n",
            "|    total_timesteps    | 40000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.77       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7999        |\n",
            "|    policy_loss        | -0.00732    |\n",
            "|    reward             | 0.009211829 |\n",
            "|    std                | 10.5        |\n",
            "|    value_loss         | 3.71e-06    |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 526            |\n",
            "|    iterations         | 8100           |\n",
            "|    time_elapsed       | 76             |\n",
            "|    total_timesteps    | 40500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -3.81          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 8099           |\n",
            "|    policy_loss        | 0.058          |\n",
            "|    reward             | -0.00060511375 |\n",
            "|    std                | 10.9           |\n",
            "|    value_loss         | 0.000283       |\n",
            "------------------------------------------\n",
            "day: 2728, episode: 15\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 11342.36\n",
            "total_reward: 1342.36\n",
            "total_cost: 102.21\n",
            "total_trades: 2728\n",
            "Sharpe: 0.152\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 526            |\n",
            "|    iterations         | 8200           |\n",
            "|    time_elapsed       | 77             |\n",
            "|    total_timesteps    | 41000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -3.85          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 8199           |\n",
            "|    policy_loss        | -0.00583       |\n",
            "|    reward             | -0.00016163854 |\n",
            "|    std                | 11.4           |\n",
            "|    value_loss         | 4.28e-05       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 526           |\n",
            "|    iterations         | 8300          |\n",
            "|    time_elapsed       | 78            |\n",
            "|    total_timesteps    | 41500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.88         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8299          |\n",
            "|    policy_loss        | -0.0299       |\n",
            "|    reward             | -0.0027760193 |\n",
            "|    std                | 11.8          |\n",
            "|    value_loss         | 7.81e-05      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 526            |\n",
            "|    iterations         | 8400           |\n",
            "|    time_elapsed       | 79             |\n",
            "|    total_timesteps    | 42000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -3.92          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 8399           |\n",
            "|    policy_loss        | -0.0289        |\n",
            "|    reward             | -0.00015882056 |\n",
            "|    std                | 12.2           |\n",
            "|    value_loss         | 6.57e-05       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 526            |\n",
            "|    iterations         | 8500           |\n",
            "|    time_elapsed       | 80             |\n",
            "|    total_timesteps    | 42500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -3.96          |\n",
            "|    explained_variance | 1.19e-07       |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 8499           |\n",
            "|    policy_loss        | 0.0219         |\n",
            "|    reward             | -0.00043945268 |\n",
            "|    std                | 12.7           |\n",
            "|    value_loss         | 3.28e-05       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 526          |\n",
            "|    iterations         | 8600         |\n",
            "|    time_elapsed       | 81           |\n",
            "|    total_timesteps    | 43000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4           |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8599         |\n",
            "|    policy_loss        | -0.018       |\n",
            "|    reward             | 0.0013447286 |\n",
            "|    std                | 13.3         |\n",
            "|    value_loss         | 3.25e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 526           |\n",
            "|    iterations         | 8700          |\n",
            "|    time_elapsed       | 82            |\n",
            "|    total_timesteps    | 43500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.04         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8699          |\n",
            "|    policy_loss        | -0.0264       |\n",
            "|    reward             | -0.0027567311 |\n",
            "|    std                | 13.8          |\n",
            "|    value_loss         | 7.56e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 526         |\n",
            "|    iterations         | 8800        |\n",
            "|    time_elapsed       | 83          |\n",
            "|    total_timesteps    | 44000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.08       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8799        |\n",
            "|    policy_loss        | -0.00424    |\n",
            "|    reward             | 0.007224325 |\n",
            "|    std                | 14.3        |\n",
            "|    value_loss         | 0.000155    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 526           |\n",
            "|    iterations         | 8900          |\n",
            "|    time_elapsed       | 84            |\n",
            "|    total_timesteps    | 44500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.1          |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8899          |\n",
            "|    policy_loss        | 0.00996       |\n",
            "|    reward             | 0.00047565487 |\n",
            "|    std                | 14.6          |\n",
            "|    value_loss         | 2.95e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 526           |\n",
            "|    iterations         | 9000          |\n",
            "|    time_elapsed       | 85            |\n",
            "|    total_timesteps    | 45000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.13         |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8999          |\n",
            "|    policy_loss        | -0.0138       |\n",
            "|    reward             | -0.0052901604 |\n",
            "|    std                | 15            |\n",
            "|    value_loss         | 1.91e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 526          |\n",
            "|    iterations         | 9100         |\n",
            "|    time_elapsed       | 86           |\n",
            "|    total_timesteps    | 45500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.16        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9099         |\n",
            "|    policy_loss        | -0.0464      |\n",
            "|    reward             | 0.0038124707 |\n",
            "|    std                | 15.5         |\n",
            "|    value_loss         | 0.000215     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 526           |\n",
            "|    iterations         | 9200          |\n",
            "|    time_elapsed       | 87            |\n",
            "|    total_timesteps    | 46000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.21         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9199          |\n",
            "|    policy_loss        | 0.0339        |\n",
            "|    reward             | -0.0015570845 |\n",
            "|    std                | 16.3          |\n",
            "|    value_loss         | 9.06e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 526          |\n",
            "|    iterations         | 9300         |\n",
            "|    time_elapsed       | 88           |\n",
            "|    total_timesteps    | 46500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.25        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9299         |\n",
            "|    policy_loss        | -0.000323    |\n",
            "|    reward             | -0.010259041 |\n",
            "|    std                | 16.9         |\n",
            "|    value_loss         | 1.3e-05      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 526          |\n",
            "|    iterations         | 9400         |\n",
            "|    time_elapsed       | 89           |\n",
            "|    total_timesteps    | 47000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.27        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9399         |\n",
            "|    policy_loss        | 0.0175       |\n",
            "|    reward             | -0.000255808 |\n",
            "|    std                | 17.4         |\n",
            "|    value_loss         | 6.92e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 526          |\n",
            "|    iterations         | 9500         |\n",
            "|    time_elapsed       | 90           |\n",
            "|    total_timesteps    | 47500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.31        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9499         |\n",
            "|    policy_loss        | 0.00187      |\n",
            "|    reward             | 0.0061531565 |\n",
            "|    std                | 18           |\n",
            "|    value_loss         | 2.27e-05     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 527            |\n",
            "|    iterations         | 9600           |\n",
            "|    time_elapsed       | 91             |\n",
            "|    total_timesteps    | 48000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -4.34          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 9599           |\n",
            "|    policy_loss        | -0.0305        |\n",
            "|    reward             | -1.9507218e-06 |\n",
            "|    std                | 18.6           |\n",
            "|    value_loss         | 7.6e-05        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 527           |\n",
            "|    iterations         | 9700          |\n",
            "|    time_elapsed       | 92            |\n",
            "|    total_timesteps    | 48500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.38         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9699          |\n",
            "|    policy_loss        | -0.0289       |\n",
            "|    reward             | 0.00053066766 |\n",
            "|    std                | 19.4          |\n",
            "|    value_loss         | 5.06e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 527           |\n",
            "|    iterations         | 9800          |\n",
            "|    time_elapsed       | 92            |\n",
            "|    total_timesteps    | 49000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.42         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9799          |\n",
            "|    policy_loss        | -0.0178       |\n",
            "|    reward             | -0.0014935979 |\n",
            "|    std                | 20.1          |\n",
            "|    value_loss         | 5.02e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 527         |\n",
            "|    iterations         | 9900        |\n",
            "|    time_elapsed       | 93          |\n",
            "|    total_timesteps    | 49500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.44       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9899        |\n",
            "|    policy_loss        | 0.118       |\n",
            "|    reward             | 0.012284214 |\n",
            "|    std                | 20.6        |\n",
            "|    value_loss         | 0.000593    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 527         |\n",
            "|    iterations         | 10000       |\n",
            "|    time_elapsed       | 94          |\n",
            "|    total_timesteps    | 50000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.46       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9999        |\n",
            "|    policy_loss        | -0.0107     |\n",
            "|    reward             | -0.00092692 |\n",
            "|    std                | 20.9        |\n",
            "|    value_loss         | 2.53e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 527         |\n",
            "|    iterations         | 10100       |\n",
            "|    time_elapsed       | 95          |\n",
            "|    total_timesteps    | 50500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.49       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10099       |\n",
            "|    policy_loss        | -0.0281     |\n",
            "|    reward             | 0.008252494 |\n",
            "|    std                | 21.6        |\n",
            "|    value_loss         | 4.68e-05    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 526           |\n",
            "|    iterations         | 10200         |\n",
            "|    time_elapsed       | 96            |\n",
            "|    total_timesteps    | 51000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.52         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10199         |\n",
            "|    policy_loss        | 0.0516        |\n",
            "|    reward             | -0.0038416926 |\n",
            "|    std                | 22.3          |\n",
            "|    value_loss         | 0.000131      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 526           |\n",
            "|    iterations         | 10300         |\n",
            "|    time_elapsed       | 97            |\n",
            "|    total_timesteps    | 51500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.56         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10299         |\n",
            "|    policy_loss        | -0.0891       |\n",
            "|    reward             | 0.00072044594 |\n",
            "|    std                | 23.1          |\n",
            "|    value_loss         | 0.00032       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 525          |\n",
            "|    iterations         | 10400        |\n",
            "|    time_elapsed       | 98           |\n",
            "|    total_timesteps    | 52000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.6         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10399        |\n",
            "|    policy_loss        | -0.0635      |\n",
            "|    reward             | -0.006515237 |\n",
            "|    std                | 24           |\n",
            "|    value_loss         | 0.00044      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 525           |\n",
            "|    iterations         | 10500         |\n",
            "|    time_elapsed       | 99            |\n",
            "|    total_timesteps    | 52500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.61         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10499         |\n",
            "|    policy_loss        | -0.15         |\n",
            "|    reward             | -0.0019383166 |\n",
            "|    std                | 24.4          |\n",
            "|    value_loss         | 0.00121       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 525          |\n",
            "|    iterations         | 10600        |\n",
            "|    time_elapsed       | 100          |\n",
            "|    total_timesteps    | 53000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.63        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10599        |\n",
            "|    policy_loss        | -0.0108      |\n",
            "|    reward             | -0.013611244 |\n",
            "|    std                | 24.8         |\n",
            "|    value_loss         | 0.000182     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 525           |\n",
            "|    iterations         | 10700         |\n",
            "|    time_elapsed       | 101           |\n",
            "|    total_timesteps    | 53500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.66         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10699         |\n",
            "|    policy_loss        | 0.0476        |\n",
            "|    reward             | -0.0061636087 |\n",
            "|    std                | 25.6          |\n",
            "|    value_loss         | 0.000111      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 525           |\n",
            "|    iterations         | 10800         |\n",
            "|    time_elapsed       | 102           |\n",
            "|    total_timesteps    | 54000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.7          |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10799         |\n",
            "|    policy_loss        | 0.0427        |\n",
            "|    reward             | -0.0063246572 |\n",
            "|    std                | 26.7          |\n",
            "|    value_loss         | 0.000108      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 525          |\n",
            "|    iterations         | 10900        |\n",
            "|    time_elapsed       | 103          |\n",
            "|    total_timesteps    | 54500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.75        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10899        |\n",
            "|    policy_loss        | 0.0129       |\n",
            "|    reward             | -0.006856712 |\n",
            "|    std                | 27.9         |\n",
            "|    value_loss         | 4.92e-05     |\n",
            "----------------------------------------\n",
            "day: 2728, episode: 20\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 11498.20\n",
            "total_reward: 1498.20\n",
            "total_cost: 99.57\n",
            "total_trades: 2728\n",
            "Sharpe: 0.161\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 525         |\n",
            "|    iterations         | 11000       |\n",
            "|    time_elapsed       | 104         |\n",
            "|    total_timesteps    | 55000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.76       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10999       |\n",
            "|    policy_loss        | 0.23        |\n",
            "|    reward             | 0.009167825 |\n",
            "|    std                | 28.4        |\n",
            "|    value_loss         | 0.00289     |\n",
            "---------------------------------------\n",
            "======A2C Validation from:  2021-02-03 to  2021-03-05\n",
            "A2C Sharpe Ratio:  0.22581522873511847\n",
            "======Best Model Retraining from:  2010-04-01 to  2021-03-05\n",
            "======Trading from:  2021-03-05 to  2021-04-06\n",
            "[[ 1.3835466e+04  2.2706450e+01 -1.6500000e+02 -1.3646212e-01\n",
            "   2.4332907e+01  2.1708006e+01  5.0922882e+01 -7.3293579e+01\n",
            "   2.7244115e+00  2.3299644e+01  2.2521513e+01]]\n",
            "============================================\n",
            "turbulence_threshold:  12.04306128869847\n",
            "======Model training from:  2010-04-01 to  2021-03-05\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c\\a2c_84_1\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 531          |\n",
            "|    iterations         | 100          |\n",
            "|    time_elapsed       | 0            |\n",
            "|    total_timesteps    | 500          |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.47        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 99           |\n",
            "|    policy_loss        | -0.0301      |\n",
            "|    reward             | -0.011911564 |\n",
            "|    std                | 1.05         |\n",
            "|    value_loss         | 0.000612     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 518          |\n",
            "|    iterations         | 200          |\n",
            "|    time_elapsed       | 1            |\n",
            "|    total_timesteps    | 1000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.49        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 199          |\n",
            "|    policy_loss        | 0.0141       |\n",
            "|    reward             | 0.0050985557 |\n",
            "|    std                | 1.08         |\n",
            "|    value_loss         | 0.000443     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 522          |\n",
            "|    iterations         | 300          |\n",
            "|    time_elapsed       | 2            |\n",
            "|    total_timesteps    | 1500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.52        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 299          |\n",
            "|    policy_loss        | -0.0128      |\n",
            "|    reward             | -0.025948465 |\n",
            "|    std                | 1.1          |\n",
            "|    value_loss         | 7.07e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 520           |\n",
            "|    iterations         | 400           |\n",
            "|    time_elapsed       | 3             |\n",
            "|    total_timesteps    | 2000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.54         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 399           |\n",
            "|    policy_loss        | -0.0166       |\n",
            "|    reward             | -0.0033597427 |\n",
            "|    std                | 1.13          |\n",
            "|    value_loss         | 0.000285      |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 518        |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 4          |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.56      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | 0.0128     |\n",
            "|    reward             | 0.08146646 |\n",
            "|    std                | 1.15       |\n",
            "|    value_loss         | 0.00141    |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 521        |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 5          |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.58      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | 0.0422     |\n",
            "|    reward             | -0.0107793 |\n",
            "|    std                | 1.18       |\n",
            "|    value_loss         | 0.0014     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 518         |\n",
            "|    iterations         | 700         |\n",
            "|    time_elapsed       | 6           |\n",
            "|    total_timesteps    | 3500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.61       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 699         |\n",
            "|    policy_loss        | 0.0548      |\n",
            "|    reward             | 0.007422926 |\n",
            "|    std                | 1.21        |\n",
            "|    value_loss         | 0.00101     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 519           |\n",
            "|    iterations         | 800           |\n",
            "|    time_elapsed       | 7             |\n",
            "|    total_timesteps    | 4000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.63         |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 799           |\n",
            "|    policy_loss        | 0.0128        |\n",
            "|    reward             | -0.0009984773 |\n",
            "|    std                | 1.24          |\n",
            "|    value_loss         | 0.000105      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 900          |\n",
            "|    time_elapsed       | 8            |\n",
            "|    total_timesteps    | 4500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.66        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 899          |\n",
            "|    policy_loss        | 0.0543       |\n",
            "|    reward             | -0.007861089 |\n",
            "|    std                | 1.27         |\n",
            "|    value_loss         | 0.000849     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 524          |\n",
            "|    iterations         | 1000         |\n",
            "|    time_elapsed       | 9            |\n",
            "|    total_timesteps    | 5000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.67        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 999          |\n",
            "|    policy_loss        | 0.059        |\n",
            "|    reward             | -0.006921303 |\n",
            "|    std                | 1.28         |\n",
            "|    value_loss         | 0.00164      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 523         |\n",
            "|    iterations         | 1100        |\n",
            "|    time_elapsed       | 10          |\n",
            "|    total_timesteps    | 5500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.68       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1099        |\n",
            "|    policy_loss        | 0.0465      |\n",
            "|    reward             | 0.021649946 |\n",
            "|    std                | 1.3         |\n",
            "|    value_loss         | 0.00132     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 523          |\n",
            "|    iterations         | 1200         |\n",
            "|    time_elapsed       | 11           |\n",
            "|    total_timesteps    | 6000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.7         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1199         |\n",
            "|    policy_loss        | -0.0216      |\n",
            "|    reward             | -0.008720439 |\n",
            "|    std                | 1.33         |\n",
            "|    value_loss         | 0.000326     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 523          |\n",
            "|    iterations         | 1300         |\n",
            "|    time_elapsed       | 12           |\n",
            "|    total_timesteps    | 6500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.73        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1299         |\n",
            "|    policy_loss        | 0.0195       |\n",
            "|    reward             | 0.0057786456 |\n",
            "|    std                | 1.36         |\n",
            "|    value_loss         | 0.000545     |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 521        |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 13         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.74      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | -0.0169    |\n",
            "|    reward             | -0.0395008 |\n",
            "|    std                | 1.38       |\n",
            "|    value_loss         | 0.000227   |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 1500         |\n",
            "|    time_elapsed       | 14           |\n",
            "|    total_timesteps    | 7500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.75        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1499         |\n",
            "|    policy_loss        | -0.0208      |\n",
            "|    reward             | -0.005636828 |\n",
            "|    std                | 1.39         |\n",
            "|    value_loss         | 0.000838     |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 521        |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 15         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.76      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | 0.0537     |\n",
            "|    reward             | 0.13560511 |\n",
            "|    std                | 1.41       |\n",
            "|    value_loss         | 0.00455    |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 519          |\n",
            "|    iterations         | 1700         |\n",
            "|    time_elapsed       | 16           |\n",
            "|    total_timesteps    | 8500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.78        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1699         |\n",
            "|    policy_loss        | 0.138        |\n",
            "|    reward             | -0.018055135 |\n",
            "|    std                | 1.43         |\n",
            "|    value_loss         | 0.00369      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 521         |\n",
            "|    iterations         | 1800        |\n",
            "|    time_elapsed       | 17          |\n",
            "|    total_timesteps    | 9000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.8        |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1799        |\n",
            "|    policy_loss        | 0.126       |\n",
            "|    reward             | 0.014237704 |\n",
            "|    std                | 1.46        |\n",
            "|    value_loss         | 0.00383     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 1900         |\n",
            "|    time_elapsed       | 18           |\n",
            "|    total_timesteps    | 9500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.82        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1899         |\n",
            "|    policy_loss        | 0.017        |\n",
            "|    reward             | -0.001977074 |\n",
            "|    std                | 1.49         |\n",
            "|    value_loss         | 0.000312     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 2000         |\n",
            "|    time_elapsed       | 19           |\n",
            "|    total_timesteps    | 10000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.83        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1999         |\n",
            "|    policy_loss        | 0.0718       |\n",
            "|    reward             | -0.013339993 |\n",
            "|    std                | 1.51         |\n",
            "|    value_loss         | 0.00221      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 2100         |\n",
            "|    time_elapsed       | 20           |\n",
            "|    total_timesteps    | 10500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.85        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2099         |\n",
            "|    policy_loss        | 0.154        |\n",
            "|    reward             | -0.011169392 |\n",
            "|    std                | 1.54         |\n",
            "|    value_loss         | 0.00473      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 520         |\n",
            "|    iterations         | 2200        |\n",
            "|    time_elapsed       | 21          |\n",
            "|    total_timesteps    | 11000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.86       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2199        |\n",
            "|    policy_loss        | 0.0916      |\n",
            "|    reward             | 0.030825831 |\n",
            "|    std                | 1.56        |\n",
            "|    value_loss         | 0.00292     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 520         |\n",
            "|    iterations         | 2300        |\n",
            "|    time_elapsed       | 22          |\n",
            "|    total_timesteps    | 11500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.88       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2299        |\n",
            "|    policy_loss        | -0.0295     |\n",
            "|    reward             | -0.01099932 |\n",
            "|    std                | 1.58        |\n",
            "|    value_loss         | 0.0005      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 521         |\n",
            "|    iterations         | 2400        |\n",
            "|    time_elapsed       | 23          |\n",
            "|    total_timesteps    | 12000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.89       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2399        |\n",
            "|    policy_loss        | 0.0329      |\n",
            "|    reward             | 0.007859301 |\n",
            "|    std                | 1.6         |\n",
            "|    value_loss         | 0.000943    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 521         |\n",
            "|    iterations         | 2500        |\n",
            "|    time_elapsed       | 23          |\n",
            "|    total_timesteps    | 12500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.91       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2499        |\n",
            "|    policy_loss        | -0.0283     |\n",
            "|    reward             | -0.05146903 |\n",
            "|    std                | 1.63        |\n",
            "|    value_loss         | 0.000364    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 2600         |\n",
            "|    time_elapsed       | 24           |\n",
            "|    total_timesteps    | 13000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.91        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2599         |\n",
            "|    policy_loss        | -0.0431      |\n",
            "|    reward             | -0.007984613 |\n",
            "|    std                | 1.64         |\n",
            "|    value_loss         | 0.00174      |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 520        |\n",
            "|    iterations         | 2700       |\n",
            "|    time_elapsed       | 25         |\n",
            "|    total_timesteps    | 13500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.93      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2699       |\n",
            "|    policy_loss        | 0.0639     |\n",
            "|    reward             | 0.22662708 |\n",
            "|    std                | 1.66       |\n",
            "|    value_loss         | 0.0136     |\n",
            "--------------------------------------\n",
            "day: 2749, episode: 5\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 8226.94\n",
            "total_reward: -1773.06\n",
            "total_cost: 114.53\n",
            "total_trades: 2749\n",
            "Sharpe: 0.453\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 2800         |\n",
            "|    time_elapsed       | 26           |\n",
            "|    total_timesteps    | 14000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.94        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2799         |\n",
            "|    policy_loss        | 0.125        |\n",
            "|    reward             | -0.019634387 |\n",
            "|    std                | 1.68         |\n",
            "|    value_loss         | 0.00451      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 520         |\n",
            "|    iterations         | 2900        |\n",
            "|    time_elapsed       | 27          |\n",
            "|    total_timesteps    | 14500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.95       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2899        |\n",
            "|    policy_loss        | 0.194       |\n",
            "|    reward             | 0.020775298 |\n",
            "|    std                | 1.7         |\n",
            "|    value_loss         | 0.00805     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 520           |\n",
            "|    iterations         | 3000          |\n",
            "|    time_elapsed       | 28            |\n",
            "|    total_timesteps    | 15000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.96         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2999          |\n",
            "|    policy_loss        | 0.0314        |\n",
            "|    reward             | -0.0032196164 |\n",
            "|    std                | 1.71          |\n",
            "|    value_loss         | 0.00077       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 520         |\n",
            "|    iterations         | 3100        |\n",
            "|    time_elapsed       | 29          |\n",
            "|    total_timesteps    | 15500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.97       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3099        |\n",
            "|    policy_loss        | 0.136       |\n",
            "|    reward             | -0.02380593 |\n",
            "|    std                | 1.74        |\n",
            "|    value_loss         | 0.00693     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 518          |\n",
            "|    iterations         | 3200         |\n",
            "|    time_elapsed       | 30           |\n",
            "|    total_timesteps    | 16000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.98        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3199         |\n",
            "|    policy_loss        | 0.279        |\n",
            "|    reward             | -0.021291833 |\n",
            "|    std                | 1.75         |\n",
            "|    value_loss         | 0.0176       |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 518        |\n",
            "|    iterations         | 3300       |\n",
            "|    time_elapsed       | 31         |\n",
            "|    total_timesteps    | 16500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.99      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3299       |\n",
            "|    policy_loss        | 0.285      |\n",
            "|    reward             | 0.05906985 |\n",
            "|    std                | 1.77       |\n",
            "|    value_loss         | 0.0111     |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 519          |\n",
            "|    iterations         | 3400         |\n",
            "|    time_elapsed       | 32           |\n",
            "|    total_timesteps    | 17000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2           |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3399         |\n",
            "|    policy_loss        | -0.0344      |\n",
            "|    reward             | -0.011634548 |\n",
            "|    std                | 1.78         |\n",
            "|    value_loss         | 0.000522     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 520         |\n",
            "|    iterations         | 3500        |\n",
            "|    time_elapsed       | 33          |\n",
            "|    total_timesteps    | 17500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2          |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3499        |\n",
            "|    policy_loss        | 0.0429      |\n",
            "|    reward             | 0.009145096 |\n",
            "|    std                | 1.79        |\n",
            "|    value_loss         | 0.00121     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 3600         |\n",
            "|    time_elapsed       | 34           |\n",
            "|    total_timesteps    | 18000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.02        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3599         |\n",
            "|    policy_loss        | -0.034       |\n",
            "|    reward             | -0.065394156 |\n",
            "|    std                | 1.83         |\n",
            "|    value_loss         | 0.000582     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 3700         |\n",
            "|    time_elapsed       | 35           |\n",
            "|    total_timesteps    | 18500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.04        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3699         |\n",
            "|    policy_loss        | -0.0868      |\n",
            "|    reward             | -0.010058693 |\n",
            "|    std                | 1.85         |\n",
            "|    value_loss         | 0.00285      |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 520       |\n",
            "|    iterations         | 3800      |\n",
            "|    time_elapsed       | 36        |\n",
            "|    total_timesteps    | 19000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.05     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3799      |\n",
            "|    policy_loss        | 0.065     |\n",
            "|    reward             | 0.2705468 |\n",
            "|    std                | 1.87      |\n",
            "|    value_loss         | 0.0193    |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 519          |\n",
            "|    iterations         | 3900         |\n",
            "|    time_elapsed       | 37           |\n",
            "|    total_timesteps    | 19500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.06        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3899         |\n",
            "|    policy_loss        | 0.132        |\n",
            "|    reward             | -0.020085601 |\n",
            "|    std                | 1.89         |\n",
            "|    value_loss         | 0.00499      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 518         |\n",
            "|    iterations         | 4000        |\n",
            "|    time_elapsed       | 38          |\n",
            "|    total_timesteps    | 20000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.06       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3999        |\n",
            "|    policy_loss        | 0.141       |\n",
            "|    reward             | 0.020116469 |\n",
            "|    std                | 1.9         |\n",
            "|    value_loss         | 0.00752     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 518           |\n",
            "|    iterations         | 4100          |\n",
            "|    time_elapsed       | 39            |\n",
            "|    total_timesteps    | 20500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.08         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4099          |\n",
            "|    policy_loss        | 0.0321        |\n",
            "|    reward             | -0.0030754814 |\n",
            "|    std                | 1.94          |\n",
            "|    value_loss         | 0.000711      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 519         |\n",
            "|    iterations         | 4200        |\n",
            "|    time_elapsed       | 40          |\n",
            "|    total_timesteps    | 21000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.1        |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4199        |\n",
            "|    policy_loss        | 0.129       |\n",
            "|    reward             | -0.02271288 |\n",
            "|    std                | 1.98        |\n",
            "|    value_loss         | 0.00626     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 519         |\n",
            "|    iterations         | 4300        |\n",
            "|    time_elapsed       | 41          |\n",
            "|    total_timesteps    | 21500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.12       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4299        |\n",
            "|    policy_loss        | 0.269       |\n",
            "|    reward             | -0.01990103 |\n",
            "|    std                | 2.01        |\n",
            "|    value_loss         | 0.0153      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 519        |\n",
            "|    iterations         | 4400       |\n",
            "|    time_elapsed       | 42         |\n",
            "|    total_timesteps    | 22000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.13      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4399       |\n",
            "|    policy_loss        | 0.187      |\n",
            "|    reward             | 0.05261538 |\n",
            "|    std                | 2.05       |\n",
            "|    value_loss         | 0.00879    |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 4500         |\n",
            "|    time_elapsed       | 43           |\n",
            "|    total_timesteps    | 22500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.15        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4499         |\n",
            "|    policy_loss        | -0.0368      |\n",
            "|    reward             | -0.010644559 |\n",
            "|    std                | 2.08         |\n",
            "|    value_loss         | 0.000452     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 4600         |\n",
            "|    time_elapsed       | 44           |\n",
            "|    total_timesteps    | 23000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.17        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4599         |\n",
            "|    policy_loss        | 0.0258       |\n",
            "|    reward             | 0.0066691423 |\n",
            "|    std                | 2.12         |\n",
            "|    value_loss         | 0.000677     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 520         |\n",
            "|    iterations         | 4700        |\n",
            "|    time_elapsed       | 45          |\n",
            "|    total_timesteps    | 23500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.18       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4699        |\n",
            "|    policy_loss        | -0.0324     |\n",
            "|    reward             | -0.04267763 |\n",
            "|    std                | 2.14        |\n",
            "|    value_loss         | 0.000251    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 521           |\n",
            "|    iterations         | 4800          |\n",
            "|    time_elapsed       | 46            |\n",
            "|    total_timesteps    | 24000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.18         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4799          |\n",
            "|    policy_loss        | -0.0407       |\n",
            "|    reward             | -0.0065126857 |\n",
            "|    std                | 2.15          |\n",
            "|    value_loss         | 0.00115       |\n",
            "-----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 521       |\n",
            "|    iterations         | 4900      |\n",
            "|    time_elapsed       | 46        |\n",
            "|    total_timesteps    | 24500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.2      |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4899      |\n",
            "|    policy_loss        | 0.0713    |\n",
            "|    reward             | 0.1669175 |\n",
            "|    std                | 2.18      |\n",
            "|    value_loss         | 0.0071    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 521        |\n",
            "|    iterations         | 5000       |\n",
            "|    time_elapsed       | 47         |\n",
            "|    total_timesteps    | 25000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.2       |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4999       |\n",
            "|    policy_loss        | 0.102      |\n",
            "|    reward             | -0.0169835 |\n",
            "|    std                | 2.17       |\n",
            "|    value_loss         | 0.00341    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 521         |\n",
            "|    iterations         | 5100        |\n",
            "|    time_elapsed       | 48          |\n",
            "|    total_timesteps    | 25500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.21       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5099        |\n",
            "|    policy_loss        | 0.116       |\n",
            "|    reward             | 0.014467309 |\n",
            "|    std                | 2.2         |\n",
            "|    value_loss         | 0.00392     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 521           |\n",
            "|    iterations         | 5200          |\n",
            "|    time_elapsed       | 49            |\n",
            "|    total_timesteps    | 26000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.23         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5199          |\n",
            "|    policy_loss        | 0.0217        |\n",
            "|    reward             | -0.0019179586 |\n",
            "|    std                | 2.25          |\n",
            "|    value_loss         | 0.000292      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 5300         |\n",
            "|    time_elapsed       | 50           |\n",
            "|    total_timesteps    | 26500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.24        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5299         |\n",
            "|    policy_loss        | 0.0862       |\n",
            "|    reward             | -0.013271677 |\n",
            "|    std                | 2.27         |\n",
            "|    value_loss         | 0.00218      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 521         |\n",
            "|    iterations         | 5400        |\n",
            "|    time_elapsed       | 51          |\n",
            "|    total_timesteps    | 27000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.24       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5399        |\n",
            "|    policy_loss        | 0.136       |\n",
            "|    reward             | -0.01066904 |\n",
            "|    std                | 2.28        |\n",
            "|    value_loss         | 0.00426     |\n",
            "---------------------------------------\n",
            "day: 2749, episode: 10\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 8386.06\n",
            "total_reward: -1613.94\n",
            "total_cost: 105.67\n",
            "total_trades: 2749\n",
            "Sharpe: 0.290\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 521         |\n",
            "|    iterations         | 5500        |\n",
            "|    time_elapsed       | 52          |\n",
            "|    total_timesteps    | 27500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.25       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5499        |\n",
            "|    policy_loss        | 0.0725      |\n",
            "|    reward             | 0.025264002 |\n",
            "|    std                | 2.29        |\n",
            "|    value_loss         | 0.00198     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 5600         |\n",
            "|    time_elapsed       | 53           |\n",
            "|    total_timesteps    | 28000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.26        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5599         |\n",
            "|    policy_loss        | -0.0302      |\n",
            "|    reward             | -0.008162957 |\n",
            "|    std                | 2.32         |\n",
            "|    value_loss         | 0.000291     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 5700         |\n",
            "|    time_elapsed       | 54           |\n",
            "|    total_timesteps    | 28500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.28        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5699         |\n",
            "|    policy_loss        | 0.0158       |\n",
            "|    reward             | 0.0028223814 |\n",
            "|    std                | 2.36         |\n",
            "|    value_loss         | 0.000133     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 5800         |\n",
            "|    time_elapsed       | 55           |\n",
            "|    total_timesteps    | 29000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.3         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5799         |\n",
            "|    policy_loss        | -0.00581     |\n",
            "|    reward             | -0.012285918 |\n",
            "|    std                | 2.41         |\n",
            "|    value_loss         | 1.59e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 520           |\n",
            "|    iterations         | 5900          |\n",
            "|    time_elapsed       | 56            |\n",
            "|    total_timesteps    | 29500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.32         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5899          |\n",
            "|    policy_loss        | -0.00751      |\n",
            "|    reward             | -0.0011336048 |\n",
            "|    std                | 2.47          |\n",
            "|    value_loss         | 3.32e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 520         |\n",
            "|    iterations         | 6000        |\n",
            "|    time_elapsed       | 57          |\n",
            "|    total_timesteps    | 30000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.35       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5999        |\n",
            "|    policy_loss        | 0.00726     |\n",
            "|    reward             | 0.023085734 |\n",
            "|    std                | 2.53        |\n",
            "|    value_loss         | 0.000118    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 6100         |\n",
            "|    time_elapsed       | 58           |\n",
            "|    total_timesteps    | 30500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.37        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6099         |\n",
            "|    policy_loss        | 0.0583       |\n",
            "|    reward             | -0.007564395 |\n",
            "|    std                | 2.59         |\n",
            "|    value_loss         | 0.000762     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 519          |\n",
            "|    iterations         | 6200         |\n",
            "|    time_elapsed       | 59           |\n",
            "|    total_timesteps    | 31000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.41        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6199         |\n",
            "|    policy_loss        | 0.0528       |\n",
            "|    reward             | 0.0051423702 |\n",
            "|    std                | 2.7          |\n",
            "|    value_loss         | 0.000535     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 518            |\n",
            "|    iterations         | 6300           |\n",
            "|    time_elapsed       | 60             |\n",
            "|    total_timesteps    | 31500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -2.44          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 6299           |\n",
            "|    policy_loss        | 0.00912        |\n",
            "|    reward             | -0.00046915433 |\n",
            "|    std                | 2.77           |\n",
            "|    value_loss         | 2.3e-05        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 519           |\n",
            "|    iterations         | 6400          |\n",
            "|    time_elapsed       | 61            |\n",
            "|    total_timesteps    | 32000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.48         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6399          |\n",
            "|    policy_loss        | 0.0229        |\n",
            "|    reward             | -0.0020382053 |\n",
            "|    std                | 2.88          |\n",
            "|    value_loss         | 7.06e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 518           |\n",
            "|    iterations         | 6500          |\n",
            "|    time_elapsed       | 62            |\n",
            "|    total_timesteps    | 32500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.52         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6499          |\n",
            "|    policy_loss        | 0.0179        |\n",
            "|    reward             | -0.0017657994 |\n",
            "|    std                | 3.02          |\n",
            "|    value_loss         | 5.21e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 518         |\n",
            "|    iterations         | 6600        |\n",
            "|    time_elapsed       | 63          |\n",
            "|    total_timesteps    | 33000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.56       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6599        |\n",
            "|    policy_loss        | 0.0139      |\n",
            "|    reward             | 0.003659833 |\n",
            "|    std                | 3.14        |\n",
            "|    value_loss         | 4.34e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 519          |\n",
            "|    iterations         | 6700         |\n",
            "|    time_elapsed       | 64           |\n",
            "|    total_timesteps    | 33500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.6         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6699         |\n",
            "|    policy_loss        | -0.0239      |\n",
            "|    reward             | -0.005196442 |\n",
            "|    std                | 3.26         |\n",
            "|    value_loss         | 0.000113     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 519          |\n",
            "|    iterations         | 6800         |\n",
            "|    time_elapsed       | 65           |\n",
            "|    total_timesteps    | 34000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.65        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6799         |\n",
            "|    policy_loss        | 0.0188       |\n",
            "|    reward             | 0.0027926243 |\n",
            "|    std                | 3.43         |\n",
            "|    value_loss         | 0.000135     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 6900         |\n",
            "|    time_elapsed       | 66           |\n",
            "|    total_timesteps    | 34500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.68        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6899         |\n",
            "|    policy_loss        | -0.00884     |\n",
            "|    reward             | -0.011282081 |\n",
            "|    std                | 3.53         |\n",
            "|    value_loss         | 1.26e-05     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 519            |\n",
            "|    iterations         | 7000           |\n",
            "|    time_elapsed       | 67             |\n",
            "|    total_timesteps    | 35000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -2.71          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 6999           |\n",
            "|    policy_loss        | -0.00929       |\n",
            "|    reward             | -0.00092301157 |\n",
            "|    std                | 3.64           |\n",
            "|    value_loss         | 2.2e-05        |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 520         |\n",
            "|    iterations         | 7100        |\n",
            "|    time_elapsed       | 68          |\n",
            "|    total_timesteps    | 35500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.75       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7099        |\n",
            "|    policy_loss        | -0.00171    |\n",
            "|    reward             | 0.025739493 |\n",
            "|    std                | 3.8         |\n",
            "|    value_loss         | 7.85e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 7200         |\n",
            "|    time_elapsed       | 69           |\n",
            "|    total_timesteps    | 36000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.8         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7199         |\n",
            "|    policy_loss        | 0.0863       |\n",
            "|    reward             | -0.009764067 |\n",
            "|    std                | 3.96         |\n",
            "|    value_loss         | 0.00122      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 7300         |\n",
            "|    time_elapsed       | 70           |\n",
            "|    total_timesteps    | 36500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.84        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7299         |\n",
            "|    policy_loss        | 0.0845       |\n",
            "|    reward             | 0.0065613827 |\n",
            "|    std                | 4.13         |\n",
            "|    value_loss         | 0.000816     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 520            |\n",
            "|    iterations         | 7400           |\n",
            "|    time_elapsed       | 71             |\n",
            "|    total_timesteps    | 37000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -2.87          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 7399           |\n",
            "|    policy_loss        | 0.00863        |\n",
            "|    reward             | -0.00050146045 |\n",
            "|    std                | 4.25           |\n",
            "|    value_loss         | 2.35e-05       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 520           |\n",
            "|    iterations         | 7500          |\n",
            "|    time_elapsed       | 72            |\n",
            "|    total_timesteps    | 37500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.9          |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7499          |\n",
            "|    policy_loss        | 0.0256        |\n",
            "|    reward             | -0.0025027506 |\n",
            "|    std                | 4.39          |\n",
            "|    value_loss         | 9.23e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 520           |\n",
            "|    iterations         | 7600          |\n",
            "|    time_elapsed       | 72            |\n",
            "|    total_timesteps    | 38000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.94         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7599          |\n",
            "|    policy_loss        | 0.0293        |\n",
            "|    reward             | -0.0015818776 |\n",
            "|    std                | 4.57          |\n",
            "|    value_loss         | 9.21e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 520         |\n",
            "|    iterations         | 7700        |\n",
            "|    time_elapsed       | 73          |\n",
            "|    total_timesteps    | 38500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.99       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7699        |\n",
            "|    policy_loss        | 0.0213      |\n",
            "|    reward             | 0.004621137 |\n",
            "|    std                | 4.83        |\n",
            "|    value_loss         | 6.07e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 7800         |\n",
            "|    time_elapsed       | 74           |\n",
            "|    total_timesteps    | 39000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.02        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7799         |\n",
            "|    policy_loss        | -0.0381      |\n",
            "|    reward             | -0.006083345 |\n",
            "|    std                | 4.97         |\n",
            "|    value_loss         | 0.000183     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 7900         |\n",
            "|    time_elapsed       | 75           |\n",
            "|    total_timesteps    | 39500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.04        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7899         |\n",
            "|    policy_loss        | 0.019        |\n",
            "|    reward             | 0.0027182393 |\n",
            "|    std                | 5.06         |\n",
            "|    value_loss         | 0.00013      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 8000         |\n",
            "|    time_elapsed       | 76           |\n",
            "|    total_timesteps    | 40000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.08        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7999         |\n",
            "|    policy_loss        | -0.00702     |\n",
            "|    reward             | -0.009850346 |\n",
            "|    std                | 5.25         |\n",
            "|    value_loss         | 8.72e-06     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 521           |\n",
            "|    iterations         | 8100          |\n",
            "|    time_elapsed       | 77            |\n",
            "|    total_timesteps    | 40500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.12         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8099          |\n",
            "|    policy_loss        | -0.00832      |\n",
            "|    reward             | -0.0008234052 |\n",
            "|    std                | 5.46          |\n",
            "|    value_loss         | 2e-05         |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 521        |\n",
            "|    iterations         | 8200       |\n",
            "|    time_elapsed       | 78         |\n",
            "|    total_timesteps    | 41000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -3.16      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8199       |\n",
            "|    policy_loss        | 0.0122     |\n",
            "|    reward             | 0.02321645 |\n",
            "|    std                | 5.69       |\n",
            "|    value_loss         | 0.00011    |\n",
            "--------------------------------------\n",
            "day: 2749, episode: 15\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 9798.14\n",
            "total_reward: -201.86\n",
            "total_cost: 108.38\n",
            "total_trades: 2749\n",
            "Sharpe: 0.080\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 8300         |\n",
            "|    time_elapsed       | 79           |\n",
            "|    total_timesteps    | 41500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.2         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8299         |\n",
            "|    policy_loss        | 0.0996       |\n",
            "|    reward             | -0.010155604 |\n",
            "|    std                | 5.91         |\n",
            "|    value_loss         | 0.0013       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 521         |\n",
            "|    iterations         | 8400        |\n",
            "|    time_elapsed       | 80          |\n",
            "|    total_timesteps    | 42000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.23       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8399        |\n",
            "|    policy_loss        | 0.107       |\n",
            "|    reward             | 0.008715241 |\n",
            "|    std                | 6.1         |\n",
            "|    value_loss         | 0.00146     |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 521            |\n",
            "|    iterations         | 8500           |\n",
            "|    time_elapsed       | 81             |\n",
            "|    total_timesteps    | 42500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -3.25          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 8499           |\n",
            "|    policy_loss        | 0.0233         |\n",
            "|    reward             | -0.00088167837 |\n",
            "|    std                | 6.26           |\n",
            "|    value_loss         | 6.62e-05       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 521           |\n",
            "|    iterations         | 8600          |\n",
            "|    time_elapsed       | 82            |\n",
            "|    total_timesteps    | 43000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.28         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8599          |\n",
            "|    policy_loss        | 0.0622        |\n",
            "|    reward             | -0.0051670554 |\n",
            "|    std                | 6.45          |\n",
            "|    value_loss         | 0.000387      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 522           |\n",
            "|    iterations         | 8700          |\n",
            "|    time_elapsed       | 83            |\n",
            "|    total_timesteps    | 43500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.32         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8699          |\n",
            "|    policy_loss        | 0.0693        |\n",
            "|    reward             | -0.0036519626 |\n",
            "|    std                | 6.7           |\n",
            "|    value_loss         | 0.000436      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 522         |\n",
            "|    iterations         | 8800        |\n",
            "|    time_elapsed       | 84          |\n",
            "|    total_timesteps    | 44000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.34       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8799        |\n",
            "|    policy_loss        | 0.0375      |\n",
            "|    reward             | 0.007756818 |\n",
            "|    std                | 6.82        |\n",
            "|    value_loss         | 0.00016     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 522          |\n",
            "|    iterations         | 8900         |\n",
            "|    time_elapsed       | 85           |\n",
            "|    total_timesteps    | 44500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.36        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8899         |\n",
            "|    policy_loss        | -0.0587      |\n",
            "|    reward             | -0.009886082 |\n",
            "|    std                | 6.96         |\n",
            "|    value_loss         | 0.000436     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 522          |\n",
            "|    iterations         | 9000         |\n",
            "|    time_elapsed       | 86           |\n",
            "|    total_timesteps    | 45000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.38        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8999         |\n",
            "|    policy_loss        | 0.0432       |\n",
            "|    reward             | 0.0045863655 |\n",
            "|    std                | 7.11         |\n",
            "|    value_loss         | 0.000344     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 522          |\n",
            "|    iterations         | 9100         |\n",
            "|    time_elapsed       | 87           |\n",
            "|    total_timesteps    | 45500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.41        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9099         |\n",
            "|    policy_loss        | -0.0175      |\n",
            "|    reward             | -0.022665737 |\n",
            "|    std                | 7.3          |\n",
            "|    value_loss         | 5.36e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 522           |\n",
            "|    iterations         | 9200          |\n",
            "|    time_elapsed       | 88            |\n",
            "|    total_timesteps    | 46000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.43         |\n",
            "|    explained_variance | -2.38e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9199          |\n",
            "|    policy_loss        | -0.0284       |\n",
            "|    reward             | -0.0027659617 |\n",
            "|    std                | 7.45          |\n",
            "|    value_loss         | 0.000189      |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 522        |\n",
            "|    iterations         | 9300       |\n",
            "|    time_elapsed       | 89         |\n",
            "|    total_timesteps    | 46500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -3.45      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9299       |\n",
            "|    policy_loss        | 0.0275     |\n",
            "|    reward             | 0.05890951 |\n",
            "|    std                | 7.62       |\n",
            "|    value_loss         | 0.00079    |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 522          |\n",
            "|    iterations         | 9400         |\n",
            "|    time_elapsed       | 89           |\n",
            "|    total_timesteps    | 47000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.47        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9399         |\n",
            "|    policy_loss        | 0.129        |\n",
            "|    reward             | -0.012809765 |\n",
            "|    std                | 7.73         |\n",
            "|    value_loss         | 0.00199      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 522         |\n",
            "|    iterations         | 9500        |\n",
            "|    time_elapsed       | 90          |\n",
            "|    total_timesteps    | 47500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.48       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9499        |\n",
            "|    policy_loss        | 0.108       |\n",
            "|    reward             | 0.007574963 |\n",
            "|    std                | 7.88        |\n",
            "|    value_loss         | 0.00109     |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 521            |\n",
            "|    iterations         | 9600           |\n",
            "|    time_elapsed       | 91             |\n",
            "|    total_timesteps    | 48000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -3.51          |\n",
            "|    explained_variance | -1.19e-07      |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 9599           |\n",
            "|    policy_loss        | 0.0182         |\n",
            "|    reward             | -0.00072511804 |\n",
            "|    std                | 8.08           |\n",
            "|    value_loss         | 4.66e-05       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 522           |\n",
            "|    iterations         | 9700          |\n",
            "|    time_elapsed       | 92            |\n",
            "|    total_timesteps    | 48500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.54         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9699          |\n",
            "|    policy_loss        | 0.0538        |\n",
            "|    reward             | -0.0040603443 |\n",
            "|    std                | 8.36          |\n",
            "|    value_loss         | 0.000247      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 522           |\n",
            "|    iterations         | 9800          |\n",
            "|    time_elapsed       | 93            |\n",
            "|    total_timesteps    | 49000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.57         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9799          |\n",
            "|    policy_loss        | 0.0616        |\n",
            "|    reward             | -0.0030927453 |\n",
            "|    std                | 8.59          |\n",
            "|    value_loss         | 0.000316      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 9900         |\n",
            "|    time_elapsed       | 94           |\n",
            "|    total_timesteps    | 49500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.59        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9899         |\n",
            "|    policy_loss        | 0.0395       |\n",
            "|    reward             | 0.0075027714 |\n",
            "|    std                | 8.75         |\n",
            "|    value_loss         | 0.000154     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 10000        |\n",
            "|    time_elapsed       | 95           |\n",
            "|    total_timesteps    | 50000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.59        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9999         |\n",
            "|    policy_loss        | -0.0668      |\n",
            "|    reward             | -0.009985717 |\n",
            "|    std                | 8.76         |\n",
            "|    value_loss         | 0.000455     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 10100        |\n",
            "|    time_elapsed       | 96           |\n",
            "|    total_timesteps    | 50500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.6         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10099        |\n",
            "|    policy_loss        | 0.0355       |\n",
            "|    reward             | 0.0043334537 |\n",
            "|    std                | 8.88         |\n",
            "|    value_loss         | 0.000313     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 10200        |\n",
            "|    time_elapsed       | 97           |\n",
            "|    total_timesteps    | 51000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.62        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10199        |\n",
            "|    policy_loss        | -0.0158      |\n",
            "|    reward             | -0.018745482 |\n",
            "|    std                | 9.05         |\n",
            "|    value_loss         | 3.77e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 521           |\n",
            "|    iterations         | 10300         |\n",
            "|    time_elapsed       | 98            |\n",
            "|    total_timesteps    | 51500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.65         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10299         |\n",
            "|    policy_loss        | -0.0248       |\n",
            "|    reward             | -0.0020725746 |\n",
            "|    std                | 9.27          |\n",
            "|    value_loss         | 0.000113      |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 521        |\n",
            "|    iterations         | 10400      |\n",
            "|    time_elapsed       | 99         |\n",
            "|    total_timesteps    | 52000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -3.66      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10399      |\n",
            "|    policy_loss        | 0.0213     |\n",
            "|    reward             | 0.03821019 |\n",
            "|    std                | 9.44       |\n",
            "|    value_loss         | 0.000332   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 521         |\n",
            "|    iterations         | 10500       |\n",
            "|    time_elapsed       | 100         |\n",
            "|    total_timesteps    | 52500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.68       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10499       |\n",
            "|    policy_loss        | 0.225       |\n",
            "|    reward             | -0.02087195 |\n",
            "|    std                | 9.55        |\n",
            "|    value_loss         | 0.00542     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 521         |\n",
            "|    iterations         | 10600       |\n",
            "|    time_elapsed       | 101         |\n",
            "|    total_timesteps    | 53000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.71       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10599       |\n",
            "|    policy_loss        | 0.144       |\n",
            "|    reward             | 0.008309809 |\n",
            "|    std                | 9.85        |\n",
            "|    value_loss         | 0.00131     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 10700        |\n",
            "|    time_elapsed       | 102          |\n",
            "|    total_timesteps    | 53500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.73        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10699        |\n",
            "|    policy_loss        | 0.0192       |\n",
            "|    reward             | -0.000782275 |\n",
            "|    std                | 10           |\n",
            "|    value_loss         | 5.22e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 10800        |\n",
            "|    time_elapsed       | 103          |\n",
            "|    total_timesteps    | 54000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.75        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10799        |\n",
            "|    policy_loss        | 0.0589       |\n",
            "|    reward             | -0.004213041 |\n",
            "|    std                | 10.3         |\n",
            "|    value_loss         | 0.000258     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 10900        |\n",
            "|    time_elapsed       | 104          |\n",
            "|    total_timesteps    | 54500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.77        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10899        |\n",
            "|    policy_loss        | 0.062        |\n",
            "|    reward             | -0.002889052 |\n",
            "|    std                | 10.5         |\n",
            "|    value_loss         | 0.000267     |\n",
            "----------------------------------------\n",
            "day: 2749, episode: 20\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 11611.26\n",
            "total_reward: 1611.26\n",
            "total_cost: 97.09\n",
            "total_trades: 2749\n",
            "Sharpe: 0.170\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 521         |\n",
            "|    iterations         | 11000       |\n",
            "|    time_elapsed       | 105         |\n",
            "|    total_timesteps    | 55000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.79       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10999       |\n",
            "|    policy_loss        | 0.0354      |\n",
            "|    reward             | 0.006887067 |\n",
            "|    std                | 10.7        |\n",
            "|    value_loss         | 0.000131    |\n",
            "---------------------------------------\n",
            "======A2C Validation from:  2021-03-05 to  2021-04-06\n",
            "A2C Sharpe Ratio:  -0.5377488207629993\n",
            "======Best Model Retraining from:  2010-04-01 to  2021-04-06\n",
            "======Trading from:  2021-04-06 to  2021-05-05\n",
            "[[ 1.3786746e+04  2.4394417e+01 -1.6300000e+02  3.0838475e-01\n",
            "   2.4958952e+01  2.3238611e+01  5.6291134e+01  7.8714127e+01\n",
            "   1.9371996e+01  2.3590782e+01  2.3505814e+01]]\n",
            "============================================\n",
            "turbulence_threshold:  12.04306128869847\n",
            "======Model training from:  2010-04-01 to  2021-04-06\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c\\a2c_105_1\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 565          |\n",
            "|    iterations         | 100          |\n",
            "|    time_elapsed       | 0            |\n",
            "|    total_timesteps    | 500          |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.46        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 99           |\n",
            "|    policy_loss        | -0.0131      |\n",
            "|    reward             | -0.005196442 |\n",
            "|    std                | 1.04         |\n",
            "|    value_loss         | 0.00015      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 542          |\n",
            "|    iterations         | 200          |\n",
            "|    time_elapsed       | 1            |\n",
            "|    total_timesteps    | 1000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.49        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 199          |\n",
            "|    policy_loss        | 0.00471      |\n",
            "|    reward             | 0.0025163374 |\n",
            "|    std                | 1.07         |\n",
            "|    value_loss         | 8.59e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 536          |\n",
            "|    iterations         | 300          |\n",
            "|    time_elapsed       | 2            |\n",
            "|    total_timesteps    | 1500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.53        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 299          |\n",
            "|    policy_loss        | -0.000315    |\n",
            "|    reward             | -0.009056137 |\n",
            "|    std                | 1.11         |\n",
            "|    value_loss         | 3.45e-06     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 525           |\n",
            "|    iterations         | 400           |\n",
            "|    time_elapsed       | 3             |\n",
            "|    total_timesteps    | 2000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.55         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 399           |\n",
            "|    policy_loss        | -0.00726      |\n",
            "|    reward             | -0.0012491693 |\n",
            "|    std                | 1.15          |\n",
            "|    value_loss         | 5.7e-05       |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 525        |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 4          |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.59      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | 0.00146    |\n",
            "|    reward             | 0.03436421 |\n",
            "|    std                | 1.19       |\n",
            "|    value_loss         | 0.000203   |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 519           |\n",
            "|    iterations         | 600           |\n",
            "|    time_elapsed       | 5             |\n",
            "|    total_timesteps    | 3000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.63         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 599           |\n",
            "|    policy_loss        | 0.0132        |\n",
            "|    reward             | -0.0017970614 |\n",
            "|    std                | 1.23          |\n",
            "|    value_loss         | 0.000123      |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 522        |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 6          |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.65      |\n",
            "|    explained_variance | 1.79e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | 0.00441    |\n",
            "|    reward             | 0.01461774 |\n",
            "|    std                | 1.25       |\n",
            "|    value_loss         | 1.15e-05   |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 524          |\n",
            "|    iterations         | 800          |\n",
            "|    time_elapsed       | 7            |\n",
            "|    total_timesteps    | 4000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.68        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 799          |\n",
            "|    policy_loss        | -0.00338     |\n",
            "|    reward             | -0.004601531 |\n",
            "|    std                | 1.29         |\n",
            "|    value_loss         | 1.78e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 518           |\n",
            "|    iterations         | 900           |\n",
            "|    time_elapsed       | 8             |\n",
            "|    total_timesteps    | 4500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.7          |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 899           |\n",
            "|    policy_loss        | -0.00948      |\n",
            "|    reward             | -0.0051624146 |\n",
            "|    std                | 1.33          |\n",
            "|    value_loss         | 9.3e-05       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 516           |\n",
            "|    iterations         | 1000          |\n",
            "|    time_elapsed       | 9             |\n",
            "|    total_timesteps    | 5000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.74         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 999           |\n",
            "|    policy_loss        | 0.0408        |\n",
            "|    reward             | -0.0018411314 |\n",
            "|    std                | 1.38          |\n",
            "|    value_loss         | 0.000863      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 515           |\n",
            "|    iterations         | 1100          |\n",
            "|    time_elapsed       | 10            |\n",
            "|    total_timesteps    | 5500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.77         |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1099          |\n",
            "|    policy_loss        | -0.0678       |\n",
            "|    reward             | -0.0026499543 |\n",
            "|    std                | 1.42          |\n",
            "|    value_loss         | 0.00125       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 517         |\n",
            "|    iterations         | 1200        |\n",
            "|    time_elapsed       | 11          |\n",
            "|    total_timesteps    | 6000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.81       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1199        |\n",
            "|    policy_loss        | -0.046      |\n",
            "|    reward             | 0.008487512 |\n",
            "|    std                | 1.47        |\n",
            "|    value_loss         | 0.000445    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 517           |\n",
            "|    iterations         | 1300          |\n",
            "|    time_elapsed       | 12            |\n",
            "|    total_timesteps    | 6500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.82         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1299          |\n",
            "|    policy_loss        | -0.0347       |\n",
            "|    reward             | -0.0018291601 |\n",
            "|    std                | 1.49          |\n",
            "|    value_loss         | 0.000667      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 1400         |\n",
            "|    time_elapsed       | 13           |\n",
            "|    total_timesteps    | 7000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.84        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1399         |\n",
            "|    policy_loss        | 0.0207       |\n",
            "|    reward             | 0.0061502205 |\n",
            "|    std                | 1.52         |\n",
            "|    value_loss         | 0.000249     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 1500         |\n",
            "|    time_elapsed       | 14           |\n",
            "|    total_timesteps    | 7500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.87        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1499         |\n",
            "|    policy_loss        | 0.00116      |\n",
            "|    reward             | 0.0022799906 |\n",
            "|    std                | 1.57         |\n",
            "|    value_loss         | 4.03e-06     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 1600         |\n",
            "|    time_elapsed       | 15           |\n",
            "|    total_timesteps    | 8000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.91        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1599         |\n",
            "|    policy_loss        | -0.00167     |\n",
            "|    reward             | 0.0004999167 |\n",
            "|    std                | 1.64         |\n",
            "|    value_loss         | 9.52e-07     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 519         |\n",
            "|    iterations         | 1700        |\n",
            "|    time_elapsed       | 16          |\n",
            "|    total_timesteps    | 8500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.95       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1699        |\n",
            "|    policy_loss        | -0.00303    |\n",
            "|    reward             | 0.000539703 |\n",
            "|    std                | 1.7         |\n",
            "|    value_loss         | 8.22e-06    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 518          |\n",
            "|    iterations         | 1800         |\n",
            "|    time_elapsed       | 17           |\n",
            "|    total_timesteps    | 9000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.98        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1799         |\n",
            "|    policy_loss        | 0.000862     |\n",
            "|    reward             | 0.0007634473 |\n",
            "|    std                | 1.76         |\n",
            "|    value_loss         | 2.24e-06     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 519          |\n",
            "|    iterations         | 1900         |\n",
            "|    time_elapsed       | 18           |\n",
            "|    total_timesteps    | 9500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.03        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1899         |\n",
            "|    policy_loss        | -0.00195     |\n",
            "|    reward             | 8.483514e-05 |\n",
            "|    std                | 1.84         |\n",
            "|    value_loss         | 1.28e-06     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 518           |\n",
            "|    iterations         | 2000          |\n",
            "|    time_elapsed       | 19            |\n",
            "|    total_timesteps    | 10000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.06         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1999          |\n",
            "|    policy_loss        | -0.00325      |\n",
            "|    reward             | -0.0016490733 |\n",
            "|    std                | 1.9           |\n",
            "|    value_loss         | 4.06e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 517          |\n",
            "|    iterations         | 2100         |\n",
            "|    time_elapsed       | 20           |\n",
            "|    total_timesteps    | 10500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.1         |\n",
            "|    explained_variance | 0.844        |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2099         |\n",
            "|    policy_loss        | -0.0776      |\n",
            "|    reward             | -0.026508352 |\n",
            "|    std                | 1.97         |\n",
            "|    value_loss         | 0.0017       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 518          |\n",
            "|    iterations         | 2200         |\n",
            "|    time_elapsed       | 21           |\n",
            "|    total_timesteps    | 11000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.11        |\n",
            "|    explained_variance | 0.00796      |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2199         |\n",
            "|    policy_loss        | 0.0543       |\n",
            "|    reward             | -0.009481734 |\n",
            "|    std                | 1.99         |\n",
            "|    value_loss         | 0.00111      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 518          |\n",
            "|    iterations         | 2300         |\n",
            "|    time_elapsed       | 22           |\n",
            "|    total_timesteps    | 11500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.12        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2299         |\n",
            "|    policy_loss        | 0.0255       |\n",
            "|    reward             | -0.007760577 |\n",
            "|    std                | 2.03         |\n",
            "|    value_loss         | 0.000297     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 519          |\n",
            "|    iterations         | 2400         |\n",
            "|    time_elapsed       | 23           |\n",
            "|    total_timesteps    | 12000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.15        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2399         |\n",
            "|    policy_loss        | -0.0258      |\n",
            "|    reward             | 0.0035704335 |\n",
            "|    std                | 2.08         |\n",
            "|    value_loss         | 0.000142     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 519         |\n",
            "|    iterations         | 2500        |\n",
            "|    time_elapsed       | 24          |\n",
            "|    total_timesteps    | 12500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.18       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2499        |\n",
            "|    policy_loss        | 0.0106      |\n",
            "|    reward             | 0.008859684 |\n",
            "|    std                | 2.15        |\n",
            "|    value_loss         | 2.24e-05    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 519           |\n",
            "|    iterations         | 2600          |\n",
            "|    time_elapsed       | 25            |\n",
            "|    total_timesteps    | 13000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.21         |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2599          |\n",
            "|    policy_loss        | -0.00158      |\n",
            "|    reward             | -0.0011244635 |\n",
            "|    std                | 2.21          |\n",
            "|    value_loss         | 1.84e-06      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 519          |\n",
            "|    iterations         | 2700         |\n",
            "|    time_elapsed       | 25           |\n",
            "|    total_timesteps    | 13500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.26        |\n",
            "|    explained_variance | -46.4        |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2699         |\n",
            "|    policy_loss        | -0.259       |\n",
            "|    reward             | 0.0069565903 |\n",
            "|    std                | 2.31         |\n",
            "|    value_loss         | 0.0206       |\n",
            "----------------------------------------\n",
            "day: 2770, episode: 5\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 4752.47\n",
            "total_reward: -5247.53\n",
            "total_cost: 118.74\n",
            "total_trades: 2770\n",
            "Sharpe: -0.223\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 519          |\n",
            "|    iterations         | 2800         |\n",
            "|    time_elapsed       | 26           |\n",
            "|    total_timesteps    | 14000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.26        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2799         |\n",
            "|    policy_loss        | 0.0133       |\n",
            "|    reward             | -0.003202842 |\n",
            "|    std                | 2.32         |\n",
            "|    value_loss         | 8.22e-05     |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 519        |\n",
            "|    iterations         | 2900       |\n",
            "|    time_elapsed       | 27         |\n",
            "|    total_timesteps    | 14500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.28      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2899       |\n",
            "|    policy_loss        | 0.00587    |\n",
            "|    reward             | 0.00599742 |\n",
            "|    std                | 2.36       |\n",
            "|    value_loss         | 1.1e-05    |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 519          |\n",
            "|    iterations         | 3000         |\n",
            "|    time_elapsed       | 28           |\n",
            "|    total_timesteps    | 15000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.3         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2999         |\n",
            "|    policy_loss        | -0.0101      |\n",
            "|    reward             | 0.0007126475 |\n",
            "|    std                | 2.42         |\n",
            "|    value_loss         | 2.31e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 3100         |\n",
            "|    time_elapsed       | 29           |\n",
            "|    total_timesteps    | 15500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.33        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3099         |\n",
            "|    policy_loss        | -0.00926     |\n",
            "|    reward             | 0.0024937957 |\n",
            "|    std                | 2.49         |\n",
            "|    value_loss         | 1.99e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 3200         |\n",
            "|    time_elapsed       | 30           |\n",
            "|    total_timesteps    | 16000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.37        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3199         |\n",
            "|    policy_loss        | -0.00169     |\n",
            "|    reward             | 0.0025828735 |\n",
            "|    std                | 2.59         |\n",
            "|    value_loss         | 6.97e-07     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 3300         |\n",
            "|    time_elapsed       | 31           |\n",
            "|    total_timesteps    | 16500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.41        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3299         |\n",
            "|    policy_loss        | 0.0174       |\n",
            "|    reward             | 0.0002650854 |\n",
            "|    std                | 2.69         |\n",
            "|    value_loss         | 0.000107     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 3400         |\n",
            "|    time_elapsed       | 32           |\n",
            "|    total_timesteps    | 17000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.45        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3399         |\n",
            "|    policy_loss        | 0.0462       |\n",
            "|    reward             | 0.0026386748 |\n",
            "|    std                | 2.81         |\n",
            "|    value_loss         | 0.00023      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 520         |\n",
            "|    iterations         | 3500        |\n",
            "|    time_elapsed       | 33          |\n",
            "|    total_timesteps    | 17500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.48       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3499        |\n",
            "|    policy_loss        | 0.00623     |\n",
            "|    reward             | 0.006499134 |\n",
            "|    std                | 2.88        |\n",
            "|    value_loss         | 1.61e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 3600         |\n",
            "|    time_elapsed       | 34           |\n",
            "|    total_timesteps    | 18000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.51        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3599         |\n",
            "|    policy_loss        | -0.0075      |\n",
            "|    reward             | -0.002405137 |\n",
            "|    std                | 2.97         |\n",
            "|    value_loss         | 2.83e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 3700         |\n",
            "|    time_elapsed       | 35           |\n",
            "|    total_timesteps    | 18500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.55        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3699         |\n",
            "|    policy_loss        | -0.00773     |\n",
            "|    reward             | -0.004460734 |\n",
            "|    std                | 3.09         |\n",
            "|    value_loss         | 1.83e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 519          |\n",
            "|    iterations         | 3800         |\n",
            "|    time_elapsed       | 36           |\n",
            "|    total_timesteps    | 19000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.59        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3799         |\n",
            "|    policy_loss        | -0.00804     |\n",
            "|    reward             | -0.004623331 |\n",
            "|    std                | 3.22         |\n",
            "|    value_loss         | 3.1e-05      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 520         |\n",
            "|    iterations         | 3900        |\n",
            "|    time_elapsed       | 37          |\n",
            "|    total_timesteps    | 19500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.63       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3899        |\n",
            "|    policy_loss        | -0.0675     |\n",
            "|    reward             | -0.00794753 |\n",
            "|    std                | 3.36        |\n",
            "|    value_loss         | 0.000614    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 520         |\n",
            "|    iterations         | 4000        |\n",
            "|    time_elapsed       | 38          |\n",
            "|    total_timesteps    | 20000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.65       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3999        |\n",
            "|    policy_loss        | 0.0616      |\n",
            "|    reward             | 0.003037628 |\n",
            "|    std                | 3.41        |\n",
            "|    value_loss         | 0.000516    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 517          |\n",
            "|    iterations         | 4100         |\n",
            "|    time_elapsed       | 39           |\n",
            "|    total_timesteps    | 20500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.67        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4099         |\n",
            "|    policy_loss        | -0.00251     |\n",
            "|    reward             | -0.006655737 |\n",
            "|    std                | 3.49         |\n",
            "|    value_loss         | 5.15e-06     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 515          |\n",
            "|    iterations         | 4200         |\n",
            "|    time_elapsed       | 40           |\n",
            "|    total_timesteps    | 21000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.71        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4199         |\n",
            "|    policy_loss        | -0.0154      |\n",
            "|    reward             | 0.0004158141 |\n",
            "|    std                | 3.65         |\n",
            "|    value_loss         | 4.48e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 514           |\n",
            "|    iterations         | 4300          |\n",
            "|    time_elapsed       | 41            |\n",
            "|    total_timesteps    | 21500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.75         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4299          |\n",
            "|    policy_loss        | 0.0544        |\n",
            "|    reward             | -0.0012619687 |\n",
            "|    std                | 3.79          |\n",
            "|    value_loss         | 0.000403      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 512           |\n",
            "|    iterations         | 4400          |\n",
            "|    time_elapsed       | 42            |\n",
            "|    total_timesteps    | 22000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.79         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4399          |\n",
            "|    policy_loss        | 0.0143        |\n",
            "|    reward             | -0.0031097974 |\n",
            "|    std                | 3.94          |\n",
            "|    value_loss         | 4.57e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 509           |\n",
            "|    iterations         | 4500          |\n",
            "|    time_elapsed       | 44            |\n",
            "|    total_timesteps    | 22500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.82         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4499          |\n",
            "|    policy_loss        | -0.041        |\n",
            "|    reward             | -0.0073184245 |\n",
            "|    std                | 4.06          |\n",
            "|    value_loss         | 0.000295      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 508          |\n",
            "|    iterations         | 4600         |\n",
            "|    time_elapsed       | 45           |\n",
            "|    total_timesteps    | 23000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.84        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4599         |\n",
            "|    policy_loss        | -0.0326      |\n",
            "|    reward             | -0.011576342 |\n",
            "|    std                | 4.12         |\n",
            "|    value_loss         | 0.000113     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 507           |\n",
            "|    iterations         | 4700          |\n",
            "|    time_elapsed       | 46            |\n",
            "|    total_timesteps    | 23500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.87         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4699          |\n",
            "|    policy_loss        | -0.0077       |\n",
            "|    reward             | -0.0005007232 |\n",
            "|    std                | 4.26          |\n",
            "|    value_loss         | 1.48e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 506           |\n",
            "|    iterations         | 4800          |\n",
            "|    time_elapsed       | 47            |\n",
            "|    total_timesteps    | 24000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.9          |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4799          |\n",
            "|    policy_loss        | -0.012        |\n",
            "|    reward             | -0.0008148735 |\n",
            "|    std                | 4.4           |\n",
            "|    value_loss         | 1.69e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 504          |\n",
            "|    iterations         | 4900         |\n",
            "|    time_elapsed       | 48           |\n",
            "|    total_timesteps    | 24500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.94        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4899         |\n",
            "|    policy_loss        | -0.0149      |\n",
            "|    reward             | 0.0011785197 |\n",
            "|    std                | 4.6          |\n",
            "|    value_loss         | 3.36e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 502          |\n",
            "|    iterations         | 5000         |\n",
            "|    time_elapsed       | 49           |\n",
            "|    total_timesteps    | 25000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.98        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4999         |\n",
            "|    policy_loss        | 0.0294       |\n",
            "|    reward             | 0.0146665685 |\n",
            "|    std                | 4.78         |\n",
            "|    value_loss         | 0.000119     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 501         |\n",
            "|    iterations         | 5100        |\n",
            "|    time_elapsed       | 50          |\n",
            "|    total_timesteps    | 25500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.01       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5099        |\n",
            "|    policy_loss        | 0.0116      |\n",
            "|    reward             | 0.016743345 |\n",
            "|    std                | 4.9         |\n",
            "|    value_loss         | 2.28e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 501         |\n",
            "|    iterations         | 5200        |\n",
            "|    time_elapsed       | 51          |\n",
            "|    total_timesteps    | 26000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.03       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5199        |\n",
            "|    policy_loss        | 0.00999     |\n",
            "|    reward             | 0.018273218 |\n",
            "|    std                | 5.01        |\n",
            "|    value_loss         | 1.36e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 499         |\n",
            "|    iterations         | 5300        |\n",
            "|    time_elapsed       | 53          |\n",
            "|    total_timesteps    | 26500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.06       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5299        |\n",
            "|    policy_loss        | -0.00598    |\n",
            "|    reward             | 0.001233885 |\n",
            "|    std                | 5.18        |\n",
            "|    value_loss         | 4.72e-06    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 499           |\n",
            "|    iterations         | 5400          |\n",
            "|    time_elapsed       | 54            |\n",
            "|    total_timesteps    | 27000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.1          |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5399          |\n",
            "|    policy_loss        | 0.00501       |\n",
            "|    reward             | -0.0060033114 |\n",
            "|    std                | 5.35          |\n",
            "|    value_loss         | 6.79e-06      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 497           |\n",
            "|    iterations         | 5500          |\n",
            "|    time_elapsed       | 55            |\n",
            "|    total_timesteps    | 27500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.13         |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5499          |\n",
            "|    policy_loss        | -0.00668      |\n",
            "|    reward             | -0.0029113442 |\n",
            "|    std                | 5.55          |\n",
            "|    value_loss         | 2.81e-05      |\n",
            "-----------------------------------------\n",
            "day: 2770, episode: 10\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 8034.13\n",
            "total_reward: -1965.87\n",
            "total_cost: 120.53\n",
            "total_trades: 2770\n",
            "Sharpe: -0.087\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 496           |\n",
            "|    iterations         | 5600          |\n",
            "|    time_elapsed       | 56            |\n",
            "|    total_timesteps    | 28000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.17         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5599          |\n",
            "|    policy_loss        | 0.0173        |\n",
            "|    reward             | -0.0038774062 |\n",
            "|    std                | 5.74          |\n",
            "|    value_loss         | 0.000229      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 495         |\n",
            "|    iterations         | 5700        |\n",
            "|    time_elapsed       | 57          |\n",
            "|    total_timesteps    | 28500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.19       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5699        |\n",
            "|    policy_loss        | 0.0144      |\n",
            "|    reward             | 0.005267649 |\n",
            "|    std                | 5.87        |\n",
            "|    value_loss         | 2.22e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 494          |\n",
            "|    iterations         | 5800         |\n",
            "|    time_elapsed       | 58           |\n",
            "|    total_timesteps    | 29000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.21        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5799         |\n",
            "|    policy_loss        | -0.00453     |\n",
            "|    reward             | -0.004995672 |\n",
            "|    std                | 5.98         |\n",
            "|    value_loss         | 1.29e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 494         |\n",
            "|    iterations         | 5900        |\n",
            "|    time_elapsed       | 59          |\n",
            "|    total_timesteps    | 29500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.24       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5899        |\n",
            "|    policy_loss        | 0.00188     |\n",
            "|    reward             | 0.003563555 |\n",
            "|    std                | 6.15        |\n",
            "|    value_loss         | 1.37e-05    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 493           |\n",
            "|    iterations         | 6000          |\n",
            "|    time_elapsed       | 60            |\n",
            "|    total_timesteps    | 30000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.28         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5999          |\n",
            "|    policy_loss        | 0.0126        |\n",
            "|    reward             | 0.00011202658 |\n",
            "|    std                | 6.41          |\n",
            "|    value_loss         | 5.09e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 492          |\n",
            "|    iterations         | 6100         |\n",
            "|    time_elapsed       | 61           |\n",
            "|    total_timesteps    | 30500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.31        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6099         |\n",
            "|    policy_loss        | 0.149        |\n",
            "|    reward             | -0.010730921 |\n",
            "|    std                | 6.66         |\n",
            "|    value_loss         | 0.00256      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 491         |\n",
            "|    iterations         | 6200        |\n",
            "|    time_elapsed       | 63          |\n",
            "|    total_timesteps    | 31000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.33       |\n",
            "|    explained_variance | 2.38e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6199        |\n",
            "|    policy_loss        | 0.0305      |\n",
            "|    reward             | 0.009945646 |\n",
            "|    std                | 6.77        |\n",
            "|    value_loss         | 0.00023     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 490           |\n",
            "|    iterations         | 6300          |\n",
            "|    time_elapsed       | 64            |\n",
            "|    total_timesteps    | 31500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.35         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6299          |\n",
            "|    policy_loss        | 0.0699        |\n",
            "|    reward             | -0.0051743505 |\n",
            "|    std                | 6.92          |\n",
            "|    value_loss         | 0.000616      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 490          |\n",
            "|    iterations         | 6400         |\n",
            "|    time_elapsed       | 65           |\n",
            "|    total_timesteps    | 32000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.38        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6399         |\n",
            "|    policy_loss        | 0.0239       |\n",
            "|    reward             | 0.0037588596 |\n",
            "|    std                | 7.13         |\n",
            "|    value_loss         | 5.03e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 489          |\n",
            "|    iterations         | 6500         |\n",
            "|    time_elapsed       | 66           |\n",
            "|    total_timesteps    | 32500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.41        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6499         |\n",
            "|    policy_loss        | 0.00505      |\n",
            "|    reward             | -0.008809811 |\n",
            "|    std                | 7.36         |\n",
            "|    value_loss         | 1.01e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 489          |\n",
            "|    iterations         | 6600         |\n",
            "|    time_elapsed       | 67           |\n",
            "|    total_timesteps    | 33000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.46        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6599         |\n",
            "|    policy_loss        | -0.0713      |\n",
            "|    reward             | -0.007589976 |\n",
            "|    std                | 7.71         |\n",
            "|    value_loss         | 0.00105      |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 488            |\n",
            "|    iterations         | 6700           |\n",
            "|    time_elapsed       | 68             |\n",
            "|    total_timesteps    | 33500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -3.5           |\n",
            "|    explained_variance | -1.19e-07      |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 6699           |\n",
            "|    policy_loss        | 0.0913         |\n",
            "|    reward             | -0.00084688753 |\n",
            "|    std                | 8              |\n",
            "|    value_loss         | 0.000803       |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 487         |\n",
            "|    iterations         | 6800        |\n",
            "|    time_elapsed       | 69          |\n",
            "|    total_timesteps    | 34000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.53       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6799        |\n",
            "|    policy_loss        | 0.0466      |\n",
            "|    reward             | 0.003665478 |\n",
            "|    std                | 8.25        |\n",
            "|    value_loss         | 0.00014     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 487          |\n",
            "|    iterations         | 6900         |\n",
            "|    time_elapsed       | 70           |\n",
            "|    total_timesteps    | 34500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.56        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6899         |\n",
            "|    policy_loss        | 0.00201      |\n",
            "|    reward             | -0.005459276 |\n",
            "|    std                | 8.51         |\n",
            "|    value_loss         | 3.14e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 486         |\n",
            "|    iterations         | 7000        |\n",
            "|    time_elapsed       | 71          |\n",
            "|    total_timesteps    | 35000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.59       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6999        |\n",
            "|    policy_loss        | 0.0138      |\n",
            "|    reward             | 0.000824341 |\n",
            "|    std                | 8.8         |\n",
            "|    value_loss         | 1.57e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 486          |\n",
            "|    iterations         | 7100         |\n",
            "|    time_elapsed       | 72           |\n",
            "|    total_timesteps    | 35500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.64        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7099         |\n",
            "|    policy_loss        | 0.012        |\n",
            "|    reward             | 0.0038448987 |\n",
            "|    std                | 9.18         |\n",
            "|    value_loss         | 1.54e-05     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 485            |\n",
            "|    iterations         | 7200           |\n",
            "|    time_elapsed       | 74             |\n",
            "|    total_timesteps    | 36000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -3.67          |\n",
            "|    explained_variance | 5.96e-08       |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 7199           |\n",
            "|    policy_loss        | 0.00957        |\n",
            "|    reward             | -0.00090351765 |\n",
            "|    std                | 9.54           |\n",
            "|    value_loss         | 1.14e-05       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 485            |\n",
            "|    iterations         | 7300           |\n",
            "|    time_elapsed       | 75             |\n",
            "|    total_timesteps    | 36500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -3.68          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 7299           |\n",
            "|    policy_loss        | 0.0174         |\n",
            "|    reward             | -0.00019277015 |\n",
            "|    std                | 9.63           |\n",
            "|    value_loss         | 4.81e-05       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 484          |\n",
            "|    iterations         | 7400         |\n",
            "|    time_elapsed       | 76           |\n",
            "|    total_timesteps    | 37000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.71        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7399         |\n",
            "|    policy_loss        | -0.0198      |\n",
            "|    reward             | 0.0042671748 |\n",
            "|    std                | 9.93         |\n",
            "|    value_loss         | 4.8e-05      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 484          |\n",
            "|    iterations         | 7500         |\n",
            "|    time_elapsed       | 77           |\n",
            "|    total_timesteps    | 37500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.74        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7499         |\n",
            "|    policy_loss        | 0.0403       |\n",
            "|    reward             | -0.001960696 |\n",
            "|    std                | 10.2         |\n",
            "|    value_loss         | 0.000135     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 483          |\n",
            "|    iterations         | 7600         |\n",
            "|    time_elapsed       | 78           |\n",
            "|    total_timesteps    | 38000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.77        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7599         |\n",
            "|    policy_loss        | 0.0977       |\n",
            "|    reward             | 0.0022371134 |\n",
            "|    std                | 10.5         |\n",
            "|    value_loss         | 0.000491     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 483           |\n",
            "|    iterations         | 7700          |\n",
            "|    time_elapsed       | 79            |\n",
            "|    total_timesteps    | 38500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.81         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7699          |\n",
            "|    policy_loss        | 0.0647        |\n",
            "|    reward             | -0.0028815812 |\n",
            "|    std                | 10.9          |\n",
            "|    value_loss         | 0.000331      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 482          |\n",
            "|    iterations         | 7800         |\n",
            "|    time_elapsed       | 80           |\n",
            "|    total_timesteps    | 39000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.84        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7799         |\n",
            "|    policy_loss        | 0.0371       |\n",
            "|    reward             | 0.0015270729 |\n",
            "|    std                | 11.3         |\n",
            "|    value_loss         | 0.00015      |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 481            |\n",
            "|    iterations         | 7900           |\n",
            "|    time_elapsed       | 81             |\n",
            "|    total_timesteps    | 39500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -3.86          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 7899           |\n",
            "|    policy_loss        | -0.0469        |\n",
            "|    reward             | -0.00019321509 |\n",
            "|    std                | 11.5           |\n",
            "|    value_loss         | 0.000161       |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 479         |\n",
            "|    iterations         | 8000        |\n",
            "|    time_elapsed       | 83          |\n",
            "|    total_timesteps    | 40000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.89       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7999        |\n",
            "|    policy_loss        | -0.0559     |\n",
            "|    reward             | 0.013896948 |\n",
            "|    std                | 11.8        |\n",
            "|    value_loss         | 0.000173    |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 478            |\n",
            "|    iterations         | 8100           |\n",
            "|    time_elapsed       | 84             |\n",
            "|    total_timesteps    | 40500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -3.92          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 8099           |\n",
            "|    policy_loss        | -0.000157      |\n",
            "|    reward             | -0.00013603218 |\n",
            "|    std                | 12.2           |\n",
            "|    value_loss         | 6.8e-06        |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 478          |\n",
            "|    iterations         | 8200         |\n",
            "|    time_elapsed       | 85           |\n",
            "|    total_timesteps    | 41000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.96        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8199         |\n",
            "|    policy_loss        | -0.0177      |\n",
            "|    reward             | -0.007049424 |\n",
            "|    std                | 12.7         |\n",
            "|    value_loss         | 6.88e-05     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 477            |\n",
            "|    iterations         | 8300           |\n",
            "|    time_elapsed       | 86             |\n",
            "|    total_timesteps    | 41500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -4.01          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 8299           |\n",
            "|    policy_loss        | 0.00474        |\n",
            "|    reward             | -0.00013546369 |\n",
            "|    std                | 13.4           |\n",
            "|    value_loss         | 6.2e-06        |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 15\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 9867.27\n",
            "total_reward: -132.73\n",
            "total_cost: 113.29\n",
            "total_trades: 2770\n",
            "Sharpe: 0.074\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 477         |\n",
            "|    iterations         | 8400        |\n",
            "|    time_elapsed       | 87          |\n",
            "|    total_timesteps    | 42000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.06       |\n",
            "|    explained_variance | -2.38e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8399        |\n",
            "|    policy_loss        | 0.137       |\n",
            "|    reward             | -0.03377037 |\n",
            "|    std                | 14          |\n",
            "|    value_loss         | 0.00177     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 476          |\n",
            "|    iterations         | 8500         |\n",
            "|    time_elapsed       | 89           |\n",
            "|    total_timesteps    | 42500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.08        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8499         |\n",
            "|    policy_loss        | -0.0276      |\n",
            "|    reward             | 0.0013192664 |\n",
            "|    std                | 14.4         |\n",
            "|    value_loss         | 0.000106     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 476          |\n",
            "|    iterations         | 8600         |\n",
            "|    time_elapsed       | 90           |\n",
            "|    total_timesteps    | 43000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.12        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8599         |\n",
            "|    policy_loss        | 0.0222       |\n",
            "|    reward             | 0.0030311034 |\n",
            "|    std                | 14.9         |\n",
            "|    value_loss         | 6.18e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 475          |\n",
            "|    iterations         | 8700         |\n",
            "|    time_elapsed       | 91           |\n",
            "|    total_timesteps    | 43500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.17        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8699         |\n",
            "|    policy_loss        | -0.101       |\n",
            "|    reward             | -0.004474874 |\n",
            "|    std                | 15.6         |\n",
            "|    value_loss         | 0.000665     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 475          |\n",
            "|    iterations         | 8800         |\n",
            "|    time_elapsed       | 92           |\n",
            "|    total_timesteps    | 44000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.21        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8799         |\n",
            "|    policy_loss        | 0.00817      |\n",
            "|    reward             | 0.0046990765 |\n",
            "|    std                | 16.3         |\n",
            "|    value_loss         | 5.59e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 475         |\n",
            "|    iterations         | 8900        |\n",
            "|    time_elapsed       | 93          |\n",
            "|    total_timesteps    | 44500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.25       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8899        |\n",
            "|    policy_loss        | 0.161       |\n",
            "|    reward             | 0.030696755 |\n",
            "|    std                | 16.9        |\n",
            "|    value_loss         | 0.00169     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 474           |\n",
            "|    iterations         | 9000          |\n",
            "|    time_elapsed       | 94            |\n",
            "|    total_timesteps    | 45000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.27         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8999          |\n",
            "|    policy_loss        | -0.0159       |\n",
            "|    reward             | -0.0008821586 |\n",
            "|    std                | 17.4          |\n",
            "|    value_loss         | 2.21e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 474         |\n",
            "|    iterations         | 9100        |\n",
            "|    time_elapsed       | 95          |\n",
            "|    total_timesteps    | 45500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.3        |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9099        |\n",
            "|    policy_loss        | -0.0337     |\n",
            "|    reward             | 0.008306184 |\n",
            "|    std                | 17.9        |\n",
            "|    value_loss         | 7.75e-05    |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 474            |\n",
            "|    iterations         | 9200           |\n",
            "|    time_elapsed       | 96             |\n",
            "|    total_timesteps    | 46000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -4.33          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 9199           |\n",
            "|    policy_loss        | -0.0085        |\n",
            "|    reward             | -2.1609412e-06 |\n",
            "|    std                | 18.4           |\n",
            "|    value_loss         | 0.000274       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 474           |\n",
            "|    iterations         | 9300          |\n",
            "|    time_elapsed       | 98            |\n",
            "|    total_timesteps    | 46500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.36         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9299          |\n",
            "|    policy_loss        | 0.0125        |\n",
            "|    reward             | -0.0015730067 |\n",
            "|    std                | 19            |\n",
            "|    value_loss         | 3.07e-05      |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 473        |\n",
            "|    iterations         | 9400       |\n",
            "|    time_elapsed       | 99         |\n",
            "|    total_timesteps    | 47000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.4       |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9399       |\n",
            "|    policy_loss        | -0.0193    |\n",
            "|    reward             | 0.01517398 |\n",
            "|    std                | 19.7       |\n",
            "|    value_loss         | 5.17e-05   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 473         |\n",
            "|    iterations         | 9500        |\n",
            "|    time_elapsed       | 100         |\n",
            "|    total_timesteps    | 47500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.42       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9499        |\n",
            "|    policy_loss        | -0.0716     |\n",
            "|    reward             | -0.00730195 |\n",
            "|    std                | 20.2        |\n",
            "|    value_loss         | 0.000386    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 473        |\n",
            "|    iterations         | 9600       |\n",
            "|    time_elapsed       | 101        |\n",
            "|    total_timesteps    | 48000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.45      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9599       |\n",
            "|    policy_loss        | 0.0371     |\n",
            "|    reward             | 0.00778016 |\n",
            "|    std                | 20.7       |\n",
            "|    value_loss         | 0.000126   |\n",
            "--------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 472            |\n",
            "|    iterations         | 9700           |\n",
            "|    time_elapsed       | 102            |\n",
            "|    total_timesteps    | 48500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -4.47          |\n",
            "|    explained_variance | -1.19e-07      |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 9699           |\n",
            "|    policy_loss        | -0.132         |\n",
            "|    reward             | -0.00091602304 |\n",
            "|    std                | 21.2           |\n",
            "|    value_loss         | 0.00121        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 472           |\n",
            "|    iterations         | 9800          |\n",
            "|    time_elapsed       | 103           |\n",
            "|    total_timesteps    | 49000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.51         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9799          |\n",
            "|    policy_loss        | 0.000225      |\n",
            "|    reward             | 0.00021946387 |\n",
            "|    std                | 21.9          |\n",
            "|    value_loss         | 2.22e-06      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 472           |\n",
            "|    iterations         | 9900          |\n",
            "|    time_elapsed       | 104           |\n",
            "|    total_timesteps    | 49500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.55         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9899          |\n",
            "|    policy_loss        | -0.0444       |\n",
            "|    reward             | -0.0055202874 |\n",
            "|    std                | 22.9          |\n",
            "|    value_loss         | 0.000126      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 472           |\n",
            "|    iterations         | 10000         |\n",
            "|    time_elapsed       | 105           |\n",
            "|    total_timesteps    | 50000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.59         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9999          |\n",
            "|    policy_loss        | -0.0537       |\n",
            "|    reward             | -0.0044113505 |\n",
            "|    std                | 23.8          |\n",
            "|    value_loss         | 0.000202      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 471         |\n",
            "|    iterations         | 10100       |\n",
            "|    time_elapsed       | 107         |\n",
            "|    total_timesteps    | 50500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.62       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10099       |\n",
            "|    policy_loss        | -0.0519     |\n",
            "|    reward             | 0.009557336 |\n",
            "|    std                | 24.6        |\n",
            "|    value_loss         | 0.000233    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 471         |\n",
            "|    iterations         | 10200       |\n",
            "|    time_elapsed       | 108         |\n",
            "|    total_timesteps    | 51000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.65       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10199       |\n",
            "|    policy_loss        | -0.0052     |\n",
            "|    reward             | 0.002943789 |\n",
            "|    std                | 25.3        |\n",
            "|    value_loss         | 4.99e-06    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 471         |\n",
            "|    iterations         | 10300       |\n",
            "|    time_elapsed       | 109         |\n",
            "|    total_timesteps    | 51500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.69       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10299       |\n",
            "|    policy_loss        | -0.0149     |\n",
            "|    reward             | 0.005150453 |\n",
            "|    std                | 26.3        |\n",
            "|    value_loss         | 1.33e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 470         |\n",
            "|    iterations         | 10400       |\n",
            "|    time_elapsed       | 110         |\n",
            "|    total_timesteps    | 52000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.73       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10399       |\n",
            "|    policy_loss        | -0.0269     |\n",
            "|    reward             | 0.004748614 |\n",
            "|    std                | 27.3        |\n",
            "|    value_loss         | 2.32e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 470         |\n",
            "|    iterations         | 10500       |\n",
            "|    time_elapsed       | 111         |\n",
            "|    total_timesteps    | 52500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.79       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10499       |\n",
            "|    policy_loss        | 0.0109      |\n",
            "|    reward             | -0.02382659 |\n",
            "|    std                | 29          |\n",
            "|    value_loss         | 3.75e-05    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 470           |\n",
            "|    iterations         | 10600         |\n",
            "|    time_elapsed       | 112           |\n",
            "|    total_timesteps    | 53000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.82         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10599         |\n",
            "|    policy_loss        | -0.141        |\n",
            "|    reward             | 0.00015211116 |\n",
            "|    std                | 29.9          |\n",
            "|    value_loss         | 0.000984      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 470         |\n",
            "|    iterations         | 10700       |\n",
            "|    time_elapsed       | 113         |\n",
            "|    total_timesteps    | 53500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.84       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10699       |\n",
            "|    policy_loss        | 0.158       |\n",
            "|    reward             | 0.008757956 |\n",
            "|    std                | 30.7        |\n",
            "|    value_loss         | 0.00109     |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 469            |\n",
            "|    iterations         | 10800          |\n",
            "|    time_elapsed       | 114            |\n",
            "|    total_timesteps    | 54000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -4.88          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 10799          |\n",
            "|    policy_loss        | 0.023          |\n",
            "|    reward             | -0.00032372208 |\n",
            "|    std                | 31.8           |\n",
            "|    value_loss         | 3.27e-05       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 469          |\n",
            "|    iterations         | 10900        |\n",
            "|    time_elapsed       | 116          |\n",
            "|    total_timesteps    | 54500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.92        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10899        |\n",
            "|    policy_loss        | 0.00501      |\n",
            "|    reward             | 0.0004442798 |\n",
            "|    std                | 33.1         |\n",
            "|    value_loss         | 0.000101     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 469         |\n",
            "|    iterations         | 11000       |\n",
            "|    time_elapsed       | 117         |\n",
            "|    total_timesteps    | 55000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.96       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10999       |\n",
            "|    policy_loss        | -0.0042     |\n",
            "|    reward             | 0.009936907 |\n",
            "|    std                | 34.6        |\n",
            "|    value_loss         | 8.91e-06    |\n",
            "---------------------------------------\n",
            "======A2C Validation from:  2021-04-06 to  2021-05-05\n",
            "A2C Sharpe Ratio:  -0.1528148006227888\n",
            "======Best Model Retraining from:  2010-04-01 to  2021-05-05\n",
            "======Trading from:  2021-05-05 to  2021-06-04\n",
            "[[ 1.3785862e+04  2.5090578e+01 -1.6300000e+02  1.9371344e-01\n",
            "   2.5122517e+01  2.3771212e+01  5.6715881e+01  1.9440404e+02\n",
            "   3.1301678e+01  2.4378202e+01  2.3856964e+01]]\n",
            "============================================\n",
            "turbulence_threshold:  12.04306128869847\n",
            "======Model training from:  2010-04-01 to  2021-05-05\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c\\a2c_126_1\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 463           |\n",
            "|    iterations         | 100           |\n",
            "|    time_elapsed       | 1             |\n",
            "|    total_timesteps    | 500           |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.48         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 99            |\n",
            "|    policy_loss        | -0.013        |\n",
            "|    reward             | -0.0051457617 |\n",
            "|    std                | 1.06          |\n",
            "|    value_loss         | 0.000134      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 460         |\n",
            "|    iterations         | 200         |\n",
            "|    time_elapsed       | 2           |\n",
            "|    total_timesteps    | 1000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.51       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 199         |\n",
            "|    policy_loss        | 0.00767     |\n",
            "|    reward             | 0.002399447 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 8.89e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 454          |\n",
            "|    iterations         | 300          |\n",
            "|    time_elapsed       | 3            |\n",
            "|    total_timesteps    | 1500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.55        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 299          |\n",
            "|    policy_loss        | -0.00164     |\n",
            "|    reward             | -0.009320873 |\n",
            "|    std                | 1.14         |\n",
            "|    value_loss         | 3.55e-06     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 455           |\n",
            "|    iterations         | 400           |\n",
            "|    time_elapsed       | 4             |\n",
            "|    total_timesteps    | 2000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.59         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 399           |\n",
            "|    policy_loss        | -0.00869      |\n",
            "|    reward             | -0.0010971107 |\n",
            "|    std                | 1.19          |\n",
            "|    value_loss         | 4.19e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 448         |\n",
            "|    iterations         | 500         |\n",
            "|    time_elapsed       | 5           |\n",
            "|    total_timesteps    | 2500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.62       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 499         |\n",
            "|    policy_loss        | 0.00157     |\n",
            "|    reward             | 0.031843137 |\n",
            "|    std                | 1.23        |\n",
            "|    value_loss         | 0.000173    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 450          |\n",
            "|    iterations         | 600          |\n",
            "|    time_elapsed       | 6            |\n",
            "|    total_timesteps    | 3000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.65        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 599          |\n",
            "|    policy_loss        | 0.193        |\n",
            "|    reward             | -0.005400985 |\n",
            "|    std                | 1.26         |\n",
            "|    value_loss         | 0.0141       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 448         |\n",
            "|    iterations         | 700         |\n",
            "|    time_elapsed       | 7           |\n",
            "|    total_timesteps    | 3500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.67       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 699         |\n",
            "|    policy_loss        | -0.047      |\n",
            "|    reward             | -0.01280755 |\n",
            "|    std                | 1.29        |\n",
            "|    value_loss         | 0.00118     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 448          |\n",
            "|    iterations         | 800          |\n",
            "|    time_elapsed       | 8            |\n",
            "|    total_timesteps    | 4000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.67        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 799          |\n",
            "|    policy_loss        | 0.00562      |\n",
            "|    reward             | -0.007173283 |\n",
            "|    std                | 1.28         |\n",
            "|    value_loss         | 0.00135      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 447         |\n",
            "|    iterations         | 900         |\n",
            "|    time_elapsed       | 10          |\n",
            "|    total_timesteps    | 4500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.67       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 899         |\n",
            "|    policy_loss        | -0.0238     |\n",
            "|    reward             | 0.005271589 |\n",
            "|    std                | 1.28        |\n",
            "|    value_loss         | 0.000755    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 446          |\n",
            "|    iterations         | 1000         |\n",
            "|    time_elapsed       | 11           |\n",
            "|    total_timesteps    | 5000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.68        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 999          |\n",
            "|    policy_loss        | -0.0747      |\n",
            "|    reward             | -0.037008125 |\n",
            "|    std                | 1.29         |\n",
            "|    value_loss         | 0.00638      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 446          |\n",
            "|    iterations         | 1100         |\n",
            "|    time_elapsed       | 12           |\n",
            "|    total_timesteps    | 5500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.68        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1099         |\n",
            "|    policy_loss        | 0.00291      |\n",
            "|    reward             | -0.014809725 |\n",
            "|    std                | 1.29         |\n",
            "|    value_loss         | 0.000524     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 446          |\n",
            "|    iterations         | 1200         |\n",
            "|    time_elapsed       | 13           |\n",
            "|    total_timesteps    | 6000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.68        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1199         |\n",
            "|    policy_loss        | -0.0176      |\n",
            "|    reward             | 0.0129735265 |\n",
            "|    std                | 1.3          |\n",
            "|    value_loss         | 0.00049      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 447         |\n",
            "|    iterations         | 1300        |\n",
            "|    time_elapsed       | 14          |\n",
            "|    total_timesteps    | 6500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.68       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1299        |\n",
            "|    policy_loss        | -0.0414     |\n",
            "|    reward             | 0.006302215 |\n",
            "|    std                | 1.3         |\n",
            "|    value_loss         | 0.000768    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 446        |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 15         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.7       |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 0.017      |\n",
            "|    reward             | 0.03434819 |\n",
            "|    std                | 1.33       |\n",
            "|    value_loss         | 0.000187   |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 446          |\n",
            "|    iterations         | 1500         |\n",
            "|    time_elapsed       | 16           |\n",
            "|    total_timesteps    | 7500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.72        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1499         |\n",
            "|    policy_loss        | -0.00185     |\n",
            "|    reward             | -0.011724496 |\n",
            "|    std                | 1.35         |\n",
            "|    value_loss         | 8.19e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 446          |\n",
            "|    iterations         | 1600         |\n",
            "|    time_elapsed       | 17           |\n",
            "|    total_timesteps    | 8000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.73        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1599         |\n",
            "|    policy_loss        | 0.0206       |\n",
            "|    reward             | -0.019648774 |\n",
            "|    std                | 1.37         |\n",
            "|    value_loss         | 0.000346     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 446           |\n",
            "|    iterations         | 1700          |\n",
            "|    time_elapsed       | 19            |\n",
            "|    total_timesteps    | 8500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.73         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1699          |\n",
            "|    policy_loss        | -0.00706      |\n",
            "|    reward             | -0.0037439207 |\n",
            "|    std                | 1.36          |\n",
            "|    value_loss         | 4.77e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 446          |\n",
            "|    iterations         | 1800         |\n",
            "|    time_elapsed       | 20           |\n",
            "|    total_timesteps    | 9000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.74        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1799         |\n",
            "|    policy_loss        | -0.0419      |\n",
            "|    reward             | 0.0066932803 |\n",
            "|    std                | 1.38         |\n",
            "|    value_loss         | 0.00038      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 446          |\n",
            "|    iterations         | 1900         |\n",
            "|    time_elapsed       | 21           |\n",
            "|    total_timesteps    | 9500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.77        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1899         |\n",
            "|    policy_loss        | -0.0101      |\n",
            "|    reward             | 0.0006803663 |\n",
            "|    std                | 1.42         |\n",
            "|    value_loss         | 8.29e-05     |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 447        |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 22         |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.8       |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | -0.00778   |\n",
            "|    reward             | 0.01566782 |\n",
            "|    std                | 1.47       |\n",
            "|    value_loss         | 1.99e-05   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 446         |\n",
            "|    iterations         | 2100        |\n",
            "|    time_elapsed       | 23          |\n",
            "|    total_timesteps    | 10500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.83       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2099        |\n",
            "|    policy_loss        | 0.00842     |\n",
            "|    reward             | 0.004429981 |\n",
            "|    std                | 1.52        |\n",
            "|    value_loss         | 2.2e-05     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 446          |\n",
            "|    iterations         | 2200         |\n",
            "|    time_elapsed       | 24           |\n",
            "|    total_timesteps    | 11000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.88        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2199         |\n",
            "|    policy_loss        | -0.0108      |\n",
            "|    reward             | -0.007727593 |\n",
            "|    std                | 1.58         |\n",
            "|    value_loss         | 4.15e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 445          |\n",
            "|    iterations         | 2300         |\n",
            "|    time_elapsed       | 25           |\n",
            "|    total_timesteps    | 11500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.9         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2299         |\n",
            "|    policy_loss        | -0.0247      |\n",
            "|    reward             | -0.007075705 |\n",
            "|    std                | 1.63         |\n",
            "|    value_loss         | 0.000264     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 446         |\n",
            "|    iterations         | 2400        |\n",
            "|    time_elapsed       | 26          |\n",
            "|    total_timesteps    | 12000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.94       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2399        |\n",
            "|    policy_loss        | -0.0263     |\n",
            "|    reward             | -0.01664025 |\n",
            "|    std                | 1.68        |\n",
            "|    value_loss         | 0.000235    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 446           |\n",
            "|    iterations         | 2500          |\n",
            "|    time_elapsed       | 27            |\n",
            "|    total_timesteps    | 12500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.97         |\n",
            "|    explained_variance | -2.38e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2499          |\n",
            "|    policy_loss        | -0.0159       |\n",
            "|    reward             | -0.0011377122 |\n",
            "|    std                | 1.73          |\n",
            "|    value_loss         | 7.39e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 446           |\n",
            "|    iterations         | 2600          |\n",
            "|    time_elapsed       | 29            |\n",
            "|    total_timesteps    | 13000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.99         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2599          |\n",
            "|    policy_loss        | -0.0164       |\n",
            "|    reward             | -0.0016040389 |\n",
            "|    std                | 1.78          |\n",
            "|    value_loss         | 5.34e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 445          |\n",
            "|    iterations         | 2700         |\n",
            "|    time_elapsed       | 30           |\n",
            "|    total_timesteps    | 13500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.03        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2699         |\n",
            "|    policy_loss        | -0.0258      |\n",
            "|    reward             | 0.0027371896 |\n",
            "|    std                | 1.83         |\n",
            "|    value_loss         | 0.000166     |\n",
            "----------------------------------------\n",
            "day: 2791, episode: 5\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 8181.65\n",
            "total_reward: -1818.35\n",
            "total_cost: 98.25\n",
            "total_trades: 2791\n",
            "Sharpe: 0.017\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 444         |\n",
            "|    iterations         | 2800        |\n",
            "|    time_elapsed       | 31          |\n",
            "|    total_timesteps    | 14000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.04       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2799        |\n",
            "|    policy_loss        | 0.0128      |\n",
            "|    reward             | 0.008470596 |\n",
            "|    std                | 1.86        |\n",
            "|    value_loss         | 0.000129    |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 443            |\n",
            "|    iterations         | 2900           |\n",
            "|    time_elapsed       | 32             |\n",
            "|    total_timesteps    | 14500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -2.07          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 2899           |\n",
            "|    policy_loss        | 0.0262         |\n",
            "|    reward             | -0.00024432078 |\n",
            "|    std                | 1.92           |\n",
            "|    value_loss         | 0.000358       |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 442         |\n",
            "|    iterations         | 3000        |\n",
            "|    time_elapsed       | 33          |\n",
            "|    total_timesteps    | 15000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.1        |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2999        |\n",
            "|    policy_loss        | -0.0101     |\n",
            "|    reward             | 0.006662429 |\n",
            "|    std                | 1.98        |\n",
            "|    value_loss         | 2.33e-05    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 442           |\n",
            "|    iterations         | 3100          |\n",
            "|    time_elapsed       | 35            |\n",
            "|    total_timesteps    | 15500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.12         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3099          |\n",
            "|    policy_loss        | 0.011         |\n",
            "|    reward             | -3.823963e-06 |\n",
            "|    std                | 2.02          |\n",
            "|    value_loss         | 8.6e-05       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 442           |\n",
            "|    iterations         | 3200          |\n",
            "|    time_elapsed       | 36            |\n",
            "|    total_timesteps    | 16000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.16         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3199          |\n",
            "|    policy_loss        | -0.0218       |\n",
            "|    reward             | -0.0053202654 |\n",
            "|    std                | 2.1           |\n",
            "|    value_loss         | 9.47e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 442          |\n",
            "|    iterations         | 3300         |\n",
            "|    time_elapsed       | 37           |\n",
            "|    total_timesteps    | 16500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.19        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3299         |\n",
            "|    policy_loss        | -0.0377      |\n",
            "|    reward             | -0.013523199 |\n",
            "|    std                | 2.15         |\n",
            "|    value_loss         | 0.000355     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 443           |\n",
            "|    iterations         | 3400          |\n",
            "|    time_elapsed       | 38            |\n",
            "|    total_timesteps    | 17000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.2          |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3399          |\n",
            "|    policy_loss        | 0.0927        |\n",
            "|    reward             | -0.0015334988 |\n",
            "|    std                | 2.17          |\n",
            "|    value_loss         | 0.00226       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 443         |\n",
            "|    iterations         | 3500        |\n",
            "|    time_elapsed       | 39          |\n",
            "|    total_timesteps    | 17500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.22       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3499        |\n",
            "|    policy_loss        | 0.0337      |\n",
            "|    reward             | 0.004834293 |\n",
            "|    std                | 2.22        |\n",
            "|    value_loss         | 0.000234    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 444          |\n",
            "|    iterations         | 3600         |\n",
            "|    time_elapsed       | 40           |\n",
            "|    total_timesteps    | 18000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.24        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3599         |\n",
            "|    policy_loss        | 0.00224      |\n",
            "|    reward             | -0.009571226 |\n",
            "|    std                | 2.28         |\n",
            "|    value_loss         | 9.89e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 443          |\n",
            "|    iterations         | 3700         |\n",
            "|    time_elapsed       | 41           |\n",
            "|    total_timesteps    | 18500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.27        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3699         |\n",
            "|    policy_loss        | 0.0154       |\n",
            "|    reward             | 0.0018263272 |\n",
            "|    std                | 2.35         |\n",
            "|    value_loss         | 7.54e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 443         |\n",
            "|    iterations         | 3800        |\n",
            "|    time_elapsed       | 42          |\n",
            "|    total_timesteps    | 19000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.31       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3799        |\n",
            "|    policy_loss        | 0.031       |\n",
            "|    reward             | 0.013955707 |\n",
            "|    std                | 2.43        |\n",
            "|    value_loss         | 0.000279    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 443           |\n",
            "|    iterations         | 3900          |\n",
            "|    time_elapsed       | 43            |\n",
            "|    total_timesteps    | 19500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.33         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3899          |\n",
            "|    policy_loss        | 0.0295        |\n",
            "|    reward             | -0.0046487036 |\n",
            "|    std                | 2.48          |\n",
            "|    value_loss         | 0.000372      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 444         |\n",
            "|    iterations         | 4000        |\n",
            "|    time_elapsed       | 45          |\n",
            "|    total_timesteps    | 20000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.34       |\n",
            "|    explained_variance | -2.38e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3999        |\n",
            "|    policy_loss        | 0.00225     |\n",
            "|    reward             | 0.011178514 |\n",
            "|    std                | 2.52        |\n",
            "|    value_loss         | 0.000104    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 444         |\n",
            "|    iterations         | 4100        |\n",
            "|    time_elapsed       | 46          |\n",
            "|    total_timesteps    | 20500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.36       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4099        |\n",
            "|    policy_loss        | -0.0617     |\n",
            "|    reward             | -0.00820963 |\n",
            "|    std                | 2.57        |\n",
            "|    value_loss         | 0.000758    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 444         |\n",
            "|    iterations         | 4200        |\n",
            "|    time_elapsed       | 47          |\n",
            "|    total_timesteps    | 21000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.39       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4199        |\n",
            "|    policy_loss        | 0.152       |\n",
            "|    reward             | 0.035159405 |\n",
            "|    std                | 2.65        |\n",
            "|    value_loss         | 0.00312     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 444         |\n",
            "|    iterations         | 4300        |\n",
            "|    time_elapsed       | 48          |\n",
            "|    total_timesteps    | 21500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.42       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4299        |\n",
            "|    policy_loss        | 0.0774      |\n",
            "|    reward             | -0.02158035 |\n",
            "|    std                | 2.72        |\n",
            "|    value_loss         | 0.00097     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 444        |\n",
            "|    iterations         | 4400       |\n",
            "|    time_elapsed       | 49         |\n",
            "|    total_timesteps    | 22000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.43      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4399       |\n",
            "|    policy_loss        | -0.037     |\n",
            "|    reward             | 0.03951731 |\n",
            "|    std                | 2.76       |\n",
            "|    value_loss         | 0.000343   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 444        |\n",
            "|    iterations         | 4500       |\n",
            "|    time_elapsed       | 50         |\n",
            "|    total_timesteps    | 22500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.45      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4499       |\n",
            "|    policy_loss        | 0.0537     |\n",
            "|    reward             | 0.01985132 |\n",
            "|    std                | 2.8        |\n",
            "|    value_loss         | 0.00064    |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 444           |\n",
            "|    iterations         | 4600          |\n",
            "|    time_elapsed       | 51            |\n",
            "|    total_timesteps    | 23000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.46         |\n",
            "|    explained_variance | 1.79e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4599          |\n",
            "|    policy_loss        | -0.0163       |\n",
            "|    reward             | -0.0016276004 |\n",
            "|    std                | 2.85          |\n",
            "|    value_loss         | 7.88e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 444         |\n",
            "|    iterations         | 4700        |\n",
            "|    time_elapsed       | 52          |\n",
            "|    total_timesteps    | 23500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.48       |\n",
            "|    explained_variance | 3.58e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4699        |\n",
            "|    policy_loss        | -0.0615     |\n",
            "|    reward             | 0.025478795 |\n",
            "|    std                | 2.89        |\n",
            "|    value_loss         | 0.000844    |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 444            |\n",
            "|    iterations         | 4800           |\n",
            "|    time_elapsed       | 53             |\n",
            "|    total_timesteps    | 24000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -2.49          |\n",
            "|    explained_variance | 1.19e-07       |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 4799           |\n",
            "|    policy_loss        | -0.0283        |\n",
            "|    reward             | -4.3218824e-06 |\n",
            "|    std                | 2.92           |\n",
            "|    value_loss         | 0.00665        |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 444          |\n",
            "|    iterations         | 4900         |\n",
            "|    time_elapsed       | 55           |\n",
            "|    total_timesteps    | 24500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.5         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4899         |\n",
            "|    policy_loss        | 0.0651       |\n",
            "|    reward             | -0.012673406 |\n",
            "|    std                | 2.94         |\n",
            "|    value_loss         | 0.00214      |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 445        |\n",
            "|    iterations         | 5000       |\n",
            "|    time_elapsed       | 56         |\n",
            "|    total_timesteps    | 25000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.51      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4999       |\n",
            "|    policy_loss        | -0.0666    |\n",
            "|    reward             | 0.09926876 |\n",
            "|    std                | 2.98       |\n",
            "|    value_loss         | 0.00196    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 444         |\n",
            "|    iterations         | 5100        |\n",
            "|    time_elapsed       | 57          |\n",
            "|    total_timesteps    | 25500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.52       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5099        |\n",
            "|    policy_loss        | -0.00104    |\n",
            "|    reward             | 0.007884573 |\n",
            "|    std                | 3           |\n",
            "|    value_loss         | 4.9e-06     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 444           |\n",
            "|    iterations         | 5200          |\n",
            "|    time_elapsed       | 58            |\n",
            "|    total_timesteps    | 26000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.53         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5199          |\n",
            "|    policy_loss        | -0.0366       |\n",
            "|    reward             | -0.0077719414 |\n",
            "|    std                | 3.04          |\n",
            "|    value_loss         | 0.000325      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 444           |\n",
            "|    iterations         | 5300          |\n",
            "|    time_elapsed       | 59            |\n",
            "|    total_timesteps    | 26500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.55         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5299          |\n",
            "|    policy_loss        | 0.0559        |\n",
            "|    reward             | -0.0031807164 |\n",
            "|    std                | 3.11          |\n",
            "|    value_loss         | 0.000818      |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 444        |\n",
            "|    iterations         | 5400       |\n",
            "|    time_elapsed       | 60         |\n",
            "|    total_timesteps    | 27000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.57      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5399       |\n",
            "|    policy_loss        | -0.0388    |\n",
            "|    reward             | 0.03211273 |\n",
            "|    std                | 3.18       |\n",
            "|    value_loss         | 0.000282   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 444         |\n",
            "|    iterations         | 5500        |\n",
            "|    time_elapsed       | 61          |\n",
            "|    total_timesteps    | 27500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.58       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5499        |\n",
            "|    policy_loss        | 0.144       |\n",
            "|    reward             | -0.04232807 |\n",
            "|    std                | 3.18        |\n",
            "|    value_loss         | 0.00352     |\n",
            "---------------------------------------\n",
            "day: 2791, episode: 10\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 6711.96\n",
            "total_reward: -3288.04\n",
            "total_cost: 109.52\n",
            "total_trades: 2791\n",
            "Sharpe: 0.167\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 444          |\n",
            "|    iterations         | 5600         |\n",
            "|    time_elapsed       | 62           |\n",
            "|    total_timesteps    | 28000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.6         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5599         |\n",
            "|    policy_loss        | -0.00139     |\n",
            "|    reward             | 0.0121429665 |\n",
            "|    std                | 3.24         |\n",
            "|    value_loss         | 4.11e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 444          |\n",
            "|    iterations         | 5700         |\n",
            "|    time_elapsed       | 64           |\n",
            "|    total_timesteps    | 28500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.61        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5699         |\n",
            "|    policy_loss        | 0.0669       |\n",
            "|    reward             | -0.021269655 |\n",
            "|    std                | 3.28         |\n",
            "|    value_loss         | 0.000877     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 444           |\n",
            "|    iterations         | 5800          |\n",
            "|    time_elapsed       | 65            |\n",
            "|    total_timesteps    | 29000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.63         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5799          |\n",
            "|    policy_loss        | 0.0081        |\n",
            "|    reward             | -0.0010782025 |\n",
            "|    std                | 3.35          |\n",
            "|    value_loss         | 0.000287      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 444          |\n",
            "|    iterations         | 5900         |\n",
            "|    time_elapsed       | 66           |\n",
            "|    total_timesteps    | 29500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.64        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5899         |\n",
            "|    policy_loss        | -0.035       |\n",
            "|    reward             | -0.017324895 |\n",
            "|    std                | 3.4          |\n",
            "|    value_loss         | 0.00151      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 444           |\n",
            "|    iterations         | 6000          |\n",
            "|    time_elapsed       | 67            |\n",
            "|    total_timesteps    | 30000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.65         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5999          |\n",
            "|    policy_loss        | -0.134        |\n",
            "|    reward             | -0.0146358805 |\n",
            "|    std                | 3.42          |\n",
            "|    value_loss         | 0.0033        |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 444        |\n",
            "|    iterations         | 6100       |\n",
            "|    time_elapsed       | 68         |\n",
            "|    total_timesteps    | 30500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.65      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6099       |\n",
            "|    policy_loss        | 0.332      |\n",
            "|    reward             | 0.03960652 |\n",
            "|    std                | 3.43       |\n",
            "|    value_loss         | 0.0224     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 444        |\n",
            "|    iterations         | 6200       |\n",
            "|    time_elapsed       | 69         |\n",
            "|    total_timesteps    | 31000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.66      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6199       |\n",
            "|    policy_loss        | -0.0317    |\n",
            "|    reward             | 0.05080378 |\n",
            "|    std                | 3.48       |\n",
            "|    value_loss         | 0.00202    |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 444          |\n",
            "|    iterations         | 6300         |\n",
            "|    time_elapsed       | 70           |\n",
            "|    total_timesteps    | 31500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.68        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6299         |\n",
            "|    policy_loss        | -0.0295      |\n",
            "|    reward             | 0.0020913666 |\n",
            "|    std                | 3.53         |\n",
            "|    value_loss         | 0.000502     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 444          |\n",
            "|    iterations         | 6400         |\n",
            "|    time_elapsed       | 71           |\n",
            "|    total_timesteps    | 32000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.69        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6399         |\n",
            "|    policy_loss        | 0.0122       |\n",
            "|    reward             | -0.025461856 |\n",
            "|    std                | 3.58         |\n",
            "|    value_loss         | 0.000417     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 444         |\n",
            "|    iterations         | 6500        |\n",
            "|    time_elapsed       | 73          |\n",
            "|    total_timesteps    | 32500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.71       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6499        |\n",
            "|    policy_loss        | -0.356      |\n",
            "|    reward             | -0.02262346 |\n",
            "|    std                | 3.64        |\n",
            "|    value_loss         | 0.0334      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 444         |\n",
            "|    iterations         | 6600        |\n",
            "|    time_elapsed       | 74          |\n",
            "|    total_timesteps    | 33000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.73       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6599        |\n",
            "|    policy_loss        | 0.0676      |\n",
            "|    reward             | 0.062031206 |\n",
            "|    std                | 3.7         |\n",
            "|    value_loss         | 0.00632     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 444         |\n",
            "|    iterations         | 6700        |\n",
            "|    time_elapsed       | 75          |\n",
            "|    total_timesteps    | 33500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.72       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6699        |\n",
            "|    policy_loss        | 0.31        |\n",
            "|    reward             | -0.19521715 |\n",
            "|    std                | 3.68        |\n",
            "|    value_loss         | 0.0145      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 444         |\n",
            "|    iterations         | 6800        |\n",
            "|    time_elapsed       | 76          |\n",
            "|    total_timesteps    | 34000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.74       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6799        |\n",
            "|    policy_loss        | -0.0144     |\n",
            "|    reward             | 0.018339332 |\n",
            "|    std                | 3.73        |\n",
            "|    value_loss         | 4.57e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 444          |\n",
            "|    iterations         | 6900         |\n",
            "|    time_elapsed       | 77           |\n",
            "|    total_timesteps    | 34500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.75        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6899         |\n",
            "|    policy_loss        | 0.162        |\n",
            "|    reward             | -0.032374263 |\n",
            "|    std                | 3.79         |\n",
            "|    value_loss         | 0.00336      |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 444        |\n",
            "|    iterations         | 7000       |\n",
            "|    time_elapsed       | 78         |\n",
            "|    total_timesteps    | 35000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.76      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6999       |\n",
            "|    policy_loss        | -0.104     |\n",
            "|    reward             | -0.0712567 |\n",
            "|    std                | 3.84       |\n",
            "|    value_loss         | 0.00141    |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 444        |\n",
            "|    iterations         | 7100       |\n",
            "|    time_elapsed       | 79         |\n",
            "|    total_timesteps    | 35500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.77      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7099       |\n",
            "|    policy_loss        | 0.0718     |\n",
            "|    reward             | 0.00730624 |\n",
            "|    std                | 3.88       |\n",
            "|    value_loss         | 0.000779   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 443         |\n",
            "|    iterations         | 7200        |\n",
            "|    time_elapsed       | 81          |\n",
            "|    total_timesteps    | 36000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.78       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7199        |\n",
            "|    policy_loss        | 0.407       |\n",
            "|    reward             | 0.011409098 |\n",
            "|    std                | 3.9         |\n",
            "|    value_loss         | 0.0274      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 443         |\n",
            "|    iterations         | 7300        |\n",
            "|    time_elapsed       | 82          |\n",
            "|    total_timesteps    | 36500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.79       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7299        |\n",
            "|    policy_loss        | -0.00225    |\n",
            "|    reward             | 0.002455936 |\n",
            "|    std                | 3.95        |\n",
            "|    value_loss         | 3.85e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 443          |\n",
            "|    iterations         | 7400         |\n",
            "|    time_elapsed       | 83           |\n",
            "|    total_timesteps    | 37000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.79        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7399         |\n",
            "|    policy_loss        | -0.0169      |\n",
            "|    reward             | -0.011896608 |\n",
            "|    std                | 3.95         |\n",
            "|    value_loss         | 0.000138     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 444          |\n",
            "|    iterations         | 7500         |\n",
            "|    time_elapsed       | 84           |\n",
            "|    total_timesteps    | 37500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.81        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7499         |\n",
            "|    policy_loss        | 0.106        |\n",
            "|    reward             | 0.0032002544 |\n",
            "|    std                | 4.04         |\n",
            "|    value_loss         | 0.00148      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 443           |\n",
            "|    iterations         | 7600          |\n",
            "|    time_elapsed       | 85            |\n",
            "|    total_timesteps    | 38000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.83         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7599          |\n",
            "|    policy_loss        | 0.0296        |\n",
            "|    reward             | -0.0017866265 |\n",
            "|    std                | 4.08          |\n",
            "|    value_loss         | 0.000278      |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 444        |\n",
            "|    iterations         | 7700       |\n",
            "|    time_elapsed       | 86         |\n",
            "|    total_timesteps    | 38500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.85      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7699       |\n",
            "|    policy_loss        | 0.0412     |\n",
            "|    reward             | 0.09940077 |\n",
            "|    std                | 4.18       |\n",
            "|    value_loss         | 0.00762    |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 444          |\n",
            "|    iterations         | 7800         |\n",
            "|    time_elapsed       | 87           |\n",
            "|    total_timesteps    | 39000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.86        |\n",
            "|    explained_variance | 2.38e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7799         |\n",
            "|    policy_loss        | -0.189       |\n",
            "|    reward             | -0.022106275 |\n",
            "|    std                | 4.24         |\n",
            "|    value_loss         | 0.00441      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 444         |\n",
            "|    iterations         | 7900        |\n",
            "|    time_elapsed       | 88          |\n",
            "|    total_timesteps    | 39500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.87       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7899        |\n",
            "|    policy_loss        | 0.0633      |\n",
            "|    reward             | 0.018095922 |\n",
            "|    std                | 4.25        |\n",
            "|    value_loss         | 0.00052     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 444         |\n",
            "|    iterations         | 8000        |\n",
            "|    time_elapsed       | 90          |\n",
            "|    total_timesteps    | 40000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.87       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7999        |\n",
            "|    policy_loss        | -0.0221     |\n",
            "|    reward             | 0.015631625 |\n",
            "|    std                | 4.28        |\n",
            "|    value_loss         | 6.89e-05    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 444        |\n",
            "|    iterations         | 8100       |\n",
            "|    time_elapsed       | 91         |\n",
            "|    total_timesteps    | 40500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.89      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8099       |\n",
            "|    policy_loss        | -0.0602    |\n",
            "|    reward             | 0.17413098 |\n",
            "|    std                | 4.36       |\n",
            "|    value_loss         | 0.00066    |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 444        |\n",
            "|    iterations         | 8200       |\n",
            "|    time_elapsed       | 92         |\n",
            "|    total_timesteps    | 41000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.9       |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8199       |\n",
            "|    policy_loss        | 0.254      |\n",
            "|    reward             | 0.04315921 |\n",
            "|    std                | 4.38       |\n",
            "|    value_loss         | 0.0086     |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 444          |\n",
            "|    iterations         | 8300         |\n",
            "|    time_elapsed       | 93           |\n",
            "|    total_timesteps    | 41500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.9         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8299         |\n",
            "|    policy_loss        | -0.276       |\n",
            "|    reward             | -0.042255014 |\n",
            "|    std                | 4.42         |\n",
            "|    value_loss         | 0.0153       |\n",
            "----------------------------------------\n",
            "day: 2791, episode: 15\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 4879.06\n",
            "total_reward: -5120.94\n",
            "total_cost: 112.97\n",
            "total_trades: 2791\n",
            "Sharpe: 0.296\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 444         |\n",
            "|    iterations         | 8400        |\n",
            "|    time_elapsed       | 94          |\n",
            "|    total_timesteps    | 42000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.91       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8399        |\n",
            "|    policy_loss        | -0.0311     |\n",
            "|    reward             | 0.013807675 |\n",
            "|    std                | 4.45        |\n",
            "|    value_loss         | 0.000184    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 444          |\n",
            "|    iterations         | 8500         |\n",
            "|    time_elapsed       | 95           |\n",
            "|    total_timesteps    | 42500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.92        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8499         |\n",
            "|    policy_loss        | -0.106       |\n",
            "|    reward             | 0.0034366727 |\n",
            "|    std                | 4.49         |\n",
            "|    value_loss         | 0.00179      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 444         |\n",
            "|    iterations         | 8600        |\n",
            "|    time_elapsed       | 96          |\n",
            "|    total_timesteps    | 43000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.94       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8599        |\n",
            "|    policy_loss        | -0.0302     |\n",
            "|    reward             | 0.036967985 |\n",
            "|    std                | 4.6         |\n",
            "|    value_loss         | 0.000147    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 443         |\n",
            "|    iterations         | 8700        |\n",
            "|    time_elapsed       | 98          |\n",
            "|    total_timesteps    | 43500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.95       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8699        |\n",
            "|    policy_loss        | -0.00145    |\n",
            "|    reward             | 0.002834728 |\n",
            "|    std                | 4.62        |\n",
            "|    value_loss         | 9.61e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 443         |\n",
            "|    iterations         | 8800        |\n",
            "|    time_elapsed       | 99          |\n",
            "|    total_timesteps    | 44000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.96       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8799        |\n",
            "|    policy_loss        | -0.186      |\n",
            "|    reward             | 0.008240344 |\n",
            "|    std                | 4.65        |\n",
            "|    value_loss         | 0.00211     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 443         |\n",
            "|    iterations         | 8900        |\n",
            "|    time_elapsed       | 100         |\n",
            "|    total_timesteps    | 44500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.96       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8899        |\n",
            "|    policy_loss        | 0.314       |\n",
            "|    reward             | 0.035592753 |\n",
            "|    std                | 4.66        |\n",
            "|    value_loss         | 0.018       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 443       |\n",
            "|    iterations         | 9000      |\n",
            "|    time_elapsed       | 101       |\n",
            "|    total_timesteps    | 45000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.97     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 8999      |\n",
            "|    policy_loss        | 0.0749    |\n",
            "|    reward             | 0.0118752 |\n",
            "|    std                | 4.74      |\n",
            "|    value_loss         | 0.000812  |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 443          |\n",
            "|    iterations         | 9100         |\n",
            "|    time_elapsed       | 102          |\n",
            "|    total_timesteps    | 45500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.99        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9099         |\n",
            "|    policy_loss        | -0.0467      |\n",
            "|    reward             | -0.009322055 |\n",
            "|    std                | 4.81         |\n",
            "|    value_loss         | 0.000404     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 443          |\n",
            "|    iterations         | 9200         |\n",
            "|    time_elapsed       | 103          |\n",
            "|    total_timesteps    | 46000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.01        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9199         |\n",
            "|    policy_loss        | 0.104        |\n",
            "|    reward             | 0.0006707609 |\n",
            "|    std                | 4.89         |\n",
            "|    value_loss         | 0.00126      |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 443        |\n",
            "|    iterations         | 9300       |\n",
            "|    time_elapsed       | 104        |\n",
            "|    total_timesteps    | 46500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -3.02      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9299       |\n",
            "|    policy_loss        | 0.0382     |\n",
            "|    reward             | 0.03508516 |\n",
            "|    std                | 4.94       |\n",
            "|    value_loss         | 0.00105    |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 444           |\n",
            "|    iterations         | 9400          |\n",
            "|    time_elapsed       | 105           |\n",
            "|    total_timesteps    | 47000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.02         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9399          |\n",
            "|    policy_loss        | 0.176         |\n",
            "|    reward             | -0.0023058183 |\n",
            "|    std                | 4.98          |\n",
            "|    value_loss         | 0.00345       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 443         |\n",
            "|    iterations         | 9500        |\n",
            "|    time_elapsed       | 106         |\n",
            "|    total_timesteps    | 47500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.05       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9499        |\n",
            "|    policy_loss        | 0.0124      |\n",
            "|    reward             | 0.008454157 |\n",
            "|    std                | 5.1         |\n",
            "|    value_loss         | 0.000257    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 444         |\n",
            "|    iterations         | 9600        |\n",
            "|    time_elapsed       | 108         |\n",
            "|    total_timesteps    | 48000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.06       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9599        |\n",
            "|    policy_loss        | 0.15        |\n",
            "|    reward             | 0.019317199 |\n",
            "|    std                | 5.16        |\n",
            "|    value_loss         | 0.00269     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 444         |\n",
            "|    iterations         | 9700        |\n",
            "|    time_elapsed       | 109         |\n",
            "|    total_timesteps    | 48500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.06       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9699        |\n",
            "|    policy_loss        | 0.0171      |\n",
            "|    reward             | 0.015937155 |\n",
            "|    std                | 5.19        |\n",
            "|    value_loss         | 8.43e-05    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 444           |\n",
            "|    iterations         | 9800          |\n",
            "|    time_elapsed       | 110           |\n",
            "|    total_timesteps    | 49000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.08         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9799          |\n",
            "|    policy_loss        | 0.0468        |\n",
            "|    reward             | -0.0029219333 |\n",
            "|    std                | 5.26          |\n",
            "|    value_loss         | 0.000309      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 443          |\n",
            "|    iterations         | 9900         |\n",
            "|    time_elapsed       | 111          |\n",
            "|    total_timesteps    | 49500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.09        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9899         |\n",
            "|    policy_loss        | -0.0365      |\n",
            "|    reward             | -0.020317052 |\n",
            "|    std                | 5.33         |\n",
            "|    value_loss         | 0.000165     |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 444        |\n",
            "|    iterations         | 10000      |\n",
            "|    time_elapsed       | 112        |\n",
            "|    total_timesteps    | 50000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -3.1       |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9999       |\n",
            "|    policy_loss        | -0.254     |\n",
            "|    reward             | 0.08593499 |\n",
            "|    std                | 5.37       |\n",
            "|    value_loss         | 0.00851    |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 444          |\n",
            "|    iterations         | 10100        |\n",
            "|    time_elapsed       | 113          |\n",
            "|    total_timesteps    | 50500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.11        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10099        |\n",
            "|    policy_loss        | 0.0509       |\n",
            "|    reward             | -0.009890822 |\n",
            "|    std                | 5.41         |\n",
            "|    value_loss         | 0.00223      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 444          |\n",
            "|    iterations         | 10200        |\n",
            "|    time_elapsed       | 114          |\n",
            "|    total_timesteps    | 51000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.13        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10199        |\n",
            "|    policy_loss        | -0.0535      |\n",
            "|    reward             | -0.001769075 |\n",
            "|    std                | 5.53         |\n",
            "|    value_loss         | 0.000738     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 444           |\n",
            "|    iterations         | 10300         |\n",
            "|    time_elapsed       | 115           |\n",
            "|    total_timesteps    | 51500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.15         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10299         |\n",
            "|    policy_loss        | 0.108         |\n",
            "|    reward             | -0.0075376746 |\n",
            "|    std                | 5.62          |\n",
            "|    value_loss         | 0.0016        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 444          |\n",
            "|    iterations         | 10400        |\n",
            "|    time_elapsed       | 117          |\n",
            "|    total_timesteps    | 52000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.16        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10399        |\n",
            "|    policy_loss        | 0.11         |\n",
            "|    reward             | 0.0006296371 |\n",
            "|    std                | 5.7          |\n",
            "|    value_loss         | 0.000924     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 444         |\n",
            "|    iterations         | 10500       |\n",
            "|    time_elapsed       | 118         |\n",
            "|    total_timesteps    | 52500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.17       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10499       |\n",
            "|    policy_loss        | -0.0622     |\n",
            "|    reward             | 0.002175551 |\n",
            "|    std                | 5.78        |\n",
            "|    value_loss         | 0.000604    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 444         |\n",
            "|    iterations         | 10600       |\n",
            "|    time_elapsed       | 119         |\n",
            "|    total_timesteps    | 53000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.19       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10599       |\n",
            "|    policy_loss        | 0.269       |\n",
            "|    reward             | 0.009463151 |\n",
            "|    std                | 5.86        |\n",
            "|    value_loss         | 0.0122      |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 443           |\n",
            "|    iterations         | 10700         |\n",
            "|    time_elapsed       | 120           |\n",
            "|    total_timesteps    | 53500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.2          |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10699         |\n",
            "|    policy_loss        | -0.104        |\n",
            "|    reward             | -0.0069920337 |\n",
            "|    std                | 5.95          |\n",
            "|    value_loss         | 0.0011        |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 444         |\n",
            "|    iterations         | 10800       |\n",
            "|    time_elapsed       | 121         |\n",
            "|    total_timesteps    | 54000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.22       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10799       |\n",
            "|    policy_loss        | -0.00848    |\n",
            "|    reward             | -0.08031782 |\n",
            "|    std                | 6.03        |\n",
            "|    value_loss         | 5.51e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 444         |\n",
            "|    iterations         | 10900       |\n",
            "|    time_elapsed       | 122         |\n",
            "|    total_timesteps    | 54500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.23       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10899       |\n",
            "|    policy_loss        | 0.00773     |\n",
            "|    reward             | 0.034537014 |\n",
            "|    std                | 6.11        |\n",
            "|    value_loss         | 6.78e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 444          |\n",
            "|    iterations         | 11000        |\n",
            "|    time_elapsed       | 123          |\n",
            "|    total_timesteps    | 55000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.25        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10999        |\n",
            "|    policy_loss        | -0.056       |\n",
            "|    reward             | -0.011773375 |\n",
            "|    std                | 6.27         |\n",
            "|    value_loss         | 0.000345     |\n",
            "----------------------------------------\n",
            "======A2C Validation from:  2021-05-05 to  2021-06-04\n",
            "A2C Sharpe Ratio:  -0.039901786542565446\n",
            "======Best Model Retraining from:  2010-04-01 to  2021-06-04\n",
            "======Trading from:  2021-06-04 to  2021-07-06\n",
            "[[ 1.3836850e+04  2.6712515e+01 -1.6500000e+02  3.1406549e-01\n",
            "   2.6296463e+01  2.4576630e+01  6.2060204e+01  1.8376817e+02\n",
            "   3.5863396e+01  2.5172453e+01  2.4717949e+01]]\n",
            "============================================\n",
            "turbulence_threshold:  12.04306128869847\n",
            "======Model training from:  2010-04-01 to  2021-06-04\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c\\a2c_147_1\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 432          |\n",
            "|    iterations         | 100          |\n",
            "|    time_elapsed       | 1            |\n",
            "|    total_timesteps    | 500          |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.44        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 99           |\n",
            "|    policy_loss        | -0.0203      |\n",
            "|    reward             | -0.011203767 |\n",
            "|    std                | 1.02         |\n",
            "|    value_loss         | 0.000553     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 432          |\n",
            "|    iterations         | 200          |\n",
            "|    time_elapsed       | 2            |\n",
            "|    total_timesteps    | 1000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.46        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 199          |\n",
            "|    policy_loss        | 0.0136       |\n",
            "|    reward             | 0.0053727203 |\n",
            "|    std                | 1.04         |\n",
            "|    value_loss         | 0.000467     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 438          |\n",
            "|    iterations         | 300          |\n",
            "|    time_elapsed       | 3            |\n",
            "|    total_timesteps    | 1500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.47        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 299          |\n",
            "|    policy_loss        | -0.0106      |\n",
            "|    reward             | -0.029337088 |\n",
            "|    std                | 1.06         |\n",
            "|    value_loss         | 0.000105     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 435           |\n",
            "|    iterations         | 400           |\n",
            "|    time_elapsed       | 4             |\n",
            "|    total_timesteps    | 2000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.49         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 399           |\n",
            "|    policy_loss        | -0.0292       |\n",
            "|    reward             | -0.0035201726 |\n",
            "|    std                | 1.07          |\n",
            "|    value_loss         | 0.00032       |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 437        |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 5          |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.5       |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | 0.00138    |\n",
            "|    reward             | 0.07085142 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 0.00109    |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 436          |\n",
            "|    iterations         | 600          |\n",
            "|    time_elapsed       | 6            |\n",
            "|    total_timesteps    | 3000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.52        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 599          |\n",
            "|    policy_loss        | -0.0176      |\n",
            "|    reward             | 0.0023052231 |\n",
            "|    std                | 1.1          |\n",
            "|    value_loss         | 0.000258     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 437          |\n",
            "|    iterations         | 700          |\n",
            "|    time_elapsed       | 7            |\n",
            "|    total_timesteps    | 3500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.54        |\n",
            "|    explained_variance | 1.79e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 699          |\n",
            "|    policy_loss        | -0.00766     |\n",
            "|    reward             | 0.0040282183 |\n",
            "|    std                | 1.13         |\n",
            "|    value_loss         | 3.82e-05     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 438            |\n",
            "|    iterations         | 800            |\n",
            "|    time_elapsed       | 9              |\n",
            "|    total_timesteps    | 4000           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -1.56          |\n",
            "|    explained_variance | -1.19e-07      |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 799            |\n",
            "|    policy_loss        | 0.0255         |\n",
            "|    reward             | -0.00095609645 |\n",
            "|    std                | 1.16           |\n",
            "|    value_loss         | 0.000254       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 441          |\n",
            "|    iterations         | 900          |\n",
            "|    time_elapsed       | 10           |\n",
            "|    total_timesteps    | 4500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.59        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 899          |\n",
            "|    policy_loss        | 0.000646     |\n",
            "|    reward             | 0.0059331823 |\n",
            "|    std                | 1.19         |\n",
            "|    value_loss         | 2.41e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 438         |\n",
            "|    iterations         | 1000        |\n",
            "|    time_elapsed       | 11          |\n",
            "|    total_timesteps    | 5000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.62       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 999         |\n",
            "|    policy_loss        | -0.0135     |\n",
            "|    reward             | 0.009826706 |\n",
            "|    std                | 1.23        |\n",
            "|    value_loss         | 0.00015     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 439          |\n",
            "|    iterations         | 1100         |\n",
            "|    time_elapsed       | 12           |\n",
            "|    total_timesteps    | 5500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.66        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1099         |\n",
            "|    policy_loss        | -0.0052      |\n",
            "|    reward             | 0.0047259424 |\n",
            "|    std                | 1.27         |\n",
            "|    value_loss         | 4.11e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 438          |\n",
            "|    iterations         | 1200         |\n",
            "|    time_elapsed       | 13           |\n",
            "|    total_timesteps    | 6000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.7         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1199         |\n",
            "|    policy_loss        | 0.0202       |\n",
            "|    reward             | 0.0031250345 |\n",
            "|    std                | 1.32         |\n",
            "|    value_loss         | 0.000207     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 442          |\n",
            "|    iterations         | 1300         |\n",
            "|    time_elapsed       | 14           |\n",
            "|    total_timesteps    | 6500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.72        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1299         |\n",
            "|    policy_loss        | 0.01         |\n",
            "|    reward             | 0.0076256655 |\n",
            "|    std                | 1.35         |\n",
            "|    value_loss         | 2.33e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 445          |\n",
            "|    iterations         | 1400         |\n",
            "|    time_elapsed       | 15           |\n",
            "|    total_timesteps    | 7000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.75        |\n",
            "|    explained_variance | -2.38e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1399         |\n",
            "|    policy_loss        | -0.00599     |\n",
            "|    reward             | -0.002020142 |\n",
            "|    std                | 1.39         |\n",
            "|    value_loss         | 3.55e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 447           |\n",
            "|    iterations         | 1500          |\n",
            "|    time_elapsed       | 16            |\n",
            "|    total_timesteps    | 7500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.78         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1499          |\n",
            "|    policy_loss        | -0.011        |\n",
            "|    reward             | -0.0053895763 |\n",
            "|    std                | 1.44          |\n",
            "|    value_loss         | 3.14e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 448           |\n",
            "|    iterations         | 1600          |\n",
            "|    time_elapsed       | 17            |\n",
            "|    total_timesteps    | 8000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.81         |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1599          |\n",
            "|    policy_loss        | -0.00854      |\n",
            "|    reward             | -0.0044352105 |\n",
            "|    std                | 1.48          |\n",
            "|    value_loss         | 3.02e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 448         |\n",
            "|    iterations         | 1700        |\n",
            "|    time_elapsed       | 18          |\n",
            "|    total_timesteps    | 8500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.85       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1699        |\n",
            "|    policy_loss        | 0.0147      |\n",
            "|    reward             | 0.014587279 |\n",
            "|    std                | 1.54        |\n",
            "|    value_loss         | 9.71e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 449         |\n",
            "|    iterations         | 1800        |\n",
            "|    time_elapsed       | 20          |\n",
            "|    total_timesteps    | 9000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.88       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1799        |\n",
            "|    policy_loss        | 0.00478     |\n",
            "|    reward             | 0.018410867 |\n",
            "|    std                | 1.59        |\n",
            "|    value_loss         | 2.28e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 448         |\n",
            "|    iterations         | 1900        |\n",
            "|    time_elapsed       | 21          |\n",
            "|    total_timesteps    | 9500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.91       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1899        |\n",
            "|    policy_loss        | 0.00979     |\n",
            "|    reward             | 0.026946394 |\n",
            "|    std                | 1.64        |\n",
            "|    value_loss         | 2.63e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 448          |\n",
            "|    iterations         | 2000         |\n",
            "|    time_elapsed       | 22           |\n",
            "|    total_timesteps    | 10000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.95        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1999         |\n",
            "|    policy_loss        | -0.0104      |\n",
            "|    reward             | 0.0034469778 |\n",
            "|    std                | 1.7          |\n",
            "|    value_loss         | 3.87e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 449          |\n",
            "|    iterations         | 2100         |\n",
            "|    time_elapsed       | 23           |\n",
            "|    total_timesteps    | 10500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.97        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2099         |\n",
            "|    policy_loss        | 0.0172       |\n",
            "|    reward             | -0.036053132 |\n",
            "|    std                | 1.73         |\n",
            "|    value_loss         | 0.000154     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 449          |\n",
            "|    iterations         | 2200         |\n",
            "|    time_elapsed       | 24           |\n",
            "|    total_timesteps    | 11000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.99        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2199         |\n",
            "|    policy_loss        | -0.0567      |\n",
            "|    reward             | -0.017492719 |\n",
            "|    std                | 1.77         |\n",
            "|    value_loss         | 0.00157      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 449           |\n",
            "|    iterations         | 2300          |\n",
            "|    time_elapsed       | 25            |\n",
            "|    total_timesteps    | 11500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.01         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2299          |\n",
            "|    policy_loss        | 0.122         |\n",
            "|    reward             | -0.0019323871 |\n",
            "|    std                | 1.8           |\n",
            "|    value_loss         | 0.00315       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 450         |\n",
            "|    iterations         | 2400        |\n",
            "|    time_elapsed       | 26          |\n",
            "|    total_timesteps    | 12000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.02       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2399        |\n",
            "|    policy_loss        | 0.0436      |\n",
            "|    reward             | 0.008904302 |\n",
            "|    std                | 1.82        |\n",
            "|    value_loss         | 0.000706    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 449          |\n",
            "|    iterations         | 2500         |\n",
            "|    time_elapsed       | 27           |\n",
            "|    total_timesteps    | 12500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.04        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2499         |\n",
            "|    policy_loss        | 0.00826      |\n",
            "|    reward             | -0.023055125 |\n",
            "|    std                | 1.87         |\n",
            "|    value_loss         | 0.000558     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 450         |\n",
            "|    iterations         | 2600        |\n",
            "|    time_elapsed       | 28          |\n",
            "|    total_timesteps    | 13000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.05       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2599        |\n",
            "|    policy_loss        | 0.0383      |\n",
            "|    reward             | 0.004842878 |\n",
            "|    std                | 1.89        |\n",
            "|    value_loss         | 0.000619    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 451        |\n",
            "|    iterations         | 2700       |\n",
            "|    time_elapsed       | 29         |\n",
            "|    total_timesteps    | 13500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.06      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2699       |\n",
            "|    policy_loss        | 0.0901     |\n",
            "|    reward             | 0.04134301 |\n",
            "|    std                | 1.9        |\n",
            "|    value_loss         | 0.00313    |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 451          |\n",
            "|    iterations         | 2800         |\n",
            "|    time_elapsed       | 31           |\n",
            "|    total_timesteps    | 14000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.07        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2799         |\n",
            "|    policy_loss        | 0.08         |\n",
            "|    reward             | -0.014575783 |\n",
            "|    std                | 1.91         |\n",
            "|    value_loss         | 0.00399      |\n",
            "----------------------------------------\n",
            "day: 2812, episode: 5\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 192.53\n",
            "total_reward: -9807.47\n",
            "total_cost: 120.01\n",
            "total_trades: 2812\n",
            "Sharpe: 0.284\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 451          |\n",
            "|    iterations         | 2900         |\n",
            "|    time_elapsed       | 32           |\n",
            "|    total_timesteps    | 14500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.08        |\n",
            "|    explained_variance | 1.79e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2899         |\n",
            "|    policy_loss        | 0.117        |\n",
            "|    reward             | -0.065816306 |\n",
            "|    std                | 1.94         |\n",
            "|    value_loss         | 0.00628      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 452         |\n",
            "|    iterations         | 3000        |\n",
            "|    time_elapsed       | 33          |\n",
            "|    total_timesteps    | 15000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.1        |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2999        |\n",
            "|    policy_loss        | -0.0445     |\n",
            "|    reward             | 0.005954077 |\n",
            "|    std                | 1.97        |\n",
            "|    value_loss         | 0.00209     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 452         |\n",
            "|    iterations         | 3100        |\n",
            "|    time_elapsed       | 34          |\n",
            "|    total_timesteps    | 15500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.11       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3099        |\n",
            "|    policy_loss        | 0.0633      |\n",
            "|    reward             | 0.026653975 |\n",
            "|    std                | 1.99        |\n",
            "|    value_loss         | 0.00324     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 453         |\n",
            "|    iterations         | 3200        |\n",
            "|    time_elapsed       | 35          |\n",
            "|    total_timesteps    | 16000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.12       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3199        |\n",
            "|    policy_loss        | -0.801      |\n",
            "|    reward             | -0.05186407 |\n",
            "|    std                | 2.01        |\n",
            "|    value_loss         | 0.107       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 453         |\n",
            "|    iterations         | 3300        |\n",
            "|    time_elapsed       | 36          |\n",
            "|    total_timesteps    | 16500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.13       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3299        |\n",
            "|    policy_loss        | -0.0264     |\n",
            "|    reward             | 0.053550065 |\n",
            "|    std                | 2.03        |\n",
            "|    value_loss         | 0.00501     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 453           |\n",
            "|    iterations         | 3400          |\n",
            "|    time_elapsed       | 37            |\n",
            "|    total_timesteps    | 17000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.13         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3399          |\n",
            "|    policy_loss        | -0.00966      |\n",
            "|    reward             | -0.0060861167 |\n",
            "|    std                | 2.05          |\n",
            "|    value_loss         | 5.55e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 454         |\n",
            "|    iterations         | 3500        |\n",
            "|    time_elapsed       | 38          |\n",
            "|    total_timesteps    | 17500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.15       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3499        |\n",
            "|    policy_loss        | -0.0526     |\n",
            "|    reward             | 0.019961413 |\n",
            "|    std                | 2.07        |\n",
            "|    value_loss         | 0.00101     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 454         |\n",
            "|    iterations         | 3600        |\n",
            "|    time_elapsed       | 39          |\n",
            "|    total_timesteps    | 18000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.15       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3599        |\n",
            "|    policy_loss        | -0.00975    |\n",
            "|    reward             | 0.017896887 |\n",
            "|    std                | 2.08        |\n",
            "|    value_loss         | 0.000137    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 454         |\n",
            "|    iterations         | 3700        |\n",
            "|    time_elapsed       | 40          |\n",
            "|    total_timesteps    | 18500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.15       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3699        |\n",
            "|    policy_loss        | -0.037      |\n",
            "|    reward             | 0.037542004 |\n",
            "|    std                | 2.08        |\n",
            "|    value_loss         | 0.000324    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 454        |\n",
            "|    iterations         | 3800       |\n",
            "|    time_elapsed       | 41         |\n",
            "|    total_timesteps    | 19000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.16      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3799       |\n",
            "|    policy_loss        | -0.154     |\n",
            "|    reward             | 0.06210887 |\n",
            "|    std                | 2.09       |\n",
            "|    value_loss         | 0.00553    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 453         |\n",
            "|    iterations         | 3900        |\n",
            "|    time_elapsed       | 42          |\n",
            "|    total_timesteps    | 19500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.18       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3899        |\n",
            "|    policy_loss        | 0.0278      |\n",
            "|    reward             | -0.22369736 |\n",
            "|    std                | 2.13        |\n",
            "|    value_loss         | 0.00262     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 453         |\n",
            "|    iterations         | 4000        |\n",
            "|    time_elapsed       | 44          |\n",
            "|    total_timesteps    | 20000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.18       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3999        |\n",
            "|    policy_loss        | 0.101       |\n",
            "|    reward             | 0.020476017 |\n",
            "|    std                | 2.15        |\n",
            "|    value_loss         | 0.00266     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 454           |\n",
            "|    iterations         | 4100          |\n",
            "|    time_elapsed       | 45            |\n",
            "|    total_timesteps    | 20500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.19         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4099          |\n",
            "|    policy_loss        | 0.032         |\n",
            "|    reward             | -3.127425e-06 |\n",
            "|    std                | 2.16          |\n",
            "|    value_loss         | 0.00059       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 454         |\n",
            "|    iterations         | 4200        |\n",
            "|    time_elapsed       | 46          |\n",
            "|    total_timesteps    | 21000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.2        |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4199        |\n",
            "|    policy_loss        | 0.0152      |\n",
            "|    reward             | 0.016087117 |\n",
            "|    std                | 2.18        |\n",
            "|    value_loss         | 0.000135    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 455          |\n",
            "|    iterations         | 4300         |\n",
            "|    time_elapsed       | 47           |\n",
            "|    total_timesteps    | 21500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.2         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4299         |\n",
            "|    policy_loss        | -0.183       |\n",
            "|    reward             | -0.029874763 |\n",
            "|    std                | 2.19         |\n",
            "|    value_loss         | 0.00555      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 454         |\n",
            "|    iterations         | 4400        |\n",
            "|    time_elapsed       | 48          |\n",
            "|    total_timesteps    | 22000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.22       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4399        |\n",
            "|    policy_loss        | 0.11        |\n",
            "|    reward             | -0.07915658 |\n",
            "|    std                | 2.22        |\n",
            "|    value_loss         | 0.00706     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 455         |\n",
            "|    iterations         | 4500        |\n",
            "|    time_elapsed       | 49          |\n",
            "|    total_timesteps    | 22500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.24       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4499        |\n",
            "|    policy_loss        | -0.0828     |\n",
            "|    reward             | 0.008528259 |\n",
            "|    std                | 2.27        |\n",
            "|    value_loss         | 0.00357     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 455         |\n",
            "|    iterations         | 4600        |\n",
            "|    time_elapsed       | 50          |\n",
            "|    total_timesteps    | 23000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.24       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4599        |\n",
            "|    policy_loss        | -0.00551    |\n",
            "|    reward             | 0.020215306 |\n",
            "|    std                | 2.28        |\n",
            "|    value_loss         | 4.73e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 455          |\n",
            "|    iterations         | 4700         |\n",
            "|    time_elapsed       | 51           |\n",
            "|    total_timesteps    | 23500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.26        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4699         |\n",
            "|    policy_loss        | 0.151        |\n",
            "|    reward             | -0.036103744 |\n",
            "|    std                | 2.31         |\n",
            "|    value_loss         | 0.00418      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 455         |\n",
            "|    iterations         | 4800        |\n",
            "|    time_elapsed       | 52          |\n",
            "|    total_timesteps    | 24000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.27       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4799        |\n",
            "|    policy_loss        | -0.0887     |\n",
            "|    reward             | -0.08403978 |\n",
            "|    std                | 2.33        |\n",
            "|    value_loss         | 0.00185     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 455         |\n",
            "|    iterations         | 4900        |\n",
            "|    time_elapsed       | 53          |\n",
            "|    total_timesteps    | 24500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.28       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4899        |\n",
            "|    policy_loss        | 0.0667      |\n",
            "|    reward             | 0.008918011 |\n",
            "|    std                | 2.37        |\n",
            "|    value_loss         | 0.00116     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 456          |\n",
            "|    iterations         | 5000         |\n",
            "|    time_elapsed       | 54           |\n",
            "|    total_timesteps    | 25000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.3         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4999         |\n",
            "|    policy_loss        | 0.523        |\n",
            "|    reward             | 0.0147345755 |\n",
            "|    std                | 2.4          |\n",
            "|    value_loss         | 0.0452       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 456          |\n",
            "|    iterations         | 5100         |\n",
            "|    time_elapsed       | 55           |\n",
            "|    total_timesteps    | 25500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.29        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5099         |\n",
            "|    policy_loss        | -0.00699     |\n",
            "|    reward             | -0.012878711 |\n",
            "|    std                | 2.39         |\n",
            "|    value_loss         | 0.000205     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 456          |\n",
            "|    iterations         | 5200         |\n",
            "|    time_elapsed       | 56           |\n",
            "|    total_timesteps    | 26000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.3         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5199         |\n",
            "|    policy_loss        | -0.191       |\n",
            "|    reward             | -0.008203956 |\n",
            "|    std                | 2.4          |\n",
            "|    value_loss         | 0.00205      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 455          |\n",
            "|    iterations         | 5300         |\n",
            "|    time_elapsed       | 58           |\n",
            "|    total_timesteps    | 26500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.31        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5299         |\n",
            "|    policy_loss        | -0.0365      |\n",
            "|    reward             | 0.0037079274 |\n",
            "|    std                | 2.45         |\n",
            "|    value_loss         | 0.000549     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 456            |\n",
            "|    iterations         | 5400           |\n",
            "|    time_elapsed       | 59             |\n",
            "|    total_timesteps    | 27000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -2.33          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 5399           |\n",
            "|    policy_loss        | -0.0742        |\n",
            "|    reward             | -4.5833444e-06 |\n",
            "|    std                | 2.48           |\n",
            "|    value_loss         | 0.000738       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 456          |\n",
            "|    iterations         | 5500         |\n",
            "|    time_elapsed       | 60           |\n",
            "|    total_timesteps    | 27500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.33        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5499         |\n",
            "|    policy_loss        | 0.106        |\n",
            "|    reward             | -0.011455834 |\n",
            "|    std                | 2.49         |\n",
            "|    value_loss         | 0.00431      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 456         |\n",
            "|    iterations         | 5600        |\n",
            "|    time_elapsed       | 61          |\n",
            "|    total_timesteps    | 28000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.34       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5599        |\n",
            "|    policy_loss        | 0.00131     |\n",
            "|    reward             | 0.029653933 |\n",
            "|    std                | 2.51        |\n",
            "|    value_loss         | 0.00229     |\n",
            "---------------------------------------\n",
            "day: 2812, episode: 10\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 4259.11\n",
            "total_reward: -5740.89\n",
            "total_cost: 110.19\n",
            "total_trades: 2812\n",
            "Sharpe: 0.208\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 456         |\n",
            "|    iterations         | 5700        |\n",
            "|    time_elapsed       | 62          |\n",
            "|    total_timesteps    | 28500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.36       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5699        |\n",
            "|    policy_loss        | -0.0861     |\n",
            "|    reward             | 0.010745992 |\n",
            "|    std                | 2.55        |\n",
            "|    value_loss         | 0.00251     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 455          |\n",
            "|    iterations         | 5800         |\n",
            "|    time_elapsed       | 63           |\n",
            "|    total_timesteps    | 29000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.37        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5799         |\n",
            "|    policy_loss        | -0.0952      |\n",
            "|    reward             | -0.002403446 |\n",
            "|    std                | 2.6          |\n",
            "|    value_loss         | 0.00413      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 455          |\n",
            "|    iterations         | 5900         |\n",
            "|    time_elapsed       | 64           |\n",
            "|    total_timesteps    | 29500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.38        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5899         |\n",
            "|    policy_loss        | 0.051        |\n",
            "|    reward             | -0.032108676 |\n",
            "|    std                | 2.62         |\n",
            "|    value_loss         | 0.0016       |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 456        |\n",
            "|    iterations         | 6000       |\n",
            "|    time_elapsed       | 65         |\n",
            "|    total_timesteps    | 30000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.4       |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5999       |\n",
            "|    policy_loss        | -0.0314    |\n",
            "|    reward             | 0.05771783 |\n",
            "|    std                | 2.66       |\n",
            "|    value_loss         | 0.000558   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 456         |\n",
            "|    iterations         | 6100        |\n",
            "|    time_elapsed       | 66          |\n",
            "|    total_timesteps    | 30500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.41       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6099        |\n",
            "|    policy_loss        | 0.227       |\n",
            "|    reward             | 0.001352937 |\n",
            "|    std                | 2.69        |\n",
            "|    value_loss         | 0.0119      |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 455           |\n",
            "|    iterations         | 6200          |\n",
            "|    time_elapsed       | 67            |\n",
            "|    total_timesteps    | 31000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.41         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6199          |\n",
            "|    policy_loss        | -0.0118       |\n",
            "|    reward             | -1.996942e-06 |\n",
            "|    std                | 2.68          |\n",
            "|    value_loss         | 0.000186      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 456          |\n",
            "|    iterations         | 6300         |\n",
            "|    time_elapsed       | 69           |\n",
            "|    total_timesteps    | 31500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.42        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6299         |\n",
            "|    policy_loss        | -0.0139      |\n",
            "|    reward             | -0.011715388 |\n",
            "|    std                | 2.72         |\n",
            "|    value_loss         | 0.00028      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 456          |\n",
            "|    iterations         | 6400         |\n",
            "|    time_elapsed       | 70           |\n",
            "|    total_timesteps    | 32000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.44        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6399         |\n",
            "|    policy_loss        | -0.0452      |\n",
            "|    reward             | 0.0028176184 |\n",
            "|    std                | 2.77         |\n",
            "|    value_loss         | 0.000389     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 456          |\n",
            "|    iterations         | 6500         |\n",
            "|    time_elapsed       | 71           |\n",
            "|    total_timesteps    | 32500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.47        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6499         |\n",
            "|    policy_loss        | -0.0557      |\n",
            "|    reward             | -0.009669311 |\n",
            "|    std                | 2.85         |\n",
            "|    value_loss         | 0.000694     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 456          |\n",
            "|    iterations         | 6600         |\n",
            "|    time_elapsed       | 72           |\n",
            "|    total_timesteps    | 33000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.48        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6599         |\n",
            "|    policy_loss        | -0.0497      |\n",
            "|    reward             | -0.019893723 |\n",
            "|    std                | 2.88         |\n",
            "|    value_loss         | 0.00115      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 457         |\n",
            "|    iterations         | 6700        |\n",
            "|    time_elapsed       | 73          |\n",
            "|    total_timesteps    | 33500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.48       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6699        |\n",
            "|    policy_loss        | -0.0279     |\n",
            "|    reward             | -0.11766248 |\n",
            "|    std                | 2.89        |\n",
            "|    value_loss         | 0.00217     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 458          |\n",
            "|    iterations         | 6800         |\n",
            "|    time_elapsed       | 74           |\n",
            "|    total_timesteps    | 34000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.49        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6799         |\n",
            "|    policy_loss        | 0.0246       |\n",
            "|    reward             | -0.006094737 |\n",
            "|    std                | 2.93         |\n",
            "|    value_loss         | 0.000812     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 458           |\n",
            "|    iterations         | 6900          |\n",
            "|    time_elapsed       | 75            |\n",
            "|    total_timesteps    | 34500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.52         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6899          |\n",
            "|    policy_loss        | -0.0431       |\n",
            "|    reward             | -0.0018344742 |\n",
            "|    std                | 3             |\n",
            "|    value_loss         | 0.000765      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 458          |\n",
            "|    iterations         | 7000         |\n",
            "|    time_elapsed       | 76           |\n",
            "|    total_timesteps    | 35000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.53        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6999         |\n",
            "|    policy_loss        | 0.111        |\n",
            "|    reward             | -0.009114382 |\n",
            "|    std                | 3.03         |\n",
            "|    value_loss         | 0.00233      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 458          |\n",
            "|    iterations         | 7100         |\n",
            "|    time_elapsed       | 77           |\n",
            "|    total_timesteps    | 35500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.55        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7099         |\n",
            "|    policy_loss        | 0.078        |\n",
            "|    reward             | 0.0007867935 |\n",
            "|    std                | 3.09         |\n",
            "|    value_loss         | 0.00137      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 458          |\n",
            "|    iterations         | 7200         |\n",
            "|    time_elapsed       | 78           |\n",
            "|    total_timesteps    | 36000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.57        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7199         |\n",
            "|    policy_loss        | -0.0744      |\n",
            "|    reward             | 0.0029437211 |\n",
            "|    std                | 3.15         |\n",
            "|    value_loss         | 0.00104      |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 458        |\n",
            "|    iterations         | 7300       |\n",
            "|    time_elapsed       | 79         |\n",
            "|    total_timesteps    | 36500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.57      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7299       |\n",
            "|    policy_loss        | 0.325      |\n",
            "|    reward             | 0.01308064 |\n",
            "|    std                | 3.17       |\n",
            "|    value_loss         | 0.0224     |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 458          |\n",
            "|    iterations         | 7400         |\n",
            "|    time_elapsed       | 80           |\n",
            "|    total_timesteps    | 37000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.58        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7399         |\n",
            "|    policy_loss        | 0.143        |\n",
            "|    reward             | 0.0047712955 |\n",
            "|    std                | 3.19         |\n",
            "|    value_loss         | 0.00394      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 458         |\n",
            "|    iterations         | 7500        |\n",
            "|    time_elapsed       | 81          |\n",
            "|    total_timesteps    | 37500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.59       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7499        |\n",
            "|    policy_loss        | -0.0726     |\n",
            "|    reward             | 0.014276333 |\n",
            "|    std                | 3.22        |\n",
            "|    value_loss         | 0.00085     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 458           |\n",
            "|    iterations         | 7600          |\n",
            "|    time_elapsed       | 82            |\n",
            "|    total_timesteps    | 38000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.6          |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7599          |\n",
            "|    policy_loss        | 0.0612        |\n",
            "|    reward             | -0.0020990407 |\n",
            "|    std                | 3.25          |\n",
            "|    value_loss         | 0.000634      |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 458        |\n",
            "|    iterations         | 7700       |\n",
            "|    time_elapsed       | 83         |\n",
            "|    total_timesteps    | 38500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.61      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7699       |\n",
            "|    policy_loss        | -0.104     |\n",
            "|    reward             | 0.16113238 |\n",
            "|    std                | 3.29       |\n",
            "|    value_loss         | 0.00351    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 458         |\n",
            "|    iterations         | 7800        |\n",
            "|    time_elapsed       | 85          |\n",
            "|    total_timesteps    | 39000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.62       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7799        |\n",
            "|    policy_loss        | -0.152      |\n",
            "|    reward             | 0.024935432 |\n",
            "|    std                | 3.34        |\n",
            "|    value_loss         | 0.00595     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 458           |\n",
            "|    iterations         | 7900          |\n",
            "|    time_elapsed       | 86            |\n",
            "|    total_timesteps    | 39500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.64         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7899          |\n",
            "|    policy_loss        | -0.0174       |\n",
            "|    reward             | -0.0058020167 |\n",
            "|    std                | 3.38          |\n",
            "|    value_loss         | 7.86e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 458          |\n",
            "|    iterations         | 8000         |\n",
            "|    time_elapsed       | 87           |\n",
            "|    total_timesteps    | 40000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.65        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7999         |\n",
            "|    policy_loss        | 0.0223       |\n",
            "|    reward             | -0.024347844 |\n",
            "|    std                | 3.42         |\n",
            "|    value_loss         | 0.000221     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 458         |\n",
            "|    iterations         | 8100        |\n",
            "|    time_elapsed       | 88          |\n",
            "|    total_timesteps    | 40500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.67       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8099        |\n",
            "|    policy_loss        | 0.0123      |\n",
            "|    reward             | -0.01738722 |\n",
            "|    std                | 3.49        |\n",
            "|    value_loss         | 4.68e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 458          |\n",
            "|    iterations         | 8200         |\n",
            "|    time_elapsed       | 89           |\n",
            "|    total_timesteps    | 41000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.68        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8199         |\n",
            "|    policy_loss        | 0.0215       |\n",
            "|    reward             | -0.005521013 |\n",
            "|    std                | 3.53         |\n",
            "|    value_loss         | 7.03e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 459          |\n",
            "|    iterations         | 8300         |\n",
            "|    time_elapsed       | 90           |\n",
            "|    total_timesteps    | 41500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.72        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8299         |\n",
            "|    policy_loss        | -0.109       |\n",
            "|    reward             | 0.0059544826 |\n",
            "|    std                | 3.66         |\n",
            "|    value_loss         | 0.00299      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 459           |\n",
            "|    iterations         | 8400          |\n",
            "|    time_elapsed       | 91            |\n",
            "|    total_timesteps    | 42000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.74         |\n",
            "|    explained_variance | -2.38e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8399          |\n",
            "|    policy_loss        | 0.19          |\n",
            "|    reward             | -4.430804e-06 |\n",
            "|    std                | 3.75          |\n",
            "|    value_loss         | 0.00677       |\n",
            "-----------------------------------------\n",
            "day: 2812, episode: 15\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 6621.09\n",
            "total_reward: -3378.91\n",
            "total_cost: 105.16\n",
            "total_trades: 2812\n",
            "Sharpe: 0.110\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 459          |\n",
            "|    iterations         | 8500         |\n",
            "|    time_elapsed       | 92           |\n",
            "|    total_timesteps    | 42500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.76        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8499         |\n",
            "|    policy_loss        | 0.0144       |\n",
            "|    reward             | -0.001964147 |\n",
            "|    std                | 3.83         |\n",
            "|    value_loss         | 0.000162     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 459         |\n",
            "|    iterations         | 8600        |\n",
            "|    time_elapsed       | 93          |\n",
            "|    total_timesteps    | 43000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.78       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8599        |\n",
            "|    policy_loss        | -0.0446     |\n",
            "|    reward             | -0.02481972 |\n",
            "|    std                | 3.88        |\n",
            "|    value_loss         | 0.000471    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 459          |\n",
            "|    iterations         | 8700         |\n",
            "|    time_elapsed       | 94           |\n",
            "|    total_timesteps    | 43500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.8         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8699         |\n",
            "|    policy_loss        | 0.0188       |\n",
            "|    reward             | -0.008506416 |\n",
            "|    std                | 3.99         |\n",
            "|    value_loss         | 0.000285     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 459         |\n",
            "|    iterations         | 8800        |\n",
            "|    time_elapsed       | 95          |\n",
            "|    total_timesteps    | 44000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.83       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8799        |\n",
            "|    policy_loss        | 0.013       |\n",
            "|    reward             | 0.002312644 |\n",
            "|    std                | 4.08        |\n",
            "|    value_loss         | 6.26e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 459          |\n",
            "|    iterations         | 8900         |\n",
            "|    time_elapsed       | 96           |\n",
            "|    total_timesteps    | 44500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.84        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8899         |\n",
            "|    policy_loss        | -0.0365      |\n",
            "|    reward             | -0.015498978 |\n",
            "|    std                | 4.13         |\n",
            "|    value_loss         | 0.000558     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 459         |\n",
            "|    iterations         | 9000        |\n",
            "|    time_elapsed       | 97          |\n",
            "|    total_timesteps    | 45000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.85       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8999        |\n",
            "|    policy_loss        | 0.0142      |\n",
            "|    reward             | -0.00886663 |\n",
            "|    std                | 4.2         |\n",
            "|    value_loss         | 0.00118     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 459         |\n",
            "|    iterations         | 9100        |\n",
            "|    time_elapsed       | 98          |\n",
            "|    total_timesteps    | 45500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.86       |\n",
            "|    explained_variance | -2.38e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9099        |\n",
            "|    policy_loss        | 0.0533      |\n",
            "|    reward             | 0.034469813 |\n",
            "|    std                | 4.24        |\n",
            "|    value_loss         | 0.00135     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 459          |\n",
            "|    iterations         | 9200         |\n",
            "|    time_elapsed       | 100          |\n",
            "|    total_timesteps    | 46000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.88        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9199         |\n",
            "|    policy_loss        | 0.0687       |\n",
            "|    reward             | -0.005639048 |\n",
            "|    std                | 4.32         |\n",
            "|    value_loss         | 0.000928     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 459          |\n",
            "|    iterations         | 9300         |\n",
            "|    time_elapsed       | 101          |\n",
            "|    total_timesteps    | 46500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.9         |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9299         |\n",
            "|    policy_loss        | 0.000742     |\n",
            "|    reward             | 0.0046348167 |\n",
            "|    std                | 4.41         |\n",
            "|    value_loss         | 0.000103     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 459         |\n",
            "|    iterations         | 9400        |\n",
            "|    time_elapsed       | 102         |\n",
            "|    total_timesteps    | 47000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.92       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9399        |\n",
            "|    policy_loss        | 0.0696      |\n",
            "|    reward             | 0.042743593 |\n",
            "|    std                | 4.47        |\n",
            "|    value_loss         | 0.00149     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 459        |\n",
            "|    iterations         | 9500       |\n",
            "|    time_elapsed       | 103        |\n",
            "|    total_timesteps    | 47500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.94      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9499       |\n",
            "|    policy_loss        | 0.158      |\n",
            "|    reward             | 0.02632454 |\n",
            "|    std                | 4.58       |\n",
            "|    value_loss         | 0.00248    |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 459           |\n",
            "|    iterations         | 9600          |\n",
            "|    time_elapsed       | 104           |\n",
            "|    total_timesteps    | 48000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.95         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9599          |\n",
            "|    policy_loss        | -0.0339       |\n",
            "|    reward             | -0.0067264587 |\n",
            "|    std                | 4.65          |\n",
            "|    value_loss         | 0.000418      |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 459        |\n",
            "|    iterations         | 9700       |\n",
            "|    time_elapsed       | 105        |\n",
            "|    total_timesteps    | 48500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.97      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9699       |\n",
            "|    policy_loss        | -0.0343    |\n",
            "|    reward             | 0.00450146 |\n",
            "|    std                | 4.69       |\n",
            "|    value_loss         | 0.000323   |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 458           |\n",
            "|    iterations         | 9800          |\n",
            "|    time_elapsed       | 106           |\n",
            "|    total_timesteps    | 49000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.98         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9799          |\n",
            "|    policy_loss        | -0.0536       |\n",
            "|    reward             | -0.0048424834 |\n",
            "|    std                | 4.78          |\n",
            "|    value_loss         | 0.000449      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 458         |\n",
            "|    iterations         | 9900        |\n",
            "|    time_elapsed       | 107         |\n",
            "|    total_timesteps    | 49500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.99       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9899        |\n",
            "|    policy_loss        | -0.0114     |\n",
            "|    reward             | -0.04779622 |\n",
            "|    std                | 4.82        |\n",
            "|    value_loss         | 4.65e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 458          |\n",
            "|    iterations         | 10000        |\n",
            "|    time_elapsed       | 109          |\n",
            "|    total_timesteps    | 50000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3           |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9999         |\n",
            "|    policy_loss        | -0.0468      |\n",
            "|    reward             | -0.011735074 |\n",
            "|    std                | 4.86         |\n",
            "|    value_loss         | 0.000743     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 458          |\n",
            "|    iterations         | 10100        |\n",
            "|    time_elapsed       | 110          |\n",
            "|    total_timesteps    | 50500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.01        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10099        |\n",
            "|    policy_loss        | -0.0432      |\n",
            "|    reward             | -0.008157274 |\n",
            "|    std                | 4.89         |\n",
            "|    value_loss         | 0.00175      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 458          |\n",
            "|    iterations         | 10200        |\n",
            "|    time_elapsed       | 111          |\n",
            "|    total_timesteps    | 51000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.01        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10199        |\n",
            "|    policy_loss        | 0.046        |\n",
            "|    reward             | 0.0046082255 |\n",
            "|    std                | 4.92         |\n",
            "|    value_loss         | 0.000394     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 458          |\n",
            "|    iterations         | 10300        |\n",
            "|    time_elapsed       | 112          |\n",
            "|    total_timesteps    | 51500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.03        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10299        |\n",
            "|    policy_loss        | -0.0374      |\n",
            "|    reward             | -0.007897735 |\n",
            "|    std                | 4.99         |\n",
            "|    value_loss         | 0.000193     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 458         |\n",
            "|    iterations         | 10400       |\n",
            "|    time_elapsed       | 113         |\n",
            "|    total_timesteps    | 52000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.05       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10399       |\n",
            "|    policy_loss        | 0.000729    |\n",
            "|    reward             | 0.001389617 |\n",
            "|    std                | 5.1         |\n",
            "|    value_loss         | 0.000969    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 458          |\n",
            "|    iterations         | 10500        |\n",
            "|    time_elapsed       | 114          |\n",
            "|    total_timesteps    | 52500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.08        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10499        |\n",
            "|    policy_loss        | -0.0258      |\n",
            "|    reward             | 0.0042049037 |\n",
            "|    std                | 5.26         |\n",
            "|    value_loss         | 0.000187     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 458           |\n",
            "|    iterations         | 10600         |\n",
            "|    time_elapsed       | 115           |\n",
            "|    total_timesteps    | 53000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.09         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10599         |\n",
            "|    policy_loss        | 0.0354        |\n",
            "|    reward             | -0.0031778938 |\n",
            "|    std                | 5.33          |\n",
            "|    value_loss         | 0.00163       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 458           |\n",
            "|    iterations         | 10700         |\n",
            "|    time_elapsed       | 116           |\n",
            "|    total_timesteps    | 53500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.11         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10699         |\n",
            "|    policy_loss        | 0.00465       |\n",
            "|    reward             | -0.0018318888 |\n",
            "|    std                | 5.43          |\n",
            "|    value_loss         | 9.41e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 457         |\n",
            "|    iterations         | 10800       |\n",
            "|    time_elapsed       | 117         |\n",
            "|    total_timesteps    | 54000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.12       |\n",
            "|    explained_variance | -2.38e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10799       |\n",
            "|    policy_loss        | 0.0255      |\n",
            "|    reward             | 0.012814255 |\n",
            "|    std                | 5.49        |\n",
            "|    value_loss         | 8.68e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 457         |\n",
            "|    iterations         | 10900       |\n",
            "|    time_elapsed       | 119         |\n",
            "|    total_timesteps    | 54500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.14       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10899       |\n",
            "|    policy_loss        | 0.061       |\n",
            "|    reward             | 0.006175768 |\n",
            "|    std                | 5.61        |\n",
            "|    value_loss         | 0.000625    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 457          |\n",
            "|    iterations         | 11000        |\n",
            "|    time_elapsed       | 120          |\n",
            "|    total_timesteps    | 55000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.15        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10999        |\n",
            "|    policy_loss        | -0.0758      |\n",
            "|    reward             | -0.012000488 |\n",
            "|    std                | 5.67         |\n",
            "|    value_loss         | 0.000834     |\n",
            "----------------------------------------\n",
            "======A2C Validation from:  2021-06-04 to  2021-07-06\n",
            "A2C Sharpe Ratio:  0.3161106625502845\n",
            "======Best Model Retraining from:  2010-04-01 to  2021-07-06\n",
            "======Trading from:  2021-07-06 to  2021-08-04\n",
            "[[ 1.3943496e+04  2.6078333e+01 -1.6900000e+02  7.6819092e-02\n",
            "   2.7859291e+01  2.5562860e+01  5.2549202e+01 -4.1669563e+01\n",
            "   1.4199882e+01  2.6381594e+01  2.5597965e+01]]\n",
            "============================================\n",
            "turbulence_threshold:  12.04306128869847\n",
            "======Model training from:  2010-04-01 to  2021-07-06\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c\\a2c_168_1\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 443          |\n",
            "|    iterations         | 100          |\n",
            "|    time_elapsed       | 1            |\n",
            "|    total_timesteps    | 500          |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.48        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 99           |\n",
            "|    policy_loss        | -0.016       |\n",
            "|    reward             | -0.007200034 |\n",
            "|    std                | 1.06         |\n",
            "|    value_loss         | 0.000271     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 458         |\n",
            "|    iterations         | 200         |\n",
            "|    time_elapsed       | 2           |\n",
            "|    total_timesteps    | 1000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.51       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 199         |\n",
            "|    policy_loss        | 0.0253      |\n",
            "|    reward             | 0.006584131 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 0.000717    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 459          |\n",
            "|    iterations         | 300          |\n",
            "|    time_elapsed       | 3            |\n",
            "|    total_timesteps    | 1500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.53        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 299          |\n",
            "|    policy_loss        | -0.0237      |\n",
            "|    reward             | -0.055810705 |\n",
            "|    std                | 1.12         |\n",
            "|    value_loss         | 0.000451     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 462          |\n",
            "|    iterations         | 400          |\n",
            "|    time_elapsed       | 4            |\n",
            "|    total_timesteps    | 2000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.54        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 399          |\n",
            "|    policy_loss        | -0.0438      |\n",
            "|    reward             | -0.008617177 |\n",
            "|    std                | 1.13         |\n",
            "|    value_loss         | 0.0019       |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 461        |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 5          |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.55      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | 0.0825     |\n",
            "|    reward             | 0.23405957 |\n",
            "|    std                | 1.14       |\n",
            "|    value_loss         | 0.0146     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 460         |\n",
            "|    iterations         | 600         |\n",
            "|    time_elapsed       | 6           |\n",
            "|    total_timesteps    | 3000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.56       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 599         |\n",
            "|    policy_loss        | 0.00908     |\n",
            "|    reward             | 0.009033381 |\n",
            "|    std                | 1.15        |\n",
            "|    value_loss         | 0.000557    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 458           |\n",
            "|    iterations         | 700           |\n",
            "|    time_elapsed       | 7             |\n",
            "|    total_timesteps    | 3500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.58         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 699           |\n",
            "|    policy_loss        | 0.00503       |\n",
            "|    reward             | -0.0033326396 |\n",
            "|    std                | 1.17          |\n",
            "|    value_loss         | 7.41e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 461          |\n",
            "|    iterations         | 800          |\n",
            "|    time_elapsed       | 8            |\n",
            "|    total_timesteps    | 4000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.58        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 799          |\n",
            "|    policy_loss        | -0.0162      |\n",
            "|    reward             | -0.029953377 |\n",
            "|    std                | 1.18         |\n",
            "|    value_loss         | 0.000922     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 461         |\n",
            "|    iterations         | 900         |\n",
            "|    time_elapsed       | 9           |\n",
            "|    total_timesteps    | 4500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.6        |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 899         |\n",
            "|    policy_loss        | 0.176       |\n",
            "|    reward             | 0.011432462 |\n",
            "|    std                | 1.2         |\n",
            "|    value_loss         | 0.0201      |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 461          |\n",
            "|    iterations         | 1000         |\n",
            "|    time_elapsed       | 10           |\n",
            "|    total_timesteps    | 5000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.6         |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 999          |\n",
            "|    policy_loss        | -0.103       |\n",
            "|    reward             | -0.055635758 |\n",
            "|    std                | 1.2          |\n",
            "|    value_loss         | 0.0118       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 460         |\n",
            "|    iterations         | 1100        |\n",
            "|    time_elapsed       | 11          |\n",
            "|    total_timesteps    | 5500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.62       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1099        |\n",
            "|    policy_loss        | 0.077       |\n",
            "|    reward             | 0.010720752 |\n",
            "|    std                | 1.22        |\n",
            "|    value_loss         | 0.00421     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 460          |\n",
            "|    iterations         | 1200         |\n",
            "|    time_elapsed       | 13           |\n",
            "|    total_timesteps    | 6000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.64        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1199         |\n",
            "|    policy_loss        | -0.0424      |\n",
            "|    reward             | -0.017620435 |\n",
            "|    std                | 1.24         |\n",
            "|    value_loss         | 0.0013       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 461          |\n",
            "|    iterations         | 1300         |\n",
            "|    time_elapsed       | 14           |\n",
            "|    total_timesteps    | 6500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.64        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1299         |\n",
            "|    policy_loss        | -0.0552      |\n",
            "|    reward             | -0.041720346 |\n",
            "|    std                | 1.24         |\n",
            "|    value_loss         | 0.0016       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 460          |\n",
            "|    iterations         | 1400         |\n",
            "|    time_elapsed       | 15           |\n",
            "|    total_timesteps    | 7000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.66        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1399         |\n",
            "|    policy_loss        | -0.027       |\n",
            "|    reward             | -0.004255207 |\n",
            "|    std                | 1.27         |\n",
            "|    value_loss         | 0.00114      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 461          |\n",
            "|    iterations         | 1500         |\n",
            "|    time_elapsed       | 16           |\n",
            "|    total_timesteps    | 7500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.67        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1499         |\n",
            "|    policy_loss        | -0.0524      |\n",
            "|    reward             | -0.008524686 |\n",
            "|    std                | 1.29         |\n",
            "|    value_loss         | 0.00157      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 462         |\n",
            "|    iterations         | 1600        |\n",
            "|    time_elapsed       | 17          |\n",
            "|    total_timesteps    | 8000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.67       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1599        |\n",
            "|    policy_loss        | -0.0858     |\n",
            "|    reward             | 0.016115243 |\n",
            "|    std                | 1.28        |\n",
            "|    value_loss         | 0.00341     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 462         |\n",
            "|    iterations         | 1700        |\n",
            "|    time_elapsed       | 18          |\n",
            "|    total_timesteps    | 8500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.67       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1699        |\n",
            "|    policy_loss        | 0.0365      |\n",
            "|    reward             | 0.011414851 |\n",
            "|    std                | 1.29        |\n",
            "|    value_loss         | 0.00521     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 463         |\n",
            "|    iterations         | 1800        |\n",
            "|    time_elapsed       | 19          |\n",
            "|    total_timesteps    | 9000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.68       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1799        |\n",
            "|    policy_loss        | -0.0146     |\n",
            "|    reward             | 0.015826114 |\n",
            "|    std                | 1.29        |\n",
            "|    value_loss         | 0.000547    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 462          |\n",
            "|    iterations         | 1900         |\n",
            "|    time_elapsed       | 20           |\n",
            "|    total_timesteps    | 9500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.68        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1899         |\n",
            "|    policy_loss        | 0.128        |\n",
            "|    reward             | -0.002139856 |\n",
            "|    std                | 1.29         |\n",
            "|    value_loss         | 0.011        |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 462        |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 21         |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.68      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | 0.0154     |\n",
            "|    reward             | 0.02803602 |\n",
            "|    std                | 1.3        |\n",
            "|    value_loss         | 0.000462   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 462         |\n",
            "|    iterations         | 2100        |\n",
            "|    time_elapsed       | 22          |\n",
            "|    total_timesteps    | 10500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.68       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2099        |\n",
            "|    policy_loss        | 0.0586      |\n",
            "|    reward             | -0.07578035 |\n",
            "|    std                | 1.29        |\n",
            "|    value_loss         | 0.00417     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 462        |\n",
            "|    iterations         | 2200       |\n",
            "|    time_elapsed       | 23         |\n",
            "|    total_timesteps    | 11000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.69      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2199       |\n",
            "|    policy_loss        | 0.785      |\n",
            "|    reward             | 0.24597664 |\n",
            "|    std                | 1.32       |\n",
            "|    value_loss         | 0.197      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 462        |\n",
            "|    iterations         | 2300       |\n",
            "|    time_elapsed       | 24         |\n",
            "|    total_timesteps    | 11500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.7       |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2299       |\n",
            "|    policy_loss        | 0.0496     |\n",
            "|    reward             | 0.02684555 |\n",
            "|    std                | 1.33       |\n",
            "|    value_loss         | 0.00113    |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 463           |\n",
            "|    iterations         | 2400          |\n",
            "|    time_elapsed       | 25            |\n",
            "|    total_timesteps    | 12000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.71         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2399          |\n",
            "|    policy_loss        | -0.0176       |\n",
            "|    reward             | -0.0026149838 |\n",
            "|    std                | 1.34          |\n",
            "|    value_loss         | 0.000184      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 463         |\n",
            "|    iterations         | 2500        |\n",
            "|    time_elapsed       | 26          |\n",
            "|    total_timesteps    | 12500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.72       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2499        |\n",
            "|    policy_loss        | -0.0601     |\n",
            "|    reward             | 0.044371966 |\n",
            "|    std                | 1.35        |\n",
            "|    value_loss         | 0.00237     |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 463            |\n",
            "|    iterations         | 2600           |\n",
            "|    time_elapsed       | 28             |\n",
            "|    total_timesteps    | 13000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -1.72          |\n",
            "|    explained_variance | -1.19e-07      |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 2599           |\n",
            "|    policy_loss        | -0.127         |\n",
            "|    reward             | -4.3218824e-06 |\n",
            "|    std                | 1.35           |\n",
            "|    value_loss         | 0.0239         |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 463          |\n",
            "|    iterations         | 2700         |\n",
            "|    time_elapsed       | 29           |\n",
            "|    total_timesteps    | 13500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.73        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2699         |\n",
            "|    policy_loss        | 0.074        |\n",
            "|    reward             | -0.025993885 |\n",
            "|    std                | 1.37         |\n",
            "|    value_loss         | 0.0091       |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 463        |\n",
            "|    iterations         | 2800       |\n",
            "|    time_elapsed       | 30         |\n",
            "|    total_timesteps    | 14000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.73      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2799       |\n",
            "|    policy_loss        | -0.0745    |\n",
            "|    reward             | 0.20364933 |\n",
            "|    std                | 1.37       |\n",
            "|    value_loss         | 0.0084     |\n",
            "--------------------------------------\n",
            "day: 2833, episode: 5\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -3538.23\n",
            "total_reward: -13538.23\n",
            "total_cost: 128.29\n",
            "total_trades: 2833\n",
            "Sharpe: 0.322\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 463          |\n",
            "|    iterations         | 2900         |\n",
            "|    time_elapsed       | 31           |\n",
            "|    total_timesteps    | 14500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.74        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2899         |\n",
            "|    policy_loss        | 0.0362       |\n",
            "|    reward             | -0.036580205 |\n",
            "|    std                | 1.38         |\n",
            "|    value_loss         | 0.000845     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 464           |\n",
            "|    iterations         | 3000          |\n",
            "|    time_elapsed       | 32            |\n",
            "|    total_timesteps    | 15000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.75         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2999          |\n",
            "|    policy_loss        | -0.0781       |\n",
            "|    reward             | -0.0007968501 |\n",
            "|    std                | 1.4           |\n",
            "|    value_loss         | 0.00249       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 463          |\n",
            "|    iterations         | 3100         |\n",
            "|    time_elapsed       | 33           |\n",
            "|    total_timesteps    | 15500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.77        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3099         |\n",
            "|    policy_loss        | 0.0957       |\n",
            "|    reward             | -0.010902486 |\n",
            "|    std                | 1.42         |\n",
            "|    value_loss         | 0.00296      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 463         |\n",
            "|    iterations         | 3200        |\n",
            "|    time_elapsed       | 34          |\n",
            "|    total_timesteps    | 16000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.77       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3199        |\n",
            "|    policy_loss        | 0.0409      |\n",
            "|    reward             | -0.12526305 |\n",
            "|    std                | 1.43        |\n",
            "|    value_loss         | 0.00175     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 464         |\n",
            "|    iterations         | 3300        |\n",
            "|    time_elapsed       | 35          |\n",
            "|    total_timesteps    | 16500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.78       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3299        |\n",
            "|    policy_loss        | -0.0193     |\n",
            "|    reward             | -0.06367389 |\n",
            "|    std                | 1.43        |\n",
            "|    value_loss         | 0.00299     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 464         |\n",
            "|    iterations         | 3400        |\n",
            "|    time_elapsed       | 36          |\n",
            "|    total_timesteps    | 17000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.79       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3399        |\n",
            "|    policy_loss        | 0.188       |\n",
            "|    reward             | 0.022618635 |\n",
            "|    std                | 1.45        |\n",
            "|    value_loss         | 0.0382      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 464         |\n",
            "|    iterations         | 3500        |\n",
            "|    time_elapsed       | 37          |\n",
            "|    total_timesteps    | 17500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.78       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3499        |\n",
            "|    policy_loss        | -0.00422    |\n",
            "|    reward             | 0.036932334 |\n",
            "|    std                | 1.44        |\n",
            "|    value_loss         | 0.000142    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 464          |\n",
            "|    iterations         | 3600         |\n",
            "|    time_elapsed       | 38           |\n",
            "|    total_timesteps    | 18000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.8         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3599         |\n",
            "|    policy_loss        | 0.226        |\n",
            "|    reward             | -0.062316623 |\n",
            "|    std                | 1.46         |\n",
            "|    value_loss         | 0.012        |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 464         |\n",
            "|    iterations         | 3700        |\n",
            "|    time_elapsed       | 39          |\n",
            "|    total_timesteps    | 18500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.81       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3699        |\n",
            "|    policy_loss        | -0.142      |\n",
            "|    reward             | -0.14266041 |\n",
            "|    std                | 1.48        |\n",
            "|    value_loss         | 0.00506     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 464         |\n",
            "|    iterations         | 3800        |\n",
            "|    time_elapsed       | 40          |\n",
            "|    total_timesteps    | 19000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.82       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3799        |\n",
            "|    policy_loss        | 0.0865      |\n",
            "|    reward             | 0.014483181 |\n",
            "|    std                | 1.49        |\n",
            "|    value_loss         | 0.00294     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 464         |\n",
            "|    iterations         | 3900        |\n",
            "|    time_elapsed       | 41          |\n",
            "|    total_timesteps    | 19500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.83       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3899        |\n",
            "|    policy_loss        | 0.632       |\n",
            "|    reward             | 0.023747008 |\n",
            "|    std                | 1.51        |\n",
            "|    value_loss         | 0.118       |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 464          |\n",
            "|    iterations         | 4000         |\n",
            "|    time_elapsed       | 43           |\n",
            "|    total_timesteps    | 20000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.84        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3999         |\n",
            "|    policy_loss        | -0.0535      |\n",
            "|    reward             | -0.008731508 |\n",
            "|    std                | 1.52         |\n",
            "|    value_loss         | 0.00107      |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 464        |\n",
            "|    iterations         | 4100       |\n",
            "|    time_elapsed       | 44         |\n",
            "|    total_timesteps    | 20500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.85      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4099       |\n",
            "|    policy_loss        | -0.0222    |\n",
            "|    reward             | 0.04149297 |\n",
            "|    std                | 1.53       |\n",
            "|    value_loss         | 0.000424   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 464       |\n",
            "|    iterations         | 4200      |\n",
            "|    time_elapsed       | 45        |\n",
            "|    total_timesteps    | 21000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.85     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4199      |\n",
            "|    policy_loss        | -0.0705   |\n",
            "|    reward             | 0.1240886 |\n",
            "|    std                | 1.53      |\n",
            "|    value_loss         | 0.000803  |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 464          |\n",
            "|    iterations         | 4300         |\n",
            "|    time_elapsed       | 46           |\n",
            "|    total_timesteps    | 21500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.87        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4299         |\n",
            "|    policy_loss        | -0.37        |\n",
            "|    reward             | 0.0014006083 |\n",
            "|    std                | 1.58         |\n",
            "|    value_loss         | 0.0814       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 465         |\n",
            "|    iterations         | 4400        |\n",
            "|    time_elapsed       | 47          |\n",
            "|    total_timesteps    | 22000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.88       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4399        |\n",
            "|    policy_loss        | -0.0759     |\n",
            "|    reward             | -0.08994169 |\n",
            "|    std                | 1.58        |\n",
            "|    value_loss         | 0.0086      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 465         |\n",
            "|    iterations         | 4500        |\n",
            "|    time_elapsed       | 48          |\n",
            "|    total_timesteps    | 22500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.87       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4499        |\n",
            "|    policy_loss        | 0.172       |\n",
            "|    reward             | 0.009504905 |\n",
            "|    std                | 1.57        |\n",
            "|    value_loss         | 0.012       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 465         |\n",
            "|    iterations         | 4600        |\n",
            "|    time_elapsed       | 49          |\n",
            "|    total_timesteps    | 23000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.88       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4599        |\n",
            "|    policy_loss        | 0.0794      |\n",
            "|    reward             | 0.015917335 |\n",
            "|    std                | 1.59        |\n",
            "|    value_loss         | 0.0013      |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 464          |\n",
            "|    iterations         | 4700         |\n",
            "|    time_elapsed       | 50           |\n",
            "|    total_timesteps    | 23500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.88        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4699         |\n",
            "|    policy_loss        | -0.0666      |\n",
            "|    reward             | -0.013748434 |\n",
            "|    std                | 1.59         |\n",
            "|    value_loss         | 0.000873     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 462          |\n",
            "|    iterations         | 4800         |\n",
            "|    time_elapsed       | 51           |\n",
            "|    total_timesteps    | 24000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.89        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4799         |\n",
            "|    policy_loss        | 0.0848       |\n",
            "|    reward             | 0.0010262849 |\n",
            "|    std                | 1.59         |\n",
            "|    value_loss         | 0.00294      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 462         |\n",
            "|    iterations         | 4900        |\n",
            "|    time_elapsed       | 52          |\n",
            "|    total_timesteps    | 24500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.89       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4899        |\n",
            "|    policy_loss        | 0.0329      |\n",
            "|    reward             | 0.053434625 |\n",
            "|    std                | 1.61        |\n",
            "|    value_loss         | 0.00266     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 462           |\n",
            "|    iterations         | 5000          |\n",
            "|    time_elapsed       | 54            |\n",
            "|    total_timesteps    | 25000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.91         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4999          |\n",
            "|    policy_loss        | 0.164         |\n",
            "|    reward             | -0.0033844751 |\n",
            "|    std                | 1.63          |\n",
            "|    value_loss         | 0.0082        |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 462         |\n",
            "|    iterations         | 5100        |\n",
            "|    time_elapsed       | 55          |\n",
            "|    total_timesteps    | 25500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.92       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5099        |\n",
            "|    policy_loss        | 0.484       |\n",
            "|    reward             | -0.07434194 |\n",
            "|    std                | 1.65        |\n",
            "|    value_loss         | 0.0842      |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 461           |\n",
            "|    iterations         | 5200          |\n",
            "|    time_elapsed       | 56            |\n",
            "|    total_timesteps    | 26000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.93         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5199          |\n",
            "|    policy_loss        | 0.00921       |\n",
            "|    reward             | -0.0037555895 |\n",
            "|    std                | 1.67          |\n",
            "|    value_loss         | 0.000118      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 462          |\n",
            "|    iterations         | 5300         |\n",
            "|    time_elapsed       | 57           |\n",
            "|    total_timesteps    | 26500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.94        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5299         |\n",
            "|    policy_loss        | 0.061        |\n",
            "|    reward             | -0.034229923 |\n",
            "|    std                | 1.68         |\n",
            "|    value_loss         | 0.000763     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 462          |\n",
            "|    iterations         | 5400         |\n",
            "|    time_elapsed       | 58           |\n",
            "|    total_timesteps    | 27000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.95        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5399         |\n",
            "|    policy_loss        | -0.0375      |\n",
            "|    reward             | -0.020123765 |\n",
            "|    std                | 1.71         |\n",
            "|    value_loss         | 0.000639     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 462         |\n",
            "|    iterations         | 5500        |\n",
            "|    time_elapsed       | 59          |\n",
            "|    total_timesteps    | 27500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.98       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5499        |\n",
            "|    policy_loss        | -0.00754    |\n",
            "|    reward             | -0.03368427 |\n",
            "|    std                | 1.75        |\n",
            "|    value_loss         | 0.00057     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 462         |\n",
            "|    iterations         | 5600        |\n",
            "|    time_elapsed       | 60          |\n",
            "|    total_timesteps    | 28000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.98       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5599        |\n",
            "|    policy_loss        | 0.137       |\n",
            "|    reward             | 0.058232177 |\n",
            "|    std                | 1.76        |\n",
            "|    value_loss         | 0.00465     |\n",
            "---------------------------------------\n",
            "day: 2833, episode: 10\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -247.85\n",
            "total_reward: -10247.85\n",
            "total_cost: 120.35\n",
            "total_trades: 2833\n",
            "Sharpe: -0.257\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 462        |\n",
            "|    iterations         | 5700       |\n",
            "|    time_elapsed       | 61         |\n",
            "|    total_timesteps    | 28500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2         |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5699       |\n",
            "|    policy_loss        | -0.00831   |\n",
            "|    reward             | 0.01024486 |\n",
            "|    std                | 1.79       |\n",
            "|    value_loss         | 2.71e-05   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 462         |\n",
            "|    iterations         | 5800        |\n",
            "|    time_elapsed       | 62          |\n",
            "|    total_timesteps    | 29000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.01       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5799        |\n",
            "|    policy_loss        | -0.0494     |\n",
            "|    reward             | 0.017620767 |\n",
            "|    std                | 1.81        |\n",
            "|    value_loss         | 0.000621    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 462          |\n",
            "|    iterations         | 5900         |\n",
            "|    time_elapsed       | 63           |\n",
            "|    total_timesteps    | 29500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.02        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5899         |\n",
            "|    policy_loss        | -0.0935      |\n",
            "|    reward             | -0.017093917 |\n",
            "|    std                | 1.83         |\n",
            "|    value_loss         | 0.00482      |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 462        |\n",
            "|    iterations         | 6000       |\n",
            "|    time_elapsed       | 64         |\n",
            "|    total_timesteps    | 30000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.05      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5999       |\n",
            "|    policy_loss        | -0.411     |\n",
            "|    reward             | 0.05162432 |\n",
            "|    std                | 1.88       |\n",
            "|    value_loss         | 0.0435     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 462         |\n",
            "|    iterations         | 6100        |\n",
            "|    time_elapsed       | 65          |\n",
            "|    total_timesteps    | 30500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.07       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6099        |\n",
            "|    policy_loss        | -0.00798    |\n",
            "|    reward             | 0.008918748 |\n",
            "|    std                | 1.91        |\n",
            "|    value_loss         | 0.00125     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 462         |\n",
            "|    iterations         | 6200        |\n",
            "|    time_elapsed       | 66          |\n",
            "|    total_timesteps    | 31000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.08       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6199        |\n",
            "|    policy_loss        | 0.038       |\n",
            "|    reward             | 0.017635124 |\n",
            "|    std                | 1.94        |\n",
            "|    value_loss         | 0.000726    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 462         |\n",
            "|    iterations         | 6300        |\n",
            "|    time_elapsed       | 68          |\n",
            "|    total_timesteps    | 31500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.1        |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6299        |\n",
            "|    policy_loss        | 0.0415      |\n",
            "|    reward             | 0.016130544 |\n",
            "|    std                | 1.97        |\n",
            "|    value_loss         | 0.00034     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 463          |\n",
            "|    iterations         | 6400         |\n",
            "|    time_elapsed       | 69           |\n",
            "|    total_timesteps    | 32000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.11        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6399         |\n",
            "|    policy_loss        | 0.0144       |\n",
            "|    reward             | -0.004948562 |\n",
            "|    std                | 1.99         |\n",
            "|    value_loss         | 9.27e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 463          |\n",
            "|    iterations         | 6500         |\n",
            "|    time_elapsed       | 70           |\n",
            "|    total_timesteps    | 32500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.12        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6499         |\n",
            "|    policy_loss        | 0.0371       |\n",
            "|    reward             | -0.007939575 |\n",
            "|    std                | 2.01         |\n",
            "|    value_loss         | 0.00182      |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 463        |\n",
            "|    iterations         | 6600       |\n",
            "|    time_elapsed       | 71         |\n",
            "|    total_timesteps    | 33000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.13      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6599       |\n",
            "|    policy_loss        | 0.126      |\n",
            "|    reward             | 0.01598752 |\n",
            "|    std                | 2.03       |\n",
            "|    value_loss         | 0.00585    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 463         |\n",
            "|    iterations         | 6700        |\n",
            "|    time_elapsed       | 72          |\n",
            "|    total_timesteps    | 33500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.14       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6699        |\n",
            "|    policy_loss        | -0.00351    |\n",
            "|    reward             | 0.033665195 |\n",
            "|    std                | 2.06        |\n",
            "|    value_loss         | 0.000396    |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 463       |\n",
            "|    iterations         | 6800      |\n",
            "|    time_elapsed       | 73        |\n",
            "|    total_timesteps    | 34000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.15     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6799      |\n",
            "|    policy_loss        | 0.153     |\n",
            "|    reward             | 0.0431824 |\n",
            "|    std                | 2.07      |\n",
            "|    value_loss         | 0.00824   |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 463         |\n",
            "|    iterations         | 6900        |\n",
            "|    time_elapsed       | 74          |\n",
            "|    total_timesteps    | 34500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.15       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6899        |\n",
            "|    policy_loss        | 0.0379      |\n",
            "|    reward             | 0.030349266 |\n",
            "|    std                | 2.09        |\n",
            "|    value_loss         | 0.000981    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 463          |\n",
            "|    iterations         | 7000         |\n",
            "|    time_elapsed       | 75           |\n",
            "|    total_timesteps    | 35000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.16        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6999         |\n",
            "|    policy_loss        | 0.0497       |\n",
            "|    reward             | -0.006573293 |\n",
            "|    std                | 2.09         |\n",
            "|    value_loss         | 0.00127      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 463          |\n",
            "|    iterations         | 7100         |\n",
            "|    time_elapsed       | 76           |\n",
            "|    total_timesteps    | 35500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.18        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7099         |\n",
            "|    policy_loss        | 0.0131       |\n",
            "|    reward             | 0.0062858225 |\n",
            "|    std                | 2.13         |\n",
            "|    value_loss         | 0.000193     |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 463        |\n",
            "|    iterations         | 7200       |\n",
            "|    time_elapsed       | 77         |\n",
            "|    total_timesteps    | 36000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.18      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7199       |\n",
            "|    policy_loss        | 0.124      |\n",
            "|    reward             | 0.06475629 |\n",
            "|    std                | 2.15       |\n",
            "|    value_loss         | 0.00362    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 463         |\n",
            "|    iterations         | 7300        |\n",
            "|    time_elapsed       | 78          |\n",
            "|    total_timesteps    | 36500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.19       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7299        |\n",
            "|    policy_loss        | 0.152       |\n",
            "|    reward             | 0.045673024 |\n",
            "|    std                | 2.17        |\n",
            "|    value_loss         | 0.00786     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 463        |\n",
            "|    iterations         | 7400       |\n",
            "|    time_elapsed       | 79         |\n",
            "|    total_timesteps    | 37000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.2       |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7399       |\n",
            "|    policy_loss        | -0.0451    |\n",
            "|    reward             | 0.03255748 |\n",
            "|    std                | 2.18       |\n",
            "|    value_loss         | 0.000692   |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 463           |\n",
            "|    iterations         | 7500          |\n",
            "|    time_elapsed       | 80            |\n",
            "|    total_timesteps    | 37500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.21         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7499          |\n",
            "|    policy_loss        | -0.0809       |\n",
            "|    reward             | -0.0027046176 |\n",
            "|    std                | 2.21          |\n",
            "|    value_loss         | 0.00244       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 463          |\n",
            "|    iterations         | 7600         |\n",
            "|    time_elapsed       | 81           |\n",
            "|    total_timesteps    | 38000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.23        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7599         |\n",
            "|    policy_loss        | -0.186       |\n",
            "|    reward             | -0.019962141 |\n",
            "|    std                | 2.25         |\n",
            "|    value_loss         | 0.0107       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 463         |\n",
            "|    iterations         | 7700        |\n",
            "|    time_elapsed       | 83          |\n",
            "|    total_timesteps    | 38500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.23       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7699        |\n",
            "|    policy_loss        | -0.169      |\n",
            "|    reward             | -0.01646602 |\n",
            "|    std                | 2.25        |\n",
            "|    value_loss         | 0.00859     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 464         |\n",
            "|    iterations         | 7800        |\n",
            "|    time_elapsed       | 84          |\n",
            "|    total_timesteps    | 39000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.25       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7799        |\n",
            "|    policy_loss        | -0.221      |\n",
            "|    reward             | 0.004587505 |\n",
            "|    std                | 2.29        |\n",
            "|    value_loss         | 0.0257      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 464         |\n",
            "|    iterations         | 7900        |\n",
            "|    time_elapsed       | 85          |\n",
            "|    total_timesteps    | 39500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.26       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7899        |\n",
            "|    policy_loss        | 0.0222      |\n",
            "|    reward             | 0.017562937 |\n",
            "|    std                | 2.32        |\n",
            "|    value_loss         | 0.00101     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 463         |\n",
            "|    iterations         | 8000        |\n",
            "|    time_elapsed       | 86          |\n",
            "|    total_timesteps    | 40000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.27       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7999        |\n",
            "|    policy_loss        | -0.106      |\n",
            "|    reward             | 0.023599027 |\n",
            "|    std                | 2.35        |\n",
            "|    value_loss         | 0.00239     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 464         |\n",
            "|    iterations         | 8100        |\n",
            "|    time_elapsed       | 87          |\n",
            "|    total_timesteps    | 40500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.28       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8099        |\n",
            "|    policy_loss        | -0.0302     |\n",
            "|    reward             | -0.03433478 |\n",
            "|    std                | 2.37        |\n",
            "|    value_loss         | 0.000708    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 464         |\n",
            "|    iterations         | 8200        |\n",
            "|    time_elapsed       | 88          |\n",
            "|    total_timesteps    | 41000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.28       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8199        |\n",
            "|    policy_loss        | 0.188       |\n",
            "|    reward             | -0.01509564 |\n",
            "|    std                | 2.37        |\n",
            "|    value_loss         | 0.00788     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 464         |\n",
            "|    iterations         | 8300        |\n",
            "|    time_elapsed       | 89          |\n",
            "|    total_timesteps    | 41500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.29       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8299        |\n",
            "|    policy_loss        | 0.173       |\n",
            "|    reward             | 0.052031472 |\n",
            "|    std                | 2.38        |\n",
            "|    value_loss         | 0.00665     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 464          |\n",
            "|    iterations         | 8400         |\n",
            "|    time_elapsed       | 90           |\n",
            "|    total_timesteps    | 42000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.3         |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8399         |\n",
            "|    policy_loss        | -0.00237     |\n",
            "|    reward             | -0.084742844 |\n",
            "|    std                | 2.41         |\n",
            "|    value_loss         | 0.0009       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 464         |\n",
            "|    iterations         | 8500        |\n",
            "|    time_elapsed       | 91          |\n",
            "|    total_timesteps    | 42500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.31       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8499        |\n",
            "|    policy_loss        | 0.00963     |\n",
            "|    reward             | -0.17663305 |\n",
            "|    std                | 2.43        |\n",
            "|    value_loss         | 0.00568     |\n",
            "---------------------------------------\n",
            "day: 2833, episode: 15\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -2092.11\n",
            "total_reward: -12092.11\n",
            "total_cost: 124.92\n",
            "total_trades: 2833\n",
            "Sharpe: -0.301\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 464         |\n",
            "|    iterations         | 8600        |\n",
            "|    time_elapsed       | 92          |\n",
            "|    total_timesteps    | 43000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.32       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8599        |\n",
            "|    policy_loss        | 0.157       |\n",
            "|    reward             | 0.012819793 |\n",
            "|    std                | 2.46        |\n",
            "|    value_loss         | 0.00614     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 464           |\n",
            "|    iterations         | 8700          |\n",
            "|    time_elapsed       | 93            |\n",
            "|    total_timesteps    | 43500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.33         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8699          |\n",
            "|    policy_loss        | 0.144         |\n",
            "|    reward             | -0.0016493726 |\n",
            "|    std                | 2.49          |\n",
            "|    value_loss         | 0.0037        |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 464         |\n",
            "|    iterations         | 8800        |\n",
            "|    time_elapsed       | 94          |\n",
            "|    total_timesteps    | 44000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.35       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8799        |\n",
            "|    policy_loss        | -0.105      |\n",
            "|    reward             | 0.004826848 |\n",
            "|    std                | 2.54        |\n",
            "|    value_loss         | 0.00387     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 464         |\n",
            "|    iterations         | 8900        |\n",
            "|    time_elapsed       | 95          |\n",
            "|    total_timesteps    | 44500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.36       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8899        |\n",
            "|    policy_loss        | 0.0447      |\n",
            "|    reward             | 0.014093997 |\n",
            "|    std                | 2.58        |\n",
            "|    value_loss         | 0.0032      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 464        |\n",
            "|    iterations         | 9000       |\n",
            "|    time_elapsed       | 96         |\n",
            "|    total_timesteps    | 45000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.38      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8999       |\n",
            "|    policy_loss        | 0.063      |\n",
            "|    reward             | 0.16940118 |\n",
            "|    std                | 2.62       |\n",
            "|    value_loss         | 0.00638    |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 464          |\n",
            "|    iterations         | 9100         |\n",
            "|    time_elapsed       | 97           |\n",
            "|    total_timesteps    | 45500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.38        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9099         |\n",
            "|    policy_loss        | -0.0649      |\n",
            "|    reward             | 0.0004291547 |\n",
            "|    std                | 2.62         |\n",
            "|    value_loss         | 0.0006       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 464          |\n",
            "|    iterations         | 9200         |\n",
            "|    time_elapsed       | 99           |\n",
            "|    total_timesteps    | 46000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.39        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9199         |\n",
            "|    policy_loss        | 0.0165       |\n",
            "|    reward             | -0.012298112 |\n",
            "|    std                | 2.65         |\n",
            "|    value_loss         | 0.00146      |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 464            |\n",
            "|    iterations         | 9300           |\n",
            "|    time_elapsed       | 100            |\n",
            "|    total_timesteps    | 46500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -2.41          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 9299           |\n",
            "|    policy_loss        | 0.0187         |\n",
            "|    reward             | -1.7297365e-06 |\n",
            "|    std                | 2.69           |\n",
            "|    value_loss         | 0.00145        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 464           |\n",
            "|    iterations         | 9400          |\n",
            "|    time_elapsed       | 101           |\n",
            "|    total_timesteps    | 47000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.42         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9399          |\n",
            "|    policy_loss        | 0.0317        |\n",
            "|    reward             | -0.0047863876 |\n",
            "|    std                | 2.72          |\n",
            "|    value_loss         | 0.00103       |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 464        |\n",
            "|    iterations         | 9500       |\n",
            "|    time_elapsed       | 102        |\n",
            "|    total_timesteps    | 47500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.44      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9499       |\n",
            "|    policy_loss        | -0.315     |\n",
            "|    reward             | 0.14022622 |\n",
            "|    std                | 2.77       |\n",
            "|    value_loss         | 0.0281     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 464        |\n",
            "|    iterations         | 9600       |\n",
            "|    time_elapsed       | 103        |\n",
            "|    total_timesteps    | 48000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.45      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9599       |\n",
            "|    policy_loss        | -0.168     |\n",
            "|    reward             | 0.06935395 |\n",
            "|    std                | 2.8        |\n",
            "|    value_loss         | 0.00985    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 464         |\n",
            "|    iterations         | 9700        |\n",
            "|    time_elapsed       | 104         |\n",
            "|    total_timesteps    | 48500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.46       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9699        |\n",
            "|    policy_loss        | -0.058      |\n",
            "|    reward             | 0.007962104 |\n",
            "|    std                | 2.84        |\n",
            "|    value_loss         | 0.000842    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 464          |\n",
            "|    iterations         | 9800         |\n",
            "|    time_elapsed       | 105          |\n",
            "|    total_timesteps    | 49000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.46        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9799         |\n",
            "|    policy_loss        | -0.122       |\n",
            "|    reward             | -0.022158954 |\n",
            "|    std                | 2.84         |\n",
            "|    value_loss         | 0.0023       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 464         |\n",
            "|    iterations         | 9900        |\n",
            "|    time_elapsed       | 106         |\n",
            "|    total_timesteps    | 49500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.48       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9899        |\n",
            "|    policy_loss        | 0.0777      |\n",
            "|    reward             | 0.015896335 |\n",
            "|    std                | 2.9         |\n",
            "|    value_loss         | 0.00226     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 464         |\n",
            "|    iterations         | 10000       |\n",
            "|    time_elapsed       | 107         |\n",
            "|    total_timesteps    | 50000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.49       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9999        |\n",
            "|    policy_loss        | 0.0615      |\n",
            "|    reward             | 0.018859439 |\n",
            "|    std                | 2.91        |\n",
            "|    value_loss         | 0.00123     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 464         |\n",
            "|    iterations         | 10100       |\n",
            "|    time_elapsed       | 108         |\n",
            "|    total_timesteps    | 50500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.51       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10099       |\n",
            "|    policy_loss        | 0.114       |\n",
            "|    reward             | 0.026648907 |\n",
            "|    std                | 2.97        |\n",
            "|    value_loss         | 0.00181     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 464        |\n",
            "|    iterations         | 10200      |\n",
            "|    time_elapsed       | 109        |\n",
            "|    total_timesteps    | 51000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.51      |\n",
            "|    explained_variance | 1.79e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10199      |\n",
            "|    policy_loss        | -0.426     |\n",
            "|    reward             | 0.08198654 |\n",
            "|    std                | 2.99       |\n",
            "|    value_loss         | 0.0374     |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 464           |\n",
            "|    iterations         | 10300         |\n",
            "|    time_elapsed       | 110           |\n",
            "|    total_timesteps    | 51500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.52         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10299         |\n",
            "|    policy_loss        | 0.154         |\n",
            "|    reward             | -0.0011394301 |\n",
            "|    std                | 3             |\n",
            "|    value_loss         | 0.00491       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 464          |\n",
            "|    iterations         | 10400        |\n",
            "|    time_elapsed       | 111          |\n",
            "|    total_timesteps    | 52000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.53        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10399        |\n",
            "|    policy_loss        | 0.0809       |\n",
            "|    reward             | -0.005737419 |\n",
            "|    std                | 3.05         |\n",
            "|    value_loss         | 0.00229      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 465          |\n",
            "|    iterations         | 10500        |\n",
            "|    time_elapsed       | 112          |\n",
            "|    total_timesteps    | 52500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.54        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10499        |\n",
            "|    policy_loss        | -0.189       |\n",
            "|    reward             | -0.024434503 |\n",
            "|    std                | 3.07         |\n",
            "|    value_loss         | 0.00627      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 465          |\n",
            "|    iterations         | 10600        |\n",
            "|    time_elapsed       | 113          |\n",
            "|    total_timesteps    | 53000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.54        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10599        |\n",
            "|    policy_loss        | -0.491       |\n",
            "|    reward             | -0.012509839 |\n",
            "|    std                | 3.08         |\n",
            "|    value_loss         | 0.0375       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 465         |\n",
            "|    iterations         | 10700       |\n",
            "|    time_elapsed       | 115         |\n",
            "|    total_timesteps    | 53500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.54       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10699       |\n",
            "|    policy_loss        | -0.246      |\n",
            "|    reward             | -0.05545346 |\n",
            "|    std                | 3.07        |\n",
            "|    value_loss         | 0.0201      |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 465            |\n",
            "|    iterations         | 10800          |\n",
            "|    time_elapsed       | 116            |\n",
            "|    total_timesteps    | 54000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -2.54          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 10799          |\n",
            "|    policy_loss        | 0.00352        |\n",
            "|    reward             | -0.00017692003 |\n",
            "|    std                | 3.07           |\n",
            "|    value_loss         | 3.3e-05        |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 464          |\n",
            "|    iterations         | 10900        |\n",
            "|    time_elapsed       | 117          |\n",
            "|    total_timesteps    | 54500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.55        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10899        |\n",
            "|    policy_loss        | 0.122        |\n",
            "|    reward             | -0.012898246 |\n",
            "|    std                | 3.1          |\n",
            "|    value_loss         | 0.00406      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 465           |\n",
            "|    iterations         | 11000         |\n",
            "|    time_elapsed       | 118           |\n",
            "|    total_timesteps    | 55000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.56         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10999         |\n",
            "|    policy_loss        | -0.103        |\n",
            "|    reward             | -0.0006265219 |\n",
            "|    std                | 3.12          |\n",
            "|    value_loss         | 0.00239       |\n",
            "-----------------------------------------\n",
            "======A2C Validation from:  2021-07-06 to  2021-08-04\n",
            "A2C Sharpe Ratio:  -0.38180840617136996\n",
            "======Best Model Retraining from:  2010-04-01 to  2021-08-04\n",
            "======Trading from:  2021-08-04 to  2021-09-02\n",
            "[[ 1.4154886e+04  2.7433176e+01 -1.7700000e+02  2.3831518e-01\n",
            "   2.7626322e+01  2.5465286e+01  5.6991024e+01  2.2329358e+02\n",
            "   1.3052706e+01  2.6470055e+01  2.6255129e+01]]\n",
            "============================================\n",
            "turbulence_threshold:  12.04306128869847\n",
            "======Model training from:  2010-04-01 to  2021-08-04\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c\\a2c_189_1\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 475           |\n",
            "|    iterations         | 100           |\n",
            "|    time_elapsed       | 1             |\n",
            "|    total_timesteps    | 500           |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.48         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 99            |\n",
            "|    policy_loss        | -0.0243       |\n",
            "|    reward             | -0.0069449074 |\n",
            "|    std                | 1.07          |\n",
            "|    value_loss         | 0.000277      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 470          |\n",
            "|    iterations         | 200          |\n",
            "|    time_elapsed       | 2            |\n",
            "|    total_timesteps    | 1000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.52        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 199          |\n",
            "|    policy_loss        | 0.0071       |\n",
            "|    reward             | 0.0028032507 |\n",
            "|    std                | 1.11         |\n",
            "|    value_loss         | 0.000102     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 463          |\n",
            "|    iterations         | 300          |\n",
            "|    time_elapsed       | 3            |\n",
            "|    total_timesteps    | 1500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.55        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 299          |\n",
            "|    policy_loss        | -0.00253     |\n",
            "|    reward             | -0.013556652 |\n",
            "|    std                | 1.15         |\n",
            "|    value_loss         | 8.64e-06     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 470           |\n",
            "|    iterations         | 400           |\n",
            "|    time_elapsed       | 4             |\n",
            "|    total_timesteps    | 2000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.59         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 399           |\n",
            "|    policy_loss        | -0.00753      |\n",
            "|    reward             | -0.0010872348 |\n",
            "|    std                | 1.18          |\n",
            "|    value_loss         | 4.32e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 467         |\n",
            "|    iterations         | 500         |\n",
            "|    time_elapsed       | 5           |\n",
            "|    total_timesteps    | 2500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.62       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 499         |\n",
            "|    policy_loss        | 0.000878    |\n",
            "|    reward             | 0.024410643 |\n",
            "|    std                | 1.23        |\n",
            "|    value_loss         | 9.74e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 471          |\n",
            "|    iterations         | 600          |\n",
            "|    time_elapsed       | 6            |\n",
            "|    total_timesteps    | 3000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.66        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 599          |\n",
            "|    policy_loss        | -0.0128      |\n",
            "|    reward             | 0.0037713766 |\n",
            "|    std                | 1.27         |\n",
            "|    value_loss         | 0.0001       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 469         |\n",
            "|    iterations         | 700         |\n",
            "|    time_elapsed       | 7           |\n",
            "|    total_timesteps    | 3500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.68       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 699         |\n",
            "|    policy_loss        | 0.00789     |\n",
            "|    reward             | 0.009616872 |\n",
            "|    std                | 1.3         |\n",
            "|    value_loss         | 2.55e-05    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 471           |\n",
            "|    iterations         | 800           |\n",
            "|    time_elapsed       | 8             |\n",
            "|    total_timesteps    | 4000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.72         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 799           |\n",
            "|    policy_loss        | 0.061         |\n",
            "|    reward             | -0.0049773282 |\n",
            "|    std                | 1.36          |\n",
            "|    value_loss         | 0.00149       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 469         |\n",
            "|    iterations         | 900         |\n",
            "|    time_elapsed       | 9           |\n",
            "|    total_timesteps    | 4500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.76       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 899         |\n",
            "|    policy_loss        | -0.0212     |\n",
            "|    reward             | 0.007329457 |\n",
            "|    std                | 1.41        |\n",
            "|    value_loss         | 0.000132    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 469         |\n",
            "|    iterations         | 1000        |\n",
            "|    time_elapsed       | 10          |\n",
            "|    total_timesteps    | 5000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.79       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 999         |\n",
            "|    policy_loss        | -0.000299   |\n",
            "|    reward             | 0.005516911 |\n",
            "|    std                | 1.46        |\n",
            "|    value_loss         | 3.51e-06    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 468          |\n",
            "|    iterations         | 1100         |\n",
            "|    time_elapsed       | 11           |\n",
            "|    total_timesteps    | 5500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.82        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1099         |\n",
            "|    policy_loss        | 0.0312       |\n",
            "|    reward             | 0.0004703199 |\n",
            "|    std                | 1.5          |\n",
            "|    value_loss         | 0.000283     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 468           |\n",
            "|    iterations         | 1200          |\n",
            "|    time_elapsed       | 12            |\n",
            "|    total_timesteps    | 6000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.87         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1199          |\n",
            "|    policy_loss        | -0.00436      |\n",
            "|    reward             | -0.0015998817 |\n",
            "|    std                | 1.57          |\n",
            "|    value_loss         | 3.17e-05      |\n",
            "-----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 464       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 13        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.89     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 0.00327   |\n",
            "|    reward             | 0.0049979 |\n",
            "|    std                | 1.61      |\n",
            "|    value_loss         | 6.9e-06   |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 467          |\n",
            "|    iterations         | 1400         |\n",
            "|    time_elapsed       | 14           |\n",
            "|    total_timesteps    | 7000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.92        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1399         |\n",
            "|    policy_loss        | 0.000345     |\n",
            "|    reward             | -0.004722401 |\n",
            "|    std                | 1.65         |\n",
            "|    value_loss         | 1.21e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 466          |\n",
            "|    iterations         | 1500         |\n",
            "|    time_elapsed       | 16           |\n",
            "|    total_timesteps    | 7500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.96        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1499         |\n",
            "|    policy_loss        | 0.00131      |\n",
            "|    reward             | 0.0032911377 |\n",
            "|    std                | 1.72         |\n",
            "|    value_loss         | 1.18e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 467           |\n",
            "|    iterations         | 1600          |\n",
            "|    time_elapsed       | 17            |\n",
            "|    total_timesteps    | 8000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.01         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1599          |\n",
            "|    policy_loss        | 0.00739       |\n",
            "|    reward             | 0.00014204254 |\n",
            "|    std                | 1.8           |\n",
            "|    value_loss         | 8.62e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 466           |\n",
            "|    iterations         | 1700          |\n",
            "|    time_elapsed       | 18            |\n",
            "|    total_timesteps    | 8500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.05         |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1699          |\n",
            "|    policy_loss        | 0.000995      |\n",
            "|    reward             | -0.0062760743 |\n",
            "|    std                | 1.88          |\n",
            "|    value_loss         | 2.23e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 466          |\n",
            "|    iterations         | 1800         |\n",
            "|    time_elapsed       | 19           |\n",
            "|    total_timesteps    | 9000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.06        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1799         |\n",
            "|    policy_loss        | 0.0399       |\n",
            "|    reward             | -0.024896668 |\n",
            "|    std                | 1.9          |\n",
            "|    value_loss         | 0.000861     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 467         |\n",
            "|    iterations         | 1900        |\n",
            "|    time_elapsed       | 20          |\n",
            "|    total_timesteps    | 9500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.09       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1899        |\n",
            "|    policy_loss        | -0.0201     |\n",
            "|    reward             | 0.001633164 |\n",
            "|    std                | 1.96        |\n",
            "|    value_loss         | 0.000154    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 467         |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 21          |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.13       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | 0.0181      |\n",
            "|    reward             | 0.003734237 |\n",
            "|    std                | 2.03        |\n",
            "|    value_loss         | 8.63e-05    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 467           |\n",
            "|    iterations         | 2100          |\n",
            "|    time_elapsed       | 22            |\n",
            "|    total_timesteps    | 10500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.16         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2099          |\n",
            "|    policy_loss        | -0.0639       |\n",
            "|    reward             | -0.0054390016 |\n",
            "|    std                | 2.1           |\n",
            "|    value_loss         | 0.00109       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 467         |\n",
            "|    iterations         | 2200        |\n",
            "|    time_elapsed       | 23          |\n",
            "|    total_timesteps    | 11000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.2        |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2199        |\n",
            "|    policy_loss        | 0.0032      |\n",
            "|    reward             | 0.004394582 |\n",
            "|    std                | 2.18        |\n",
            "|    value_loss         | 4.78e-05    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 466        |\n",
            "|    iterations         | 2300       |\n",
            "|    time_elapsed       | 24         |\n",
            "|    total_timesteps    | 11500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.25      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2299       |\n",
            "|    policy_loss        | 0.000259   |\n",
            "|    reward             | 0.01516651 |\n",
            "|    std                | 2.29       |\n",
            "|    value_loss         | 6.63e-05   |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 467          |\n",
            "|    iterations         | 2400         |\n",
            "|    time_elapsed       | 25           |\n",
            "|    total_timesteps    | 12000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.28        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2399         |\n",
            "|    policy_loss        | 0.0455       |\n",
            "|    reward             | -0.013493553 |\n",
            "|    std                | 2.37         |\n",
            "|    value_loss         | 0.000384     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 466            |\n",
            "|    iterations         | 2500           |\n",
            "|    time_elapsed       | 26             |\n",
            "|    total_timesteps    | 12500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -2.31          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 2499           |\n",
            "|    policy_loss        | 0.00184        |\n",
            "|    reward             | -0.00031426537 |\n",
            "|    std                | 2.43           |\n",
            "|    value_loss         | 1.09e-05       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 465           |\n",
            "|    iterations         | 2600          |\n",
            "|    time_elapsed       | 27            |\n",
            "|    total_timesteps    | 13000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.35         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2599          |\n",
            "|    policy_loss        | -0.0155       |\n",
            "|    reward             | -0.0043777702 |\n",
            "|    std                | 2.54          |\n",
            "|    value_loss         | 0.000132      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 466           |\n",
            "|    iterations         | 2700          |\n",
            "|    time_elapsed       | 28            |\n",
            "|    total_timesteps    | 13500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.39         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2699          |\n",
            "|    policy_loss        | -0.0199       |\n",
            "|    reward             | -0.0021043834 |\n",
            "|    std                | 2.65          |\n",
            "|    value_loss         | 6.59e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 465          |\n",
            "|    iterations         | 2800         |\n",
            "|    time_elapsed       | 30           |\n",
            "|    total_timesteps    | 14000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.44        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2799         |\n",
            "|    policy_loss        | 0.0576       |\n",
            "|    reward             | 0.0050392463 |\n",
            "|    std                | 2.78         |\n",
            "|    value_loss         | 0.000447     |\n",
            "----------------------------------------\n",
            "day: 2854, episode: 5\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 8062.41\n",
            "total_reward: -1937.59\n",
            "total_cost: 129.58\n",
            "total_trades: 2854\n",
            "Sharpe: -0.079\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 465         |\n",
            "|    iterations         | 2900        |\n",
            "|    time_elapsed       | 31          |\n",
            "|    total_timesteps    | 14500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.48       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2899        |\n",
            "|    policy_loss        | -0.0364     |\n",
            "|    reward             | 0.012666234 |\n",
            "|    std                | 2.88        |\n",
            "|    value_loss         | 0.000315    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 465           |\n",
            "|    iterations         | 3000          |\n",
            "|    time_elapsed       | 32            |\n",
            "|    total_timesteps    | 15000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.51         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2999          |\n",
            "|    policy_loss        | 0.0423        |\n",
            "|    reward             | -0.0065689483 |\n",
            "|    std                | 3             |\n",
            "|    value_loss         | 0.000198      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 464           |\n",
            "|    iterations         | 3100          |\n",
            "|    time_elapsed       | 33            |\n",
            "|    total_timesteps    | 15500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.56         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3099          |\n",
            "|    policy_loss        | -0.0129       |\n",
            "|    reward             | -0.0053456365 |\n",
            "|    std                | 3.12          |\n",
            "|    value_loss         | 4.68e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 465          |\n",
            "|    iterations         | 3200         |\n",
            "|    time_elapsed       | 34           |\n",
            "|    total_timesteps    | 16000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.6         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3199         |\n",
            "|    policy_loss        | 0.0458       |\n",
            "|    reward             | 0.0011391483 |\n",
            "|    std                | 3.27         |\n",
            "|    value_loss         | 0.000223     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 464           |\n",
            "|    iterations         | 3300          |\n",
            "|    time_elapsed       | 35            |\n",
            "|    total_timesteps    | 16500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.65         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3299          |\n",
            "|    policy_loss        | 0.00144       |\n",
            "|    reward             | -0.0032258485 |\n",
            "|    std                | 3.42          |\n",
            "|    value_loss         | 5.29e-06      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 465         |\n",
            "|    iterations         | 3400        |\n",
            "|    time_elapsed       | 36          |\n",
            "|    total_timesteps    | 17000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.68       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3399        |\n",
            "|    policy_loss        | -0.038      |\n",
            "|    reward             | 0.022808617 |\n",
            "|    std                | 3.54        |\n",
            "|    value_loss         | 0.000231    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 465          |\n",
            "|    iterations         | 3500         |\n",
            "|    time_elapsed       | 37           |\n",
            "|    total_timesteps    | 17500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.72        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3499         |\n",
            "|    policy_loss        | -0.0508      |\n",
            "|    reward             | 0.0045539127 |\n",
            "|    std                | 3.69         |\n",
            "|    value_loss         | 0.000715     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 465            |\n",
            "|    iterations         | 3600           |\n",
            "|    time_elapsed       | 38             |\n",
            "|    total_timesteps    | 18000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -2.75          |\n",
            "|    explained_variance | -1.19e-07      |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 3599           |\n",
            "|    policy_loss        | -0.0562        |\n",
            "|    reward             | -0.00086992484 |\n",
            "|    std                | 3.8            |\n",
            "|    value_loss         | 0.000611       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 465          |\n",
            "|    iterations         | 3700         |\n",
            "|    time_elapsed       | 39           |\n",
            "|    total_timesteps    | 18500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.78        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3699         |\n",
            "|    policy_loss        | 0.0108       |\n",
            "|    reward             | -0.005280821 |\n",
            "|    std                | 3.9          |\n",
            "|    value_loss         | 3.83e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 465          |\n",
            "|    iterations         | 3800         |\n",
            "|    time_elapsed       | 40           |\n",
            "|    total_timesteps    | 19000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.82        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3799         |\n",
            "|    policy_loss        | -0.00595     |\n",
            "|    reward             | 0.0063113887 |\n",
            "|    std                | 4.05         |\n",
            "|    value_loss         | 8.54e-06     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 465           |\n",
            "|    iterations         | 3900          |\n",
            "|    time_elapsed       | 41            |\n",
            "|    total_timesteps    | 19500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.86         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3899          |\n",
            "|    policy_loss        | 0.0271        |\n",
            "|    reward             | 0.00016508393 |\n",
            "|    std                | 4.23          |\n",
            "|    value_loss         | 0.000109      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 464          |\n",
            "|    iterations         | 4000         |\n",
            "|    time_elapsed       | 43           |\n",
            "|    total_timesteps    | 20000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.9         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3999         |\n",
            "|    policy_loss        | 0.0183       |\n",
            "|    reward             | -0.004297166 |\n",
            "|    std                | 4.4          |\n",
            "|    value_loss         | 4.02e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 465          |\n",
            "|    iterations         | 4100         |\n",
            "|    time_elapsed       | 44           |\n",
            "|    total_timesteps    | 20500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.93        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4099         |\n",
            "|    policy_loss        | 0.048        |\n",
            "|    reward             | -0.012754986 |\n",
            "|    std                | 4.53         |\n",
            "|    value_loss         | 0.000295     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 464           |\n",
            "|    iterations         | 4200          |\n",
            "|    time_elapsed       | 45            |\n",
            "|    total_timesteps    | 21000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.95         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4199          |\n",
            "|    policy_loss        | 0.0658        |\n",
            "|    reward             | -0.0072279195 |\n",
            "|    std                | 4.62          |\n",
            "|    value_loss         | 0.000361      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 465           |\n",
            "|    iterations         | 4300          |\n",
            "|    time_elapsed       | 46            |\n",
            "|    total_timesteps    | 21500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.98         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4299          |\n",
            "|    policy_loss        | -0.00112      |\n",
            "|    reward             | 0.00012984328 |\n",
            "|    std                | 4.76          |\n",
            "|    value_loss         | 1.61e-06      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 465           |\n",
            "|    iterations         | 4400          |\n",
            "|    time_elapsed       | 47            |\n",
            "|    total_timesteps    | 22000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.02         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4399          |\n",
            "|    policy_loss        | 0.0205        |\n",
            "|    reward             | -0.0010136635 |\n",
            "|    std                | 4.95          |\n",
            "|    value_loss         | 8.89e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 465           |\n",
            "|    iterations         | 4500          |\n",
            "|    time_elapsed       | 48            |\n",
            "|    total_timesteps    | 22500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.06         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4499          |\n",
            "|    policy_loss        | 0.0214        |\n",
            "|    reward             | -0.0064573605 |\n",
            "|    std                | 5.16          |\n",
            "|    value_loss         | 5.87e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 465         |\n",
            "|    iterations         | 4600        |\n",
            "|    time_elapsed       | 49          |\n",
            "|    total_timesteps    | 23000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.09       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4599        |\n",
            "|    policy_loss        | -0.0209     |\n",
            "|    reward             | 0.015729703 |\n",
            "|    std                | 5.31        |\n",
            "|    value_loss         | 0.00011     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 465         |\n",
            "|    iterations         | 4700        |\n",
            "|    time_elapsed       | 50          |\n",
            "|    total_timesteps    | 23500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.1        |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4699        |\n",
            "|    policy_loss        | -0.0353     |\n",
            "|    reward             | 0.010139696 |\n",
            "|    std                | 5.35        |\n",
            "|    value_loss         | 0.0002      |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 465           |\n",
            "|    iterations         | 4800          |\n",
            "|    time_elapsed       | 51            |\n",
            "|    total_timesteps    | 24000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.12         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4799          |\n",
            "|    policy_loss        | -0.0518       |\n",
            "|    reward             | -0.0053707757 |\n",
            "|    std                | 5.48          |\n",
            "|    value_loss         | 0.000584      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 465         |\n",
            "|    iterations         | 4900        |\n",
            "|    time_elapsed       | 52          |\n",
            "|    total_timesteps    | 24500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.16       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4899        |\n",
            "|    policy_loss        | -0.116      |\n",
            "|    reward             | 0.009609238 |\n",
            "|    std                | 5.69        |\n",
            "|    value_loss         | 0.00152     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 465          |\n",
            "|    iterations         | 5000         |\n",
            "|    time_elapsed       | 53           |\n",
            "|    total_timesteps    | 25000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.19        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4999         |\n",
            "|    policy_loss        | 0.000339     |\n",
            "|    reward             | 0.0009799668 |\n",
            "|    std                | 5.9          |\n",
            "|    value_loss         | 1.77e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 465          |\n",
            "|    iterations         | 5100         |\n",
            "|    time_elapsed       | 54           |\n",
            "|    total_timesteps    | 25500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.24        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5099         |\n",
            "|    policy_loss        | -0.0005      |\n",
            "|    reward             | 0.0018718038 |\n",
            "|    std                | 6.17         |\n",
            "|    value_loss         | 2.06e-06     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 464          |\n",
            "|    iterations         | 5200         |\n",
            "|    time_elapsed       | 55           |\n",
            "|    total_timesteps    | 26000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.27        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5199         |\n",
            "|    policy_loss        | 0.0144       |\n",
            "|    reward             | -0.002837124 |\n",
            "|    std                | 6.39         |\n",
            "|    value_loss         | 0.000264     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 464          |\n",
            "|    iterations         | 5300         |\n",
            "|    time_elapsed       | 57           |\n",
            "|    total_timesteps    | 26500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.29        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5299         |\n",
            "|    policy_loss        | -0.0514      |\n",
            "|    reward             | -0.019784445 |\n",
            "|    std                | 6.49         |\n",
            "|    value_loss         | 0.000299     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 464           |\n",
            "|    iterations         | 5400          |\n",
            "|    time_elapsed       | 58            |\n",
            "|    total_timesteps    | 27000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.32         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5399          |\n",
            "|    policy_loss        | 0.013         |\n",
            "|    reward             | -0.0031287638 |\n",
            "|    std                | 6.66          |\n",
            "|    value_loss         | 4.89e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 464           |\n",
            "|    iterations         | 5500          |\n",
            "|    time_elapsed       | 59            |\n",
            "|    total_timesteps    | 27500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.36         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5499          |\n",
            "|    policy_loss        | 0.00511       |\n",
            "|    reward             | 0.00061178213 |\n",
            "|    std                | 6.95          |\n",
            "|    value_loss         | 5.63e-06      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 465           |\n",
            "|    iterations         | 5600          |\n",
            "|    time_elapsed       | 60            |\n",
            "|    total_timesteps    | 28000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.4          |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5599          |\n",
            "|    policy_loss        | -0.0151       |\n",
            "|    reward             | -0.0038373969 |\n",
            "|    std                | 7.27          |\n",
            "|    value_loss         | 4.58e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 464           |\n",
            "|    iterations         | 5700          |\n",
            "|    time_elapsed       | 61            |\n",
            "|    total_timesteps    | 28500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.44         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5699          |\n",
            "|    policy_loss        | 0.00971       |\n",
            "|    reward             | -0.0015865446 |\n",
            "|    std                | 7.55          |\n",
            "|    value_loss         | 5.01e-05      |\n",
            "-----------------------------------------\n",
            "day: 2854, episode: 10\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 8655.25\n",
            "total_reward: -1344.75\n",
            "total_cost: 118.50\n",
            "total_trades: 2854\n",
            "Sharpe: 0.006\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 465           |\n",
            "|    iterations         | 5800          |\n",
            "|    time_elapsed       | 62            |\n",
            "|    total_timesteps    | 29000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.47         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5799          |\n",
            "|    policy_loss        | -0.0119       |\n",
            "|    reward             | 0.00037081592 |\n",
            "|    std                | 7.81          |\n",
            "|    value_loss         | 4.32e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 465          |\n",
            "|    iterations         | 5900         |\n",
            "|    time_elapsed       | 63           |\n",
            "|    total_timesteps    | 29500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.5         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5899         |\n",
            "|    policy_loss        | -0.0122      |\n",
            "|    reward             | 0.0018078608 |\n",
            "|    std                | 7.99         |\n",
            "|    value_loss         | 4.42e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 464           |\n",
            "|    iterations         | 6000          |\n",
            "|    time_elapsed       | 64            |\n",
            "|    total_timesteps    | 30000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.53         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5999          |\n",
            "|    policy_loss        | 0.00388       |\n",
            "|    reward             | -0.0018538568 |\n",
            "|    std                | 8.28          |\n",
            "|    value_loss         | 4.37e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 464           |\n",
            "|    iterations         | 6100          |\n",
            "|    time_elapsed       | 65            |\n",
            "|    total_timesteps    | 30500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.57         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6099          |\n",
            "|    policy_loss        | 0.019         |\n",
            "|    reward             | 0.00011323077 |\n",
            "|    std                | 8.55          |\n",
            "|    value_loss         | 6.04e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 464         |\n",
            "|    iterations         | 6200        |\n",
            "|    time_elapsed       | 66          |\n",
            "|    total_timesteps    | 31000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.61       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6199        |\n",
            "|    policy_loss        | -0.00478    |\n",
            "|    reward             | 0.002396977 |\n",
            "|    std                | 8.95        |\n",
            "|    value_loss         | 8.3e-06     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 464           |\n",
            "|    iterations         | 6300          |\n",
            "|    time_elapsed       | 67            |\n",
            "|    total_timesteps    | 31500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.65         |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6299          |\n",
            "|    policy_loss        | -0.0214       |\n",
            "|    reward             | -0.0051517156 |\n",
            "|    std                | 9.3           |\n",
            "|    value_loss         | 3.52e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 464         |\n",
            "|    iterations         | 6400        |\n",
            "|    time_elapsed       | 68          |\n",
            "|    total_timesteps    | 32000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.67       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6399        |\n",
            "|    policy_loss        | 0.00184     |\n",
            "|    reward             | -0.01730615 |\n",
            "|    std                | 9.49        |\n",
            "|    value_loss         | 7.09e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 464          |\n",
            "|    iterations         | 6500         |\n",
            "|    time_elapsed       | 69           |\n",
            "|    total_timesteps    | 32500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.69        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6499         |\n",
            "|    policy_loss        | -0.00502     |\n",
            "|    reward             | 0.0070911883 |\n",
            "|    std                | 9.71         |\n",
            "|    value_loss         | 3.16e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 463          |\n",
            "|    iterations         | 6600         |\n",
            "|    time_elapsed       | 71           |\n",
            "|    total_timesteps    | 33000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.72        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6599         |\n",
            "|    policy_loss        | -0.0408      |\n",
            "|    reward             | 0.0067422707 |\n",
            "|    std                | 9.96         |\n",
            "|    value_loss         | 0.000137     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 463         |\n",
            "|    iterations         | 6700        |\n",
            "|    time_elapsed       | 72          |\n",
            "|    total_timesteps    | 33500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.75       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6699        |\n",
            "|    policy_loss        | 0.00609     |\n",
            "|    reward             | 0.029329717 |\n",
            "|    std                | 10.3        |\n",
            "|    value_loss         | 6.26e-06    |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 464            |\n",
            "|    iterations         | 6800           |\n",
            "|    time_elapsed       | 73             |\n",
            "|    total_timesteps    | 34000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -3.8           |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 6799           |\n",
            "|    policy_loss        | -0.0185        |\n",
            "|    reward             | -0.00017835894 |\n",
            "|    std                | 10.8           |\n",
            "|    value_loss         | 4.18e-05       |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 464         |\n",
            "|    iterations         | 6900        |\n",
            "|    time_elapsed       | 74          |\n",
            "|    total_timesteps    | 34500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.84       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6899        |\n",
            "|    policy_loss        | -0.0556     |\n",
            "|    reward             | 0.023832694 |\n",
            "|    std                | 11.2        |\n",
            "|    value_loss         | 0.000243    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 464         |\n",
            "|    iterations         | 7000        |\n",
            "|    time_elapsed       | 75          |\n",
            "|    total_timesteps    | 35000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.85       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6999        |\n",
            "|    policy_loss        | 0.044       |\n",
            "|    reward             | 0.002489807 |\n",
            "|    std                | 11.4        |\n",
            "|    value_loss         | 0.000174    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 463          |\n",
            "|    iterations         | 7100         |\n",
            "|    time_elapsed       | 76           |\n",
            "|    total_timesteps    | 35500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.88        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7099         |\n",
            "|    policy_loss        | 0.0334       |\n",
            "|    reward             | -0.007236182 |\n",
            "|    std                | 11.7         |\n",
            "|    value_loss         | 5.55e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 464           |\n",
            "|    iterations         | 7200          |\n",
            "|    time_elapsed       | 77            |\n",
            "|    total_timesteps    | 36000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.92         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7199          |\n",
            "|    policy_loss        | -0.00891      |\n",
            "|    reward             | -0.0028228692 |\n",
            "|    std                | 12.1          |\n",
            "|    value_loss         | 1.35e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 463          |\n",
            "|    iterations         | 7300         |\n",
            "|    time_elapsed       | 78           |\n",
            "|    total_timesteps    | 36500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.95        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7299         |\n",
            "|    policy_loss        | -0.0221      |\n",
            "|    reward             | 0.0003615557 |\n",
            "|    std                | 12.6         |\n",
            "|    value_loss         | 4.94e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 463          |\n",
            "|    iterations         | 7400         |\n",
            "|    time_elapsed       | 79           |\n",
            "|    total_timesteps    | 37000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.99        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7399         |\n",
            "|    policy_loss        | -0.0481      |\n",
            "|    reward             | 0.0012817897 |\n",
            "|    std                | 13.1         |\n",
            "|    value_loss         | 0.000203     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 463          |\n",
            "|    iterations         | 7500         |\n",
            "|    time_elapsed       | 80           |\n",
            "|    total_timesteps    | 37500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.02        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7499         |\n",
            "|    policy_loss        | 0.13         |\n",
            "|    reward             | -0.015347715 |\n",
            "|    std                | 13.5         |\n",
            "|    value_loss         | 0.00129      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 463         |\n",
            "|    iterations         | 7600        |\n",
            "|    time_elapsed       | 81          |\n",
            "|    total_timesteps    | 38000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.04       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7599        |\n",
            "|    policy_loss        | 0.0293      |\n",
            "|    reward             | 0.005474306 |\n",
            "|    std                | 13.8        |\n",
            "|    value_loss         | 4.34e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 463          |\n",
            "|    iterations         | 7700         |\n",
            "|    time_elapsed       | 83           |\n",
            "|    total_timesteps    | 38500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.06        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7699         |\n",
            "|    policy_loss        | 0.0103       |\n",
            "|    reward             | -0.003968981 |\n",
            "|    std                | 14.1         |\n",
            "|    value_loss         | 1.44e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 463           |\n",
            "|    iterations         | 7800          |\n",
            "|    time_elapsed       | 84            |\n",
            "|    total_timesteps    | 39000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.09         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7799          |\n",
            "|    policy_loss        | 0.000377      |\n",
            "|    reward             | 0.00026596102 |\n",
            "|    std                | 14.5          |\n",
            "|    value_loss         | 2.08e-06      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 463           |\n",
            "|    iterations         | 7900          |\n",
            "|    time_elapsed       | 85            |\n",
            "|    total_timesteps    | 39500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.12         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7899          |\n",
            "|    policy_loss        | -0.00418      |\n",
            "|    reward             | -0.0069011766 |\n",
            "|    std                | 14.9          |\n",
            "|    value_loss         | 8.88e-06      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 463          |\n",
            "|    iterations         | 8000         |\n",
            "|    time_elapsed       | 86           |\n",
            "|    total_timesteps    | 40000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.15        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7999         |\n",
            "|    policy_loss        | 0.071        |\n",
            "|    reward             | 0.0063228863 |\n",
            "|    std                | 15.4         |\n",
            "|    value_loss         | 0.000281     |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 463        |\n",
            "|    iterations         | 8100       |\n",
            "|    time_elapsed       | 87         |\n",
            "|    total_timesteps    | 40500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.18      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8099       |\n",
            "|    policy_loss        | -0.00792   |\n",
            "|    reward             | 0.00575305 |\n",
            "|    std                | 15.8       |\n",
            "|    value_loss         | 2.7e-05    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 463         |\n",
            "|    iterations         | 8200        |\n",
            "|    time_elapsed       | 88          |\n",
            "|    total_timesteps    | 41000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.2        |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8199        |\n",
            "|    policy_loss        | 0.0618      |\n",
            "|    reward             | 0.003756003 |\n",
            "|    std                | 16.2        |\n",
            "|    value_loss         | 0.000315    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 463           |\n",
            "|    iterations         | 8300          |\n",
            "|    time_elapsed       | 89            |\n",
            "|    total_timesteps    | 41500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.23         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8299          |\n",
            "|    policy_loss        | -0.0188       |\n",
            "|    reward             | 0.00015000284 |\n",
            "|    std                | 16.7          |\n",
            "|    value_loss         | 2.73e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 463           |\n",
            "|    iterations         | 8400          |\n",
            "|    time_elapsed       | 90            |\n",
            "|    total_timesteps    | 42000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.26         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8399          |\n",
            "|    policy_loss        | 0.034         |\n",
            "|    reward             | -4.221329e-06 |\n",
            "|    std                | 17.2          |\n",
            "|    value_loss         | 7.61e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 463         |\n",
            "|    iterations         | 8500        |\n",
            "|    time_elapsed       | 91          |\n",
            "|    total_timesteps    | 42500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.3        |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8499        |\n",
            "|    policy_loss        | -0.0688     |\n",
            "|    reward             | 0.009660174 |\n",
            "|    std                | 17.8        |\n",
            "|    value_loss         | 0.000257    |\n",
            "---------------------------------------\n",
            "day: 2854, episode: 15\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 7589.43\n",
            "total_reward: -2410.57\n",
            "total_cost: 119.97\n",
            "total_trades: 2854\n",
            "Sharpe: -0.116\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 463          |\n",
            "|    iterations         | 8600         |\n",
            "|    time_elapsed       | 92           |\n",
            "|    total_timesteps    | 43000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.34        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8599         |\n",
            "|    policy_loss        | -0.0557      |\n",
            "|    reward             | -0.021765148 |\n",
            "|    std                | 18.5         |\n",
            "|    value_loss         | 0.00026      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 463           |\n",
            "|    iterations         | 8700          |\n",
            "|    time_elapsed       | 93            |\n",
            "|    total_timesteps    | 43500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.37         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8699          |\n",
            "|    policy_loss        | -0.0992       |\n",
            "|    reward             | -0.0071266554 |\n",
            "|    std                | 19.1          |\n",
            "|    value_loss         | 0.000627      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 463         |\n",
            "|    iterations         | 8800        |\n",
            "|    time_elapsed       | 94          |\n",
            "|    total_timesteps    | 44000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.4        |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8799        |\n",
            "|    policy_loss        | -0.0456     |\n",
            "|    reward             | 0.006956446 |\n",
            "|    std                | 19.7        |\n",
            "|    value_loss         | 0.000131    |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 463            |\n",
            "|    iterations         | 8900           |\n",
            "|    time_elapsed       | 96             |\n",
            "|    total_timesteps    | 44500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -4.44          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 8899           |\n",
            "|    policy_loss        | -0.029         |\n",
            "|    reward             | -0.00071232906 |\n",
            "|    std                | 20.4           |\n",
            "|    value_loss         | 5.92e-05       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 463          |\n",
            "|    iterations         | 9000         |\n",
            "|    time_elapsed       | 97           |\n",
            "|    total_timesteps    | 45000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.48        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8999         |\n",
            "|    policy_loss        | 0.0904       |\n",
            "|    reward             | 0.0066226674 |\n",
            "|    std                | 21.3         |\n",
            "|    value_loss         | 0.000516     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 463          |\n",
            "|    iterations         | 9100         |\n",
            "|    time_elapsed       | 98           |\n",
            "|    total_timesteps    | 45500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.52        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9099         |\n",
            "|    policy_loss        | -0.0572      |\n",
            "|    reward             | -0.008246336 |\n",
            "|    std                | 22.3         |\n",
            "|    value_loss         | 0.000206     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 463         |\n",
            "|    iterations         | 9200        |\n",
            "|    time_elapsed       | 99          |\n",
            "|    total_timesteps    | 46000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.56       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9199        |\n",
            "|    policy_loss        | -0.163      |\n",
            "|    reward             | 0.020802619 |\n",
            "|    std                | 23.1        |\n",
            "|    value_loss         | 0.00147     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 463           |\n",
            "|    iterations         | 9300          |\n",
            "|    time_elapsed       | 100           |\n",
            "|    total_timesteps    | 46500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.57         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9299          |\n",
            "|    policy_loss        | -0.0263       |\n",
            "|    reward             | -0.0054241917 |\n",
            "|    std                | 23.3          |\n",
            "|    value_loss         | 6.46e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 463          |\n",
            "|    iterations         | 9400         |\n",
            "|    time_elapsed       | 101          |\n",
            "|    total_timesteps    | 47000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.59        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9399         |\n",
            "|    policy_loss        | 0.0221       |\n",
            "|    reward             | 0.0024159022 |\n",
            "|    std                | 23.8         |\n",
            "|    value_loss         | 5.94e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 463           |\n",
            "|    iterations         | 9500          |\n",
            "|    time_elapsed       | 102           |\n",
            "|    total_timesteps    | 47500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.62         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9499          |\n",
            "|    policy_loss        | 0.00892       |\n",
            "|    reward             | 0.00088879064 |\n",
            "|    std                | 24.6          |\n",
            "|    value_loss         | 1.09e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 463           |\n",
            "|    iterations         | 9600          |\n",
            "|    time_elapsed       | 103           |\n",
            "|    total_timesteps    | 48000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.66         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9599          |\n",
            "|    policy_loss        | 0.00382       |\n",
            "|    reward             | -0.0014177992 |\n",
            "|    std                | 25.6          |\n",
            "|    value_loss         | 1.85e-06      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 463          |\n",
            "|    iterations         | 9700         |\n",
            "|    time_elapsed       | 104          |\n",
            "|    total_timesteps    | 48500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.69        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9699         |\n",
            "|    policy_loss        | -0.0829      |\n",
            "|    reward             | 0.0028195523 |\n",
            "|    std                | 26.3         |\n",
            "|    value_loss         | 0.000351     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 463          |\n",
            "|    iterations         | 9800         |\n",
            "|    time_elapsed       | 105          |\n",
            "|    total_timesteps    | 49000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.72        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9799         |\n",
            "|    policy_loss        | 0.111        |\n",
            "|    reward             | -0.018828496 |\n",
            "|    std                | 27.2         |\n",
            "|    value_loss         | 0.000495     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 463         |\n",
            "|    iterations         | 9900        |\n",
            "|    time_elapsed       | 106         |\n",
            "|    total_timesteps    | 49500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.75       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9899        |\n",
            "|    policy_loss        | -0.152      |\n",
            "|    reward             | 0.028833967 |\n",
            "|    std                | 28          |\n",
            "|    value_loss         | 0.00115     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 463          |\n",
            "|    iterations         | 10000        |\n",
            "|    time_elapsed       | 107          |\n",
            "|    total_timesteps    | 50000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.78        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9999         |\n",
            "|    policy_loss        | 0.0219       |\n",
            "|    reward             | 0.0018210121 |\n",
            "|    std                | 29           |\n",
            "|    value_loss         | 3.13e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 463           |\n",
            "|    iterations         | 10100         |\n",
            "|    time_elapsed       | 108           |\n",
            "|    total_timesteps    | 50500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.82         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10099         |\n",
            "|    policy_loss        | -0.0028       |\n",
            "|    reward             | -0.0057237246 |\n",
            "|    std                | 30.1          |\n",
            "|    value_loss         | 4.1e-06       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 463         |\n",
            "|    iterations         | 10200       |\n",
            "|    time_elapsed       | 109         |\n",
            "|    total_timesteps    | 51000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.87       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10199       |\n",
            "|    policy_loss        | 0.00158     |\n",
            "|    reward             | -0.00571784 |\n",
            "|    std                | 31.5        |\n",
            "|    value_loss         | 1.11e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 463          |\n",
            "|    iterations         | 10300        |\n",
            "|    time_elapsed       | 111          |\n",
            "|    total_timesteps    | 51500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.91        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10299        |\n",
            "|    policy_loss        | -0.0431      |\n",
            "|    reward             | -0.008287513 |\n",
            "|    std                | 33           |\n",
            "|    value_loss         | 0.000102     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 463         |\n",
            "|    iterations         | 10400       |\n",
            "|    time_elapsed       | 112         |\n",
            "|    total_timesteps    | 52000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.94       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10399       |\n",
            "|    policy_loss        | 0.0339      |\n",
            "|    reward             | 0.021120453 |\n",
            "|    std                | 33.9        |\n",
            "|    value_loss         | 6.83e-05    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 463           |\n",
            "|    iterations         | 10500         |\n",
            "|    time_elapsed       | 113           |\n",
            "|    total_timesteps    | 52500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.96         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10499         |\n",
            "|    policy_loss        | -0.0964       |\n",
            "|    reward             | -0.0012844374 |\n",
            "|    std                | 34.5          |\n",
            "|    value_loss         | 0.000414      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 463           |\n",
            "|    iterations         | 10600         |\n",
            "|    time_elapsed       | 114           |\n",
            "|    total_timesteps    | 53000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.97         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10599         |\n",
            "|    policy_loss        | -0.00572      |\n",
            "|    reward             | -0.0040131137 |\n",
            "|    std                | 35            |\n",
            "|    value_loss         | 6.25e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 463           |\n",
            "|    iterations         | 10700         |\n",
            "|    time_elapsed       | 115           |\n",
            "|    total_timesteps    | 53500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.99         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10699         |\n",
            "|    policy_loss        | -0.0349       |\n",
            "|    reward             | -0.0079312315 |\n",
            "|    std                | 35.6          |\n",
            "|    value_loss         | 6.5e-05       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 463         |\n",
            "|    iterations         | 10800       |\n",
            "|    time_elapsed       | 116         |\n",
            "|    total_timesteps    | 54000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -5.02       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10799       |\n",
            "|    policy_loss        | -0.0228     |\n",
            "|    reward             | 0.008694729 |\n",
            "|    std                | 36.5        |\n",
            "|    value_loss         | 3.38e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 463          |\n",
            "|    iterations         | 10900        |\n",
            "|    time_elapsed       | 117          |\n",
            "|    total_timesteps    | 54500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -5.05        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10899        |\n",
            "|    policy_loss        | -0.0314      |\n",
            "|    reward             | 0.0052119694 |\n",
            "|    std                | 37.8         |\n",
            "|    value_loss         | 0.000119     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 463            |\n",
            "|    iterations         | 11000          |\n",
            "|    time_elapsed       | 118            |\n",
            "|    total_timesteps    | 55000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -5.07          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 10999          |\n",
            "|    policy_loss        | 0.0308         |\n",
            "|    reward             | -2.9868302e-06 |\n",
            "|    std                | 38.4           |\n",
            "|    value_loss         | 6e-05          |\n",
            "------------------------------------------\n",
            "======A2C Validation from:  2021-08-04 to  2021-09-02\n",
            "A2C Sharpe Ratio:  -0.5513943428207454\n",
            "======Best Model Retraining from:  2010-04-01 to  2021-09-02\n",
            "======Trading from:  2021-09-02 to  2021-10-04\n",
            "[[ 1.4597488e+04  2.8414133e+01 -1.9300000e+02  3.8091409e-01\n",
            "   2.8720968e+01  2.6922543e+01  5.9895725e+01  8.4576836e+01\n",
            "   1.5103782e+01  2.7489805e+01  2.7001869e+01]]\n",
            "============================================\n",
            "turbulence_threshold:  12.04306128869847\n",
            "======Model training from:  2010-04-01 to  2021-09-02\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c\\a2c_210_1\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 488           |\n",
            "|    iterations         | 100           |\n",
            "|    time_elapsed       | 1             |\n",
            "|    total_timesteps    | 500           |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.44         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 99            |\n",
            "|    policy_loss        | -0.0159       |\n",
            "|    reward             | -0.0059313043 |\n",
            "|    std                | 1.03          |\n",
            "|    value_loss         | 0.000209      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 477         |\n",
            "|    iterations         | 200         |\n",
            "|    time_elapsed       | 2           |\n",
            "|    total_timesteps    | 1000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.47       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 199         |\n",
            "|    policy_loss        | 0.00488     |\n",
            "|    reward             | 0.002452579 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 7.71e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 463          |\n",
            "|    iterations         | 300          |\n",
            "|    time_elapsed       | 3            |\n",
            "|    total_timesteps    | 1500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.5         |\n",
            "|    explained_variance | -3.58e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 299          |\n",
            "|    policy_loss        | 0.00699      |\n",
            "|    reward             | -0.009164192 |\n",
            "|    std                | 1.09         |\n",
            "|    value_loss         | 2.38e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 459           |\n",
            "|    iterations         | 400           |\n",
            "|    time_elapsed       | 4             |\n",
            "|    total_timesteps    | 2000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.54         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 399           |\n",
            "|    policy_loss        | -0.0097       |\n",
            "|    reward             | -0.0014704225 |\n",
            "|    std                | 1.13          |\n",
            "|    value_loss         | 8.88e-05      |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 463        |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 5          |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.57      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | 0.00499    |\n",
            "|    reward             | 0.03383346 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 0.000202   |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 462           |\n",
            "|    iterations         | 600           |\n",
            "|    time_elapsed       | 6             |\n",
            "|    total_timesteps    | 3000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.6          |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 599           |\n",
            "|    policy_loss        | -0.0156       |\n",
            "|    reward             | -0.0074878414 |\n",
            "|    std                | 1.2           |\n",
            "|    value_loss         | 0.000138      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 461         |\n",
            "|    iterations         | 700         |\n",
            "|    time_elapsed       | 7           |\n",
            "|    total_timesteps    | 3500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.62       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 699         |\n",
            "|    policy_loss        | -0.038      |\n",
            "|    reward             | 0.010739602 |\n",
            "|    std                | 1.22        |\n",
            "|    value_loss         | 0.000906    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 464           |\n",
            "|    iterations         | 800           |\n",
            "|    time_elapsed       | 8             |\n",
            "|    total_timesteps    | 4000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.64         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 799           |\n",
            "|    policy_loss        | -0.0167       |\n",
            "|    reward             | 0.00085523643 |\n",
            "|    std                | 1.24          |\n",
            "|    value_loss         | 0.000152      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 461         |\n",
            "|    iterations         | 900         |\n",
            "|    time_elapsed       | 9           |\n",
            "|    total_timesteps    | 4500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.67       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 899         |\n",
            "|    policy_loss        | -0.0073     |\n",
            "|    reward             | 0.018511225 |\n",
            "|    std                | 1.28        |\n",
            "|    value_loss         | 2.31e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 462          |\n",
            "|    iterations         | 1000         |\n",
            "|    time_elapsed       | 10           |\n",
            "|    total_timesteps    | 5000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.7         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 999          |\n",
            "|    policy_loss        | 0.0053       |\n",
            "|    reward             | 0.0020715995 |\n",
            "|    std                | 1.32         |\n",
            "|    value_loss         | 6e-06        |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 459           |\n",
            "|    iterations         | 1100          |\n",
            "|    time_elapsed       | 11            |\n",
            "|    total_timesteps    | 5500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.72         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1099          |\n",
            "|    policy_loss        | -0.0112       |\n",
            "|    reward             | -0.0073925466 |\n",
            "|    std                | 1.36          |\n",
            "|    value_loss         | 4.3e-05       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 459           |\n",
            "|    iterations         | 1200          |\n",
            "|    time_elapsed       | 13            |\n",
            "|    total_timesteps    | 6000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.75         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1199          |\n",
            "|    policy_loss        | 0.0382        |\n",
            "|    reward             | -0.0007684177 |\n",
            "|    std                | 1.4           |\n",
            "|    value_loss         | 0.000653      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 458          |\n",
            "|    iterations         | 1300         |\n",
            "|    time_elapsed       | 14           |\n",
            "|    total_timesteps    | 6500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.76        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1299         |\n",
            "|    policy_loss        | 0.0177       |\n",
            "|    reward             | 0.0026109198 |\n",
            "|    std                | 1.41         |\n",
            "|    value_loss         | 8.2e-05      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 455           |\n",
            "|    iterations         | 1400          |\n",
            "|    time_elapsed       | 15            |\n",
            "|    total_timesteps    | 7000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.79         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1399          |\n",
            "|    policy_loss        | 0.000948      |\n",
            "|    reward             | -0.0041605583 |\n",
            "|    std                | 1.45          |\n",
            "|    value_loss         | 2.03e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 455           |\n",
            "|    iterations         | 1500          |\n",
            "|    time_elapsed       | 16            |\n",
            "|    total_timesteps    | 7500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.82         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1499          |\n",
            "|    policy_loss        | 0.00397       |\n",
            "|    reward             | 0.00053054333 |\n",
            "|    std                | 1.5           |\n",
            "|    value_loss         | 7.7e-06       |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 455        |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 17         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.86      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | 0.00704    |\n",
            "|    reward             | 0.00345067 |\n",
            "|    std                | 1.55       |\n",
            "|    value_loss         | 1.62e-05   |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 455           |\n",
            "|    iterations         | 1700          |\n",
            "|    time_elapsed       | 18            |\n",
            "|    total_timesteps    | 8500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.89         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1699          |\n",
            "|    policy_loss        | 0.00477       |\n",
            "|    reward             | -0.0011171468 |\n",
            "|    std                | 1.61          |\n",
            "|    value_loss         | 1.76e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 455          |\n",
            "|    iterations         | 1800         |\n",
            "|    time_elapsed       | 19           |\n",
            "|    total_timesteps    | 9000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.93        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1799         |\n",
            "|    policy_loss        | -0.00182     |\n",
            "|    reward             | 0.0064426903 |\n",
            "|    std                | 1.67         |\n",
            "|    value_loss         | 4.1e-06      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 456          |\n",
            "|    iterations         | 1900         |\n",
            "|    time_elapsed       | 20           |\n",
            "|    total_timesteps    | 9500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.96        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1899         |\n",
            "|    policy_loss        | -0.0164      |\n",
            "|    reward             | -0.004788365 |\n",
            "|    std                | 1.72         |\n",
            "|    value_loss         | 9.95e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 456           |\n",
            "|    iterations         | 2000          |\n",
            "|    time_elapsed       | 21            |\n",
            "|    total_timesteps    | 10000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.99         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1999          |\n",
            "|    policy_loss        | 0.012         |\n",
            "|    reward             | -0.0011253331 |\n",
            "|    std                | 1.76          |\n",
            "|    value_loss         | 5.58e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 456         |\n",
            "|    iterations         | 2100        |\n",
            "|    time_elapsed       | 22          |\n",
            "|    total_timesteps    | 10500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.02       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2099        |\n",
            "|    policy_loss        | -0.00547    |\n",
            "|    reward             | 0.005611998 |\n",
            "|    std                | 1.82        |\n",
            "|    value_loss         | 1.13e-05    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 456           |\n",
            "|    iterations         | 2200          |\n",
            "|    time_elapsed       | 24            |\n",
            "|    total_timesteps    | 11000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.06         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2199          |\n",
            "|    policy_loss        | 0.0112        |\n",
            "|    reward             | -0.0064036534 |\n",
            "|    std                | 1.9           |\n",
            "|    value_loss         | 5.08e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 456           |\n",
            "|    iterations         | 2300          |\n",
            "|    time_elapsed       | 25            |\n",
            "|    total_timesteps    | 11500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.09         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2299          |\n",
            "|    policy_loss        | -0.00366      |\n",
            "|    reward             | -0.0011875898 |\n",
            "|    std                | 1.96          |\n",
            "|    value_loss         | 1.15e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 456         |\n",
            "|    iterations         | 2400        |\n",
            "|    time_elapsed       | 26          |\n",
            "|    total_timesteps    | 12000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.13       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2399        |\n",
            "|    policy_loss        | -0.00536    |\n",
            "|    reward             | 0.008002392 |\n",
            "|    std                | 2.05        |\n",
            "|    value_loss         | 1.45e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 456         |\n",
            "|    iterations         | 2500        |\n",
            "|    time_elapsed       | 27          |\n",
            "|    total_timesteps    | 12500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.16       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2499        |\n",
            "|    policy_loss        | 0.033       |\n",
            "|    reward             | -0.00818452 |\n",
            "|    std                | 2.11        |\n",
            "|    value_loss         | 0.000262    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 457          |\n",
            "|    iterations         | 2600         |\n",
            "|    time_elapsed       | 28           |\n",
            "|    total_timesteps    | 13000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.2         |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2599         |\n",
            "|    policy_loss        | -0.0206      |\n",
            "|    reward             | -0.013465964 |\n",
            "|    std                | 2.18         |\n",
            "|    value_loss         | 0.000123     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 457           |\n",
            "|    iterations         | 2700          |\n",
            "|    time_elapsed       | 29            |\n",
            "|    total_timesteps    | 13500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.22         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2699          |\n",
            "|    policy_loss        | 0.011         |\n",
            "|    reward             | 0.00096480834 |\n",
            "|    std                | 2.24          |\n",
            "|    value_loss         | 1.08e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 457         |\n",
            "|    iterations         | 2800        |\n",
            "|    time_elapsed       | 30          |\n",
            "|    total_timesteps    | 14000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.27       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2799        |\n",
            "|    policy_loss        | 0.0369      |\n",
            "|    reward             | 0.001646267 |\n",
            "|    std                | 2.33        |\n",
            "|    value_loss         | 0.000341    |\n",
            "---------------------------------------\n",
            "day: 2875, episode: 5\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 8156.20\n",
            "total_reward: -1843.80\n",
            "total_cost: 141.57\n",
            "total_trades: 2875\n",
            "Sharpe: -0.090\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 457        |\n",
            "|    iterations         | 2900       |\n",
            "|    time_elapsed       | 31         |\n",
            "|    total_timesteps    | 14500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.3       |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2899       |\n",
            "|    policy_loss        | -0.0171    |\n",
            "|    reward             | 0.00916725 |\n",
            "|    std                | 2.42       |\n",
            "|    value_loss         | 8.22e-05   |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 457          |\n",
            "|    iterations         | 3000         |\n",
            "|    time_elapsed       | 32           |\n",
            "|    total_timesteps    | 15000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.34        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2999         |\n",
            "|    policy_loss        | -0.0416      |\n",
            "|    reward             | 0.0018295101 |\n",
            "|    std                | 2.52         |\n",
            "|    value_loss         | 0.000429     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 457          |\n",
            "|    iterations         | 3100         |\n",
            "|    time_elapsed       | 33           |\n",
            "|    total_timesteps    | 15500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.37        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3099         |\n",
            "|    policy_loss        | -0.00894     |\n",
            "|    reward             | 0.0075766733 |\n",
            "|    std                | 2.6          |\n",
            "|    value_loss         | 1.13e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 457           |\n",
            "|    iterations         | 3200          |\n",
            "|    time_elapsed       | 34            |\n",
            "|    total_timesteps    | 16000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.41         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3199          |\n",
            "|    policy_loss        | 0.00102       |\n",
            "|    reward             | 0.00038973344 |\n",
            "|    std                | 2.68          |\n",
            "|    value_loss         | 2.19e-06      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 457          |\n",
            "|    iterations         | 3300         |\n",
            "|    time_elapsed       | 36           |\n",
            "|    total_timesteps    | 16500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.44        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3299         |\n",
            "|    policy_loss        | -0.0132      |\n",
            "|    reward             | 0.0008910468 |\n",
            "|    std                | 2.76         |\n",
            "|    value_loss         | 2.82e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 456         |\n",
            "|    iterations         | 3400        |\n",
            "|    time_elapsed       | 37          |\n",
            "|    total_timesteps    | 17000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.48       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3399        |\n",
            "|    policy_loss        | 0.0282      |\n",
            "|    reward             | 0.003923022 |\n",
            "|    std                | 2.88        |\n",
            "|    value_loss         | 0.000219    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 457           |\n",
            "|    iterations         | 3500          |\n",
            "|    time_elapsed       | 38            |\n",
            "|    total_timesteps    | 17500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.51         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3499          |\n",
            "|    policy_loss        | 0.0158        |\n",
            "|    reward             | -0.0026157913 |\n",
            "|    std                | 2.97          |\n",
            "|    value_loss         | 0.000156      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 456            |\n",
            "|    iterations         | 3600           |\n",
            "|    time_elapsed       | 39             |\n",
            "|    total_timesteps    | 18000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -2.54          |\n",
            "|    explained_variance | 1.19e-07       |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 3599           |\n",
            "|    policy_loss        | -0.0188        |\n",
            "|    reward             | -0.00075700914 |\n",
            "|    std                | 3.07           |\n",
            "|    value_loss         | 0.000119       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 457           |\n",
            "|    iterations         | 3700          |\n",
            "|    time_elapsed       | 40            |\n",
            "|    total_timesteps    | 18500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.58         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3699          |\n",
            "|    policy_loss        | 0.0279        |\n",
            "|    reward             | -0.0023785948 |\n",
            "|    std                | 3.18          |\n",
            "|    value_loss         | 0.000102      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 457           |\n",
            "|    iterations         | 3800          |\n",
            "|    time_elapsed       | 41            |\n",
            "|    total_timesteps    | 19000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.61         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3799          |\n",
            "|    policy_loss        | 0.0164        |\n",
            "|    reward             | 0.00012144125 |\n",
            "|    std                | 3.3           |\n",
            "|    value_loss         | 5.41e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 457           |\n",
            "|    iterations         | 3900          |\n",
            "|    time_elapsed       | 42            |\n",
            "|    total_timesteps    | 19500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.65         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3899          |\n",
            "|    policy_loss        | -0.00981      |\n",
            "|    reward             | 0.00035638822 |\n",
            "|    std                | 3.43          |\n",
            "|    value_loss         | 2.36e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 457          |\n",
            "|    iterations         | 4000         |\n",
            "|    time_elapsed       | 43           |\n",
            "|    total_timesteps    | 20000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.69        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3999         |\n",
            "|    policy_loss        | 0.0552       |\n",
            "|    reward             | 0.0017348105 |\n",
            "|    std                | 3.57         |\n",
            "|    value_loss         | 0.000684     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 457         |\n",
            "|    iterations         | 4100        |\n",
            "|    time_elapsed       | 44          |\n",
            "|    total_timesteps    | 20500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.73       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4099        |\n",
            "|    policy_loss        | -0.0652     |\n",
            "|    reward             | 0.015785046 |\n",
            "|    std                | 3.7         |\n",
            "|    value_loss         | 0.000478    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 457         |\n",
            "|    iterations         | 4200        |\n",
            "|    time_elapsed       | 45          |\n",
            "|    total_timesteps    | 21000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.75       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4199        |\n",
            "|    policy_loss        | -0.062      |\n",
            "|    reward             | 0.004758066 |\n",
            "|    std                | 3.79        |\n",
            "|    value_loss         | 0.000677    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 458           |\n",
            "|    iterations         | 4300          |\n",
            "|    time_elapsed       | 46            |\n",
            "|    total_timesteps    | 21500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.78         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4299          |\n",
            "|    policy_loss        | -0.0077       |\n",
            "|    reward             | -0.0075960234 |\n",
            "|    std                | 3.9           |\n",
            "|    value_loss         | 3.63e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 458          |\n",
            "|    iterations         | 4400         |\n",
            "|    time_elapsed       | 48           |\n",
            "|    total_timesteps    | 22000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.82        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4399         |\n",
            "|    policy_loss        | -0.0142      |\n",
            "|    reward             | -0.001026437 |\n",
            "|    std                | 4.06         |\n",
            "|    value_loss         | 2.74e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 458          |\n",
            "|    iterations         | 4500         |\n",
            "|    time_elapsed       | 49           |\n",
            "|    total_timesteps    | 22500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.86        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4499         |\n",
            "|    policy_loss        | -0.00805     |\n",
            "|    reward             | 0.0010401688 |\n",
            "|    std                | 4.22         |\n",
            "|    value_loss         | 3.24e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 458           |\n",
            "|    iterations         | 4600          |\n",
            "|    time_elapsed       | 50            |\n",
            "|    total_timesteps    | 23000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.89         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4599          |\n",
            "|    policy_loss        | -0.00705      |\n",
            "|    reward             | -0.0018909056 |\n",
            "|    std                | 4.36          |\n",
            "|    value_loss         | 1.52e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 457         |\n",
            "|    iterations         | 4700        |\n",
            "|    time_elapsed       | 51          |\n",
            "|    total_timesteps    | 23500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.92       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4699        |\n",
            "|    policy_loss        | 0.015       |\n",
            "|    reward             | 0.012126009 |\n",
            "|    std                | 4.47        |\n",
            "|    value_loss         | 0.000137    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 457           |\n",
            "|    iterations         | 4800          |\n",
            "|    time_elapsed       | 52            |\n",
            "|    total_timesteps    | 24000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.94         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4799          |\n",
            "|    policy_loss        | 0.0282        |\n",
            "|    reward             | -0.0014806842 |\n",
            "|    std                | 4.6           |\n",
            "|    value_loss         | 0.000106      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 458         |\n",
            "|    iterations         | 4900        |\n",
            "|    time_elapsed       | 53          |\n",
            "|    total_timesteps    | 24500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.97       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4899        |\n",
            "|    policy_loss        | -0.00742    |\n",
            "|    reward             | 0.000759289 |\n",
            "|    std                | 4.73        |\n",
            "|    value_loss         | 1.09e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 458          |\n",
            "|    iterations         | 5000         |\n",
            "|    time_elapsed       | 54           |\n",
            "|    total_timesteps    | 25000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.01        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4999         |\n",
            "|    policy_loss        | 0.00434      |\n",
            "|    reward             | 0.0065973205 |\n",
            "|    std                | 4.9          |\n",
            "|    value_loss         | 2.13e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 459          |\n",
            "|    iterations         | 5100         |\n",
            "|    time_elapsed       | 55           |\n",
            "|    total_timesteps    | 25500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.05        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5099         |\n",
            "|    policy_loss        | 0.0204       |\n",
            "|    reward             | 0.0043096812 |\n",
            "|    std                | 5.12         |\n",
            "|    value_loss         | 7.29e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 460          |\n",
            "|    iterations         | 5200         |\n",
            "|    time_elapsed       | 56           |\n",
            "|    total_timesteps    | 26000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.1         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5199         |\n",
            "|    policy_loss        | 0.0217       |\n",
            "|    reward             | -0.006338975 |\n",
            "|    std                | 5.39         |\n",
            "|    value_loss         | 0.000183     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 461         |\n",
            "|    iterations         | 5300        |\n",
            "|    time_elapsed       | 57          |\n",
            "|    total_timesteps    | 26500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.13       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5299        |\n",
            "|    policy_loss        | 0.0533      |\n",
            "|    reward             | 0.012339911 |\n",
            "|    std                | 5.54        |\n",
            "|    value_loss         | 0.000264    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 462          |\n",
            "|    iterations         | 5400         |\n",
            "|    time_elapsed       | 58           |\n",
            "|    total_timesteps    | 27000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.15        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5399         |\n",
            "|    policy_loss        | 0.00912      |\n",
            "|    reward             | -0.002501078 |\n",
            "|    std                | 5.67         |\n",
            "|    value_loss         | 2.61e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 464          |\n",
            "|    iterations         | 5500         |\n",
            "|    time_elapsed       | 59           |\n",
            "|    total_timesteps    | 27500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.19        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5499         |\n",
            "|    policy_loss        | -0.00909     |\n",
            "|    reward             | 0.0020707864 |\n",
            "|    std                | 5.87         |\n",
            "|    value_loss         | 1.67e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 464           |\n",
            "|    iterations         | 5600          |\n",
            "|    time_elapsed       | 60            |\n",
            "|    total_timesteps    | 28000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.23         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5599          |\n",
            "|    policy_loss        | -0.0397       |\n",
            "|    reward             | 0.00038334282 |\n",
            "|    std                | 6.11          |\n",
            "|    value_loss         | 0.0002        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 465          |\n",
            "|    iterations         | 5700         |\n",
            "|    time_elapsed       | 61           |\n",
            "|    total_timesteps    | 28500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.27        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5699         |\n",
            "|    policy_loss        | 0.0413       |\n",
            "|    reward             | 0.0010450442 |\n",
            "|    std                | 6.39         |\n",
            "|    value_loss         | 0.000229     |\n",
            "----------------------------------------\n",
            "day: 2875, episode: 10\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 8429.50\n",
            "total_reward: -1570.50\n",
            "total_cost: 129.52\n",
            "total_trades: 2875\n",
            "Sharpe: -0.027\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 466         |\n",
            "|    iterations         | 5800        |\n",
            "|    time_elapsed       | 62          |\n",
            "|    total_timesteps    | 29000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.31       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5799        |\n",
            "|    policy_loss        | -0.0268     |\n",
            "|    reward             | 0.017807428 |\n",
            "|    std                | 6.64        |\n",
            "|    value_loss         | 0.000128    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 467          |\n",
            "|    iterations         | 5900         |\n",
            "|    time_elapsed       | 63           |\n",
            "|    total_timesteps    | 29500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.34        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5899         |\n",
            "|    policy_loss        | 0.047        |\n",
            "|    reward             | 0.0022036352 |\n",
            "|    std                | 6.83         |\n",
            "|    value_loss         | 0.000143     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 468           |\n",
            "|    iterations         | 6000          |\n",
            "|    time_elapsed       | 64            |\n",
            "|    total_timesteps    | 30000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.37         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5999          |\n",
            "|    policy_loss        | 0.0185        |\n",
            "|    reward             | -0.0065405797 |\n",
            "|    std                | 7.02          |\n",
            "|    value_loss         | 4.28e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 468           |\n",
            "|    iterations         | 6100          |\n",
            "|    time_elapsed       | 65            |\n",
            "|    total_timesteps    | 30500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.4          |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6099          |\n",
            "|    policy_loss        | -0.0103       |\n",
            "|    reward             | -0.0034823017 |\n",
            "|    std                | 7.23          |\n",
            "|    value_loss         | 2.12e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 469           |\n",
            "|    iterations         | 6200          |\n",
            "|    time_elapsed       | 66            |\n",
            "|    total_timesteps    | 31000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.43         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6199          |\n",
            "|    policy_loss        | -0.0261       |\n",
            "|    reward             | 0.00043881914 |\n",
            "|    std                | 7.49          |\n",
            "|    value_loss         | 6.75e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 469         |\n",
            "|    iterations         | 6300        |\n",
            "|    time_elapsed       | 67          |\n",
            "|    total_timesteps    | 31500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.46       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6299        |\n",
            "|    policy_loss        | -0.043      |\n",
            "|    reward             | 0.001206709 |\n",
            "|    std                | 7.73        |\n",
            "|    value_loss         | 0.000177    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 470         |\n",
            "|    iterations         | 6400        |\n",
            "|    time_elapsed       | 67          |\n",
            "|    total_timesteps    | 32000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.48       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6399        |\n",
            "|    policy_loss        | -0.0276     |\n",
            "|    reward             | 0.002352423 |\n",
            "|    std                | 7.89        |\n",
            "|    value_loss         | 0.000287    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 472           |\n",
            "|    iterations         | 6500          |\n",
            "|    time_elapsed       | 68            |\n",
            "|    total_timesteps    | 32500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.5          |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6499          |\n",
            "|    policy_loss        | 0.0396        |\n",
            "|    reward             | -0.0057491204 |\n",
            "|    std                | 8.04          |\n",
            "|    value_loss         | 0.000191      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 472         |\n",
            "|    iterations         | 6600        |\n",
            "|    time_elapsed       | 69          |\n",
            "|    total_timesteps    | 33000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.53       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6599        |\n",
            "|    policy_loss        | 0.117       |\n",
            "|    reward             | 0.012460763 |\n",
            "|    std                | 8.23        |\n",
            "|    value_loss         | 0.00152     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 472           |\n",
            "|    iterations         | 6700          |\n",
            "|    time_elapsed       | 70            |\n",
            "|    total_timesteps    | 33500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.56         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6699          |\n",
            "|    policy_loss        | 0.0118        |\n",
            "|    reward             | -0.0012363082 |\n",
            "|    std                | 8.51          |\n",
            "|    value_loss         | 2.16e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 472         |\n",
            "|    iterations         | 6800        |\n",
            "|    time_elapsed       | 71          |\n",
            "|    total_timesteps    | 34000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.59       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6799        |\n",
            "|    policy_loss        | 0.0819      |\n",
            "|    reward             | 0.000954031 |\n",
            "|    std                | 8.81        |\n",
            "|    value_loss         | 0.000547    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 473          |\n",
            "|    iterations         | 6900         |\n",
            "|    time_elapsed       | 72           |\n",
            "|    total_timesteps    | 34500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.63        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6899         |\n",
            "|    policy_loss        | 0.0228       |\n",
            "|    reward             | 0.0036813128 |\n",
            "|    std                | 9.15         |\n",
            "|    value_loss         | 7.96e-05     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 473            |\n",
            "|    iterations         | 7000           |\n",
            "|    time_elapsed       | 73             |\n",
            "|    total_timesteps    | 35000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -3.65          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 6999           |\n",
            "|    policy_loss        | 0.0798         |\n",
            "|    reward             | -0.00039078435 |\n",
            "|    std                | 9.3            |\n",
            "|    value_loss         | 0.000601       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 474          |\n",
            "|    iterations         | 7100         |\n",
            "|    time_elapsed       | 74           |\n",
            "|    total_timesteps    | 35500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.67        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7099         |\n",
            "|    policy_loss        | 0.0415       |\n",
            "|    reward             | -0.001306695 |\n",
            "|    std                | 9.51         |\n",
            "|    value_loss         | 0.000172     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 474          |\n",
            "|    iterations         | 7200         |\n",
            "|    time_elapsed       | 75           |\n",
            "|    total_timesteps    | 36000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.7         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7199         |\n",
            "|    policy_loss        | -0.0377      |\n",
            "|    reward             | -0.003348147 |\n",
            "|    std                | 9.78         |\n",
            "|    value_loss         | 0.000178     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 474           |\n",
            "|    iterations         | 7300          |\n",
            "|    time_elapsed       | 76            |\n",
            "|    total_timesteps    | 36500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.74         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7299          |\n",
            "|    policy_loss        | -0.0704       |\n",
            "|    reward             | -0.0011540523 |\n",
            "|    std                | 10.2          |\n",
            "|    value_loss         | 0.000494      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 475          |\n",
            "|    iterations         | 7400         |\n",
            "|    time_elapsed       | 77           |\n",
            "|    total_timesteps    | 37000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.78        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7399         |\n",
            "|    policy_loss        | -0.0437      |\n",
            "|    reward             | -0.005202368 |\n",
            "|    std                | 10.6         |\n",
            "|    value_loss         | 0.000249     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 475           |\n",
            "|    iterations         | 7500          |\n",
            "|    time_elapsed       | 78            |\n",
            "|    total_timesteps    | 37500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.81         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7499          |\n",
            "|    policy_loss        | -0.0777       |\n",
            "|    reward             | 0.00030097188 |\n",
            "|    std                | 10.9          |\n",
            "|    value_loss         | 0.000397      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 474          |\n",
            "|    iterations         | 7600         |\n",
            "|    time_elapsed       | 80           |\n",
            "|    total_timesteps    | 38000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.82        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7599         |\n",
            "|    policy_loss        | 0.0392       |\n",
            "|    reward             | -0.006683717 |\n",
            "|    std                | 11           |\n",
            "|    value_loss         | 0.000159     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 475            |\n",
            "|    iterations         | 7700           |\n",
            "|    time_elapsed       | 81             |\n",
            "|    total_timesteps    | 38500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -3.85          |\n",
            "|    explained_variance | 1.19e-07       |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 7699           |\n",
            "|    policy_loss        | -0.000254      |\n",
            "|    reward             | -1.9037783e-06 |\n",
            "|    std                | 11.4           |\n",
            "|    value_loss         | 2.71e-05       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 475          |\n",
            "|    iterations         | 7800         |\n",
            "|    time_elapsed       | 82           |\n",
            "|    total_timesteps    | 39000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.88        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7799         |\n",
            "|    policy_loss        | 0.0145       |\n",
            "|    reward             | -0.000533854 |\n",
            "|    std                | 11.8         |\n",
            "|    value_loss         | 4.11e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 475           |\n",
            "|    iterations         | 7900          |\n",
            "|    time_elapsed       | 83            |\n",
            "|    total_timesteps    | 39500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.93         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7899          |\n",
            "|    policy_loss        | -0.00445      |\n",
            "|    reward             | -0.0015945176 |\n",
            "|    std                | 12.3          |\n",
            "|    value_loss         | 3.65e-06      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 476         |\n",
            "|    iterations         | 8000        |\n",
            "|    time_elapsed       | 83          |\n",
            "|    total_timesteps    | 40000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.97       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7999        |\n",
            "|    policy_loss        | -0.0171     |\n",
            "|    reward             | 0.008955049 |\n",
            "|    std                | 12.8        |\n",
            "|    value_loss         | 2.51e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 476         |\n",
            "|    iterations         | 8100        |\n",
            "|    time_elapsed       | 84          |\n",
            "|    total_timesteps    | 40500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.02       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8099        |\n",
            "|    policy_loss        | 0.000169    |\n",
            "|    reward             | 0.014221145 |\n",
            "|    std                | 13.4        |\n",
            "|    value_loss         | 0.00013     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 477           |\n",
            "|    iterations         | 8200          |\n",
            "|    time_elapsed       | 85            |\n",
            "|    total_timesteps    | 41000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.05         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8199          |\n",
            "|    policy_loss        | 0.0443        |\n",
            "|    reward             | -0.0034921975 |\n",
            "|    std                | 13.9          |\n",
            "|    value_loss         | 0.000308      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 477           |\n",
            "|    iterations         | 8300          |\n",
            "|    time_elapsed       | 86            |\n",
            "|    total_timesteps    | 41500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.08         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8299          |\n",
            "|    policy_loss        | -0.0085       |\n",
            "|    reward             | -0.0019664534 |\n",
            "|    std                | 14.3          |\n",
            "|    value_loss         | 9.89e-06      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 478          |\n",
            "|    iterations         | 8400         |\n",
            "|    time_elapsed       | 87           |\n",
            "|    total_timesteps    | 42000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.1         |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8399         |\n",
            "|    policy_loss        | -0.0184      |\n",
            "|    reward             | 0.0014442427 |\n",
            "|    std                | 14.7         |\n",
            "|    value_loss         | 3.02e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 478           |\n",
            "|    iterations         | 8500          |\n",
            "|    time_elapsed       | 88            |\n",
            "|    total_timesteps    | 42500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.14         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8499          |\n",
            "|    policy_loss        | -0.0327       |\n",
            "|    reward             | -0.0005763855 |\n",
            "|    std                | 15.2          |\n",
            "|    value_loss         | 6.26e-05      |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 478        |\n",
            "|    iterations         | 8600       |\n",
            "|    time_elapsed       | 89         |\n",
            "|    total_timesteps    | 43000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.16      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8599       |\n",
            "|    policy_loss        | -0.00823   |\n",
            "|    reward             | 0.00978473 |\n",
            "|    std                | 15.5       |\n",
            "|    value_loss         | 1.86e-05   |\n",
            "--------------------------------------\n",
            "day: 2875, episode: 15\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 7703.55\n",
            "total_reward: -2296.45\n",
            "total_cost: 112.97\n",
            "total_trades: 2875\n",
            "Sharpe: -0.096\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 479         |\n",
            "|    iterations         | 8700        |\n",
            "|    time_elapsed       | 90          |\n",
            "|    total_timesteps    | 43500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.19       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8699        |\n",
            "|    policy_loss        | -0.0928     |\n",
            "|    reward             | 0.024815008 |\n",
            "|    std                | 16          |\n",
            "|    value_loss         | 0.000839    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 480           |\n",
            "|    iterations         | 8800          |\n",
            "|    time_elapsed       | 91            |\n",
            "|    total_timesteps    | 44000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.21         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8799          |\n",
            "|    policy_loss        | 0.0372        |\n",
            "|    reward             | -0.0005941759 |\n",
            "|    std                | 16.3          |\n",
            "|    value_loss         | 8.86e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 480          |\n",
            "|    iterations         | 8900         |\n",
            "|    time_elapsed       | 92           |\n",
            "|    total_timesteps    | 44500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.24        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8899         |\n",
            "|    policy_loss        | 0.0116       |\n",
            "|    reward             | -0.009808293 |\n",
            "|    std                | 16.9         |\n",
            "|    value_loss         | 8.13e-06     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 481           |\n",
            "|    iterations         | 9000          |\n",
            "|    time_elapsed       | 93            |\n",
            "|    total_timesteps    | 45000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.27         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8999          |\n",
            "|    policy_loss        | 0.00126       |\n",
            "|    reward             | 0.00029085483 |\n",
            "|    std                | 17.3          |\n",
            "|    value_loss         | 3.84e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 481           |\n",
            "|    iterations         | 9100          |\n",
            "|    time_elapsed       | 94            |\n",
            "|    total_timesteps    | 45500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.31         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9099          |\n",
            "|    policy_loss        | 0.00685       |\n",
            "|    reward             | -0.0062954053 |\n",
            "|    std                | 18.1          |\n",
            "|    value_loss         | 1.94e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 482         |\n",
            "|    iterations         | 9200        |\n",
            "|    time_elapsed       | 95          |\n",
            "|    total_timesteps    | 46000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.35       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9199        |\n",
            "|    policy_loss        | -0.0435     |\n",
            "|    reward             | -0.00370398 |\n",
            "|    std                | 18.7        |\n",
            "|    value_loss         | 0.000298    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 482          |\n",
            "|    iterations         | 9300         |\n",
            "|    time_elapsed       | 96           |\n",
            "|    total_timesteps    | 46500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.36        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9299         |\n",
            "|    policy_loss        | 0.0217       |\n",
            "|    reward             | 0.0075738365 |\n",
            "|    std                | 18.9         |\n",
            "|    value_loss         | 6.56e-05     |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 482        |\n",
            "|    iterations         | 9400       |\n",
            "|    time_elapsed       | 97         |\n",
            "|    total_timesteps    | 47000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.38      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9399       |\n",
            "|    policy_loss        | -0.0294    |\n",
            "|    reward             | 0.00619955 |\n",
            "|    std                | 19.3       |\n",
            "|    value_loss         | 6.58e-05   |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 482           |\n",
            "|    iterations         | 9500          |\n",
            "|    time_elapsed       | 98            |\n",
            "|    total_timesteps    | 47500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.41         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9499          |\n",
            "|    policy_loss        | -0.161        |\n",
            "|    reward             | -0.0063535664 |\n",
            "|    std                | 20            |\n",
            "|    value_loss         | 0.00169       |\n",
            "-----------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 483      |\n",
            "|    iterations         | 9600     |\n",
            "|    time_elapsed       | 99       |\n",
            "|    total_timesteps    | 48000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -4.45    |\n",
            "|    explained_variance | 1.79e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 9599     |\n",
            "|    policy_loss        | -0.0124  |\n",
            "|    reward             | 0.011354 |\n",
            "|    std                | 20.7     |\n",
            "|    value_loss         | 0.0001   |\n",
            "------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 483          |\n",
            "|    iterations         | 9700         |\n",
            "|    time_elapsed       | 100          |\n",
            "|    total_timesteps    | 48500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.48        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9699         |\n",
            "|    policy_loss        | -0.0056      |\n",
            "|    reward             | -0.009549554 |\n",
            "|    std                | 21.3         |\n",
            "|    value_loss         | 2.26e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 484         |\n",
            "|    iterations         | 9800        |\n",
            "|    time_elapsed       | 101         |\n",
            "|    total_timesteps    | 49000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.5        |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9799        |\n",
            "|    policy_loss        | -0.0531     |\n",
            "|    reward             | -0.02275244 |\n",
            "|    std                | 21.8        |\n",
            "|    value_loss         | 0.000189    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 484          |\n",
            "|    iterations         | 9900         |\n",
            "|    time_elapsed       | 102          |\n",
            "|    total_timesteps    | 49500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.54        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9899         |\n",
            "|    policy_loss        | 0.0046       |\n",
            "|    reward             | -0.016882494 |\n",
            "|    std                | 22.6         |\n",
            "|    value_loss         | 3.89e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 484          |\n",
            "|    iterations         | 10000        |\n",
            "|    time_elapsed       | 103          |\n",
            "|    total_timesteps    | 50000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.55        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9999         |\n",
            "|    policy_loss        | -0.0439      |\n",
            "|    reward             | 0.0053712497 |\n",
            "|    std                | 23           |\n",
            "|    value_loss         | 0.00012      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 485           |\n",
            "|    iterations         | 10100         |\n",
            "|    time_elapsed       | 104           |\n",
            "|    total_timesteps    | 50500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.59         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10099         |\n",
            "|    policy_loss        | -0.00496      |\n",
            "|    reward             | -0.0044811093 |\n",
            "|    std                | 23.8          |\n",
            "|    value_loss         | 3.59e-06      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 485           |\n",
            "|    iterations         | 10200         |\n",
            "|    time_elapsed       | 105           |\n",
            "|    total_timesteps    | 51000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.63         |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10199         |\n",
            "|    policy_loss        | -0.0314       |\n",
            "|    reward             | 0.00074062793 |\n",
            "|    std                | 24.8          |\n",
            "|    value_loss         | 5.49e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 485         |\n",
            "|    iterations         | 10300       |\n",
            "|    time_elapsed       | 106         |\n",
            "|    total_timesteps    | 51500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.67       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10299       |\n",
            "|    policy_loss        | -0.0411     |\n",
            "|    reward             | 0.009805678 |\n",
            "|    std                | 25.7        |\n",
            "|    value_loss         | 0.000141    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 485         |\n",
            "|    iterations         | 10400       |\n",
            "|    time_elapsed       | 107         |\n",
            "|    total_timesteps    | 52000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.7        |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10399       |\n",
            "|    policy_loss        | 0.0664      |\n",
            "|    reward             | -0.01619171 |\n",
            "|    std                | 26.5        |\n",
            "|    value_loss         | 0.00145     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 486          |\n",
            "|    iterations         | 10500        |\n",
            "|    time_elapsed       | 108          |\n",
            "|    total_timesteps    | 52500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.71        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10499        |\n",
            "|    policy_loss        | 0.0568       |\n",
            "|    reward             | 0.0009726403 |\n",
            "|    std                | 26.8         |\n",
            "|    value_loss         | 0.000198     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 486           |\n",
            "|    iterations         | 10600         |\n",
            "|    time_elapsed       | 108           |\n",
            "|    total_timesteps    | 53000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.73         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10599         |\n",
            "|    policy_loss        | -0.0494       |\n",
            "|    reward             | -0.0068105804 |\n",
            "|    std                | 27.4          |\n",
            "|    value_loss         | 0.000138      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 486           |\n",
            "|    iterations         | 10700         |\n",
            "|    time_elapsed       | 109           |\n",
            "|    total_timesteps    | 53500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.75         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10699         |\n",
            "|    policy_loss        | -0.00564      |\n",
            "|    reward             | -0.0018388379 |\n",
            "|    std                | 28.1          |\n",
            "|    value_loss         | 2.49e-06      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 487           |\n",
            "|    iterations         | 10800         |\n",
            "|    time_elapsed       | 110           |\n",
            "|    total_timesteps    | 54000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.79         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10799         |\n",
            "|    policy_loss        | -0.0295       |\n",
            "|    reward             | -0.0016707889 |\n",
            "|    std                | 29.2          |\n",
            "|    value_loss         | 4.17e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 487         |\n",
            "|    iterations         | 10900       |\n",
            "|    time_elapsed       | 111         |\n",
            "|    total_timesteps    | 54500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.83       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10899       |\n",
            "|    policy_loss        | 0.0984      |\n",
            "|    reward             | -0.00953384 |\n",
            "|    std                | 30.2        |\n",
            "|    value_loss         | 0.000771    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 487          |\n",
            "|    iterations         | 11000        |\n",
            "|    time_elapsed       | 112          |\n",
            "|    total_timesteps    | 55000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.88        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10999        |\n",
            "|    policy_loss        | 0.211        |\n",
            "|    reward             | -0.027959082 |\n",
            "|    std                | 31.8         |\n",
            "|    value_loss         | 0.0017       |\n",
            "----------------------------------------\n",
            "======A2C Validation from:  2021-09-02 to  2021-10-04\n",
            "A2C Sharpe Ratio:  0.2076557656175653\n",
            "======Best Model Retraining from:  2010-04-01 to  2021-10-04\n",
            "======Trading from:  2021-10-04 to  2021-11-02\n",
            "[[ 1.4544639e+04  2.6885557e+01 -1.9100000e+02 -1.0853610e-01\n",
            "   2.7763987e+01  2.6487947e+01  4.8687778e+01 -7.4907639e+01\n",
            "   2.2414761e+01  2.7489609e+01  2.7204998e+01]]\n",
            "============================================\n",
            "turbulence_threshold:  12.04306128869847\n",
            "======Model training from:  2010-04-01 to  2021-10-04\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c\\a2c_231_1\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 521           |\n",
            "|    iterations         | 100           |\n",
            "|    time_elapsed       | 0             |\n",
            "|    total_timesteps    | 500           |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.47         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 99            |\n",
            "|    policy_loss        | -0.0289       |\n",
            "|    reward             | -0.0049937214 |\n",
            "|    std                | 1.05          |\n",
            "|    value_loss         | 0.000173      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 512          |\n",
            "|    iterations         | 200          |\n",
            "|    time_elapsed       | 1            |\n",
            "|    total_timesteps    | 1000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.49        |\n",
            "|    explained_variance | 1.79e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 199          |\n",
            "|    policy_loss        | 0.0062       |\n",
            "|    reward             | 0.0021019075 |\n",
            "|    std                | 1.07         |\n",
            "|    value_loss         | 5.48e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 512          |\n",
            "|    iterations         | 300          |\n",
            "|    time_elapsed       | 2            |\n",
            "|    total_timesteps    | 1500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.53        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 299          |\n",
            "|    policy_loss        | 0.00118      |\n",
            "|    reward             | -0.010593767 |\n",
            "|    std                | 1.11         |\n",
            "|    value_loss         | 5.68e-06     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 513           |\n",
            "|    iterations         | 400           |\n",
            "|    time_elapsed       | 3             |\n",
            "|    total_timesteps    | 2000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.56         |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 399           |\n",
            "|    policy_loss        | -0.00679      |\n",
            "|    reward             | -0.0008355699 |\n",
            "|    std                | 1.15          |\n",
            "|    value_loss         | 3.14e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 517         |\n",
            "|    iterations         | 500         |\n",
            "|    time_elapsed       | 4           |\n",
            "|    total_timesteps    | 2500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.6        |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 499         |\n",
            "|    policy_loss        | -0.00153    |\n",
            "|    reward             | 0.020564662 |\n",
            "|    std                | 1.2         |\n",
            "|    value_loss         | 5.89e-05    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 514           |\n",
            "|    iterations         | 600           |\n",
            "|    time_elapsed       | 5             |\n",
            "|    total_timesteps    | 3000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.65         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 599           |\n",
            "|    policy_loss        | -0.0321       |\n",
            "|    reward             | -0.0058140587 |\n",
            "|    std                | 1.27          |\n",
            "|    value_loss         | 0.000483      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 514          |\n",
            "|    iterations         | 700          |\n",
            "|    time_elapsed       | 6            |\n",
            "|    total_timesteps    | 3500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.69        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 699          |\n",
            "|    policy_loss        | 0.013        |\n",
            "|    reward             | 0.0017093385 |\n",
            "|    std                | 1.31         |\n",
            "|    value_loss         | 7.21e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 518          |\n",
            "|    iterations         | 800          |\n",
            "|    time_elapsed       | 7            |\n",
            "|    total_timesteps    | 4000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.72        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 799          |\n",
            "|    policy_loss        | -0.00158     |\n",
            "|    reward             | -0.012230572 |\n",
            "|    std                | 1.35         |\n",
            "|    value_loss         | 1.7e-05      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 518           |\n",
            "|    iterations         | 900           |\n",
            "|    time_elapsed       | 8             |\n",
            "|    total_timesteps    | 4500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.74         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 899           |\n",
            "|    policy_loss        | -0.0107       |\n",
            "|    reward             | 0.00038289806 |\n",
            "|    std                | 1.38          |\n",
            "|    value_loss         | 3.79e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 516          |\n",
            "|    iterations         | 1000         |\n",
            "|    time_elapsed       | 9            |\n",
            "|    total_timesteps    | 5000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.77        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 999          |\n",
            "|    policy_loss        | -0.0217      |\n",
            "|    reward             | 0.0010036292 |\n",
            "|    std                | 1.42         |\n",
            "|    value_loss         | 0.000241     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 512           |\n",
            "|    iterations         | 1100          |\n",
            "|    time_elapsed       | 10            |\n",
            "|    total_timesteps    | 5500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.8          |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1099          |\n",
            "|    policy_loss        | 0.00925       |\n",
            "|    reward             | -0.0030280224 |\n",
            "|    std                | 1.46          |\n",
            "|    value_loss         | 5.61e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 512           |\n",
            "|    iterations         | 1200          |\n",
            "|    time_elapsed       | 11            |\n",
            "|    total_timesteps    | 6000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.84         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1199          |\n",
            "|    policy_loss        | 0.00596       |\n",
            "|    reward             | 0.00054144877 |\n",
            "|    std                | 1.53          |\n",
            "|    value_loss         | 2.14e-05      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 512            |\n",
            "|    iterations         | 1300           |\n",
            "|    time_elapsed       | 12             |\n",
            "|    total_timesteps    | 6500           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -1.86          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 1299           |\n",
            "|    policy_loss        | -0.0158        |\n",
            "|    reward             | -0.00016623164 |\n",
            "|    std                | 1.56           |\n",
            "|    value_loss         | 8.66e-05       |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 513         |\n",
            "|    iterations         | 1400        |\n",
            "|    time_elapsed       | 13          |\n",
            "|    total_timesteps    | 7000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.9        |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1399        |\n",
            "|    policy_loss        | -0.0281     |\n",
            "|    reward             | 0.015033526 |\n",
            "|    std                | 1.61        |\n",
            "|    value_loss         | 0.00019     |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 512            |\n",
            "|    iterations         | 1500           |\n",
            "|    time_elapsed       | 14             |\n",
            "|    total_timesteps    | 7500           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -1.94          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 1499           |\n",
            "|    policy_loss        | -0.000445      |\n",
            "|    reward             | -0.00012156417 |\n",
            "|    std                | 1.68           |\n",
            "|    value_loss         | 7.25e-06       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 514          |\n",
            "|    iterations         | 1600         |\n",
            "|    time_elapsed       | 15           |\n",
            "|    total_timesteps    | 8000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.98        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1599         |\n",
            "|    policy_loss        | -0.00958     |\n",
            "|    reward             | -0.007049424 |\n",
            "|    std                | 1.75         |\n",
            "|    value_loss         | 4.97e-05     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 514            |\n",
            "|    iterations         | 1700           |\n",
            "|    time_elapsed       | 16             |\n",
            "|    total_timesteps    | 8500           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -2.02          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 1699           |\n",
            "|    policy_loss        | 0.00181        |\n",
            "|    reward             | -0.00013168028 |\n",
            "|    std                | 1.82           |\n",
            "|    value_loss         | 6.55e-06       |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 513         |\n",
            "|    iterations         | 1800        |\n",
            "|    time_elapsed       | 17          |\n",
            "|    total_timesteps    | 9000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.07       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1799        |\n",
            "|    policy_loss        | 0.0205      |\n",
            "|    reward             | 0.008413555 |\n",
            "|    std                | 1.91        |\n",
            "|    value_loss         | 0.000158    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 515           |\n",
            "|    iterations         | 1900          |\n",
            "|    time_elapsed       | 18            |\n",
            "|    total_timesteps    | 9500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.09         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1899          |\n",
            "|    policy_loss        | 0.0156        |\n",
            "|    reward             | -3.127425e-06 |\n",
            "|    std                | 1.96          |\n",
            "|    value_loss         | 0.000118      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 513         |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 19          |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.12       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | 0.00629     |\n",
            "|    reward             | 0.002510956 |\n",
            "|    std                | 2.02        |\n",
            "|    value_loss         | 7.45e-06    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 512           |\n",
            "|    iterations         | 2100          |\n",
            "|    time_elapsed       | 20            |\n",
            "|    total_timesteps    | 10500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.16         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2099          |\n",
            "|    policy_loss        | -0.0205       |\n",
            "|    reward             | -0.0034987384 |\n",
            "|    std                | 2.1           |\n",
            "|    value_loss         | 7.92e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 511          |\n",
            "|    iterations         | 2200         |\n",
            "|    time_elapsed       | 21           |\n",
            "|    total_timesteps    | 11000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.2         |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2199         |\n",
            "|    policy_loss        | 0.012        |\n",
            "|    reward             | -0.008899092 |\n",
            "|    std                | 2.19         |\n",
            "|    value_loss         | 6.51e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 512           |\n",
            "|    iterations         | 2300          |\n",
            "|    time_elapsed       | 22            |\n",
            "|    total_timesteps    | 11500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.25         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2299          |\n",
            "|    policy_loss        | -0.00435      |\n",
            "|    reward             | 0.00056443183 |\n",
            "|    std                | 2.29          |\n",
            "|    value_loss         | 1.34e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 512         |\n",
            "|    iterations         | 2400        |\n",
            "|    time_elapsed       | 23          |\n",
            "|    total_timesteps    | 12000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.28       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2399        |\n",
            "|    policy_loss        | 0.0229      |\n",
            "|    reward             | 0.008721847 |\n",
            "|    std                | 2.36        |\n",
            "|    value_loss         | 0.000135    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 513         |\n",
            "|    iterations         | 2500        |\n",
            "|    time_elapsed       | 24          |\n",
            "|    total_timesteps    | 12500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.31       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2499        |\n",
            "|    policy_loss        | -0.00703    |\n",
            "|    reward             | 0.005142434 |\n",
            "|    std                | 2.43        |\n",
            "|    value_loss         | 9.13e-06    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 513         |\n",
            "|    iterations         | 2600        |\n",
            "|    time_elapsed       | 25          |\n",
            "|    total_timesteps    | 13000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.34       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2599        |\n",
            "|    policy_loss        | -0.00161    |\n",
            "|    reward             | 0.024932465 |\n",
            "|    std                | 2.51        |\n",
            "|    value_loss         | 9.11e-06    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 513          |\n",
            "|    iterations         | 2700         |\n",
            "|    time_elapsed       | 26           |\n",
            "|    total_timesteps    | 13500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.38        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2699         |\n",
            "|    policy_loss        | 0.0303       |\n",
            "|    reward             | 0.0056155627 |\n",
            "|    std                | 2.63         |\n",
            "|    value_loss         | 0.0001       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 512           |\n",
            "|    iterations         | 2800          |\n",
            "|    time_elapsed       | 27            |\n",
            "|    total_timesteps    | 14000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.42         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2799          |\n",
            "|    policy_loss        | -0.0323       |\n",
            "|    reward             | -0.0043379194 |\n",
            "|    std                | 2.72          |\n",
            "|    value_loss         | 0.000229      |\n",
            "-----------------------------------------\n",
            "day: 2896, episode: 5\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 7724.64\n",
            "total_reward: -2275.36\n",
            "total_cost: 144.00\n",
            "total_trades: 2896\n",
            "Sharpe: -0.086\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 512           |\n",
            "|    iterations         | 2900          |\n",
            "|    time_elapsed       | 28            |\n",
            "|    total_timesteps    | 14500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.47         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2899          |\n",
            "|    policy_loss        | 0.0308        |\n",
            "|    reward             | -0.0113441665 |\n",
            "|    std                | 2.86          |\n",
            "|    value_loss         | 0.000183      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 512         |\n",
            "|    iterations         | 3000        |\n",
            "|    time_elapsed       | 29          |\n",
            "|    total_timesteps    | 15000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.49       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2999        |\n",
            "|    policy_loss        | 0.0243      |\n",
            "|    reward             | -0.01071303 |\n",
            "|    std                | 2.93        |\n",
            "|    value_loss         | 0.000189    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 511           |\n",
            "|    iterations         | 3100          |\n",
            "|    time_elapsed       | 30            |\n",
            "|    total_timesteps    | 15500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.53         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3099          |\n",
            "|    policy_loss        | 0.032         |\n",
            "|    reward             | -0.0060835406 |\n",
            "|    std                | 3.03          |\n",
            "|    value_loss         | 0.000272      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 509           |\n",
            "|    iterations         | 3200          |\n",
            "|    time_elapsed       | 31            |\n",
            "|    total_timesteps    | 16000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.57         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3199          |\n",
            "|    policy_loss        | 0.000553      |\n",
            "|    reward             | 0.00014581045 |\n",
            "|    std                | 3.18          |\n",
            "|    value_loss         | 1.74e-06      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 507           |\n",
            "|    iterations         | 3300          |\n",
            "|    time_elapsed       | 32            |\n",
            "|    total_timesteps    | 16500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.61         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3299          |\n",
            "|    policy_loss        | 0.0173        |\n",
            "|    reward             | -0.0007798043 |\n",
            "|    std                | 3.29          |\n",
            "|    value_loss         | 8.62e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 507           |\n",
            "|    iterations         | 3400          |\n",
            "|    time_elapsed       | 33            |\n",
            "|    total_timesteps    | 17000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.66         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3399          |\n",
            "|    policy_loss        | 0.0276        |\n",
            "|    reward             | -0.0060860254 |\n",
            "|    std                | 3.44          |\n",
            "|    value_loss         | 0.000149      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 507          |\n",
            "|    iterations         | 3500         |\n",
            "|    time_elapsed       | 34           |\n",
            "|    total_timesteps    | 17500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.69        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3499         |\n",
            "|    policy_loss        | -0.0185      |\n",
            "|    reward             | -0.005240451 |\n",
            "|    std                | 3.58         |\n",
            "|    value_loss         | 7.97e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 508          |\n",
            "|    iterations         | 3600         |\n",
            "|    time_elapsed       | 35           |\n",
            "|    total_timesteps    | 18000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.73        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3599         |\n",
            "|    policy_loss        | 0.0177       |\n",
            "|    reward             | -0.017049342 |\n",
            "|    std                | 3.71         |\n",
            "|    value_loss         | 0.000104     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 508           |\n",
            "|    iterations         | 3700          |\n",
            "|    time_elapsed       | 36            |\n",
            "|    total_timesteps    | 18500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.77         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3699          |\n",
            "|    policy_loss        | 0.0044        |\n",
            "|    reward             | -0.0057989354 |\n",
            "|    std                | 3.85          |\n",
            "|    value_loss         | 5.64e-06      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 508           |\n",
            "|    iterations         | 3800          |\n",
            "|    time_elapsed       | 37            |\n",
            "|    total_timesteps    | 19000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.8          |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3799          |\n",
            "|    policy_loss        | 0.0088        |\n",
            "|    reward             | -0.0016636216 |\n",
            "|    std                | 3.98          |\n",
            "|    value_loss         | 1.24e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 509          |\n",
            "|    iterations         | 3900         |\n",
            "|    time_elapsed       | 38           |\n",
            "|    total_timesteps    | 19500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.83        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3899         |\n",
            "|    policy_loss        | -0.0258      |\n",
            "|    reward             | 0.0011075033 |\n",
            "|    std                | 4.09         |\n",
            "|    value_loss         | 0.0001       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 509           |\n",
            "|    iterations         | 4000          |\n",
            "|    time_elapsed       | 39            |\n",
            "|    total_timesteps    | 20000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.86         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3999          |\n",
            "|    policy_loss        | 0.0401        |\n",
            "|    reward             | -2.215402e-06 |\n",
            "|    std                | 4.24          |\n",
            "|    value_loss         | 0.000252      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 510          |\n",
            "|    iterations         | 4100         |\n",
            "|    time_elapsed       | 40           |\n",
            "|    total_timesteps    | 20500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.9         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4099         |\n",
            "|    policy_loss        | -0.0824      |\n",
            "|    reward             | -0.014920577 |\n",
            "|    std                | 4.39         |\n",
            "|    value_loss         | 0.00114      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 510          |\n",
            "|    iterations         | 4200         |\n",
            "|    time_elapsed       | 41           |\n",
            "|    total_timesteps    | 21000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.94        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4199         |\n",
            "|    policy_loss        | -0.0122      |\n",
            "|    reward             | 0.0020744067 |\n",
            "|    std                | 4.57         |\n",
            "|    value_loss         | 6.85e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 510           |\n",
            "|    iterations         | 4300          |\n",
            "|    time_elapsed       | 42            |\n",
            "|    total_timesteps    | 21500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.96         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4299          |\n",
            "|    policy_loss        | -0.0225       |\n",
            "|    reward             | -0.0028222785 |\n",
            "|    std                | 4.68          |\n",
            "|    value_loss         | 8.7e-05       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 510            |\n",
            "|    iterations         | 4400           |\n",
            "|    time_elapsed       | 43             |\n",
            "|    total_timesteps    | 22000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -2.99          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 4399           |\n",
            "|    policy_loss        | -0.0174        |\n",
            "|    reward             | -0.00032395517 |\n",
            "|    std                | 4.83           |\n",
            "|    value_loss         | 4.29e-05       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 511          |\n",
            "|    iterations         | 4500         |\n",
            "|    time_elapsed       | 43           |\n",
            "|    total_timesteps    | 22500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.02        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4499         |\n",
            "|    policy_loss        | 0.0128       |\n",
            "|    reward             | 0.0027585647 |\n",
            "|    std                | 4.98         |\n",
            "|    value_loss         | 2.39e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 511          |\n",
            "|    iterations         | 4600         |\n",
            "|    time_elapsed       | 44           |\n",
            "|    total_timesteps    | 23000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.06        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4599         |\n",
            "|    policy_loss        | -0.0171      |\n",
            "|    reward             | 0.0031351128 |\n",
            "|    std                | 5.15         |\n",
            "|    value_loss         | 2.73e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 511         |\n",
            "|    iterations         | 4700        |\n",
            "|    time_elapsed       | 45          |\n",
            "|    total_timesteps    | 23500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.09       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4699        |\n",
            "|    policy_loss        | -0.0854     |\n",
            "|    reward             | 0.011057638 |\n",
            "|    std                | 5.3         |\n",
            "|    value_loss         | 0.000718    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 511          |\n",
            "|    iterations         | 4800         |\n",
            "|    time_elapsed       | 46           |\n",
            "|    total_timesteps    | 24000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.12        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4799         |\n",
            "|    policy_loss        | -0.0112      |\n",
            "|    reward             | -0.009143612 |\n",
            "|    std                | 5.47         |\n",
            "|    value_loss         | 4.81e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 511          |\n",
            "|    iterations         | 4900         |\n",
            "|    time_elapsed       | 47           |\n",
            "|    total_timesteps    | 24500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.15        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4899         |\n",
            "|    policy_loss        | 0.0345       |\n",
            "|    reward             | -0.002015097 |\n",
            "|    std                | 5.62         |\n",
            "|    value_loss         | 0.000153     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 511         |\n",
            "|    iterations         | 5000        |\n",
            "|    time_elapsed       | 48          |\n",
            "|    total_timesteps    | 25000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.18       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4999        |\n",
            "|    policy_loss        | 0.019       |\n",
            "|    reward             | 0.004286457 |\n",
            "|    std                | 5.81        |\n",
            "|    value_loss         | 5.17e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 512          |\n",
            "|    iterations         | 5100         |\n",
            "|    time_elapsed       | 49           |\n",
            "|    total_timesteps    | 25500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.22        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5099         |\n",
            "|    policy_loss        | 0.00214      |\n",
            "|    reward             | -0.005300969 |\n",
            "|    std                | 6.03         |\n",
            "|    value_loss         | 5.1e-06      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 512          |\n",
            "|    iterations         | 5200         |\n",
            "|    time_elapsed       | 50           |\n",
            "|    total_timesteps    | 26000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.26        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5199         |\n",
            "|    policy_loss        | 0.0103       |\n",
            "|    reward             | -0.008598614 |\n",
            "|    std                | 6.31         |\n",
            "|    value_loss         | 2.18e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 511         |\n",
            "|    iterations         | 5300        |\n",
            "|    time_elapsed       | 51          |\n",
            "|    total_timesteps    | 26500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.29       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5299        |\n",
            "|    policy_loss        | -0.0771     |\n",
            "|    reward             | 0.020493943 |\n",
            "|    std                | 6.52        |\n",
            "|    value_loss         | 0.00069     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 511          |\n",
            "|    iterations         | 5400         |\n",
            "|    time_elapsed       | 52           |\n",
            "|    total_timesteps    | 27000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.31        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5399         |\n",
            "|    policy_loss        | -0.00207     |\n",
            "|    reward             | -0.009840018 |\n",
            "|    std                | 6.66         |\n",
            "|    value_loss         | 2.19e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 511           |\n",
            "|    iterations         | 5500          |\n",
            "|    time_elapsed       | 53            |\n",
            "|    total_timesteps    | 27500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.34         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5499          |\n",
            "|    policy_loss        | -0.027        |\n",
            "|    reward             | -0.0033424636 |\n",
            "|    std                | 6.8           |\n",
            "|    value_loss         | 8.5e-05       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 511          |\n",
            "|    iterations         | 5600         |\n",
            "|    time_elapsed       | 54           |\n",
            "|    total_timesteps    | 28000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.37        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5599         |\n",
            "|    policy_loss        | -0.04        |\n",
            "|    reward             | -0.004798706 |\n",
            "|    std                | 7.03         |\n",
            "|    value_loss         | 0.000179     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 511         |\n",
            "|    iterations         | 5700        |\n",
            "|    time_elapsed       | 55          |\n",
            "|    total_timesteps    | 28500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.4        |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5699        |\n",
            "|    policy_loss        | 0.0356      |\n",
            "|    reward             | 0.007606503 |\n",
            "|    std                | 7.29        |\n",
            "|    value_loss         | 0.00011     |\n",
            "---------------------------------------\n",
            "day: 2896, episode: 10\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 8338.25\n",
            "total_reward: -1661.75\n",
            "total_cost: 133.24\n",
            "total_trades: 2896\n",
            "Sharpe: -0.028\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 512        |\n",
            "|    iterations         | 5800       |\n",
            "|    time_elapsed       | 56         |\n",
            "|    total_timesteps    | 29000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -3.44      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5799       |\n",
            "|    policy_loss        | 0.143      |\n",
            "|    reward             | 0.01633053 |\n",
            "|    std                | 7.56       |\n",
            "|    value_loss         | 0.00204    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 511         |\n",
            "|    iterations         | 5900        |\n",
            "|    time_elapsed       | 57          |\n",
            "|    total_timesteps    | 29500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.47       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5899        |\n",
            "|    policy_loss        | -0.0107     |\n",
            "|    reward             | 0.005831522 |\n",
            "|    std                | 7.79        |\n",
            "|    value_loss         | 2.63e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 511          |\n",
            "|    iterations         | 6000         |\n",
            "|    time_elapsed       | 58           |\n",
            "|    total_timesteps    | 30000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.49        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5999         |\n",
            "|    policy_loss        | 0.0305       |\n",
            "|    reward             | 0.0027117534 |\n",
            "|    std                | 7.95         |\n",
            "|    value_loss         | 0.00017      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 512          |\n",
            "|    iterations         | 6100         |\n",
            "|    time_elapsed       | 59           |\n",
            "|    total_timesteps    | 30500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.52        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6099         |\n",
            "|    policy_loss        | -0.0145      |\n",
            "|    reward             | 0.0001416067 |\n",
            "|    std                | 8.17         |\n",
            "|    value_loss         | 2.2e-05      |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 512            |\n",
            "|    iterations         | 6200           |\n",
            "|    time_elapsed       | 60             |\n",
            "|    total_timesteps    | 31000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -3.56          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 6199           |\n",
            "|    policy_loss        | 0.0333         |\n",
            "|    reward             | -2.1106646e-06 |\n",
            "|    std                | 8.49           |\n",
            "|    value_loss         | 8.75e-05       |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 512         |\n",
            "|    iterations         | 6300        |\n",
            "|    time_elapsed       | 61          |\n",
            "|    total_timesteps    | 31500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.6        |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6299        |\n",
            "|    policy_loss        | -0.0429     |\n",
            "|    reward             | 0.009838649 |\n",
            "|    std                | 8.89        |\n",
            "|    value_loss         | 0.000212    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 512           |\n",
            "|    iterations         | 6400          |\n",
            "|    time_elapsed       | 62            |\n",
            "|    total_timesteps    | 32000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.64         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6399          |\n",
            "|    policy_loss        | 0.0322        |\n",
            "|    reward             | -0.0056159617 |\n",
            "|    std                | 9.24          |\n",
            "|    value_loss         | 0.000198      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 512         |\n",
            "|    iterations         | 6500        |\n",
            "|    time_elapsed       | 63          |\n",
            "|    total_timesteps    | 32500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.66       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6499        |\n",
            "|    policy_loss        | 0.0701      |\n",
            "|    reward             | 0.002578404 |\n",
            "|    std                | 9.36        |\n",
            "|    value_loss         | 0.000465    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 513         |\n",
            "|    iterations         | 6600        |\n",
            "|    time_elapsed       | 64          |\n",
            "|    total_timesteps    | 33000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.68       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6599        |\n",
            "|    policy_loss        | 0.00843     |\n",
            "|    reward             | 0.007560747 |\n",
            "|    std                | 9.57        |\n",
            "|    value_loss         | 7.93e-06    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 513          |\n",
            "|    iterations         | 6700         |\n",
            "|    time_elapsed       | 65           |\n",
            "|    total_timesteps    | 33500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.71        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6699         |\n",
            "|    policy_loss        | 0.0106       |\n",
            "|    reward             | 0.0021359914 |\n",
            "|    std                | 9.91         |\n",
            "|    value_loss         | 3.43e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 513          |\n",
            "|    iterations         | 6800         |\n",
            "|    time_elapsed       | 66           |\n",
            "|    total_timesteps    | 34000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.75        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6799         |\n",
            "|    policy_loss        | -0.0109      |\n",
            "|    reward             | -0.004914672 |\n",
            "|    std                | 10.3         |\n",
            "|    value_loss         | 1.11e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 513           |\n",
            "|    iterations         | 6900          |\n",
            "|    time_elapsed       | 67            |\n",
            "|    total_timesteps    | 34500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.78         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6899          |\n",
            "|    policy_loss        | 0.0261        |\n",
            "|    reward             | -0.0016550623 |\n",
            "|    std                | 10.7          |\n",
            "|    value_loss         | 0.000207      |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 513        |\n",
            "|    iterations         | 7000       |\n",
            "|    time_elapsed       | 68         |\n",
            "|    total_timesteps    | 35000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -3.83      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6999       |\n",
            "|    policy_loss        | 0.00862    |\n",
            "|    reward             | 0.02696439 |\n",
            "|    std                | 11.1       |\n",
            "|    value_loss         | 0.000434   |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 512           |\n",
            "|    iterations         | 7100          |\n",
            "|    time_elapsed       | 69            |\n",
            "|    total_timesteps    | 35500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.85         |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7099          |\n",
            "|    policy_loss        | 0.0363        |\n",
            "|    reward             | -0.0027254177 |\n",
            "|    std                | 11.4          |\n",
            "|    value_loss         | 0.000194      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 513           |\n",
            "|    iterations         | 7200          |\n",
            "|    time_elapsed       | 70            |\n",
            "|    total_timesteps    | 36000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.88         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7199          |\n",
            "|    policy_loss        | -0.00645      |\n",
            "|    reward             | -0.0017925616 |\n",
            "|    std                | 11.7          |\n",
            "|    value_loss         | 7.34e-06      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 513          |\n",
            "|    iterations         | 7300         |\n",
            "|    time_elapsed       | 71           |\n",
            "|    total_timesteps    | 36500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.91        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7299         |\n",
            "|    policy_loss        | -0.0193      |\n",
            "|    reward             | 0.0015038115 |\n",
            "|    std                | 12.1         |\n",
            "|    value_loss         | 3.22e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 513           |\n",
            "|    iterations         | 7400          |\n",
            "|    time_elapsed       | 72            |\n",
            "|    total_timesteps    | 37000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.95         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7399          |\n",
            "|    policy_loss        | -0.0362       |\n",
            "|    reward             | -0.0005965057 |\n",
            "|    std                | 12.5          |\n",
            "|    value_loss         | 6.1e-05       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 513         |\n",
            "|    iterations         | 7500        |\n",
            "|    time_elapsed       | 73          |\n",
            "|    total_timesteps    | 37500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4          |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7499        |\n",
            "|    policy_loss        | -0.00784    |\n",
            "|    reward             | 0.009254259 |\n",
            "|    std                | 13.2        |\n",
            "|    value_loss         | 1.6e-05     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 513         |\n",
            "|    iterations         | 7600        |\n",
            "|    time_elapsed       | 74          |\n",
            "|    total_timesteps    | 38000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.04       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7599        |\n",
            "|    policy_loss        | 0.46        |\n",
            "|    reward             | 0.030484349 |\n",
            "|    std                | 13.7        |\n",
            "|    value_loss         | 0.0159      |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 512          |\n",
            "|    iterations         | 7700         |\n",
            "|    time_elapsed       | 75           |\n",
            "|    total_timesteps    | 38500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.07        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7699         |\n",
            "|    policy_loss        | -0.0537      |\n",
            "|    reward             | -0.005470224 |\n",
            "|    std                | 14.2         |\n",
            "|    value_loss         | 0.000215     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 512           |\n",
            "|    iterations         | 7800          |\n",
            "|    time_elapsed       | 76            |\n",
            "|    total_timesteps    | 39000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.1          |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7799          |\n",
            "|    policy_loss        | -0.00641      |\n",
            "|    reward             | -0.0018546485 |\n",
            "|    std                | 14.6          |\n",
            "|    value_loss         | 6.4e-06       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 513           |\n",
            "|    iterations         | 7900          |\n",
            "|    time_elapsed       | 76            |\n",
            "|    total_timesteps    | 39500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.13         |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7899          |\n",
            "|    policy_loss        | 0.00084       |\n",
            "|    reward             | -0.0025783847 |\n",
            "|    std                | 15            |\n",
            "|    value_loss         | 1.21e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 513          |\n",
            "|    iterations         | 8000         |\n",
            "|    time_elapsed       | 77           |\n",
            "|    total_timesteps    | 40000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.17        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7999         |\n",
            "|    policy_loss        | 0.0197       |\n",
            "|    reward             | -0.002231189 |\n",
            "|    std                | 15.7         |\n",
            "|    value_loss         | 6.99e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 513           |\n",
            "|    iterations         | 8100          |\n",
            "|    time_elapsed       | 78            |\n",
            "|    total_timesteps    | 40500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.22         |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8099          |\n",
            "|    policy_loss        | 0.0275        |\n",
            "|    reward             | -0.0017389586 |\n",
            "|    std                | 16.4          |\n",
            "|    value_loss         | 5.68e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 513          |\n",
            "|    iterations         | 8200         |\n",
            "|    time_elapsed       | 79           |\n",
            "|    total_timesteps    | 41000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.24        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8199         |\n",
            "|    policy_loss        | -0.17        |\n",
            "|    reward             | 0.0016855253 |\n",
            "|    std                | 16.8         |\n",
            "|    value_loss         | 0.00214      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 513           |\n",
            "|    iterations         | 8300          |\n",
            "|    time_elapsed       | 80            |\n",
            "|    total_timesteps    | 41500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.26         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8299          |\n",
            "|    policy_loss        | -0.0224       |\n",
            "|    reward             | -0.0057538594 |\n",
            "|    std                | 17.1          |\n",
            "|    value_loss         | 3.86e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 513          |\n",
            "|    iterations         | 8400         |\n",
            "|    time_elapsed       | 81           |\n",
            "|    total_timesteps    | 42000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.28        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8399         |\n",
            "|    policy_loss        | -0.00352     |\n",
            "|    reward             | -0.003987303 |\n",
            "|    std                | 17.5         |\n",
            "|    value_loss         | 4.76e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 513         |\n",
            "|    iterations         | 8500        |\n",
            "|    time_elapsed       | 82          |\n",
            "|    total_timesteps    | 42500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.32       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8499        |\n",
            "|    policy_loss        | -0.0165     |\n",
            "|    reward             | 0.005451427 |\n",
            "|    std                | 18.1        |\n",
            "|    value_loss         | 3.2e-05     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 513         |\n",
            "|    iterations         | 8600        |\n",
            "|    time_elapsed       | 83          |\n",
            "|    total_timesteps    | 43000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.35       |\n",
            "|    explained_variance | 1.79e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8599        |\n",
            "|    policy_loss        | 0.0438      |\n",
            "|    reward             | -0.00559179 |\n",
            "|    std                | 18.8        |\n",
            "|    value_loss         | 0.00014     |\n",
            "---------------------------------------\n",
            "day: 2896, episode: 15\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 9514.17\n",
            "total_reward: -485.83\n",
            "total_cost: 111.41\n",
            "total_trades: 2896\n",
            "Sharpe: 0.054\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 513          |\n",
            "|    iterations         | 8700         |\n",
            "|    time_elapsed       | 84           |\n",
            "|    total_timesteps    | 43500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.39        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8699         |\n",
            "|    policy_loss        | -0.0624      |\n",
            "|    reward             | 0.0111580435 |\n",
            "|    std                | 19.5         |\n",
            "|    value_loss         | 0.000542     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 513          |\n",
            "|    iterations         | 8800         |\n",
            "|    time_elapsed       | 85           |\n",
            "|    total_timesteps    | 44000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.41        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8799         |\n",
            "|    policy_loss        | -0.0598      |\n",
            "|    reward             | 0.0035175686 |\n",
            "|    std                | 19.8         |\n",
            "|    value_loss         | 0.000271     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 513           |\n",
            "|    iterations         | 8900          |\n",
            "|    time_elapsed       | 86            |\n",
            "|    total_timesteps    | 44500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.44         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8899          |\n",
            "|    policy_loss        | 0.0261        |\n",
            "|    reward             | -0.0038662998 |\n",
            "|    std                | 20.4          |\n",
            "|    value_loss         | 4.63e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 513           |\n",
            "|    iterations         | 9000          |\n",
            "|    time_elapsed       | 87            |\n",
            "|    total_timesteps    | 45000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.47         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8999          |\n",
            "|    policy_loss        | 0.00262       |\n",
            "|    reward             | -0.0055385684 |\n",
            "|    std                | 21.1          |\n",
            "|    value_loss         | 8.38e-06      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 513            |\n",
            "|    iterations         | 9100           |\n",
            "|    time_elapsed       | 88             |\n",
            "|    total_timesteps    | 45500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -4.51          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 9099           |\n",
            "|    policy_loss        | -0.0394        |\n",
            "|    reward             | -0.00045330316 |\n",
            "|    std                | 22             |\n",
            "|    value_loss         | 0.000131       |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 513         |\n",
            "|    iterations         | 9200        |\n",
            "|    time_elapsed       | 89          |\n",
            "|    total_timesteps    | 46000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.56       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9199        |\n",
            "|    policy_loss        | 0.028       |\n",
            "|    reward             | 0.007891514 |\n",
            "|    std                | 23.1        |\n",
            "|    value_loss         | 0.000403    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 514         |\n",
            "|    iterations         | 9300        |\n",
            "|    time_elapsed       | 90          |\n",
            "|    total_timesteps    | 46500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.59       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9299        |\n",
            "|    policy_loss        | -0.0206     |\n",
            "|    reward             | 0.010807038 |\n",
            "|    std                | 23.8        |\n",
            "|    value_loss         | 0.000285    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 513         |\n",
            "|    iterations         | 9400        |\n",
            "|    time_elapsed       | 91          |\n",
            "|    total_timesteps    | 47000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.62       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9399        |\n",
            "|    policy_loss        | -0.0848     |\n",
            "|    reward             | 0.037967764 |\n",
            "|    std                | 24.6        |\n",
            "|    value_loss         | 0.000538    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 513         |\n",
            "|    iterations         | 9500        |\n",
            "|    time_elapsed       | 92          |\n",
            "|    total_timesteps    | 47500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.65       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9499        |\n",
            "|    policy_loss        | 0.0408      |\n",
            "|    reward             | 0.009028705 |\n",
            "|    std                | 25.2        |\n",
            "|    value_loss         | 0.000494    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 511          |\n",
            "|    iterations         | 9600         |\n",
            "|    time_elapsed       | 93           |\n",
            "|    total_timesteps    | 48000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.67        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9599         |\n",
            "|    policy_loss        | 0.00232      |\n",
            "|    reward             | 0.0045536514 |\n",
            "|    std                | 26           |\n",
            "|    value_loss         | 1.49e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 512         |\n",
            "|    iterations         | 9700        |\n",
            "|    time_elapsed       | 94          |\n",
            "|    total_timesteps    | 48500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.72       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9699        |\n",
            "|    policy_loss        | 0.0386      |\n",
            "|    reward             | 0.011247148 |\n",
            "|    std                | 27          |\n",
            "|    value_loss         | 6.71e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 511          |\n",
            "|    iterations         | 9800         |\n",
            "|    time_elapsed       | 95           |\n",
            "|    total_timesteps    | 49000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.74        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9799         |\n",
            "|    policy_loss        | -0.00929     |\n",
            "|    reward             | -0.010773617 |\n",
            "|    std                | 27.8         |\n",
            "|    value_loss         | 6.27e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 511         |\n",
            "|    iterations         | 9900        |\n",
            "|    time_elapsed       | 96          |\n",
            "|    total_timesteps    | 49500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.78       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9899        |\n",
            "|    policy_loss        | 0.0669      |\n",
            "|    reward             | -0.03174376 |\n",
            "|    std                | 28.8        |\n",
            "|    value_loss         | 0.000978    |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 511            |\n",
            "|    iterations         | 10000          |\n",
            "|    time_elapsed       | 97             |\n",
            "|    total_timesteps    | 50000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -4.81          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 9999           |\n",
            "|    policy_loss        | 0.115          |\n",
            "|    reward             | -0.00056552654 |\n",
            "|    std                | 29.7           |\n",
            "|    value_loss         | 0.000701       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 511           |\n",
            "|    iterations         | 10100         |\n",
            "|    time_elapsed       | 98            |\n",
            "|    total_timesteps    | 50500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.83         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10099         |\n",
            "|    policy_loss        | -0.00363      |\n",
            "|    reward             | -0.0044080606 |\n",
            "|    std                | 30.4          |\n",
            "|    value_loss         | 3.38e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 511           |\n",
            "|    iterations         | 10200         |\n",
            "|    time_elapsed       | 99            |\n",
            "|    total_timesteps    | 51000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.85         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10199         |\n",
            "|    policy_loss        | 0.0419        |\n",
            "|    reward             | -0.0054321913 |\n",
            "|    std                | 30.9          |\n",
            "|    value_loss         | 0.000116      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 511          |\n",
            "|    iterations         | 10300        |\n",
            "|    time_elapsed       | 100          |\n",
            "|    total_timesteps    | 51500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.87        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10299        |\n",
            "|    policy_loss        | 0.0458       |\n",
            "|    reward             | -0.004002172 |\n",
            "|    std                | 31.5         |\n",
            "|    value_loss         | 0.000136     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 511           |\n",
            "|    iterations         | 10400         |\n",
            "|    time_elapsed       | 101           |\n",
            "|    total_timesteps    | 52000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.89         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10399         |\n",
            "|    policy_loss        | -0.0404       |\n",
            "|    reward             | -0.0025914274 |\n",
            "|    std                | 32.2          |\n",
            "|    value_loss         | 7.69e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 511         |\n",
            "|    iterations         | 10500       |\n",
            "|    time_elapsed       | 102         |\n",
            "|    total_timesteps    | 52500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.92       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10499       |\n",
            "|    policy_loss        | 0.132       |\n",
            "|    reward             | 0.010732333 |\n",
            "|    std                | 33.1        |\n",
            "|    value_loss         | 0.000706    |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 511            |\n",
            "|    iterations         | 10600          |\n",
            "|    time_elapsed       | 103            |\n",
            "|    total_timesteps    | 53000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -4.94          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 10599          |\n",
            "|    policy_loss        | 0.125          |\n",
            "|    reward             | -0.00024381957 |\n",
            "|    std                | 33.9           |\n",
            "|    value_loss         | 0.000833       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 511          |\n",
            "|    iterations         | 10700        |\n",
            "|    time_elapsed       | 104          |\n",
            "|    total_timesteps    | 53500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.97        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10699        |\n",
            "|    policy_loss        | 0.0298       |\n",
            "|    reward             | 0.0033198013 |\n",
            "|    std                | 34.9         |\n",
            "|    value_loss         | 2.93e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 511           |\n",
            "|    iterations         | 10800         |\n",
            "|    time_elapsed       | 105           |\n",
            "|    total_timesteps    | 54000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -5.01         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10799         |\n",
            "|    policy_loss        | -0.00876      |\n",
            "|    reward             | 0.00046309974 |\n",
            "|    std                | 36.2          |\n",
            "|    value_loss         | 1.69e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 511           |\n",
            "|    iterations         | 10900         |\n",
            "|    time_elapsed       | 106           |\n",
            "|    total_timesteps    | 54500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -5.04         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10899         |\n",
            "|    policy_loss        | 0.0166        |\n",
            "|    reward             | -0.0046897414 |\n",
            "|    std                | 37.5          |\n",
            "|    value_loss         | 2.27e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 511          |\n",
            "|    iterations         | 11000        |\n",
            "|    time_elapsed       | 107          |\n",
            "|    total_timesteps    | 55000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -5.09        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10999        |\n",
            "|    policy_loss        | -0.0146      |\n",
            "|    reward             | -0.014295618 |\n",
            "|    std                | 39.1         |\n",
            "|    value_loss         | 1.35e-05     |\n",
            "----------------------------------------\n",
            "======A2C Validation from:  2021-10-04 to  2021-11-02\n",
            "A2C Sharpe Ratio:  -0.3601148541700452\n",
            "======Best Model Retraining from:  2010-04-01 to  2021-11-02\n",
            "======Trading from:  2021-11-02 to  2021-12-02\n",
            "[[ 1.4602806e+04  3.0203924e+01 -1.9300000e+02  4.6399525e-01\n",
            "   2.9603964e+01  2.6094315e+01  6.3430550e+01  3.2927182e+02\n",
            "   4.7696384e+01  2.7630173e+01  2.7611444e+01]]\n",
            "============================================\n",
            "turbulence_threshold:  12.04306128869847\n",
            "======Model training from:  2010-04-01 to  2021-11-02\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c\\a2c_252_1\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 530          |\n",
            "|    iterations         | 100          |\n",
            "|    time_elapsed       | 0            |\n",
            "|    total_timesteps    | 500          |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.47        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 99           |\n",
            "|    policy_loss        | -0.0211      |\n",
            "|    reward             | -0.005521582 |\n",
            "|    std                | 1.05         |\n",
            "|    value_loss         | 0.000116     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 540          |\n",
            "|    iterations         | 200          |\n",
            "|    time_elapsed       | 1            |\n",
            "|    total_timesteps    | 1000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.5         |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 199          |\n",
            "|    policy_loss        | 0.0052       |\n",
            "|    reward             | 0.0016874775 |\n",
            "|    std                | 1.09         |\n",
            "|    value_loss         | 3.32e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 543         |\n",
            "|    iterations         | 300         |\n",
            "|    time_elapsed       | 2           |\n",
            "|    total_timesteps    | 1500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.54       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 299         |\n",
            "|    policy_loss        | 0.00148     |\n",
            "|    reward             | -0.00805014 |\n",
            "|    std                | 1.13        |\n",
            "|    value_loss         | 3.4e-06     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 537          |\n",
            "|    iterations         | 400          |\n",
            "|    time_elapsed       | 3            |\n",
            "|    total_timesteps    | 2000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.58        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 399          |\n",
            "|    policy_loss        | -0.00531     |\n",
            "|    reward             | -0.000890311 |\n",
            "|    std                | 1.17         |\n",
            "|    value_loss         | 3.45e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 532         |\n",
            "|    iterations         | 500         |\n",
            "|    time_elapsed       | 4           |\n",
            "|    total_timesteps    | 2500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.61       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 499         |\n",
            "|    policy_loss        | 0.00633     |\n",
            "|    reward             | 0.016584024 |\n",
            "|    std                | 1.22        |\n",
            "|    value_loss         | 4.71e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 526          |\n",
            "|    iterations         | 600          |\n",
            "|    time_elapsed       | 5            |\n",
            "|    total_timesteps    | 3000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.65        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 599          |\n",
            "|    policy_loss        | -0.0278      |\n",
            "|    reward             | 0.0054256055 |\n",
            "|    std                | 1.26         |\n",
            "|    value_loss         | 0.000555     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 522         |\n",
            "|    iterations         | 700         |\n",
            "|    time_elapsed       | 6           |\n",
            "|    total_timesteps    | 3500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.68       |\n",
            "|    explained_variance | -2.38e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 699         |\n",
            "|    policy_loss        | 0.000542    |\n",
            "|    reward             | 0.001826439 |\n",
            "|    std                | 1.3         |\n",
            "|    value_loss         | 4.63e-07    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 522          |\n",
            "|    iterations         | 800          |\n",
            "|    time_elapsed       | 7            |\n",
            "|    total_timesteps    | 4000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.72        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 799          |\n",
            "|    policy_loss        | 0.00229      |\n",
            "|    reward             | -0.004011395 |\n",
            "|    std                | 1.35         |\n",
            "|    value_loss         | 7.02e-06     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 521            |\n",
            "|    iterations         | 900            |\n",
            "|    time_elapsed       | 8              |\n",
            "|    total_timesteps    | 4500           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -1.76          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 899            |\n",
            "|    policy_loss        | 0.00031        |\n",
            "|    reward             | -0.00023831955 |\n",
            "|    std                | 1.41           |\n",
            "|    value_loss         | 1.53e-06       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 522          |\n",
            "|    iterations         | 1000         |\n",
            "|    time_elapsed       | 9            |\n",
            "|    total_timesteps    | 5000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.81        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 999          |\n",
            "|    policy_loss        | -0.0287      |\n",
            "|    reward             | 0.0014917031 |\n",
            "|    std                | 1.48         |\n",
            "|    value_loss         | 0.000182     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 1100         |\n",
            "|    time_elapsed       | 10           |\n",
            "|    total_timesteps    | 5500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.85        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1099         |\n",
            "|    policy_loss        | 0.0059       |\n",
            "|    reward             | -0.003163522 |\n",
            "|    std                | 1.55         |\n",
            "|    value_loss         | 1.17e-05     |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 519        |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 11         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.91      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | 0.0414     |\n",
            "|    reward             | 0.01740235 |\n",
            "|    std                | 1.63       |\n",
            "|    value_loss         | 0.000635   |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 515           |\n",
            "|    iterations         | 1300          |\n",
            "|    time_elapsed       | 12            |\n",
            "|    total_timesteps    | 6500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.95         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1299          |\n",
            "|    policy_loss        | -0.00445      |\n",
            "|    reward             | -0.0011351747 |\n",
            "|    std                | 1.7           |\n",
            "|    value_loss         | 7.24e-06      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 517          |\n",
            "|    iterations         | 1400         |\n",
            "|    time_elapsed       | 13           |\n",
            "|    total_timesteps    | 7000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.98        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1399         |\n",
            "|    policy_loss        | -0.00883     |\n",
            "|    reward             | 0.0067907902 |\n",
            "|    std                | 1.75         |\n",
            "|    value_loss         | 3.45e-05     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 517            |\n",
            "|    iterations         | 1500           |\n",
            "|    time_elapsed       | 14             |\n",
            "|    total_timesteps    | 7500           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -2.01          |\n",
            "|    explained_variance | 1.19e-07       |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 1499           |\n",
            "|    policy_loss        | -0.00189       |\n",
            "|    reward             | -2.1609412e-06 |\n",
            "|    std                | 1.81           |\n",
            "|    value_loss         | 0.000249       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 517           |\n",
            "|    iterations         | 1600          |\n",
            "|    time_elapsed       | 15            |\n",
            "|    total_timesteps    | 8000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.06         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1599          |\n",
            "|    policy_loss        | 0.00532       |\n",
            "|    reward             | -0.0012156426 |\n",
            "|    std                | 1.89          |\n",
            "|    value_loss         | 1.91e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 515         |\n",
            "|    iterations         | 1700        |\n",
            "|    time_elapsed       | 16          |\n",
            "|    total_timesteps    | 8500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.11       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1699        |\n",
            "|    policy_loss        | -0.00783    |\n",
            "|    reward             | 0.012064772 |\n",
            "|    std                | 1.99        |\n",
            "|    value_loss         | 3.36e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 515          |\n",
            "|    iterations         | 1800         |\n",
            "|    time_elapsed       | 17           |\n",
            "|    total_timesteps    | 9000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.14        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1799         |\n",
            "|    policy_loss        | 0.0309       |\n",
            "|    reward             | -0.018618574 |\n",
            "|    std                | 2.06         |\n",
            "|    value_loss         | 0.00035      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 515         |\n",
            "|    iterations         | 1900        |\n",
            "|    time_elapsed       | 18          |\n",
            "|    total_timesteps    | 9500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.18       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1899        |\n",
            "|    policy_loss        | 0.00787     |\n",
            "|    reward             | -0.00355884 |\n",
            "|    std                | 2.13        |\n",
            "|    value_loss         | 6.85e-05    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 515           |\n",
            "|    iterations         | 2000          |\n",
            "|    time_elapsed       | 19            |\n",
            "|    total_timesteps    | 10000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.2          |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1999          |\n",
            "|    policy_loss        | -0.00523      |\n",
            "|    reward             | -0.0028779758 |\n",
            "|    std                | 2.19          |\n",
            "|    value_loss         | 3.48e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 514           |\n",
            "|    iterations         | 2100          |\n",
            "|    time_elapsed       | 20            |\n",
            "|    total_timesteps    | 10500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.24         |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2099          |\n",
            "|    policy_loss        | 0.00173       |\n",
            "|    reward             | -0.0015241745 |\n",
            "|    std                | 2.27          |\n",
            "|    value_loss         | 3.47e-06      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 514            |\n",
            "|    iterations         | 2200           |\n",
            "|    time_elapsed       | 21             |\n",
            "|    total_timesteps    | 11000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -2.28          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 2199           |\n",
            "|    policy_loss        | 0.00265        |\n",
            "|    reward             | -0.00039833284 |\n",
            "|    std                | 2.37           |\n",
            "|    value_loss         | 5.53e-06       |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 512         |\n",
            "|    iterations         | 2300        |\n",
            "|    time_elapsed       | 22          |\n",
            "|    total_timesteps    | 11500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.32       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2299        |\n",
            "|    policy_loss        | 0.0162      |\n",
            "|    reward             | -0.00954351 |\n",
            "|    std                | 2.47        |\n",
            "|    value_loss         | 7.35e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 511          |\n",
            "|    iterations         | 2400         |\n",
            "|    time_elapsed       | 23           |\n",
            "|    total_timesteps    | 12000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.34        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2399         |\n",
            "|    policy_loss        | 0.0201       |\n",
            "|    reward             | 0.0049885768 |\n",
            "|    std                | 2.52         |\n",
            "|    value_loss         | 0.000139     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 512           |\n",
            "|    iterations         | 2500          |\n",
            "|    time_elapsed       | 24            |\n",
            "|    total_timesteps    | 12500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.37         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2499          |\n",
            "|    policy_loss        | -0.0119       |\n",
            "|    reward             | -0.0032010984 |\n",
            "|    std                | 2.59          |\n",
            "|    value_loss         | 5.26e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 512           |\n",
            "|    iterations         | 2600          |\n",
            "|    time_elapsed       | 25            |\n",
            "|    total_timesteps    | 13000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.4          |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2599          |\n",
            "|    policy_loss        | 0.0139        |\n",
            "|    reward             | 0.00011838159 |\n",
            "|    std                | 2.67          |\n",
            "|    value_loss         | 4.29e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 512          |\n",
            "|    iterations         | 2700         |\n",
            "|    time_elapsed       | 26           |\n",
            "|    total_timesteps    | 13500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.45        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2699         |\n",
            "|    policy_loss        | 0.00188      |\n",
            "|    reward             | 0.0045425743 |\n",
            "|    std                | 2.8          |\n",
            "|    value_loss         | 1.24e-05     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 513            |\n",
            "|    iterations         | 2800           |\n",
            "|    time_elapsed       | 27             |\n",
            "|    total_timesteps    | 14000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -2.49          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 2799           |\n",
            "|    policy_loss        | 0.0198         |\n",
            "|    reward             | -0.00030489286 |\n",
            "|    std                | 2.92           |\n",
            "|    value_loss         | 6.73e-05       |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 513         |\n",
            "|    iterations         | 2900        |\n",
            "|    time_elapsed       | 28          |\n",
            "|    total_timesteps    | 14500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.54       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2899        |\n",
            "|    policy_loss        | 0.0511      |\n",
            "|    reward             | -0.00529772 |\n",
            "|    std                | 3.08        |\n",
            "|    value_loss         | 0.000326    |\n",
            "---------------------------------------\n",
            "day: 2917, episode: 5\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 7877.49\n",
            "total_reward: -2122.51\n",
            "total_cost: 148.31\n",
            "total_trades: 2917\n",
            "Sharpe: -0.085\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 513          |\n",
            "|    iterations         | 3000         |\n",
            "|    time_elapsed       | 29           |\n",
            "|    total_timesteps    | 15000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.56        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2999         |\n",
            "|    policy_loss        | 0.00429      |\n",
            "|    reward             | 0.0022344873 |\n",
            "|    std                | 3.14         |\n",
            "|    value_loss         | 6.75e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 513          |\n",
            "|    iterations         | 3100         |\n",
            "|    time_elapsed       | 30           |\n",
            "|    total_timesteps    | 15500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.58        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3099         |\n",
            "|    policy_loss        | 0.00928      |\n",
            "|    reward             | 0.0029574956 |\n",
            "|    std                | 3.2          |\n",
            "|    value_loss         | 1.88e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 512         |\n",
            "|    iterations         | 3200        |\n",
            "|    time_elapsed       | 31          |\n",
            "|    total_timesteps    | 16000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.62       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3199        |\n",
            "|    policy_loss        | 0.00844     |\n",
            "|    reward             | 0.002511943 |\n",
            "|    std                | 3.32        |\n",
            "|    value_loss         | 6.04e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 512          |\n",
            "|    iterations         | 3300         |\n",
            "|    time_elapsed       | 32           |\n",
            "|    total_timesteps    | 16500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.66        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3299         |\n",
            "|    policy_loss        | -0.011       |\n",
            "|    reward             | 0.0010504737 |\n",
            "|    std                | 3.45         |\n",
            "|    value_loss         | 1.39e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 511          |\n",
            "|    iterations         | 3400         |\n",
            "|    time_elapsed       | 33           |\n",
            "|    total_timesteps    | 17000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.7         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3399         |\n",
            "|    policy_loss        | -0.0194      |\n",
            "|    reward             | 0.0009763125 |\n",
            "|    std                | 3.61         |\n",
            "|    value_loss         | 4.78e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 512          |\n",
            "|    iterations         | 3500         |\n",
            "|    time_elapsed       | 34           |\n",
            "|    total_timesteps    | 17500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.74        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3499         |\n",
            "|    policy_loss        | -0.0117      |\n",
            "|    reward             | 0.0014483965 |\n",
            "|    std                | 3.77         |\n",
            "|    value_loss         | 2.49e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 512         |\n",
            "|    iterations         | 3600        |\n",
            "|    time_elapsed       | 35          |\n",
            "|    total_timesteps    | 18000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.78       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3599        |\n",
            "|    policy_loss        | 0.0177      |\n",
            "|    reward             | 0.008761671 |\n",
            "|    std                | 3.9         |\n",
            "|    value_loss         | 7.68e-05    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 512           |\n",
            "|    iterations         | 3700          |\n",
            "|    time_elapsed       | 36            |\n",
            "|    total_timesteps    | 18500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.8          |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3699          |\n",
            "|    policy_loss        | 0.0206        |\n",
            "|    reward             | -0.0010981585 |\n",
            "|    std                | 4             |\n",
            "|    value_loss         | 6.37e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 513           |\n",
            "|    iterations         | 3800          |\n",
            "|    time_elapsed       | 37            |\n",
            "|    total_timesteps    | 19000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.83         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3799          |\n",
            "|    policy_loss        | -0.00479      |\n",
            "|    reward             | 0.00096602977 |\n",
            "|    std                | 4.12          |\n",
            "|    value_loss         | 1e-05         |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 513          |\n",
            "|    iterations         | 3900         |\n",
            "|    time_elapsed       | 38           |\n",
            "|    total_timesteps    | 19500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.87        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3899         |\n",
            "|    policy_loss        | 0.0052       |\n",
            "|    reward             | 0.0066398983 |\n",
            "|    std                | 4.27         |\n",
            "|    value_loss         | 2.4e-05      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 513         |\n",
            "|    iterations         | 4000        |\n",
            "|    time_elapsed       | 38          |\n",
            "|    total_timesteps    | 20000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.91       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3999        |\n",
            "|    policy_loss        | 0.0234      |\n",
            "|    reward             | 0.004287099 |\n",
            "|    std                | 4.43        |\n",
            "|    value_loss         | 8.55e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 513         |\n",
            "|    iterations         | 4100        |\n",
            "|    time_elapsed       | 39          |\n",
            "|    total_timesteps    | 20500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.95       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4099        |\n",
            "|    policy_loss        | -0.117      |\n",
            "|    reward             | -0.01934231 |\n",
            "|    std                | 4.64        |\n",
            "|    value_loss         | 0.00158     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 513         |\n",
            "|    iterations         | 4200        |\n",
            "|    time_elapsed       | 40          |\n",
            "|    total_timesteps    | 21000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.99       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4199        |\n",
            "|    policy_loss        | -0.029      |\n",
            "|    reward             | 0.003163899 |\n",
            "|    std                | 4.8         |\n",
            "|    value_loss         | 0.00017     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 514           |\n",
            "|    iterations         | 4300          |\n",
            "|    time_elapsed       | 41            |\n",
            "|    total_timesteps    | 21500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.01         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4299          |\n",
            "|    policy_loss        | -0.00889      |\n",
            "|    reward             | -0.0044423873 |\n",
            "|    std                | 4.89          |\n",
            "|    value_loss         | 1.43e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 514         |\n",
            "|    iterations         | 4400        |\n",
            "|    time_elapsed       | 42          |\n",
            "|    total_timesteps    | 22000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.04       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4399        |\n",
            "|    policy_loss        | 0.0328      |\n",
            "|    reward             | 0.002454214 |\n",
            "|    std                | 5.05        |\n",
            "|    value_loss         | 0.000128    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 513           |\n",
            "|    iterations         | 4500          |\n",
            "|    time_elapsed       | 43            |\n",
            "|    total_timesteps    | 22500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.07         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4499          |\n",
            "|    policy_loss        | 0.0311        |\n",
            "|    reward             | -0.0024137236 |\n",
            "|    std                | 5.23          |\n",
            "|    value_loss         | 0.000138      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 512         |\n",
            "|    iterations         | 4600        |\n",
            "|    time_elapsed       | 44          |\n",
            "|    total_timesteps    | 23000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.11       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4599        |\n",
            "|    policy_loss        | 0.0033      |\n",
            "|    reward             | 0.007727303 |\n",
            "|    std                | 5.43        |\n",
            "|    value_loss         | 0.000233    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 512          |\n",
            "|    iterations         | 4700         |\n",
            "|    time_elapsed       | 45           |\n",
            "|    total_timesteps    | 23500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.14        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4699         |\n",
            "|    policy_loss        | -0.167       |\n",
            "|    reward             | 0.0005484803 |\n",
            "|    std                | 5.58         |\n",
            "|    value_loss         | 0.00193      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 512           |\n",
            "|    iterations         | 4800          |\n",
            "|    time_elapsed       | 46            |\n",
            "|    total_timesteps    | 24000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.16         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4799          |\n",
            "|    policy_loss        | 0.00322       |\n",
            "|    reward             | -0.0053232866 |\n",
            "|    std                | 5.71          |\n",
            "|    value_loss         | 0.000279      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 513           |\n",
            "|    iterations         | 4900          |\n",
            "|    time_elapsed       | 47            |\n",
            "|    total_timesteps    | 24500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.19         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4899          |\n",
            "|    policy_loss        | -0.00517      |\n",
            "|    reward             | -3.459473e-06 |\n",
            "|    std                | 5.89          |\n",
            "|    value_loss         | 5.08e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 513           |\n",
            "|    iterations         | 5000          |\n",
            "|    time_elapsed       | 48            |\n",
            "|    total_timesteps    | 25000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.23         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4999          |\n",
            "|    policy_loss        | 0.00344       |\n",
            "|    reward             | -0.0006160705 |\n",
            "|    std                | 6.1           |\n",
            "|    value_loss         | 1.53e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 513         |\n",
            "|    iterations         | 5100        |\n",
            "|    time_elapsed       | 49          |\n",
            "|    total_timesteps    | 25500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.27       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5099        |\n",
            "|    policy_loss        | -0.0358     |\n",
            "|    reward             | 0.013305069 |\n",
            "|    std                | 6.38        |\n",
            "|    value_loss         | 0.000241    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 513         |\n",
            "|    iterations         | 5200        |\n",
            "|    time_elapsed       | 50          |\n",
            "|    total_timesteps    | 26000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.31       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5199        |\n",
            "|    policy_loss        | -0.0301     |\n",
            "|    reward             | 0.006810168 |\n",
            "|    std                | 6.64        |\n",
            "|    value_loss         | 0.000106    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 513          |\n",
            "|    iterations         | 5300         |\n",
            "|    time_elapsed       | 51           |\n",
            "|    total_timesteps    | 26500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.35        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5299         |\n",
            "|    policy_loss        | 0.00614      |\n",
            "|    reward             | -0.021655405 |\n",
            "|    std                | 6.92         |\n",
            "|    value_loss         | 5.77e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 513         |\n",
            "|    iterations         | 5400        |\n",
            "|    time_elapsed       | 52          |\n",
            "|    total_timesteps    | 27000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.39       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5399        |\n",
            "|    policy_loss        | 0.0233      |\n",
            "|    reward             | 0.009136816 |\n",
            "|    std                | 7.19        |\n",
            "|    value_loss         | 0.000105    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 513          |\n",
            "|    iterations         | 5500         |\n",
            "|    time_elapsed       | 53           |\n",
            "|    total_timesteps    | 27500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.43        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5499         |\n",
            "|    policy_loss        | -0.0192      |\n",
            "|    reward             | 0.0126479855 |\n",
            "|    std                | 7.44         |\n",
            "|    value_loss         | 5.35e-05     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 512            |\n",
            "|    iterations         | 5600           |\n",
            "|    time_elapsed       | 54             |\n",
            "|    total_timesteps    | 28000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -3.46          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 5599           |\n",
            "|    policy_loss        | -0.0273        |\n",
            "|    reward             | -0.00018170162 |\n",
            "|    std                | 7.73           |\n",
            "|    value_loss         | 6.26e-05       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 511           |\n",
            "|    iterations         | 5700          |\n",
            "|    time_elapsed       | 55            |\n",
            "|    total_timesteps    | 28500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.5          |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5699          |\n",
            "|    policy_loss        | -0.0424       |\n",
            "|    reward             | -0.0062970985 |\n",
            "|    std                | 8.01          |\n",
            "|    value_loss         | 0.000223      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 511          |\n",
            "|    iterations         | 5800         |\n",
            "|    time_elapsed       | 56           |\n",
            "|    total_timesteps    | 29000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.53        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5799         |\n",
            "|    policy_loss        | -0.0835      |\n",
            "|    reward             | 0.0059525752 |\n",
            "|    std                | 8.28         |\n",
            "|    value_loss         | 0.000599     |\n",
            "----------------------------------------\n",
            "day: 2917, episode: 10\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 7654.51\n",
            "total_reward: -2345.49\n",
            "total_cost: 108.74\n",
            "total_trades: 2917\n",
            "Sharpe: -0.087\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 510         |\n",
            "|    iterations         | 5900        |\n",
            "|    time_elapsed       | 57          |\n",
            "|    total_timesteps    | 29500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.57       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5899        |\n",
            "|    policy_loss        | -0.0763     |\n",
            "|    reward             | 0.011608395 |\n",
            "|    std                | 8.64        |\n",
            "|    value_loss         | 0.00051     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 511         |\n",
            "|    iterations         | 6000        |\n",
            "|    time_elapsed       | 58          |\n",
            "|    total_timesteps    | 30000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.6        |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5999        |\n",
            "|    policy_loss        | -0.0245     |\n",
            "|    reward             | -0.00732464 |\n",
            "|    std                | 8.84        |\n",
            "|    value_loss         | 0.000118    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 510          |\n",
            "|    iterations         | 6100         |\n",
            "|    time_elapsed       | 59           |\n",
            "|    total_timesteps    | 30500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.63        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6099         |\n",
            "|    policy_loss        | 0.0268       |\n",
            "|    reward             | 0.0037794586 |\n",
            "|    std                | 9.1          |\n",
            "|    value_loss         | 0.000139     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 511          |\n",
            "|    iterations         | 6200         |\n",
            "|    time_elapsed       | 60           |\n",
            "|    total_timesteps    | 31000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.64        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6199         |\n",
            "|    policy_loss        | 0.0194       |\n",
            "|    reward             | 0.0020763269 |\n",
            "|    std                | 9.21         |\n",
            "|    value_loss         | 6.59e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 511           |\n",
            "|    iterations         | 6300          |\n",
            "|    time_elapsed       | 61            |\n",
            "|    total_timesteps    | 31500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.67         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6299          |\n",
            "|    policy_loss        | -0.00202      |\n",
            "|    reward             | -0.0031162626 |\n",
            "|    std                | 9.48          |\n",
            "|    value_loss         | 1.2e-05       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 511         |\n",
            "|    iterations         | 6400        |\n",
            "|    time_elapsed       | 62          |\n",
            "|    total_timesteps    | 32000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.68       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6399        |\n",
            "|    policy_loss        | -0.224      |\n",
            "|    reward             | 0.007965145 |\n",
            "|    std                | 9.58        |\n",
            "|    value_loss         | 0.00292     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 511          |\n",
            "|    iterations         | 6500         |\n",
            "|    time_elapsed       | 63           |\n",
            "|    total_timesteps    | 32500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.7         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6499         |\n",
            "|    policy_loss        | -0.199       |\n",
            "|    reward             | -0.007163783 |\n",
            "|    std                | 9.82         |\n",
            "|    value_loss         | 0.00331      |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 511        |\n",
            "|    iterations         | 6600       |\n",
            "|    time_elapsed       | 64         |\n",
            "|    total_timesteps    | 33000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -3.73      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6599       |\n",
            "|    policy_loss        | 0.169      |\n",
            "|    reward             | 0.00813175 |\n",
            "|    std                | 10.1       |\n",
            "|    value_loss         | 0.00197    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 511         |\n",
            "|    iterations         | 6700        |\n",
            "|    time_elapsed       | 65          |\n",
            "|    total_timesteps    | 33500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.76       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6699        |\n",
            "|    policy_loss        | 0.00401     |\n",
            "|    reward             | 0.016738549 |\n",
            "|    std                | 10.4        |\n",
            "|    value_loss         | 1.75e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 511          |\n",
            "|    iterations         | 6800         |\n",
            "|    time_elapsed       | 66           |\n",
            "|    total_timesteps    | 34000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.79        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6799         |\n",
            "|    policy_loss        | 0.212        |\n",
            "|    reward             | 0.0071758805 |\n",
            "|    std                | 10.7         |\n",
            "|    value_loss         | 0.00403      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 511          |\n",
            "|    iterations         | 6900         |\n",
            "|    time_elapsed       | 67           |\n",
            "|    total_timesteps    | 34500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.81        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6899         |\n",
            "|    policy_loss        | -0.000606    |\n",
            "|    reward             | 0.0018930024 |\n",
            "|    std                | 10.9         |\n",
            "|    value_loss         | 7.27e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 511          |\n",
            "|    iterations         | 7000         |\n",
            "|    time_elapsed       | 68           |\n",
            "|    total_timesteps    | 35000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.83        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6999         |\n",
            "|    policy_loss        | 0.0706       |\n",
            "|    reward             | 0.0018084804 |\n",
            "|    std                | 11.1         |\n",
            "|    value_loss         | 0.00048      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 511         |\n",
            "|    iterations         | 7100        |\n",
            "|    time_elapsed       | 69          |\n",
            "|    total_timesteps    | 35500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.83       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7099        |\n",
            "|    policy_loss        | 0.0181      |\n",
            "|    reward             | 0.010101485 |\n",
            "|    std                | 11.2        |\n",
            "|    value_loss         | 9.56e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 511         |\n",
            "|    iterations         | 7200        |\n",
            "|    time_elapsed       | 70          |\n",
            "|    total_timesteps    | 36000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.85       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7199        |\n",
            "|    policy_loss        | -0.0455     |\n",
            "|    reward             | 0.010326698 |\n",
            "|    std                | 11.4        |\n",
            "|    value_loss         | 0.000207    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 511         |\n",
            "|    iterations         | 7300        |\n",
            "|    time_elapsed       | 71          |\n",
            "|    total_timesteps    | 36500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.86       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7299        |\n",
            "|    policy_loss        | -0.279      |\n",
            "|    reward             | -0.01195714 |\n",
            "|    std                | 11.5        |\n",
            "|    value_loss         | 0.00547     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 511         |\n",
            "|    iterations         | 7400        |\n",
            "|    time_elapsed       | 72          |\n",
            "|    total_timesteps    | 37000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.89       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7399        |\n",
            "|    policy_loss        | -0.0177     |\n",
            "|    reward             | 0.028893571 |\n",
            "|    std                | 11.9        |\n",
            "|    value_loss         | 0.000681    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 511          |\n",
            "|    iterations         | 7500         |\n",
            "|    time_elapsed       | 73           |\n",
            "|    total_timesteps    | 37500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.92        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7499         |\n",
            "|    policy_loss        | -0.00326     |\n",
            "|    reward             | -0.030825898 |\n",
            "|    std                | 12.2         |\n",
            "|    value_loss         | 0.000149     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 512          |\n",
            "|    iterations         | 7600         |\n",
            "|    time_elapsed       | 74           |\n",
            "|    total_timesteps    | 38000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.92        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7599         |\n",
            "|    policy_loss        | 0.108        |\n",
            "|    reward             | -0.045319438 |\n",
            "|    std                | 12.2         |\n",
            "|    value_loss         | 0.000899     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 512         |\n",
            "|    iterations         | 7700        |\n",
            "|    time_elapsed       | 75          |\n",
            "|    total_timesteps    | 38500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.92       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7699        |\n",
            "|    policy_loss        | 0.0565      |\n",
            "|    reward             | 0.001828416 |\n",
            "|    std                | 12.2        |\n",
            "|    value_loss         | 0.000288    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 512          |\n",
            "|    iterations         | 7800         |\n",
            "|    time_elapsed       | 76           |\n",
            "|    total_timesteps    | 39000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.93        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7799         |\n",
            "|    policy_loss        | 0.139        |\n",
            "|    reward             | -0.004105484 |\n",
            "|    std                | 12.4         |\n",
            "|    value_loss         | 0.00101      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 513           |\n",
            "|    iterations         | 7900          |\n",
            "|    time_elapsed       | 76            |\n",
            "|    total_timesteps    | 39500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.96         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7899          |\n",
            "|    policy_loss        | 0.0653        |\n",
            "|    reward             | -3.920014e-06 |\n",
            "|    std                | 12.7          |\n",
            "|    value_loss         | 0.000432      |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 513        |\n",
            "|    iterations         | 8000       |\n",
            "|    time_elapsed       | 77         |\n",
            "|    total_timesteps    | 40000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -3.98      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7999       |\n",
            "|    policy_loss        | -0.153     |\n",
            "|    reward             | 0.03096784 |\n",
            "|    std                | 12.9       |\n",
            "|    value_loss         | 0.00184    |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 513        |\n",
            "|    iterations         | 8100       |\n",
            "|    time_elapsed       | 78         |\n",
            "|    total_timesteps    | 40500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4         |\n",
            "|    explained_variance | 1.79e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8099       |\n",
            "|    policy_loss        | -0.129     |\n",
            "|    reward             | 0.11675246 |\n",
            "|    std                | 13.3       |\n",
            "|    value_loss         | 0.00138    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 513         |\n",
            "|    iterations         | 8200        |\n",
            "|    time_elapsed       | 79          |\n",
            "|    total_timesteps    | 41000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.01       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8199        |\n",
            "|    policy_loss        | -0.0394     |\n",
            "|    reward             | 0.012730255 |\n",
            "|    std                | 13.3        |\n",
            "|    value_loss         | 0.000408    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 513        |\n",
            "|    iterations         | 8300       |\n",
            "|    time_elapsed       | 80         |\n",
            "|    total_timesteps    | 41500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.02      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8299       |\n",
            "|    policy_loss        | -0.136     |\n",
            "|    reward             | 0.05966527 |\n",
            "|    std                | 13.5       |\n",
            "|    value_loss         | 0.00121    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 513         |\n",
            "|    iterations         | 8400        |\n",
            "|    time_elapsed       | 81          |\n",
            "|    total_timesteps    | 42000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.05       |\n",
            "|    explained_variance | 1.79e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8399        |\n",
            "|    policy_loss        | 0.0984      |\n",
            "|    reward             | 0.022900967 |\n",
            "|    std                | 13.8        |\n",
            "|    value_loss         | 0.00316     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 512         |\n",
            "|    iterations         | 8500        |\n",
            "|    time_elapsed       | 82          |\n",
            "|    total_timesteps    | 42500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.06       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8499        |\n",
            "|    policy_loss        | -0.000103   |\n",
            "|    reward             | 0.017685546 |\n",
            "|    std                | 14          |\n",
            "|    value_loss         | 0.000238    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 511         |\n",
            "|    iterations         | 8600        |\n",
            "|    time_elapsed       | 84          |\n",
            "|    total_timesteps    | 43000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.07       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8599        |\n",
            "|    policy_loss        | 0.152       |\n",
            "|    reward             | 0.056842137 |\n",
            "|    std                | 14.2        |\n",
            "|    value_loss         | 0.00113     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 511          |\n",
            "|    iterations         | 8700         |\n",
            "|    time_elapsed       | 85           |\n",
            "|    total_timesteps    | 43500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.08        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8699         |\n",
            "|    policy_loss        | 0.0052       |\n",
            "|    reward             | -0.044119127 |\n",
            "|    std                | 14.3         |\n",
            "|    value_loss         | 0.000725     |\n",
            "----------------------------------------\n",
            "day: 2917, episode: 15\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 4450.79\n",
            "total_reward: -5549.21\n",
            "total_cost: 109.34\n",
            "total_trades: 2917\n",
            "Sharpe: 0.062\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 511         |\n",
            "|    iterations         | 8800        |\n",
            "|    time_elapsed       | 86          |\n",
            "|    total_timesteps    | 44000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.09       |\n",
            "|    explained_variance | -2.38e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8799        |\n",
            "|    policy_loss        | 0.121       |\n",
            "|    reward             | 0.013300126 |\n",
            "|    std                | 14.4        |\n",
            "|    value_loss         | 0.000757    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 510          |\n",
            "|    iterations         | 8900         |\n",
            "|    time_elapsed       | 87           |\n",
            "|    total_timesteps    | 44500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.1         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8899         |\n",
            "|    policy_loss        | -0.0509      |\n",
            "|    reward             | 0.0077343336 |\n",
            "|    std                | 14.6         |\n",
            "|    value_loss         | 0.000166     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 510         |\n",
            "|    iterations         | 9000        |\n",
            "|    time_elapsed       | 88          |\n",
            "|    total_timesteps    | 45000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.13       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8999        |\n",
            "|    policy_loss        | -0.0486     |\n",
            "|    reward             | -0.00656811 |\n",
            "|    std                | 15.1        |\n",
            "|    value_loss         | 0.000165    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 510          |\n",
            "|    iterations         | 9100         |\n",
            "|    time_elapsed       | 89           |\n",
            "|    total_timesteps    | 45500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.15        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9099         |\n",
            "|    policy_loss        | -0.009       |\n",
            "|    reward             | 0.0019354869 |\n",
            "|    std                | 15.4         |\n",
            "|    value_loss         | 7.85e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 510           |\n",
            "|    iterations         | 9200          |\n",
            "|    time_elapsed       | 90            |\n",
            "|    total_timesteps    | 46000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.17         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9199          |\n",
            "|    policy_loss        | 0.116         |\n",
            "|    reward             | -0.0032191775 |\n",
            "|    std                | 15.7          |\n",
            "|    value_loss         | 0.00283       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 510           |\n",
            "|    iterations         | 9300          |\n",
            "|    time_elapsed       | 91            |\n",
            "|    total_timesteps    | 46500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.2          |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9299          |\n",
            "|    policy_loss        | -0.0354       |\n",
            "|    reward             | -0.0035902858 |\n",
            "|    std                | 16.2          |\n",
            "|    value_loss         | 0.00175       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 510          |\n",
            "|    iterations         | 9400         |\n",
            "|    time_elapsed       | 92           |\n",
            "|    total_timesteps    | 47000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.22        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9399         |\n",
            "|    policy_loss        | 0.00339      |\n",
            "|    reward             | -0.008244402 |\n",
            "|    std                | 16.5         |\n",
            "|    value_loss         | 4.57e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 510         |\n",
            "|    iterations         | 9500        |\n",
            "|    time_elapsed       | 93          |\n",
            "|    total_timesteps    | 47500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.24       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9499        |\n",
            "|    policy_loss        | -0.031      |\n",
            "|    reward             | 0.007451941 |\n",
            "|    std                | 16.8        |\n",
            "|    value_loss         | 0.00014     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 510          |\n",
            "|    iterations         | 9600         |\n",
            "|    time_elapsed       | 94           |\n",
            "|    total_timesteps    | 48000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.26        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9599         |\n",
            "|    policy_loss        | -0.0535      |\n",
            "|    reward             | -0.013676099 |\n",
            "|    std                | 17.2         |\n",
            "|    value_loss         | 0.000165     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 510          |\n",
            "|    iterations         | 9700         |\n",
            "|    time_elapsed       | 95           |\n",
            "|    total_timesteps    | 48500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.28        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9699         |\n",
            "|    policy_loss        | -0.0213      |\n",
            "|    reward             | -0.011600576 |\n",
            "|    std                | 17.5         |\n",
            "|    value_loss         | 0.000177     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 510           |\n",
            "|    iterations         | 9800          |\n",
            "|    time_elapsed       | 96            |\n",
            "|    total_timesteps    | 49000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.3          |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9799          |\n",
            "|    policy_loss        | -0.0188       |\n",
            "|    reward             | -0.0050303084 |\n",
            "|    std                | 17.8          |\n",
            "|    value_loss         | 6.26e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 510          |\n",
            "|    iterations         | 9900         |\n",
            "|    time_elapsed       | 97           |\n",
            "|    total_timesteps    | 49500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.31        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9899         |\n",
            "|    policy_loss        | -0.00636     |\n",
            "|    reward             | -0.022368101 |\n",
            "|    std                | 18.1         |\n",
            "|    value_loss         | 0.000207     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 509         |\n",
            "|    iterations         | 10000       |\n",
            "|    time_elapsed       | 98          |\n",
            "|    total_timesteps    | 50000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.33       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9999        |\n",
            "|    policy_loss        | -0.288      |\n",
            "|    reward             | -0.02041743 |\n",
            "|    std                | 18.3        |\n",
            "|    value_loss         | 0.00551     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 509          |\n",
            "|    iterations         | 10100        |\n",
            "|    time_elapsed       | 99           |\n",
            "|    total_timesteps    | 50500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.34        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10099        |\n",
            "|    policy_loss        | 0.0437       |\n",
            "|    reward             | -0.005838177 |\n",
            "|    std                | 18.6         |\n",
            "|    value_loss         | 0.000346     |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 509        |\n",
            "|    iterations         | 10200      |\n",
            "|    time_elapsed       | 100        |\n",
            "|    total_timesteps    | 51000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.35      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10199      |\n",
            "|    policy_loss        | -0.432     |\n",
            "|    reward             | 0.01136829 |\n",
            "|    std                | 18.8       |\n",
            "|    value_loss         | 0.0143     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 509         |\n",
            "|    iterations         | 10300       |\n",
            "|    time_elapsed       | 101         |\n",
            "|    total_timesteps    | 51500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.36       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10299       |\n",
            "|    policy_loss        | -0.116      |\n",
            "|    reward             | 0.056321394 |\n",
            "|    std                | 18.9        |\n",
            "|    value_loss         | 0.000741    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 509          |\n",
            "|    iterations         | 10400        |\n",
            "|    time_elapsed       | 102          |\n",
            "|    total_timesteps    | 52000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.4         |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10399        |\n",
            "|    policy_loss        | -0.111       |\n",
            "|    reward             | -0.012124432 |\n",
            "|    std                | 19.7         |\n",
            "|    value_loss         | 0.00107      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 509          |\n",
            "|    iterations         | 10500        |\n",
            "|    time_elapsed       | 103          |\n",
            "|    total_timesteps    | 52500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.4         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10499        |\n",
            "|    policy_loss        | 0.0334       |\n",
            "|    reward             | -0.006294111 |\n",
            "|    std                | 19.6         |\n",
            "|    value_loss         | 0.000415     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 509         |\n",
            "|    iterations         | 10600       |\n",
            "|    time_elapsed       | 104         |\n",
            "|    total_timesteps    | 53000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.41       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10599       |\n",
            "|    policy_loss        | 0.0706      |\n",
            "|    reward             | 0.015077026 |\n",
            "|    std                | 19.9        |\n",
            "|    value_loss         | 0.000249    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 509           |\n",
            "|    iterations         | 10700         |\n",
            "|    time_elapsed       | 105           |\n",
            "|    total_timesteps    | 53500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.42         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10699         |\n",
            "|    policy_loss        | -0.126        |\n",
            "|    reward             | -0.0015510828 |\n",
            "|    std                | 20.2          |\n",
            "|    value_loss         | 0.000965      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 509           |\n",
            "|    iterations         | 10800         |\n",
            "|    time_elapsed       | 106           |\n",
            "|    total_timesteps    | 54000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.44         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10799         |\n",
            "|    policy_loss        | -0.0383       |\n",
            "|    reward             | -0.0033716764 |\n",
            "|    std                | 20.6          |\n",
            "|    value_loss         | 0.000888      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 509          |\n",
            "|    iterations         | 10900        |\n",
            "|    time_elapsed       | 106          |\n",
            "|    total_timesteps    | 54500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.46        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10899        |\n",
            "|    policy_loss        | -0.0446      |\n",
            "|    reward             | -0.017050989 |\n",
            "|    std                | 21           |\n",
            "|    value_loss         | 0.000274     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 509          |\n",
            "|    iterations         | 11000        |\n",
            "|    time_elapsed       | 107          |\n",
            "|    total_timesteps    | 55000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.49        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10999        |\n",
            "|    policy_loss        | 0.0147       |\n",
            "|    reward             | -0.011678133 |\n",
            "|    std                | 21.5         |\n",
            "|    value_loss         | 3.04e-05     |\n",
            "----------------------------------------\n",
            "======A2C Validation from:  2021-11-02 to  2021-12-02\n",
            "A2C Sharpe Ratio:  0.0782870618770452\n",
            "======Best Model Retraining from:  2010-04-01 to  2021-12-02\n",
            "======Trading from:  2021-12-02 to  2022-01-03\n",
            "[[ 1.4476484e+04  3.0385111e+01 -1.8900000e+02  4.2746419e-01\n",
            "   3.1652199e+01  2.9830368e+01  5.7070820e+01  1.2103013e+01\n",
            "   1.2698821e+01  2.9958473e+01  2.8615505e+01]]\n",
            "============================================\n",
            "turbulence_threshold:  12.04306128869847\n",
            "======Model training from:  2010-04-01 to  2021-12-02\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c\\a2c_273_1\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 514          |\n",
            "|    iterations         | 100          |\n",
            "|    time_elapsed       | 0            |\n",
            "|    total_timesteps    | 500          |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.47        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 99           |\n",
            "|    policy_loss        | -0.0267      |\n",
            "|    reward             | -0.007808196 |\n",
            "|    std                | 1.05         |\n",
            "|    value_loss         | 0.000306     |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 504        |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 1          |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.49      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | 0.00811    |\n",
            "|    reward             | 0.00310079 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 0.000132   |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 503          |\n",
            "|    iterations         | 300          |\n",
            "|    time_elapsed       | 2            |\n",
            "|    total_timesteps    | 1500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.52        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 299          |\n",
            "|    policy_loss        | -0.00105     |\n",
            "|    reward             | -0.011650552 |\n",
            "|    std                | 1.1          |\n",
            "|    value_loss         | 6.13e-06     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 507           |\n",
            "|    iterations         | 400           |\n",
            "|    time_elapsed       | 3             |\n",
            "|    total_timesteps    | 2000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.55         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 399           |\n",
            "|    policy_loss        | -0.0137       |\n",
            "|    reward             | -0.0017197987 |\n",
            "|    std                | 1.14          |\n",
            "|    value_loss         | 0.000105      |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 514        |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 4          |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.57      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | 0.00567    |\n",
            "|    reward             | 0.04855985 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 0.000434   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 509         |\n",
            "|    iterations         | 600         |\n",
            "|    time_elapsed       | 5           |\n",
            "|    total_timesteps    | 3000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.6        |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 599         |\n",
            "|    policy_loss        | 0.0127      |\n",
            "|    reward             | 0.012523776 |\n",
            "|    std                | 1.2         |\n",
            "|    value_loss         | 8.05e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 510         |\n",
            "|    iterations         | 700         |\n",
            "|    time_elapsed       | 6           |\n",
            "|    total_timesteps    | 3500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.61       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 699         |\n",
            "|    policy_loss        | 0.00677     |\n",
            "|    reward             | 0.032166567 |\n",
            "|    std                | 1.21        |\n",
            "|    value_loss         | 6.79e-05    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 507        |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 7          |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.63      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | 0.0174     |\n",
            "|    reward             | 0.06995985 |\n",
            "|    std                | 1.23       |\n",
            "|    value_loss         | 0.000197   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 508         |\n",
            "|    iterations         | 900         |\n",
            "|    time_elapsed       | 8           |\n",
            "|    total_timesteps    | 4500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.64       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 899         |\n",
            "|    policy_loss        | -0.0177     |\n",
            "|    reward             | 0.008403796 |\n",
            "|    std                | 1.24        |\n",
            "|    value_loss         | 0.000216    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 506          |\n",
            "|    iterations         | 1000         |\n",
            "|    time_elapsed       | 9            |\n",
            "|    total_timesteps    | 5000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.66        |\n",
            "|    explained_variance | -2.38e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 999          |\n",
            "|    policy_loss        | 0.023        |\n",
            "|    reward             | -0.071799025 |\n",
            "|    std                | 1.27         |\n",
            "|    value_loss         | 0.000711     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 488         |\n",
            "|    iterations         | 1100        |\n",
            "|    time_elapsed       | 11          |\n",
            "|    total_timesteps    | 5500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.66       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1099        |\n",
            "|    policy_loss        | -0.0897     |\n",
            "|    reward             | -0.03180553 |\n",
            "|    std                | 1.27        |\n",
            "|    value_loss         | 0.00584     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 477           |\n",
            "|    iterations         | 1200          |\n",
            "|    time_elapsed       | 12            |\n",
            "|    total_timesteps    | 6000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.67         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1199          |\n",
            "|    policy_loss        | -0.0135       |\n",
            "|    reward             | -0.0054249004 |\n",
            "|    std                | 1.28          |\n",
            "|    value_loss         | 0.000144      |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 476        |\n",
            "|    iterations         | 1300       |\n",
            "|    time_elapsed       | 13         |\n",
            "|    total_timesteps    | 6500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.68      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1299       |\n",
            "|    policy_loss        | -0.0423    |\n",
            "|    reward             | 0.02066439 |\n",
            "|    std                | 1.3        |\n",
            "|    value_loss         | 0.00113    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 472         |\n",
            "|    iterations         | 1400        |\n",
            "|    time_elapsed       | 14          |\n",
            "|    total_timesteps    | 7000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.7        |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1399        |\n",
            "|    policy_loss        | -0.0215     |\n",
            "|    reward             | 0.018841015 |\n",
            "|    std                | 1.33        |\n",
            "|    value_loss         | 0.000159    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 471        |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 15         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.7       |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | -0.0234    |\n",
            "|    reward             | 0.03623983 |\n",
            "|    std                | 1.33       |\n",
            "|    value_loss         | 0.000346   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 475         |\n",
            "|    iterations         | 1600        |\n",
            "|    time_elapsed       | 16          |\n",
            "|    total_timesteps    | 8000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.71       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1599        |\n",
            "|    policy_loss        | -0.167      |\n",
            "|    reward             | 0.061897602 |\n",
            "|    std                | 1.34        |\n",
            "|    value_loss         | 0.00556     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 478         |\n",
            "|    iterations         | 1700        |\n",
            "|    time_elapsed       | 17          |\n",
            "|    total_timesteps    | 8500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.7        |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1699        |\n",
            "|    policy_loss        | 0.0254      |\n",
            "|    reward             | -0.23523453 |\n",
            "|    std                | 1.33        |\n",
            "|    value_loss         | 0.00276     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 473          |\n",
            "|    iterations         | 1800         |\n",
            "|    time_elapsed       | 18           |\n",
            "|    total_timesteps    | 9000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.71        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1799         |\n",
            "|    policy_loss        | 0.00973      |\n",
            "|    reward             | -0.014956582 |\n",
            "|    std                | 1.34         |\n",
            "|    value_loss         | 0.000254     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 467          |\n",
            "|    iterations         | 1900         |\n",
            "|    time_elapsed       | 20           |\n",
            "|    total_timesteps    | 9500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.71        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1899         |\n",
            "|    policy_loss        | -0.0798      |\n",
            "|    reward             | -0.011543279 |\n",
            "|    std                | 1.34         |\n",
            "|    value_loss         | 0.00387      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 463          |\n",
            "|    iterations         | 2000         |\n",
            "|    time_elapsed       | 21           |\n",
            "|    total_timesteps    | 10000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.72        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1999         |\n",
            "|    policy_loss        | -0.0335      |\n",
            "|    reward             | 0.0058506783 |\n",
            "|    std                | 1.35         |\n",
            "|    value_loss         | 0.00141      |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 460            |\n",
            "|    iterations         | 2100           |\n",
            "|    time_elapsed       | 22             |\n",
            "|    total_timesteps    | 10500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -1.73          |\n",
            "|    explained_variance | -1.19e-07      |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 2099           |\n",
            "|    policy_loss        | -0.112         |\n",
            "|    reward             | -4.5833444e-06 |\n",
            "|    std                | 1.37           |\n",
            "|    value_loss         | 0.00225        |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 457          |\n",
            "|    iterations         | 2200         |\n",
            "|    time_elapsed       | 24           |\n",
            "|    total_timesteps    | 11000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.73        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2199         |\n",
            "|    policy_loss        | 0.115        |\n",
            "|    reward             | -0.021480566 |\n",
            "|    std                | 1.37         |\n",
            "|    value_loss         | 0.0155       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 458         |\n",
            "|    iterations         | 2300        |\n",
            "|    time_elapsed       | 25          |\n",
            "|    total_timesteps    | 11500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.74       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2299        |\n",
            "|    policy_loss        | 0.0107      |\n",
            "|    reward             | 0.058351554 |\n",
            "|    std                | 1.38        |\n",
            "|    value_loss         | 0.00846     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 457          |\n",
            "|    iterations         | 2400         |\n",
            "|    time_elapsed       | 26           |\n",
            "|    total_timesteps    | 12000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.75        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2399         |\n",
            "|    policy_loss        | 0.017        |\n",
            "|    reward             | -0.008887049 |\n",
            "|    std                | 1.39         |\n",
            "|    value_loss         | 0.0017       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 457          |\n",
            "|    iterations         | 2500         |\n",
            "|    time_elapsed       | 27           |\n",
            "|    total_timesteps    | 12500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.76        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2499         |\n",
            "|    policy_loss        | -0.0588      |\n",
            "|    reward             | -0.002867781 |\n",
            "|    std                | 1.4          |\n",
            "|    value_loss         | 0.00187      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 456          |\n",
            "|    iterations         | 2600         |\n",
            "|    time_elapsed       | 28           |\n",
            "|    total_timesteps    | 13000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.76        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2599         |\n",
            "|    policy_loss        | 0.109        |\n",
            "|    reward             | -0.015492712 |\n",
            "|    std                | 1.41         |\n",
            "|    value_loss         | 0.00674      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 450         |\n",
            "|    iterations         | 2700        |\n",
            "|    time_elapsed       | 29          |\n",
            "|    total_timesteps    | 13500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.76       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2699        |\n",
            "|    policy_loss        | 0.123       |\n",
            "|    reward             | 0.001542839 |\n",
            "|    std                | 1.41        |\n",
            "|    value_loss         | 0.00478     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 450          |\n",
            "|    iterations         | 2800         |\n",
            "|    time_elapsed       | 31           |\n",
            "|    total_timesteps    | 14000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.78        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2799         |\n",
            "|    policy_loss        | -0.0879      |\n",
            "|    reward             | 0.0060260454 |\n",
            "|    std                | 1.43         |\n",
            "|    value_loss         | 0.00419      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 444         |\n",
            "|    iterations         | 2900        |\n",
            "|    time_elapsed       | 32          |\n",
            "|    total_timesteps    | 14500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.77       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2899        |\n",
            "|    policy_loss        | 0.377       |\n",
            "|    reward             | 0.028287685 |\n",
            "|    std                | 1.43        |\n",
            "|    value_loss         | 0.0973      |\n",
            "---------------------------------------\n",
            "day: 2938, episode: 5\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -13515.22\n",
            "total_reward: -23515.22\n",
            "total_cost: 132.94\n",
            "total_trades: 2938\n",
            "Sharpe: 0.073\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 443           |\n",
            "|    iterations         | 3000          |\n",
            "|    time_elapsed       | 33            |\n",
            "|    total_timesteps    | 15000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.78         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2999          |\n",
            "|    policy_loss        | 0.0444        |\n",
            "|    reward             | -0.0041318764 |\n",
            "|    std                | 1.44          |\n",
            "|    value_loss         | 0.000921      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 442         |\n",
            "|    iterations         | 3100        |\n",
            "|    time_elapsed       | 35          |\n",
            "|    total_timesteps    | 15500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.79       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3099        |\n",
            "|    policy_loss        | -0.0852     |\n",
            "|    reward             | -0.06280009 |\n",
            "|    std                | 1.45        |\n",
            "|    value_loss         | 0.00274     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 438          |\n",
            "|    iterations         | 3200         |\n",
            "|    time_elapsed       | 36           |\n",
            "|    total_timesteps    | 16000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.82        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3199         |\n",
            "|    policy_loss        | 0.0337       |\n",
            "|    reward             | -0.024303492 |\n",
            "|    std                | 1.49         |\n",
            "|    value_loss         | 0.00206      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 435         |\n",
            "|    iterations         | 3300        |\n",
            "|    time_elapsed       | 37          |\n",
            "|    total_timesteps    | 16500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.83       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3299        |\n",
            "|    policy_loss        | 0.0232      |\n",
            "|    reward             | 0.007385239 |\n",
            "|    std                | 1.5         |\n",
            "|    value_loss         | 0.000438    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 434         |\n",
            "|    iterations         | 3400        |\n",
            "|    time_elapsed       | 39          |\n",
            "|    total_timesteps    | 17000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.83       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3399        |\n",
            "|    policy_loss        | -0.0301     |\n",
            "|    reward             | -0.04801093 |\n",
            "|    std                | 1.51        |\n",
            "|    value_loss         | 0.0047      |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 436          |\n",
            "|    iterations         | 3500         |\n",
            "|    time_elapsed       | 40           |\n",
            "|    total_timesteps    | 17500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.84        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3499         |\n",
            "|    policy_loss        | 0.071        |\n",
            "|    reward             | -0.027457522 |\n",
            "|    std                | 1.52         |\n",
            "|    value_loss         | 0.011        |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 434         |\n",
            "|    iterations         | 3600        |\n",
            "|    time_elapsed       | 41          |\n",
            "|    total_timesteps    | 18000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.84       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3599        |\n",
            "|    policy_loss        | 0.0745      |\n",
            "|    reward             | 0.010452647 |\n",
            "|    std                | 1.53        |\n",
            "|    value_loss         | 0.00282     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 432          |\n",
            "|    iterations         | 3700         |\n",
            "|    time_elapsed       | 42           |\n",
            "|    total_timesteps    | 18500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.85        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3699         |\n",
            "|    policy_loss        | -0.0577      |\n",
            "|    reward             | -0.022020744 |\n",
            "|    std                | 1.54         |\n",
            "|    value_loss         | 0.00142      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 431          |\n",
            "|    iterations         | 3800         |\n",
            "|    time_elapsed       | 44           |\n",
            "|    total_timesteps    | 19000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.88        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3799         |\n",
            "|    policy_loss        | 0.118        |\n",
            "|    reward             | 0.0046815965 |\n",
            "|    std                | 1.59         |\n",
            "|    value_loss         | 0.011        |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 432         |\n",
            "|    iterations         | 3900        |\n",
            "|    time_elapsed       | 45          |\n",
            "|    total_timesteps    | 19500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.89       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3899        |\n",
            "|    policy_loss        | -0.0491     |\n",
            "|    reward             | 0.015558516 |\n",
            "|    std                | 1.6         |\n",
            "|    value_loss         | 0.00267     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 431          |\n",
            "|    iterations         | 4000         |\n",
            "|    time_elapsed       | 46           |\n",
            "|    total_timesteps    | 20000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.89        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3999         |\n",
            "|    policy_loss        | 0.064        |\n",
            "|    reward             | -0.011855509 |\n",
            "|    std                | 1.61         |\n",
            "|    value_loss         | 0.0252       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 431         |\n",
            "|    iterations         | 4100        |\n",
            "|    time_elapsed       | 47          |\n",
            "|    total_timesteps    | 20500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.9        |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4099        |\n",
            "|    policy_loss        | -0.0909     |\n",
            "|    reward             | -0.04626817 |\n",
            "|    std                | 1.61        |\n",
            "|    value_loss         | 0.00256     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 429        |\n",
            "|    iterations         | 4200       |\n",
            "|    time_elapsed       | 48         |\n",
            "|    total_timesteps    | 21000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.9       |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4199       |\n",
            "|    policy_loss        | -0.102     |\n",
            "|    reward             | 0.05530397 |\n",
            "|    std                | 1.62       |\n",
            "|    value_loss         | 0.00388    |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 428          |\n",
            "|    iterations         | 4300         |\n",
            "|    time_elapsed       | 50           |\n",
            "|    total_timesteps    | 21500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.91        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4299         |\n",
            "|    policy_loss        | -0.0094      |\n",
            "|    reward             | -0.029976917 |\n",
            "|    std                | 1.64         |\n",
            "|    value_loss         | 0.000204     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 428          |\n",
            "|    iterations         | 4400         |\n",
            "|    time_elapsed       | 51           |\n",
            "|    total_timesteps    | 22000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.92        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4399         |\n",
            "|    policy_loss        | -0.0866      |\n",
            "|    reward             | -0.022179242 |\n",
            "|    std                | 1.65         |\n",
            "|    value_loss         | 0.00308      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 426          |\n",
            "|    iterations         | 4500         |\n",
            "|    time_elapsed       | 52           |\n",
            "|    total_timesteps    | 22500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.92        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4499         |\n",
            "|    policy_loss        | -0.0714      |\n",
            "|    reward             | -0.025916468 |\n",
            "|    std                | 1.66         |\n",
            "|    value_loss         | 0.00359      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 426         |\n",
            "|    iterations         | 4600        |\n",
            "|    time_elapsed       | 53          |\n",
            "|    total_timesteps    | 23000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.93       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4599        |\n",
            "|    policy_loss        | 0.104       |\n",
            "|    reward             | 0.046730626 |\n",
            "|    std                | 1.67        |\n",
            "|    value_loss         | 0.00307     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 425          |\n",
            "|    iterations         | 4700         |\n",
            "|    time_elapsed       | 55           |\n",
            "|    total_timesteps    | 23500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.95        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4699         |\n",
            "|    policy_loss        | -0.0337      |\n",
            "|    reward             | -0.009339277 |\n",
            "|    std                | 1.7          |\n",
            "|    value_loss         | 0.00115      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 425           |\n",
            "|    iterations         | 4800          |\n",
            "|    time_elapsed       | 56            |\n",
            "|    total_timesteps    | 24000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.96         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4799          |\n",
            "|    policy_loss        | 0.0591        |\n",
            "|    reward             | -0.0004840719 |\n",
            "|    std                | 1.73          |\n",
            "|    value_loss         | 0.000889      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 425           |\n",
            "|    iterations         | 4900          |\n",
            "|    time_elapsed       | 57            |\n",
            "|    total_timesteps    | 24500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.98         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4899          |\n",
            "|    policy_loss        | 0.0216        |\n",
            "|    reward             | -0.0018581303 |\n",
            "|    std                | 1.76          |\n",
            "|    value_loss         | 0.000278      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 425          |\n",
            "|    iterations         | 5000         |\n",
            "|    time_elapsed       | 58           |\n",
            "|    total_timesteps    | 25000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.01        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4999         |\n",
            "|    policy_loss        | -0.0261      |\n",
            "|    reward             | -0.006344212 |\n",
            "|    std                | 1.82         |\n",
            "|    value_loss         | 0.00056      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 425          |\n",
            "|    iterations         | 5100         |\n",
            "|    time_elapsed       | 59           |\n",
            "|    total_timesteps    | 25500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.03        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5099         |\n",
            "|    policy_loss        | -0.0769      |\n",
            "|    reward             | -0.002117197 |\n",
            "|    std                | 1.85         |\n",
            "|    value_loss         | 0.00151      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 426           |\n",
            "|    iterations         | 5200          |\n",
            "|    time_elapsed       | 60            |\n",
            "|    total_timesteps    | 26000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.05         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5199          |\n",
            "|    policy_loss        | -0.0232       |\n",
            "|    reward             | -0.0046765073 |\n",
            "|    std                | 1.89          |\n",
            "|    value_loss         | 0.000208      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 426          |\n",
            "|    iterations         | 5300         |\n",
            "|    time_elapsed       | 62           |\n",
            "|    total_timesteps    | 26500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.09        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5299         |\n",
            "|    policy_loss        | 0.0298       |\n",
            "|    reward             | -0.006926361 |\n",
            "|    std                | 1.95         |\n",
            "|    value_loss         | 0.00026      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 424          |\n",
            "|    iterations         | 5400         |\n",
            "|    time_elapsed       | 63           |\n",
            "|    total_timesteps    | 27000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.12        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5399         |\n",
            "|    policy_loss        | -0.00538     |\n",
            "|    reward             | -0.005003122 |\n",
            "|    std                | 2.01         |\n",
            "|    value_loss         | 4.48e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 424           |\n",
            "|    iterations         | 5500          |\n",
            "|    time_elapsed       | 64            |\n",
            "|    total_timesteps    | 27500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.15         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5499          |\n",
            "|    policy_loss        | -0.0137       |\n",
            "|    reward             | -0.0003751456 |\n",
            "|    std                | 2.07          |\n",
            "|    value_loss         | 6.87e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 423         |\n",
            "|    iterations         | 5600        |\n",
            "|    time_elapsed       | 66          |\n",
            "|    total_timesteps    | 28000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.18       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5599        |\n",
            "|    policy_loss        | 0.00557     |\n",
            "|    reward             | 0.001033441 |\n",
            "|    std                | 2.15        |\n",
            "|    value_loss         | 1.19e-05    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 424           |\n",
            "|    iterations         | 5700          |\n",
            "|    time_elapsed       | 67            |\n",
            "|    total_timesteps    | 28500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.22         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5699          |\n",
            "|    policy_loss        | -0.0108       |\n",
            "|    reward             | -0.0029226376 |\n",
            "|    std                | 2.23          |\n",
            "|    value_loss         | 3.28e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 424          |\n",
            "|    iterations         | 5800         |\n",
            "|    time_elapsed       | 68           |\n",
            "|    total_timesteps    | 29000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.27        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5799         |\n",
            "|    policy_loss        | -0.0742      |\n",
            "|    reward             | -0.009395587 |\n",
            "|    std                | 2.33         |\n",
            "|    value_loss         | 0.000671     |\n",
            "----------------------------------------\n",
            "day: 2938, episode: 10\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 7327.39\n",
            "total_reward: -2672.61\n",
            "total_cost: 123.22\n",
            "total_trades: 2938\n",
            "Sharpe: -0.136\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 422           |\n",
            "|    iterations         | 5900          |\n",
            "|    time_elapsed       | 69            |\n",
            "|    total_timesteps    | 29500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.29         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5899          |\n",
            "|    policy_loss        | -0.00838      |\n",
            "|    reward             | -0.0043532443 |\n",
            "|    std                | 2.4           |\n",
            "|    value_loss         | 2.49e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 423         |\n",
            "|    iterations         | 6000        |\n",
            "|    time_elapsed       | 70          |\n",
            "|    total_timesteps    | 30000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.32       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5999        |\n",
            "|    policy_loss        | 0.0164      |\n",
            "|    reward             | 0.017183688 |\n",
            "|    std                | 2.47        |\n",
            "|    value_loss         | 6.42e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 421          |\n",
            "|    iterations         | 6100         |\n",
            "|    time_elapsed       | 72           |\n",
            "|    total_timesteps    | 30500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.35        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6099         |\n",
            "|    policy_loss        | -0.0335      |\n",
            "|    reward             | -0.001161299 |\n",
            "|    std                | 2.54         |\n",
            "|    value_loss         | 0.000355     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 421           |\n",
            "|    iterations         | 6200          |\n",
            "|    time_elapsed       | 73            |\n",
            "|    total_timesteps    | 31000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.37         |\n",
            "|    explained_variance | 2.98e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6199          |\n",
            "|    policy_loss        | -0.00925      |\n",
            "|    reward             | -0.0051394156 |\n",
            "|    std                | 2.59          |\n",
            "|    value_loss         | 9.99e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 420          |\n",
            "|    iterations         | 6300         |\n",
            "|    time_elapsed       | 74           |\n",
            "|    total_timesteps    | 31500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.4         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6299         |\n",
            "|    policy_loss        | -0.0204      |\n",
            "|    reward             | -0.012703934 |\n",
            "|    std                | 2.68         |\n",
            "|    value_loss         | 0.000149     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 419         |\n",
            "|    iterations         | 6400        |\n",
            "|    time_elapsed       | 76          |\n",
            "|    total_timesteps    | 32000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.44       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6399        |\n",
            "|    policy_loss        | -0.0264     |\n",
            "|    reward             | 0.014386544 |\n",
            "|    std                | 2.78        |\n",
            "|    value_loss         | 0.00011     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 419         |\n",
            "|    iterations         | 6500        |\n",
            "|    time_elapsed       | 77          |\n",
            "|    total_timesteps    | 32500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.46       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6499        |\n",
            "|    policy_loss        | 0.0129      |\n",
            "|    reward             | 0.019254746 |\n",
            "|    std                | 2.83        |\n",
            "|    value_loss         | 0.000257    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 418           |\n",
            "|    iterations         | 6600          |\n",
            "|    time_elapsed       | 78            |\n",
            "|    total_timesteps    | 33000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.48         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6599          |\n",
            "|    policy_loss        | 0.022         |\n",
            "|    reward             | -0.0056603034 |\n",
            "|    std                | 2.9           |\n",
            "|    value_loss         | 0.000239      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 418          |\n",
            "|    iterations         | 6700         |\n",
            "|    time_elapsed       | 80           |\n",
            "|    total_timesteps    | 33500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.51        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6699         |\n",
            "|    policy_loss        | -0.032       |\n",
            "|    reward             | -0.004123018 |\n",
            "|    std                | 2.98         |\n",
            "|    value_loss         | 0.000245     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 418            |\n",
            "|    iterations         | 6800           |\n",
            "|    time_elapsed       | 81             |\n",
            "|    total_timesteps    | 34000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -2.53          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 6799           |\n",
            "|    policy_loss        | 0.00179        |\n",
            "|    reward             | -4.4490466e-06 |\n",
            "|    std                | 3.03           |\n",
            "|    value_loss         | 4.27e-05       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 418          |\n",
            "|    iterations         | 6900         |\n",
            "|    time_elapsed       | 82           |\n",
            "|    total_timesteps    | 34500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.54        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6899         |\n",
            "|    policy_loss        | -0.0529      |\n",
            "|    reward             | 0.0030950704 |\n",
            "|    std                | 3.07         |\n",
            "|    value_loss         | 0.000595     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 417          |\n",
            "|    iterations         | 7000         |\n",
            "|    time_elapsed       | 83           |\n",
            "|    total_timesteps    | 35000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.57        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6999         |\n",
            "|    policy_loss        | 0.0993       |\n",
            "|    reward             | -0.034303308 |\n",
            "|    std                | 3.16         |\n",
            "|    value_loss         | 0.00324      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 416          |\n",
            "|    iterations         | 7100         |\n",
            "|    time_elapsed       | 85           |\n",
            "|    total_timesteps    | 35500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.59        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7099         |\n",
            "|    policy_loss        | 0.0172       |\n",
            "|    reward             | -0.008638876 |\n",
            "|    std                | 3.24         |\n",
            "|    value_loss         | 0.000397     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 416          |\n",
            "|    iterations         | 7200         |\n",
            "|    time_elapsed       | 86           |\n",
            "|    total_timesteps    | 36000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.61        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7199         |\n",
            "|    policy_loss        | 0.0347       |\n",
            "|    reward             | 0.0011507734 |\n",
            "|    std                | 3.3          |\n",
            "|    value_loss         | 0.000284     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 416          |\n",
            "|    iterations         | 7300         |\n",
            "|    time_elapsed       | 87           |\n",
            "|    total_timesteps    | 36500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.64        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7299         |\n",
            "|    policy_loss        | -0.0404      |\n",
            "|    reward             | -0.012064157 |\n",
            "|    std                | 3.39         |\n",
            "|    value_loss         | 0.000422     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 416          |\n",
            "|    iterations         | 7400         |\n",
            "|    time_elapsed       | 88           |\n",
            "|    total_timesteps    | 37000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.65        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7399         |\n",
            "|    policy_loss        | -0.0115      |\n",
            "|    reward             | -0.005544944 |\n",
            "|    std                | 3.43         |\n",
            "|    value_loss         | 2.67e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 415          |\n",
            "|    iterations         | 7500         |\n",
            "|    time_elapsed       | 90           |\n",
            "|    total_timesteps    | 37500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.67        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7499         |\n",
            "|    policy_loss        | -0.0225      |\n",
            "|    reward             | -0.004552394 |\n",
            "|    std                | 3.51         |\n",
            "|    value_loss         | 0.00011      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 416          |\n",
            "|    iterations         | 7600         |\n",
            "|    time_elapsed       | 91           |\n",
            "|    total_timesteps    | 38000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.68        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7599         |\n",
            "|    policy_loss        | 0.19         |\n",
            "|    reward             | -0.021278033 |\n",
            "|    std                | 3.55         |\n",
            "|    value_loss         | 0.00336      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 417         |\n",
            "|    iterations         | 7700        |\n",
            "|    time_elapsed       | 92          |\n",
            "|    total_timesteps    | 38500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.71       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7699        |\n",
            "|    policy_loss        | 0.0985      |\n",
            "|    reward             | 0.011613963 |\n",
            "|    std                | 3.62        |\n",
            "|    value_loss         | 0.00121     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 417           |\n",
            "|    iterations         | 7800          |\n",
            "|    time_elapsed       | 93            |\n",
            "|    total_timesteps    | 39000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.72         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7799          |\n",
            "|    policy_loss        | -0.0146       |\n",
            "|    reward             | -0.0028278609 |\n",
            "|    std                | 3.68          |\n",
            "|    value_loss         | 8.79e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 418           |\n",
            "|    iterations         | 7900          |\n",
            "|    time_elapsed       | 94            |\n",
            "|    total_timesteps    | 39500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.74         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7899          |\n",
            "|    policy_loss        | -0.0169       |\n",
            "|    reward             | 0.00016260381 |\n",
            "|    std                | 3.76          |\n",
            "|    value_loss         | 4.17e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 419          |\n",
            "|    iterations         | 8000         |\n",
            "|    time_elapsed       | 95           |\n",
            "|    total_timesteps    | 40000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.77        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7999         |\n",
            "|    policy_loss        | -0.00031     |\n",
            "|    reward             | 0.0002748577 |\n",
            "|    std                | 3.88         |\n",
            "|    value_loss         | 1.01e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 420         |\n",
            "|    iterations         | 8100        |\n",
            "|    time_elapsed       | 96          |\n",
            "|    total_timesteps    | 40500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.81       |\n",
            "|    explained_variance | -2.38e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8099        |\n",
            "|    policy_loss        | 0.0197      |\n",
            "|    reward             | 0.013352503 |\n",
            "|    std                | 4.02        |\n",
            "|    value_loss         | 6.85e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 421          |\n",
            "|    iterations         | 8200         |\n",
            "|    time_elapsed       | 97           |\n",
            "|    total_timesteps    | 41000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.85        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8199         |\n",
            "|    policy_loss        | -0.0496      |\n",
            "|    reward             | -0.010883684 |\n",
            "|    std                | 4.18         |\n",
            "|    value_loss         | 0.000296     |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 422        |\n",
            "|    iterations         | 8300       |\n",
            "|    time_elapsed       | 98         |\n",
            "|    total_timesteps    | 41500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.89      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8299       |\n",
            "|    policy_loss        | 0.0766     |\n",
            "|    reward             | 0.01116564 |\n",
            "|    std                | 4.36       |\n",
            "|    value_loss         | 0.000805   |\n",
            "--------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 423            |\n",
            "|    iterations         | 8400           |\n",
            "|    time_elapsed       | 99             |\n",
            "|    total_timesteps    | 42000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -2.92          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 8399           |\n",
            "|    policy_loss        | 0.0606         |\n",
            "|    reward             | -0.00016936843 |\n",
            "|    std                | 4.51           |\n",
            "|    value_loss         | 0.000421       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 424          |\n",
            "|    iterations         | 8500         |\n",
            "|    time_elapsed       | 100          |\n",
            "|    total_timesteps    | 42500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.96        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8499         |\n",
            "|    policy_loss        | 0.0106       |\n",
            "|    reward             | 0.0026904983 |\n",
            "|    std                | 4.68         |\n",
            "|    value_loss         | 2.19e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 425           |\n",
            "|    iterations         | 8600          |\n",
            "|    time_elapsed       | 100           |\n",
            "|    total_timesteps    | 43000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3            |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8599          |\n",
            "|    policy_loss        | -0.00499      |\n",
            "|    reward             | 0.00039091115 |\n",
            "|    std                | 4.86          |\n",
            "|    value_loss         | 1.43e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 426           |\n",
            "|    iterations         | 8700          |\n",
            "|    time_elapsed       | 101           |\n",
            "|    total_timesteps    | 43500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.04         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8699          |\n",
            "|    policy_loss        | 0.00832       |\n",
            "|    reward             | -0.0045171967 |\n",
            "|    std                | 5.04          |\n",
            "|    value_loss         | 2.06e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 427          |\n",
            "|    iterations         | 8800         |\n",
            "|    time_elapsed       | 102          |\n",
            "|    total_timesteps    | 44000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.08        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8799         |\n",
            "|    policy_loss        | -0.00867     |\n",
            "|    reward             | -0.013493474 |\n",
            "|    std                | 5.24         |\n",
            "|    value_loss         | 1.37e-05     |\n",
            "----------------------------------------\n",
            "day: 2938, episode: 15\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 7345.47\n",
            "total_reward: -2654.53\n",
            "total_cost: 138.30\n",
            "total_trades: 2938\n",
            "Sharpe: -0.143\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 428         |\n",
            "|    iterations         | 8900        |\n",
            "|    time_elapsed       | 103         |\n",
            "|    total_timesteps    | 44500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.09       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8899        |\n",
            "|    policy_loss        | -0.0508     |\n",
            "|    reward             | 0.014617743 |\n",
            "|    std                | 5.33        |\n",
            "|    value_loss         | 0.000386    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 429         |\n",
            "|    iterations         | 9000        |\n",
            "|    time_elapsed       | 104         |\n",
            "|    total_timesteps    | 45000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.12       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8999        |\n",
            "|    policy_loss        | -0.0197     |\n",
            "|    reward             | 0.004433011 |\n",
            "|    std                | 5.49        |\n",
            "|    value_loss         | 7.46e-05    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 429           |\n",
            "|    iterations         | 9100          |\n",
            "|    time_elapsed       | 105           |\n",
            "|    total_timesteps    | 45500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.16         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9099          |\n",
            "|    policy_loss        | 0.0136        |\n",
            "|    reward             | -0.0009185925 |\n",
            "|    std                | 5.69          |\n",
            "|    value_loss         | 2.96e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 430          |\n",
            "|    iterations         | 9200         |\n",
            "|    time_elapsed       | 106          |\n",
            "|    total_timesteps    | 46000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.2         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9199         |\n",
            "|    policy_loss        | 0.0184       |\n",
            "|    reward             | 0.0035665291 |\n",
            "|    std                | 5.96         |\n",
            "|    value_loss         | 8.45e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 431          |\n",
            "|    iterations         | 9300         |\n",
            "|    time_elapsed       | 107          |\n",
            "|    total_timesteps    | 46500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.24        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9299         |\n",
            "|    policy_loss        | -0.0182      |\n",
            "|    reward             | -0.006322302 |\n",
            "|    std                | 6.18         |\n",
            "|    value_loss         | 3.88e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 432          |\n",
            "|    iterations         | 9400         |\n",
            "|    time_elapsed       | 108          |\n",
            "|    total_timesteps    | 47000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.29        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9399         |\n",
            "|    policy_loss        | 0.0101       |\n",
            "|    reward             | 0.0014714921 |\n",
            "|    std                | 6.53         |\n",
            "|    value_loss         | 2.04e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 433         |\n",
            "|    iterations         | 9500        |\n",
            "|    time_elapsed       | 109         |\n",
            "|    total_timesteps    | 47500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.32       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9499        |\n",
            "|    policy_loss        | 0.0228      |\n",
            "|    reward             | 0.007519949 |\n",
            "|    std                | 6.7         |\n",
            "|    value_loss         | 7.04e-05    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 434           |\n",
            "|    iterations         | 9600          |\n",
            "|    time_elapsed       | 110           |\n",
            "|    total_timesteps    | 48000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.35         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9599          |\n",
            "|    policy_loss        | -0.0396       |\n",
            "|    reward             | -0.0007771763 |\n",
            "|    std                | 6.92          |\n",
            "|    value_loss         | 0.000169      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 434           |\n",
            "|    iterations         | 9700          |\n",
            "|    time_elapsed       | 111           |\n",
            "|    total_timesteps    | 48500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.4          |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9699          |\n",
            "|    policy_loss        | -0.0282       |\n",
            "|    reward             | -0.0013294152 |\n",
            "|    std                | 7.23          |\n",
            "|    value_loss         | 0.000159      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 435          |\n",
            "|    iterations         | 9800         |\n",
            "|    time_elapsed       | 112          |\n",
            "|    total_timesteps    | 49000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.43        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9799         |\n",
            "|    policy_loss        | -0.0109      |\n",
            "|    reward             | -0.004843303 |\n",
            "|    std                | 7.51         |\n",
            "|    value_loss         | 2.27e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 436           |\n",
            "|    iterations         | 9900          |\n",
            "|    time_elapsed       | 113           |\n",
            "|    total_timesteps    | 49500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.48         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9899          |\n",
            "|    policy_loss        | 0.00213       |\n",
            "|    reward             | -0.0035106577 |\n",
            "|    std                | 7.85          |\n",
            "|    value_loss         | 2.01e-06      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 437           |\n",
            "|    iterations         | 10000         |\n",
            "|    time_elapsed       | 114           |\n",
            "|    total_timesteps    | 50000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.51         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9999          |\n",
            "|    policy_loss        | 0.0305        |\n",
            "|    reward             | -0.0018853492 |\n",
            "|    std                | 8.09          |\n",
            "|    value_loss         | 0.00012       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 438          |\n",
            "|    iterations         | 10100        |\n",
            "|    time_elapsed       | 115          |\n",
            "|    total_timesteps    | 50500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.53        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10099        |\n",
            "|    policy_loss        | 0.0813       |\n",
            "|    reward             | 0.0048736893 |\n",
            "|    std                | 8.3          |\n",
            "|    value_loss         | 0.000523     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 438           |\n",
            "|    iterations         | 10200         |\n",
            "|    time_elapsed       | 116           |\n",
            "|    total_timesteps    | 51000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.56         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10199         |\n",
            "|    policy_loss        | 0.0125        |\n",
            "|    reward             | -0.0017919798 |\n",
            "|    std                | 8.47          |\n",
            "|    value_loss         | 2.12e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 439           |\n",
            "|    iterations         | 10300         |\n",
            "|    time_elapsed       | 117           |\n",
            "|    total_timesteps    | 51500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.58         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10299         |\n",
            "|    policy_loss        | 0.026         |\n",
            "|    reward             | -0.0061773234 |\n",
            "|    std                | 8.7           |\n",
            "|    value_loss         | 6.94e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 440           |\n",
            "|    iterations         | 10400         |\n",
            "|    time_elapsed       | 118           |\n",
            "|    total_timesteps    | 52000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.61         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10399         |\n",
            "|    policy_loss        | -0.022        |\n",
            "|    reward             | -0.0066929827 |\n",
            "|    std                | 8.96          |\n",
            "|    value_loss         | 3.65e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 440         |\n",
            "|    iterations         | 10500       |\n",
            "|    time_elapsed       | 119         |\n",
            "|    total_timesteps    | 52500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.64       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10499       |\n",
            "|    policy_loss        | -0.0247     |\n",
            "|    reward             | 0.027898917 |\n",
            "|    std                | 9.24        |\n",
            "|    value_loss         | 0.000119    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 441          |\n",
            "|    iterations         | 10600        |\n",
            "|    time_elapsed       | 120          |\n",
            "|    total_timesteps    | 53000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.68        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10599        |\n",
            "|    policy_loss        | 0.0976       |\n",
            "|    reward             | -0.008104395 |\n",
            "|    std                | 9.58         |\n",
            "|    value_loss         | 0.00113      |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 442        |\n",
            "|    iterations         | 10700      |\n",
            "|    time_elapsed       | 120        |\n",
            "|    total_timesteps    | 53500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -3.69      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10699      |\n",
            "|    policy_loss        | -0.16      |\n",
            "|    reward             | 0.02306447 |\n",
            "|    std                | 9.67       |\n",
            "|    value_loss         | 0.00135    |\n",
            "--------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 442            |\n",
            "|    iterations         | 10800          |\n",
            "|    time_elapsed       | 121            |\n",
            "|    total_timesteps    | 54000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -3.71          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 10799          |\n",
            "|    policy_loss        | 0.0159         |\n",
            "|    reward             | -0.00041046028 |\n",
            "|    std                | 9.93           |\n",
            "|    value_loss         | 4.11e-05       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 443          |\n",
            "|    iterations         | 10900        |\n",
            "|    time_elapsed       | 122          |\n",
            "|    total_timesteps    | 54500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.75        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10899        |\n",
            "|    policy_loss        | 0.0598       |\n",
            "|    reward             | -0.008022838 |\n",
            "|    std                | 10.3         |\n",
            "|    value_loss         | 0.000367     |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 443        |\n",
            "|    iterations         | 11000      |\n",
            "|    time_elapsed       | 123        |\n",
            "|    total_timesteps    | 55000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -3.78      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10999      |\n",
            "|    policy_loss        | -0.00486   |\n",
            "|    reward             | 0.00566455 |\n",
            "|    std                | 10.6       |\n",
            "|    value_loss         | 4.9e-06    |\n",
            "--------------------------------------\n",
            "======A2C Validation from:  2021-12-02 to  2022-01-03\n",
            "A2C Sharpe Ratio:  -0.7698057120674834\n",
            "======Best Model Retraining from:  2010-04-01 to  2022-01-03\n",
            "======Trading from:  2022-01-03 to  2022-02-02\n",
            "[[ 1.4481178e+04  3.4425423e+01 -1.8900000e+02  1.0010729e+00\n",
            "   3.5395180e+01  3.0754988e+01  6.5352493e+01  1.2120095e+02\n",
            "   4.6444374e+01  3.2299797e+01  3.0651716e+01]]\n",
            "============================================\n",
            "turbulence_threshold:  12.04306128869847\n",
            "======Model training from:  2010-04-01 to  2022-01-03\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c\\a2c_294_1\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 525          |\n",
            "|    iterations         | 100          |\n",
            "|    time_elapsed       | 0            |\n",
            "|    total_timesteps    | 500          |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.49        |\n",
            "|    explained_variance | 1.97e-06     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 99           |\n",
            "|    policy_loss        | -0.0192      |\n",
            "|    reward             | -0.005020787 |\n",
            "|    std                | 1.08         |\n",
            "|    value_loss         | 0.000132     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 513          |\n",
            "|    iterations         | 200          |\n",
            "|    time_elapsed       | 1            |\n",
            "|    total_timesteps    | 1000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.52        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 199          |\n",
            "|    policy_loss        | 0.0038       |\n",
            "|    reward             | 0.0020806547 |\n",
            "|    std                | 1.1          |\n",
            "|    value_loss         | 5.36e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 504          |\n",
            "|    iterations         | 300          |\n",
            "|    time_elapsed       | 2            |\n",
            "|    total_timesteps    | 1500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.55        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 299          |\n",
            "|    policy_loss        | -0.000107    |\n",
            "|    reward             | -0.010699661 |\n",
            "|    std                | 1.14         |\n",
            "|    value_loss         | 4.34e-06     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 510           |\n",
            "|    iterations         | 400           |\n",
            "|    time_elapsed       | 3             |\n",
            "|    total_timesteps    | 2000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.58         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 399           |\n",
            "|    policy_loss        | -0.011        |\n",
            "|    reward             | -0.0016201923 |\n",
            "|    std                | 1.18          |\n",
            "|    value_loss         | 9.92e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 511         |\n",
            "|    iterations         | 500         |\n",
            "|    time_elapsed       | 4           |\n",
            "|    total_timesteps    | 2500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.61       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 499         |\n",
            "|    policy_loss        | 0.00143     |\n",
            "|    reward             | 0.032639265 |\n",
            "|    std                | 1.21        |\n",
            "|    value_loss         | 0.000182    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 513         |\n",
            "|    iterations         | 600         |\n",
            "|    time_elapsed       | 5           |\n",
            "|    total_timesteps    | 3000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.64       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 599         |\n",
            "|    policy_loss        | 0.0041      |\n",
            "|    reward             | 0.009048291 |\n",
            "|    std                | 1.25        |\n",
            "|    value_loss         | 0.000105    |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 519            |\n",
            "|    iterations         | 700            |\n",
            "|    time_elapsed       | 6              |\n",
            "|    total_timesteps    | 3500           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -1.67          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 699            |\n",
            "|    policy_loss        | 0.0145         |\n",
            "|    reward             | -0.00018054171 |\n",
            "|    std                | 1.29           |\n",
            "|    value_loss         | 0.000179       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 518          |\n",
            "|    iterations         | 800          |\n",
            "|    time_elapsed       | 7            |\n",
            "|    total_timesteps    | 4000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.7         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 799          |\n",
            "|    policy_loss        | -0.0105      |\n",
            "|    reward             | 0.0052940645 |\n",
            "|    std                | 1.33         |\n",
            "|    value_loss         | 3.18e-05     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 518            |\n",
            "|    iterations         | 900            |\n",
            "|    time_elapsed       | 8              |\n",
            "|    total_timesteps    | 4500           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -1.74          |\n",
            "|    explained_variance | -1.19e-07      |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 899            |\n",
            "|    policy_loss        | 0.00312        |\n",
            "|    reward             | -1.9119816e-06 |\n",
            "|    std                | 1.38           |\n",
            "|    value_loss         | 5.07e-05       |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 517         |\n",
            "|    iterations         | 1000        |\n",
            "|    time_elapsed       | 9           |\n",
            "|    total_timesteps    | 5000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.78       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 999         |\n",
            "|    policy_loss        | -0.00987    |\n",
            "|    reward             | -0.00331819 |\n",
            "|    std                | 1.44        |\n",
            "|    value_loss         | 5.46e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 517          |\n",
            "|    iterations         | 1100         |\n",
            "|    time_elapsed       | 10           |\n",
            "|    total_timesteps    | 5500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.83        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1099         |\n",
            "|    policy_loss        | -0.0154      |\n",
            "|    reward             | -0.009835595 |\n",
            "|    std                | 1.51         |\n",
            "|    value_loss         | 0.000128     |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 517        |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 11         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.87      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | 0.000602   |\n",
            "|    reward             | 0.01101238 |\n",
            "|    std                | 1.57       |\n",
            "|    value_loss         | 3.98e-05   |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 516          |\n",
            "|    iterations         | 1300         |\n",
            "|    time_elapsed       | 12           |\n",
            "|    total_timesteps    | 6500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.91        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1299         |\n",
            "|    policy_loss        | 0.033        |\n",
            "|    reward             | -0.015915172 |\n",
            "|    std                | 1.63         |\n",
            "|    value_loss         | 0.000516     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 519            |\n",
            "|    iterations         | 1400           |\n",
            "|    time_elapsed       | 13             |\n",
            "|    total_timesteps    | 7000           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -1.94          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 1399           |\n",
            "|    policy_loss        | 0.00499        |\n",
            "|    reward             | -0.00035677978 |\n",
            "|    std                | 1.69           |\n",
            "|    value_loss         | 3.41e-05       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 519           |\n",
            "|    iterations         | 1500          |\n",
            "|    time_elapsed       | 14            |\n",
            "|    total_timesteps    | 7500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.97         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1499          |\n",
            "|    policy_loss        | -0.0109       |\n",
            "|    reward             | -0.0041973735 |\n",
            "|    std                | 1.73          |\n",
            "|    value_loss         | 0.000145      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 521           |\n",
            "|    iterations         | 1600          |\n",
            "|    time_elapsed       | 15            |\n",
            "|    total_timesteps    | 8000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.01         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1599          |\n",
            "|    policy_loss        | -0.0131       |\n",
            "|    reward             | -0.0018657548 |\n",
            "|    std                | 1.8           |\n",
            "|    value_loss         | 5.21e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 522          |\n",
            "|    iterations         | 1700         |\n",
            "|    time_elapsed       | 16           |\n",
            "|    total_timesteps    | 8500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.05        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1699         |\n",
            "|    policy_loss        | 0.0447       |\n",
            "|    reward             | 0.0054713637 |\n",
            "|    std                | 1.88         |\n",
            "|    value_loss         | 0.000528     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 523         |\n",
            "|    iterations         | 1800        |\n",
            "|    time_elapsed       | 17          |\n",
            "|    total_timesteps    | 9000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.09       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1799        |\n",
            "|    policy_loss        | -0.0241     |\n",
            "|    reward             | 0.015203019 |\n",
            "|    std                | 1.96        |\n",
            "|    value_loss         | 0.000212    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 523          |\n",
            "|    iterations         | 1900         |\n",
            "|    time_elapsed       | 18           |\n",
            "|    total_timesteps    | 9500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.11        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1899         |\n",
            "|    policy_loss        | -0.0559      |\n",
            "|    reward             | 0.0019390972 |\n",
            "|    std                | 2            |\n",
            "|    value_loss         | 0.000512     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 522          |\n",
            "|    iterations         | 2000         |\n",
            "|    time_elapsed       | 19           |\n",
            "|    total_timesteps    | 10000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.14        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1999         |\n",
            "|    policy_loss        | -0.00672     |\n",
            "|    reward             | 0.0074899574 |\n",
            "|    std                | 2.05         |\n",
            "|    value_loss         | 1.12e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 522          |\n",
            "|    iterations         | 2100         |\n",
            "|    time_elapsed       | 20           |\n",
            "|    total_timesteps    | 10500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.17        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2099         |\n",
            "|    policy_loss        | 0.00137      |\n",
            "|    reward             | 0.0005525264 |\n",
            "|    std                | 2.13         |\n",
            "|    value_loss         | 4.22e-06     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 2200         |\n",
            "|    time_elapsed       | 21           |\n",
            "|    total_timesteps    | 11000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.2         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2199         |\n",
            "|    policy_loss        | -0.0105      |\n",
            "|    reward             | 0.0010820829 |\n",
            "|    std                | 2.19         |\n",
            "|    value_loss         | 4.35e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 518          |\n",
            "|    iterations         | 2300         |\n",
            "|    time_elapsed       | 22           |\n",
            "|    total_timesteps    | 11500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.24        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2299         |\n",
            "|    policy_loss        | 0.0392       |\n",
            "|    reward             | 0.0051028207 |\n",
            "|    std                | 2.28         |\n",
            "|    value_loss         | 0.00036      |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 518        |\n",
            "|    iterations         | 2400       |\n",
            "|    time_elapsed       | 23         |\n",
            "|    total_timesteps    | 12000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.26      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2399       |\n",
            "|    policy_loss        | -0.0126    |\n",
            "|    reward             | 0.01523792 |\n",
            "|    std                | 2.33       |\n",
            "|    value_loss         | 0.000107   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 518         |\n",
            "|    iterations         | 2500        |\n",
            "|    time_elapsed       | 24          |\n",
            "|    total_timesteps    | 12500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.28       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2499        |\n",
            "|    policy_loss        | -0.0374     |\n",
            "|    reward             | 0.009241983 |\n",
            "|    std                | 2.37        |\n",
            "|    value_loss         | 0.000175    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 519           |\n",
            "|    iterations         | 2600          |\n",
            "|    time_elapsed       | 25            |\n",
            "|    total_timesteps    | 13000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.31         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2599          |\n",
            "|    policy_loss        | -0.0394       |\n",
            "|    reward             | -0.0053479215 |\n",
            "|    std                | 2.45          |\n",
            "|    value_loss         | 0.000627      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 519         |\n",
            "|    iterations         | 2700        |\n",
            "|    time_elapsed       | 25          |\n",
            "|    total_timesteps    | 13500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.35       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2699        |\n",
            "|    policy_loss        | -0.112      |\n",
            "|    reward             | 0.012756626 |\n",
            "|    std                | 2.54        |\n",
            "|    value_loss         | 0.00278     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 519          |\n",
            "|    iterations         | 2800         |\n",
            "|    time_elapsed       | 26           |\n",
            "|    total_timesteps    | 14000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.39        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2799         |\n",
            "|    policy_loss        | -0.00249     |\n",
            "|    reward             | 0.0019069503 |\n",
            "|    std                | 2.64         |\n",
            "|    value_loss         | 6.27e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 519         |\n",
            "|    iterations         | 2900        |\n",
            "|    time_elapsed       | 27          |\n",
            "|    total_timesteps    | 14500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.42       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2899        |\n",
            "|    policy_loss        | -0.000976   |\n",
            "|    reward             | 0.002348997 |\n",
            "|    std                | 2.72        |\n",
            "|    value_loss         | 3.28e-06    |\n",
            "---------------------------------------\n",
            "day: 2959, episode: 5\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 9330.20\n",
            "total_reward: -669.80\n",
            "total_cost: 103.88\n",
            "total_trades: 2959\n",
            "Sharpe: 0.052\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 519           |\n",
            "|    iterations         | 3000          |\n",
            "|    time_elapsed       | 28            |\n",
            "|    total_timesteps    | 15000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.45         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2999          |\n",
            "|    policy_loss        | 0.0108        |\n",
            "|    reward             | -0.0077985954 |\n",
            "|    std                | 2.81          |\n",
            "|    value_loss         | 3.83e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 518          |\n",
            "|    iterations         | 3100         |\n",
            "|    time_elapsed       | 29           |\n",
            "|    total_timesteps    | 15500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.47        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3099         |\n",
            "|    policy_loss        | -0.0185      |\n",
            "|    reward             | -0.008389892 |\n",
            "|    std                | 2.88         |\n",
            "|    value_loss         | 0.000156     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 519           |\n",
            "|    iterations         | 3200          |\n",
            "|    time_elapsed       | 30            |\n",
            "|    total_timesteps    | 16000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.51         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3199          |\n",
            "|    policy_loss        | 0.00131       |\n",
            "|    reward             | -0.0089321295 |\n",
            "|    std                | 2.97          |\n",
            "|    value_loss         | 2.94e-06      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 519         |\n",
            "|    iterations         | 3300        |\n",
            "|    time_elapsed       | 31          |\n",
            "|    total_timesteps    | 16500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.54       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3299        |\n",
            "|    policy_loss        | 0.0325      |\n",
            "|    reward             | 0.002007639 |\n",
            "|    std                | 3.08        |\n",
            "|    value_loss         | 9.79e-05    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 521           |\n",
            "|    iterations         | 3400          |\n",
            "|    time_elapsed       | 32            |\n",
            "|    total_timesteps    | 17000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.57         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3399          |\n",
            "|    policy_loss        | 0.0308        |\n",
            "|    reward             | -0.0031047831 |\n",
            "|    std                | 3.17          |\n",
            "|    value_loss         | 0.000206      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 521         |\n",
            "|    iterations         | 3500        |\n",
            "|    time_elapsed       | 33          |\n",
            "|    total_timesteps    | 17500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.61       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3499        |\n",
            "|    policy_loss        | -0.0114     |\n",
            "|    reward             | 0.004471409 |\n",
            "|    std                | 3.3         |\n",
            "|    value_loss         | 3.08e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 521         |\n",
            "|    iterations         | 3600        |\n",
            "|    time_elapsed       | 34          |\n",
            "|    total_timesteps    | 18000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.65       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3599        |\n",
            "|    policy_loss        | -0.0188     |\n",
            "|    reward             | 0.014493325 |\n",
            "|    std                | 3.43        |\n",
            "|    value_loss         | 9.72e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 3700         |\n",
            "|    time_elapsed       | 35           |\n",
            "|    total_timesteps    | 18500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.69        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3699         |\n",
            "|    policy_loss        | 0.0377       |\n",
            "|    reward             | 0.0030177915 |\n",
            "|    std                | 3.57         |\n",
            "|    value_loss         | 0.000255     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 3800         |\n",
            "|    time_elapsed       | 36           |\n",
            "|    total_timesteps    | 19000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.71        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3799         |\n",
            "|    policy_loss        | 0.0258       |\n",
            "|    reward             | -0.011201116 |\n",
            "|    std                | 3.65         |\n",
            "|    value_loss         | 0.000115     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 3900         |\n",
            "|    time_elapsed       | 37           |\n",
            "|    total_timesteps    | 19500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.73        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3899         |\n",
            "|    policy_loss        | -0.0184      |\n",
            "|    reward             | -0.007818569 |\n",
            "|    std                | 3.73         |\n",
            "|    value_loss         | 0.000119     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 4000         |\n",
            "|    time_elapsed       | 38           |\n",
            "|    total_timesteps    | 20000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.76        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3999         |\n",
            "|    policy_loss        | -0.0477      |\n",
            "|    reward             | 0.0011134688 |\n",
            "|    std                | 3.82         |\n",
            "|    value_loss         | 0.000421     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 4100         |\n",
            "|    time_elapsed       | 39           |\n",
            "|    total_timesteps    | 20500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.79        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4099         |\n",
            "|    policy_loss        | -0.0944      |\n",
            "|    reward             | 0.0033313697 |\n",
            "|    std                | 3.93         |\n",
            "|    value_loss         | 0.00149      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 4200         |\n",
            "|    time_elapsed       | 40           |\n",
            "|    total_timesteps    | 21000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.8         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4199         |\n",
            "|    policy_loss        | 0.0782       |\n",
            "|    reward             | -0.021855902 |\n",
            "|    std                | 4            |\n",
            "|    value_loss         | 0.00109      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 521         |\n",
            "|    iterations         | 4300        |\n",
            "|    time_elapsed       | 41          |\n",
            "|    total_timesteps    | 21500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.82       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4299        |\n",
            "|    policy_loss        | -0.0522     |\n",
            "|    reward             | -0.01918689 |\n",
            "|    std                | 4.04        |\n",
            "|    value_loss         | 0.000411    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 4400         |\n",
            "|    time_elapsed       | 42           |\n",
            "|    total_timesteps    | 22000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.83        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4399         |\n",
            "|    policy_loss        | -0.209       |\n",
            "|    reward             | -0.006430322 |\n",
            "|    std                | 4.08         |\n",
            "|    value_loss         | 0.0063       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 4500         |\n",
            "|    time_elapsed       | 43           |\n",
            "|    total_timesteps    | 22500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.83        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4499         |\n",
            "|    policy_loss        | -0.0131      |\n",
            "|    reward             | -0.024491336 |\n",
            "|    std                | 4.12         |\n",
            "|    value_loss         | 3.13e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 4600         |\n",
            "|    time_elapsed       | 44           |\n",
            "|    total_timesteps    | 23000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.86        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4599         |\n",
            "|    policy_loss        | -0.0521      |\n",
            "|    reward             | -0.019623468 |\n",
            "|    std                | 4.21         |\n",
            "|    value_loss         | 0.000532     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 4700         |\n",
            "|    time_elapsed       | 45           |\n",
            "|    total_timesteps    | 23500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.88        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4699         |\n",
            "|    policy_loss        | 0.021        |\n",
            "|    reward             | 0.0060829152 |\n",
            "|    std                | 4.32         |\n",
            "|    value_loss         | 0.000154     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 521         |\n",
            "|    iterations         | 4800        |\n",
            "|    time_elapsed       | 46          |\n",
            "|    total_timesteps    | 24000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.9        |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4799        |\n",
            "|    policy_loss        | -0.0674     |\n",
            "|    reward             | 0.014572322 |\n",
            "|    std                | 4.39        |\n",
            "|    value_loss         | 0.000617    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 4900         |\n",
            "|    time_elapsed       | 47           |\n",
            "|    total_timesteps    | 24500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.91        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4899         |\n",
            "|    policy_loss        | -0.0273      |\n",
            "|    reward             | -0.009098393 |\n",
            "|    std                | 4.46         |\n",
            "|    value_loss         | 0.000181     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 521         |\n",
            "|    iterations         | 5000        |\n",
            "|    time_elapsed       | 47          |\n",
            "|    total_timesteps    | 25000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.93       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4999        |\n",
            "|    policy_loss        | 0.0437      |\n",
            "|    reward             | 0.005524826 |\n",
            "|    std                | 4.55        |\n",
            "|    value_loss         | 0.000284    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 522          |\n",
            "|    iterations         | 5100         |\n",
            "|    time_elapsed       | 48           |\n",
            "|    total_timesteps    | 25500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.95        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5099         |\n",
            "|    policy_loss        | 0.0262       |\n",
            "|    reward             | 0.0031679007 |\n",
            "|    std                | 4.63         |\n",
            "|    value_loss         | 0.00015      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 522           |\n",
            "|    iterations         | 5200          |\n",
            "|    time_elapsed       | 49            |\n",
            "|    total_timesteps    | 26000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.98         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5199          |\n",
            "|    policy_loss        | -0.00369      |\n",
            "|    reward             | -0.0044103297 |\n",
            "|    std                | 4.78          |\n",
            "|    value_loss         | 2.56e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 522         |\n",
            "|    iterations         | 5300        |\n",
            "|    time_elapsed       | 50          |\n",
            "|    total_timesteps    | 26500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.01       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5299        |\n",
            "|    policy_loss        | -0.203      |\n",
            "|    reward             | 0.011680783 |\n",
            "|    std                | 4.92        |\n",
            "|    value_loss         | 0.00656     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 522         |\n",
            "|    iterations         | 5400        |\n",
            "|    time_elapsed       | 51          |\n",
            "|    total_timesteps    | 27000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.03       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5399        |\n",
            "|    policy_loss        | -0.0531     |\n",
            "|    reward             | 0.019361284 |\n",
            "|    std                | 5.03        |\n",
            "|    value_loss         | 0.000485    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 522           |\n",
            "|    iterations         | 5500          |\n",
            "|    time_elapsed       | 52            |\n",
            "|    total_timesteps    | 27500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.06         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5499          |\n",
            "|    policy_loss        | 0.0327        |\n",
            "|    reward             | -0.0007143562 |\n",
            "|    std                | 5.16          |\n",
            "|    value_loss         | 0.000124      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 522          |\n",
            "|    iterations         | 5600         |\n",
            "|    time_elapsed       | 53           |\n",
            "|    total_timesteps    | 28000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.09        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5599         |\n",
            "|    policy_loss        | 0.0132       |\n",
            "|    reward             | -0.017091278 |\n",
            "|    std                | 5.34         |\n",
            "|    value_loss         | 2.26e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 522           |\n",
            "|    iterations         | 5700          |\n",
            "|    time_elapsed       | 54            |\n",
            "|    total_timesteps    | 28500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.13         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5699          |\n",
            "|    policy_loss        | 0.00221       |\n",
            "|    reward             | 0.00060118217 |\n",
            "|    std                | 5.55          |\n",
            "|    value_loss         | 0.000166      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 5800         |\n",
            "|    time_elapsed       | 55           |\n",
            "|    total_timesteps    | 29000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.17        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5799         |\n",
            "|    policy_loss        | 0.0126       |\n",
            "|    reward             | -0.015207391 |\n",
            "|    std                | 5.74         |\n",
            "|    value_loss         | 0.000116     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 521           |\n",
            "|    iterations         | 5900          |\n",
            "|    time_elapsed       | 56            |\n",
            "|    total_timesteps    | 29500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.19         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5899          |\n",
            "|    policy_loss        | -0.0618       |\n",
            "|    reward             | -0.0070966384 |\n",
            "|    std                | 5.89          |\n",
            "|    value_loss         | 0.0011        |\n",
            "-----------------------------------------\n",
            "day: 2959, episode: 10\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 5212.98\n",
            "total_reward: -4787.02\n",
            "total_cost: 108.51\n",
            "total_trades: 2959\n",
            "Sharpe: -0.158\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 521         |\n",
            "|    iterations         | 6000        |\n",
            "|    time_elapsed       | 57          |\n",
            "|    total_timesteps    | 30000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.21       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5999        |\n",
            "|    policy_loss        | -0.244      |\n",
            "|    reward             | 0.012115191 |\n",
            "|    std                | 6           |\n",
            "|    value_loss         | 0.00514     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 522          |\n",
            "|    iterations         | 6100         |\n",
            "|    time_elapsed       | 58           |\n",
            "|    total_timesteps    | 30500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.24        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6099         |\n",
            "|    policy_loss        | -0.0244      |\n",
            "|    reward             | -0.006231698 |\n",
            "|    std                | 6.15         |\n",
            "|    value_loss         | 0.000242     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 6200         |\n",
            "|    time_elapsed       | 59           |\n",
            "|    total_timesteps    | 31000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.25        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6199         |\n",
            "|    policy_loss        | -0.0353      |\n",
            "|    reward             | 0.0018728551 |\n",
            "|    std                | 6.27         |\n",
            "|    value_loss         | 0.0002       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 521           |\n",
            "|    iterations         | 6300          |\n",
            "|    time_elapsed       | 60            |\n",
            "|    total_timesteps    | 31500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.27         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6299          |\n",
            "|    policy_loss        | 0.155         |\n",
            "|    reward             | -0.0035324073 |\n",
            "|    std                | 6.37          |\n",
            "|    value_loss         | 0.00311       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 522          |\n",
            "|    iterations         | 6400         |\n",
            "|    time_elapsed       | 61           |\n",
            "|    total_timesteps    | 32000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.29        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6399         |\n",
            "|    policy_loss        | 0.0274       |\n",
            "|    reward             | 0.0073955585 |\n",
            "|    std                | 6.47         |\n",
            "|    value_loss         | 0.000883     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 522         |\n",
            "|    iterations         | 6500        |\n",
            "|    time_elapsed       | 62          |\n",
            "|    total_timesteps    | 32500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.29       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6499        |\n",
            "|    policy_loss        | 0.186       |\n",
            "|    reward             | -0.03512111 |\n",
            "|    std                | 6.51        |\n",
            "|    value_loss         | 0.00384     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 521        |\n",
            "|    iterations         | 6600       |\n",
            "|    time_elapsed       | 63         |\n",
            "|    total_timesteps    | 33000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -3.32      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 6599       |\n",
            "|    policy_loss        | -0.0924    |\n",
            "|    reward             | 0.00698494 |\n",
            "|    std                | 6.72       |\n",
            "|    value_loss         | 0.00079    |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 521           |\n",
            "|    iterations         | 6700          |\n",
            "|    time_elapsed       | 64            |\n",
            "|    total_timesteps    | 33500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.35         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6699          |\n",
            "|    policy_loss        | 0.0114        |\n",
            "|    reward             | -0.0034358136 |\n",
            "|    std                | 6.88          |\n",
            "|    value_loss         | 0.000118      |\n",
            "-----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 522       |\n",
            "|    iterations         | 6800      |\n",
            "|    time_elapsed       | 65        |\n",
            "|    total_timesteps    | 34000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -3.37     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6799      |\n",
            "|    policy_loss        | 0.088     |\n",
            "|    reward             | 0.0130633 |\n",
            "|    std                | 7.01      |\n",
            "|    value_loss         | 0.000919  |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 6900         |\n",
            "|    time_elapsed       | 66           |\n",
            "|    total_timesteps    | 34500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.38        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6899         |\n",
            "|    policy_loss        | 0.0587       |\n",
            "|    reward             | -0.006774102 |\n",
            "|    std                | 7.14         |\n",
            "|    value_loss         | 0.000988     |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 521       |\n",
            "|    iterations         | 7000      |\n",
            "|    time_elapsed       | 67        |\n",
            "|    total_timesteps    | 35000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -3.41     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 6999      |\n",
            "|    policy_loss        | 0.132     |\n",
            "|    reward             | 0.0071791 |\n",
            "|    std                | 7.31      |\n",
            "|    value_loss         | 0.00132   |\n",
            "-------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 521           |\n",
            "|    iterations         | 7100          |\n",
            "|    time_elapsed       | 68            |\n",
            "|    total_timesteps    | 35500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.44         |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7099          |\n",
            "|    policy_loss        | 0.167         |\n",
            "|    reward             | -0.0026172034 |\n",
            "|    std                | 7.52          |\n",
            "|    value_loss         | 0.00218       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 521         |\n",
            "|    iterations         | 7200        |\n",
            "|    time_elapsed       | 68          |\n",
            "|    total_timesteps    | 36000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.45       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7199        |\n",
            "|    policy_loss        | -0.0677     |\n",
            "|    reward             | 0.003261545 |\n",
            "|    std                | 7.63        |\n",
            "|    value_loss         | 0.000617    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 521         |\n",
            "|    iterations         | 7300        |\n",
            "|    time_elapsed       | 69          |\n",
            "|    total_timesteps    | 36500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.48       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7299        |\n",
            "|    policy_loss        | 0.017       |\n",
            "|    reward             | 0.008796564 |\n",
            "|    std                | 7.83        |\n",
            "|    value_loss         | 6.89e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 7400         |\n",
            "|    time_elapsed       | 70           |\n",
            "|    total_timesteps    | 37000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.51        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7399         |\n",
            "|    policy_loss        | 0.101        |\n",
            "|    reward             | -0.010550064 |\n",
            "|    std                | 8.1          |\n",
            "|    value_loss         | 0.00125      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 7500         |\n",
            "|    time_elapsed       | 71           |\n",
            "|    total_timesteps    | 37500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.53        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7499         |\n",
            "|    policy_loss        | 0.207        |\n",
            "|    reward             | -0.010908603 |\n",
            "|    std                | 8.23         |\n",
            "|    value_loss         | 0.00518      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 522          |\n",
            "|    iterations         | 7600         |\n",
            "|    time_elapsed       | 72           |\n",
            "|    total_timesteps    | 38000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.55        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7599         |\n",
            "|    policy_loss        | 0.0773       |\n",
            "|    reward             | -0.021796538 |\n",
            "|    std                | 8.44         |\n",
            "|    value_loss         | 0.0014       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 521         |\n",
            "|    iterations         | 7700        |\n",
            "|    time_elapsed       | 73          |\n",
            "|    total_timesteps    | 38500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.58       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7699        |\n",
            "|    policy_loss        | 0.0414      |\n",
            "|    reward             | 0.011177332 |\n",
            "|    std                | 8.68        |\n",
            "|    value_loss         | 0.000299    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 521         |\n",
            "|    iterations         | 7800        |\n",
            "|    time_elapsed       | 74          |\n",
            "|    total_timesteps    | 39000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.6        |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7799        |\n",
            "|    policy_loss        | -0.0213     |\n",
            "|    reward             | -0.03007594 |\n",
            "|    std                | 8.88        |\n",
            "|    value_loss         | 0.000138    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 7900         |\n",
            "|    time_elapsed       | 75           |\n",
            "|    total_timesteps    | 39500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.62        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7899         |\n",
            "|    policy_loss        | 0.0377       |\n",
            "|    reward             | -0.011606451 |\n",
            "|    std                | 9.03         |\n",
            "|    value_loss         | 0.00015      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 521           |\n",
            "|    iterations         | 8000          |\n",
            "|    time_elapsed       | 76            |\n",
            "|    total_timesteps    | 40000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.65         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7999          |\n",
            "|    policy_loss        | 0.0385        |\n",
            "|    reward             | -0.0018609569 |\n",
            "|    std                | 9.33          |\n",
            "|    value_loss         | 0.000135      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 522           |\n",
            "|    iterations         | 8100          |\n",
            "|    time_elapsed       | 77            |\n",
            "|    total_timesteps    | 40500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.68         |\n",
            "|    explained_variance | 1.79e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8099          |\n",
            "|    policy_loss        | 0.00125       |\n",
            "|    reward             | -0.0009301541 |\n",
            "|    std                | 9.62          |\n",
            "|    value_loss         | 1.2e-05       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 522          |\n",
            "|    iterations         | 8200         |\n",
            "|    time_elapsed       | 78           |\n",
            "|    total_timesteps    | 41000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.7         |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8199         |\n",
            "|    policy_loss        | -0.161       |\n",
            "|    reward             | -0.044658687 |\n",
            "|    std                | 9.76         |\n",
            "|    value_loss         | 0.00374      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 522          |\n",
            "|    iterations         | 8300         |\n",
            "|    time_elapsed       | 79           |\n",
            "|    total_timesteps    | 41500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.71        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8299         |\n",
            "|    policy_loss        | 0.0312       |\n",
            "|    reward             | -0.007109482 |\n",
            "|    std                | 9.87         |\n",
            "|    value_loss         | 5.67e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 522           |\n",
            "|    iterations         | 8400          |\n",
            "|    time_elapsed       | 80            |\n",
            "|    total_timesteps    | 42000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.72         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8399          |\n",
            "|    policy_loss        | 0.0316        |\n",
            "|    reward             | -0.0063796383 |\n",
            "|    std                | 10            |\n",
            "|    value_loss         | 0.000168      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 522           |\n",
            "|    iterations         | 8500          |\n",
            "|    time_elapsed       | 81            |\n",
            "|    total_timesteps    | 42500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.75         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8499          |\n",
            "|    policy_loss        | 0.01          |\n",
            "|    reward             | -0.0014390382 |\n",
            "|    std                | 10.3          |\n",
            "|    value_loss         | 9.66e-06      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 522           |\n",
            "|    iterations         | 8600          |\n",
            "|    time_elapsed       | 82            |\n",
            "|    total_timesteps    | 43000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.78         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8599          |\n",
            "|    policy_loss        | -0.00321      |\n",
            "|    reward             | -0.0019225371 |\n",
            "|    std                | 10.6          |\n",
            "|    value_loss         | 1.89e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 522          |\n",
            "|    iterations         | 8700         |\n",
            "|    time_elapsed       | 83           |\n",
            "|    total_timesteps    | 43500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.8         |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8699         |\n",
            "|    policy_loss        | 0.0469       |\n",
            "|    reward             | -4.79902e-06 |\n",
            "|    std                | 10.8         |\n",
            "|    value_loss         | 0.000149     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 522          |\n",
            "|    iterations         | 8800         |\n",
            "|    time_elapsed       | 84           |\n",
            "|    total_timesteps    | 44000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.82        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8799         |\n",
            "|    policy_loss        | -0.0642      |\n",
            "|    reward             | -0.008546409 |\n",
            "|    std                | 11.1         |\n",
            "|    value_loss         | 0.000367     |\n",
            "----------------------------------------\n",
            "day: 2959, episode: 15\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 5243.00\n",
            "total_reward: -4757.00\n",
            "total_cost: 109.94\n",
            "total_trades: 2959\n",
            "Sharpe: -0.154\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 521         |\n",
            "|    iterations         | 8900        |\n",
            "|    time_elapsed       | 85          |\n",
            "|    total_timesteps    | 44500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.84       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8899        |\n",
            "|    policy_loss        | 0.0621      |\n",
            "|    reward             | 0.012141763 |\n",
            "|    std                | 11.3        |\n",
            "|    value_loss         | 0.00189     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 521           |\n",
            "|    iterations         | 9000          |\n",
            "|    time_elapsed       | 86            |\n",
            "|    total_timesteps    | 45000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.86         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8999          |\n",
            "|    policy_loss        | -0.128        |\n",
            "|    reward             | -0.0050911354 |\n",
            "|    std                | 11.5          |\n",
            "|    value_loss         | 0.00124       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 520         |\n",
            "|    iterations         | 9100        |\n",
            "|    time_elapsed       | 87          |\n",
            "|    total_timesteps    | 45500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.87       |\n",
            "|    explained_variance | -2.38e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9099        |\n",
            "|    policy_loss        | 0.0409      |\n",
            "|    reward             | 0.020431787 |\n",
            "|    std                | 11.6        |\n",
            "|    value_loss         | 0.000128    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 9200         |\n",
            "|    time_elapsed       | 88           |\n",
            "|    total_timesteps    | 46000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.89        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9199         |\n",
            "|    policy_loss        | 0.101        |\n",
            "|    reward             | 0.0038884464 |\n",
            "|    std                | 11.9         |\n",
            "|    value_loss         | 0.00113      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 9300         |\n",
            "|    time_elapsed       | 89           |\n",
            "|    total_timesteps    | 46500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.92        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9299         |\n",
            "|    policy_loss        | 0.275        |\n",
            "|    reward             | -0.006344911 |\n",
            "|    std                | 12.2         |\n",
            "|    value_loss         | 0.006        |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 9400         |\n",
            "|    time_elapsed       | 90           |\n",
            "|    total_timesteps    | 47000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.93        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9399         |\n",
            "|    policy_loss        | -0.112       |\n",
            "|    reward             | 0.0026214449 |\n",
            "|    std                | 12.3         |\n",
            "|    value_loss         | 0.00091      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 520         |\n",
            "|    iterations         | 9500        |\n",
            "|    time_elapsed       | 91          |\n",
            "|    total_timesteps    | 47500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.94       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9499        |\n",
            "|    policy_loss        | 0.00421     |\n",
            "|    reward             | -0.04809353 |\n",
            "|    std                | 12.4        |\n",
            "|    value_loss         | 2.87e-05    |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 519            |\n",
            "|    iterations         | 9600           |\n",
            "|    time_elapsed       | 92             |\n",
            "|    total_timesteps    | 48000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -3.97          |\n",
            "|    explained_variance | 1.19e-07       |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 9599           |\n",
            "|    policy_loss        | 0.0191         |\n",
            "|    reward             | -2.6729426e-06 |\n",
            "|    std                | 12.8           |\n",
            "|    value_loss         | 6.23e-05       |\n",
            "------------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 519        |\n",
            "|    iterations         | 9700       |\n",
            "|    time_elapsed       | 93         |\n",
            "|    total_timesteps    | 48500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -3.98      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9699       |\n",
            "|    policy_loss        | -0.0175    |\n",
            "|    reward             | 0.06270041 |\n",
            "|    std                | 13         |\n",
            "|    value_loss         | 4.39e-05   |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 9800         |\n",
            "|    time_elapsed       | 94           |\n",
            "|    total_timesteps    | 49000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.01        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9799         |\n",
            "|    policy_loss        | -0.0142      |\n",
            "|    reward             | -0.021009587 |\n",
            "|    std                | 13.4         |\n",
            "|    value_loss         | 3.62e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 519          |\n",
            "|    iterations         | 9900         |\n",
            "|    time_elapsed       | 95           |\n",
            "|    total_timesteps    | 49500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.02        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9899         |\n",
            "|    policy_loss        | -0.0873      |\n",
            "|    reward             | 0.0018724385 |\n",
            "|    std                | 13.5         |\n",
            "|    value_loss         | 0.00105      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 519         |\n",
            "|    iterations         | 10000       |\n",
            "|    time_elapsed       | 96          |\n",
            "|    total_timesteps    | 50000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.05       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9999        |\n",
            "|    policy_loss        | -0.0277     |\n",
            "|    reward             | -0.01034915 |\n",
            "|    std                | 13.9        |\n",
            "|    value_loss         | 5.86e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 519          |\n",
            "|    iterations         | 10100        |\n",
            "|    time_elapsed       | 97           |\n",
            "|    total_timesteps    | 50500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.06        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10099        |\n",
            "|    policy_loss        | -0.0548      |\n",
            "|    reward             | -0.010831722 |\n",
            "|    std                | 14.1         |\n",
            "|    value_loss         | 0.000218     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 519         |\n",
            "|    iterations         | 10200       |\n",
            "|    time_elapsed       | 98          |\n",
            "|    total_timesteps    | 51000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.08       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10199       |\n",
            "|    policy_loss        | -0.0435     |\n",
            "|    reward             | 0.005473823 |\n",
            "|    std                | 14.3        |\n",
            "|    value_loss         | 0.0001      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 519         |\n",
            "|    iterations         | 10300       |\n",
            "|    time_elapsed       | 99          |\n",
            "|    total_timesteps    | 51500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.12       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10299       |\n",
            "|    policy_loss        | 0.0266      |\n",
            "|    reward             | 0.018100899 |\n",
            "|    std                | 14.8        |\n",
            "|    value_loss         | 5.92e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 519         |\n",
            "|    iterations         | 10400       |\n",
            "|    time_elapsed       | 100         |\n",
            "|    total_timesteps    | 52000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.15       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10399       |\n",
            "|    policy_loss        | 0.00615     |\n",
            "|    reward             | 0.016245378 |\n",
            "|    std                | 15.4        |\n",
            "|    value_loss         | 3.13e-06    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 519          |\n",
            "|    iterations         | 10500        |\n",
            "|    time_elapsed       | 100          |\n",
            "|    total_timesteps    | 52500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.17        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10499        |\n",
            "|    policy_loss        | 0.0254       |\n",
            "|    reward             | -0.009089613 |\n",
            "|    std                | 15.7         |\n",
            "|    value_loss         | 6.47e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 519         |\n",
            "|    iterations         | 10600       |\n",
            "|    time_elapsed       | 101         |\n",
            "|    total_timesteps    | 53000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.2        |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10599       |\n",
            "|    policy_loss        | -0.0957     |\n",
            "|    reward             | 0.009727276 |\n",
            "|    std                | 16.1        |\n",
            "|    value_loss         | 0.000582    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 519           |\n",
            "|    iterations         | 10700         |\n",
            "|    time_elapsed       | 102           |\n",
            "|    total_timesteps    | 53500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.23         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10699         |\n",
            "|    policy_loss        | -0.0787       |\n",
            "|    reward             | -0.0024924725 |\n",
            "|    std                | 16.6          |\n",
            "|    value_loss         | 0.000538      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 519         |\n",
            "|    iterations         | 10800       |\n",
            "|    time_elapsed       | 103         |\n",
            "|    total_timesteps    | 54000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.25       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10799       |\n",
            "|    policy_loss        | -0.00308    |\n",
            "|    reward             | 0.002961092 |\n",
            "|    std                | 17          |\n",
            "|    value_loss         | 5.62e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 10900        |\n",
            "|    time_elapsed       | 104          |\n",
            "|    total_timesteps    | 54500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.28        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10899        |\n",
            "|    policy_loss        | -0.0586      |\n",
            "|    reward             | -0.012909699 |\n",
            "|    std                | 17.5         |\n",
            "|    value_loss         | 0.000279     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 11000        |\n",
            "|    time_elapsed       | 105          |\n",
            "|    total_timesteps    | 55000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.3         |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10999        |\n",
            "|    policy_loss        | -0.0379      |\n",
            "|    reward             | -0.008794015 |\n",
            "|    std                | 17.8         |\n",
            "|    value_loss         | 7.13e-05     |\n",
            "----------------------------------------\n",
            "======A2C Validation from:  2022-01-03 to  2022-02-02\n",
            "A2C Sharpe Ratio:  0.07486968152041895\n",
            "======Best Model Retraining from:  2010-04-01 to  2022-02-02\n",
            "======Trading from:  2022-02-02 to  2022-03-04\n",
            "[[ 1.4154596e+04  3.3685516e+01 -1.7900000e+02 -3.6042396e-02\n",
            "   3.5223644e+01  3.0470894e+01  5.6228458e+01  2.4486637e+01\n",
            "   1.6455780e+01  3.3234100e+01  3.2290688e+01]]\n",
            "============================================\n",
            "turbulence_threshold:  12.04306128869847\n",
            "======Model training from:  2010-04-01 to  2022-02-02\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c\\a2c_315_1\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 564           |\n",
            "|    iterations         | 100           |\n",
            "|    time_elapsed       | 0             |\n",
            "|    total_timesteps    | 500           |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.48         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 99            |\n",
            "|    policy_loss        | -0.0175       |\n",
            "|    reward             | -0.0072996686 |\n",
            "|    std                | 1.07          |\n",
            "|    value_loss         | 0.000287      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 536          |\n",
            "|    iterations         | 200          |\n",
            "|    time_elapsed       | 1            |\n",
            "|    total_timesteps    | 1000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.51        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 199          |\n",
            "|    policy_loss        | 0.0119       |\n",
            "|    reward             | 0.0038850226 |\n",
            "|    std                | 1.1          |\n",
            "|    value_loss         | 0.000219     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 531          |\n",
            "|    iterations         | 300          |\n",
            "|    time_elapsed       | 2            |\n",
            "|    total_timesteps    | 1500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.54        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 299          |\n",
            "|    policy_loss        | -0.0132      |\n",
            "|    reward             | -0.028278144 |\n",
            "|    std                | 1.12         |\n",
            "|    value_loss         | 8.2e-05      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 537           |\n",
            "|    iterations         | 400           |\n",
            "|    time_elapsed       | 3             |\n",
            "|    total_timesteps    | 2000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.55         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 399           |\n",
            "|    policy_loss        | -0.0158       |\n",
            "|    reward             | -0.0042865477 |\n",
            "|    std                | 1.14          |\n",
            "|    value_loss         | 0.000454      |\n",
            "-----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 528       |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 4         |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.56     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 0.0246    |\n",
            "|    reward             | 0.1207421 |\n",
            "|    std                | 1.15      |\n",
            "|    value_loss         | 0.00324   |\n",
            "-------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 525           |\n",
            "|    iterations         | 600           |\n",
            "|    time_elapsed       | 5             |\n",
            "|    total_timesteps    | 3000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.57         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 599           |\n",
            "|    policy_loss        | 0.0292        |\n",
            "|    reward             | -0.0045250384 |\n",
            "|    std                | 1.16          |\n",
            "|    value_loss         | 0.00083       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 524         |\n",
            "|    iterations         | 700         |\n",
            "|    time_elapsed       | 6           |\n",
            "|    total_timesteps    | 3500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.57       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 699         |\n",
            "|    policy_loss        | 0.0302      |\n",
            "|    reward             | 0.014829753 |\n",
            "|    std                | 1.17        |\n",
            "|    value_loss         | 0.00054     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 522          |\n",
            "|    iterations         | 800          |\n",
            "|    time_elapsed       | 7            |\n",
            "|    total_timesteps    | 4000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.59        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 799          |\n",
            "|    policy_loss        | 0.0898       |\n",
            "|    reward             | -0.014309115 |\n",
            "|    std                | 1.19         |\n",
            "|    value_loss         | 0.00418      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 520         |\n",
            "|    iterations         | 900         |\n",
            "|    time_elapsed       | 8           |\n",
            "|    total_timesteps    | 4500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.6        |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 899         |\n",
            "|    policy_loss        | 0.0733      |\n",
            "|    reward             | 0.019451626 |\n",
            "|    std                | 1.2         |\n",
            "|    value_loss         | 0.0011      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 519         |\n",
            "|    iterations         | 1000        |\n",
            "|    time_elapsed       | 9           |\n",
            "|    total_timesteps    | 5000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.62       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 999         |\n",
            "|    policy_loss        | 0.0202      |\n",
            "|    reward             | -0.05791128 |\n",
            "|    std                | 1.22        |\n",
            "|    value_loss         | 0.000554    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 519          |\n",
            "|    iterations         | 1100         |\n",
            "|    time_elapsed       | 10           |\n",
            "|    total_timesteps    | 5500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.63        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1099         |\n",
            "|    policy_loss        | -0.254       |\n",
            "|    reward             | -0.061787035 |\n",
            "|    std                | 1.23         |\n",
            "|    value_loss         | 0.0522       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 1200         |\n",
            "|    time_elapsed       | 11           |\n",
            "|    total_timesteps    | 6000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.63        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1199         |\n",
            "|    policy_loss        | 0.0343       |\n",
            "|    reward             | 0.0029999146 |\n",
            "|    std                | 1.24         |\n",
            "|    value_loss         | 0.000734     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 523          |\n",
            "|    iterations         | 1300         |\n",
            "|    time_elapsed       | 12           |\n",
            "|    total_timesteps    | 6500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.65        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1299         |\n",
            "|    policy_loss        | 0.0769       |\n",
            "|    reward             | -0.025693625 |\n",
            "|    std                | 1.26         |\n",
            "|    value_loss         | 0.00273      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 521         |\n",
            "|    iterations         | 1400        |\n",
            "|    time_elapsed       | 13          |\n",
            "|    total_timesteps    | 7000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.67       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1399        |\n",
            "|    policy_loss        | 0.0157      |\n",
            "|    reward             | 0.025572028 |\n",
            "|    std                | 1.28        |\n",
            "|    value_loss         | 0.000151    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 523         |\n",
            "|    iterations         | 1500        |\n",
            "|    time_elapsed       | 14          |\n",
            "|    total_timesteps    | 7500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.67       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1499        |\n",
            "|    policy_loss        | 0.138       |\n",
            "|    reward             | 0.037438057 |\n",
            "|    std                | 1.28        |\n",
            "|    value_loss         | 0.0129      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 523         |\n",
            "|    iterations         | 1600        |\n",
            "|    time_elapsed       | 15          |\n",
            "|    total_timesteps    | 8000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.67       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1599        |\n",
            "|    policy_loss        | -0.0539     |\n",
            "|    reward             | -0.04408868 |\n",
            "|    std                | 1.29        |\n",
            "|    value_loss         | 0.00165     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 524          |\n",
            "|    iterations         | 1700         |\n",
            "|    time_elapsed       | 16           |\n",
            "|    total_timesteps    | 8500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.67        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1699         |\n",
            "|    policy_loss        | -0.152       |\n",
            "|    reward             | -0.047054555 |\n",
            "|    std                | 1.28         |\n",
            "|    value_loss         | 0.00951      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 523           |\n",
            "|    iterations         | 1800          |\n",
            "|    time_elapsed       | 17            |\n",
            "|    total_timesteps    | 9000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.66         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1799          |\n",
            "|    policy_loss        | -0.00183      |\n",
            "|    reward             | -3.993884e-06 |\n",
            "|    std                | 1.27          |\n",
            "|    value_loss         | 2.93e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 522         |\n",
            "|    iterations         | 1900        |\n",
            "|    time_elapsed       | 18          |\n",
            "|    total_timesteps    | 9500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.68       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1899        |\n",
            "|    policy_loss        | -0.0058     |\n",
            "|    reward             | -0.01177179 |\n",
            "|    std                | 1.3         |\n",
            "|    value_loss         | 0.000305    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 523          |\n",
            "|    iterations         | 2000         |\n",
            "|    time_elapsed       | 19           |\n",
            "|    total_timesteps    | 10000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.69        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1999         |\n",
            "|    policy_loss        | -0.036       |\n",
            "|    reward             | 0.0033897944 |\n",
            "|    std                | 1.31         |\n",
            "|    value_loss         | 0.000585     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 524          |\n",
            "|    iterations         | 2100         |\n",
            "|    time_elapsed       | 20           |\n",
            "|    total_timesteps    | 10500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.7         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2099         |\n",
            "|    policy_loss        | -0.031       |\n",
            "|    reward             | -0.012412751 |\n",
            "|    std                | 1.32         |\n",
            "|    value_loss         | 0.001        |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 524          |\n",
            "|    iterations         | 2200         |\n",
            "|    time_elapsed       | 20           |\n",
            "|    total_timesteps    | 11000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.7         |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2199         |\n",
            "|    policy_loss        | -0.0518      |\n",
            "|    reward             | -0.026063839 |\n",
            "|    std                | 1.32         |\n",
            "|    value_loss         | 0.00181      |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 524        |\n",
            "|    iterations         | 2300       |\n",
            "|    time_elapsed       | 21         |\n",
            "|    total_timesteps    | 11500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.72      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2299       |\n",
            "|    policy_loss        | -0.00127   |\n",
            "|    reward             | -0.1577558 |\n",
            "|    std                | 1.35       |\n",
            "|    value_loss         | 0.0036     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 524         |\n",
            "|    iterations         | 2400        |\n",
            "|    time_elapsed       | 22          |\n",
            "|    total_timesteps    | 12000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.74       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2399        |\n",
            "|    policy_loss        | -0.0195     |\n",
            "|    reward             | 0.003100261 |\n",
            "|    std                | 1.37        |\n",
            "|    value_loss         | 0.000151    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 523           |\n",
            "|    iterations         | 2500          |\n",
            "|    time_elapsed       | 23            |\n",
            "|    total_timesteps    | 12500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.75         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2499          |\n",
            "|    policy_loss        | 0.0215        |\n",
            "|    reward             | 0.00051446934 |\n",
            "|    std                | 1.4           |\n",
            "|    value_loss         | 0.000471      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 521         |\n",
            "|    iterations         | 2600        |\n",
            "|    time_elapsed       | 24          |\n",
            "|    total_timesteps    | 13000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.77       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2599        |\n",
            "|    policy_loss        | -0.0144     |\n",
            "|    reward             | 0.010638072 |\n",
            "|    std                | 1.42        |\n",
            "|    value_loss         | 0.000313    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 520         |\n",
            "|    iterations         | 2700        |\n",
            "|    time_elapsed       | 25          |\n",
            "|    total_timesteps    | 13500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.79       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2699        |\n",
            "|    policy_loss        | 0.213       |\n",
            "|    reward             | 0.018392956 |\n",
            "|    std                | 1.44        |\n",
            "|    value_loss         | 0.0371      |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 2800         |\n",
            "|    time_elapsed       | 26           |\n",
            "|    total_timesteps    | 14000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.79        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2799         |\n",
            "|    policy_loss        | 0.0713       |\n",
            "|    reward             | -0.024372686 |\n",
            "|    std                | 1.45         |\n",
            "|    value_loss         | 0.00326      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 521         |\n",
            "|    iterations         | 2900        |\n",
            "|    time_elapsed       | 27          |\n",
            "|    total_timesteps    | 14500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.79       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2899        |\n",
            "|    policy_loss        | 0.00768     |\n",
            "|    reward             | 0.023179421 |\n",
            "|    std                | 1.45        |\n",
            "|    value_loss         | 0.00524     |\n",
            "---------------------------------------\n",
            "day: 2980, episode: 5\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -17123.16\n",
            "total_reward: -27123.16\n",
            "total_cost: 129.74\n",
            "total_trades: 2980\n",
            "Sharpe: 0.439\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 521          |\n",
            "|    iterations         | 3000         |\n",
            "|    time_elapsed       | 28           |\n",
            "|    total_timesteps    | 15000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.79        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2999         |\n",
            "|    policy_loss        | -0.00519     |\n",
            "|    reward             | -0.006124418 |\n",
            "|    std                | 1.46         |\n",
            "|    value_loss         | 2.65e-05     |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 520        |\n",
            "|    iterations         | 3100       |\n",
            "|    time_elapsed       | 29         |\n",
            "|    total_timesteps    | 15500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.8       |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3099       |\n",
            "|    policy_loss        | -0.00939   |\n",
            "|    reward             | -0.0314164 |\n",
            "|    std                | 1.47       |\n",
            "|    value_loss         | 0.000282   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 521         |\n",
            "|    iterations         | 3200        |\n",
            "|    time_elapsed       | 30          |\n",
            "|    total_timesteps    | 16000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.81       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3199        |\n",
            "|    policy_loss        | 0.00124     |\n",
            "|    reward             | 0.029121947 |\n",
            "|    std                | 1.48        |\n",
            "|    value_loss         | 0.000413    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 521         |\n",
            "|    iterations         | 3300        |\n",
            "|    time_elapsed       | 31          |\n",
            "|    total_timesteps    | 16500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.82       |\n",
            "|    explained_variance | 1.79e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3299        |\n",
            "|    policy_loss        | -0.125      |\n",
            "|    reward             | 0.044532847 |\n",
            "|    std                | 1.5         |\n",
            "|    value_loss         | 0.00582     |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 522       |\n",
            "|    iterations         | 3400      |\n",
            "|    time_elapsed       | 32        |\n",
            "|    total_timesteps    | 17000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.83     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3399      |\n",
            "|    policy_loss        | 0.0165    |\n",
            "|    reward             | 0.3252114 |\n",
            "|    std                | 1.51      |\n",
            "|    value_loss         | 0.000625  |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 522          |\n",
            "|    iterations         | 3500         |\n",
            "|    time_elapsed       | 33           |\n",
            "|    total_timesteps    | 17500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.84        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3499         |\n",
            "|    policy_loss        | -0.0747      |\n",
            "|    reward             | -0.002062356 |\n",
            "|    std                | 1.52         |\n",
            "|    value_loss         | 0.00502      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 522           |\n",
            "|    iterations         | 3600          |\n",
            "|    time_elapsed       | 34            |\n",
            "|    total_timesteps    | 18000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.84         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3599          |\n",
            "|    policy_loss        | -0.0023       |\n",
            "|    reward             | -0.0017632883 |\n",
            "|    std                | 1.53          |\n",
            "|    value_loss         | 8.08e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 522         |\n",
            "|    iterations         | 3700        |\n",
            "|    time_elapsed       | 35          |\n",
            "|    total_timesteps    | 18500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.86       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3699        |\n",
            "|    policy_loss        | -0.0438     |\n",
            "|    reward             | -0.04119534 |\n",
            "|    std                | 1.55        |\n",
            "|    value_loss         | 0.000791    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 522          |\n",
            "|    iterations         | 3800         |\n",
            "|    time_elapsed       | 36           |\n",
            "|    total_timesteps    | 19000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.87        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3799         |\n",
            "|    policy_loss        | 0.116        |\n",
            "|    reward             | -0.004695806 |\n",
            "|    std                | 1.57         |\n",
            "|    value_loss         | 0.00368      |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 523        |\n",
            "|    iterations         | 3900       |\n",
            "|    time_elapsed       | 37         |\n",
            "|    total_timesteps    | 19500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.9       |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3899       |\n",
            "|    policy_loss        | 0.0174     |\n",
            "|    reward             | 0.01334321 |\n",
            "|    std                | 1.61       |\n",
            "|    value_loss         | 0.00186    |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 522          |\n",
            "|    iterations         | 4000         |\n",
            "|    time_elapsed       | 38           |\n",
            "|    total_timesteps    | 20000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.91        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3999         |\n",
            "|    policy_loss        | -0.106       |\n",
            "|    reward             | -0.014218008 |\n",
            "|    std                | 1.63         |\n",
            "|    value_loss         | 0.00365      |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 522        |\n",
            "|    iterations         | 4100       |\n",
            "|    time_elapsed       | 39         |\n",
            "|    total_timesteps    | 20500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.91      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4099       |\n",
            "|    policy_loss        | 0.161      |\n",
            "|    reward             | 0.03457844 |\n",
            "|    std                | 1.64       |\n",
            "|    value_loss         | 0.0101     |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 523           |\n",
            "|    iterations         | 4200          |\n",
            "|    time_elapsed       | 40            |\n",
            "|    total_timesteps    | 21000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.91         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4199          |\n",
            "|    policy_loss        | 0.02          |\n",
            "|    reward             | -0.0044683903 |\n",
            "|    std                | 1.64          |\n",
            "|    value_loss         | 0.000233      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 523          |\n",
            "|    iterations         | 4300         |\n",
            "|    time_elapsed       | 41           |\n",
            "|    total_timesteps    | 21500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.92        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4299         |\n",
            "|    policy_loss        | 0.087        |\n",
            "|    reward             | 0.0070989933 |\n",
            "|    std                | 1.65         |\n",
            "|    value_loss         | 0.0033       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 522         |\n",
            "|    iterations         | 4400        |\n",
            "|    time_elapsed       | 42          |\n",
            "|    total_timesteps    | 22000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.93       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4399        |\n",
            "|    policy_loss        | 0.0254      |\n",
            "|    reward             | 0.046452124 |\n",
            "|    std                | 1.66        |\n",
            "|    value_loss         | 0.000284    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 522         |\n",
            "|    iterations         | 4500        |\n",
            "|    time_elapsed       | 43          |\n",
            "|    total_timesteps    | 22500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.94       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4499        |\n",
            "|    policy_loss        | 0.0814      |\n",
            "|    reward             | 0.018664965 |\n",
            "|    std                | 1.68        |\n",
            "|    value_loss         | 0.0031      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 522         |\n",
            "|    iterations         | 4600        |\n",
            "|    time_elapsed       | 44          |\n",
            "|    total_timesteps    | 23000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.95       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4599        |\n",
            "|    policy_loss        | -0.081      |\n",
            "|    reward             | -0.06928162 |\n",
            "|    std                | 1.7         |\n",
            "|    value_loss         | 0.00181     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 522          |\n",
            "|    iterations         | 4700         |\n",
            "|    time_elapsed       | 44           |\n",
            "|    total_timesteps    | 23500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.96        |\n",
            "|    explained_variance | 1.79e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4699         |\n",
            "|    policy_loss        | 0.19         |\n",
            "|    reward             | -0.030116301 |\n",
            "|    std                | 1.71         |\n",
            "|    value_loss         | 0.0621       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 520           |\n",
            "|    iterations         | 4800          |\n",
            "|    time_elapsed       | 46            |\n",
            "|    total_timesteps    | 24000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.96         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4799          |\n",
            "|    policy_loss        | -0.0042       |\n",
            "|    reward             | -0.0128180515 |\n",
            "|    std                | 1.72          |\n",
            "|    value_loss         | 3.72e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 520         |\n",
            "|    iterations         | 4900        |\n",
            "|    time_elapsed       | 47          |\n",
            "|    total_timesteps    | 24500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.97       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4899        |\n",
            "|    policy_loss        | 0.00796     |\n",
            "|    reward             | -0.04469062 |\n",
            "|    std                | 1.74        |\n",
            "|    value_loss         | 0.000422    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 519         |\n",
            "|    iterations         | 5000        |\n",
            "|    time_elapsed       | 48          |\n",
            "|    total_timesteps    | 25000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.98       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4999        |\n",
            "|    policy_loss        | -0.164      |\n",
            "|    reward             | -0.10379018 |\n",
            "|    std                | 1.76        |\n",
            "|    value_loss         | 0.011       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 519        |\n",
            "|    iterations         | 5100       |\n",
            "|    time_elapsed       | 49         |\n",
            "|    total_timesteps    | 25500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2         |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5099       |\n",
            "|    policy_loss        | 0.366      |\n",
            "|    reward             | -0.0571216 |\n",
            "|    std                | 1.78       |\n",
            "|    value_loss         | 0.0446     |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 518          |\n",
            "|    iterations         | 5200         |\n",
            "|    time_elapsed       | 50           |\n",
            "|    total_timesteps    | 26000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.01        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5199         |\n",
            "|    policy_loss        | 0.531        |\n",
            "|    reward             | -0.061542604 |\n",
            "|    std                | 1.8          |\n",
            "|    value_loss         | 0.103        |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 517         |\n",
            "|    iterations         | 5300        |\n",
            "|    time_elapsed       | 51          |\n",
            "|    total_timesteps    | 26500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2          |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5299        |\n",
            "|    policy_loss        | -0.0673     |\n",
            "|    reward             | 0.074590996 |\n",
            "|    std                | 1.79        |\n",
            "|    value_loss         | 0.00562     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 518         |\n",
            "|    iterations         | 5400        |\n",
            "|    time_elapsed       | 52          |\n",
            "|    total_timesteps    | 27000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2          |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5399        |\n",
            "|    policy_loss        | 0.022       |\n",
            "|    reward             | 0.016826957 |\n",
            "|    std                | 1.8         |\n",
            "|    value_loss         | 0.000303    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 517          |\n",
            "|    iterations         | 5500         |\n",
            "|    time_elapsed       | 53           |\n",
            "|    total_timesteps    | 27500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2           |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5499         |\n",
            "|    policy_loss        | 0.0467       |\n",
            "|    reward             | -0.015005439 |\n",
            "|    std                | 1.8          |\n",
            "|    value_loss         | 0.00163      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 517          |\n",
            "|    iterations         | 5600         |\n",
            "|    time_elapsed       | 54           |\n",
            "|    total_timesteps    | 28000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.01        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5599         |\n",
            "|    policy_loss        | -0.0902      |\n",
            "|    reward             | -0.021151543 |\n",
            "|    std                | 1.81         |\n",
            "|    value_loss         | 0.00507      |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 518            |\n",
            "|    iterations         | 5700           |\n",
            "|    time_elapsed       | 55             |\n",
            "|    total_timesteps    | 28500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -2.03          |\n",
            "|    explained_variance | -1.19e-07      |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 5699           |\n",
            "|    policy_loss        | 0.0214         |\n",
            "|    reward             | -4.4490466e-06 |\n",
            "|    std                | 1.85           |\n",
            "|    value_loss         | 0.00158        |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 517         |\n",
            "|    iterations         | 5800        |\n",
            "|    time_elapsed       | 56          |\n",
            "|    total_timesteps    | 29000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.05       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5799        |\n",
            "|    policy_loss        | -0.237      |\n",
            "|    reward             | 0.017772356 |\n",
            "|    std                | 1.88        |\n",
            "|    value_loss         | 0.021       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 517         |\n",
            "|    iterations         | 5900        |\n",
            "|    time_elapsed       | 57          |\n",
            "|    total_timesteps    | 29500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.07       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5899        |\n",
            "|    policy_loss        | 0.6         |\n",
            "|    reward             | -0.21280044 |\n",
            "|    std                | 1.92        |\n",
            "|    value_loss         | 0.131       |\n",
            "---------------------------------------\n",
            "day: 2980, episode: 10\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -23737.15\n",
            "total_reward: -33737.15\n",
            "total_cost: 136.77\n",
            "total_trades: 2980\n",
            "Sharpe: 0.186\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 517          |\n",
            "|    iterations         | 6000         |\n",
            "|    time_elapsed       | 57           |\n",
            "|    total_timesteps    | 30000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.08        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5999         |\n",
            "|    policy_loss        | 0.036        |\n",
            "|    reward             | 0.0065944744 |\n",
            "|    std                | 1.95         |\n",
            "|    value_loss         | 0.000219     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 517          |\n",
            "|    iterations         | 6100         |\n",
            "|    time_elapsed       | 58           |\n",
            "|    total_timesteps    | 30500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.08        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6099         |\n",
            "|    policy_loss        | -0.0757      |\n",
            "|    reward             | 0.0063966466 |\n",
            "|    std                | 1.94         |\n",
            "|    value_loss         | 0.00179      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 517          |\n",
            "|    iterations         | 6200         |\n",
            "|    time_elapsed       | 59           |\n",
            "|    total_timesteps    | 31000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.08        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6199         |\n",
            "|    policy_loss        | 0.0997       |\n",
            "|    reward             | -0.018870356 |\n",
            "|    std                | 1.94         |\n",
            "|    value_loss         | 0.00117      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 516          |\n",
            "|    iterations         | 6300         |\n",
            "|    time_elapsed       | 60           |\n",
            "|    total_timesteps    | 31500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.11        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6299         |\n",
            "|    policy_loss        | -0.433       |\n",
            "|    reward             | -0.031367257 |\n",
            "|    std                | 1.99         |\n",
            "|    value_loss         | 0.0521       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 517         |\n",
            "|    iterations         | 6400        |\n",
            "|    time_elapsed       | 61          |\n",
            "|    total_timesteps    | 32000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.11       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6399        |\n",
            "|    policy_loss        | 0.16        |\n",
            "|    reward             | -0.12449784 |\n",
            "|    std                | 2           |\n",
            "|    value_loss         | 0.0137      |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 517          |\n",
            "|    iterations         | 6500         |\n",
            "|    time_elapsed       | 62           |\n",
            "|    total_timesteps    | 32500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.12        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6499         |\n",
            "|    policy_loss        | 0.0608       |\n",
            "|    reward             | -0.033034563 |\n",
            "|    std                | 2.01         |\n",
            "|    value_loss         | 0.00362      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 517         |\n",
            "|    iterations         | 6600        |\n",
            "|    time_elapsed       | 63          |\n",
            "|    total_timesteps    | 33000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.12       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6599        |\n",
            "|    policy_loss        | 0.264       |\n",
            "|    reward             | 0.044287328 |\n",
            "|    std                | 2.03        |\n",
            "|    value_loss         | 0.0222      |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 516          |\n",
            "|    iterations         | 6700         |\n",
            "|    time_elapsed       | 64           |\n",
            "|    total_timesteps    | 33500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.13        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6699         |\n",
            "|    policy_loss        | -0.0882      |\n",
            "|    reward             | -0.092102855 |\n",
            "|    std                | 2.04         |\n",
            "|    value_loss         | 0.00195      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 516          |\n",
            "|    iterations         | 6800         |\n",
            "|    time_elapsed       | 65           |\n",
            "|    total_timesteps    | 34000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.14        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6799         |\n",
            "|    policy_loss        | 0.0415       |\n",
            "|    reward             | -0.014916412 |\n",
            "|    std                | 2.06         |\n",
            "|    value_loss         | 0.00339      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 516          |\n",
            "|    iterations         | 6900         |\n",
            "|    time_elapsed       | 66           |\n",
            "|    total_timesteps    | 34500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.15        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6899         |\n",
            "|    policy_loss        | -0.0841      |\n",
            "|    reward             | -0.011841731 |\n",
            "|    std                | 2.07         |\n",
            "|    value_loss         | 0.00342      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 516          |\n",
            "|    iterations         | 7000         |\n",
            "|    time_elapsed       | 67           |\n",
            "|    total_timesteps    | 35000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.16        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6999         |\n",
            "|    policy_loss        | 0.316        |\n",
            "|    reward             | -0.023787472 |\n",
            "|    std                | 2.09         |\n",
            "|    value_loss         | 0.0315       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 516         |\n",
            "|    iterations         | 7100        |\n",
            "|    time_elapsed       | 68          |\n",
            "|    total_timesteps    | 35500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.16       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7099        |\n",
            "|    policy_loss        | -0.022      |\n",
            "|    reward             | -0.20644903 |\n",
            "|    std                | 2.11        |\n",
            "|    value_loss         | 0.00177     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 516          |\n",
            "|    iterations         | 7200         |\n",
            "|    time_elapsed       | 69           |\n",
            "|    total_timesteps    | 36000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.17        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7199         |\n",
            "|    policy_loss        | -0.00596     |\n",
            "|    reward             | -0.021429228 |\n",
            "|    std                | 2.12         |\n",
            "|    value_loss         | 7.2e-05      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 516           |\n",
            "|    iterations         | 7300          |\n",
            "|    time_elapsed       | 70            |\n",
            "|    total_timesteps    | 36500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.18         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7299          |\n",
            "|    policy_loss        | 0.0211        |\n",
            "|    reward             | -0.0082531115 |\n",
            "|    std                | 2.14          |\n",
            "|    value_loss         | 0.00047       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 516         |\n",
            "|    iterations         | 7400        |\n",
            "|    time_elapsed       | 71          |\n",
            "|    total_timesteps    | 37000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.19       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7399        |\n",
            "|    policy_loss        | 0.00834     |\n",
            "|    reward             | 0.019575715 |\n",
            "|    std                | 2.16        |\n",
            "|    value_loss         | 0.000627    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 516          |\n",
            "|    iterations         | 7500         |\n",
            "|    time_elapsed       | 72           |\n",
            "|    total_timesteps    | 37500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.21        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7499         |\n",
            "|    policy_loss        | -0.129       |\n",
            "|    reward             | -0.036787745 |\n",
            "|    std                | 2.2          |\n",
            "|    value_loss         | 0.00624      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 517         |\n",
            "|    iterations         | 7600        |\n",
            "|    time_elapsed       | 73          |\n",
            "|    total_timesteps    | 38000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.21       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7599        |\n",
            "|    policy_loss        | 1.03        |\n",
            "|    reward             | 0.030141782 |\n",
            "|    std                | 2.21        |\n",
            "|    value_loss         | 0.163       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 517        |\n",
            "|    iterations         | 7700       |\n",
            "|    time_elapsed       | 74         |\n",
            "|    total_timesteps    | 38500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.22      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 7699       |\n",
            "|    policy_loss        | -0.555     |\n",
            "|    reward             | 0.14944547 |\n",
            "|    std                | 2.23       |\n",
            "|    value_loss         | 0.0646     |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 517          |\n",
            "|    iterations         | 7800         |\n",
            "|    time_elapsed       | 75           |\n",
            "|    total_timesteps    | 39000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.22        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7799         |\n",
            "|    policy_loss        | 0.0959       |\n",
            "|    reward             | -0.021635603 |\n",
            "|    std                | 2.22         |\n",
            "|    value_loss         | 0.00265      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 517         |\n",
            "|    iterations         | 7900        |\n",
            "|    time_elapsed       | 76          |\n",
            "|    total_timesteps    | 39500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.22       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7899        |\n",
            "|    policy_loss        | 0.0657      |\n",
            "|    reward             | 0.029796679 |\n",
            "|    std                | 2.24        |\n",
            "|    value_loss         | 0.000651    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 517         |\n",
            "|    iterations         | 8000        |\n",
            "|    time_elapsed       | 77          |\n",
            "|    total_timesteps    | 40000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.22       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7999        |\n",
            "|    policy_loss        | 0.0413      |\n",
            "|    reward             | 0.017883282 |\n",
            "|    std                | 2.22        |\n",
            "|    value_loss         | 0.00182     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 517          |\n",
            "|    iterations         | 8100         |\n",
            "|    time_elapsed       | 78           |\n",
            "|    total_timesteps    | 40500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.23        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8099         |\n",
            "|    policy_loss        | 0.002        |\n",
            "|    reward             | -0.031225808 |\n",
            "|    std                | 2.25         |\n",
            "|    value_loss         | 0.000416     |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 518        |\n",
            "|    iterations         | 8200       |\n",
            "|    time_elapsed       | 79         |\n",
            "|    total_timesteps    | 41000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.25      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8199       |\n",
            "|    policy_loss        | 0.107      |\n",
            "|    reward             | 0.12956965 |\n",
            "|    std                | 2.29       |\n",
            "|    value_loss         | 0.00398    |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 517        |\n",
            "|    iterations         | 8300       |\n",
            "|    time_elapsed       | 80         |\n",
            "|    total_timesteps    | 41500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.26      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 8299       |\n",
            "|    policy_loss        | 0.269      |\n",
            "|    reward             | 0.04500017 |\n",
            "|    std                | 2.31       |\n",
            "|    value_loss         | 0.023      |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 517          |\n",
            "|    iterations         | 8400         |\n",
            "|    time_elapsed       | 81           |\n",
            "|    total_timesteps    | 42000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.27        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8399         |\n",
            "|    policy_loss        | 0.021        |\n",
            "|    reward             | -0.025384266 |\n",
            "|    std                | 2.34         |\n",
            "|    value_loss         | 0.000253     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 516         |\n",
            "|    iterations         | 8500        |\n",
            "|    time_elapsed       | 82          |\n",
            "|    total_timesteps    | 42500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.28       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8499        |\n",
            "|    policy_loss        | -0.0902     |\n",
            "|    reward             | 0.026929416 |\n",
            "|    std                | 2.38        |\n",
            "|    value_loss         | 0.00239     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 517          |\n",
            "|    iterations         | 8600         |\n",
            "|    time_elapsed       | 83           |\n",
            "|    total_timesteps    | 43000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.31        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8599         |\n",
            "|    policy_loss        | -0.174       |\n",
            "|    reward             | -0.043117356 |\n",
            "|    std                | 2.44         |\n",
            "|    value_loss         | 0.00741      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 517          |\n",
            "|    iterations         | 8700         |\n",
            "|    time_elapsed       | 84           |\n",
            "|    total_timesteps    | 43500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.32        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8699         |\n",
            "|    policy_loss        | 0.0253       |\n",
            "|    reward             | 0.0015177878 |\n",
            "|    std                | 2.47         |\n",
            "|    value_loss         | 0.000283     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 517          |\n",
            "|    iterations         | 8800         |\n",
            "|    time_elapsed       | 85           |\n",
            "|    total_timesteps    | 44000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.32        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8799         |\n",
            "|    policy_loss        | 0.148        |\n",
            "|    reward             | -0.021913273 |\n",
            "|    std                | 2.46         |\n",
            "|    value_loss         | 0.00834      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 517         |\n",
            "|    iterations         | 8900        |\n",
            "|    time_elapsed       | 85          |\n",
            "|    total_timesteps    | 44500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.33       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8899        |\n",
            "|    policy_loss        | 0.0596      |\n",
            "|    reward             | 0.040476132 |\n",
            "|    std                | 2.5         |\n",
            "|    value_loss         | 0.00646     |\n",
            "---------------------------------------\n",
            "day: 2980, episode: 15\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -21665.26\n",
            "total_reward: -31665.26\n",
            "total_cost: 134.66\n",
            "total_trades: 2980\n",
            "Sharpe: 0.403\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 517          |\n",
            "|    iterations         | 9000         |\n",
            "|    time_elapsed       | 86           |\n",
            "|    total_timesteps    | 45000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.34        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 8999         |\n",
            "|    policy_loss        | -0.0633      |\n",
            "|    reward             | -0.011559099 |\n",
            "|    std                | 2.53         |\n",
            "|    value_loss         | 0.000993     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 517          |\n",
            "|    iterations         | 9100         |\n",
            "|    time_elapsed       | 87           |\n",
            "|    total_timesteps    | 45500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.35        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9099         |\n",
            "|    policy_loss        | -0.104       |\n",
            "|    reward             | 0.0019544268 |\n",
            "|    std                | 2.53         |\n",
            "|    value_loss         | 0.00255      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 517          |\n",
            "|    iterations         | 9200         |\n",
            "|    time_elapsed       | 88           |\n",
            "|    total_timesteps    | 46000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.36        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9199         |\n",
            "|    policy_loss        | -0.0815      |\n",
            "|    reward             | -0.010990292 |\n",
            "|    std                | 2.56         |\n",
            "|    value_loss         | 0.00173      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 517         |\n",
            "|    iterations         | 9300        |\n",
            "|    time_elapsed       | 89          |\n",
            "|    total_timesteps    | 46500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.37       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9299        |\n",
            "|    policy_loss        | -0.517      |\n",
            "|    reward             | -0.02760541 |\n",
            "|    std                | 2.59        |\n",
            "|    value_loss         | 0.0637      |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 517           |\n",
            "|    iterations         | 9400          |\n",
            "|    time_elapsed       | 90            |\n",
            "|    total_timesteps    | 47000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.37         |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9399          |\n",
            "|    policy_loss        | -0.224        |\n",
            "|    reward             | -0.0035938637 |\n",
            "|    std                | 2.6           |\n",
            "|    value_loss         | 0.0132        |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 517         |\n",
            "|    iterations         | 9500        |\n",
            "|    time_elapsed       | 91          |\n",
            "|    total_timesteps    | 47500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.39       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9499        |\n",
            "|    policy_loss        | -0.0876     |\n",
            "|    reward             | -0.06040628 |\n",
            "|    std                | 2.64        |\n",
            "|    value_loss         | 0.00266     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 517         |\n",
            "|    iterations         | 9600        |\n",
            "|    time_elapsed       | 92          |\n",
            "|    total_timesteps    | 48000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.4        |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9599        |\n",
            "|    policy_loss        | 0.0352      |\n",
            "|    reward             | 0.036436014 |\n",
            "|    std                | 2.67        |\n",
            "|    value_loss         | 0.000892    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 516           |\n",
            "|    iterations         | 9700          |\n",
            "|    time_elapsed       | 93            |\n",
            "|    total_timesteps    | 48500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.4          |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9699          |\n",
            "|    policy_loss        | -0.109        |\n",
            "|    reward             | -0.0062932484 |\n",
            "|    std                | 2.68          |\n",
            "|    value_loss         | 0.00317       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 517         |\n",
            "|    iterations         | 9800        |\n",
            "|    time_elapsed       | 94          |\n",
            "|    total_timesteps    | 49000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.4        |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9799        |\n",
            "|    policy_loss        | 0.169       |\n",
            "|    reward             | 0.021320214 |\n",
            "|    std                | 2.68        |\n",
            "|    value_loss         | 0.00357     |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 517        |\n",
            "|    iterations         | 9900       |\n",
            "|    time_elapsed       | 95         |\n",
            "|    total_timesteps    | 49500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.41      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 9899       |\n",
            "|    policy_loss        | 0.0998     |\n",
            "|    reward             | -0.1085529 |\n",
            "|    std                | 2.69       |\n",
            "|    value_loss         | 0.00189    |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 517           |\n",
            "|    iterations         | 10000         |\n",
            "|    time_elapsed       | 96            |\n",
            "|    total_timesteps    | 50000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.42         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9999          |\n",
            "|    policy_loss        | -0.22         |\n",
            "|    reward             | -0.0056037484 |\n",
            "|    std                | 2.71          |\n",
            "|    value_loss         | 0.0109        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 517          |\n",
            "|    iterations         | 10100        |\n",
            "|    time_elapsed       | 97           |\n",
            "|    total_timesteps    | 50500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.43        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10099        |\n",
            "|    policy_loss        | 0.0771       |\n",
            "|    reward             | -0.051008537 |\n",
            "|    std                | 2.74         |\n",
            "|    value_loss         | 0.0148       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 517          |\n",
            "|    iterations         | 10200        |\n",
            "|    time_elapsed       | 98           |\n",
            "|    total_timesteps    | 51000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.43        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10199        |\n",
            "|    policy_loss        | -0.031       |\n",
            "|    reward             | 0.0043846853 |\n",
            "|    std                | 2.76         |\n",
            "|    value_loss         | 0.000253     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 517          |\n",
            "|    iterations         | 10300        |\n",
            "|    time_elapsed       | 99           |\n",
            "|    total_timesteps    | 51500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.44        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10299        |\n",
            "|    policy_loss        | -0.0371      |\n",
            "|    reward             | -0.000580498 |\n",
            "|    std                | 2.78         |\n",
            "|    value_loss         | 0.00094      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 517         |\n",
            "|    iterations         | 10400       |\n",
            "|    time_elapsed       | 100         |\n",
            "|    total_timesteps    | 52000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.43       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10399       |\n",
            "|    policy_loss        | 0.112       |\n",
            "|    reward             | 0.032548834 |\n",
            "|    std                | 2.76        |\n",
            "|    value_loss         | 0.00229     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 517          |\n",
            "|    iterations         | 10500        |\n",
            "|    time_elapsed       | 101          |\n",
            "|    total_timesteps    | 52500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.45        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10499        |\n",
            "|    policy_loss        | 0.0207       |\n",
            "|    reward             | -0.028543994 |\n",
            "|    std                | 2.79         |\n",
            "|    value_loss         | 0.000512     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 517         |\n",
            "|    iterations         | 10600       |\n",
            "|    time_elapsed       | 102         |\n",
            "|    total_timesteps    | 53000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.46       |\n",
            "|    explained_variance | 1.79e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10599       |\n",
            "|    policy_loss        | -0.0197     |\n",
            "|    reward             | 0.048148494 |\n",
            "|    std                | 2.84        |\n",
            "|    value_loss         | 0.000731    |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 517       |\n",
            "|    iterations         | 10700     |\n",
            "|    time_elapsed       | 103       |\n",
            "|    total_timesteps    | 53500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -2.48     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 10699     |\n",
            "|    policy_loss        | -0.116    |\n",
            "|    reward             | 0.1571063 |\n",
            "|    std                | 2.89      |\n",
            "|    value_loss         | 0.00876   |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 517         |\n",
            "|    iterations         | 10800       |\n",
            "|    time_elapsed       | 104         |\n",
            "|    total_timesteps    | 54000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.48       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10799       |\n",
            "|    policy_loss        | 0.137       |\n",
            "|    reward             | -0.03368723 |\n",
            "|    std                | 2.89        |\n",
            "|    value_loss         | 0.00896     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 518          |\n",
            "|    iterations         | 10900        |\n",
            "|    time_elapsed       | 105          |\n",
            "|    total_timesteps    | 54500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.49        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10899        |\n",
            "|    policy_loss        | -0.0205      |\n",
            "|    reward             | 0.0013721281 |\n",
            "|    std                | 2.93         |\n",
            "|    value_loss         | 0.000239     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 517          |\n",
            "|    iterations         | 11000        |\n",
            "|    time_elapsed       | 106          |\n",
            "|    total_timesteps    | 55000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.5         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10999        |\n",
            "|    policy_loss        | -0.203       |\n",
            "|    reward             | -0.032003906 |\n",
            "|    std                | 2.95         |\n",
            "|    value_loss         | 0.00534      |\n",
            "----------------------------------------\n",
            "======A2C Validation from:  2022-02-02 to  2022-03-04\n",
            "A2C Sharpe Ratio:  0.03866542593812702\n",
            "======Best Model Retraining from:  2010-04-01 to  2022-03-04\n",
            "======Trading from:  2022-03-04 to  2022-04-04\n",
            "[[ 1.4153709e+04  3.3452095e+01 -1.7900000e+02  4.9944267e-02\n",
            "   3.4455540e+01  3.2319069e+01  5.2941219e+01  2.1312513e+01\n",
            "   1.0220530e+01  3.3013554e+01  3.3194733e+01]]\n",
            "============================================\n",
            "turbulence_threshold:  12.04306128869847\n",
            "======Model training from:  2010-04-01 to  2022-03-04\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/a2c\\a2c_336_1\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 482           |\n",
            "|    iterations         | 100           |\n",
            "|    time_elapsed       | 1             |\n",
            "|    total_timesteps    | 500           |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -1.48         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 99            |\n",
            "|    policy_loss        | -0.0154       |\n",
            "|    reward             | -0.0053231423 |\n",
            "|    std                | 1.06          |\n",
            "|    value_loss         | 0.000107      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 514          |\n",
            "|    iterations         | 200          |\n",
            "|    time_elapsed       | 1            |\n",
            "|    total_timesteps    | 1000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.52        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 199          |\n",
            "|    policy_loss        | 0.00328      |\n",
            "|    reward             | 0.0019212585 |\n",
            "|    std                | 1.11         |\n",
            "|    value_loss         | 2.76e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 520          |\n",
            "|    iterations         | 300          |\n",
            "|    time_elapsed       | 2            |\n",
            "|    total_timesteps    | 1500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.56        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 299          |\n",
            "|    policy_loss        | 0.00135      |\n",
            "|    reward             | -0.008314876 |\n",
            "|    std                | 1.15         |\n",
            "|    value_loss         | 4.97e-06     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 515            |\n",
            "|    iterations         | 400            |\n",
            "|    time_elapsed       | 3              |\n",
            "|    total_timesteps    | 2000           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -1.61          |\n",
            "|    explained_variance | 5.96e-08       |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 399            |\n",
            "|    policy_loss        | -0.00163       |\n",
            "|    reward             | -0.00017867678 |\n",
            "|    std                | 1.21           |\n",
            "|    value_loss         | 2.14e-06       |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 506         |\n",
            "|    iterations         | 500         |\n",
            "|    time_elapsed       | 4           |\n",
            "|    total_timesteps    | 2500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.66       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 499         |\n",
            "|    policy_loss        | -0.00256    |\n",
            "|    reward             | 0.014195641 |\n",
            "|    std                | 1.27        |\n",
            "|    value_loss         | 2.84e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 505         |\n",
            "|    iterations         | 600         |\n",
            "|    time_elapsed       | 5           |\n",
            "|    total_timesteps    | 3000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.71       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 599         |\n",
            "|    policy_loss        | 0.0153      |\n",
            "|    reward             | -0.00708742 |\n",
            "|    std                | 1.34        |\n",
            "|    value_loss         | 8.18e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 501          |\n",
            "|    iterations         | 700          |\n",
            "|    time_elapsed       | 6            |\n",
            "|    total_timesteps    | 3500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -1.76        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 699          |\n",
            "|    policy_loss        | -0.00154     |\n",
            "|    reward             | 0.0010698672 |\n",
            "|    std                | 1.41         |\n",
            "|    value_loss         | 3.31e-06     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 504            |\n",
            "|    iterations         | 800            |\n",
            "|    time_elapsed       | 7              |\n",
            "|    total_timesteps    | 4000           |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -1.82          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 799            |\n",
            "|    policy_loss        | 0.0162         |\n",
            "|    reward             | -0.00021963967 |\n",
            "|    std                | 1.49           |\n",
            "|    value_loss         | 0.000105       |\n",
            "------------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 500        |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 8          |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -1.87      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | 0.00149    |\n",
            "|    reward             | 0.00250485 |\n",
            "|    std                | 1.57       |\n",
            "|    value_loss         | 3.86e-06   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 501         |\n",
            "|    iterations         | 1000        |\n",
            "|    time_elapsed       | 9           |\n",
            "|    total_timesteps    | 5000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.92       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 999         |\n",
            "|    policy_loss        | -0.00118    |\n",
            "|    reward             | -0.00522117 |\n",
            "|    std                | 1.65        |\n",
            "|    value_loss         | 1.15e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 502         |\n",
            "|    iterations         | 1100        |\n",
            "|    time_elapsed       | 10          |\n",
            "|    total_timesteps    | 5500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -1.96       |\n",
            "|    explained_variance | 1.79e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1099        |\n",
            "|    policy_loss        | 0.0326      |\n",
            "|    reward             | 0.011285585 |\n",
            "|    std                | 1.72        |\n",
            "|    value_loss         | 0.000461    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 504          |\n",
            "|    iterations         | 1200         |\n",
            "|    time_elapsed       | 11           |\n",
            "|    total_timesteps    | 6000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2           |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1199         |\n",
            "|    policy_loss        | 0.00277      |\n",
            "|    reward             | 0.0030965465 |\n",
            "|    std                | 1.79         |\n",
            "|    value_loss         | 1.23e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 499          |\n",
            "|    iterations         | 1300         |\n",
            "|    time_elapsed       | 13           |\n",
            "|    total_timesteps    | 6500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.02        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1299         |\n",
            "|    policy_loss        | -0.00195     |\n",
            "|    reward             | 0.0012071915 |\n",
            "|    std                | 1.83         |\n",
            "|    value_loss         | 1.56e-06     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 500          |\n",
            "|    iterations         | 1400         |\n",
            "|    time_elapsed       | 13           |\n",
            "|    total_timesteps    | 7000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.06        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1399         |\n",
            "|    policy_loss        | 0.0172       |\n",
            "|    reward             | -0.003823545 |\n",
            "|    std                | 1.9          |\n",
            "|    value_loss         | 6.1e-05      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 501           |\n",
            "|    iterations         | 1500          |\n",
            "|    time_elapsed       | 14            |\n",
            "|    total_timesteps    | 7500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.11         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1499          |\n",
            "|    policy_loss        | -0.00332      |\n",
            "|    reward             | -0.0024225921 |\n",
            "|    std                | 1.99          |\n",
            "|    value_loss         | 2.65e-06      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 503           |\n",
            "|    iterations         | 1600          |\n",
            "|    time_elapsed       | 15            |\n",
            "|    total_timesteps    | 8000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.15         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1599          |\n",
            "|    policy_loss        | 0.00419       |\n",
            "|    reward             | 0.00084316527 |\n",
            "|    std                | 2.08          |\n",
            "|    value_loss         | 6.96e-06      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 504          |\n",
            "|    iterations         | 1700         |\n",
            "|    time_elapsed       | 16           |\n",
            "|    total_timesteps    | 8500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.2         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1699         |\n",
            "|    policy_loss        | 0.0676       |\n",
            "|    reward             | 0.0021790327 |\n",
            "|    std                | 2.18         |\n",
            "|    value_loss         | 0.00117      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 505          |\n",
            "|    iterations         | 1800         |\n",
            "|    time_elapsed       | 17           |\n",
            "|    total_timesteps    | 9000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.24        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1799         |\n",
            "|    policy_loss        | -0.00882     |\n",
            "|    reward             | -0.005190393 |\n",
            "|    std                | 2.28         |\n",
            "|    value_loss         | 1.9e-05      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 508           |\n",
            "|    iterations         | 1900          |\n",
            "|    time_elapsed       | 18            |\n",
            "|    total_timesteps    | 9500          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.29         |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1899          |\n",
            "|    policy_loss        | 0.00101       |\n",
            "|    reward             | -0.0015385523 |\n",
            "|    std                | 2.38          |\n",
            "|    value_loss         | 2.26e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 507          |\n",
            "|    iterations         | 2000         |\n",
            "|    time_elapsed       | 19           |\n",
            "|    total_timesteps    | 10000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.32        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1999         |\n",
            "|    policy_loss        | 0.0136       |\n",
            "|    reward             | -0.006255247 |\n",
            "|    std                | 2.47         |\n",
            "|    value_loss         | 4.9e-05      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 507           |\n",
            "|    iterations         | 2100          |\n",
            "|    time_elapsed       | 20            |\n",
            "|    total_timesteps    | 10500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.36         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2099          |\n",
            "|    policy_loss        | -0.00496      |\n",
            "|    reward             | -0.0034982339 |\n",
            "|    std                | 2.57          |\n",
            "|    value_loss         | 8.36e-06      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 507           |\n",
            "|    iterations         | 2200          |\n",
            "|    time_elapsed       | 21            |\n",
            "|    total_timesteps    | 11000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.39         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2199          |\n",
            "|    policy_loss        | -0.00471      |\n",
            "|    reward             | -0.0031095268 |\n",
            "|    std                | 2.65          |\n",
            "|    value_loss         | 5.77e-06      |\n",
            "-----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 508        |\n",
            "|    iterations         | 2300       |\n",
            "|    time_elapsed       | 22         |\n",
            "|    total_timesteps    | 11500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -2.44      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2299       |\n",
            "|    policy_loss        | 0.00896    |\n",
            "|    reward             | 0.00524664 |\n",
            "|    std                | 2.77       |\n",
            "|    value_loss         | 4.76e-05   |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 507          |\n",
            "|    iterations         | 2400         |\n",
            "|    time_elapsed       | 23           |\n",
            "|    total_timesteps    | 12000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.47        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2399         |\n",
            "|    policy_loss        | 0.0259       |\n",
            "|    reward             | 0.0051570963 |\n",
            "|    std                | 2.85         |\n",
            "|    value_loss         | 0.000163     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 507         |\n",
            "|    iterations         | 2500        |\n",
            "|    time_elapsed       | 24          |\n",
            "|    total_timesteps    | 12500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.49       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2499        |\n",
            "|    policy_loss        | 0.0163      |\n",
            "|    reward             | 0.014449185 |\n",
            "|    std                | 2.92        |\n",
            "|    value_loss         | 0.000196    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 507           |\n",
            "|    iterations         | 2600          |\n",
            "|    time_elapsed       | 25            |\n",
            "|    total_timesteps    | 13000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.51         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2599          |\n",
            "|    policy_loss        | 0.0192        |\n",
            "|    reward             | -0.0014365466 |\n",
            "|    std                | 2.99          |\n",
            "|    value_loss         | 9.32e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 507           |\n",
            "|    iterations         | 2700          |\n",
            "|    time_elapsed       | 26            |\n",
            "|    total_timesteps    | 13500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.55         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 2699          |\n",
            "|    policy_loss        | -0.00823      |\n",
            "|    reward             | 0.00087314344 |\n",
            "|    std                | 3.09          |\n",
            "|    value_loss         | 1.42e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 507          |\n",
            "|    iterations         | 2800         |\n",
            "|    time_elapsed       | 27           |\n",
            "|    total_timesteps    | 14000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.58        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2799         |\n",
            "|    policy_loss        | 0.00299      |\n",
            "|    reward             | 0.0056180325 |\n",
            "|    std                | 3.21         |\n",
            "|    value_loss         | 1.45e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 508         |\n",
            "|    iterations         | 2900        |\n",
            "|    time_elapsed       | 28          |\n",
            "|    total_timesteps    | 14500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.62       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2899        |\n",
            "|    policy_loss        | 0.0155      |\n",
            "|    reward             | 0.003989226 |\n",
            "|    std                | 3.32        |\n",
            "|    value_loss         | 6.82e-05    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 508          |\n",
            "|    iterations         | 3000         |\n",
            "|    time_elapsed       | 29           |\n",
            "|    total_timesteps    | 15000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.66        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2999         |\n",
            "|    policy_loss        | 0.0151       |\n",
            "|    reward             | 0.0048235897 |\n",
            "|    std                | 3.46         |\n",
            "|    value_loss         | 3.94e-05     |\n",
            "----------------------------------------\n",
            "day: 3001, episode: 5\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 8646.84\n",
            "total_reward: -1353.16\n",
            "total_cost: 125.48\n",
            "total_trades: 3001\n",
            "Sharpe: -0.005\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 507          |\n",
            "|    iterations         | 3100         |\n",
            "|    time_elapsed       | 30           |\n",
            "|    total_timesteps    | 15500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.71        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3099         |\n",
            "|    policy_loss        | 0.0729       |\n",
            "|    reward             | 0.0050728456 |\n",
            "|    std                | 3.62         |\n",
            "|    value_loss         | 0.00114      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 507           |\n",
            "|    iterations         | 3200          |\n",
            "|    time_elapsed       | 31            |\n",
            "|    total_timesteps    | 16000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.73         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3199          |\n",
            "|    policy_loss        | 0.0371        |\n",
            "|    reward             | -0.0003653284 |\n",
            "|    std                | 3.72          |\n",
            "|    value_loss         | 0.000241      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 508           |\n",
            "|    iterations         | 3300          |\n",
            "|    time_elapsed       | 32            |\n",
            "|    total_timesteps    | 16500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -2.77         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3299          |\n",
            "|    policy_loss        | -0.0176       |\n",
            "|    reward             | 0.00066482456 |\n",
            "|    std                | 3.85          |\n",
            "|    value_loss         | 6.52e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 507          |\n",
            "|    iterations         | 3400         |\n",
            "|    time_elapsed       | 33           |\n",
            "|    total_timesteps    | 17000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.81        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3399         |\n",
            "|    policy_loss        | 0.0032       |\n",
            "|    reward             | 0.0011060941 |\n",
            "|    std                | 4.02         |\n",
            "|    value_loss         | 2.07e-05     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 508         |\n",
            "|    iterations         | 3500        |\n",
            "|    time_elapsed       | 34          |\n",
            "|    total_timesteps    | 17500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.85       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3499        |\n",
            "|    policy_loss        | 0.00571     |\n",
            "|    reward             | 0.011170308 |\n",
            "|    std                | 4.16        |\n",
            "|    value_loss         | 2.89e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 508         |\n",
            "|    iterations         | 3600        |\n",
            "|    time_elapsed       | 35          |\n",
            "|    total_timesteps    | 18000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -2.9        |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3599        |\n",
            "|    policy_loss        | -0.00537    |\n",
            "|    reward             | -0.00702177 |\n",
            "|    std                | 4.42        |\n",
            "|    value_loss         | 1.01e-05    |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 508            |\n",
            "|    iterations         | 3700           |\n",
            "|    time_elapsed       | 36             |\n",
            "|    total_timesteps    | 18500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -2.93          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 3699           |\n",
            "|    policy_loss        | 0.0597         |\n",
            "|    reward             | -0.00033205433 |\n",
            "|    std                | 4.51           |\n",
            "|    value_loss         | 0.000438       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 508          |\n",
            "|    iterations         | 3800         |\n",
            "|    time_elapsed       | 37           |\n",
            "|    total_timesteps    | 19000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -2.96        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3799         |\n",
            "|    policy_loss        | 0.0213       |\n",
            "|    reward             | -0.001011324 |\n",
            "|    std                | 4.67         |\n",
            "|    value_loss         | 0.000112     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 508           |\n",
            "|    iterations         | 3900          |\n",
            "|    time_elapsed       | 38            |\n",
            "|    total_timesteps    | 19500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3            |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3899          |\n",
            "|    policy_loss        | -0.0357       |\n",
            "|    reward             | -0.0036746718 |\n",
            "|    std                | 4.86          |\n",
            "|    value_loss         | 0.000227      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 508           |\n",
            "|    iterations         | 4000          |\n",
            "|    time_elapsed       | 39            |\n",
            "|    total_timesteps    | 20000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.04         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3999          |\n",
            "|    policy_loss        | -0.0609       |\n",
            "|    reward             | -0.0012783291 |\n",
            "|    std                | 5.05          |\n",
            "|    value_loss         | 0.00061       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 509          |\n",
            "|    iterations         | 4100         |\n",
            "|    time_elapsed       | 40           |\n",
            "|    total_timesteps    | 20500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.08        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4099         |\n",
            "|    policy_loss        | -0.0338      |\n",
            "|    reward             | -0.004501221 |\n",
            "|    std                | 5.26         |\n",
            "|    value_loss         | 0.000208     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 508          |\n",
            "|    iterations         | 4200         |\n",
            "|    time_elapsed       | 41           |\n",
            "|    total_timesteps    | 21000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.11        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4199         |\n",
            "|    policy_loss        | -0.0172      |\n",
            "|    reward             | 0.0054870937 |\n",
            "|    std                | 5.45         |\n",
            "|    value_loss         | 4.85e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 508          |\n",
            "|    iterations         | 4300         |\n",
            "|    time_elapsed       | 42           |\n",
            "|    total_timesteps    | 21500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.14        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4299         |\n",
            "|    policy_loss        | -0.00908     |\n",
            "|    reward             | 0.0037827198 |\n",
            "|    std                | 5.61         |\n",
            "|    value_loss         | 1.17e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 508          |\n",
            "|    iterations         | 4400         |\n",
            "|    time_elapsed       | 43           |\n",
            "|    total_timesteps    | 22000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.17        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4399         |\n",
            "|    policy_loss        | 0.0322       |\n",
            "|    reward             | 0.0037555876 |\n",
            "|    std                | 5.74         |\n",
            "|    value_loss         | 0.000128     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 508         |\n",
            "|    iterations         | 4500        |\n",
            "|    time_elapsed       | 44          |\n",
            "|    total_timesteps    | 22500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.2        |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4499        |\n",
            "|    policy_loss        | -0.0958     |\n",
            "|    reward             | 0.004038321 |\n",
            "|    std                | 5.95        |\n",
            "|    value_loss         | 0.00133     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 508         |\n",
            "|    iterations         | 4600        |\n",
            "|    time_elapsed       | 45          |\n",
            "|    total_timesteps    | 23000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.24       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4599        |\n",
            "|    policy_loss        | -0.0315     |\n",
            "|    reward             | 0.004164041 |\n",
            "|    std                | 6.16        |\n",
            "|    value_loss         | 0.000137    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 508          |\n",
            "|    iterations         | 4700         |\n",
            "|    time_elapsed       | 46           |\n",
            "|    total_timesteps    | 23500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.28        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4699         |\n",
            "|    policy_loss        | -0.0417      |\n",
            "|    reward             | 0.0023879698 |\n",
            "|    std                | 6.44         |\n",
            "|    value_loss         | 0.000159     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 508           |\n",
            "|    iterations         | 4800          |\n",
            "|    time_elapsed       | 47            |\n",
            "|    total_timesteps    | 24000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.32         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 4799          |\n",
            "|    policy_loss        | -0.0763       |\n",
            "|    reward             | -0.0030233904 |\n",
            "|    std                | 6.67          |\n",
            "|    value_loss         | 0.000837      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 508          |\n",
            "|    iterations         | 4900         |\n",
            "|    time_elapsed       | 48           |\n",
            "|    total_timesteps    | 24500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.35        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4899         |\n",
            "|    policy_loss        | 0.0151       |\n",
            "|    reward             | 0.0076982714 |\n",
            "|    std                | 6.88         |\n",
            "|    value_loss         | 7.33e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 508          |\n",
            "|    iterations         | 5000         |\n",
            "|    time_elapsed       | 49           |\n",
            "|    total_timesteps    | 25000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.37        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4999         |\n",
            "|    policy_loss        | -0.0185      |\n",
            "|    reward             | 0.0046325577 |\n",
            "|    std                | 7.05         |\n",
            "|    value_loss         | 3.4e-05      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 508          |\n",
            "|    iterations         | 5100         |\n",
            "|    time_elapsed       | 50           |\n",
            "|    total_timesteps    | 25500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.41        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5099         |\n",
            "|    policy_loss        | -0.106       |\n",
            "|    reward             | -0.004267646 |\n",
            "|    std                | 7.29         |\n",
            "|    value_loss         | 0.000786     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 508          |\n",
            "|    iterations         | 5200         |\n",
            "|    time_elapsed       | 51           |\n",
            "|    total_timesteps    | 26000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.44        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5199         |\n",
            "|    policy_loss        | -0.00983     |\n",
            "|    reward             | 0.0073407213 |\n",
            "|    std                | 7.56         |\n",
            "|    value_loss         | 4.38e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 508          |\n",
            "|    iterations         | 5300         |\n",
            "|    time_elapsed       | 52           |\n",
            "|    total_timesteps    | 26500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.48        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5299         |\n",
            "|    policy_loss        | -0.00774     |\n",
            "|    reward             | -0.007498621 |\n",
            "|    std                | 7.88         |\n",
            "|    value_loss         | 1.87e-05     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 508          |\n",
            "|    iterations         | 5400         |\n",
            "|    time_elapsed       | 53           |\n",
            "|    total_timesteps    | 27000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.52        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5399         |\n",
            "|    policy_loss        | -0.146       |\n",
            "|    reward             | 0.0067025702 |\n",
            "|    std                | 8.17         |\n",
            "|    value_loss         | 0.00219      |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 509        |\n",
            "|    iterations         | 5500       |\n",
            "|    time_elapsed       | 53         |\n",
            "|    total_timesteps    | 27500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -3.56      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5499       |\n",
            "|    policy_loss        | 0.00515    |\n",
            "|    reward             | 0.02194526 |\n",
            "|    std                | 8.5        |\n",
            "|    value_loss         | 0.000201   |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 508        |\n",
            "|    iterations         | 5600       |\n",
            "|    time_elapsed       | 55         |\n",
            "|    total_timesteps    | 28000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -3.6       |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5599       |\n",
            "|    policy_loss        | 0.0462     |\n",
            "|    reward             | 0.00473679 |\n",
            "|    std                | 8.83       |\n",
            "|    value_loss         | 0.000162   |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 509           |\n",
            "|    iterations         | 5700          |\n",
            "|    time_elapsed       | 55            |\n",
            "|    total_timesteps    | 28500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.63         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5699          |\n",
            "|    policy_loss        | -0.00487      |\n",
            "|    reward             | -0.0039768987 |\n",
            "|    std                | 9.08          |\n",
            "|    value_loss         | 4.73e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 508           |\n",
            "|    iterations         | 5800          |\n",
            "|    time_elapsed       | 56            |\n",
            "|    total_timesteps    | 29000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.66         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5799          |\n",
            "|    policy_loss        | 0.015         |\n",
            "|    reward             | 0.00025089367 |\n",
            "|    std                | 9.37          |\n",
            "|    value_loss         | 4.75e-05      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 508           |\n",
            "|    iterations         | 5900          |\n",
            "|    time_elapsed       | 57            |\n",
            "|    total_timesteps    | 29500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.69         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5899          |\n",
            "|    policy_loss        | -0.0242       |\n",
            "|    reward             | -0.0040264875 |\n",
            "|    std                | 9.74          |\n",
            "|    value_loss         | 5.23e-05      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 508          |\n",
            "|    iterations         | 6000         |\n",
            "|    time_elapsed       | 58           |\n",
            "|    total_timesteps    | 30000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.72        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5999         |\n",
            "|    policy_loss        | 0.0464       |\n",
            "|    reward             | -0.002638258 |\n",
            "|    std                | 9.99         |\n",
            "|    value_loss         | 0.000328     |\n",
            "----------------------------------------\n",
            "day: 3001, episode: 10\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 6894.98\n",
            "total_reward: -3105.02\n",
            "total_cost: 108.91\n",
            "total_trades: 3001\n",
            "Sharpe: -0.133\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 508          |\n",
            "|    iterations         | 6100         |\n",
            "|    time_elapsed       | 59           |\n",
            "|    total_timesteps    | 30500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.74        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6099         |\n",
            "|    policy_loss        | -0.0585      |\n",
            "|    reward             | 0.0029697414 |\n",
            "|    std                | 10.2         |\n",
            "|    value_loss         | 0.000467     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 508         |\n",
            "|    iterations         | 6200        |\n",
            "|    time_elapsed       | 60          |\n",
            "|    total_timesteps    | 31000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.78       |\n",
            "|    explained_variance | -2.38e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6199        |\n",
            "|    policy_loss        | 0.0168      |\n",
            "|    reward             | 0.006802716 |\n",
            "|    std                | 10.6        |\n",
            "|    value_loss         | 5.07e-05    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 507           |\n",
            "|    iterations         | 6300          |\n",
            "|    time_elapsed       | 62            |\n",
            "|    total_timesteps    | 31500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.81         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6299          |\n",
            "|    policy_loss        | 0.0787        |\n",
            "|    reward             | -0.0071646944 |\n",
            "|    std                | 11            |\n",
            "|    value_loss         | 0.00059       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 507           |\n",
            "|    iterations         | 6400          |\n",
            "|    time_elapsed       | 63            |\n",
            "|    total_timesteps    | 32000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.85         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6399          |\n",
            "|    policy_loss        | 0.129         |\n",
            "|    reward             | -0.0055652284 |\n",
            "|    std                | 11.3          |\n",
            "|    value_loss         | 0.00135       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 507          |\n",
            "|    iterations         | 6500         |\n",
            "|    time_elapsed       | 64           |\n",
            "|    total_timesteps    | 32500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.88        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6499         |\n",
            "|    policy_loss        | 0.0425       |\n",
            "|    reward             | -0.009995769 |\n",
            "|    std                | 11.7         |\n",
            "|    value_loss         | 0.000307     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 508         |\n",
            "|    iterations         | 6600        |\n",
            "|    time_elapsed       | 64          |\n",
            "|    total_timesteps    | 33000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.91       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6599        |\n",
            "|    policy_loss        | 0.128       |\n",
            "|    reward             | 0.014269571 |\n",
            "|    std                | 12.1        |\n",
            "|    value_loss         | 0.00126     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 508         |\n",
            "|    iterations         | 6700        |\n",
            "|    time_elapsed       | 65          |\n",
            "|    total_timesteps    | 33500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.94       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6699        |\n",
            "|    policy_loss        | -0.158      |\n",
            "|    reward             | 0.008360616 |\n",
            "|    std                | 12.4        |\n",
            "|    value_loss         | 0.00174     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 508           |\n",
            "|    iterations         | 6800          |\n",
            "|    time_elapsed       | 66            |\n",
            "|    total_timesteps    | 34000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -3.95         |\n",
            "|    explained_variance | 1.19e-07      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 6799          |\n",
            "|    policy_loss        | 0.0573        |\n",
            "|    reward             | -0.0063726595 |\n",
            "|    std                | 12.6          |\n",
            "|    value_loss         | 0.000193      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 507          |\n",
            "|    iterations         | 6900         |\n",
            "|    time_elapsed       | 67           |\n",
            "|    total_timesteps    | 34500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -3.97        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 6899         |\n",
            "|    policy_loss        | 0.196        |\n",
            "|    reward             | -0.042088583 |\n",
            "|    std                | 12.8         |\n",
            "|    value_loss         | 0.00296      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 508         |\n",
            "|    iterations         | 7000        |\n",
            "|    time_elapsed       | 68          |\n",
            "|    total_timesteps    | 35000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -3.99       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 6999        |\n",
            "|    policy_loss        | 0.141       |\n",
            "|    reward             | 0.023618942 |\n",
            "|    std                | 13.1        |\n",
            "|    value_loss         | 0.00194     |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 507            |\n",
            "|    iterations         | 7100           |\n",
            "|    time_elapsed       | 69             |\n",
            "|    total_timesteps    | 35500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -4.02          |\n",
            "|    explained_variance | -1.19e-07      |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 7099           |\n",
            "|    policy_loss        | 0.225          |\n",
            "|    reward             | -0.00035913254 |\n",
            "|    std                | 13.4           |\n",
            "|    value_loss         | 0.00278        |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 507         |\n",
            "|    iterations         | 7200        |\n",
            "|    time_elapsed       | 70          |\n",
            "|    total_timesteps    | 36000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.02       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7199        |\n",
            "|    policy_loss        | 0.17        |\n",
            "|    reward             | -0.07577513 |\n",
            "|    std                | 13.5        |\n",
            "|    value_loss         | 0.00246     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 507         |\n",
            "|    iterations         | 7300        |\n",
            "|    time_elapsed       | 71          |\n",
            "|    total_timesteps    | 36500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.04       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7299        |\n",
            "|    policy_loss        | 0.0458      |\n",
            "|    reward             | 0.012649753 |\n",
            "|    std                | 13.7        |\n",
            "|    value_loss         | 0.000164    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 507           |\n",
            "|    iterations         | 7400          |\n",
            "|    time_elapsed       | 72            |\n",
            "|    total_timesteps    | 37000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.05         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7399          |\n",
            "|    policy_loss        | -0.0815       |\n",
            "|    reward             | -0.0011358224 |\n",
            "|    std                | 13.9          |\n",
            "|    value_loss         | 0.000475      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 507           |\n",
            "|    iterations         | 7500          |\n",
            "|    time_elapsed       | 73            |\n",
            "|    total_timesteps    | 37500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.07         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7499          |\n",
            "|    policy_loss        | -0.032        |\n",
            "|    reward             | -0.0021712936 |\n",
            "|    std                | 14.2          |\n",
            "|    value_loss         | 0.000453      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 507          |\n",
            "|    iterations         | 7600         |\n",
            "|    time_elapsed       | 74           |\n",
            "|    total_timesteps    | 38000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.09        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7599         |\n",
            "|    policy_loss        | -0.0266      |\n",
            "|    reward             | -0.009273669 |\n",
            "|    std                | 14.4         |\n",
            "|    value_loss         | 7.97e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 507           |\n",
            "|    iterations         | 7700          |\n",
            "|    time_elapsed       | 75            |\n",
            "|    total_timesteps    | 38500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.12         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7699          |\n",
            "|    policy_loss        | 0.00414       |\n",
            "|    reward             | -0.0053341375 |\n",
            "|    std                | 14.9          |\n",
            "|    value_loss         | 6.32e-06      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 507          |\n",
            "|    iterations         | 7800         |\n",
            "|    time_elapsed       | 76           |\n",
            "|    total_timesteps    | 39000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.14        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 7799         |\n",
            "|    policy_loss        | 0.132        |\n",
            "|    reward             | 0.0017843748 |\n",
            "|    std                | 15.3         |\n",
            "|    value_loss         | 0.000974     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 507         |\n",
            "|    iterations         | 7900        |\n",
            "|    time_elapsed       | 77          |\n",
            "|    total_timesteps    | 39500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.18       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 7899        |\n",
            "|    policy_loss        | -0.0435     |\n",
            "|    reward             | 0.002641478 |\n",
            "|    std                | 15.8        |\n",
            "|    value_loss         | 0.000195    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 507           |\n",
            "|    iterations         | 8000          |\n",
            "|    time_elapsed       | 78            |\n",
            "|    total_timesteps    | 40000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.21         |\n",
            "|    explained_variance | 5.96e-08      |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 7999          |\n",
            "|    policy_loss        | 0.0148        |\n",
            "|    reward             | -0.0078051346 |\n",
            "|    std                | 16.2          |\n",
            "|    value_loss         | 0.000186      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 507           |\n",
            "|    iterations         | 8100          |\n",
            "|    time_elapsed       | 79            |\n",
            "|    total_timesteps    | 40500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.23         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8099          |\n",
            "|    policy_loss        | 0.0325        |\n",
            "|    reward             | -0.0003432346 |\n",
            "|    std                | 16.7          |\n",
            "|    value_loss         | 0.000911      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 507         |\n",
            "|    iterations         | 8200        |\n",
            "|    time_elapsed       | 80          |\n",
            "|    total_timesteps    | 41000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.27       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8199        |\n",
            "|    policy_loss        | -0.0139     |\n",
            "|    reward             | 0.004902681 |\n",
            "|    std                | 17.4        |\n",
            "|    value_loss         | 2.68e-05    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 507           |\n",
            "|    iterations         | 8300          |\n",
            "|    time_elapsed       | 81            |\n",
            "|    total_timesteps    | 41500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.32         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8299          |\n",
            "|    policy_loss        | 0.00944       |\n",
            "|    reward             | -0.0030988124 |\n",
            "|    std                | 18.2          |\n",
            "|    value_loss         | 1.59e-05      |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 506         |\n",
            "|    iterations         | 8400        |\n",
            "|    time_elapsed       | 82          |\n",
            "|    total_timesteps    | 42000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.36       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8399        |\n",
            "|    policy_loss        | 0.0214      |\n",
            "|    reward             | 0.009370237 |\n",
            "|    std                | 19          |\n",
            "|    value_loss         | 5.93e-05    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 506           |\n",
            "|    iterations         | 8500          |\n",
            "|    time_elapsed       | 83            |\n",
            "|    total_timesteps    | 42500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.39         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 8499          |\n",
            "|    policy_loss        | -0.153        |\n",
            "|    reward             | -0.0030265483 |\n",
            "|    std                | 19.5          |\n",
            "|    value_loss         | 0.00171       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 506         |\n",
            "|    iterations         | 8600        |\n",
            "|    time_elapsed       | 84          |\n",
            "|    total_timesteps    | 43000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.41       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8599        |\n",
            "|    policy_loss        | 0.0757      |\n",
            "|    reward             | 0.001746296 |\n",
            "|    std                | 19.9        |\n",
            "|    value_loss         | 0.000621    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 506         |\n",
            "|    iterations         | 8700        |\n",
            "|    time_elapsed       | 85          |\n",
            "|    total_timesteps    | 43500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.43       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8699        |\n",
            "|    policy_loss        | 0.236       |\n",
            "|    reward             | 0.020979805 |\n",
            "|    std                | 20.3        |\n",
            "|    value_loss         | 0.00406     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 506         |\n",
            "|    iterations         | 8800        |\n",
            "|    time_elapsed       | 86          |\n",
            "|    total_timesteps    | 44000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.45       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8799        |\n",
            "|    policy_loss        | 0.018       |\n",
            "|    reward             | 0.049808882 |\n",
            "|    std                | 20.8        |\n",
            "|    value_loss         | 8.6e-05     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 505         |\n",
            "|    iterations         | 8900        |\n",
            "|    time_elapsed       | 88          |\n",
            "|    total_timesteps    | 44500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.48       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8899        |\n",
            "|    policy_loss        | 0.00714     |\n",
            "|    reward             | 0.024521854 |\n",
            "|    std                | 21.4        |\n",
            "|    value_loss         | 1.49e-05    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 504         |\n",
            "|    iterations         | 9000        |\n",
            "|    time_elapsed       | 89          |\n",
            "|    total_timesteps    | 45000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.51       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 8999        |\n",
            "|    policy_loss        | -0.00935    |\n",
            "|    reward             | 0.004347266 |\n",
            "|    std                | 22.1        |\n",
            "|    value_loss         | 4.09e-05    |\n",
            "---------------------------------------\n",
            "day: 3001, episode: 15\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 9515.53\n",
            "total_reward: -484.47\n",
            "total_cost: 105.99\n",
            "total_trades: 3001\n",
            "Sharpe: 0.081\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 504         |\n",
            "|    iterations         | 9100        |\n",
            "|    time_elapsed       | 90          |\n",
            "|    total_timesteps    | 45500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.54       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9099        |\n",
            "|    policy_loss        | -0.167      |\n",
            "|    reward             | 0.014284625 |\n",
            "|    std                | 22.7        |\n",
            "|    value_loss         | 0.00157     |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 504          |\n",
            "|    iterations         | 9200         |\n",
            "|    time_elapsed       | 91           |\n",
            "|    total_timesteps    | 46000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.56        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9199         |\n",
            "|    policy_loss        | 0.176        |\n",
            "|    reward             | -0.007420105 |\n",
            "|    std                | 23.2         |\n",
            "|    value_loss         | 0.00176      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 503          |\n",
            "|    iterations         | 9300         |\n",
            "|    time_elapsed       | 92           |\n",
            "|    total_timesteps    | 46500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.58        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9299         |\n",
            "|    policy_loss        | -0.0705      |\n",
            "|    reward             | 0.0024335813 |\n",
            "|    std                | 23.6         |\n",
            "|    value_loss         | 0.000427     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 503          |\n",
            "|    iterations         | 9400         |\n",
            "|    time_elapsed       | 93           |\n",
            "|    total_timesteps    | 47000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.61        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9399         |\n",
            "|    policy_loss        | 0.0155       |\n",
            "|    reward             | -0.009013929 |\n",
            "|    std                | 24.4         |\n",
            "|    value_loss         | 0.000326     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 503          |\n",
            "|    iterations         | 9500         |\n",
            "|    time_elapsed       | 94           |\n",
            "|    total_timesteps    | 47500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.63        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9499         |\n",
            "|    policy_loss        | -0.0547      |\n",
            "|    reward             | -0.002255734 |\n",
            "|    std                | 24.9         |\n",
            "|    value_loss         | 0.000123     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 501         |\n",
            "|    iterations         | 9600        |\n",
            "|    time_elapsed       | 95          |\n",
            "|    total_timesteps    | 48000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.67       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 9599        |\n",
            "|    policy_loss        | 0.0447      |\n",
            "|    reward             | 0.013437809 |\n",
            "|    std                | 25.9        |\n",
            "|    value_loss         | 0.000297    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 501           |\n",
            "|    iterations         | 9700          |\n",
            "|    time_elapsed       | 96            |\n",
            "|    total_timesteps    | 48500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.7          |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 9699          |\n",
            "|    policy_loss        | 8.34e-06      |\n",
            "|    reward             | -0.0019986094 |\n",
            "|    std                | 26.7          |\n",
            "|    value_loss         | 0.000359      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 501            |\n",
            "|    iterations         | 9800           |\n",
            "|    time_elapsed       | 97             |\n",
            "|    total_timesteps    | 49000          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -4.73          |\n",
            "|    explained_variance | 0              |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 9799           |\n",
            "|    policy_loss        | -0.0856        |\n",
            "|    reward             | -0.00055311114 |\n",
            "|    std                | 27.2           |\n",
            "|    value_loss         | 0.000585       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 501          |\n",
            "|    iterations         | 9900         |\n",
            "|    time_elapsed       | 98           |\n",
            "|    total_timesteps    | 49500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.74        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9899         |\n",
            "|    policy_loss        | -0.0588      |\n",
            "|    reward             | -0.019739125 |\n",
            "|    std                | 27.8         |\n",
            "|    value_loss         | 0.000204     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 501          |\n",
            "|    iterations         | 10000        |\n",
            "|    time_elapsed       | 99           |\n",
            "|    total_timesteps    | 50000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.77        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 9999         |\n",
            "|    policy_loss        | 0.105        |\n",
            "|    reward             | 0.0068036327 |\n",
            "|    std                | 28.7         |\n",
            "|    value_loss         | 0.000498     |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 502          |\n",
            "|    iterations         | 10100        |\n",
            "|    time_elapsed       | 100          |\n",
            "|    total_timesteps    | 50500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.8         |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10099        |\n",
            "|    policy_loss        | -0.025       |\n",
            "|    reward             | 0.0019058718 |\n",
            "|    std                | 29.4         |\n",
            "|    value_loss         | 3.65e-05     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 502           |\n",
            "|    iterations         | 10200         |\n",
            "|    time_elapsed       | 101           |\n",
            "|    total_timesteps    | 51000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.82         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10199         |\n",
            "|    policy_loss        | 0.0747        |\n",
            "|    reward             | 0.00017962421 |\n",
            "|    std                | 29.9          |\n",
            "|    value_loss         | 0.000379      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 501           |\n",
            "|    iterations         | 10300         |\n",
            "|    time_elapsed       | 102           |\n",
            "|    total_timesteps    | 51500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -4.83         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10299         |\n",
            "|    policy_loss        | 0.166         |\n",
            "|    reward             | -0.0046173446 |\n",
            "|    std                | 30.3          |\n",
            "|    value_loss         | 0.00131       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 501          |\n",
            "|    iterations         | 10400        |\n",
            "|    time_elapsed       | 103          |\n",
            "|    total_timesteps    | 52000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.85        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10399        |\n",
            "|    policy_loss        | -0.178       |\n",
            "|    reward             | 0.0064160046 |\n",
            "|    std                | 30.9         |\n",
            "|    value_loss         | 0.0013       |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 500        |\n",
            "|    iterations         | 10500      |\n",
            "|    time_elapsed       | 104        |\n",
            "|    total_timesteps    | 52500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.88      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10499      |\n",
            "|    policy_loss        | 0.00494    |\n",
            "|    reward             | 0.09903711 |\n",
            "|    std                | 31.7       |\n",
            "|    value_loss         | 2.18e-05   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 500         |\n",
            "|    iterations         | 10600       |\n",
            "|    time_elapsed       | 105         |\n",
            "|    total_timesteps    | 53000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.9        |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10599       |\n",
            "|    policy_loss        | 0.0163      |\n",
            "|    reward             | 0.006028858 |\n",
            "|    std                | 32.5        |\n",
            "|    value_loss         | 2.85e-05    |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 500        |\n",
            "|    iterations         | 10700      |\n",
            "|    time_elapsed       | 106        |\n",
            "|    total_timesteps    | 53500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -4.92      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 10699      |\n",
            "|    policy_loss        | 0.00575    |\n",
            "|    reward             | 0.00437999 |\n",
            "|    std                | 33.3       |\n",
            "|    value_loss         | 5.95e-06   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 500         |\n",
            "|    iterations         | 10800       |\n",
            "|    time_elapsed       | 107         |\n",
            "|    total_timesteps    | 54000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -4.95       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 10799       |\n",
            "|    policy_loss        | 0.097       |\n",
            "|    reward             | -0.02036069 |\n",
            "|    std                | 34.2        |\n",
            "|    value_loss         | 0.000439    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 501          |\n",
            "|    iterations         | 10900        |\n",
            "|    time_elapsed       | 108          |\n",
            "|    total_timesteps    | 54500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -4.99        |\n",
            "|    explained_variance | 1.79e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 10899        |\n",
            "|    policy_loss        | 0.0699       |\n",
            "|    reward             | 0.0013067168 |\n",
            "|    std                | 35.5         |\n",
            "|    value_loss         | 0.000288     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 501           |\n",
            "|    iterations         | 11000         |\n",
            "|    time_elapsed       | 109           |\n",
            "|    total_timesteps    | 55000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -5            |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 10999         |\n",
            "|    policy_loss        | 0.0289        |\n",
            "|    reward             | -0.0028405434 |\n",
            "|    std                | 36.1          |\n",
            "|    value_loss         | 3.7e-05       |\n",
            "-----------------------------------------\n",
            "======A2C Validation from:  2022-03-04 to  2022-04-04\n",
            "A2C Sharpe Ratio:  -0.7042913665144538\n",
            "======Best Model Retraining from:  2010-04-01 to  2022-04-04\n",
            "======Trading from:  2022-04-04 to  2022-05-04\n",
            "[[ 1.43574346e+04  3.60381432e+01 -1.85000000e+02  8.65784585e-01\n",
            "   3.77322044e+01  3.14602470e+01  5.89183693e+01  1.06077927e+02\n",
            "   1.31321125e+01  3.40602112e+01  3.35991249e+01]]\n",
            "Ensemble Strategy took:  28.31744405825933  minutes\n"
          ]
        }
      ],
      "source": [
        "# df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n",
        "#                                                  PPO_model_kwargs,\n",
        "#                                                  DDPG_model_kwargs,\n",
        "#                                                  timesteps_dict)\n",
        "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n",
        "                                                 None,\n",
        "                                                 None,\n",
        "                                                 timesteps_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "-0qd8acMtj1f",
        "outputId": "b5d9cb94-51a9-4569-a9a8-7e18f1139f4e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iter</th>\n",
              "      <th>Val Start</th>\n",
              "      <th>Val End</th>\n",
              "      <th>Model Used</th>\n",
              "      <th>A2C Sharpe</th>\n",
              "      <th>PPO Sharpe</th>\n",
              "      <th>DDPG Sharpe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>42</td>\n",
              "      <td>2021-01-04</td>\n",
              "      <td>2021-02-03</td>\n",
              "      <td>A2C</td>\n",
              "      <td>-0.101277</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>63</td>\n",
              "      <td>2021-02-03</td>\n",
              "      <td>2021-03-05</td>\n",
              "      <td>A2C</td>\n",
              "      <td>0.225815</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84</td>\n",
              "      <td>2021-03-05</td>\n",
              "      <td>2021-04-06</td>\n",
              "      <td>A2C</td>\n",
              "      <td>-0.537749</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>105</td>\n",
              "      <td>2021-04-06</td>\n",
              "      <td>2021-05-05</td>\n",
              "      <td>A2C</td>\n",
              "      <td>-0.152815</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>126</td>\n",
              "      <td>2021-05-05</td>\n",
              "      <td>2021-06-04</td>\n",
              "      <td>A2C</td>\n",
              "      <td>-0.039902</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>147</td>\n",
              "      <td>2021-06-04</td>\n",
              "      <td>2021-07-06</td>\n",
              "      <td>A2C</td>\n",
              "      <td>0.316111</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>168</td>\n",
              "      <td>2021-07-06</td>\n",
              "      <td>2021-08-04</td>\n",
              "      <td>A2C</td>\n",
              "      <td>-0.381808</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>189</td>\n",
              "      <td>2021-08-04</td>\n",
              "      <td>2021-09-02</td>\n",
              "      <td>A2C</td>\n",
              "      <td>-0.551394</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>210</td>\n",
              "      <td>2021-09-02</td>\n",
              "      <td>2021-10-04</td>\n",
              "      <td>A2C</td>\n",
              "      <td>0.207656</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>231</td>\n",
              "      <td>2021-10-04</td>\n",
              "      <td>2021-11-02</td>\n",
              "      <td>A2C</td>\n",
              "      <td>-0.360115</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>252</td>\n",
              "      <td>2021-11-02</td>\n",
              "      <td>2021-12-02</td>\n",
              "      <td>A2C</td>\n",
              "      <td>0.078287</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>273</td>\n",
              "      <td>2021-12-02</td>\n",
              "      <td>2022-01-03</td>\n",
              "      <td>A2C</td>\n",
              "      <td>-0.769806</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>294</td>\n",
              "      <td>2022-01-03</td>\n",
              "      <td>2022-02-02</td>\n",
              "      <td>A2C</td>\n",
              "      <td>0.07487</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>315</td>\n",
              "      <td>2022-02-02</td>\n",
              "      <td>2022-03-04</td>\n",
              "      <td>A2C</td>\n",
              "      <td>0.038665</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>336</td>\n",
              "      <td>2022-03-04</td>\n",
              "      <td>2022-04-04</td>\n",
              "      <td>A2C</td>\n",
              "      <td>-0.704291</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Iter   Val Start     Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n",
              "0    42  2021-01-04  2021-02-03        A2C  -0.101277          0           0\n",
              "1    63  2021-02-03  2021-03-05        A2C   0.225815          0           0\n",
              "2    84  2021-03-05  2021-04-06        A2C  -0.537749          0           0\n",
              "3   105  2021-04-06  2021-05-05        A2C  -0.152815          0           0\n",
              "4   126  2021-05-05  2021-06-04        A2C  -0.039902          0           0\n",
              "5   147  2021-06-04  2021-07-06        A2C   0.316111          0           0\n",
              "6   168  2021-07-06  2021-08-04        A2C  -0.381808          0           0\n",
              "7   189  2021-08-04  2021-09-02        A2C  -0.551394          0           0\n",
              "8   210  2021-09-02  2021-10-04        A2C   0.207656          0           0\n",
              "9   231  2021-10-04  2021-11-02        A2C  -0.360115          0           0\n",
              "10  252  2021-11-02  2021-12-02        A2C   0.078287          0           0\n",
              "11  273  2021-12-02  2022-01-03        A2C  -0.769806          0           0\n",
              "12  294  2022-01-03  2022-02-02        A2C    0.07487          0           0\n",
              "13  315  2022-02-02  2022-03-04        A2C   0.038665          0           0\n",
              "14  336  2022-03-04  2022-04-04        A2C  -0.704291          0           0"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6vvNSC6h1jZ"
      },
      "source": [
        "<a id='6'></a>\n",
        "# Part 7: Backtest Our Strategy\n",
        "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "X4JKB--8tj1g"
      },
      "outputs": [],
      "source": [
        "unique_trade_date = processed[(processed.date > TEST_START_DATE)&(processed.date <= TEST_END_DATE)].date.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9mKF7GGtj1g",
        "outputId": "8b89807b-ff71-4902-dd45-1f9111788cbb",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sharpe Ratio:  -0.757568743876359\n"
          ]
        }
      ],
      "source": [
        "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\n",
        "\n",
        "df_account_value=pd.DataFrame()\n",
        "for i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n",
        "    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n",
        "    df_account_value = df_account_value.append(temp,ignore_index=True)\n",
        "sharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\n",
        "print('Sharpe Ratio: ',sharpe)\n",
        "df_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oyosyW7_tj1g",
        "outputId": "d2dc62c2-e2a0-48fc-8183-0399d1b27f53"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>account_value</th>\n",
              "      <th>date</th>\n",
              "      <th>daily_return</th>\n",
              "      <th>datadate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000.000000</td>\n",
              "      <td>2021-02-03</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2021-02-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9994.768643</td>\n",
              "      <td>2021-02-04</td>\n",
              "      <td>-0.000523</td>\n",
              "      <td>2021-02-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9989.185621</td>\n",
              "      <td>2021-02-05</td>\n",
              "      <td>-0.000559</td>\n",
              "      <td>2021-02-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9938.964265</td>\n",
              "      <td>2021-02-08</td>\n",
              "      <td>-0.005028</td>\n",
              "      <td>2021-02-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9894.935760</td>\n",
              "      <td>2021-02-09</td>\n",
              "      <td>-0.004430</td>\n",
              "      <td>2021-02-09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   account_value        date  daily_return    datadate\n",
              "0   10000.000000  2021-02-03           NaN  2021-02-03\n",
              "1    9994.768643  2021-02-04     -0.000523  2021-02-04\n",
              "2    9989.185621  2021-02-05     -0.000559  2021-02-05\n",
              "3    9938.964265  2021-02-08     -0.005028  2021-02-08\n",
              "4    9894.935760  2021-02-09     -0.004430  2021-02-09"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_account_value.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "wLsRdw2Ctj1h",
        "outputId": "9a874df9-2c5f-423c-8fd2-8966aab63fc0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "df_account_value.account_value.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr2zX7ZxNyFQ"
      },
      "source": [
        "<a id='6.1'></a>\n",
        "## 7.1 BackTestStats\n",
        "pass in df_account_value, this information is stored in env class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nzkr9yv-AdV_",
        "outputId": "b419a565-8c15-47d8-f66c-00f81c3c526d",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============Get Backtest Results===========\n",
            "Annual return         -0.121146\n",
            "Cumulative returns    -0.149065\n",
            "Annual volatility      0.155079\n",
            "Sharpe ratio          -0.757569\n",
            "Calmar ratio          -0.465754\n",
            "Stability              0.884834\n",
            "Max drawdown          -0.260106\n",
            "Omega ratio            0.875633\n",
            "Sortino ratio         -0.994571\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             0.845027\n",
            "Daily value at risk   -0.020004\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(\"==============Get Backtest Results===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiHhM1YkoCel",
        "outputId": "903ef035-f9f4-4678-d18a-1516254eaf3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============Get Baseline Stats===========\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (314, 8)\n",
            "Annual return          0.067590\n",
            "Cumulative returns     0.084907\n",
            "Annual volatility      0.158076\n",
            "Sharpe ratio           0.494077\n",
            "Calmar ratio           0.487786\n",
            "Stability              0.503320\n",
            "Max drawdown          -0.138564\n",
            "Omega ratio            1.086194\n",
            "Sortino ratio          0.686099\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             0.871518\n",
            "Daily value at risk   -0.019606\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "#baseline stats\n",
        "print(\"==============Get Baseline Stats===========\")\n",
        "baseline_df = get_baseline(\n",
        "        ticker=\"^GSPC\", \n",
        "        start = df_account_value.loc[0,'date'],\n",
        "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
        "\n",
        "stats = backtest_stats(baseline_df, value_col_name = 'close')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U6Suru3h1jc"
      },
      "source": [
        "<a id='6.2'></a>\n",
        "## 7.2 BackTestPlot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HggausPRoCem",
        "outputId": "e61a64e0-58ed-4490-b19a-78bd4f76e666"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============Compare to DJIA===========\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (314, 8)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2021-02-03</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2022-05-03</td></tr>\n",
              "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>15</td></tr>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Backtest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Annual return</th>\n",
              "      <td>-12.115%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cumulative returns</th>\n",
              "      <td>-14.907%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Annual volatility</th>\n",
              "      <td>15.508%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sharpe ratio</th>\n",
              "      <td>-0.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Calmar ratio</th>\n",
              "      <td>-0.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stability</th>\n",
              "      <td>0.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Max drawdown</th>\n",
              "      <td>-26.011%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Omega ratio</th>\n",
              "      <td>0.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sortino ratio</th>\n",
              "      <td>-0.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Skew</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Kurtosis</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tail ratio</th>\n",
              "      <td>0.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Daily value at risk</th>\n",
              "      <td>-2.0%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Alpha</th>\n",
              "      <td>-0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Beta</th>\n",
              "      <td>-0.63</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Worst drawdown periods</th>\n",
              "      <th>Net drawdown in %</th>\n",
              "      <th>Peak date</th>\n",
              "      <th>Valley date</th>\n",
              "      <th>Recovery date</th>\n",
              "      <th>Duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>26.01</td>\n",
              "      <td>2021-02-26</td>\n",
              "      <td>2022-03-29</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.37</td>\n",
              "      <td>2021-02-03</td>\n",
              "      <td>2021-02-11</td>\n",
              "      <td>2021-02-16</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.22</td>\n",
              "      <td>2021-02-23</td>\n",
              "      <td>2021-02-24</td>\n",
              "      <td>2021-02-26</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.08</td>\n",
              "      <td>2021-02-19</td>\n",
              "      <td>2021-02-22</td>\n",
              "      <td>2021-02-23</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Stress Events</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>New Normal</th>\n",
              "      <td>-0.05%</td>\n",
              "      <td>-4.53%</td>\n",
              "      <td>3.81%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1008x5184 with 13 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1008x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"==============Compare to DJIA===========\")\n",
        "%matplotlib inline\n",
        "# S&P 500: ^GSPC\n",
        "# Dow Jones Index: ^DJI\n",
        "# NASDAQ 100: ^NDX\n",
        "backtest_plot(df_account_value, \n",
        "              baseline_ticker = '^GSPC', \n",
        "              baseline_start = df_account_value.loc[0,'date'],\n",
        "              baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBQx4bVQFi-a"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "FinRL_Ensemble_StockTrading_ICAIF_2020.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "vscode": {
      "interpreter": {
        "hash": "a1dc24e770f11933509167a1c29cdaaeb86ecb8b4614cc65da123615b71c0aa2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
