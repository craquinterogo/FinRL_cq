{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lb9q2_QZgdNk"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Tutorials/blob/master/2-Advance/FinRL_Ensemble_StockTrading_ICAIF_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXaoZs2lh1hi"
      },
      "source": [
        "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading Using Ensemble Strategy\n",
        "\n",
        "Tutorials to use OpenAI DRL to trade multiple stocks using ensemble strategy in one Jupyter Notebook | Presented at ICAIF 2020\n",
        "\n",
        "* This notebook is the reimplementation of our paper: Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, using FinRL.\n",
        "* Check out medium blog for detailed explanations: https://medium.com/@ai4finance/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02\n",
        "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
        "* **Pytorch Version** \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGunVt8oLCVS"
      },
      "source": [
        "# Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOzAKQ-SLGX6"
      },
      "source": [
        "* [1. Problem Definition](#0)\n",
        "* [2. Getting Started - Load Python packages](#1)\n",
        "    * [2.1. Install Packages](#1.1)    \n",
        "    * [2.2. Check Additional Packages](#1.2)\n",
        "    * [2.3. Import Packages](#1.3)\n",
        "    * [2.4. Create Folders](#1.4)\n",
        "* [3. Download Data](#2)\n",
        "* [4. Preprocess Data](#3)        \n",
        "    * [4.1. Technical Indicators](#3.1)\n",
        "    * [4.2. Perform Feature Engineering](#3.2)\n",
        "* [5.Build Environment](#4)  \n",
        "    * [5.1. Training & Trade Data Split](#4.1)\n",
        "    * [5.2. User-defined Environment](#4.2)   \n",
        "    * [5.3. Initialize Environment](#4.3)    \n",
        "* [6.Implement DRL Algorithms](#5)  \n",
        "* [7.Backtesting Performance](#6)  \n",
        "    * [7.1. BackTestStats](#6.1)\n",
        "    * [7.2. BackTestPlot](#6.2)   \n",
        "    * [7.3. Baseline Stats](#6.3)   \n",
        "    * [7.3. Compare to Stock Market Index](#6.4)             "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sApkDlD9LIZv"
      },
      "source": [
        "<a id='0'></a>\n",
        "# Part 1. Problem Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjLD2TZSLKZ-"
      },
      "source": [
        "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
        "\n",
        "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
        "\n",
        "\n",
        "* Action: The action space describes the allowed actions that the agent interacts with the\n",
        "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
        "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
        "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
        "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
        "\n",
        "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
        "values at state s′ and s, respectively\n",
        "\n",
        "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
        "our trading agent observes many different features to better learn in an interactive environment.\n",
        "\n",
        "* Environment: Dow 30 consituents\n",
        "\n",
        "\n",
        "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffsre789LY08"
      },
      "source": [
        "<a id='1'></a>\n",
        "# Part 2. Getting Started- Load Python Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy5_PTmOh1hj"
      },
      "source": [
        "<a id='1.1'></a>\n",
        "## 2.1. Install all the packages through FinRL library\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mPT0ipYE28wL",
        "outputId": "4352663d-20eb-4080-a83e-bf6b97183bf4"
      },
      "outputs": [],
      "source": [
        "# # ## install finrl library\n",
        "# !pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osBHhVysOEzi"
      },
      "source": [
        "\n",
        "<a id='1.2'></a>\n",
        "## 2.2. Check if the additional packages needed are present, if not install them. \n",
        "* Yahoo Finance API\n",
        "* pandas\n",
        "* numpy\n",
        "* matplotlib\n",
        "* stockstats\n",
        "* OpenAI gym\n",
        "* stable-baselines\n",
        "* tensorflow\n",
        "* pyfolio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGv01K8Sh1hn"
      },
      "source": [
        "<a id='1.3'></a>\n",
        "## 2.3. Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EeMK7Uentj1V"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lPqeTTwoh1hn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# matplotlib.use('Agg')\n",
        "import datetime\n",
        "\n",
        "%matplotlib inline\n",
        "from finrl.config_tickers import DOW_30_TICKER\n",
        "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from finrl.meta.env_stock_trading.env_stocktrading_pair_trading_Prices import StockPairTradingEnv\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent,DRLEnsembleAgent, DRLEnsembleAgentOne\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../FinRL-Library\")\n",
        "\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2owTj985RW4"
      },
      "source": [
        "<a id='1.4'></a>\n",
        "## 2.4. Create Folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "w9A8CN5R5PuZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from finrl.main import check_and_make_directories\n",
        "from finrl.config import (\n",
        "    DATA_SAVE_DIR,\n",
        "    TRAINED_MODEL_DIR,\n",
        "    TENSORBOARD_LOG_DIR,\n",
        "    RESULTS_DIR,\n",
        "    INDICATORS,\n",
        "    TRAIN_START_DATE,\n",
        "    TRAIN_END_DATE,\n",
        "    TEST_START_DATE,\n",
        "    TEST_END_DATE,\n",
        "    TRADE_START_DATE,\n",
        "    TRADE_END_DATE,\n",
        ")\n",
        "\n",
        "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A289rQWMh1hq"
      },
      "source": [
        "<a id='2'></a>\n",
        "# Part 3. Download Data\n",
        "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
        "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
        "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPeQ7iS-LoMm"
      },
      "source": [
        "\n",
        "\n",
        "-----\n",
        "class YahooDownloader:\n",
        "    Provides methods for retrieving daily stock data from\n",
        "    Yahoo Finance API\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        start_date : str\n",
        "            start date of the data (modified from config.py)\n",
        "        end_date : str\n",
        "            end date of the data (modified from config.py)\n",
        "        ticker_list : list\n",
        "            a list of stock tickers (modified from config.py)\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    fetch_data()\n",
        "        Fetches data from yahoo API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzqRRTOX6aFu",
        "outputId": "cd002c5d-2490-4947-9bd3-2b0696cb0f69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['A', 'AVGO']\n"
          ]
        }
      ],
      "source": [
        "DOW_30_TICKER = ['A','AVGO']\n",
        "print(DOW_30_TICKER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCKm4om-s9kE",
        "outputId": "743f675b-6126-44ea-bf39-7b3333d15044"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (6126, 8)\n"
          ]
        }
      ],
      "source": [
        "TRAIN_START_DATE = '2010-04-01'\n",
        "TRAIN_END_DATE = '2021-01-01'\n",
        "TEST_START_DATE = '2021-01-01'\n",
        "TEST_END_DATE = '2022-06-01'\n",
        "\n",
        "df = YahooDownloader(start_date = TRAIN_START_DATE,\n",
        "                     end_date = TEST_END_DATE,\n",
        "                     ticker_list = DOW_30_TICKER).fetch_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GiRuFOTOtj1Y",
        "outputId": "632ce1e6-ad27-4f50-fec7-0ca27c8e3c96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "A       3063\n",
              "AVGO    3063\n",
              "Name: tic, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['tic'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DSw4ZEzVtj1Z",
        "outputId": "0015b377-84ec-4a6d-ac4e-e138c2c9bac8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6121</th>\n",
              "      <td>2022-05-26</td>\n",
              "      <td>531.539978</td>\n",
              "      <td>554.570007</td>\n",
              "      <td>527.719971</td>\n",
              "      <td>537.109497</td>\n",
              "      <td>3974300</td>\n",
              "      <td>AVGO</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6122</th>\n",
              "      <td>2022-05-27</td>\n",
              "      <td>124.919998</td>\n",
              "      <td>130.770004</td>\n",
              "      <td>124.489998</td>\n",
              "      <td>130.094025</td>\n",
              "      <td>2698800</td>\n",
              "      <td>A</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6123</th>\n",
              "      <td>2022-05-27</td>\n",
              "      <td>562.090027</td>\n",
              "      <td>585.460022</td>\n",
              "      <td>560.010010</td>\n",
              "      <td>568.926819</td>\n",
              "      <td>3730100</td>\n",
              "      <td>AVGO</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6124</th>\n",
              "      <td>2022-05-31</td>\n",
              "      <td>128.910004</td>\n",
              "      <td>130.070007</td>\n",
              "      <td>126.720001</td>\n",
              "      <td>127.114464</td>\n",
              "      <td>3403100</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6125</th>\n",
              "      <td>2022-05-31</td>\n",
              "      <td>584.500000</td>\n",
              "      <td>587.030029</td>\n",
              "      <td>576.000000</td>\n",
              "      <td>565.854309</td>\n",
              "      <td>3000900</td>\n",
              "      <td>AVGO</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            date        open        high         low       close   volume  \\\n",
              "6121  2022-05-26  531.539978  554.570007  527.719971  537.109497  3974300   \n",
              "6122  2022-05-27  124.919998  130.770004  124.489998  130.094025  2698800   \n",
              "6123  2022-05-27  562.090027  585.460022  560.010010  568.926819  3730100   \n",
              "6124  2022-05-31  128.910004  130.070007  126.720001  127.114464  3403100   \n",
              "6125  2022-05-31  584.500000  587.030029  576.000000  565.854309  3000900   \n",
              "\n",
              "       tic  day  \n",
              "6121  AVGO    3  \n",
              "6122     A    4  \n",
              "6123  AVGO    4  \n",
              "6124     A    1  \n",
              "6125  AVGO    1  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV3HrZHLh1hy",
        "outputId": "42781af6-4cee-4277-8a00-cf46052f991c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6126, 8)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4hYkeaPiICHS",
        "outputId": "59c51c93-f786-469b-c008-4e4416a041b4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-04-01</td>\n",
              "      <td>24.706724</td>\n",
              "      <td>24.942776</td>\n",
              "      <td>24.499285</td>\n",
              "      <td>22.442747</td>\n",
              "      <td>3105098</td>\n",
              "      <td>A</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-04-01</td>\n",
              "      <td>20.690001</td>\n",
              "      <td>20.799999</td>\n",
              "      <td>20.090000</td>\n",
              "      <td>15.103767</td>\n",
              "      <td>324600</td>\n",
              "      <td>AVGO</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-04-05</td>\n",
              "      <td>24.742489</td>\n",
              "      <td>24.921316</td>\n",
              "      <td>24.706724</td>\n",
              "      <td>22.618128</td>\n",
              "      <td>3731961</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-04-05</td>\n",
              "      <td>20.690001</td>\n",
              "      <td>20.700001</td>\n",
              "      <td>19.790001</td>\n",
              "      <td>14.926938</td>\n",
              "      <td>612000</td>\n",
              "      <td>AVGO</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-04-06</td>\n",
              "      <td>24.778255</td>\n",
              "      <td>24.814020</td>\n",
              "      <td>24.620888</td>\n",
              "      <td>22.449238</td>\n",
              "      <td>3499054</td>\n",
              "      <td>A</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date       open       high        low      close   volume   tic  day\n",
              "0  2010-04-01  24.706724  24.942776  24.499285  22.442747  3105098     A    3\n",
              "1  2010-04-01  20.690001  20.799999  20.090000  15.103767   324600  AVGO    3\n",
              "2  2010-04-05  24.742489  24.921316  24.706724  22.618128  3731961     A    0\n",
              "3  2010-04-05  20.690001  20.700001  19.790001  14.926938   612000  AVGO    0\n",
              "4  2010-04-06  24.778255  24.814020  24.620888  22.449238  3499054     A    1"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sort_values(['date','tic']).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2vryMsdNL9H",
        "outputId": "dff3babf-4aba-44dd-ad61-8845df60243e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df.tic.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcNyXa7RNPrF",
        "outputId": "fd13ad85-36fd-4a55-9084-dbf807bbeb02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "A       3063\n",
              "AVGO    3063\n",
              "Name: tic, dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.tic.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqC6c40Zh1iH"
      },
      "source": [
        "# Part 4: Preprocess Data\n",
        "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
        "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
        "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kM5bH9uroCeg"
      },
      "outputs": [],
      "source": [
        "#  INDICATORS = ['macd',\n",
        "#                'rsi_30',\n",
        "#                'cci_30',\n",
        "#                'dx_30']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgXfBcjxtj1a",
        "outputId": "aa687295-c857-4366-d9af-96ea233c6463",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully added technical indicators\n",
            "Successfully added turbulence index\n"
          ]
        }
      ],
      "source": [
        "fe = FeatureEngineer(use_technical_indicator=True,\n",
        "                     tech_indicator_list = INDICATORS,\n",
        "                     use_turbulence=True,\n",
        "                     user_defined_feature = False)\n",
        "\n",
        "processed = fe.preprocess_data(df)\n",
        "processed = processed.copy()\n",
        "processed = processed.fillna(0)\n",
        "processed = processed.replace(np.inf,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "grvhGJJII3Xn",
        "outputId": "6dd919fa-032b-4180-adf4-1f732777cedc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "A       3063\n",
              "AVGO    3063\n",
              "Name: tic, dtype: int64"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processed.tic.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QsYaY0Dh1iw"
      },
      "source": [
        "<a id='4'></a>\n",
        "# Part 5. Design Environment\n",
        "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
        "\n",
        "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
        "\n",
        "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2zqII8rMIqn",
        "outputId": "0194749d-62ec-420f-9b54-492873c266a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stock Dimension: 2, State Space: 21\n"
          ]
        }
      ],
      "source": [
        "stock_dimension = len(processed.tic.unique())\n",
        "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "AWyp84Ltto19"
      },
      "outputs": [],
      "source": [
        "env_kwargs = {\n",
        "    \"hmax\": 100, \n",
        "    \"initial_amount\": 10000, \n",
        "    \"buy_cost_pct\": 0.001, \n",
        "    \"sell_cost_pct\": 0.001, \n",
        "    \"state_space\": state_space, \n",
        "    \"stock_dim\": stock_dimension, \n",
        "    \"tech_indicator_list\": INDICATORS,\n",
        "    \"action_space\": stock_dimension, \n",
        "    \"reward_scaling\": 1e-4,\n",
        "    \"print_verbosity\":5\n",
        "    \n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMNR5nHjh1iz"
      },
      "source": [
        "<a id='5'></a>\n",
        "# Part 6: Implement DRL Algorithms\n",
        "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
        "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
        "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
        "design their own DRL algorithms by adapting these DRL algorithms.\n",
        "\n",
        "* In this notebook, we are training and validating 3 agents (A2C, PPO, DDPG) using Rolling-window Ensemble Method ([reference code](https://github.com/AI4Finance-LLC/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020/blob/80415db8fa7b2179df6bd7e81ce4fe8dbf913806/model/models.py#L92))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "v-gthCxMtj1d"
      },
      "outputs": [],
      "source": [
        "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\n",
        "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
        "\n",
        "ensemble_agent = DRLEnsembleAgentOne(df=processed,\n",
        "                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n",
        "                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n",
        "                 rebalance_window=rebalance_window, \n",
        "                 validation_window=validation_window, \n",
        "                 seed=106,\n",
        "                 **env_kwargs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "KsfEHa_Etj1d",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "A2C_model_kwargs = {\n",
        "                    'n_steps': 5,\n",
        "                    'ent_coef': 0.005,\n",
        "                    'learning_rate': 0.0007\n",
        "                    }\n",
        "\n",
        "PPO_model_kwargs = {\n",
        "                    \"ent_coef\":0.01,\n",
        "                    \"n_steps\": 2048,\n",
        "                    \"learning_rate\": 0.00025,\n",
        "                    \"batch_size\": 128\n",
        "                    }\n",
        "\n",
        "DDPG_model_kwargs = {\n",
        "                      #\"action_noise\":\"ornstein_uhlenbeck\",\n",
        "                      \"buffer_size\": 10_000,\n",
        "                      \"learning_rate\": 0.0005,\n",
        "                      \"batch_size\": 64\n",
        "                    }\n",
        "\n",
        "timesteps_dict = {'a2c' : 0, \n",
        "                 'ppo' : 1_000_000, \n",
        "                 'ddpg' : 0\n",
        "                 }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1lyCECstj1e",
        "outputId": "b2a1cfbc-ced9-4d06-dd9a-4300845e1113",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============Start Ensemble Strategy============\n",
            "============================================\n",
            "turbulence_threshold:  18.962438407024404\n",
            "======Model training from:  2010-04-01 to  2021-01-04\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo\\ppo_126_1\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    fps             | 346         |\n",
            "|    iterations      | 1           |\n",
            "|    time_elapsed    | 5           |\n",
            "|    total_timesteps | 2048        |\n",
            "| train/             |             |\n",
            "|    reward          | -0.05952631 |\n",
            "------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 397          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 10           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037666983 |\n",
            "|    clip_fraction        | 0.0211       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | -0.441       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0173      |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00181     |\n",
            "|    reward               | 0.06261984   |\n",
            "|    std                  | 0.998        |\n",
            "|    value_loss           | 0.0095       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 415           |\n",
            "|    iterations           | 3             |\n",
            "|    time_elapsed         | 14            |\n",
            "|    total_timesteps      | 6144          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.001221992   |\n",
            "|    clip_fraction        | 0.00566       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.83         |\n",
            "|    explained_variance   | -0.0539       |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0119       |\n",
            "|    n_updates            | 20            |\n",
            "|    policy_gradient_loss | -0.000226     |\n",
            "|    reward               | -0.0065799546 |\n",
            "|    std                  | 0.998         |\n",
            "|    value_loss           | 0.0331        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 423          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 19           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037355185 |\n",
            "|    clip_fraction        | 0.0041       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | 0.0148       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00135     |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.000383    |\n",
            "|    reward               | 0.0044606635 |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.069        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 23           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021354535 |\n",
            "|    clip_fraction        | 0.0133       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | 0.042        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0339      |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00177     |\n",
            "|    reward               | -0.073850095 |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.0217       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 437          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 28           |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029406415 |\n",
            "|    clip_fraction        | 0.0215       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | 0.043        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0319      |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.00103     |\n",
            "|    reward               | 0.12530726   |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.0136       |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 5\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -96640.48\n",
            "total_reward: -106640.48\n",
            "total_cost: 373.57\n",
            "total_trades: 2700\n",
            "Sharpe: -0.082\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 442          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 32           |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058530523 |\n",
            "|    clip_fraction        | 0.0601       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | 0.0573       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00911     |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.00195     |\n",
            "|    reward               | 0.007900412  |\n",
            "|    std                  | 0.999        |\n",
            "|    value_loss           | 0.0512       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 446          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 36           |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005499647  |\n",
            "|    clip_fraction        | 0.0337       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.83        |\n",
            "|    explained_variance   | 0.128        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0239       |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.00237     |\n",
            "|    reward               | 0.0018360233 |\n",
            "|    std                  | 0.995        |\n",
            "|    value_loss           | 0.0713       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 448          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 41           |\n",
            "|    total_timesteps      | 18432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061586765 |\n",
            "|    clip_fraction        | 0.0557       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.82        |\n",
            "|    explained_variance   | 0.151        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00677     |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -0.00377     |\n",
            "|    reward               | -0.1665212   |\n",
            "|    std                  | 0.992        |\n",
            "|    value_loss           | 0.0786       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 450          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 45           |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030842088 |\n",
            "|    clip_fraction        | 0.00679      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.83        |\n",
            "|    explained_variance   | 0.024        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00242     |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.000714    |\n",
            "|    reward               | 0.053224914  |\n",
            "|    std                  | 0.998        |\n",
            "|    value_loss           | 0.0326       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 451          |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 49           |\n",
            "|    total_timesteps      | 22528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026947402 |\n",
            "|    clip_fraction        | 0.0128       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | 0.112        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0465       |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -0.000902    |\n",
            "|    reward               | 0.005563658  |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.131        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 453          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 54           |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005364309  |\n",
            "|    clip_fraction        | 0.0198       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | 0.134        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0578       |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.000793    |\n",
            "|    reward               | 0.0023814274 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.237        |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 454        |\n",
            "|    iterations           | 13         |\n",
            "|    time_elapsed         | 58         |\n",
            "|    total_timesteps      | 26624      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00831775 |\n",
            "|    clip_fraction        | 0.037      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.85      |\n",
            "|    explained_variance   | 0.212      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 0.0127     |\n",
            "|    n_updates            | 120        |\n",
            "|    policy_gradient_loss | -0.00115   |\n",
            "|    reward               | 0.07703813 |\n",
            "|    std                  | 1          |\n",
            "|    value_loss           | 0.108      |\n",
            "----------------------------------------\n",
            "day: 2707, episode: 10\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -103441.35\n",
            "total_reward: -113441.35\n",
            "total_cost: 372.93\n",
            "total_trades: 2688\n",
            "Sharpe: -0.206\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 451          |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 63           |\n",
            "|    total_timesteps      | 28672        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028793951 |\n",
            "|    clip_fraction        | 0.0166       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | 0.317        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0137      |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -0.00109     |\n",
            "|    reward               | 0.0128369555 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.0236       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 452           |\n",
            "|    iterations           | 15            |\n",
            "|    time_elapsed         | 67            |\n",
            "|    total_timesteps      | 30720         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.004059913   |\n",
            "|    clip_fraction        | 0.0173        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.86         |\n",
            "|    explained_variance   | 0.205         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.00379      |\n",
            "|    n_updates            | 140           |\n",
            "|    policy_gradient_loss | -0.000157     |\n",
            "|    reward               | -0.0043310462 |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 0.0649        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 453          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 72           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037712138 |\n",
            "|    clip_fraction        | 0.0139       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.87        |\n",
            "|    explained_variance   | 0.226        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0214      |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -0.000942    |\n",
            "|    reward               | 0.0046467613 |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 0.0336       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 454          |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 76           |\n",
            "|    total_timesteps      | 34816        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004250128  |\n",
            "|    clip_fraction        | 0.0239       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.88        |\n",
            "|    explained_variance   | 0.0504       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0151      |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -0.0023      |\n",
            "|    reward               | -0.027622135 |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 0.0351       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 455          |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 80           |\n",
            "|    total_timesteps      | 36864        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058311867 |\n",
            "|    clip_fraction        | 0.0299       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.89        |\n",
            "|    explained_variance   | 0.197        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0198      |\n",
            "|    n_updates            | 170          |\n",
            "|    policy_gradient_loss | -0.00236     |\n",
            "|    reward               | -0.15948644  |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 0.0091       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 455          |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 85           |\n",
            "|    total_timesteps      | 38912        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029935916 |\n",
            "|    clip_fraction        | 0.0174       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.9         |\n",
            "|    explained_variance   | -0.0115      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00279     |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -0.0018      |\n",
            "|    reward               | 0.05850184   |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.0423       |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 15\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -250191.67\n",
            "total_reward: -260191.67\n",
            "total_cost: 398.11\n",
            "total_trades: 2782\n",
            "Sharpe: 0.324\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 456          |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 89           |\n",
            "|    total_timesteps      | 40960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011852251 |\n",
            "|    clip_fraction        | 0.00352      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.92        |\n",
            "|    explained_variance   | -0.0211      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.112        |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | -0.000121    |\n",
            "|    reward               | 0.0028375012 |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.255        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 457          |\n",
            "|    iterations           | 21           |\n",
            "|    time_elapsed         | 94           |\n",
            "|    total_timesteps      | 43008        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032144436 |\n",
            "|    clip_fraction        | 0.00317      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.92        |\n",
            "|    explained_variance   | 0.0476       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0655       |\n",
            "|    n_updates            | 200          |\n",
            "|    policy_gradient_loss | -0.000952    |\n",
            "|    reward               | -0.05068511  |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.361        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 457          |\n",
            "|    iterations           | 22           |\n",
            "|    time_elapsed         | 98           |\n",
            "|    total_timesteps      | 45056        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035456475 |\n",
            "|    clip_fraction        | 0.0473       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.92        |\n",
            "|    explained_variance   | 0.0572       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0269       |\n",
            "|    n_updates            | 210          |\n",
            "|    policy_gradient_loss | -0.00391     |\n",
            "|    reward               | 0.002977163  |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.115        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 458          |\n",
            "|    iterations           | 23           |\n",
            "|    time_elapsed         | 102          |\n",
            "|    total_timesteps      | 47104        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015232692 |\n",
            "|    clip_fraction        | 0.021        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.92        |\n",
            "|    explained_variance   | 0.087        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0416       |\n",
            "|    n_updates            | 220          |\n",
            "|    policy_gradient_loss | -0.00135     |\n",
            "|    reward               | -0.013863268 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.131        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 458          |\n",
            "|    iterations           | 24           |\n",
            "|    time_elapsed         | 107          |\n",
            "|    total_timesteps      | 49152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045591984 |\n",
            "|    clip_fraction        | 0.0225       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.93        |\n",
            "|    explained_variance   | 0.172        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0367       |\n",
            "|    n_updates            | 230          |\n",
            "|    policy_gradient_loss | -0.000571    |\n",
            "|    reward               | -0.011182486 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.123        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 459          |\n",
            "|    iterations           | 25           |\n",
            "|    time_elapsed         | 111          |\n",
            "|    total_timesteps      | 51200        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018753269 |\n",
            "|    clip_fraction        | 0.00322      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.94        |\n",
            "|    explained_variance   | 0.424        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0189      |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | 3.44e-06     |\n",
            "|    reward               | 0.2476356    |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.0207       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 459          |\n",
            "|    iterations           | 26           |\n",
            "|    time_elapsed         | 115          |\n",
            "|    total_timesteps      | 53248        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038417622 |\n",
            "|    clip_fraction        | 0.048        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.94        |\n",
            "|    explained_variance   | 0.119        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00153     |\n",
            "|    n_updates            | 250          |\n",
            "|    policy_gradient_loss | -0.0035      |\n",
            "|    reward               | 0.13422468   |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.0516       |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 20\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -218089.08\n",
            "total_reward: -228089.08\n",
            "total_cost: 393.85\n",
            "total_trades: 2730\n",
            "Sharpe: -0.344\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 459          |\n",
            "|    iterations           | 27           |\n",
            "|    time_elapsed         | 120          |\n",
            "|    total_timesteps      | 55296        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043731756 |\n",
            "|    clip_fraction        | 0.00996      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.94        |\n",
            "|    explained_variance   | 0.103        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0152       |\n",
            "|    n_updates            | 260          |\n",
            "|    policy_gradient_loss | -0.00098     |\n",
            "|    reward               | 0.031566687  |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.0894       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 460          |\n",
            "|    iterations           | 28           |\n",
            "|    time_elapsed         | 124          |\n",
            "|    total_timesteps      | 57344        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023473753 |\n",
            "|    clip_fraction        | 0.00083      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.94        |\n",
            "|    explained_variance   | 0.0772       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0958       |\n",
            "|    n_updates            | 270          |\n",
            "|    policy_gradient_loss | -0.000804    |\n",
            "|    reward               | 0.0034614136 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.263        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 460          |\n",
            "|    iterations           | 29           |\n",
            "|    time_elapsed         | 128          |\n",
            "|    total_timesteps      | 59392        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045436714 |\n",
            "|    clip_fraction        | 0.0516       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.94        |\n",
            "|    explained_variance   | 0.101        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.119        |\n",
            "|    n_updates            | 280          |\n",
            "|    policy_gradient_loss | -0.004       |\n",
            "|    reward               | -0.09468128  |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.339        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 460          |\n",
            "|    iterations           | 30           |\n",
            "|    time_elapsed         | 133          |\n",
            "|    total_timesteps      | 61440        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029285522 |\n",
            "|    clip_fraction        | 0.0159       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.94        |\n",
            "|    explained_variance   | -0.0356      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0121      |\n",
            "|    n_updates            | 290          |\n",
            "|    policy_gradient_loss | -0.000164    |\n",
            "|    reward               | 0.15002595   |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.034        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 461          |\n",
            "|    iterations           | 31           |\n",
            "|    time_elapsed         | 137          |\n",
            "|    total_timesteps      | 63488        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037953989 |\n",
            "|    clip_fraction        | 0.0273       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.94        |\n",
            "|    explained_variance   | 0.378        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0109      |\n",
            "|    n_updates            | 300          |\n",
            "|    policy_gradient_loss | -0.00142     |\n",
            "|    reward               | 0.01522756   |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.0169       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 462          |\n",
            "|    iterations           | 32           |\n",
            "|    time_elapsed         | 141          |\n",
            "|    total_timesteps      | 65536        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.007105236  |\n",
            "|    clip_fraction        | 0.0665       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.94        |\n",
            "|    explained_variance   | 0.306        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00195      |\n",
            "|    n_updates            | 310          |\n",
            "|    policy_gradient_loss | -0.00355     |\n",
            "|    reward               | -0.030841429 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.0473       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 462         |\n",
            "|    iterations           | 33          |\n",
            "|    time_elapsed         | 146         |\n",
            "|    total_timesteps      | 67584       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.00661719  |\n",
            "|    clip_fraction        | 0.0608      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.94       |\n",
            "|    explained_variance   | 0.173       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0136     |\n",
            "|    n_updates            | 320         |\n",
            "|    policy_gradient_loss | -0.00452    |\n",
            "|    reward               | -0.19096199 |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 0.0824      |\n",
            "-----------------------------------------\n",
            "day: 2707, episode: 25\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -142205.52\n",
            "total_reward: -152205.52\n",
            "total_cost: 382.89\n",
            "total_trades: 2678\n",
            "Sharpe: -0.373\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 461        |\n",
            "|    iterations           | 34         |\n",
            "|    time_elapsed         | 150        |\n",
            "|    total_timesteps      | 69632      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00243754 |\n",
            "|    clip_fraction        | 0.00156    |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.93      |\n",
            "|    explained_variance   | 0.0228     |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 0.0213     |\n",
            "|    n_updates            | 330        |\n",
            "|    policy_gradient_loss | 0.000265   |\n",
            "|    reward               | 0.13947645 |\n",
            "|    std                  | 1.05       |\n",
            "|    value_loss           | 0.138      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 462         |\n",
            "|    iterations           | 35          |\n",
            "|    time_elapsed         | 155         |\n",
            "|    total_timesteps      | 71680       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004141464 |\n",
            "|    clip_fraction        | 0.0272      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.93       |\n",
            "|    explained_variance   | 0.196       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.00858    |\n",
            "|    n_updates            | 340         |\n",
            "|    policy_gradient_loss | -0.00178    |\n",
            "|    reward               | -0.22297792 |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 0.0465      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 462          |\n",
            "|    iterations           | 36           |\n",
            "|    time_elapsed         | 159          |\n",
            "|    total_timesteps      | 73728        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012860127 |\n",
            "|    clip_fraction        | 0.0121       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.94        |\n",
            "|    explained_variance   | 0.172        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00219     |\n",
            "|    n_updates            | 350          |\n",
            "|    policy_gradient_loss | -0.000327    |\n",
            "|    reward               | 0.0085339565 |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.0833       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 462          |\n",
            "|    iterations           | 37           |\n",
            "|    time_elapsed         | 163          |\n",
            "|    total_timesteps      | 75776        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036533494 |\n",
            "|    clip_fraction        | 0.00493      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.95        |\n",
            "|    explained_variance   | 0.0723       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.242        |\n",
            "|    n_updates            | 360          |\n",
            "|    policy_gradient_loss | -0.000647    |\n",
            "|    reward               | 0.019901978  |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.427        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 463         |\n",
            "|    iterations           | 38          |\n",
            "|    time_elapsed         | 167         |\n",
            "|    total_timesteps      | 77824       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002770223 |\n",
            "|    clip_fraction        | 0.00825     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.97       |\n",
            "|    explained_variance   | 0.356       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.000963    |\n",
            "|    n_updates            | 370         |\n",
            "|    policy_gradient_loss | -0.00108    |\n",
            "|    reward               | 0.048800692 |\n",
            "|    std                  | 1.07        |\n",
            "|    value_loss           | 0.0523      |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 463           |\n",
            "|    iterations           | 39            |\n",
            "|    time_elapsed         | 172           |\n",
            "|    total_timesteps      | 79872         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.004361186   |\n",
            "|    clip_fraction        | 0.0137        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.98         |\n",
            "|    explained_variance   | 0.297         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0175       |\n",
            "|    n_updates            | 380           |\n",
            "|    policy_gradient_loss | -0.00106      |\n",
            "|    reward               | -0.0023120202 |\n",
            "|    std                  | 1.07          |\n",
            "|    value_loss           | 0.0282        |\n",
            "-------------------------------------------\n",
            "day: 2707, episode: 30\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -99548.75\n",
            "total_reward: -109548.75\n",
            "total_cost: 355.67\n",
            "total_trades: 2656\n",
            "Sharpe: -0.144\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 463          |\n",
            "|    iterations           | 40           |\n",
            "|    time_elapsed         | 176          |\n",
            "|    total_timesteps      | 81920        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0074365446 |\n",
            "|    clip_fraction        | 0.048        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.97        |\n",
            "|    explained_variance   | 0.131        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0014       |\n",
            "|    n_updates            | 390          |\n",
            "|    policy_gradient_loss | -0.00248     |\n",
            "|    reward               | -0.008278257 |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.127        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 463           |\n",
            "|    iterations           | 41            |\n",
            "|    time_elapsed         | 181           |\n",
            "|    total_timesteps      | 83968         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0017612067  |\n",
            "|    clip_fraction        | 0.0261        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.97         |\n",
            "|    explained_variance   | 0.295         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.000763      |\n",
            "|    n_updates            | 400           |\n",
            "|    policy_gradient_loss | -0.00101      |\n",
            "|    reward               | 0.00045644282 |\n",
            "|    std                  | 1.07          |\n",
            "|    value_loss           | 0.0787        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 463          |\n",
            "|    iterations           | 42           |\n",
            "|    time_elapsed         | 185          |\n",
            "|    total_timesteps      | 86016        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013818867 |\n",
            "|    clip_fraction        | 0.00449      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.98        |\n",
            "|    explained_variance   | 0.157        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0307       |\n",
            "|    n_updates            | 410          |\n",
            "|    policy_gradient_loss | -0.000309    |\n",
            "|    reward               | 0.010459453  |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 0.15         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 463          |\n",
            "|    iterations           | 43           |\n",
            "|    time_elapsed         | 189          |\n",
            "|    total_timesteps      | 88064        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015014121 |\n",
            "|    clip_fraction        | 0.00894      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.98        |\n",
            "|    explained_variance   | 0.409        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0186      |\n",
            "|    n_updates            | 420          |\n",
            "|    policy_gradient_loss | -0.00014     |\n",
            "|    reward               | 0.04047449   |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 0.0264       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 463           |\n",
            "|    iterations           | 44            |\n",
            "|    time_elapsed         | 194           |\n",
            "|    total_timesteps      | 90112         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0039801924  |\n",
            "|    clip_fraction        | 0.0181        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.99         |\n",
            "|    explained_variance   | 0.165         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0745        |\n",
            "|    n_updates            | 430           |\n",
            "|    policy_gradient_loss | -0.00122      |\n",
            "|    reward               | -9.547729e-05 |\n",
            "|    std                  | 1.09          |\n",
            "|    value_loss           | 0.181         |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 463           |\n",
            "|    iterations           | 45            |\n",
            "|    time_elapsed         | 198           |\n",
            "|    total_timesteps      | 92160         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0029093407  |\n",
            "|    clip_fraction        | 0.0222        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.01         |\n",
            "|    explained_variance   | 0.207         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0519        |\n",
            "|    n_updates            | 440           |\n",
            "|    policy_gradient_loss | -0.000487     |\n",
            "|    reward               | -0.0031899596 |\n",
            "|    std                  | 1.09          |\n",
            "|    value_loss           | 0.189         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 464          |\n",
            "|    iterations           | 46           |\n",
            "|    time_elapsed         | 203          |\n",
            "|    total_timesteps      | 94208        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020100144 |\n",
            "|    clip_fraction        | 0.0112       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | 0.137        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0485       |\n",
            "|    n_updates            | 450          |\n",
            "|    policy_gradient_loss | -0.000915    |\n",
            "|    reward               | 0.064655     |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.302        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 35\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -157485.12\n",
            "total_reward: -167485.12\n",
            "total_cost: 417.20\n",
            "total_trades: 2796\n",
            "Sharpe: 0.004\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 464          |\n",
            "|    iterations           | 47           |\n",
            "|    time_elapsed         | 207          |\n",
            "|    total_timesteps      | 96256        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019968979 |\n",
            "|    clip_fraction        | 0.00356      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | 0.519        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0248      |\n",
            "|    n_updates            | 460          |\n",
            "|    policy_gradient_loss | 0.000169     |\n",
            "|    reward               | 0.079044834  |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.0408       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 464          |\n",
            "|    iterations           | 48           |\n",
            "|    time_elapsed         | 211          |\n",
            "|    total_timesteps      | 98304        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005587787  |\n",
            "|    clip_fraction        | 0.0401       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 0.246        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.019        |\n",
            "|    n_updates            | 470          |\n",
            "|    policy_gradient_loss | -0.00316     |\n",
            "|    reward               | 0.0011617074 |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.192        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 462          |\n",
            "|    iterations           | 49           |\n",
            "|    time_elapsed         | 216          |\n",
            "|    total_timesteps      | 100352       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029677118 |\n",
            "|    clip_fraction        | 0.0202       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 0.275        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.103        |\n",
            "|    n_updates            | 480          |\n",
            "|    policy_gradient_loss | -0.00146     |\n",
            "|    reward               | -0.006527138 |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.261        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 462          |\n",
            "|    iterations           | 50           |\n",
            "|    time_elapsed         | 221          |\n",
            "|    total_timesteps      | 102400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069144466 |\n",
            "|    clip_fraction        | 0.0421       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 0.225        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0509       |\n",
            "|    n_updates            | 490          |\n",
            "|    policy_gradient_loss | -0.00337     |\n",
            "|    reward               | 1.1638281    |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.209        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 462         |\n",
            "|    iterations           | 51          |\n",
            "|    time_elapsed         | 225         |\n",
            "|    total_timesteps      | 104448      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004558942 |\n",
            "|    clip_fraction        | 0.0196      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.03       |\n",
            "|    explained_variance   | 0.467       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0146      |\n",
            "|    n_updates            | 500         |\n",
            "|    policy_gradient_loss | -0.00125    |\n",
            "|    reward               | 0.043533407 |\n",
            "|    std                  | 1.1         |\n",
            "|    value_loss           | 0.0773      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 461         |\n",
            "|    iterations           | 52          |\n",
            "|    time_elapsed         | 230         |\n",
            "|    total_timesteps      | 106496      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003947931 |\n",
            "|    clip_fraction        | 0.0366      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.03       |\n",
            "|    explained_variance   | 0.219       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.126       |\n",
            "|    n_updates            | 510         |\n",
            "|    policy_gradient_loss | -0.00211    |\n",
            "|    reward               | -0.01037026 |\n",
            "|    std                  | 1.1         |\n",
            "|    value_loss           | 0.334       |\n",
            "-----------------------------------------\n",
            "day: 2707, episode: 40\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -239638.87\n",
            "total_reward: -249638.87\n",
            "total_cost: 474.69\n",
            "total_trades: 3040\n",
            "Sharpe: -0.229\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 461           |\n",
            "|    iterations           | 53            |\n",
            "|    time_elapsed         | 235           |\n",
            "|    total_timesteps      | 108544        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0062656202  |\n",
            "|    clip_fraction        | 0.0583        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.04         |\n",
            "|    explained_variance   | 0.26          |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.223         |\n",
            "|    n_updates            | 520           |\n",
            "|    policy_gradient_loss | -0.00499      |\n",
            "|    reward               | -0.0011617098 |\n",
            "|    std                  | 1.11          |\n",
            "|    value_loss           | 0.451         |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 461         |\n",
            "|    iterations           | 54          |\n",
            "|    time_elapsed         | 239         |\n",
            "|    total_timesteps      | 110592      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002401731 |\n",
            "|    clip_fraction        | 0.00625     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.04       |\n",
            "|    explained_variance   | 0.123       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.232       |\n",
            "|    n_updates            | 530         |\n",
            "|    policy_gradient_loss | -0.00134    |\n",
            "|    reward               | -0.12523046 |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 0.511       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 461          |\n",
            "|    iterations           | 55           |\n",
            "|    time_elapsed         | 244          |\n",
            "|    total_timesteps      | 112640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.003281507  |\n",
            "|    clip_fraction        | 0.0416       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 0.486        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0498       |\n",
            "|    n_updates            | 540          |\n",
            "|    policy_gradient_loss | -0.00208     |\n",
            "|    reward               | -0.034007125 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.158        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 460         |\n",
            "|    iterations           | 56          |\n",
            "|    time_elapsed         | 249         |\n",
            "|    total_timesteps      | 114688      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005184521 |\n",
            "|    clip_fraction        | 0.0061      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.04       |\n",
            "|    explained_variance   | 0.142       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.178       |\n",
            "|    n_updates            | 550         |\n",
            "|    policy_gradient_loss | -0.000773   |\n",
            "|    reward               | 0.019353205 |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 0.472       |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 460           |\n",
            "|    iterations           | 57            |\n",
            "|    time_elapsed         | 253           |\n",
            "|    total_timesteps      | 116736        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0055177035  |\n",
            "|    clip_fraction        | 0.0206        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.05         |\n",
            "|    explained_variance   | 0.128         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.201         |\n",
            "|    n_updates            | 560           |\n",
            "|    policy_gradient_loss | -0.00101      |\n",
            "|    reward               | -0.0062436005 |\n",
            "|    std                  | 1.12          |\n",
            "|    value_loss           | 0.48          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 461           |\n",
            "|    iterations           | 58            |\n",
            "|    time_elapsed         | 257           |\n",
            "|    total_timesteps      | 118784        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0017814233  |\n",
            "|    clip_fraction        | 0.00132       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.05         |\n",
            "|    explained_variance   | 0.172         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.21          |\n",
            "|    n_updates            | 570           |\n",
            "|    policy_gradient_loss | 0.000147      |\n",
            "|    reward               | -0.0077269105 |\n",
            "|    std                  | 1.12          |\n",
            "|    value_loss           | 0.574         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 462          |\n",
            "|    iterations           | 59           |\n",
            "|    time_elapsed         | 261          |\n",
            "|    total_timesteps      | 120832       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038753557 |\n",
            "|    clip_fraction        | 0.0148       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 0.438        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0676       |\n",
            "|    n_updates            | 580          |\n",
            "|    policy_gradient_loss | -0.00128     |\n",
            "|    reward               | 0.33351183   |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.179        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 45\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -239994.45\n",
            "total_reward: -249994.45\n",
            "total_cost: 475.95\n",
            "total_trades: 2942\n",
            "Sharpe: -0.294\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 462          |\n",
            "|    iterations           | 60           |\n",
            "|    time_elapsed         | 265          |\n",
            "|    total_timesteps      | 122880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021581477 |\n",
            "|    clip_fraction        | 0.00112      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.06        |\n",
            "|    explained_variance   | 0.312        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.236        |\n",
            "|    n_updates            | 590          |\n",
            "|    policy_gradient_loss | -0.000241    |\n",
            "|    reward               | -0.038484324 |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.39         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 463          |\n",
            "|    iterations           | 61           |\n",
            "|    time_elapsed         | 269          |\n",
            "|    total_timesteps      | 124928       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049611274 |\n",
            "|    clip_fraction        | 0.018        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.07        |\n",
            "|    explained_variance   | 0.326        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.184        |\n",
            "|    n_updates            | 600          |\n",
            "|    policy_gradient_loss | -0.000485    |\n",
            "|    reward               | 0.010857815  |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.481        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 463          |\n",
            "|    iterations           | 62           |\n",
            "|    time_elapsed         | 273          |\n",
            "|    total_timesteps      | 126976       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0078076613 |\n",
            "|    clip_fraction        | 0.0614       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.243        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.186        |\n",
            "|    n_updates            | 610          |\n",
            "|    policy_gradient_loss | -0.00311     |\n",
            "|    reward               | -0.16854076  |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.55         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 464           |\n",
            "|    iterations           | 63            |\n",
            "|    time_elapsed         | 277           |\n",
            "|    total_timesteps      | 129024        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.002843665   |\n",
            "|    clip_fraction        | 0.00913       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.08         |\n",
            "|    explained_variance   | 0.397         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.122         |\n",
            "|    n_updates            | 620           |\n",
            "|    policy_gradient_loss | -0.0011       |\n",
            "|    reward               | -0.0076267594 |\n",
            "|    std                  | 1.13          |\n",
            "|    value_loss           | 0.286         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 464          |\n",
            "|    iterations           | 64           |\n",
            "|    time_elapsed         | 282          |\n",
            "|    total_timesteps      | 131072       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069384403 |\n",
            "|    clip_fraction        | 0.0333       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.316        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.128        |\n",
            "|    n_updates            | 630          |\n",
            "|    policy_gradient_loss | -0.00236     |\n",
            "|    reward               | 0.024954857  |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.639        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 465          |\n",
            "|    iterations           | 65           |\n",
            "|    time_elapsed         | 286          |\n",
            "|    total_timesteps      | 133120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051949867 |\n",
            "|    clip_fraction        | 0.0154       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.09        |\n",
            "|    explained_variance   | 0.239        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.625        |\n",
            "|    n_updates            | 640          |\n",
            "|    policy_gradient_loss | -0.00105     |\n",
            "|    reward               | -0.008665183 |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 0.969        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 465           |\n",
            "|    iterations           | 66            |\n",
            "|    time_elapsed         | 290           |\n",
            "|    total_timesteps      | 135168        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0028435541  |\n",
            "|    clip_fraction        | 0.00923       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.1          |\n",
            "|    explained_variance   | 0.197         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.34          |\n",
            "|    n_updates            | 650           |\n",
            "|    policy_gradient_loss | -0.00095      |\n",
            "|    reward               | -0.0044428734 |\n",
            "|    std                  | 1.15          |\n",
            "|    value_loss           | 0.917         |\n",
            "-------------------------------------------\n",
            "day: 2707, episode: 50\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -303820.58\n",
            "total_reward: -313820.58\n",
            "total_cost: 520.70\n",
            "total_trades: 3124\n",
            "Sharpe: 0.182\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 466         |\n",
            "|    iterations           | 67          |\n",
            "|    time_elapsed         | 294         |\n",
            "|    total_timesteps      | 137216      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004450651 |\n",
            "|    clip_fraction        | 0.00825     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.11       |\n",
            "|    explained_variance   | 0.387       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.117       |\n",
            "|    n_updates            | 660         |\n",
            "|    policy_gradient_loss | -0.000166   |\n",
            "|    reward               | -0.32048607 |\n",
            "|    std                  | 1.15        |\n",
            "|    value_loss           | 0.317       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 466          |\n",
            "|    iterations           | 68           |\n",
            "|    time_elapsed         | 298          |\n",
            "|    total_timesteps      | 139264       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.00274642   |\n",
            "|    clip_fraction        | 0.0218       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.11        |\n",
            "|    explained_variance   | 0.361        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.202        |\n",
            "|    n_updates            | 670          |\n",
            "|    policy_gradient_loss | -0.000659    |\n",
            "|    reward               | -0.014875699 |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 0.55         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 69           |\n",
            "|    time_elapsed         | 302          |\n",
            "|    total_timesteps      | 141312       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052732155 |\n",
            "|    clip_fraction        | 0.0432       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.12        |\n",
            "|    explained_variance   | 0.278        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.501        |\n",
            "|    n_updates            | 680          |\n",
            "|    policy_gradient_loss | -0.00286     |\n",
            "|    reward               | 0.0055174013 |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 0.94         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 70           |\n",
            "|    time_elapsed         | 306          |\n",
            "|    total_timesteps      | 143360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042881817 |\n",
            "|    clip_fraction        | 0.0496       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.1         |\n",
            "|    explained_variance   | 0.276        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.48         |\n",
            "|    n_updates            | 690          |\n",
            "|    policy_gradient_loss | -0.00285     |\n",
            "|    reward               | -0.04233393  |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.814        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 71           |\n",
            "|    time_elapsed         | 310          |\n",
            "|    total_timesteps      | 145408       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061760587 |\n",
            "|    clip_fraction        | 0.0141       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.265        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.504        |\n",
            "|    n_updates            | 700          |\n",
            "|    policy_gradient_loss | -0.00159     |\n",
            "|    reward               | 0.2430148    |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.688        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 72           |\n",
            "|    time_elapsed         | 314          |\n",
            "|    total_timesteps      | 147456       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005239277  |\n",
            "|    clip_fraction        | 0.0423       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.09        |\n",
            "|    explained_variance   | 0.57         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.14         |\n",
            "|    n_updates            | 710          |\n",
            "|    policy_gradient_loss | -0.00131     |\n",
            "|    reward               | -0.026670175 |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 0.312        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 55\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -261476.04\n",
            "total_reward: -271476.04\n",
            "total_cost: 508.73\n",
            "total_trades: 3068\n",
            "Sharpe: 0.269\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 468           |\n",
            "|    iterations           | 73            |\n",
            "|    time_elapsed         | 319           |\n",
            "|    total_timesteps      | 149504        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0028582863  |\n",
            "|    clip_fraction        | 0.0215        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.09         |\n",
            "|    explained_variance   | 0.358         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.521         |\n",
            "|    n_updates            | 720           |\n",
            "|    policy_gradient_loss | -0.00174      |\n",
            "|    reward               | -0.0062237587 |\n",
            "|    std                  | 1.14          |\n",
            "|    value_loss           | 0.772         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 469          |\n",
            "|    iterations           | 74           |\n",
            "|    time_elapsed         | 323          |\n",
            "|    total_timesteps      | 151552       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0070900763 |\n",
            "|    clip_fraction        | 0.0818       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.1         |\n",
            "|    explained_variance   | 0.363        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.289        |\n",
            "|    n_updates            | 730          |\n",
            "|    policy_gradient_loss | -0.00482     |\n",
            "|    reward               | -0.23680006  |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 0.599        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 469          |\n",
            "|    iterations           | 75           |\n",
            "|    time_elapsed         | 327          |\n",
            "|    total_timesteps      | 153600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022931725 |\n",
            "|    clip_fraction        | 0.000439     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.09        |\n",
            "|    explained_variance   | 0.159        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.326        |\n",
            "|    n_updates            | 740          |\n",
            "|    policy_gradient_loss | -0.00106     |\n",
            "|    reward               | -0.7248635   |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 0.702        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 469          |\n",
            "|    iterations           | 76           |\n",
            "|    time_elapsed         | 331          |\n",
            "|    total_timesteps      | 155648       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012589766 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.09        |\n",
            "|    explained_variance   | 0.592        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0541       |\n",
            "|    n_updates            | 750          |\n",
            "|    policy_gradient_loss | -0.000257    |\n",
            "|    reward               | 0.01289321   |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 0.227        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 470          |\n",
            "|    iterations           | 77           |\n",
            "|    time_elapsed         | 335          |\n",
            "|    total_timesteps      | 157696       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006799745  |\n",
            "|    clip_fraction        | 0.0406       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.09        |\n",
            "|    explained_variance   | 0.274        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.394        |\n",
            "|    n_updates            | 760          |\n",
            "|    policy_gradient_loss | -0.0025      |\n",
            "|    reward               | 0.0055705765 |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 0.926        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 470         |\n",
            "|    iterations           | 78          |\n",
            "|    time_elapsed         | 339         |\n",
            "|    total_timesteps      | 159744      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004336671 |\n",
            "|    clip_fraction        | 0.0384      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.08       |\n",
            "|    explained_variance   | 0.304       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.45        |\n",
            "|    n_updates            | 770         |\n",
            "|    policy_gradient_loss | -0.00233    |\n",
            "|    reward               | 0.094948426 |\n",
            "|    std                  | 1.12        |\n",
            "|    value_loss           | 0.766       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 470          |\n",
            "|    iterations           | 79           |\n",
            "|    time_elapsed         | 343          |\n",
            "|    total_timesteps      | 161792       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005618855  |\n",
            "|    clip_fraction        | 0.0478       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.07        |\n",
            "|    explained_variance   | 0.172        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.223        |\n",
            "|    n_updates            | 780          |\n",
            "|    policy_gradient_loss | -0.00201     |\n",
            "|    reward               | -0.041646805 |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.834        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 60\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -350517.62\n",
            "total_reward: -360517.62\n",
            "total_cost: 555.29\n",
            "total_trades: 3290\n",
            "Sharpe: 0.466\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 471         |\n",
            "|    iterations           | 80          |\n",
            "|    time_elapsed         | 347         |\n",
            "|    total_timesteps      | 163840      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008089586 |\n",
            "|    clip_fraction        | 0.0258      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.07       |\n",
            "|    explained_variance   | 0.678       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0741      |\n",
            "|    n_updates            | 790         |\n",
            "|    policy_gradient_loss | -0.001      |\n",
            "|    reward               | -0.37058514 |\n",
            "|    std                  | 1.13        |\n",
            "|    value_loss           | 0.148       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 471          |\n",
            "|    iterations           | 81           |\n",
            "|    time_elapsed         | 351          |\n",
            "|    total_timesteps      | 165888       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005155487  |\n",
            "|    clip_fraction        | 0.021        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.29         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.525        |\n",
            "|    n_updates            | 800          |\n",
            "|    policy_gradient_loss | -0.000847    |\n",
            "|    reward               | -0.017305514 |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.982        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 471          |\n",
            "|    iterations           | 82           |\n",
            "|    time_elapsed         | 355          |\n",
            "|    total_timesteps      | 167936       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036257324 |\n",
            "|    clip_fraction        | 0.0298       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.34         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.482        |\n",
            "|    n_updates            | 810          |\n",
            "|    policy_gradient_loss | -0.00252     |\n",
            "|    reward               | 0.009876554  |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.821        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 472          |\n",
            "|    iterations           | 83           |\n",
            "|    time_elapsed         | 360          |\n",
            "|    total_timesteps      | 169984       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0003437362 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.07        |\n",
            "|    explained_variance   | 0.18         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.319        |\n",
            "|    n_updates            | 820          |\n",
            "|    policy_gradient_loss | -0.000265    |\n",
            "|    reward               | -0.029288348 |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.757        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 472          |\n",
            "|    iterations           | 84           |\n",
            "|    time_elapsed         | 364          |\n",
            "|    total_timesteps      | 172032       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033039886 |\n",
            "|    clip_fraction        | 0.0185       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.703        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0102       |\n",
            "|    n_updates            | 830          |\n",
            "|    policy_gradient_loss | -0.000307    |\n",
            "|    reward               | 0.03751931   |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.112        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 472           |\n",
            "|    iterations           | 85            |\n",
            "|    time_elapsed         | 368           |\n",
            "|    total_timesteps      | 174080        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.003224599   |\n",
            "|    clip_fraction        | 0.0284        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.08         |\n",
            "|    explained_variance   | 0.363         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.404         |\n",
            "|    n_updates            | 840           |\n",
            "|    policy_gradient_loss | -0.000976     |\n",
            "|    reward               | -0.0071037426 |\n",
            "|    std                  | 1.13          |\n",
            "|    value_loss           | 0.607         |\n",
            "-------------------------------------------\n",
            "day: 2707, episode: 65\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -328282.50\n",
            "total_reward: -338282.50\n",
            "total_cost: 535.07\n",
            "total_trades: 3132\n",
            "Sharpe: -0.152\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 472         |\n",
            "|    iterations           | 86          |\n",
            "|    time_elapsed         | 372         |\n",
            "|    total_timesteps      | 176128      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003720296 |\n",
            "|    clip_fraction        | 0.0255      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.07       |\n",
            "|    explained_variance   | 0.322       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.342       |\n",
            "|    n_updates            | 850         |\n",
            "|    policy_gradient_loss | -0.00219    |\n",
            "|    reward               | -0.00746427 |\n",
            "|    std                  | 1.12        |\n",
            "|    value_loss           | 0.858       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 473          |\n",
            "|    iterations           | 87           |\n",
            "|    time_elapsed         | 376          |\n",
            "|    total_timesteps      | 178176       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045968276 |\n",
            "|    clip_fraction        | 0.00547      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 0.197        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.341        |\n",
            "|    n_updates            | 860          |\n",
            "|    policy_gradient_loss | 0.000141     |\n",
            "|    reward               | -0.02728307  |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.956        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 473           |\n",
            "|    iterations           | 88            |\n",
            "|    time_elapsed         | 380           |\n",
            "|    total_timesteps      | 180224        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00029199748 |\n",
            "|    clip_fraction        | 0.00425       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.06         |\n",
            "|    explained_variance   | 0.66          |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0432        |\n",
            "|    n_updates            | 870           |\n",
            "|    policy_gradient_loss | -8.68e-05     |\n",
            "|    reward               | -0.24626075   |\n",
            "|    std                  | 1.12          |\n",
            "|    value_loss           | 0.186         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 473          |\n",
            "|    iterations           | 89           |\n",
            "|    time_elapsed         | 384          |\n",
            "|    total_timesteps      | 182272       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017432693 |\n",
            "|    clip_fraction        | 0.0241       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.06        |\n",
            "|    explained_variance   | 0.345        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.292        |\n",
            "|    n_updates            | 880          |\n",
            "|    policy_gradient_loss | 0.000629     |\n",
            "|    reward               | 0.007738347  |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.908        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 473          |\n",
            "|    iterations           | 90           |\n",
            "|    time_elapsed         | 388          |\n",
            "|    total_timesteps      | 184320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020107892 |\n",
            "|    clip_fraction        | 0.00937      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.376        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.382        |\n",
            "|    n_updates            | 890          |\n",
            "|    policy_gradient_loss | -0.000773    |\n",
            "|    reward               | -0.009914405 |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 0.926        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 474         |\n",
            "|    iterations           | 91          |\n",
            "|    time_elapsed         | 392         |\n",
            "|    total_timesteps      | 186368      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004390599 |\n",
            "|    clip_fraction        | 0.0631      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.1        |\n",
            "|    explained_variance   | 0.251       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.548       |\n",
            "|    n_updates            | 900         |\n",
            "|    policy_gradient_loss | -0.00319    |\n",
            "|    reward               | 0.09824663  |\n",
            "|    std                  | 1.15        |\n",
            "|    value_loss           | 0.903       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 474          |\n",
            "|    iterations           | 92           |\n",
            "|    time_elapsed         | 397          |\n",
            "|    total_timesteps      | 188416       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018608095 |\n",
            "|    clip_fraction        | 0.000635     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.11        |\n",
            "|    explained_variance   | 0.741        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.092        |\n",
            "|    n_updates            | 910          |\n",
            "|    policy_gradient_loss | -0.000234    |\n",
            "|    reward               | 0.12684296   |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 0.153        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 70\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -279627.18\n",
            "total_reward: -289627.18\n",
            "total_cost: 490.49\n",
            "total_trades: 3026\n",
            "Sharpe: 0.614\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 474          |\n",
            "|    iterations           | 93           |\n",
            "|    time_elapsed         | 401          |\n",
            "|    total_timesteps      | 190464       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030575227 |\n",
            "|    clip_fraction        | 0.00142      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.11        |\n",
            "|    explained_variance   | 0.47         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.48         |\n",
            "|    n_updates            | 920          |\n",
            "|    policy_gradient_loss | -5.58e-05    |\n",
            "|    reward               | 0.01826837   |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 0.537        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 474          |\n",
            "|    iterations           | 94           |\n",
            "|    time_elapsed         | 406          |\n",
            "|    total_timesteps      | 192512       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004460755  |\n",
            "|    clip_fraction        | 0.0296       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.12        |\n",
            "|    explained_variance   | 0.459        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.338        |\n",
            "|    n_updates            | 930          |\n",
            "|    policy_gradient_loss | -0.00111     |\n",
            "|    reward               | -0.024929056 |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 0.646        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 473          |\n",
            "|    iterations           | 95           |\n",
            "|    time_elapsed         | 410          |\n",
            "|    total_timesteps      | 194560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032144138 |\n",
            "|    clip_fraction        | 0.00371      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.12        |\n",
            "|    explained_variance   | -0.0461      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.304        |\n",
            "|    n_updates            | 940          |\n",
            "|    policy_gradient_loss | -0.000392    |\n",
            "|    reward               | 0.007817033  |\n",
            "|    std                  | 1.16         |\n",
            "|    value_loss           | 1.03         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 473         |\n",
            "|    iterations           | 96          |\n",
            "|    time_elapsed         | 414         |\n",
            "|    total_timesteps      | 196608      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003858183 |\n",
            "|    clip_fraction        | 0.019       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.13       |\n",
            "|    explained_variance   | 0.345       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.083       |\n",
            "|    n_updates            | 950         |\n",
            "|    policy_gradient_loss | -0.00138    |\n",
            "|    reward               | 0.11756522  |\n",
            "|    std                  | 1.17        |\n",
            "|    value_loss           | 0.228       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 473          |\n",
            "|    iterations           | 97           |\n",
            "|    time_elapsed         | 419          |\n",
            "|    total_timesteps      | 198656       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.007316347  |\n",
            "|    clip_fraction        | 0.0647       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.14        |\n",
            "|    explained_variance   | 0.229        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.241        |\n",
            "|    n_updates            | 960          |\n",
            "|    policy_gradient_loss | -0.00385     |\n",
            "|    reward               | -0.062703185 |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 0.684        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 474          |\n",
            "|    iterations           | 98           |\n",
            "|    time_elapsed         | 423          |\n",
            "|    total_timesteps      | 200704       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017453063 |\n",
            "|    clip_fraction        | 0.0109       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.15        |\n",
            "|    explained_variance   | 0.266        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.395        |\n",
            "|    n_updates            | 970          |\n",
            "|    policy_gradient_loss | -0.00043     |\n",
            "|    reward               | -0.006259053 |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 0.843        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 473          |\n",
            "|    iterations           | 99           |\n",
            "|    time_elapsed         | 427          |\n",
            "|    total_timesteps      | 202752       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046144966 |\n",
            "|    clip_fraction        | 0.0531       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.16        |\n",
            "|    explained_variance   | 0.174        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.419        |\n",
            "|    n_updates            | 980          |\n",
            "|    policy_gradient_loss | -0.00287     |\n",
            "|    reward               | -0.4451027   |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 0.903        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 75\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -320149.04\n",
            "total_reward: -330149.04\n",
            "total_cost: 577.95\n",
            "total_trades: 3092\n",
            "Sharpe: 0.354\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 473          |\n",
            "|    iterations           | 100          |\n",
            "|    time_elapsed         | 432          |\n",
            "|    total_timesteps      | 204800       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028567957 |\n",
            "|    clip_fraction        | 0.00596      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.16        |\n",
            "|    explained_variance   | 0.434        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0988       |\n",
            "|    n_updates            | 990          |\n",
            "|    policy_gradient_loss | -0.000656    |\n",
            "|    reward               | 0.1990206    |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 0.31         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 473          |\n",
            "|    iterations           | 101          |\n",
            "|    time_elapsed         | 436          |\n",
            "|    total_timesteps      | 206848       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026348755 |\n",
            "|    clip_fraction        | 0.00278      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.16        |\n",
            "|    explained_variance   | 0.346        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.268        |\n",
            "|    n_updates            | 1000         |\n",
            "|    policy_gradient_loss | -0.000881    |\n",
            "|    reward               | 0.033833254  |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 0.667        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 473          |\n",
            "|    iterations           | 102          |\n",
            "|    time_elapsed         | 441          |\n",
            "|    total_timesteps      | 208896       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012612527 |\n",
            "|    clip_fraction        | 4.88e-05     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.16        |\n",
            "|    explained_variance   | 0.188        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.374        |\n",
            "|    n_updates            | 1010         |\n",
            "|    policy_gradient_loss | -0.000572    |\n",
            "|    reward               | 0.026786705  |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 1.21         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 473          |\n",
            "|    iterations           | 103          |\n",
            "|    time_elapsed         | 445          |\n",
            "|    total_timesteps      | 210944       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042959396 |\n",
            "|    clip_fraction        | 0.0394       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.16        |\n",
            "|    explained_variance   | 0.187        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.552        |\n",
            "|    n_updates            | 1020         |\n",
            "|    policy_gradient_loss | -0.00369     |\n",
            "|    reward               | -0.36677635  |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 1.15         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 473         |\n",
            "|    iterations           | 104         |\n",
            "|    time_elapsed         | 449         |\n",
            "|    total_timesteps      | 212992      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004220975 |\n",
            "|    clip_fraction        | 0.0145      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.16       |\n",
            "|    explained_variance   | 0.378       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.202       |\n",
            "|    n_updates            | 1030        |\n",
            "|    policy_gradient_loss | -0.00131    |\n",
            "|    reward               | 0.017339686 |\n",
            "|    std                  | 1.18        |\n",
            "|    value_loss           | 0.447       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 473          |\n",
            "|    iterations           | 105          |\n",
            "|    time_elapsed         | 454          |\n",
            "|    total_timesteps      | 215040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017809008 |\n",
            "|    clip_fraction        | 0.000342     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.16        |\n",
            "|    explained_variance   | 0.354        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.356        |\n",
            "|    n_updates            | 1040         |\n",
            "|    policy_gradient_loss | -0.000774    |\n",
            "|    reward               | -0.008798299 |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 0.856        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 80\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -410964.70\n",
            "total_reward: -420964.70\n",
            "total_cost: 585.91\n",
            "total_trades: 3420\n",
            "Sharpe: 0.117\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 473          |\n",
            "|    iterations           | 106          |\n",
            "|    time_elapsed         | 458          |\n",
            "|    total_timesteps      | 217088       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.003186394  |\n",
            "|    clip_fraction        | 0.00195      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.16        |\n",
            "|    explained_variance   | 0.284        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.824        |\n",
            "|    n_updates            | 1050         |\n",
            "|    policy_gradient_loss | -0.000895    |\n",
            "|    reward               | -0.014375784 |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 1.31         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 473         |\n",
            "|    iterations           | 107         |\n",
            "|    time_elapsed         | 462         |\n",
            "|    total_timesteps      | 219136      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005814115 |\n",
            "|    clip_fraction        | 0.0508      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.17       |\n",
            "|    explained_variance   | 0.225       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.881       |\n",
            "|    n_updates            | 1060        |\n",
            "|    policy_gradient_loss | -0.00272    |\n",
            "|    reward               | 1.220567    |\n",
            "|    std                  | 1.19        |\n",
            "|    value_loss           | 1.49        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 473          |\n",
            "|    iterations           | 108          |\n",
            "|    time_elapsed         | 467          |\n",
            "|    total_timesteps      | 221184       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050471737 |\n",
            "|    clip_fraction        | 0.0177       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.18        |\n",
            "|    explained_variance   | 0.373        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.371        |\n",
            "|    n_updates            | 1070         |\n",
            "|    policy_gradient_loss | -0.000366    |\n",
            "|    reward               | -0.14224127  |\n",
            "|    std                  | 1.19         |\n",
            "|    value_loss           | 0.6          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 473          |\n",
            "|    iterations           | 109          |\n",
            "|    time_elapsed         | 471          |\n",
            "|    total_timesteps      | 223232       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020467746 |\n",
            "|    clip_fraction        | 0.00151      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.18        |\n",
            "|    explained_variance   | 0.527        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.126        |\n",
            "|    n_updates            | 1080         |\n",
            "|    policy_gradient_loss | -0.00139     |\n",
            "|    reward               | -0.06754015  |\n",
            "|    std                  | 1.19         |\n",
            "|    value_loss           | 0.707        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 473          |\n",
            "|    iterations           | 110          |\n",
            "|    time_elapsed         | 476          |\n",
            "|    total_timesteps      | 225280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006424997  |\n",
            "|    clip_fraction        | 0.019        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.18        |\n",
            "|    explained_variance   | 0.328        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.696        |\n",
            "|    n_updates            | 1090         |\n",
            "|    policy_gradient_loss | -0.00116     |\n",
            "|    reward               | 0.0076655247 |\n",
            "|    std                  | 1.19         |\n",
            "|    value_loss           | 1.55         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 473          |\n",
            "|    iterations           | 111          |\n",
            "|    time_elapsed         | 480          |\n",
            "|    total_timesteps      | 227328       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049868263 |\n",
            "|    clip_fraction        | 0.0316       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.17        |\n",
            "|    explained_variance   | 0.0877       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.713        |\n",
            "|    n_updates            | 1100         |\n",
            "|    policy_gradient_loss | -0.00154     |\n",
            "|    reward               | 0.30908802   |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 2.03         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 473          |\n",
            "|    iterations           | 112          |\n",
            "|    time_elapsed         | 484          |\n",
            "|    total_timesteps      | 229376       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032504862 |\n",
            "|    clip_fraction        | 0.00937      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.16        |\n",
            "|    explained_variance   | -0.124       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.276        |\n",
            "|    n_updates            | 1110         |\n",
            "|    policy_gradient_loss | -0.0012      |\n",
            "|    reward               | -0.00142194  |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 1.5          |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 85\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -436840.99\n",
            "total_reward: -446840.99\n",
            "total_cost: 680.73\n",
            "total_trades: 3412\n",
            "Sharpe: 0.472\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 473          |\n",
            "|    iterations           | 113          |\n",
            "|    time_elapsed         | 489          |\n",
            "|    total_timesteps      | 231424       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055865096 |\n",
            "|    clip_fraction        | 0.0292       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.16        |\n",
            "|    explained_variance   | 0.303        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.172        |\n",
            "|    n_updates            | 1120         |\n",
            "|    policy_gradient_loss | -0.0012      |\n",
            "|    reward               | -0.07705057  |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 0.462        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 473           |\n",
            "|    iterations           | 114           |\n",
            "|    time_elapsed         | 493           |\n",
            "|    total_timesteps      | 233472        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0029748227  |\n",
            "|    clip_fraction        | 0.00659       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.16         |\n",
            "|    explained_variance   | 0.00371       |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.393         |\n",
            "|    n_updates            | 1130          |\n",
            "|    policy_gradient_loss | -0.000925     |\n",
            "|    reward               | -0.0062555373 |\n",
            "|    std                  | 1.18          |\n",
            "|    value_loss           | 1.45          |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 472         |\n",
            "|    iterations           | 115         |\n",
            "|    time_elapsed         | 498         |\n",
            "|    total_timesteps      | 235520      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005203109 |\n",
            "|    clip_fraction        | 0.026       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.15       |\n",
            "|    explained_variance   | 0.067       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.22        |\n",
            "|    n_updates            | 1140        |\n",
            "|    policy_gradient_loss | -0.00189    |\n",
            "|    reward               | -0.7246207  |\n",
            "|    std                  | 1.17        |\n",
            "|    value_loss           | 1.43        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 472          |\n",
            "|    iterations           | 116          |\n",
            "|    time_elapsed         | 502          |\n",
            "|    total_timesteps      | 237568       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032673588 |\n",
            "|    clip_fraction        | 0.00186      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.14        |\n",
            "|    explained_variance   | 0.0127       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.841        |\n",
            "|    n_updates            | 1150         |\n",
            "|    policy_gradient_loss | -0.00019     |\n",
            "|    reward               | -0.7217727   |\n",
            "|    std                  | 1.17         |\n",
            "|    value_loss           | 1.75         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 472          |\n",
            "|    iterations           | 117          |\n",
            "|    time_elapsed         | 506          |\n",
            "|    total_timesteps      | 239616       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053316797 |\n",
            "|    clip_fraction        | 0.0372       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.14        |\n",
            "|    explained_variance   | 0.0955       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.199        |\n",
            "|    n_updates            | 1160         |\n",
            "|    policy_gradient_loss | -0.00236     |\n",
            "|    reward               | -0.14218786  |\n",
            "|    std                  | 1.17         |\n",
            "|    value_loss           | 0.468        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 472          |\n",
            "|    iterations           | 118          |\n",
            "|    time_elapsed         | 511          |\n",
            "|    total_timesteps      | 241664       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004349769  |\n",
            "|    clip_fraction        | 0.0143       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.14        |\n",
            "|    explained_variance   | 0.00131      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.3          |\n",
            "|    n_updates            | 1170         |\n",
            "|    policy_gradient_loss | -0.00115     |\n",
            "|    reward               | -0.047194008 |\n",
            "|    std                  | 1.16         |\n",
            "|    value_loss           | 2.13         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 472          |\n",
            "|    iterations           | 119          |\n",
            "|    time_elapsed         | 515          |\n",
            "|    total_timesteps      | 243712       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021890928 |\n",
            "|    clip_fraction        | 0.00918      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.14        |\n",
            "|    explained_variance   | -0.0176      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.859        |\n",
            "|    n_updates            | 1180         |\n",
            "|    policy_gradient_loss | -1.37e-05    |\n",
            "|    reward               | 0.9129171    |\n",
            "|    std                  | 1.17         |\n",
            "|    value_loss           | 2.22         |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 90\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -446220.05\n",
            "total_reward: -456220.05\n",
            "total_cost: 688.43\n",
            "total_trades: 3538\n",
            "Sharpe: 0.013\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 472          |\n",
            "|    iterations           | 120          |\n",
            "|    time_elapsed         | 520          |\n",
            "|    total_timesteps      | 245760       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.372443e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.14        |\n",
            "|    explained_variance   | 0.00669      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.677        |\n",
            "|    n_updates            | 1190         |\n",
            "|    policy_gradient_loss | 0.000142     |\n",
            "|    reward               | 0.066630565  |\n",
            "|    std                  | 1.17         |\n",
            "|    value_loss           | 1.67         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 472          |\n",
            "|    iterations           | 121          |\n",
            "|    time_elapsed         | 524          |\n",
            "|    total_timesteps      | 247808       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032462082 |\n",
            "|    clip_fraction        | 0.0176       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.14        |\n",
            "|    explained_variance   | -0.0138      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0533       |\n",
            "|    n_updates            | 1200         |\n",
            "|    policy_gradient_loss | -0.000941    |\n",
            "|    reward               | 0.08626723   |\n",
            "|    std                  | 1.17         |\n",
            "|    value_loss           | 0.138        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 472          |\n",
            "|    iterations           | 122          |\n",
            "|    time_elapsed         | 529          |\n",
            "|    total_timesteps      | 249856       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041126697 |\n",
            "|    clip_fraction        | 0.0199       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.15        |\n",
            "|    explained_variance   | -4.17e-06    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.638        |\n",
            "|    n_updates            | 1210         |\n",
            "|    policy_gradient_loss | -0.00116     |\n",
            "|    reward               | 0.0017321659 |\n",
            "|    std                  | 1.17         |\n",
            "|    value_loss           | 1.3          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 472          |\n",
            "|    iterations           | 123          |\n",
            "|    time_elapsed         | 533          |\n",
            "|    total_timesteps      | 251904       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005032421  |\n",
            "|    clip_fraction        | 0.0227       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.15        |\n",
            "|    explained_variance   | 4.59e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.1          |\n",
            "|    n_updates            | 1220         |\n",
            "|    policy_gradient_loss | -0.00143     |\n",
            "|    reward               | 0.0016787107 |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 1.46         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 471          |\n",
            "|    iterations           | 124          |\n",
            "|    time_elapsed         | 538          |\n",
            "|    total_timesteps      | 253952       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059149396 |\n",
            "|    clip_fraction        | 0.0434       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.14        |\n",
            "|    explained_variance   | 4.07e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.783        |\n",
            "|    n_updates            | 1230         |\n",
            "|    policy_gradient_loss | -0.00377     |\n",
            "|    reward               | 0.06588309   |\n",
            "|    std                  | 1.16         |\n",
            "|    value_loss           | 1.25         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 471         |\n",
            "|    iterations           | 125         |\n",
            "|    time_elapsed         | 543         |\n",
            "|    total_timesteps      | 256000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003427178 |\n",
            "|    clip_fraction        | 0.0158      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.13       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0347      |\n",
            "|    n_updates            | 1240        |\n",
            "|    policy_gradient_loss | -0.000758   |\n",
            "|    reward               | 0.12274679  |\n",
            "|    std                  | 1.16        |\n",
            "|    value_loss           | 0.154       |\n",
            "-----------------------------------------\n",
            "day: 2707, episode: 95\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -352097.72\n",
            "total_reward: -362097.72\n",
            "total_cost: 537.49\n",
            "total_trades: 3152\n",
            "Sharpe: 0.561\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 470           |\n",
            "|    iterations           | 126           |\n",
            "|    time_elapsed         | 548           |\n",
            "|    total_timesteps      | 258048        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0032864555  |\n",
            "|    clip_fraction        | 0.0211        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.14         |\n",
            "|    explained_variance   | 4.68e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.462         |\n",
            "|    n_updates            | 1250          |\n",
            "|    policy_gradient_loss | -0.00155      |\n",
            "|    reward               | -0.0057472596 |\n",
            "|    std                  | 1.17          |\n",
            "|    value_loss           | 0.863         |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 470         |\n",
            "|    iterations           | 127         |\n",
            "|    time_elapsed         | 553         |\n",
            "|    total_timesteps      | 260096      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006417394 |\n",
            "|    clip_fraction        | 0.0693      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.15       |\n",
            "|    explained_variance   | 3.06e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.4         |\n",
            "|    n_updates            | 1260        |\n",
            "|    policy_gradient_loss | -0.00409    |\n",
            "|    reward               | 0.029863555 |\n",
            "|    std                  | 1.17        |\n",
            "|    value_loss           | 1.08        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 469          |\n",
            "|    iterations           | 128          |\n",
            "|    time_elapsed         | 558          |\n",
            "|    total_timesteps      | 262144       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038918764 |\n",
            "|    clip_fraction        | 0.0214       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.14        |\n",
            "|    explained_variance   | 5.04e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.385        |\n",
            "|    n_updates            | 1270         |\n",
            "|    policy_gradient_loss | -0.0019      |\n",
            "|    reward               | 0.0936713    |\n",
            "|    std                  | 1.17         |\n",
            "|    value_loss           | 0.856        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 129          |\n",
            "|    time_elapsed         | 563          |\n",
            "|    total_timesteps      | 264192       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045300084 |\n",
            "|    clip_fraction        | 0.0334       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.15        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0516       |\n",
            "|    n_updates            | 1280         |\n",
            "|    policy_gradient_loss | -0.00146     |\n",
            "|    reward               | 0.031108975  |\n",
            "|    std                  | 1.17         |\n",
            "|    value_loss           | 0.175        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 130          |\n",
            "|    time_elapsed         | 567          |\n",
            "|    total_timesteps      | 266240       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056175147 |\n",
            "|    clip_fraction        | 0.0358       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.14        |\n",
            "|    explained_variance   | 1.72e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.508        |\n",
            "|    n_updates            | 1290         |\n",
            "|    policy_gradient_loss | -0.0026      |\n",
            "|    reward               | -0.021636108 |\n",
            "|    std                  | 1.16         |\n",
            "|    value_loss           | 0.907        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 131          |\n",
            "|    time_elapsed         | 572          |\n",
            "|    total_timesteps      | 268288       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030281246 |\n",
            "|    clip_fraction        | 0.0153       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.14        |\n",
            "|    explained_variance   | 2.44e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.377        |\n",
            "|    n_updates            | 1300         |\n",
            "|    policy_gradient_loss | -0.000877    |\n",
            "|    reward               | -0.017783554 |\n",
            "|    std                  | 1.16         |\n",
            "|    value_loss           | 1.01         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 468         |\n",
            "|    iterations           | 132         |\n",
            "|    time_elapsed         | 576         |\n",
            "|    total_timesteps      | 270336      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005447126 |\n",
            "|    clip_fraction        | 0.0533      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.13       |\n",
            "|    explained_variance   | 5.33e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.901       |\n",
            "|    n_updates            | 1310        |\n",
            "|    policy_gradient_loss | -0.00331    |\n",
            "|    reward               | -0.19159059 |\n",
            "|    std                  | 1.16        |\n",
            "|    value_loss           | 1.1         |\n",
            "-----------------------------------------\n",
            "day: 2707, episode: 100\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -362943.04\n",
            "total_reward: -372943.04\n",
            "total_cost: 559.37\n",
            "total_trades: 3204\n",
            "Sharpe: -0.085\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 133          |\n",
            "|    time_elapsed         | 581          |\n",
            "|    total_timesteps      | 272384       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054320027 |\n",
            "|    clip_fraction        | 0.0394       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.12        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0654       |\n",
            "|    n_updates            | 1320         |\n",
            "|    policy_gradient_loss | -0.00218     |\n",
            "|    reward               | -0.061018184 |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 0.248        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 134          |\n",
            "|    time_elapsed         | 585          |\n",
            "|    total_timesteps      | 274432       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005527231  |\n",
            "|    clip_fraction        | 0.042        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.12        |\n",
            "|    explained_variance   | 6.74e-06     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.443        |\n",
            "|    n_updates            | 1330         |\n",
            "|    policy_gradient_loss | -0.00213     |\n",
            "|    reward               | -0.006371675 |\n",
            "|    std                  | 1.16         |\n",
            "|    value_loss           | 0.98         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 135          |\n",
            "|    time_elapsed         | 589          |\n",
            "|    total_timesteps      | 276480       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038612923 |\n",
            "|    clip_fraction        | 0.0181       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.14        |\n",
            "|    explained_variance   | 4.95e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.423        |\n",
            "|    n_updates            | 1340         |\n",
            "|    policy_gradient_loss | -0.00119     |\n",
            "|    reward               | 0.023026599  |\n",
            "|    std                  | 1.17         |\n",
            "|    value_loss           | 0.823        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 136          |\n",
            "|    time_elapsed         | 594          |\n",
            "|    total_timesteps      | 278528       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038662935 |\n",
            "|    clip_fraction        | 0.0125       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.13        |\n",
            "|    explained_variance   | 6.1e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.386        |\n",
            "|    n_updates            | 1350         |\n",
            "|    policy_gradient_loss | -0.000712    |\n",
            "|    reward               | -0.41800225  |\n",
            "|    std                  | 1.16         |\n",
            "|    value_loss           | 0.928        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 137          |\n",
            "|    time_elapsed         | 598          |\n",
            "|    total_timesteps      | 280576       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035378481 |\n",
            "|    clip_fraction        | 0.00996      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.13        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.12         |\n",
            "|    n_updates            | 1360         |\n",
            "|    policy_gradient_loss | -0.000718    |\n",
            "|    reward               | 0.028865753  |\n",
            "|    std                  | 1.16         |\n",
            "|    value_loss           | 0.251        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 138          |\n",
            "|    time_elapsed         | 602          |\n",
            "|    total_timesteps      | 282624       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006007352  |\n",
            "|    clip_fraction        | 0.0548       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.14        |\n",
            "|    explained_variance   | 3.44e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.168        |\n",
            "|    n_updates            | 1370         |\n",
            "|    policy_gradient_loss | -0.00363     |\n",
            "|    reward               | -0.039426796 |\n",
            "|    std                  | 1.17         |\n",
            "|    value_loss           | 0.612        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 105\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -322225.20\n",
            "total_reward: -332225.20\n",
            "total_cost: 535.93\n",
            "total_trades: 3136\n",
            "Sharpe: 0.316\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 468         |\n",
            "|    iterations           | 139         |\n",
            "|    time_elapsed         | 607         |\n",
            "|    total_timesteps      | 284672      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002254962 |\n",
            "|    clip_fraction        | 0.00801     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.15       |\n",
            "|    explained_variance   | 2.62e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.423       |\n",
            "|    n_updates            | 1380        |\n",
            "|    policy_gradient_loss | -0.000762   |\n",
            "|    reward               | 0.00912533  |\n",
            "|    std                  | 1.18        |\n",
            "|    value_loss           | 0.908       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 140          |\n",
            "|    time_elapsed         | 611          |\n",
            "|    total_timesteps      | 286720       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024994481 |\n",
            "|    clip_fraction        | 0.00488      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.16        |\n",
            "|    explained_variance   | 4.66e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.502        |\n",
            "|    n_updates            | 1390         |\n",
            "|    policy_gradient_loss | -0.000114    |\n",
            "|    reward               | 0.14536068   |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 0.923        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 141          |\n",
            "|    time_elapsed         | 616          |\n",
            "|    total_timesteps      | 288768       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0007921553 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.17        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0914       |\n",
            "|    n_updates            | 1400         |\n",
            "|    policy_gradient_loss | 3.02e-05     |\n",
            "|    reward               | 0.19516951   |\n",
            "|    std                  | 1.19         |\n",
            "|    value_loss           | 0.3          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 468         |\n",
            "|    iterations           | 142         |\n",
            "|    time_elapsed         | 620         |\n",
            "|    total_timesteps      | 290816      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004742882 |\n",
            "|    clip_fraction        | 0.0227      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.17       |\n",
            "|    explained_variance   | 1.93e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.256       |\n",
            "|    n_updates            | 1410        |\n",
            "|    policy_gradient_loss | -0.00134    |\n",
            "|    reward               | 0.00667442  |\n",
            "|    std                  | 1.18        |\n",
            "|    value_loss           | 0.657       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 143          |\n",
            "|    time_elapsed         | 624          |\n",
            "|    total_timesteps      | 292864       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044007525 |\n",
            "|    clip_fraction        | 0.00977      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.16        |\n",
            "|    explained_variance   | 2.06e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.262        |\n",
            "|    n_updates            | 1420         |\n",
            "|    policy_gradient_loss | -0.000644    |\n",
            "|    reward               | 0.03445074   |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 0.828        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 468         |\n",
            "|    iterations           | 144         |\n",
            "|    time_elapsed         | 629         |\n",
            "|    total_timesteps      | 294912      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005393251 |\n",
            "|    clip_fraction        | 0.0451      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.16       |\n",
            "|    explained_variance   | 3.47e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.487       |\n",
            "|    n_updates            | 1430        |\n",
            "|    policy_gradient_loss | -0.00355    |\n",
            "|    reward               | 0.18251032  |\n",
            "|    std                  | 1.18        |\n",
            "|    value_loss           | 1.37        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 145          |\n",
            "|    time_elapsed         | 633          |\n",
            "|    total_timesteps      | 296960       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031601149 |\n",
            "|    clip_fraction        | 0.00669      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.16        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.138        |\n",
            "|    n_updates            | 1440         |\n",
            "|    policy_gradient_loss | -0.000119    |\n",
            "|    reward               | -0.23972166  |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 0.392        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 110\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -394280.57\n",
            "total_reward: -404280.57\n",
            "total_cost: 616.20\n",
            "total_trades: 3316\n",
            "Sharpe: 0.354\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 146          |\n",
            "|    time_elapsed         | 638          |\n",
            "|    total_timesteps      | 299008       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023423643 |\n",
            "|    clip_fraction        | 0.0168       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.17        |\n",
            "|    explained_variance   | 3.48e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.464        |\n",
            "|    n_updates            | 1450         |\n",
            "|    policy_gradient_loss | -0.00107     |\n",
            "|    reward               | -0.06270011  |\n",
            "|    std                  | 1.19         |\n",
            "|    value_loss           | 0.9          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 147          |\n",
            "|    time_elapsed         | 642          |\n",
            "|    total_timesteps      | 301056       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039153104 |\n",
            "|    clip_fraction        | 0.0254       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.19        |\n",
            "|    explained_variance   | 2.18e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.409        |\n",
            "|    n_updates            | 1460         |\n",
            "|    policy_gradient_loss | -0.00167     |\n",
            "|    reward               | -0.008325737 |\n",
            "|    std                  | 1.2          |\n",
            "|    value_loss           | 1.41         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 148          |\n",
            "|    time_elapsed         | 646          |\n",
            "|    total_timesteps      | 303104       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0057824543 |\n",
            "|    clip_fraction        | 0.0199       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.19        |\n",
            "|    explained_variance   | 5.01e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.95         |\n",
            "|    n_updates            | 1470         |\n",
            "|    policy_gradient_loss | -0.00123     |\n",
            "|    reward               | 0.35189575   |\n",
            "|    std                  | 1.19         |\n",
            "|    value_loss           | 1.07         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 468         |\n",
            "|    iterations           | 149         |\n",
            "|    time_elapsed         | 651         |\n",
            "|    total_timesteps      | 305152      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008213634 |\n",
            "|    clip_fraction        | 0.0907      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.18       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.235       |\n",
            "|    n_updates            | 1480        |\n",
            "|    policy_gradient_loss | -0.00737    |\n",
            "|    reward               | -0.20303747 |\n",
            "|    std                  | 1.19        |\n",
            "|    value_loss           | 0.914       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 468         |\n",
            "|    iterations           | 150         |\n",
            "|    time_elapsed         | 655         |\n",
            "|    total_timesteps      | 307200      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003305941 |\n",
            "|    clip_fraction        | 0.00566     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.19       |\n",
            "|    explained_variance   | 0.000108    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.251       |\n",
            "|    n_updates            | 1490        |\n",
            "|    policy_gradient_loss | -7.55e-05   |\n",
            "|    reward               | 0.014310724 |\n",
            "|    std                  | 1.2         |\n",
            "|    value_loss           | 0.525       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 151          |\n",
            "|    time_elapsed         | 660          |\n",
            "|    total_timesteps      | 309248       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044729738 |\n",
            "|    clip_fraction        | 0.0223       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.19        |\n",
            "|    explained_variance   | 2.19e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.539        |\n",
            "|    n_updates            | 1500         |\n",
            "|    policy_gradient_loss | -0.00152     |\n",
            "|    reward               | 0.009877157  |\n",
            "|    std                  | 1.2          |\n",
            "|    value_loss           | 1.17         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 468           |\n",
            "|    iterations           | 152           |\n",
            "|    time_elapsed         | 664           |\n",
            "|    total_timesteps      | 311296        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00069981103 |\n",
            "|    clip_fraction        | 0.000586      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.18         |\n",
            "|    explained_variance   | 4.91e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.571         |\n",
            "|    n_updates            | 1510          |\n",
            "|    policy_gradient_loss | -0.000727     |\n",
            "|    reward               | -0.7102251    |\n",
            "|    std                  | 1.19          |\n",
            "|    value_loss           | 1.06          |\n",
            "-------------------------------------------\n",
            "day: 2707, episode: 115\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -376482.12\n",
            "total_reward: -386482.12\n",
            "total_cost: 710.60\n",
            "total_trades: 3272\n",
            "Sharpe: 0.516\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 468         |\n",
            "|    iterations           | 153         |\n",
            "|    time_elapsed         | 668         |\n",
            "|    total_timesteps      | 313344      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007136115 |\n",
            "|    clip_fraction        | 0.0696      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.17       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.293       |\n",
            "|    n_updates            | 1520        |\n",
            "|    policy_gradient_loss | -0.00618    |\n",
            "|    reward               | -0.19912648 |\n",
            "|    std                  | 1.19        |\n",
            "|    value_loss           | 0.863       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 468         |\n",
            "|    iterations           | 154         |\n",
            "|    time_elapsed         | 673         |\n",
            "|    total_timesteps      | 315392      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004250994 |\n",
            "|    clip_fraction        | 0.0378      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.19       |\n",
            "|    explained_variance   | 0.000103    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.219       |\n",
            "|    n_updates            | 1530        |\n",
            "|    policy_gradient_loss | -0.00185    |\n",
            "|    reward               | 0.006890335 |\n",
            "|    std                  | 1.2         |\n",
            "|    value_loss           | 0.43        |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 468           |\n",
            "|    iterations           | 155           |\n",
            "|    time_elapsed         | 677           |\n",
            "|    total_timesteps      | 317440        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0046745734  |\n",
            "|    clip_fraction        | 0.0426        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.19         |\n",
            "|    explained_variance   | 2.34e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.253         |\n",
            "|    n_updates            | 1540          |\n",
            "|    policy_gradient_loss | -0.00198      |\n",
            "|    reward               | -0.0056361207 |\n",
            "|    std                  | 1.2           |\n",
            "|    value_loss           | 0.796         |\n",
            "-------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 468        |\n",
            "|    iterations           | 156        |\n",
            "|    time_elapsed         | 681        |\n",
            "|    total_timesteps      | 319488     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00561349 |\n",
            "|    clip_fraction        | 0.0251     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.2       |\n",
            "|    explained_variance   | 2.88e-05   |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 0.793      |\n",
            "|    n_updates            | 1550       |\n",
            "|    policy_gradient_loss | -0.00146   |\n",
            "|    reward               | 0.08940825 |\n",
            "|    std                  | 1.21       |\n",
            "|    value_loss           | 0.81       |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 157          |\n",
            "|    time_elapsed         | 686          |\n",
            "|    total_timesteps      | 321536       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021937552 |\n",
            "|    clip_fraction        | 0.0123       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.21        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.213        |\n",
            "|    n_updates            | 1560         |\n",
            "|    policy_gradient_loss | -0.0015      |\n",
            "|    reward               | 0.20228696   |\n",
            "|    std                  | 1.22         |\n",
            "|    value_loss           | 0.695        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 468         |\n",
            "|    iterations           | 158         |\n",
            "|    time_elapsed         | 690         |\n",
            "|    total_timesteps      | 323584      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006477075 |\n",
            "|    clip_fraction        | 0.0555      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.22       |\n",
            "|    explained_variance   | 0.000105    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0344      |\n",
            "|    n_updates            | 1570        |\n",
            "|    policy_gradient_loss | -0.00297    |\n",
            "|    reward               | 0.04736434  |\n",
            "|    std                  | 1.22        |\n",
            "|    value_loss           | 0.181       |\n",
            "-----------------------------------------\n",
            "day: 2707, episode: 120\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -297589.04\n",
            "total_reward: -307589.04\n",
            "total_cost: 498.17\n",
            "total_trades: 3016\n",
            "Sharpe: 0.235\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 159          |\n",
            "|    time_elapsed         | 695          |\n",
            "|    total_timesteps      | 325632       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046427734 |\n",
            "|    clip_fraction        | 0.0164       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.22        |\n",
            "|    explained_variance   | 4.7e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.287        |\n",
            "|    n_updates            | 1580         |\n",
            "|    policy_gradient_loss | -0.00126     |\n",
            "|    reward               | 0.0005418477 |\n",
            "|    std                  | 1.22         |\n",
            "|    value_loss           | 0.72         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 468           |\n",
            "|    iterations           | 160           |\n",
            "|    time_elapsed         | 699           |\n",
            "|    total_timesteps      | 327680        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0056018927  |\n",
            "|    clip_fraction        | 0.0587        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.23         |\n",
            "|    explained_variance   | 5.33e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.325         |\n",
            "|    n_updates            | 1590          |\n",
            "|    policy_gradient_loss | -0.00484      |\n",
            "|    reward               | -0.0004362669 |\n",
            "|    std                  | 1.23          |\n",
            "|    value_loss           | 0.785         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 161          |\n",
            "|    time_elapsed         | 703          |\n",
            "|    total_timesteps      | 329728       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049512773 |\n",
            "|    clip_fraction        | 0.0415       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.23        |\n",
            "|    explained_variance   | 2.14e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.501        |\n",
            "|    n_updates            | 1600         |\n",
            "|    policy_gradient_loss | -0.00402     |\n",
            "|    reward               | -0.0781705   |\n",
            "|    std                  | 1.23         |\n",
            "|    value_loss           | 0.987        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 162          |\n",
            "|    time_elapsed         | 708          |\n",
            "|    total_timesteps      | 331776       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032733185 |\n",
            "|    clip_fraction        | 0.00933      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.24        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00481     |\n",
            "|    n_updates            | 1610         |\n",
            "|    policy_gradient_loss | -0.000686    |\n",
            "|    reward               | -0.24581896  |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 0.0932       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 163          |\n",
            "|    time_elapsed         | 712          |\n",
            "|    total_timesteps      | 333824       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005443192  |\n",
            "|    clip_fraction        | 0.0293       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.26        |\n",
            "|    explained_variance   | 2.59e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.28         |\n",
            "|    n_updates            | 1620         |\n",
            "|    policy_gradient_loss | -0.00227     |\n",
            "|    reward               | -0.003519261 |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.753        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 468         |\n",
            "|    iterations           | 164         |\n",
            "|    time_elapsed         | 717         |\n",
            "|    total_timesteps      | 335872      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006026443 |\n",
            "|    clip_fraction        | 0.0406      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.26       |\n",
            "|    explained_variance   | 2.94e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.495       |\n",
            "|    n_updates            | 1630        |\n",
            "|    policy_gradient_loss | -0.00181    |\n",
            "|    reward               | 0.011174107 |\n",
            "|    std                  | 1.24        |\n",
            "|    value_loss           | 0.999       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 468         |\n",
            "|    iterations           | 165         |\n",
            "|    time_elapsed         | 721         |\n",
            "|    total_timesteps      | 337920      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004818555 |\n",
            "|    clip_fraction        | 0.0295      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.26       |\n",
            "|    explained_variance   | 5.48e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.308       |\n",
            "|    n_updates            | 1640        |\n",
            "|    policy_gradient_loss | -0.00228    |\n",
            "|    reward               | -0.40856832 |\n",
            "|    std                  | 1.24        |\n",
            "|    value_loss           | 0.905       |\n",
            "-----------------------------------------\n",
            "day: 2707, episode: 125\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -306907.09\n",
            "total_reward: -316907.09\n",
            "total_cost: 529.15\n",
            "total_trades: 3178\n",
            "Sharpe: 0.003\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 166          |\n",
            "|    time_elapsed         | 725          |\n",
            "|    total_timesteps      | 339968       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038751697 |\n",
            "|    clip_fraction        | 0.0118       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.26        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0384       |\n",
            "|    n_updates            | 1650         |\n",
            "|    policy_gradient_loss | -0.00139     |\n",
            "|    reward               | -0.16571198  |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.139        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 167          |\n",
            "|    time_elapsed         | 730          |\n",
            "|    total_timesteps      | 342016       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025702151 |\n",
            "|    clip_fraction        | 0.00684      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.27        |\n",
            "|    explained_variance   | 2.66e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.234        |\n",
            "|    n_updates            | 1660         |\n",
            "|    policy_gradient_loss | -0.000602    |\n",
            "|    reward               | -0.019421127 |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.731        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 168          |\n",
            "|    time_elapsed         | 734          |\n",
            "|    total_timesteps      | 344064       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031422284 |\n",
            "|    clip_fraction        | 0.0156       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.27        |\n",
            "|    explained_variance   | 5.78e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.253        |\n",
            "|    n_updates            | 1670         |\n",
            "|    policy_gradient_loss | -0.00147     |\n",
            "|    reward               | 0.004128431  |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.578        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 169          |\n",
            "|    time_elapsed         | 739          |\n",
            "|    total_timesteps      | 346112       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037867022 |\n",
            "|    clip_fraction        | 0.0183       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.27        |\n",
            "|    explained_variance   | 5.45e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.239        |\n",
            "|    n_updates            | 1680         |\n",
            "|    policy_gradient_loss | -0.00119     |\n",
            "|    reward               | 0.15452993   |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.822        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 170          |\n",
            "|    time_elapsed         | 743          |\n",
            "|    total_timesteps      | 348160       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027549611 |\n",
            "|    clip_fraction        | 0.00273      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0236       |\n",
            "|    n_updates            | 1690         |\n",
            "|    policy_gradient_loss | -0.000442    |\n",
            "|    reward               | -0.024406975 |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.152        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 171          |\n",
            "|    time_elapsed         | 747          |\n",
            "|    total_timesteps      | 350208       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040755626 |\n",
            "|    clip_fraction        | 0.0245       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.27        |\n",
            "|    explained_variance   | 4.77e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.445        |\n",
            "|    n_updates            | 1700         |\n",
            "|    policy_gradient_loss | -0.00203     |\n",
            "|    reward               | -0.01556779  |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 0.672        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 130\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -435386.22\n",
            "total_reward: -445386.22\n",
            "total_cost: 649.01\n",
            "total_trades: 3158\n",
            "Sharpe: 0.559\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 468           |\n",
            "|    iterations           | 172           |\n",
            "|    time_elapsed         | 752           |\n",
            "|    total_timesteps      | 352256        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0018394054  |\n",
            "|    clip_fraction        | 0.00542       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.26         |\n",
            "|    explained_variance   | 2.72e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.416         |\n",
            "|    n_updates            | 1710          |\n",
            "|    policy_gradient_loss | -0.000204     |\n",
            "|    reward               | -0.0028051499 |\n",
            "|    std                  | 1.24          |\n",
            "|    value_loss           | 0.883         |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 468         |\n",
            "|    iterations           | 173         |\n",
            "|    time_elapsed         | 756         |\n",
            "|    total_timesteps      | 354304      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004579479 |\n",
            "|    clip_fraction        | 0.0304      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.26       |\n",
            "|    explained_variance   | 4.23e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.552       |\n",
            "|    n_updates            | 1720        |\n",
            "|    policy_gradient_loss | -0.00179    |\n",
            "|    reward               | -0.42877233 |\n",
            "|    std                  | 1.25        |\n",
            "|    value_loss           | 1.27        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 174          |\n",
            "|    time_elapsed         | 761          |\n",
            "|    total_timesteps      | 356352       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056538535 |\n",
            "|    clip_fraction        | 0.0463       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.27        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0816       |\n",
            "|    n_updates            | 1730         |\n",
            "|    policy_gradient_loss | -0.00416     |\n",
            "|    reward               | -0.15723146  |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.227        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 468           |\n",
            "|    iterations           | 175           |\n",
            "|    time_elapsed         | 765           |\n",
            "|    total_timesteps      | 358400        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.007338149   |\n",
            "|    clip_fraction        | 0.0688        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.29         |\n",
            "|    explained_variance   | 3.01e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0964        |\n",
            "|    n_updates            | 1740          |\n",
            "|    policy_gradient_loss | -0.00415      |\n",
            "|    reward               | -0.0046717897 |\n",
            "|    std                  | 1.27          |\n",
            "|    value_loss           | 0.792         |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 468         |\n",
            "|    iterations           | 176         |\n",
            "|    time_elapsed         | 769         |\n",
            "|    total_timesteps      | 360448      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004734436 |\n",
            "|    clip_fraction        | 0.0351      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.29       |\n",
            "|    explained_variance   | 3.52e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.405       |\n",
            "|    n_updates            | 1750        |\n",
            "|    policy_gradient_loss | -0.00219    |\n",
            "|    reward               | 0.008344463 |\n",
            "|    std                  | 1.26        |\n",
            "|    value_loss           | 0.762       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 177          |\n",
            "|    time_elapsed         | 774          |\n",
            "|    total_timesteps      | 362496       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.00304955   |\n",
            "|    clip_fraction        | 0.00645      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | 5.52e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.501        |\n",
            "|    n_updates            | 1760         |\n",
            "|    policy_gradient_loss | -0.000624    |\n",
            "|    reward               | -0.046907306 |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.804        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 178          |\n",
            "|    time_elapsed         | 778          |\n",
            "|    total_timesteps      | 364544       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032731844 |\n",
            "|    clip_fraction        | 0.00259      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.29        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.124        |\n",
            "|    n_updates            | 1770         |\n",
            "|    policy_gradient_loss | -0.000111    |\n",
            "|    reward               | -0.05924802  |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.284        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 135\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -321449.45\n",
            "total_reward: -331449.45\n",
            "total_cost: 490.96\n",
            "total_trades: 2994\n",
            "Sharpe: -0.130\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 468         |\n",
            "|    iterations           | 179         |\n",
            "|    time_elapsed         | 782         |\n",
            "|    total_timesteps      | 366592      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004631051 |\n",
            "|    clip_fraction        | 0.0412      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.28       |\n",
            "|    explained_variance   | 4.29e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.159       |\n",
            "|    n_updates            | 1780        |\n",
            "|    policy_gradient_loss | -0.00348    |\n",
            "|    reward               | -0.08121644 |\n",
            "|    std                  | 1.26        |\n",
            "|    value_loss           | 0.71        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 468         |\n",
            "|    iterations           | 180         |\n",
            "|    time_elapsed         | 787         |\n",
            "|    total_timesteps      | 368640      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004258792 |\n",
            "|    clip_fraction        | 0.0202      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.28       |\n",
            "|    explained_variance   | 4.64e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.57        |\n",
            "|    n_updates            | 1790        |\n",
            "|    policy_gradient_loss | -0.00261    |\n",
            "|    reward               | -0.04359849 |\n",
            "|    std                  | 1.26        |\n",
            "|    value_loss           | 0.886       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 468         |\n",
            "|    iterations           | 181         |\n",
            "|    time_elapsed         | 791         |\n",
            "|    total_timesteps      | 370688      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005108719 |\n",
            "|    clip_fraction        | 0.0306      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.28       |\n",
            "|    explained_variance   | 4.39e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.216       |\n",
            "|    n_updates            | 1800        |\n",
            "|    policy_gradient_loss | -0.00191    |\n",
            "|    reward               | -0.06817747 |\n",
            "|    std                  | 1.26        |\n",
            "|    value_loss           | 1.19        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 182          |\n",
            "|    time_elapsed         | 796          |\n",
            "|    total_timesteps      | 372736       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030343016 |\n",
            "|    clip_fraction        | 0.00498      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.27        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0929       |\n",
            "|    n_updates            | 1810         |\n",
            "|    policy_gradient_loss | 8.82e-05     |\n",
            "|    reward               | -0.2773456   |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.315        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 468         |\n",
            "|    iterations           | 183         |\n",
            "|    time_elapsed         | 800         |\n",
            "|    total_timesteps      | 374784      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004783007 |\n",
            "|    clip_fraction        | 0.0578      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.27       |\n",
            "|    explained_variance   | 3.13e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.425       |\n",
            "|    n_updates            | 1820        |\n",
            "|    policy_gradient_loss | -0.00369    |\n",
            "|    reward               | 0.07129494  |\n",
            "|    std                  | 1.26        |\n",
            "|    value_loss           | 0.729       |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 468           |\n",
            "|    iterations           | 184           |\n",
            "|    time_elapsed         | 804           |\n",
            "|    total_timesteps      | 376832        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0037890263  |\n",
            "|    clip_fraction        | 0.00654       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.29         |\n",
            "|    explained_variance   | 2.29e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.456         |\n",
            "|    n_updates            | 1830          |\n",
            "|    policy_gradient_loss | -0.000305     |\n",
            "|    reward               | -0.0028727937 |\n",
            "|    std                  | 1.27          |\n",
            "|    value_loss           | 1.03          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 468           |\n",
            "|    iterations           | 185           |\n",
            "|    time_elapsed         | 809           |\n",
            "|    total_timesteps      | 378880        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00029786097 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.3          |\n",
            "|    explained_variance   | 4.7e-05       |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.44          |\n",
            "|    n_updates            | 1840          |\n",
            "|    policy_gradient_loss | 6.72e-05      |\n",
            "|    reward               | -0.45870328   |\n",
            "|    std                  | 1.28          |\n",
            "|    value_loss           | 1.04          |\n",
            "-------------------------------------------\n",
            "day: 2707, episode: 140\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -325250.09\n",
            "total_reward: -335250.09\n",
            "total_cost: 511.89\n",
            "total_trades: 3100\n",
            "Sharpe: -0.254\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 186          |\n",
            "|    time_elapsed         | 813          |\n",
            "|    total_timesteps      | 380928       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0062485    |\n",
            "|    clip_fraction        | 0.0333       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.31        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0714       |\n",
            "|    n_updates            | 1850         |\n",
            "|    policy_gradient_loss | -0.00202     |\n",
            "|    reward               | -0.026709806 |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.356        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 187          |\n",
            "|    time_elapsed         | 818          |\n",
            "|    total_timesteps      | 382976       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036170855 |\n",
            "|    clip_fraction        | 0.0198       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.31        |\n",
            "|    explained_variance   | 5.3e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.173        |\n",
            "|    n_updates            | 1860         |\n",
            "|    policy_gradient_loss | -0.00186     |\n",
            "|    reward               | 0.056452233  |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.652        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 188          |\n",
            "|    time_elapsed         | 822          |\n",
            "|    total_timesteps      | 385024       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048052566 |\n",
            "|    clip_fraction        | 0.0213       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.3         |\n",
            "|    explained_variance   | 4.23e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.363        |\n",
            "|    n_updates            | 1870         |\n",
            "|    policy_gradient_loss | -0.00148     |\n",
            "|    reward               | -0.01886849  |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.719        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 189          |\n",
            "|    time_elapsed         | 826          |\n",
            "|    total_timesteps      | 387072       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052928794 |\n",
            "|    clip_fraction        | 0.0627       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.3         |\n",
            "|    explained_variance   | 3.34e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.213        |\n",
            "|    n_updates            | 1880         |\n",
            "|    policy_gradient_loss | -0.00472     |\n",
            "|    reward               | -0.99189115  |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.757        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 468         |\n",
            "|    iterations           | 190         |\n",
            "|    time_elapsed         | 831         |\n",
            "|    total_timesteps      | 389120      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004324476 |\n",
            "|    clip_fraction        | 0.0309      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.3        |\n",
            "|    explained_variance   | 1.19e-07    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.212       |\n",
            "|    n_updates            | 1890        |\n",
            "|    policy_gradient_loss | -0.00276    |\n",
            "|    reward               | 0.055411782 |\n",
            "|    std                  | 1.27        |\n",
            "|    value_loss           | 0.54        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 191          |\n",
            "|    time_elapsed         | 835          |\n",
            "|    total_timesteps      | 391168       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0066746827 |\n",
            "|    clip_fraction        | 0.062        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.29        |\n",
            "|    explained_variance   | 0.000142     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0956       |\n",
            "|    n_updates            | 1900         |\n",
            "|    policy_gradient_loss | -0.00451     |\n",
            "|    reward               | 0.14129935   |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.27         |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 145\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -270585.68\n",
            "total_reward: -280585.68\n",
            "total_cost: 492.35\n",
            "total_trades: 3026\n",
            "Sharpe: 0.108\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 192          |\n",
            "|    time_elapsed         | 840          |\n",
            "|    total_timesteps      | 393216       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060624494 |\n",
            "|    clip_fraction        | 0.0464       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | 4.32e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.235        |\n",
            "|    n_updates            | 1910         |\n",
            "|    policy_gradient_loss | -0.0027      |\n",
            "|    reward               | 0.0073533957 |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.695        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 193          |\n",
            "|    time_elapsed         | 844          |\n",
            "|    total_timesteps      | 395264       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015270433 |\n",
            "|    clip_fraction        | 0.000635     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.26        |\n",
            "|    explained_variance   | 3.15e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.208        |\n",
            "|    n_updates            | 1920         |\n",
            "|    policy_gradient_loss | 5.43e-05     |\n",
            "|    reward               | -0.096576646 |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.627        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 194          |\n",
            "|    time_elapsed         | 848          |\n",
            "|    total_timesteps      | 397312       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031511558 |\n",
            "|    clip_fraction        | 0.0176       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.25        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.12         |\n",
            "|    n_updates            | 1930         |\n",
            "|    policy_gradient_loss | -0.00114     |\n",
            "|    reward               | 0.040463038  |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 0.525        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 195          |\n",
            "|    time_elapsed         | 853          |\n",
            "|    total_timesteps      | 399360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034775625 |\n",
            "|    clip_fraction        | 0.0125       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.25        |\n",
            "|    explained_variance   | 0.000139     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.081        |\n",
            "|    n_updates            | 1940         |\n",
            "|    policy_gradient_loss | -0.000821    |\n",
            "|    reward               | -0.034892347 |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 0.181        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 468         |\n",
            "|    iterations           | 196         |\n",
            "|    time_elapsed         | 857         |\n",
            "|    total_timesteps      | 401408      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004914171 |\n",
            "|    clip_fraction        | 0.0242      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.25       |\n",
            "|    explained_variance   | 4.61e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.431       |\n",
            "|    n_updates            | 1950        |\n",
            "|    policy_gradient_loss | -0.00204    |\n",
            "|    reward               | 0.031535476 |\n",
            "|    std                  | 1.24        |\n",
            "|    value_loss           | 0.677       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 468         |\n",
            "|    iterations           | 197         |\n",
            "|    time_elapsed         | 862         |\n",
            "|    total_timesteps      | 403456      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006800437 |\n",
            "|    clip_fraction        | 0.0416      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.24       |\n",
            "|    explained_variance   | 2.59e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.126       |\n",
            "|    n_updates            | 1960        |\n",
            "|    policy_gradient_loss | -0.00267    |\n",
            "|    reward               | 1.022657    |\n",
            "|    std                  | 1.23        |\n",
            "|    value_loss           | 0.489       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 198          |\n",
            "|    time_elapsed         | 866          |\n",
            "|    total_timesteps      | 405504       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034657163 |\n",
            "|    clip_fraction        | 0.0204       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.23        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.208        |\n",
            "|    n_updates            | 1970         |\n",
            "|    policy_gradient_loss | -0.00168     |\n",
            "|    reward               | 0.048354354  |\n",
            "|    std                  | 1.23         |\n",
            "|    value_loss           | 0.504        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 150\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -237272.66\n",
            "total_reward: -247272.66\n",
            "total_cost: 473.30\n",
            "total_trades: 2876\n",
            "Sharpe: -0.341\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 199          |\n",
            "|    time_elapsed         | 870          |\n",
            "|    total_timesteps      | 407552       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036664242 |\n",
            "|    clip_fraction        | 0.0275       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.24        |\n",
            "|    explained_variance   | 0.000126     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.055        |\n",
            "|    n_updates            | 1980         |\n",
            "|    policy_gradient_loss | -0.0021      |\n",
            "|    reward               | 0.08732051   |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 0.0992       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 200          |\n",
            "|    time_elapsed         | 875          |\n",
            "|    total_timesteps      | 409600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034032003 |\n",
            "|    clip_fraction        | 0.0244       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.25        |\n",
            "|    explained_variance   | 5.2e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.102        |\n",
            "|    n_updates            | 1990         |\n",
            "|    policy_gradient_loss | -0.000898    |\n",
            "|    reward               | -0.019720836 |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.463        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 201          |\n",
            "|    time_elapsed         | 879          |\n",
            "|    total_timesteps      | 411648       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034334504 |\n",
            "|    clip_fraction        | 0.0231       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.24        |\n",
            "|    explained_variance   | 3.1e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.157        |\n",
            "|    n_updates            | 2000         |\n",
            "|    policy_gradient_loss | -0.00223     |\n",
            "|    reward               | 0.012928631  |\n",
            "|    std                  | 1.23         |\n",
            "|    value_loss           | 0.539        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 202          |\n",
            "|    time_elapsed         | 884          |\n",
            "|    total_timesteps      | 413696       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036608884 |\n",
            "|    clip_fraction        | 0.0134       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.22        |\n",
            "|    explained_variance   | 3.22e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.194        |\n",
            "|    n_updates            | 2010         |\n",
            "|    policy_gradient_loss | -0.00142     |\n",
            "|    reward               | -0.10187341  |\n",
            "|    std                  | 1.22         |\n",
            "|    value_loss           | 0.413        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 467         |\n",
            "|    iterations           | 203         |\n",
            "|    time_elapsed         | 888         |\n",
            "|    total_timesteps      | 415744      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004635173 |\n",
            "|    clip_fraction        | 0.0268      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.21       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0211     |\n",
            "|    n_updates            | 2020        |\n",
            "|    policy_gradient_loss | -0.00117    |\n",
            "|    reward               | 0.03213592  |\n",
            "|    std                  | 1.22        |\n",
            "|    value_loss           | 0.0391      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 204          |\n",
            "|    time_elapsed         | 892          |\n",
            "|    total_timesteps      | 417792       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005658896  |\n",
            "|    clip_fraction        | 0.0427       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.21        |\n",
            "|    explained_variance   | 4.96e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.103        |\n",
            "|    n_updates            | 2030         |\n",
            "|    policy_gradient_loss | -0.00288     |\n",
            "|    reward               | -0.019175818 |\n",
            "|    std                  | 1.22         |\n",
            "|    value_loss           | 0.307        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 155\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -262851.15\n",
            "total_reward: -272851.15\n",
            "total_cost: 494.18\n",
            "total_trades: 3028\n",
            "Sharpe: 0.096\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 205          |\n",
            "|    time_elapsed         | 897          |\n",
            "|    total_timesteps      | 419840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030695922 |\n",
            "|    clip_fraction        | 0.0131       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.2         |\n",
            "|    explained_variance   | 3.06e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.345        |\n",
            "|    n_updates            | 2040         |\n",
            "|    policy_gradient_loss | -0.000657    |\n",
            "|    reward               | 0.016577981  |\n",
            "|    std                  | 1.21         |\n",
            "|    value_loss           | 0.537        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 467         |\n",
            "|    iterations           | 206         |\n",
            "|    time_elapsed         | 901         |\n",
            "|    total_timesteps      | 421888      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004167898 |\n",
            "|    clip_fraction        | 0.0243      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.19       |\n",
            "|    explained_variance   | 4.89e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.289       |\n",
            "|    n_updates            | 2050        |\n",
            "|    policy_gradient_loss | -0.00252    |\n",
            "|    reward               | 0.19894555  |\n",
            "|    std                  | 1.21        |\n",
            "|    value_loss           | 0.608       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 467         |\n",
            "|    iterations           | 207         |\n",
            "|    time_elapsed         | 905         |\n",
            "|    total_timesteps      | 423936      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004595288 |\n",
            "|    clip_fraction        | 0.0213      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.19       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.00639     |\n",
            "|    n_updates            | 2060        |\n",
            "|    policy_gradient_loss | -0.00151    |\n",
            "|    reward               | -0.20907705 |\n",
            "|    std                  | 1.21        |\n",
            "|    value_loss           | 0.12        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 208          |\n",
            "|    time_elapsed         | 910          |\n",
            "|    total_timesteps      | 425984       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029326444 |\n",
            "|    clip_fraction        | 0.00171      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.2         |\n",
            "|    explained_variance   | 2.79e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.183        |\n",
            "|    n_updates            | 2070         |\n",
            "|    policy_gradient_loss | -5.65e-05    |\n",
            "|    reward               | 0.0003118435 |\n",
            "|    std                  | 1.21         |\n",
            "|    value_loss           | 0.589        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 209          |\n",
            "|    time_elapsed         | 914          |\n",
            "|    total_timesteps      | 428032       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045634746 |\n",
            "|    clip_fraction        | 0.0247       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.2         |\n",
            "|    explained_variance   | 4.79e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.294        |\n",
            "|    n_updates            | 2080         |\n",
            "|    policy_gradient_loss | -0.00192     |\n",
            "|    reward               | 0.017699528  |\n",
            "|    std                  | 1.21         |\n",
            "|    value_loss           | 0.753        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 210          |\n",
            "|    time_elapsed         | 919          |\n",
            "|    total_timesteps      | 430080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038925444 |\n",
            "|    clip_fraction        | 0.0136       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.2         |\n",
            "|    explained_variance   | 3.23e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.397        |\n",
            "|    n_updates            | 2090         |\n",
            "|    policy_gradient_loss | -0.0006      |\n",
            "|    reward               | 0.16143014   |\n",
            "|    std                  | 1.22         |\n",
            "|    value_loss           | 0.72         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 467         |\n",
            "|    iterations           | 211         |\n",
            "|    time_elapsed         | 923         |\n",
            "|    total_timesteps      | 432128      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004994418 |\n",
            "|    clip_fraction        | 0.0229      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.21       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0264      |\n",
            "|    n_updates            | 2100        |\n",
            "|    policy_gradient_loss | -0.00154    |\n",
            "|    reward               | -0.09376186 |\n",
            "|    std                  | 1.22        |\n",
            "|    value_loss           | 0.117       |\n",
            "-----------------------------------------\n",
            "day: 2707, episode: 160\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -291787.13\n",
            "total_reward: -301787.13\n",
            "total_cost: 502.69\n",
            "total_trades: 3090\n",
            "Sharpe: 0.080\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 212          |\n",
            "|    time_elapsed         | 928          |\n",
            "|    total_timesteps      | 434176       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018344232 |\n",
            "|    clip_fraction        | 0.00703      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.21        |\n",
            "|    explained_variance   | 3.58e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.264        |\n",
            "|    n_updates            | 2110         |\n",
            "|    policy_gradient_loss | -0.000443    |\n",
            "|    reward               | 0.012111282  |\n",
            "|    std                  | 1.22         |\n",
            "|    value_loss           | 0.463        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 213          |\n",
            "|    time_elapsed         | 932          |\n",
            "|    total_timesteps      | 436224       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030597143 |\n",
            "|    clip_fraction        | 0.0163       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.22        |\n",
            "|    explained_variance   | 2.73e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.363        |\n",
            "|    n_updates            | 2120         |\n",
            "|    policy_gradient_loss | -0.00166     |\n",
            "|    reward               | 0.007619681  |\n",
            "|    std                  | 1.23         |\n",
            "|    value_loss           | 0.752        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 214          |\n",
            "|    time_elapsed         | 936          |\n",
            "|    total_timesteps      | 438272       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0070110774 |\n",
            "|    clip_fraction        | 0.0437       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.22        |\n",
            "|    explained_variance   | 3.47e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.241        |\n",
            "|    n_updates            | 2130         |\n",
            "|    policy_gradient_loss | -0.00286     |\n",
            "|    reward               | -0.38474253  |\n",
            "|    std                  | 1.23         |\n",
            "|    value_loss           | 0.705        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 215          |\n",
            "|    time_elapsed         | 941          |\n",
            "|    total_timesteps      | 440320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040996945 |\n",
            "|    clip_fraction        | 0.0207       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.23        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.074        |\n",
            "|    n_updates            | 2140         |\n",
            "|    policy_gradient_loss | -0.00101     |\n",
            "|    reward               | -0.030319685 |\n",
            "|    std                  | 1.23         |\n",
            "|    value_loss           | 0.156        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 216          |\n",
            "|    time_elapsed         | 945          |\n",
            "|    total_timesteps      | 442368       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004276227  |\n",
            "|    clip_fraction        | 0.0317       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.22        |\n",
            "|    explained_variance   | 2.44e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.308        |\n",
            "|    n_updates            | 2150         |\n",
            "|    policy_gradient_loss | -0.00102     |\n",
            "|    reward               | -0.038449556 |\n",
            "|    std                  | 1.23         |\n",
            "|    value_loss           | 0.484        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 217          |\n",
            "|    time_elapsed         | 950          |\n",
            "|    total_timesteps      | 444416       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034916208 |\n",
            "|    clip_fraction        | 0.0177       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.22        |\n",
            "|    explained_variance   | 2.74e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.32         |\n",
            "|    n_updates            | 2160         |\n",
            "|    policy_gradient_loss | -0.00192     |\n",
            "|    reward               | 0.018483246  |\n",
            "|    std                  | 1.23         |\n",
            "|    value_loss           | 0.709        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 467         |\n",
            "|    iterations           | 218         |\n",
            "|    time_elapsed         | 954         |\n",
            "|    total_timesteps      | 446464      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003600927 |\n",
            "|    clip_fraction        | 0.0232      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.21       |\n",
            "|    explained_variance   | 3.37e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.287       |\n",
            "|    n_updates            | 2170        |\n",
            "|    policy_gradient_loss | -0.00211    |\n",
            "|    reward               | 0.08513809  |\n",
            "|    std                  | 1.22        |\n",
            "|    value_loss           | 0.656       |\n",
            "-----------------------------------------\n",
            "day: 2707, episode: 165\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -294373.03\n",
            "total_reward: -304373.03\n",
            "total_cost: 505.65\n",
            "total_trades: 2980\n",
            "Sharpe: -0.152\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 467         |\n",
            "|    iterations           | 219         |\n",
            "|    time_elapsed         | 958         |\n",
            "|    total_timesteps      | 448512      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005042891 |\n",
            "|    clip_fraction        | 0.042       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.22       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0367      |\n",
            "|    n_updates            | 2180        |\n",
            "|    policy_gradient_loss | -0.00342    |\n",
            "|    reward               | -0.08525709 |\n",
            "|    std                  | 1.23        |\n",
            "|    value_loss           | 0.258       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 220          |\n",
            "|    time_elapsed         | 963          |\n",
            "|    total_timesteps      | 450560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005183367  |\n",
            "|    clip_fraction        | 0.0308       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.23        |\n",
            "|    explained_variance   | 4.59e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.335        |\n",
            "|    n_updates            | 2190         |\n",
            "|    policy_gradient_loss | -0.00149     |\n",
            "|    reward               | -0.032277882 |\n",
            "|    std                  | 1.23         |\n",
            "|    value_loss           | 0.554        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 221          |\n",
            "|    time_elapsed         | 967          |\n",
            "|    total_timesteps      | 452608       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038113957 |\n",
            "|    clip_fraction        | 0.0229       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.24        |\n",
            "|    explained_variance   | 2.5e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.218        |\n",
            "|    n_updates            | 2200         |\n",
            "|    policy_gradient_loss | -0.00161     |\n",
            "|    reward               | 0.05472957   |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 0.506        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 467         |\n",
            "|    iterations           | 222         |\n",
            "|    time_elapsed         | 971         |\n",
            "|    total_timesteps      | 454656      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005490035 |\n",
            "|    clip_fraction        | 0.0365      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.24       |\n",
            "|    explained_variance   | 6.34e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.168       |\n",
            "|    n_updates            | 2210        |\n",
            "|    policy_gradient_loss | -0.00247    |\n",
            "|    reward               | 0.040317763 |\n",
            "|    std                  | 1.24        |\n",
            "|    value_loss           | 0.459       |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 467           |\n",
            "|    iterations           | 223           |\n",
            "|    time_elapsed         | 976           |\n",
            "|    total_timesteps      | 456704        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0036630612  |\n",
            "|    clip_fraction        | 0.00962       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.24         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0689        |\n",
            "|    n_updates            | 2220          |\n",
            "|    policy_gradient_loss | -0.00107      |\n",
            "|    reward               | -0.0148176905 |\n",
            "|    std                  | 1.24          |\n",
            "|    value_loss           | 0.166         |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 467         |\n",
            "|    iterations           | 224         |\n",
            "|    time_elapsed         | 980         |\n",
            "|    total_timesteps      | 458752      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003949766 |\n",
            "|    clip_fraction        | 0.0147      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.24       |\n",
            "|    explained_variance   | 5.07e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.218       |\n",
            "|    n_updates            | 2230        |\n",
            "|    policy_gradient_loss | -0.00116    |\n",
            "|    reward               | -0.06579548 |\n",
            "|    std                  | 1.24        |\n",
            "|    value_loss           | 0.341       |\n",
            "-----------------------------------------\n",
            "day: 2707, episode: 170\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -276340.43\n",
            "total_reward: -286340.43\n",
            "total_cost: 480.05\n",
            "total_trades: 2972\n",
            "Sharpe: -0.373\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 225          |\n",
            "|    time_elapsed         | 985          |\n",
            "|    total_timesteps      | 460800       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041715754 |\n",
            "|    clip_fraction        | 0.0169       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.24        |\n",
            "|    explained_variance   | 2.63e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.283        |\n",
            "|    n_updates            | 2240         |\n",
            "|    policy_gradient_loss | -0.00146     |\n",
            "|    reward               | 0.026263136  |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 0.568        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 467         |\n",
            "|    iterations           | 226         |\n",
            "|    time_elapsed         | 989         |\n",
            "|    total_timesteps      | 462848      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006297075 |\n",
            "|    clip_fraction        | 0.0582      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.24       |\n",
            "|    explained_variance   | 4.94e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.391       |\n",
            "|    n_updates            | 2250        |\n",
            "|    policy_gradient_loss | -0.00456    |\n",
            "|    reward               | 0.58587354  |\n",
            "|    std                  | 1.24        |\n",
            "|    value_loss           | 0.671       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 227          |\n",
            "|    time_elapsed         | 993          |\n",
            "|    total_timesteps      | 464896       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033864907 |\n",
            "|    clip_fraction        | 0.0221       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.24        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.161        |\n",
            "|    n_updates            | 2260         |\n",
            "|    policy_gradient_loss | -0.00152     |\n",
            "|    reward               | -0.19782029  |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 0.335        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 228          |\n",
            "|    time_elapsed         | 998          |\n",
            "|    total_timesteps      | 466944       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028321815 |\n",
            "|    clip_fraction        | 0.00591      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.24        |\n",
            "|    explained_variance   | 5.35e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.317        |\n",
            "|    n_updates            | 2270         |\n",
            "|    policy_gradient_loss | -0.000425    |\n",
            "|    reward               | 0.07666612   |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 0.511        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 229          |\n",
            "|    time_elapsed         | 1002         |\n",
            "|    total_timesteps      | 468992       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014863962 |\n",
            "|    clip_fraction        | 0.00137      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.25        |\n",
            "|    explained_variance   | 3.81e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.407        |\n",
            "|    n_updates            | 2280         |\n",
            "|    policy_gradient_loss | -0.000404    |\n",
            "|    reward               | -0.010959894 |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.752        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 230          |\n",
            "|    time_elapsed         | 1006         |\n",
            "|    total_timesteps      | 471040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041973745 |\n",
            "|    clip_fraction        | 0.0249       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.27        |\n",
            "|    explained_variance   | 4.11e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.442        |\n",
            "|    n_updates            | 2290         |\n",
            "|    policy_gradient_loss | -0.00227     |\n",
            "|    reward               | 0.3355178    |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.775        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 231          |\n",
            "|    time_elapsed         | 1011         |\n",
            "|    total_timesteps      | 473088       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0007708954 |\n",
            "|    clip_fraction        | 0.00137      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.118        |\n",
            "|    n_updates            | 2300         |\n",
            "|    policy_gradient_loss | -0.000204    |\n",
            "|    reward               | -0.20248389  |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.405        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 175\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -233802.48\n",
            "total_reward: -243802.48\n",
            "total_cost: 447.83\n",
            "total_trades: 2798\n",
            "Sharpe: 0.317\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 232          |\n",
            "|    time_elapsed         | 1015         |\n",
            "|    total_timesteps      | 475136       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005394886 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.29        |\n",
            "|    explained_variance   | 0.000139     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0375       |\n",
            "|    n_updates            | 2310         |\n",
            "|    policy_gradient_loss | 0.000146     |\n",
            "|    reward               | -0.047445606 |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.169        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 233          |\n",
            "|    time_elapsed         | 1020         |\n",
            "|    total_timesteps      | 477184       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.003388276  |\n",
            "|    clip_fraction        | 0.0233       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.27        |\n",
            "|    explained_variance   | 4.77e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.136        |\n",
            "|    n_updates            | 2320         |\n",
            "|    policy_gradient_loss | -0.00206     |\n",
            "|    reward               | -0.013185981 |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.457        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 234          |\n",
            "|    time_elapsed         | 1024         |\n",
            "|    total_timesteps      | 479232       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021933357 |\n",
            "|    clip_fraction        | 0.00332      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.25        |\n",
            "|    explained_variance   | 2.94e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.179        |\n",
            "|    n_updates            | 2330         |\n",
            "|    policy_gradient_loss | -0.000754    |\n",
            "|    reward               | -1.2225157   |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 0.468        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 467         |\n",
            "|    iterations           | 235         |\n",
            "|    time_elapsed         | 1028        |\n",
            "|    total_timesteps      | 481280      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004292837 |\n",
            "|    clip_fraction        | 0.0168      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.24       |\n",
            "|    explained_variance   | 1.19e-07    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0898      |\n",
            "|    n_updates            | 2340        |\n",
            "|    policy_gradient_loss | -0.00124    |\n",
            "|    reward               | 0.14679536  |\n",
            "|    std                  | 1.23        |\n",
            "|    value_loss           | 0.517       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 236          |\n",
            "|    time_elapsed         | 1033         |\n",
            "|    total_timesteps      | 483328       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043232497 |\n",
            "|    clip_fraction        | 0.0267       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.23        |\n",
            "|    explained_variance   | 0.000154     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00523     |\n",
            "|    n_updates            | 2350         |\n",
            "|    policy_gradient_loss | -0.00202     |\n",
            "|    reward               | 0.16957672   |\n",
            "|    std                  | 1.23         |\n",
            "|    value_loss           | 0.12         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 467         |\n",
            "|    iterations           | 237         |\n",
            "|    time_elapsed         | 1037        |\n",
            "|    total_timesteps      | 485376      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005132777 |\n",
            "|    clip_fraction        | 0.0261      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.23       |\n",
            "|    explained_variance   | 2.76e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.178       |\n",
            "|    n_updates            | 2360        |\n",
            "|    policy_gradient_loss | -0.00196    |\n",
            "|    reward               | 0.013191994 |\n",
            "|    std                  | 1.23        |\n",
            "|    value_loss           | 0.414       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 238          |\n",
            "|    time_elapsed         | 1042         |\n",
            "|    total_timesteps      | 487424       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045478875 |\n",
            "|    clip_fraction        | 0.0135       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.23        |\n",
            "|    explained_variance   | 4.5e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.1          |\n",
            "|    n_updates            | 2370         |\n",
            "|    policy_gradient_loss | -0.000821    |\n",
            "|    reward               | 0.5980212    |\n",
            "|    std                  | 1.23         |\n",
            "|    value_loss           | 0.452        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 180\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -252733.45\n",
            "total_reward: -262733.45\n",
            "total_cost: 498.11\n",
            "total_trades: 3004\n",
            "Sharpe: -0.133\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 467         |\n",
            "|    iterations           | 239         |\n",
            "|    time_elapsed         | 1047        |\n",
            "|    total_timesteps      | 489472      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003699122 |\n",
            "|    clip_fraction        | 0.0105      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.23       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.244       |\n",
            "|    n_updates            | 2380        |\n",
            "|    policy_gradient_loss | -0.000963   |\n",
            "|    reward               | -0.12222709 |\n",
            "|    std                  | 1.23        |\n",
            "|    value_loss           | 0.554       |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 467           |\n",
            "|    iterations           | 240           |\n",
            "|    time_elapsed         | 1052          |\n",
            "|    total_timesteps      | 491520        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0027476372  |\n",
            "|    clip_fraction        | 0.00508       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.22         |\n",
            "|    explained_variance   | 0.000156      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.00924      |\n",
            "|    n_updates            | 2390          |\n",
            "|    policy_gradient_loss | -0.000444     |\n",
            "|    reward               | -0.0007867507 |\n",
            "|    std                  | 1.22          |\n",
            "|    value_loss           | 0.0603        |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 467           |\n",
            "|    iterations           | 241           |\n",
            "|    time_elapsed         | 1056          |\n",
            "|    total_timesteps      | 493568        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0036218185  |\n",
            "|    clip_fraction        | 0.0157        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.22         |\n",
            "|    explained_variance   | 2.71e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.152         |\n",
            "|    n_updates            | 2400          |\n",
            "|    policy_gradient_loss | -0.000886     |\n",
            "|    reward               | -0.0062327413 |\n",
            "|    std                  | 1.22          |\n",
            "|    value_loss           | 0.475         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 466          |\n",
            "|    iterations           | 242          |\n",
            "|    time_elapsed         | 1061         |\n",
            "|    total_timesteps      | 495616       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054612188 |\n",
            "|    clip_fraction        | 0.0328       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.22        |\n",
            "|    explained_variance   | 4.12e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.203        |\n",
            "|    n_updates            | 2410         |\n",
            "|    policy_gradient_loss | -0.00231     |\n",
            "|    reward               | -0.011669269 |\n",
            "|    std                  | 1.22         |\n",
            "|    value_loss           | 0.622        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 466         |\n",
            "|    iterations           | 243         |\n",
            "|    time_elapsed         | 1067        |\n",
            "|    total_timesteps      | 497664      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004711415 |\n",
            "|    clip_fraction        | 0.0321      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.21       |\n",
            "|    explained_variance   | 3.08e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.141       |\n",
            "|    n_updates            | 2420        |\n",
            "|    policy_gradient_loss | -0.0023     |\n",
            "|    reward               | -0.07538007 |\n",
            "|    std                  | 1.21        |\n",
            "|    value_loss           | 0.463       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 465         |\n",
            "|    iterations           | 244         |\n",
            "|    time_elapsed         | 1072        |\n",
            "|    total_timesteps      | 499712      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003799294 |\n",
            "|    clip_fraction        | 0.00937     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.21       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.00951    |\n",
            "|    n_updates            | 2430        |\n",
            "|    policy_gradient_loss | -0.000514   |\n",
            "|    reward               | 0.016980477 |\n",
            "|    std                  | 1.22        |\n",
            "|    value_loss           | 0.0627      |\n",
            "-----------------------------------------\n",
            "day: 2707, episode: 185\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -206112.57\n",
            "total_reward: -216112.57\n",
            "total_cost: 408.91\n",
            "total_trades: 2768\n",
            "Sharpe: 0.238\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 465          |\n",
            "|    iterations           | 245          |\n",
            "|    time_elapsed         | 1077         |\n",
            "|    total_timesteps      | 501760       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004360365  |\n",
            "|    clip_fraction        | 0.0124       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.21        |\n",
            "|    explained_variance   | 3.94e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0817       |\n",
            "|    n_updates            | 2440         |\n",
            "|    policy_gradient_loss | -0.000602    |\n",
            "|    reward               | -0.021745859 |\n",
            "|    std                  | 1.22         |\n",
            "|    value_loss           | 0.361        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 465          |\n",
            "|    iterations           | 246          |\n",
            "|    time_elapsed         | 1081         |\n",
            "|    total_timesteps      | 503808       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028001603 |\n",
            "|    clip_fraction        | 0.0121       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.22        |\n",
            "|    explained_variance   | 3.43e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0845       |\n",
            "|    n_updates            | 2450         |\n",
            "|    policy_gradient_loss | -0.00184     |\n",
            "|    reward               | 0.004384195  |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 0.351        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 465          |\n",
            "|    iterations           | 247          |\n",
            "|    time_elapsed         | 1085         |\n",
            "|    total_timesteps      | 505856       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015997926 |\n",
            "|    clip_fraction        | 0.00151      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.23        |\n",
            "|    explained_variance   | 5.98e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0843       |\n",
            "|    n_updates            | 2460         |\n",
            "|    policy_gradient_loss | -0.000241    |\n",
            "|    reward               | -0.1717873   |\n",
            "|    std                  | 1.23         |\n",
            "|    value_loss           | 0.283        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 465         |\n",
            "|    iterations           | 248         |\n",
            "|    time_elapsed         | 1090        |\n",
            "|    total_timesteps      | 507904      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004237757 |\n",
            "|    clip_fraction        | 0.0326      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.22       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.00936    |\n",
            "|    n_updates            | 2470        |\n",
            "|    policy_gradient_loss | -0.00203    |\n",
            "|    reward               | -0.08327089 |\n",
            "|    std                  | 1.23        |\n",
            "|    value_loss           | 0.0295      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 465         |\n",
            "|    iterations           | 249         |\n",
            "|    time_elapsed         | 1095        |\n",
            "|    total_timesteps      | 509952      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.00229196  |\n",
            "|    clip_fraction        | 0.00996     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.23       |\n",
            "|    explained_variance   | 6.72e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.062       |\n",
            "|    n_updates            | 2480        |\n",
            "|    policy_gradient_loss | -0.00104    |\n",
            "|    reward               | 0.015497352 |\n",
            "|    std                  | 1.24        |\n",
            "|    value_loss           | 0.132       |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 465           |\n",
            "|    iterations           | 250           |\n",
            "|    time_elapsed         | 1099          |\n",
            "|    total_timesteps      | 512000        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0028772326  |\n",
            "|    clip_fraction        | 0.0215        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.26         |\n",
            "|    explained_variance   | 2.15e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.107         |\n",
            "|    n_updates            | 2490          |\n",
            "|    policy_gradient_loss | -0.00148      |\n",
            "|    reward               | -0.0052751545 |\n",
            "|    std                  | 1.25          |\n",
            "|    value_loss           | 0.211         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 465          |\n",
            "|    iterations           | 251          |\n",
            "|    time_elapsed         | 1103         |\n",
            "|    total_timesteps      | 514048       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052597146 |\n",
            "|    clip_fraction        | 0.0479       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.26        |\n",
            "|    explained_variance   | 0.000124     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0227       |\n",
            "|    n_updates            | 2500         |\n",
            "|    policy_gradient_loss | -0.00301     |\n",
            "|    reward               | -0.06672185  |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.166        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 190\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -137958.35\n",
            "total_reward: -147958.35\n",
            "total_cost: 381.44\n",
            "total_trades: 2688\n",
            "Sharpe: -0.012\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 465           |\n",
            "|    iterations           | 252           |\n",
            "|    time_elapsed         | 1108          |\n",
            "|    total_timesteps      | 516096        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.004052124   |\n",
            "|    clip_fraction        | 0.0139        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.26         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0203       |\n",
            "|    n_updates            | 2510          |\n",
            "|    policy_gradient_loss | -0.000895     |\n",
            "|    reward               | -0.0050997343 |\n",
            "|    std                  | 1.25          |\n",
            "|    value_loss           | 0.0441        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 465          |\n",
            "|    iterations           | 253          |\n",
            "|    time_elapsed         | 1112         |\n",
            "|    total_timesteps      | 518144       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043330044 |\n",
            "|    clip_fraction        | 0.024        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.26        |\n",
            "|    explained_variance   | 1.91e-06     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0296       |\n",
            "|    n_updates            | 2520         |\n",
            "|    policy_gradient_loss | -0.00216     |\n",
            "|    reward               | 0.021711452  |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.134        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 465           |\n",
            "|    iterations           | 254           |\n",
            "|    time_elapsed         | 1116          |\n",
            "|    total_timesteps      | 520192        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.001540772   |\n",
            "|    clip_fraction        | 0.00269       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.27         |\n",
            "|    explained_variance   | 1.29e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0131        |\n",
            "|    n_updates            | 2530          |\n",
            "|    policy_gradient_loss | -0.00117      |\n",
            "|    reward               | -0.0029217172 |\n",
            "|    std                  | 1.26          |\n",
            "|    value_loss           | 0.129         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 465          |\n",
            "|    iterations           | 255          |\n",
            "|    time_elapsed         | 1120         |\n",
            "|    total_timesteps      | 522240       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060944636 |\n",
            "|    clip_fraction        | 0.0311       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | 0.000106     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0555       |\n",
            "|    n_updates            | 2540         |\n",
            "|    policy_gradient_loss | -0.00255     |\n",
            "|    reward               | 0.007532158  |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.156        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 466         |\n",
            "|    iterations           | 256         |\n",
            "|    time_elapsed         | 1124        |\n",
            "|    total_timesteps      | 524288      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002575938 |\n",
            "|    clip_fraction        | 0.00713     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.27       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.00675    |\n",
            "|    n_updates            | 2550        |\n",
            "|    policy_gradient_loss | -0.000805   |\n",
            "|    reward               | 0.08000687  |\n",
            "|    std                  | 1.25        |\n",
            "|    value_loss           | 0.0273      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 466          |\n",
            "|    iterations           | 257          |\n",
            "|    time_elapsed         | 1128         |\n",
            "|    total_timesteps      | 526336       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047490112 |\n",
            "|    clip_fraction        | 0.0224       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.27        |\n",
            "|    explained_variance   | -4.33e-05    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0171       |\n",
            "|    n_updates            | 2560         |\n",
            "|    policy_gradient_loss | -0.000794    |\n",
            "|    reward               | -0.010137155 |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.0539       |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 195\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -88159.22\n",
            "total_reward: -98159.22\n",
            "total_cost: 377.79\n",
            "total_trades: 2752\n",
            "Sharpe: -0.244\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 466          |\n",
            "|    iterations           | 258          |\n",
            "|    time_elapsed         | 1133         |\n",
            "|    total_timesteps      | 528384       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0057728104 |\n",
            "|    clip_fraction        | 0.0317       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | -2.77e-05    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0139      |\n",
            "|    n_updates            | 2570         |\n",
            "|    policy_gradient_loss | -0.00226     |\n",
            "|    reward               | 0.020568253  |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.0501       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 466          |\n",
            "|    iterations           | 259          |\n",
            "|    time_elapsed         | 1137         |\n",
            "|    total_timesteps      | 530432       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046136263 |\n",
            "|    clip_fraction        | 0.0346       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.27        |\n",
            "|    explained_variance   | 1.64e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.006        |\n",
            "|    n_updates            | 2580         |\n",
            "|    policy_gradient_loss | -0.00254     |\n",
            "|    reward               | -0.19159561  |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.0652       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 466          |\n",
            "|    iterations           | 260          |\n",
            "|    time_elapsed         | 1141         |\n",
            "|    total_timesteps      | 532480       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058297403 |\n",
            "|    clip_fraction        | 0.0293       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.27        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0231      |\n",
            "|    n_updates            | 2590         |\n",
            "|    policy_gradient_loss | -0.00194     |\n",
            "|    reward               | 0.014428961  |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.0271       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 466           |\n",
            "|    iterations           | 261           |\n",
            "|    time_elapsed         | 1145          |\n",
            "|    total_timesteps      | 534528        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0052697146  |\n",
            "|    clip_fraction        | 0.0374        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.28         |\n",
            "|    explained_variance   | -0.000336     |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.00856       |\n",
            "|    n_updates            | 2600          |\n",
            "|    policy_gradient_loss | -0.00293      |\n",
            "|    reward               | -0.0022819424 |\n",
            "|    std                  | 1.25          |\n",
            "|    value_loss           | 0.108         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 466          |\n",
            "|    iterations           | 262          |\n",
            "|    time_elapsed         | 1149         |\n",
            "|    total_timesteps      | 536576       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035967273 |\n",
            "|    clip_fraction        | 0.00845      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.27        |\n",
            "|    explained_variance   | 0.0159       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.138        |\n",
            "|    n_updates            | 2610         |\n",
            "|    policy_gradient_loss | -0.000975    |\n",
            "|    reward               | 0.10556711   |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.529        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 263          |\n",
            "|    time_elapsed         | 1153         |\n",
            "|    total_timesteps      | 538624       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031533355 |\n",
            "|    clip_fraction        | 0.0188       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | 0.255        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0346       |\n",
            "|    n_updates            | 2620         |\n",
            "|    policy_gradient_loss | -0.00208     |\n",
            "|    reward               | -0.17460406  |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.0911       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 264          |\n",
            "|    time_elapsed         | 1157         |\n",
            "|    total_timesteps      | 540672       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041781096 |\n",
            "|    clip_fraction        | 0.0117       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.27        |\n",
            "|    explained_variance   | 0.000566     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.119        |\n",
            "|    n_updates            | 2630         |\n",
            "|    policy_gradient_loss | -0.000896    |\n",
            "|    reward               | -0.08258082  |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.347        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 200\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -236411.83\n",
            "total_reward: -246411.83\n",
            "total_cost: 371.45\n",
            "total_trades: 2584\n",
            "Sharpe: 0.342\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 467         |\n",
            "|    iterations           | 265         |\n",
            "|    time_elapsed         | 1161        |\n",
            "|    total_timesteps      | 542720      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004013752 |\n",
            "|    clip_fraction        | 0.0547      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.27       |\n",
            "|    explained_variance   | 0.0896      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.039       |\n",
            "|    n_updates            | 2640        |\n",
            "|    policy_gradient_loss | -0.00201    |\n",
            "|    reward               | 0.010562755 |\n",
            "|    std                  | 1.25        |\n",
            "|    value_loss           | 0.434       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 266          |\n",
            "|    time_elapsed         | 1166         |\n",
            "|    total_timesteps      | 544768       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.003544933  |\n",
            "|    clip_fraction        | 0.00469      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | 0.376        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.115        |\n",
            "|    n_updates            | 2650         |\n",
            "|    policy_gradient_loss | -0.000593    |\n",
            "|    reward               | 0.0038783082 |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.302        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 467         |\n",
            "|    iterations           | 267         |\n",
            "|    time_elapsed         | 1170        |\n",
            "|    total_timesteps      | 546816      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003590387 |\n",
            "|    clip_fraction        | 0.0136      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.29       |\n",
            "|    explained_variance   | 0.475       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0648      |\n",
            "|    n_updates            | 2660        |\n",
            "|    policy_gradient_loss | -0.00144    |\n",
            "|    reward               | -0.35149243 |\n",
            "|    std                  | 1.26        |\n",
            "|    value_loss           | 0.168       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 268          |\n",
            "|    time_elapsed         | 1175         |\n",
            "|    total_timesteps      | 548864       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033804062 |\n",
            "|    clip_fraction        | 0.016        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.29        |\n",
            "|    explained_variance   | 0.368        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0468       |\n",
            "|    n_updates            | 2670         |\n",
            "|    policy_gradient_loss | -0.00113     |\n",
            "|    reward               | 0.078081004  |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.111        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 269          |\n",
            "|    time_elapsed         | 1179         |\n",
            "|    total_timesteps      | 550912       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061655147 |\n",
            "|    clip_fraction        | 0.0393       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | 0.621        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00887     |\n",
            "|    n_updates            | 2680         |\n",
            "|    policy_gradient_loss | -0.00274     |\n",
            "|    reward               | -0.04908269  |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.0447       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 467         |\n",
            "|    iterations           | 270         |\n",
            "|    time_elapsed         | 1183        |\n",
            "|    total_timesteps      | 552960      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005621684 |\n",
            "|    clip_fraction        | 0.0267      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.28       |\n",
            "|    explained_variance   | 0.551       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0132      |\n",
            "|    n_updates            | 2690        |\n",
            "|    policy_gradient_loss | -0.0046     |\n",
            "|    reward               | 0.034135684 |\n",
            "|    std                  | 1.26        |\n",
            "|    value_loss           | 0.0898      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 271          |\n",
            "|    time_elapsed         | 1187         |\n",
            "|    total_timesteps      | 555008       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.00566636   |\n",
            "|    clip_fraction        | 0.0708       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | 0.604        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0147      |\n",
            "|    n_updates            | 2700         |\n",
            "|    policy_gradient_loss | -0.00358     |\n",
            "|    reward               | -0.033779413 |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.0219       |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 205\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -55680.26\n",
            "total_reward: -65680.26\n",
            "total_cost: 370.25\n",
            "total_trades: 2774\n",
            "Sharpe: 0.038\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 272          |\n",
            "|    time_elapsed         | 1191         |\n",
            "|    total_timesteps      | 557056       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005567777  |\n",
            "|    clip_fraction        | 0.055        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.27        |\n",
            "|    explained_variance   | 0.307        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0227      |\n",
            "|    n_updates            | 2710         |\n",
            "|    policy_gradient_loss | -0.00282     |\n",
            "|    reward               | -0.018414577 |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.0207       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 273          |\n",
            "|    time_elapsed         | 1195         |\n",
            "|    total_timesteps      | 559104       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019377349 |\n",
            "|    clip_fraction        | 0.014        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | 0.477        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0201      |\n",
            "|    n_updates            | 2720         |\n",
            "|    policy_gradient_loss | 0.000179     |\n",
            "|    reward               | -0.0520342   |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.0228       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 274          |\n",
            "|    time_elapsed         | 1199         |\n",
            "|    total_timesteps      | 561152       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039225705 |\n",
            "|    clip_fraction        | 0.0203       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.27        |\n",
            "|    explained_variance   | 0.185        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0322       |\n",
            "|    n_updates            | 2730         |\n",
            "|    policy_gradient_loss | -9.89e-05    |\n",
            "|    reward               | 0.014020093  |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.111        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 275          |\n",
            "|    time_elapsed         | 1203         |\n",
            "|    total_timesteps      | 563200       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034628375 |\n",
            "|    clip_fraction        | 0.036        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.29        |\n",
            "|    explained_variance   | 0.256        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00263      |\n",
            "|    n_updates            | 2740         |\n",
            "|    policy_gradient_loss | -0.00118     |\n",
            "|    reward               | -0.18554635  |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.0675       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 276          |\n",
            "|    time_elapsed         | 1208         |\n",
            "|    total_timesteps      | 565248       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034050455 |\n",
            "|    clip_fraction        | 0.0195       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.32        |\n",
            "|    explained_variance   | 0.107        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0811       |\n",
            "|    n_updates            | 2750         |\n",
            "|    policy_gradient_loss | 0.000134     |\n",
            "|    reward               | 0.08277853   |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.208        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 277          |\n",
            "|    time_elapsed         | 1212         |\n",
            "|    total_timesteps      | 567296       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036711274 |\n",
            "|    clip_fraction        | 0.0207       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.32        |\n",
            "|    explained_variance   | 0.438        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0148      |\n",
            "|    n_updates            | 2760         |\n",
            "|    policy_gradient_loss | -0.0012      |\n",
            "|    reward               | 0.003607679  |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.055        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 210\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -77775.41\n",
            "total_reward: -87775.41\n",
            "total_cost: 370.52\n",
            "total_trades: 2724\n",
            "Sharpe: -0.074\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 467         |\n",
            "|    iterations           | 278         |\n",
            "|    time_elapsed         | 1217        |\n",
            "|    total_timesteps      | 569344      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003354113 |\n",
            "|    clip_fraction        | 0.0308      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.32       |\n",
            "|    explained_variance   | 0.277       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0622      |\n",
            "|    n_updates            | 2770        |\n",
            "|    policy_gradient_loss | 0.00215     |\n",
            "|    reward               | -0.04150013 |\n",
            "|    std                  | 1.29        |\n",
            "|    value_loss           | 0.162       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 279          |\n",
            "|    time_elapsed         | 1221         |\n",
            "|    total_timesteps      | 571392       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052243047 |\n",
            "|    clip_fraction        | 0.0468       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.32        |\n",
            "|    explained_variance   | 0.562        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.000522     |\n",
            "|    n_updates            | 2780         |\n",
            "|    policy_gradient_loss | -0.000758    |\n",
            "|    reward               | 0.0083685145 |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.0446       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 280          |\n",
            "|    time_elapsed         | 1225         |\n",
            "|    total_timesteps      | 573440       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047729583 |\n",
            "|    clip_fraction        | 0.045        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.31        |\n",
            "|    explained_variance   | 0.361        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0128       |\n",
            "|    n_updates            | 2790         |\n",
            "|    policy_gradient_loss | -0.00198     |\n",
            "|    reward               | -0.084448345 |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.0668       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 281          |\n",
            "|    time_elapsed         | 1229         |\n",
            "|    total_timesteps      | 575488       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006542748  |\n",
            "|    clip_fraction        | 0.0202       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.3         |\n",
            "|    explained_variance   | 0.781        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0299      |\n",
            "|    n_updates            | 2800         |\n",
            "|    policy_gradient_loss | -0.0017      |\n",
            "|    reward               | -0.008645305 |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.0117       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 468           |\n",
            "|    iterations           | 282           |\n",
            "|    time_elapsed         | 1233          |\n",
            "|    total_timesteps      | 577536        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0012250115  |\n",
            "|    clip_fraction        | 0.0145        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.3          |\n",
            "|    explained_variance   | 0.444         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.00812       |\n",
            "|    n_updates            | 2810          |\n",
            "|    policy_gradient_loss | -0.000797     |\n",
            "|    reward               | -0.0058398494 |\n",
            "|    std                  | 1.27          |\n",
            "|    value_loss           | 0.0581        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 283          |\n",
            "|    time_elapsed         | 1237         |\n",
            "|    total_timesteps      | 579584       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036790478 |\n",
            "|    clip_fraction        | 0.0267       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.3         |\n",
            "|    explained_variance   | 0.327        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0124       |\n",
            "|    n_updates            | 2820         |\n",
            "|    policy_gradient_loss | -0.000573    |\n",
            "|    reward               | 0.0034774155 |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.0998       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 284          |\n",
            "|    time_elapsed         | 1241         |\n",
            "|    total_timesteps      | 581632       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0066961707 |\n",
            "|    clip_fraction        | 0.0454       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.29        |\n",
            "|    explained_variance   | 0.154        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0423       |\n",
            "|    n_updates            | 2830         |\n",
            "|    policy_gradient_loss | -0.00249     |\n",
            "|    reward               | -0.07096198  |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.177        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 215\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -127325.57\n",
            "total_reward: -137325.57\n",
            "total_cost: 395.80\n",
            "total_trades: 2670\n",
            "Sharpe: -0.152\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 285          |\n",
            "|    time_elapsed         | 1246         |\n",
            "|    total_timesteps      | 583680       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0066757705 |\n",
            "|    clip_fraction        | 0.0537       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.3         |\n",
            "|    explained_variance   | 0.642        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00556     |\n",
            "|    n_updates            | 2840         |\n",
            "|    policy_gradient_loss | -0.00222     |\n",
            "|    reward               | -0.09703361  |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.0253       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 468           |\n",
            "|    iterations           | 286           |\n",
            "|    time_elapsed         | 1250          |\n",
            "|    total_timesteps      | 585728        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0056421747  |\n",
            "|    clip_fraction        | 0.0208        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.3          |\n",
            "|    explained_variance   | 0.331         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0225        |\n",
            "|    n_updates            | 2850          |\n",
            "|    policy_gradient_loss | -0.0013       |\n",
            "|    reward               | 0.00033210893 |\n",
            "|    std                  | 1.27          |\n",
            "|    value_loss           | 0.121         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 287          |\n",
            "|    time_elapsed         | 1254         |\n",
            "|    total_timesteps      | 587776       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031541444 |\n",
            "|    clip_fraction        | 0.0251       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.3         |\n",
            "|    explained_variance   | 0.255        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0915       |\n",
            "|    n_updates            | 2860         |\n",
            "|    policy_gradient_loss | -0.00153     |\n",
            "|    reward               | -0.013912606 |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.225        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 288          |\n",
            "|    time_elapsed         | 1258         |\n",
            "|    total_timesteps      | 589824       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0065097283 |\n",
            "|    clip_fraction        | 0.0411       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.3         |\n",
            "|    explained_variance   | 0.122        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.108        |\n",
            "|    n_updates            | 2870         |\n",
            "|    policy_gradient_loss | -0.00351     |\n",
            "|    reward               | -0.5208804   |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.341        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 289          |\n",
            "|    time_elapsed         | 1262         |\n",
            "|    total_timesteps      | 591872       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069836304 |\n",
            "|    clip_fraction        | 0.0397       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.3         |\n",
            "|    explained_variance   | 0.537        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0242      |\n",
            "|    n_updates            | 2880         |\n",
            "|    policy_gradient_loss | -0.00298     |\n",
            "|    reward               | -0.022902794 |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.0692       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 290          |\n",
            "|    time_elapsed         | 1266         |\n",
            "|    total_timesteps      | 593920       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033547194 |\n",
            "|    clip_fraction        | 0.0147       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.31        |\n",
            "|    explained_variance   | 0.292        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.079        |\n",
            "|    n_updates            | 2890         |\n",
            "|    policy_gradient_loss | -0.00127     |\n",
            "|    reward               | 0.0072911023 |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.276        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 220\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -160907.24\n",
            "total_reward: -170907.24\n",
            "total_cost: 384.65\n",
            "total_trades: 2654\n",
            "Sharpe: 0.361\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 291          |\n",
            "|    time_elapsed         | 1271         |\n",
            "|    total_timesteps      | 595968       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017289207 |\n",
            "|    clip_fraction        | 0.0116       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.31        |\n",
            "|    explained_variance   | 0.431        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0302       |\n",
            "|    n_updates            | 2900         |\n",
            "|    policy_gradient_loss | -0.00231     |\n",
            "|    reward               | 0.0003532277 |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.187        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 292          |\n",
            "|    time_elapsed         | 1275         |\n",
            "|    total_timesteps      | 598016       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071718637 |\n",
            "|    clip_fraction        | 0.0527       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.31        |\n",
            "|    explained_variance   | 0.203        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0841       |\n",
            "|    n_updates            | 2910         |\n",
            "|    policy_gradient_loss | -0.00223     |\n",
            "|    reward               | 0.26330692   |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.213        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 293          |\n",
            "|    time_elapsed         | 1280         |\n",
            "|    total_timesteps      | 600064       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005782903  |\n",
            "|    clip_fraction        | 0.0195       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.31        |\n",
            "|    explained_variance   | 0.569        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0073      |\n",
            "|    n_updates            | 2920         |\n",
            "|    policy_gradient_loss | -0.00151     |\n",
            "|    reward               | -0.042556398 |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.0759       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 294          |\n",
            "|    time_elapsed         | 1284         |\n",
            "|    total_timesteps      | 602112       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058284467 |\n",
            "|    clip_fraction        | 0.0134       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.31        |\n",
            "|    explained_variance   | 0.346        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0692       |\n",
            "|    n_updates            | 2930         |\n",
            "|    policy_gradient_loss | -0.000686    |\n",
            "|    reward               | -0.010562584 |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.247        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 466          |\n",
            "|    iterations           | 295          |\n",
            "|    time_elapsed         | 1295         |\n",
            "|    total_timesteps      | 604160       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019299474 |\n",
            "|    clip_fraction        | 0.00215      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.31        |\n",
            "|    explained_variance   | 0.316        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.118        |\n",
            "|    n_updates            | 2940         |\n",
            "|    policy_gradient_loss | -7.3e-05     |\n",
            "|    reward               | 0.0010983654 |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.365        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 466          |\n",
            "|    iterations           | 296          |\n",
            "|    time_elapsed         | 1300         |\n",
            "|    total_timesteps      | 606208       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039017769 |\n",
            "|    clip_fraction        | 0.031        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.31        |\n",
            "|    explained_variance   | 0.207        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.126        |\n",
            "|    n_updates            | 2950         |\n",
            "|    policy_gradient_loss | -0.00169     |\n",
            "|    reward               | -0.30196592  |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.344        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 466           |\n",
            "|    iterations           | 297           |\n",
            "|    time_elapsed         | 1305          |\n",
            "|    total_timesteps      | 608256        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0034895325  |\n",
            "|    clip_fraction        | 0.00503       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.32         |\n",
            "|    explained_variance   | 0.133         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.037         |\n",
            "|    n_updates            | 2960          |\n",
            "|    policy_gradient_loss | -0.0002       |\n",
            "|    reward               | -0.0007823685 |\n",
            "|    std                  | 1.28          |\n",
            "|    value_loss           | 0.161         |\n",
            "-------------------------------------------\n",
            "day: 2707, episode: 225\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -204890.54\n",
            "total_reward: -214890.54\n",
            "total_cost: 445.91\n",
            "total_trades: 2804\n",
            "Sharpe: -0.410\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 465          |\n",
            "|    iterations           | 298          |\n",
            "|    time_elapsed         | 1311         |\n",
            "|    total_timesteps      | 610304       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051755803 |\n",
            "|    clip_fraction        | 0.0116       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.32        |\n",
            "|    explained_variance   | 0.214        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.147        |\n",
            "|    n_updates            | 2970         |\n",
            "|    policy_gradient_loss | -0.00131     |\n",
            "|    reward               | -0.03543948  |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.342        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 464           |\n",
            "|    iterations           | 299           |\n",
            "|    time_elapsed         | 1317          |\n",
            "|    total_timesteps      | 612352        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00031725454 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.32         |\n",
            "|    explained_variance   | 0.179         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.174         |\n",
            "|    n_updates            | 2980          |\n",
            "|    policy_gradient_loss | -0.000292     |\n",
            "|    reward               | -0.045182146  |\n",
            "|    std                  | 1.28          |\n",
            "|    value_loss           | 0.367         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 464          |\n",
            "|    iterations           | 300          |\n",
            "|    time_elapsed         | 1323         |\n",
            "|    total_timesteps      | 614400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016730762 |\n",
            "|    clip_fraction        | 0.00771      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.34        |\n",
            "|    explained_variance   | 0.148        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.252        |\n",
            "|    n_updates            | 2990         |\n",
            "|    policy_gradient_loss | -0.000476    |\n",
            "|    reward               | 0.3090361    |\n",
            "|    std                  | 1.3          |\n",
            "|    value_loss           | 0.492        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 463           |\n",
            "|    iterations           | 301           |\n",
            "|    time_elapsed         | 1329          |\n",
            "|    total_timesteps      | 616448        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00069646706 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.36         |\n",
            "|    explained_variance   | 0.11          |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0574        |\n",
            "|    n_updates            | 3000          |\n",
            "|    policy_gradient_loss | -7.62e-05     |\n",
            "|    reward               | -0.07044511   |\n",
            "|    std                  | 1.3           |\n",
            "|    value_loss           | 0.174         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 463          |\n",
            "|    iterations           | 302          |\n",
            "|    time_elapsed         | 1335         |\n",
            "|    total_timesteps      | 618496       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034295223 |\n",
            "|    clip_fraction        | 0.0082       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.36        |\n",
            "|    explained_variance   | 0.288        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.203        |\n",
            "|    n_updates            | 3010         |\n",
            "|    policy_gradient_loss | -0.000528    |\n",
            "|    reward               | 0.017575843  |\n",
            "|    std                  | 1.3          |\n",
            "|    value_loss           | 0.33         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 462          |\n",
            "|    iterations           | 303          |\n",
            "|    time_elapsed         | 1341         |\n",
            "|    total_timesteps      | 620544       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0072584795 |\n",
            "|    clip_fraction        | 0.0285       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.36        |\n",
            "|    explained_variance   | 0.325        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0766       |\n",
            "|    n_updates            | 3020         |\n",
            "|    policy_gradient_loss | -0.00214     |\n",
            "|    reward               | 0.0068474174 |\n",
            "|    std                  | 1.3          |\n",
            "|    value_loss           | 0.319        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 461         |\n",
            "|    iterations           | 304         |\n",
            "|    time_elapsed         | 1347        |\n",
            "|    total_timesteps      | 622592      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006607202 |\n",
            "|    clip_fraction        | 0.0671      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.36       |\n",
            "|    explained_variance   | 0.239       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0961      |\n",
            "|    n_updates            | 3030        |\n",
            "|    policy_gradient_loss | -0.00467    |\n",
            "|    reward               | 0.0974432   |\n",
            "|    std                  | 1.31        |\n",
            "|    value_loss           | 0.378       |\n",
            "-----------------------------------------\n",
            "day: 2707, episode: 230\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -147374.75\n",
            "total_reward: -157374.75\n",
            "total_cost: 395.61\n",
            "total_trades: 2676\n",
            "Sharpe: -0.212\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 461          |\n",
            "|    iterations           | 305          |\n",
            "|    time_elapsed         | 1353         |\n",
            "|    total_timesteps      | 624640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054700915 |\n",
            "|    clip_fraction        | 0.0215       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.36        |\n",
            "|    explained_variance   | 0.578        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00191      |\n",
            "|    n_updates            | 3040         |\n",
            "|    policy_gradient_loss | -0.00103     |\n",
            "|    reward               | -0.04758257  |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 0.0777       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 461          |\n",
            "|    iterations           | 306          |\n",
            "|    time_elapsed         | 1358         |\n",
            "|    total_timesteps      | 626688       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051536746 |\n",
            "|    clip_fraction        | 0.022        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.36        |\n",
            "|    explained_variance   | 0.527        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00339      |\n",
            "|    n_updates            | 3050         |\n",
            "|    policy_gradient_loss | -0.00126     |\n",
            "|    reward               | 0.1944912    |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 0.139        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 460          |\n",
            "|    iterations           | 307          |\n",
            "|    time_elapsed         | 1364         |\n",
            "|    total_timesteps      | 628736       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.001655784  |\n",
            "|    clip_fraction        | 0.000391     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.36        |\n",
            "|    explained_variance   | 0.373        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.133        |\n",
            "|    n_updates            | 3060         |\n",
            "|    policy_gradient_loss | -0.000599    |\n",
            "|    reward               | -0.013013761 |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 0.263        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 460         |\n",
            "|    iterations           | 308         |\n",
            "|    time_elapsed         | 1369        |\n",
            "|    total_timesteps      | 630784      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004698776 |\n",
            "|    clip_fraction        | 0.0289      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.35       |\n",
            "|    explained_variance   | 0.348       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.126       |\n",
            "|    n_updates            | 3070        |\n",
            "|    policy_gradient_loss | -0.00201    |\n",
            "|    reward               | -0.330972   |\n",
            "|    std                  | 1.29        |\n",
            "|    value_loss           | 0.229       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 460          |\n",
            "|    iterations           | 309          |\n",
            "|    time_elapsed         | 1374         |\n",
            "|    total_timesteps      | 632832       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030723717 |\n",
            "|    clip_fraction        | 0.00449      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.34        |\n",
            "|    explained_variance   | 0.17         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0549       |\n",
            "|    n_updates            | 3080         |\n",
            "|    policy_gradient_loss | -0.00136     |\n",
            "|    reward               | -0.22232847  |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.149        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 460          |\n",
            "|    iterations           | 310          |\n",
            "|    time_elapsed         | 1379         |\n",
            "|    total_timesteps      | 634880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004094489  |\n",
            "|    clip_fraction        | 0.00762      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.34        |\n",
            "|    explained_variance   | 0.494        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0131       |\n",
            "|    n_updates            | 3090         |\n",
            "|    policy_gradient_loss | -0.00145     |\n",
            "|    reward               | -0.026180938 |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.0779       |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 235\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -214011.46\n",
            "total_reward: -224011.46\n",
            "total_cost: 447.85\n",
            "total_trades: 2870\n",
            "Sharpe: 0.357\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 460          |\n",
            "|    iterations           | 311          |\n",
            "|    time_elapsed         | 1383         |\n",
            "|    total_timesteps      | 636928       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010515256 |\n",
            "|    clip_fraction        | 9.77e-05     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.34        |\n",
            "|    explained_variance   | 0.246        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.152        |\n",
            "|    n_updates            | 3100         |\n",
            "|    policy_gradient_loss | 6.96e-05     |\n",
            "|    reward               | 0.011306375  |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.289        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 460         |\n",
            "|    iterations           | 312         |\n",
            "|    time_elapsed         | 1387        |\n",
            "|    total_timesteps      | 638976      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.000972786 |\n",
            "|    clip_fraction        | 4.88e-05    |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.33       |\n",
            "|    explained_variance   | 0.171       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.173       |\n",
            "|    n_updates            | 3110        |\n",
            "|    policy_gradient_loss | -0.000251   |\n",
            "|    reward               | 0.26144895  |\n",
            "|    std                  | 1.29        |\n",
            "|    value_loss           | 0.406       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 460          |\n",
            "|    iterations           | 313          |\n",
            "|    time_elapsed         | 1392         |\n",
            "|    total_timesteps      | 641024       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038266142 |\n",
            "|    clip_fraction        | 0.0387       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.34        |\n",
            "|    explained_variance   | 1.46e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.21         |\n",
            "|    n_updates            | 3120         |\n",
            "|    policy_gradient_loss | -0.00242     |\n",
            "|    reward               | -0.004941854 |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.334        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 460          |\n",
            "|    iterations           | 314          |\n",
            "|    time_elapsed         | 1397         |\n",
            "|    total_timesteps      | 643072       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0004629945 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.34        |\n",
            "|    explained_variance   | 0.467        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0666       |\n",
            "|    n_updates            | 3130         |\n",
            "|    policy_gradient_loss | -0.000281    |\n",
            "|    reward               | 0.07052215   |\n",
            "|    std                  | 1.3          |\n",
            "|    value_loss           | 0.108        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 460          |\n",
            "|    iterations           | 315          |\n",
            "|    time_elapsed         | 1402         |\n",
            "|    total_timesteps      | 645120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061216634 |\n",
            "|    clip_fraction        | 0.0192       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.34        |\n",
            "|    explained_variance   | 0.37         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0257       |\n",
            "|    n_updates            | 3140         |\n",
            "|    policy_gradient_loss | -0.000373    |\n",
            "|    reward               | 0.024430174  |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.179        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 460         |\n",
            "|    iterations           | 316         |\n",
            "|    time_elapsed         | 1406        |\n",
            "|    total_timesteps      | 647168      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005988977 |\n",
            "|    clip_fraction        | 0.0252      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.34       |\n",
            "|    explained_variance   | 0.203       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.128       |\n",
            "|    n_updates            | 3150        |\n",
            "|    policy_gradient_loss | -0.00125    |\n",
            "|    reward               | -0.46756068 |\n",
            "|    std                  | 1.3         |\n",
            "|    value_loss           | 0.303       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 460         |\n",
            "|    iterations           | 317         |\n",
            "|    time_elapsed         | 1410        |\n",
            "|    total_timesteps      | 649216      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003012396 |\n",
            "|    clip_fraction        | 0.00112     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.35       |\n",
            "|    explained_variance   | 0.0258      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.154       |\n",
            "|    n_updates            | 3160        |\n",
            "|    policy_gradient_loss | -0.000713   |\n",
            "|    reward               | 0.2850382   |\n",
            "|    std                  | 1.3         |\n",
            "|    value_loss           | 0.297       |\n",
            "-----------------------------------------\n",
            "day: 2707, episode: 240\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -141105.39\n",
            "total_reward: -151105.39\n",
            "total_cost: 399.45\n",
            "total_trades: 2712\n",
            "Sharpe: 0.519\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 460          |\n",
            "|    iterations           | 318          |\n",
            "|    time_elapsed         | 1414         |\n",
            "|    total_timesteps      | 651264       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038869926 |\n",
            "|    clip_fraction        | 0.0337       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.35        |\n",
            "|    explained_variance   | 0.622        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00694      |\n",
            "|    n_updates            | 3170         |\n",
            "|    policy_gradient_loss | -0.00235     |\n",
            "|    reward               | 0.071944885  |\n",
            "|    std                  | 1.3          |\n",
            "|    value_loss           | 0.0568       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 460          |\n",
            "|    iterations           | 319          |\n",
            "|    time_elapsed         | 1419         |\n",
            "|    total_timesteps      | 653312       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055421097 |\n",
            "|    clip_fraction        | 0.0453       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.36        |\n",
            "|    explained_variance   | 0.364        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0188       |\n",
            "|    n_updates            | 3180         |\n",
            "|    policy_gradient_loss | -0.0027      |\n",
            "|    reward               | -0.011326711 |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 0.168        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 460         |\n",
            "|    iterations           | 320         |\n",
            "|    time_elapsed         | 1423        |\n",
            "|    total_timesteps      | 655360      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005914618 |\n",
            "|    clip_fraction        | 0.0289      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.36       |\n",
            "|    explained_variance   | 0.179       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.124       |\n",
            "|    n_updates            | 3190        |\n",
            "|    policy_gradient_loss | -0.00145    |\n",
            "|    reward               | 0.038487505 |\n",
            "|    std                  | 1.31        |\n",
            "|    value_loss           | 0.387       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 460          |\n",
            "|    iterations           | 321          |\n",
            "|    time_elapsed         | 1428         |\n",
            "|    total_timesteps      | 657408       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054071955 |\n",
            "|    clip_fraction        | 0.0492       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.36        |\n",
            "|    explained_variance   | 0.0115       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.467        |\n",
            "|    n_updates            | 3200         |\n",
            "|    policy_gradient_loss | -0.00318     |\n",
            "|    reward               | 0.4428941    |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 0.623        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 460          |\n",
            "|    iterations           | 322          |\n",
            "|    time_elapsed         | 1432         |\n",
            "|    total_timesteps      | 659456       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028725914 |\n",
            "|    clip_fraction        | 0.0119       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.37        |\n",
            "|    explained_variance   | 0.607        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0109      |\n",
            "|    n_updates            | 3210         |\n",
            "|    policy_gradient_loss | -0.00163     |\n",
            "|    reward               | 0.11889536   |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 0.0698       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 460          |\n",
            "|    iterations           | 323          |\n",
            "|    time_elapsed         | 1437         |\n",
            "|    total_timesteps      | 661504       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005052113  |\n",
            "|    clip_fraction        | 0.0383       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.37        |\n",
            "|    explained_variance   | 0.178        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.209        |\n",
            "|    n_updates            | 3220         |\n",
            "|    policy_gradient_loss | -0.00254     |\n",
            "|    reward               | -0.006876647 |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 0.535        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 245\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -258451.72\n",
            "total_reward: -268451.72\n",
            "total_cost: 454.89\n",
            "total_trades: 2910\n",
            "Sharpe: -0.361\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 460          |\n",
            "|    iterations           | 324          |\n",
            "|    time_elapsed         | 1441         |\n",
            "|    total_timesteps      | 663552       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047864746 |\n",
            "|    clip_fraction        | 0.00723      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.37        |\n",
            "|    explained_variance   | 0.183        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.221        |\n",
            "|    n_updates            | 3230         |\n",
            "|    policy_gradient_loss | -0.000708    |\n",
            "|    reward               | 0.013093299  |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 0.544        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 460          |\n",
            "|    iterations           | 325          |\n",
            "|    time_elapsed         | 1446         |\n",
            "|    total_timesteps      | 665600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021525226 |\n",
            "|    clip_fraction        | 0.00337      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.36        |\n",
            "|    explained_variance   | 0.0525       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.214        |\n",
            "|    n_updates            | 3240         |\n",
            "|    policy_gradient_loss | -0.000909    |\n",
            "|    reward               | -0.17048964  |\n",
            "|    std                  | 1.3          |\n",
            "|    value_loss           | 0.575        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 460           |\n",
            "|    iterations           | 326           |\n",
            "|    time_elapsed         | 1450          |\n",
            "|    total_timesteps      | 667648        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 5.2905438e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.35         |\n",
            "|    explained_variance   | 0.537         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.00698       |\n",
            "|    n_updates            | 3250          |\n",
            "|    policy_gradient_loss | -4.63e-05     |\n",
            "|    reward               | 0.14626251    |\n",
            "|    std                  | 1.3           |\n",
            "|    value_loss           | 0.109         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 460          |\n",
            "|    iterations           | 327          |\n",
            "|    time_elapsed         | 1455         |\n",
            "|    total_timesteps      | 669696       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021179672 |\n",
            "|    clip_fraction        | 0.000684     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.35        |\n",
            "|    explained_variance   | 0.222        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0739       |\n",
            "|    n_updates            | 3260         |\n",
            "|    policy_gradient_loss | -0.00106     |\n",
            "|    reward               | -0.014240588 |\n",
            "|    std                  | 1.3          |\n",
            "|    value_loss           | 0.484        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 460           |\n",
            "|    iterations           | 328           |\n",
            "|    time_elapsed         | 1459          |\n",
            "|    total_timesteps      | 671744        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00051283545 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.36         |\n",
            "|    explained_variance   | 0.217         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.231         |\n",
            "|    n_updates            | 3270          |\n",
            "|    policy_gradient_loss | 2.42e-05      |\n",
            "|    reward               | -0.000584157  |\n",
            "|    std                  | 1.3           |\n",
            "|    value_loss           | 0.565         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 460          |\n",
            "|    iterations           | 329          |\n",
            "|    time_elapsed         | 1463         |\n",
            "|    total_timesteps      | 673792       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046511423 |\n",
            "|    clip_fraction        | 0.0218       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.35        |\n",
            "|    explained_variance   | 0.107        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.285        |\n",
            "|    n_updates            | 3280         |\n",
            "|    policy_gradient_loss | -0.000993    |\n",
            "|    reward               | -0.615603    |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.561        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 460          |\n",
            "|    iterations           | 330          |\n",
            "|    time_elapsed         | 1468         |\n",
            "|    total_timesteps      | 675840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056158416 |\n",
            "|    clip_fraction        | 0.036        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.33        |\n",
            "|    explained_variance   | 0.43         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0161       |\n",
            "|    n_updates            | 3290         |\n",
            "|    policy_gradient_loss | -0.00258     |\n",
            "|    reward               | -0.09208062  |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.107        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 250\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -236664.52\n",
            "total_reward: -246664.52\n",
            "total_cost: 452.86\n",
            "total_trades: 2880\n",
            "Sharpe: 0.436\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 459         |\n",
            "|    iterations           | 331         |\n",
            "|    time_elapsed         | 1473        |\n",
            "|    total_timesteps      | 677888      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.00674155  |\n",
            "|    clip_fraction        | 0.0198      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.33       |\n",
            "|    explained_variance   | 0.201       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.192       |\n",
            "|    n_updates            | 3300        |\n",
            "|    policy_gradient_loss | -0.00304    |\n",
            "|    reward               | -0.03776412 |\n",
            "|    std                  | 1.29        |\n",
            "|    value_loss           | 0.439       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 459          |\n",
            "|    iterations           | 332          |\n",
            "|    time_elapsed         | 1478         |\n",
            "|    total_timesteps      | 679936       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.008021138  |\n",
            "|    clip_fraction        | 0.0325       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.33        |\n",
            "|    explained_variance   | 0.206        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.165        |\n",
            "|    n_updates            | 3310         |\n",
            "|    policy_gradient_loss | -0.00224     |\n",
            "|    reward               | -0.028609876 |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.471        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 459          |\n",
            "|    iterations           | 333          |\n",
            "|    time_elapsed         | 1482         |\n",
            "|    total_timesteps      | 681984       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0076313536 |\n",
            "|    clip_fraction        | 0.0643       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.33        |\n",
            "|    explained_variance   | 0.177        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.137        |\n",
            "|    n_updates            | 3320         |\n",
            "|    policy_gradient_loss | -0.00382     |\n",
            "|    reward               | -0.09202691  |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.339        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 459          |\n",
            "|    iterations           | 334          |\n",
            "|    time_elapsed         | 1487         |\n",
            "|    total_timesteps      | 684032       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0077145128 |\n",
            "|    clip_fraction        | 0.0672       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.33        |\n",
            "|    explained_variance   | 0.587        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0123       |\n",
            "|    n_updates            | 3330         |\n",
            "|    policy_gradient_loss | -0.00309     |\n",
            "|    reward               | 0.020887455  |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.097        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 459          |\n",
            "|    iterations           | 335          |\n",
            "|    time_elapsed         | 1493         |\n",
            "|    total_timesteps      | 686080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0001243176 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.33        |\n",
            "|    explained_variance   | 0.342        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0622       |\n",
            "|    n_updates            | 3340         |\n",
            "|    policy_gradient_loss | 0.000176     |\n",
            "|    reward               | -0.016069604 |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.276        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 458          |\n",
            "|    iterations           | 336          |\n",
            "|    time_elapsed         | 1499         |\n",
            "|    total_timesteps      | 688128       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021722487 |\n",
            "|    clip_fraction        | 0.0132       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.33        |\n",
            "|    explained_variance   | 0.406        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.079        |\n",
            "|    n_updates            | 3350         |\n",
            "|    policy_gradient_loss | -0.000971    |\n",
            "|    reward               | 0.014682935  |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.271        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 458         |\n",
            "|    iterations           | 337         |\n",
            "|    time_elapsed         | 1505        |\n",
            "|    total_timesteps      | 690176      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004172095 |\n",
            "|    clip_fraction        | 0.0368      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.32       |\n",
            "|    explained_variance   | 0.259       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.112       |\n",
            "|    n_updates            | 3360        |\n",
            "|    policy_gradient_loss | -0.00263    |\n",
            "|    reward               | 0.14456245  |\n",
            "|    std                  | 1.27        |\n",
            "|    value_loss           | 0.273       |\n",
            "-----------------------------------------\n",
            "day: 2707, episode: 255\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -166821.51\n",
            "total_reward: -176821.51\n",
            "total_cost: 376.75\n",
            "total_trades: 2668\n",
            "Sharpe: 0.145\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 457         |\n",
            "|    iterations           | 338         |\n",
            "|    time_elapsed         | 1512        |\n",
            "|    total_timesteps      | 692224      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005944474 |\n",
            "|    clip_fraction        | 0.0157      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.31       |\n",
            "|    explained_variance   | 0.587       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.027       |\n",
            "|    n_updates            | 3370        |\n",
            "|    policy_gradient_loss | -0.000425   |\n",
            "|    reward               | -0.09218555 |\n",
            "|    std                  | 1.27        |\n",
            "|    value_loss           | 0.0893      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 457          |\n",
            "|    iterations           | 339          |\n",
            "|    time_elapsed         | 1517         |\n",
            "|    total_timesteps      | 694272       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010181444 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.31        |\n",
            "|    explained_variance   | 0.484        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0738       |\n",
            "|    n_updates            | 3380         |\n",
            "|    policy_gradient_loss | 0.000229     |\n",
            "|    reward               | 0.03470681   |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.161        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 457          |\n",
            "|    iterations           | 340          |\n",
            "|    time_elapsed         | 1523         |\n",
            "|    total_timesteps      | 696320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0063826167 |\n",
            "|    clip_fraction        | 0.0382       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.3         |\n",
            "|    explained_variance   | 0.446        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0733       |\n",
            "|    n_updates            | 3390         |\n",
            "|    policy_gradient_loss | -0.00217     |\n",
            "|    reward               | 0.019602254  |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.164        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 456          |\n",
            "|    iterations           | 341          |\n",
            "|    time_elapsed         | 1528         |\n",
            "|    total_timesteps      | 698368       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032742764 |\n",
            "|    clip_fraction        | 0.0118       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.29        |\n",
            "|    explained_variance   | 0.289        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.104        |\n",
            "|    n_updates            | 3400         |\n",
            "|    policy_gradient_loss | -0.000383    |\n",
            "|    reward               | -0.09858818  |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.217        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 456          |\n",
            "|    iterations           | 342          |\n",
            "|    time_elapsed         | 1533         |\n",
            "|    total_timesteps      | 700416       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049968828 |\n",
            "|    clip_fraction        | 0.00537      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | 0.49         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00706      |\n",
            "|    n_updates            | 3410         |\n",
            "|    policy_gradient_loss | 0.000176     |\n",
            "|    reward               | 0.032866523  |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.0916       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 456          |\n",
            "|    iterations           | 343          |\n",
            "|    time_elapsed         | 1537         |\n",
            "|    total_timesteps      | 702464       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013860235 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | 0.412        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0649       |\n",
            "|    n_updates            | 3420         |\n",
            "|    policy_gradient_loss | -2.51e-05    |\n",
            "|    reward               | -0.020384168 |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.181        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 260\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -188538.86\n",
            "total_reward: -198538.86\n",
            "total_cost: 438.90\n",
            "total_trades: 2820\n",
            "Sharpe: 0.441\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 456           |\n",
            "|    iterations           | 344           |\n",
            "|    time_elapsed         | 1541          |\n",
            "|    total_timesteps      | 704512        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.007142172   |\n",
            "|    clip_fraction        | 0.0183        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.29         |\n",
            "|    explained_variance   | 0.429         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0432        |\n",
            "|    n_updates            | 3430          |\n",
            "|    policy_gradient_loss | -0.000156     |\n",
            "|    reward               | -0.0076308325 |\n",
            "|    std                  | 1.26          |\n",
            "|    value_loss           | 0.177         |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 456         |\n",
            "|    iterations           | 345         |\n",
            "|    time_elapsed         | 1546        |\n",
            "|    total_timesteps      | 706560      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003133845 |\n",
            "|    clip_fraction        | 0.0243      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.29       |\n",
            "|    explained_variance   | 0.257       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.187       |\n",
            "|    n_updates            | 3440        |\n",
            "|    policy_gradient_loss | -0.00131    |\n",
            "|    reward               | 0.22464605  |\n",
            "|    std                  | 1.27        |\n",
            "|    value_loss           | 0.315       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 456          |\n",
            "|    iterations           | 346          |\n",
            "|    time_elapsed         | 1551         |\n",
            "|    total_timesteps      | 708608       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.003964965  |\n",
            "|    clip_fraction        | 0.00884      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.31        |\n",
            "|    explained_variance   | 0.453        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0191       |\n",
            "|    n_updates            | 3450         |\n",
            "|    policy_gradient_loss | -0.000659    |\n",
            "|    reward               | -0.041173197 |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.108        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 456          |\n",
            "|    iterations           | 347          |\n",
            "|    time_elapsed         | 1557         |\n",
            "|    total_timesteps      | 710656       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031921738 |\n",
            "|    clip_fraction        | 0.0457       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.32        |\n",
            "|    explained_variance   | 0.487        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0352       |\n",
            "|    n_updates            | 3460         |\n",
            "|    policy_gradient_loss | -0.00399     |\n",
            "|    reward               | 0.060252637  |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.178        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 455          |\n",
            "|    iterations           | 348          |\n",
            "|    time_elapsed         | 1562         |\n",
            "|    total_timesteps      | 712704       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011077758 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.32        |\n",
            "|    explained_variance   | 0.371        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0972       |\n",
            "|    n_updates            | 3470         |\n",
            "|    policy_gradient_loss | -2.34e-05    |\n",
            "|    reward               | -0.017221456 |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.271        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 455          |\n",
            "|    iterations           | 349          |\n",
            "|    time_elapsed         | 1568         |\n",
            "|    total_timesteps      | 714752       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037693803 |\n",
            "|    clip_fraction        | 0.0331       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.33        |\n",
            "|    explained_variance   | 0.355        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0657       |\n",
            "|    n_updates            | 3480         |\n",
            "|    policy_gradient_loss | -0.00214     |\n",
            "|    reward               | 0.28281122   |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.243        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 455          |\n",
            "|    iterations           | 350          |\n",
            "|    time_elapsed         | 1573         |\n",
            "|    total_timesteps      | 716800       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027532498 |\n",
            "|    clip_fraction        | 0.00132      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.34        |\n",
            "|    explained_variance   | 0.325        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0356       |\n",
            "|    n_updates            | 3490         |\n",
            "|    policy_gradient_loss | 7.8e-05      |\n",
            "|    reward               | 0.008763726  |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.154        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 265\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -122787.36\n",
            "total_reward: -132787.36\n",
            "total_cost: 390.09\n",
            "total_trades: 2682\n",
            "Sharpe: 0.310\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 455          |\n",
            "|    iterations           | 351          |\n",
            "|    time_elapsed         | 1578         |\n",
            "|    total_timesteps      | 718848       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.00822039   |\n",
            "|    clip_fraction        | 0.0417       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.34        |\n",
            "|    explained_variance   | 0.713        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0141      |\n",
            "|    n_updates            | 3500         |\n",
            "|    policy_gradient_loss | -0.00194     |\n",
            "|    reward               | 0.0060403883 |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.0608       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 455          |\n",
            "|    iterations           | 352          |\n",
            "|    time_elapsed         | 1582         |\n",
            "|    total_timesteps      | 720896       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037291057 |\n",
            "|    clip_fraction        | 0.0272       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.35        |\n",
            "|    explained_variance   | 0.539        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00808      |\n",
            "|    n_updates            | 3510         |\n",
            "|    policy_gradient_loss | -0.00125     |\n",
            "|    reward               | 0.008486906  |\n",
            "|    std                  | 1.3          |\n",
            "|    value_loss           | 0.117        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 455          |\n",
            "|    iterations           | 353          |\n",
            "|    time_elapsed         | 1586         |\n",
            "|    total_timesteps      | 722944       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006481969  |\n",
            "|    clip_fraction        | 0.0564       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.35        |\n",
            "|    explained_variance   | 0.514        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00194      |\n",
            "|    n_updates            | 3520         |\n",
            "|    policy_gradient_loss | -0.00369     |\n",
            "|    reward               | -0.048034742 |\n",
            "|    std                  | 1.3          |\n",
            "|    value_loss           | 0.0985       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 455          |\n",
            "|    iterations           | 354          |\n",
            "|    time_elapsed         | 1591         |\n",
            "|    total_timesteps      | 724992       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052072504 |\n",
            "|    clip_fraction        | 0.0131       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.36        |\n",
            "|    explained_variance   | 0.303        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00576      |\n",
            "|    n_updates            | 3530         |\n",
            "|    policy_gradient_loss | -0.00125     |\n",
            "|    reward               | -0.01830443  |\n",
            "|    std                  | 1.3          |\n",
            "|    value_loss           | 0.122        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 455           |\n",
            "|    iterations           | 355           |\n",
            "|    time_elapsed         | 1596          |\n",
            "|    total_timesteps      | 727040        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00027180582 |\n",
            "|    clip_fraction        | 0.00195       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.36         |\n",
            "|    explained_variance   | 0.76          |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0217       |\n",
            "|    n_updates            | 3540          |\n",
            "|    policy_gradient_loss | -6.31e-05     |\n",
            "|    reward               | -0.21462065   |\n",
            "|    std                  | 1.31          |\n",
            "|    value_loss           | 0.0342        |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 455         |\n",
            "|    iterations           | 356         |\n",
            "|    time_elapsed         | 1600        |\n",
            "|    total_timesteps      | 729088      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002585256 |\n",
            "|    clip_fraction        | 0.0061      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.36       |\n",
            "|    explained_variance   | 0.488       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0206      |\n",
            "|    n_updates            | 3550        |\n",
            "|    policy_gradient_loss | -9.6e-06    |\n",
            "|    reward               | 0.009525511 |\n",
            "|    std                  | 1.3         |\n",
            "|    value_loss           | 0.119       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 455          |\n",
            "|    iterations           | 357          |\n",
            "|    time_elapsed         | 1604         |\n",
            "|    total_timesteps      | 731136       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051810984 |\n",
            "|    clip_fraction        | 0.0792       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.36        |\n",
            "|    explained_variance   | 0.414        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0608       |\n",
            "|    n_updates            | 3560         |\n",
            "|    policy_gradient_loss | -0.00437     |\n",
            "|    reward               | -0.103906736 |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 0.146        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 270\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -90760.31\n",
            "total_reward: -100760.31\n",
            "total_cost: 351.22\n",
            "total_trades: 2492\n",
            "Sharpe: -0.342\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 455          |\n",
            "|    iterations           | 358          |\n",
            "|    time_elapsed         | 1608         |\n",
            "|    total_timesteps      | 733184       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044281096 |\n",
            "|    clip_fraction        | 0.0274       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.36        |\n",
            "|    explained_variance   | 0.386        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00717     |\n",
            "|    n_updates            | 3570         |\n",
            "|    policy_gradient_loss | -0.00123     |\n",
            "|    reward               | -0.066305995 |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 0.067        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 455          |\n",
            "|    iterations           | 359          |\n",
            "|    time_elapsed         | 1612         |\n",
            "|    total_timesteps      | 735232       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053498643 |\n",
            "|    clip_fraction        | 0.034        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.37        |\n",
            "|    explained_variance   | 0.805        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0283      |\n",
            "|    n_updates            | 3580         |\n",
            "|    policy_gradient_loss | -0.00307     |\n",
            "|    reward               | 0.49611136   |\n",
            "|    std                  | 1.32         |\n",
            "|    value_loss           | 0.0181       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 455          |\n",
            "|    iterations           | 360          |\n",
            "|    time_elapsed         | 1617         |\n",
            "|    total_timesteps      | 737280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041324813 |\n",
            "|    clip_fraction        | 0.0146       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.39        |\n",
            "|    explained_variance   | 0.364        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0668       |\n",
            "|    n_updates            | 3590         |\n",
            "|    policy_gradient_loss | -0.00104     |\n",
            "|    reward               | -0.010808135 |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 0.137        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 455         |\n",
            "|    iterations           | 361         |\n",
            "|    time_elapsed         | 1621        |\n",
            "|    total_timesteps      | 739328      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004431354 |\n",
            "|    clip_fraction        | 0.0173      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.39       |\n",
            "|    explained_variance   | 0.136       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.364       |\n",
            "|    n_updates            | 3600        |\n",
            "|    policy_gradient_loss | -0.000726   |\n",
            "|    reward               | 0.057115205 |\n",
            "|    std                  | 1.33        |\n",
            "|    value_loss           | 0.76        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 455          |\n",
            "|    iterations           | 362          |\n",
            "|    time_elapsed         | 1626         |\n",
            "|    total_timesteps      | 741376       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034235248 |\n",
            "|    clip_fraction        | 0.00278      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.4         |\n",
            "|    explained_variance   | 0.231        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00446      |\n",
            "|    n_updates            | 3610         |\n",
            "|    policy_gradient_loss | -0.000149    |\n",
            "|    reward               | -0.026874783 |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 0.114        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 455         |\n",
            "|    iterations           | 363         |\n",
            "|    time_elapsed         | 1631        |\n",
            "|    total_timesteps      | 743424      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.00445881  |\n",
            "|    clip_fraction        | 0.00571     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.4        |\n",
            "|    explained_variance   | 0.757       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0128     |\n",
            "|    n_updates            | 3620        |\n",
            "|    policy_gradient_loss | -0.000408   |\n",
            "|    reward               | 0.019944295 |\n",
            "|    std                  | 1.34        |\n",
            "|    value_loss           | 0.0307      |\n",
            "-----------------------------------------\n",
            "day: 2707, episode: 275\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -126846.46\n",
            "total_reward: -136846.46\n",
            "total_cost: 348.88\n",
            "total_trades: 2470\n",
            "Sharpe: -0.109\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 455         |\n",
            "|    iterations           | 364         |\n",
            "|    time_elapsed         | 1635        |\n",
            "|    total_timesteps      | 745472      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001586671 |\n",
            "|    clip_fraction        | 0.000195    |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.41       |\n",
            "|    explained_variance   | 0.399       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 9.34e-06    |\n",
            "|    n_updates            | 3630        |\n",
            "|    policy_gradient_loss | -0.000343   |\n",
            "|    reward               | 0.019829517 |\n",
            "|    std                  | 1.34        |\n",
            "|    value_loss           | 0.119       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 455          |\n",
            "|    iterations           | 365          |\n",
            "|    time_elapsed         | 1641         |\n",
            "|    total_timesteps      | 747520       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.003721144  |\n",
            "|    clip_fraction        | 0.00444      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.42        |\n",
            "|    explained_variance   | 0.386        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0177       |\n",
            "|    n_updates            | 3640         |\n",
            "|    policy_gradient_loss | -0.000795    |\n",
            "|    reward               | 0.0007560524 |\n",
            "|    std                  | 1.34         |\n",
            "|    value_loss           | 0.134        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 455         |\n",
            "|    iterations           | 366         |\n",
            "|    time_elapsed         | 1647        |\n",
            "|    total_timesteps      | 749568      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005714003 |\n",
            "|    clip_fraction        | 0.0547      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.42       |\n",
            "|    explained_variance   | 0.0952      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0658      |\n",
            "|    n_updates            | 3650        |\n",
            "|    policy_gradient_loss | -0.00277    |\n",
            "|    reward               | 0.062267236 |\n",
            "|    std                  | 1.34        |\n",
            "|    value_loss           | 0.21        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 454          |\n",
            "|    iterations           | 367          |\n",
            "|    time_elapsed         | 1653         |\n",
            "|    total_timesteps      | 751616       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031973175 |\n",
            "|    clip_fraction        | 0.00454      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.42        |\n",
            "|    explained_variance   | 0.45         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00656     |\n",
            "|    n_updates            | 3660         |\n",
            "|    policy_gradient_loss | -0.000633    |\n",
            "|    reward               | -0.08280411  |\n",
            "|    std                  | 1.35         |\n",
            "|    value_loss           | 0.0453       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 454           |\n",
            "|    iterations           | 368           |\n",
            "|    time_elapsed         | 1659          |\n",
            "|    total_timesteps      | 753664        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0039944747  |\n",
            "|    clip_fraction        | 0.00396       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.42         |\n",
            "|    explained_variance   | 0.219         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0149        |\n",
            "|    n_updates            | 3670          |\n",
            "|    policy_gradient_loss | -0.000773     |\n",
            "|    reward               | -0.0048885276 |\n",
            "|    std                  | 1.34          |\n",
            "|    value_loss           | 0.166         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 453          |\n",
            "|    iterations           | 369          |\n",
            "|    time_elapsed         | 1665         |\n",
            "|    total_timesteps      | 755712       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047984226 |\n",
            "|    clip_fraction        | 0.0303       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.42        |\n",
            "|    explained_variance   | 0.166        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0879       |\n",
            "|    n_updates            | 3680         |\n",
            "|    policy_gradient_loss | -0.00237     |\n",
            "|    reward               | -0.022855112 |\n",
            "|    std                  | 1.35         |\n",
            "|    value_loss           | 0.255        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 453          |\n",
            "|    iterations           | 370          |\n",
            "|    time_elapsed         | 1671         |\n",
            "|    total_timesteps      | 757760       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023130786 |\n",
            "|    clip_fraction        | 0.0109       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.43        |\n",
            "|    explained_variance   | 0.0947       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.077        |\n",
            "|    n_updates            | 3690         |\n",
            "|    policy_gradient_loss | -0.00114     |\n",
            "|    reward               | 0.29065803   |\n",
            "|    std                  | 1.35         |\n",
            "|    value_loss           | 0.276        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 280\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -167130.28\n",
            "total_reward: -177130.28\n",
            "total_cost: 399.26\n",
            "total_trades: 2664\n",
            "Sharpe: 0.075\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 453         |\n",
            "|    iterations           | 371         |\n",
            "|    time_elapsed         | 1676        |\n",
            "|    total_timesteps      | 759808      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.00265254  |\n",
            "|    clip_fraction        | 0.00781     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.43       |\n",
            "|    explained_variance   | 0.304       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0114     |\n",
            "|    n_updates            | 3700        |\n",
            "|    policy_gradient_loss | -0.000381   |\n",
            "|    reward               | -0.12843442 |\n",
            "|    std                  | 1.35        |\n",
            "|    value_loss           | 0.0543      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 452          |\n",
            "|    iterations           | 372          |\n",
            "|    time_elapsed         | 1682         |\n",
            "|    total_timesteps      | 761856       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060132165 |\n",
            "|    clip_fraction        | 0.0326       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.44        |\n",
            "|    explained_variance   | 0.193        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0209       |\n",
            "|    n_updates            | 3710         |\n",
            "|    policy_gradient_loss | -0.00209     |\n",
            "|    reward               | 0.0396788    |\n",
            "|    std                  | 1.36         |\n",
            "|    value_loss           | 0.213        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 452           |\n",
            "|    iterations           | 373           |\n",
            "|    time_elapsed         | 1688          |\n",
            "|    total_timesteps      | 763904        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00014574066 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.44         |\n",
            "|    explained_variance   | 0.175         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.119         |\n",
            "|    n_updates            | 3720          |\n",
            "|    policy_gradient_loss | 5.75e-05      |\n",
            "|    reward               | -0.0013225359 |\n",
            "|    std                  | 1.36          |\n",
            "|    value_loss           | 0.297         |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 452         |\n",
            "|    iterations           | 374         |\n",
            "|    time_elapsed         | 1694        |\n",
            "|    total_timesteps      | 765952      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006633243 |\n",
            "|    clip_fraction        | 0.0498      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.45       |\n",
            "|    explained_variance   | 0.172       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.159       |\n",
            "|    n_updates            | 3730        |\n",
            "|    policy_gradient_loss | -0.00434    |\n",
            "|    reward               | 0.24296623  |\n",
            "|    std                  | 1.37        |\n",
            "|    value_loss           | 0.197       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 451          |\n",
            "|    iterations           | 375          |\n",
            "|    time_elapsed         | 1699         |\n",
            "|    total_timesteps      | 768000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004043564  |\n",
            "|    clip_fraction        | 0.00552      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.47        |\n",
            "|    explained_variance   | 0.592        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.016       |\n",
            "|    n_updates            | 3740         |\n",
            "|    policy_gradient_loss | -0.00152     |\n",
            "|    reward               | -0.030626746 |\n",
            "|    std                  | 1.38         |\n",
            "|    value_loss           | 0.0482       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 451           |\n",
            "|    iterations           | 376           |\n",
            "|    time_elapsed         | 1705          |\n",
            "|    total_timesteps      | 770048        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00022801408 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.47         |\n",
            "|    explained_variance   | 0.42          |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0226        |\n",
            "|    n_updates            | 3750          |\n",
            "|    policy_gradient_loss | 0.000285      |\n",
            "|    reward               | -0.004509402  |\n",
            "|    std                  | 1.37          |\n",
            "|    value_loss           | 0.121         |\n",
            "-------------------------------------------\n",
            "day: 2707, episode: 285\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -139788.36\n",
            "total_reward: -149788.36\n",
            "total_cost: 402.39\n",
            "total_trades: 2768\n",
            "Sharpe: -0.053\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 451           |\n",
            "|    iterations           | 377           |\n",
            "|    time_elapsed         | 1710          |\n",
            "|    total_timesteps      | 772096        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00060986145 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.47         |\n",
            "|    explained_variance   | 0.503         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.00548       |\n",
            "|    n_updates            | 3760          |\n",
            "|    policy_gradient_loss | -7.32e-05     |\n",
            "|    reward               | -0.012279919  |\n",
            "|    std                  | 1.38          |\n",
            "|    value_loss           | 0.0971        |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 451           |\n",
            "|    iterations           | 378           |\n",
            "|    time_elapsed         | 1716          |\n",
            "|    total_timesteps      | 774144        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00477709    |\n",
            "|    clip_fraction        | 0.0429        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.49         |\n",
            "|    explained_variance   | 0.243         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0683        |\n",
            "|    n_updates            | 3770          |\n",
            "|    policy_gradient_loss | -0.00287      |\n",
            "|    reward               | -0.0022749465 |\n",
            "|    std                  | 1.4           |\n",
            "|    value_loss           | 0.168         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 450          |\n",
            "|    iterations           | 379          |\n",
            "|    time_elapsed         | 1722         |\n",
            "|    total_timesteps      | 776192       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015189379 |\n",
            "|    clip_fraction        | 0.000977     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.5         |\n",
            "|    explained_variance   | 0.189        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00936      |\n",
            "|    n_updates            | 3780         |\n",
            "|    policy_gradient_loss | -0.000222    |\n",
            "|    reward               | -0.06728553  |\n",
            "|    std                  | 1.4          |\n",
            "|    value_loss           | 0.0667       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 450          |\n",
            "|    iterations           | 380          |\n",
            "|    time_elapsed         | 1728         |\n",
            "|    total_timesteps      | 778240       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.001135845  |\n",
            "|    clip_fraction        | 0.000342     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.51        |\n",
            "|    explained_variance   | 0.298        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0595       |\n",
            "|    n_updates            | 3790         |\n",
            "|    policy_gradient_loss | -0.000548    |\n",
            "|    reward               | -0.007820666 |\n",
            "|    std                  | 1.4          |\n",
            "|    value_loss           | 0.129        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 450          |\n",
            "|    iterations           | 381          |\n",
            "|    time_elapsed         | 1733         |\n",
            "|    total_timesteps      | 780288       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009725837 |\n",
            "|    clip_fraction        | 9.77e-05     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.51        |\n",
            "|    explained_variance   | 0.284        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00544      |\n",
            "|    n_updates            | 3800         |\n",
            "|    policy_gradient_loss | -0.000321    |\n",
            "|    reward               | 0.028399007  |\n",
            "|    std                  | 1.4          |\n",
            "|    value_loss           | 0.108        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 449         |\n",
            "|    iterations           | 382         |\n",
            "|    time_elapsed         | 1739        |\n",
            "|    total_timesteps      | 782336      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004325893 |\n",
            "|    clip_fraction        | 0.0104      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.51       |\n",
            "|    explained_variance   | 0.195       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0816      |\n",
            "|    n_updates            | 3810        |\n",
            "|    policy_gradient_loss | -0.000396   |\n",
            "|    reward               | -0.09072509 |\n",
            "|    std                  | 1.41        |\n",
            "|    value_loss           | 0.155       |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 449           |\n",
            "|    iterations           | 383           |\n",
            "|    time_elapsed         | 1745          |\n",
            "|    total_timesteps      | 784384        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00056639634 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.51         |\n",
            "|    explained_variance   | 0.0944        |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.00854       |\n",
            "|    n_updates            | 3820          |\n",
            "|    policy_gradient_loss | 0.000146      |\n",
            "|    reward               | -0.078041956  |\n",
            "|    std                  | 1.4           |\n",
            "|    value_loss           | 0.0813        |\n",
            "-------------------------------------------\n",
            "day: 2707, episode: 290\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -147434.82\n",
            "total_reward: -157434.82\n",
            "total_cost: 414.87\n",
            "total_trades: 2792\n",
            "Sharpe: 0.276\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 449          |\n",
            "|    iterations           | 384          |\n",
            "|    time_elapsed         | 1751         |\n",
            "|    total_timesteps      | 786432       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037000414 |\n",
            "|    clip_fraction        | 0.00488      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.51        |\n",
            "|    explained_variance   | 0.189        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0115       |\n",
            "|    n_updates            | 3830         |\n",
            "|    policy_gradient_loss | -0.000777    |\n",
            "|    reward               | -0.084386595 |\n",
            "|    std                  | 1.41         |\n",
            "|    value_loss           | 0.15         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 448          |\n",
            "|    iterations           | 385          |\n",
            "|    time_elapsed         | 1756         |\n",
            "|    total_timesteps      | 788480       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.003085344  |\n",
            "|    clip_fraction        | 0.00728      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.51        |\n",
            "|    explained_variance   | 0.203        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0391       |\n",
            "|    n_updates            | 3840         |\n",
            "|    policy_gradient_loss | -0.00158     |\n",
            "|    reward               | -0.012421068 |\n",
            "|    std                  | 1.41         |\n",
            "|    value_loss           | 0.183        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 448          |\n",
            "|    iterations           | 386          |\n",
            "|    time_elapsed         | 1762         |\n",
            "|    total_timesteps      | 790528       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026895779 |\n",
            "|    clip_fraction        | 0.00464      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.52        |\n",
            "|    explained_variance   | 0.135        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.117        |\n",
            "|    n_updates            | 3850         |\n",
            "|    policy_gradient_loss | 2.26e-07     |\n",
            "|    reward               | 1.139935     |\n",
            "|    std                  | 1.42         |\n",
            "|    value_loss           | 0.343        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 448          |\n",
            "|    iterations           | 387          |\n",
            "|    time_elapsed         | 1768         |\n",
            "|    total_timesteps      | 792576       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038637186 |\n",
            "|    clip_fraction        | 0.00972      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.53        |\n",
            "|    explained_variance   | 0.221        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0337       |\n",
            "|    n_updates            | 3860         |\n",
            "|    policy_gradient_loss | -0.000488    |\n",
            "|    reward               | 0.002470365  |\n",
            "|    std                  | 1.42         |\n",
            "|    value_loss           | 0.151        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 448          |\n",
            "|    iterations           | 388          |\n",
            "|    time_elapsed         | 1773         |\n",
            "|    total_timesteps      | 794624       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0064692777 |\n",
            "|    clip_fraction        | 0.0474       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.54        |\n",
            "|    explained_variance   | 0.452        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0326       |\n",
            "|    n_updates            | 3870         |\n",
            "|    policy_gradient_loss | -0.003       |\n",
            "|    reward               | 0.102093674  |\n",
            "|    std                  | 1.42         |\n",
            "|    value_loss           | 0.132        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 447          |\n",
            "|    iterations           | 389          |\n",
            "|    time_elapsed         | 1779         |\n",
            "|    total_timesteps      | 796672       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032260274 |\n",
            "|    clip_fraction        | 0.0043       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.54        |\n",
            "|    explained_variance   | 0.29         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0827       |\n",
            "|    n_updates            | 3880         |\n",
            "|    policy_gradient_loss | -0.000549    |\n",
            "|    reward               | 0.03042708   |\n",
            "|    std                  | 1.43         |\n",
            "|    value_loss           | 0.338        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 447          |\n",
            "|    iterations           | 390          |\n",
            "|    time_elapsed         | 1784         |\n",
            "|    total_timesteps      | 798720       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037918556 |\n",
            "|    clip_fraction        | 0.0294       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.53        |\n",
            "|    explained_variance   | 0.242        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.222        |\n",
            "|    n_updates            | 3890         |\n",
            "|    policy_gradient_loss | -0.00216     |\n",
            "|    reward               | -0.2637693   |\n",
            "|    std                  | 1.41         |\n",
            "|    value_loss           | 0.424        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 295\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -230448.36\n",
            "total_reward: -240448.36\n",
            "total_cost: 455.75\n",
            "total_trades: 2934\n",
            "Sharpe: 0.386\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 447          |\n",
            "|    iterations           | 391          |\n",
            "|    time_elapsed         | 1790         |\n",
            "|    total_timesteps      | 800768       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035441807 |\n",
            "|    clip_fraction        | 0.0155       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.53        |\n",
            "|    explained_variance   | 0.215        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.202        |\n",
            "|    n_updates            | 3900         |\n",
            "|    policy_gradient_loss | -0.000901    |\n",
            "|    reward               | -0.46740794  |\n",
            "|    std                  | 1.42         |\n",
            "|    value_loss           | 0.362        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 446          |\n",
            "|    iterations           | 392          |\n",
            "|    time_elapsed         | 1796         |\n",
            "|    total_timesteps      | 802816       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022492711 |\n",
            "|    clip_fraction        | 0.000928     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.54        |\n",
            "|    explained_variance   | 0.613        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.000211    |\n",
            "|    n_updates            | 3910         |\n",
            "|    policy_gradient_loss | -0.0004      |\n",
            "|    reward               | -0.06355206  |\n",
            "|    std                  | 1.43         |\n",
            "|    value_loss           | 0.129        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 446          |\n",
            "|    iterations           | 393          |\n",
            "|    time_elapsed         | 1802         |\n",
            "|    total_timesteps      | 804864       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027534415 |\n",
            "|    clip_fraction        | 0.0182       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.54        |\n",
            "|    explained_variance   | 0.328        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.231        |\n",
            "|    n_updates            | 3920         |\n",
            "|    policy_gradient_loss | -0.000862    |\n",
            "|    reward               | -0.019249171 |\n",
            "|    std                  | 1.42         |\n",
            "|    value_loss           | 0.517        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 446          |\n",
            "|    iterations           | 394          |\n",
            "|    time_elapsed         | 1807         |\n",
            "|    total_timesteps      | 806912       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026383204 |\n",
            "|    clip_fraction        | 0.0222       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.55        |\n",
            "|    explained_variance   | 0.294        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.217        |\n",
            "|    n_updates            | 3930         |\n",
            "|    policy_gradient_loss | -0.00145     |\n",
            "|    reward               | 0.42437094   |\n",
            "|    std                  | 1.44         |\n",
            "|    value_loss           | 0.599        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 446          |\n",
            "|    iterations           | 395          |\n",
            "|    time_elapsed         | 1813         |\n",
            "|    total_timesteps      | 808960       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027494759 |\n",
            "|    clip_fraction        | 0.00132      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.56        |\n",
            "|    explained_variance   | 0.144        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.305        |\n",
            "|    n_updates            | 3940         |\n",
            "|    policy_gradient_loss | -0.000627    |\n",
            "|    reward               | -0.64744896  |\n",
            "|    std                  | 1.44         |\n",
            "|    value_loss           | 0.604        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 445          |\n",
            "|    iterations           | 396          |\n",
            "|    time_elapsed         | 1819         |\n",
            "|    total_timesteps      | 811008       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045433734 |\n",
            "|    clip_fraction        | 0.0318       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.56        |\n",
            "|    explained_variance   | 0.643        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0593       |\n",
            "|    n_updates            | 3950         |\n",
            "|    policy_gradient_loss | -0.00191     |\n",
            "|    reward               | 0.03982815   |\n",
            "|    std                  | 1.44         |\n",
            "|    value_loss           | 0.157        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 300\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -180234.22\n",
            "total_reward: -190234.22\n",
            "total_cost: 412.63\n",
            "total_trades: 2762\n",
            "Sharpe: 0.030\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 445          |\n",
            "|    iterations           | 397          |\n",
            "|    time_elapsed         | 1825         |\n",
            "|    total_timesteps      | 813056       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0057233684 |\n",
            "|    clip_fraction        | 0.0487       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.56        |\n",
            "|    explained_variance   | 0.41         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.139        |\n",
            "|    n_updates            | 3960         |\n",
            "|    policy_gradient_loss | -0.00266     |\n",
            "|    reward               | 0.029807214  |\n",
            "|    std                  | 1.44         |\n",
            "|    value_loss           | 0.451        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 445          |\n",
            "|    iterations           | 398          |\n",
            "|    time_elapsed         | 1830         |\n",
            "|    total_timesteps      | 815104       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052055274 |\n",
            "|    clip_fraction        | 0.0347       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.57        |\n",
            "|    explained_variance   | 0.501        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.116        |\n",
            "|    n_updates            | 3970         |\n",
            "|    policy_gradient_loss | -0.00247     |\n",
            "|    reward               | -0.027689673 |\n",
            "|    std                  | 1.46         |\n",
            "|    value_loss           | 0.276        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 445          |\n",
            "|    iterations           | 399          |\n",
            "|    time_elapsed         | 1836         |\n",
            "|    total_timesteps      | 817152       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017242557 |\n",
            "|    clip_fraction        | 0.000732     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.58        |\n",
            "|    explained_variance   | 0.0715       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.086        |\n",
            "|    n_updates            | 3980         |\n",
            "|    policy_gradient_loss | -0.000512    |\n",
            "|    reward               | 0.15596484   |\n",
            "|    std                  | 1.46         |\n",
            "|    value_loss           | 0.352        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 444          |\n",
            "|    iterations           | 400          |\n",
            "|    time_elapsed         | 1841         |\n",
            "|    total_timesteps      | 819200       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024522431 |\n",
            "|    clip_fraction        | 0.00146      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.59        |\n",
            "|    explained_variance   | 0.86         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0172      |\n",
            "|    n_updates            | 3990         |\n",
            "|    policy_gradient_loss | -0.000305    |\n",
            "|    reward               | -0.13536507  |\n",
            "|    std                  | 1.46         |\n",
            "|    value_loss           | 0.0358       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 444          |\n",
            "|    iterations           | 401          |\n",
            "|    time_elapsed         | 1848         |\n",
            "|    total_timesteps      | 821248       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036718375 |\n",
            "|    clip_fraction        | 0.0259       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.59        |\n",
            "|    explained_variance   | 0.491        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0807       |\n",
            "|    n_updates            | 4000         |\n",
            "|    policy_gradient_loss | -0.00073     |\n",
            "|    reward               | 0.034274556  |\n",
            "|    std                  | 1.47         |\n",
            "|    value_loss           | 0.243        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 443          |\n",
            "|    iterations           | 402          |\n",
            "|    time_elapsed         | 1854         |\n",
            "|    total_timesteps      | 823296       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037928806 |\n",
            "|    clip_fraction        | 0.0113       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.61        |\n",
            "|    explained_variance   | 0.564        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0716       |\n",
            "|    n_updates            | 4010         |\n",
            "|    policy_gradient_loss | -0.000758    |\n",
            "|    reward               | 0.010131984  |\n",
            "|    std                  | 1.49         |\n",
            "|    value_loss           | 0.173        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 443          |\n",
            "|    iterations           | 403          |\n",
            "|    time_elapsed         | 1860         |\n",
            "|    total_timesteps      | 825344       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039189337 |\n",
            "|    clip_fraction        | 0.0506       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.63        |\n",
            "|    explained_variance   | 0.34         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0704       |\n",
            "|    n_updates            | 4020         |\n",
            "|    policy_gradient_loss | -0.00331     |\n",
            "|    reward               | -0.15722553  |\n",
            "|    std                  | 1.5          |\n",
            "|    value_loss           | 0.192        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 305\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -169558.39\n",
            "total_reward: -179558.39\n",
            "total_cost: 376.37\n",
            "total_trades: 2678\n",
            "Sharpe: 0.410\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 443          |\n",
            "|    iterations           | 404          |\n",
            "|    time_elapsed         | 1866         |\n",
            "|    total_timesteps      | 827392       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0063761603 |\n",
            "|    clip_fraction        | 0.0421       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.63        |\n",
            "|    explained_variance   | 0.758        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0258      |\n",
            "|    n_updates            | 4030         |\n",
            "|    policy_gradient_loss | -0.00308     |\n",
            "|    reward               | 0.12541181   |\n",
            "|    std                  | 1.49         |\n",
            "|    value_loss           | 0.0477       |\n",
            "------------------------------------------\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 443            |\n",
            "|    iterations           | 405            |\n",
            "|    time_elapsed         | 1871           |\n",
            "|    total_timesteps      | 829440         |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.0047470243   |\n",
            "|    clip_fraction        | 0.0495         |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -3.62          |\n",
            "|    explained_variance   | 0.467          |\n",
            "|    learning_rate        | 0.00025        |\n",
            "|    loss                 | 0.0293         |\n",
            "|    n_updates            | 4040           |\n",
            "|    policy_gradient_loss | -0.00106       |\n",
            "|    reward               | -0.00074692996 |\n",
            "|    std                  | 1.48           |\n",
            "|    value_loss           | 0.203          |\n",
            "--------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 442          |\n",
            "|    iterations           | 406          |\n",
            "|    time_elapsed         | 1877         |\n",
            "|    total_timesteps      | 831488       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006156892  |\n",
            "|    clip_fraction        | 0.0441       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.62        |\n",
            "|    explained_variance   | 0.501        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0512       |\n",
            "|    n_updates            | 4050         |\n",
            "|    policy_gradient_loss | -0.00279     |\n",
            "|    reward               | -0.012722572 |\n",
            "|    std                  | 1.49         |\n",
            "|    value_loss           | 0.179        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 442          |\n",
            "|    iterations           | 407          |\n",
            "|    time_elapsed         | 1882         |\n",
            "|    total_timesteps      | 833536       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036344458 |\n",
            "|    clip_fraction        | 0.0114       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.63        |\n",
            "|    explained_variance   | 0.329        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0285       |\n",
            "|    n_updates            | 4060         |\n",
            "|    policy_gradient_loss | -0.00162     |\n",
            "|    reward               | -0.016143512 |\n",
            "|    std                  | 1.49         |\n",
            "|    value_loss           | 0.149        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 442         |\n",
            "|    iterations           | 408         |\n",
            "|    time_elapsed         | 1888        |\n",
            "|    total_timesteps      | 835584      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003754143 |\n",
            "|    clip_fraction        | 0.0326      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.62       |\n",
            "|    explained_variance   | 0.78        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0289     |\n",
            "|    n_updates            | 4070        |\n",
            "|    policy_gradient_loss | -0.00364    |\n",
            "|    reward               | 0.05395144  |\n",
            "|    std                  | 1.48        |\n",
            "|    value_loss           | 0.031       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 442          |\n",
            "|    iterations           | 409          |\n",
            "|    time_elapsed         | 1894         |\n",
            "|    total_timesteps      | 837632       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029319923 |\n",
            "|    clip_fraction        | 0.00757      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.62        |\n",
            "|    explained_variance   | 0.57         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0135       |\n",
            "|    n_updates            | 4080         |\n",
            "|    policy_gradient_loss | -0.00073     |\n",
            "|    reward               | 0.009189703  |\n",
            "|    std                  | 1.49         |\n",
            "|    value_loss           | 0.0951       |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 310\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -103355.71\n",
            "total_reward: -113355.71\n",
            "total_cost: 371.11\n",
            "total_trades: 2744\n",
            "Sharpe: -0.396\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 441          |\n",
            "|    iterations           | 410          |\n",
            "|    time_elapsed         | 1899         |\n",
            "|    total_timesteps      | 839680       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006310679  |\n",
            "|    clip_fraction        | 0.0262       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.62        |\n",
            "|    explained_variance   | 0.682        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0172      |\n",
            "|    n_updates            | 4090         |\n",
            "|    policy_gradient_loss | -0.000565    |\n",
            "|    reward               | -0.008844953 |\n",
            "|    std                  | 1.49         |\n",
            "|    value_loss           | 0.0501       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 441         |\n",
            "|    iterations           | 411         |\n",
            "|    time_elapsed         | 1905        |\n",
            "|    total_timesteps      | 841728      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005421759 |\n",
            "|    clip_fraction        | 0.0178      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.62       |\n",
            "|    explained_variance   | 0.341       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.00323    |\n",
            "|    n_updates            | 4100        |\n",
            "|    policy_gradient_loss | -0.0017     |\n",
            "|    reward               | 0.038522154 |\n",
            "|    std                  | 1.48        |\n",
            "|    value_loss           | 0.0813      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 441          |\n",
            "|    iterations           | 412          |\n",
            "|    time_elapsed         | 1911         |\n",
            "|    total_timesteps      | 843776       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0006024437 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.61        |\n",
            "|    explained_variance   | 0.8          |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0315      |\n",
            "|    n_updates            | 4110         |\n",
            "|    policy_gradient_loss | -0.000301    |\n",
            "|    reward               | 0.009698633  |\n",
            "|    std                  | 1.47         |\n",
            "|    value_loss           | 0.0143       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 441          |\n",
            "|    iterations           | 413          |\n",
            "|    time_elapsed         | 1917         |\n",
            "|    total_timesteps      | 845824       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.00475436   |\n",
            "|    clip_fraction        | 0.0269       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.6         |\n",
            "|    explained_variance   | 0.561        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0318      |\n",
            "|    n_updates            | 4120         |\n",
            "|    policy_gradient_loss | -0.00274     |\n",
            "|    reward               | 0.0001544403 |\n",
            "|    std                  | 1.47         |\n",
            "|    value_loss           | 0.0332       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 440          |\n",
            "|    iterations           | 414          |\n",
            "|    time_elapsed         | 1923         |\n",
            "|    total_timesteps      | 847872       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024864823 |\n",
            "|    clip_fraction        | 0.00815      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.6         |\n",
            "|    explained_variance   | 0.501        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0379      |\n",
            "|    n_updates            | 4130         |\n",
            "|    policy_gradient_loss | -0.000744    |\n",
            "|    reward               | 0.012956011  |\n",
            "|    std                  | 1.47         |\n",
            "|    value_loss           | 0.0209       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 440         |\n",
            "|    iterations           | 415         |\n",
            "|    time_elapsed         | 1929        |\n",
            "|    total_timesteps      | 849920      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004453319 |\n",
            "|    clip_fraction        | 0.0538      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.61       |\n",
            "|    explained_variance   | 0.0769      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.117       |\n",
            "|    n_updates            | 4140        |\n",
            "|    policy_gradient_loss | -0.00316    |\n",
            "|    reward               | 0.26301363  |\n",
            "|    std                  | 1.48        |\n",
            "|    value_loss           | 0.375       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 440          |\n",
            "|    iterations           | 416          |\n",
            "|    time_elapsed         | 1935         |\n",
            "|    total_timesteps      | 851968       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058915103 |\n",
            "|    clip_fraction        | 0.00815      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.61        |\n",
            "|    explained_variance   | 0.73         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.017       |\n",
            "|    n_updates            | 4150         |\n",
            "|    policy_gradient_loss | -0.000935    |\n",
            "|    reward               | 0.038376328  |\n",
            "|    std                  | 1.48         |\n",
            "|    value_loss           | 0.0187       |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 315\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -261467.30\n",
            "total_reward: -271467.30\n",
            "total_cost: 379.45\n",
            "total_trades: 2614\n",
            "Sharpe: 0.223\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 439          |\n",
            "|    iterations           | 417          |\n",
            "|    time_elapsed         | 1941         |\n",
            "|    total_timesteps      | 854016       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034422441 |\n",
            "|    clip_fraction        | 0.0236       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.6         |\n",
            "|    explained_variance   | 0.341        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.012       |\n",
            "|    n_updates            | 4160         |\n",
            "|    policy_gradient_loss | -0.000498    |\n",
            "|    reward               | -0.02246566  |\n",
            "|    std                  | 1.48         |\n",
            "|    value_loss           | 0.0646       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 439          |\n",
            "|    iterations           | 418          |\n",
            "|    time_elapsed         | 1947         |\n",
            "|    total_timesteps      | 856064       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041299346 |\n",
            "|    clip_fraction        | 0.00649      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.61        |\n",
            "|    explained_variance   | 0.191        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.141        |\n",
            "|    n_updates            | 4170         |\n",
            "|    policy_gradient_loss | -0.00151     |\n",
            "|    reward               | 0.017260062  |\n",
            "|    std                  | 1.48         |\n",
            "|    value_loss           | 0.408        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 439          |\n",
            "|    iterations           | 419          |\n",
            "|    time_elapsed         | 1952         |\n",
            "|    total_timesteps      | 858112       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0067116953 |\n",
            "|    clip_fraction        | 0.0266       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.61        |\n",
            "|    explained_variance   | 0.671        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0328      |\n",
            "|    n_updates            | 4180         |\n",
            "|    policy_gradient_loss | -0.00284     |\n",
            "|    reward               | 0.09591442   |\n",
            "|    std                  | 1.49         |\n",
            "|    value_loss           | 0.0224       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 438          |\n",
            "|    iterations           | 420          |\n",
            "|    time_elapsed         | 1959         |\n",
            "|    total_timesteps      | 860160       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004749431  |\n",
            "|    clip_fraction        | 0.0105       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.62        |\n",
            "|    explained_variance   | 0.472        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00567     |\n",
            "|    n_updates            | 4190         |\n",
            "|    policy_gradient_loss | -0.00206     |\n",
            "|    reward               | -0.006591491 |\n",
            "|    std                  | 1.49         |\n",
            "|    value_loss           | 0.0472       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 438          |\n",
            "|    iterations           | 421          |\n",
            "|    time_elapsed         | 1966         |\n",
            "|    total_timesteps      | 862208       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024745534 |\n",
            "|    clip_fraction        | 0.00356      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.63        |\n",
            "|    explained_variance   | 0.446        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.000816     |\n",
            "|    n_updates            | 4200         |\n",
            "|    policy_gradient_loss | 0.000103     |\n",
            "|    reward               | 0.01390284   |\n",
            "|    std                  | 1.51         |\n",
            "|    value_loss           | 0.0981       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 437           |\n",
            "|    iterations           | 422           |\n",
            "|    time_elapsed         | 1973          |\n",
            "|    total_timesteps      | 864256        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0041298894  |\n",
            "|    clip_fraction        | 0.0509        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.65         |\n",
            "|    explained_variance   | 0.285         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0867        |\n",
            "|    n_updates            | 4210          |\n",
            "|    policy_gradient_loss | -0.00365      |\n",
            "|    reward               | -0.0006569927 |\n",
            "|    std                  | 1.51          |\n",
            "|    value_loss           | 0.264         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 437          |\n",
            "|    iterations           | 423          |\n",
            "|    time_elapsed         | 1980         |\n",
            "|    total_timesteps      | 866304       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054680347 |\n",
            "|    clip_fraction        | 0.042        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.66        |\n",
            "|    explained_variance   | 0.547        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0161      |\n",
            "|    n_updates            | 4220         |\n",
            "|    policy_gradient_loss | -0.00313     |\n",
            "|    reward               | 0.12216661   |\n",
            "|    std                  | 1.52         |\n",
            "|    value_loss           | 0.0429       |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 320\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -349311.97\n",
            "total_reward: -359311.97\n",
            "total_cost: 402.08\n",
            "total_trades: 2626\n",
            "Sharpe: 0.121\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 436          |\n",
            "|    iterations           | 424          |\n",
            "|    time_elapsed         | 1988         |\n",
            "|    total_timesteps      | 868352       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041577583 |\n",
            "|    clip_fraction        | 0.0193       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.67        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.156        |\n",
            "|    n_updates            | 4230         |\n",
            "|    policy_gradient_loss | -0.00106     |\n",
            "|    reward               | -0.15379122  |\n",
            "|    std                  | 1.52         |\n",
            "|    value_loss           | 0.387        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 436          |\n",
            "|    iterations           | 425          |\n",
            "|    time_elapsed         | 1994         |\n",
            "|    total_timesteps      | 870400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018712733 |\n",
            "|    clip_fraction        | 0.00591      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.66        |\n",
            "|    explained_variance   | 0.105        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.242        |\n",
            "|    n_updates            | 4240         |\n",
            "|    policy_gradient_loss | -0.000506    |\n",
            "|    reward               | 0.0033635604 |\n",
            "|    std                  | 1.51         |\n",
            "|    value_loss           | 0.514        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 436          |\n",
            "|    iterations           | 426          |\n",
            "|    time_elapsed         | 2000         |\n",
            "|    total_timesteps      | 872448       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044651255 |\n",
            "|    clip_fraction        | 0.0132       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.65        |\n",
            "|    explained_variance   | 0.317        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.11         |\n",
            "|    n_updates            | 4250         |\n",
            "|    policy_gradient_loss | -0.00111     |\n",
            "|    reward               | 0.013751304  |\n",
            "|    std                  | 1.51         |\n",
            "|    value_loss           | 0.266        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 436          |\n",
            "|    iterations           | 427          |\n",
            "|    time_elapsed         | 2005         |\n",
            "|    total_timesteps      | 874496       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020907228 |\n",
            "|    clip_fraction        | 0.019        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.64        |\n",
            "|    explained_variance   | 0.732        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0389      |\n",
            "|    n_updates            | 4260         |\n",
            "|    policy_gradient_loss | -0.00109     |\n",
            "|    reward               | -0.75465864  |\n",
            "|    std                  | 1.5          |\n",
            "|    value_loss           | 0.0152       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 428          |\n",
            "|    time_elapsed         | 2011         |\n",
            "|    total_timesteps      | 876544       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043176226 |\n",
            "|    clip_fraction        | 0.0316       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.64        |\n",
            "|    explained_variance   | -0.0107      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0051       |\n",
            "|    n_updates            | 4270         |\n",
            "|    policy_gradient_loss | -0.00246     |\n",
            "|    reward               | -0.026116468 |\n",
            "|    std                  | 1.5          |\n",
            "|    value_loss           | 0.151        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 429          |\n",
            "|    time_elapsed         | 2016         |\n",
            "|    total_timesteps      | 878592       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025261117 |\n",
            "|    clip_fraction        | 0.0107       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.64        |\n",
            "|    explained_variance   | 0.417        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0138      |\n",
            "|    n_updates            | 4280         |\n",
            "|    policy_gradient_loss | -0.00103     |\n",
            "|    reward               | -0.042010356 |\n",
            "|    std                  | 1.51         |\n",
            "|    value_loss           | 0.069        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 325\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -63035.74\n",
            "total_reward: -73035.74\n",
            "total_cost: 364.67\n",
            "total_trades: 2660\n",
            "Sharpe: 0.538\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 430          |\n",
            "|    time_elapsed         | 2022         |\n",
            "|    total_timesteps      | 880640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0002453757 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.65        |\n",
            "|    explained_variance   | 0.342        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.137        |\n",
            "|    n_updates            | 4290         |\n",
            "|    policy_gradient_loss | -0.000313    |\n",
            "|    reward               | -0.036358397 |\n",
            "|    std                  | 1.51         |\n",
            "|    value_loss           | 0.272        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 431          |\n",
            "|    time_elapsed         | 2028         |\n",
            "|    total_timesteps      | 882688       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035003661 |\n",
            "|    clip_fraction        | 0.0233       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.65        |\n",
            "|    explained_variance   | 0.753        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0284      |\n",
            "|    n_updates            | 4300         |\n",
            "|    policy_gradient_loss | -0.00191     |\n",
            "|    reward               | -0.2703115   |\n",
            "|    std                  | 1.51         |\n",
            "|    value_loss           | 0.0309       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 432          |\n",
            "|    time_elapsed         | 2034         |\n",
            "|    total_timesteps      | 884736       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054993904 |\n",
            "|    clip_fraction        | 0.0392       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.66        |\n",
            "|    explained_variance   | 0.142        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.196        |\n",
            "|    n_updates            | 4310         |\n",
            "|    policy_gradient_loss | -0.003       |\n",
            "|    reward               | -0.062182646 |\n",
            "|    std                  | 1.52         |\n",
            "|    value_loss           | 0.353        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 434         |\n",
            "|    iterations           | 433         |\n",
            "|    time_elapsed         | 2040        |\n",
            "|    total_timesteps      | 886784      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006074216 |\n",
            "|    clip_fraction        | 0.019       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.66       |\n",
            "|    explained_variance   | 0.387       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0153     |\n",
            "|    n_updates            | 4320        |\n",
            "|    policy_gradient_loss | -0.000933   |\n",
            "|    reward               | 0.024270562 |\n",
            "|    std                  | 1.52        |\n",
            "|    value_loss           | 0.0654      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 434          |\n",
            "|    time_elapsed         | 2045         |\n",
            "|    total_timesteps      | 888832       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004164339  |\n",
            "|    clip_fraction        | 0.00908      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.67        |\n",
            "|    explained_variance   | 0.604        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0285       |\n",
            "|    n_updates            | 4330         |\n",
            "|    policy_gradient_loss | -0.00185     |\n",
            "|    reward               | 0.0013290137 |\n",
            "|    std                  | 1.53         |\n",
            "|    value_loss           | 0.119        |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 434        |\n",
            "|    iterations           | 435        |\n",
            "|    time_elapsed         | 2050       |\n",
            "|    total_timesteps      | 890880     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00348441 |\n",
            "|    clip_fraction        | 0.00439    |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.68      |\n",
            "|    explained_variance   | 0.574      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 0.018      |\n",
            "|    n_updates            | 4340       |\n",
            "|    policy_gradient_loss | -0.000554  |\n",
            "|    reward               | 0.05726478 |\n",
            "|    std                  | 1.54       |\n",
            "|    value_loss           | 0.138      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 434        |\n",
            "|    iterations           | 436        |\n",
            "|    time_elapsed         | 2055       |\n",
            "|    total_timesteps      | 892928     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00313027 |\n",
            "|    clip_fraction        | 0.0124     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.69      |\n",
            "|    explained_variance   | 0.76       |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.025     |\n",
            "|    n_updates            | 4350       |\n",
            "|    policy_gradient_loss | -0.000548  |\n",
            "|    reward               | 0.08498844 |\n",
            "|    std                  | 1.55       |\n",
            "|    value_loss           | 0.0259     |\n",
            "----------------------------------------\n",
            "day: 2707, episode: 330\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -297984.46\n",
            "total_reward: -307984.46\n",
            "total_cost: 386.42\n",
            "total_trades: 2608\n",
            "Sharpe: 0.420\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 437          |\n",
            "|    time_elapsed         | 2059         |\n",
            "|    total_timesteps      | 894976       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043480466 |\n",
            "|    clip_fraction        | 0.0287       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.7         |\n",
            "|    explained_variance   | 0.225        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0158       |\n",
            "|    n_updates            | 4360         |\n",
            "|    policy_gradient_loss | -0.00158     |\n",
            "|    reward               | -0.14502847  |\n",
            "|    std                  | 1.55         |\n",
            "|    value_loss           | 0.104        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 434         |\n",
            "|    iterations           | 438         |\n",
            "|    time_elapsed         | 2065        |\n",
            "|    total_timesteps      | 897024      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002717485 |\n",
            "|    clip_fraction        | 0.0115      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.71       |\n",
            "|    explained_variance   | 0.153       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.251       |\n",
            "|    n_updates            | 4370        |\n",
            "|    policy_gradient_loss | -0.000291   |\n",
            "|    reward               | -0.02605336 |\n",
            "|    std                  | 1.56        |\n",
            "|    value_loss           | 0.457       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 439          |\n",
            "|    time_elapsed         | 2071         |\n",
            "|    total_timesteps      | 899072       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.00510201   |\n",
            "|    clip_fraction        | 0.0154       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.71        |\n",
            "|    explained_variance   | 0.194        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.214        |\n",
            "|    n_updates            | 4380         |\n",
            "|    policy_gradient_loss | -0.00184     |\n",
            "|    reward               | -0.004503925 |\n",
            "|    std                  | 1.56         |\n",
            "|    value_loss           | 0.711        |\n",
            "------------------------------------------\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 433            |\n",
            "|    iterations           | 440            |\n",
            "|    time_elapsed         | 2076           |\n",
            "|    total_timesteps      | 901120         |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.005684116    |\n",
            "|    clip_fraction        | 0.0347         |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -3.71          |\n",
            "|    explained_variance   | 0.0832         |\n",
            "|    learning_rate        | 0.00025        |\n",
            "|    loss                 | 0.281          |\n",
            "|    n_updates            | 4390           |\n",
            "|    policy_gradient_loss | -0.00146       |\n",
            "|    reward               | -0.00038945602 |\n",
            "|    std                  | 1.56           |\n",
            "|    value_loss           | 0.575          |\n",
            "--------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 441          |\n",
            "|    time_elapsed         | 2082         |\n",
            "|    total_timesteps      | 903168       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026813133 |\n",
            "|    clip_fraction        | 0.00801      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.72        |\n",
            "|    explained_variance   | 0.915        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0358      |\n",
            "|    n_updates            | 4400         |\n",
            "|    policy_gradient_loss | -0.000982    |\n",
            "|    reward               | -0.21824837  |\n",
            "|    std                  | 1.56         |\n",
            "|    value_loss           | 0.00698      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 433         |\n",
            "|    iterations           | 442         |\n",
            "|    time_elapsed         | 2088        |\n",
            "|    total_timesteps      | 905216      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002540003 |\n",
            "|    clip_fraction        | 0.0316      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.71       |\n",
            "|    explained_variance   | 0.67        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0281     |\n",
            "|    n_updates            | 4410        |\n",
            "|    policy_gradient_loss | -3.41e-05   |\n",
            "|    reward               | 0.035723757 |\n",
            "|    std                  | 1.56        |\n",
            "|    value_loss           | 0.0287      |\n",
            "-----------------------------------------\n",
            "day: 2707, episode: 335\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -155667.25\n",
            "total_reward: -165667.25\n",
            "total_cost: 367.96\n",
            "total_trades: 2610\n",
            "Sharpe: 0.038\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 443          |\n",
            "|    time_elapsed         | 2093         |\n",
            "|    total_timesteps      | 907264       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.002332492  |\n",
            "|    clip_fraction        | 0.0116       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.72        |\n",
            "|    explained_variance   | 0.322        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00966      |\n",
            "|    n_updates            | 4420         |\n",
            "|    policy_gradient_loss | -0.00386     |\n",
            "|    reward               | -0.011483299 |\n",
            "|    std                  | 1.56         |\n",
            "|    value_loss           | 0.108        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 444          |\n",
            "|    time_elapsed         | 2099         |\n",
            "|    total_timesteps      | 909312       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036094978 |\n",
            "|    clip_fraction        | 0.0161       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.72        |\n",
            "|    explained_variance   | 0.0774       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00532     |\n",
            "|    n_updates            | 4430         |\n",
            "|    policy_gradient_loss | -0.00529     |\n",
            "|    reward               | -0.07385053  |\n",
            "|    std                  | 1.57         |\n",
            "|    value_loss           | 0.103        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 432         |\n",
            "|    iterations           | 445         |\n",
            "|    time_elapsed         | 2105        |\n",
            "|    total_timesteps      | 911360      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004692495 |\n",
            "|    clip_fraction        | 0.0245      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.72       |\n",
            "|    explained_variance   | 0.536       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.022      |\n",
            "|    n_updates            | 4440        |\n",
            "|    policy_gradient_loss | -0.002      |\n",
            "|    reward               | 0.26703936  |\n",
            "|    std                  | 1.56        |\n",
            "|    value_loss           | 0.0321      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 446          |\n",
            "|    time_elapsed         | 2110         |\n",
            "|    total_timesteps      | 913408       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047281384 |\n",
            "|    clip_fraction        | 0.0287       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.71        |\n",
            "|    explained_variance   | 0.371        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0218      |\n",
            "|    n_updates            | 4450         |\n",
            "|    policy_gradient_loss | -0.00705     |\n",
            "|    reward               | 0.020177668  |\n",
            "|    std                  | 1.55         |\n",
            "|    value_loss           | 0.0575       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 447          |\n",
            "|    time_elapsed         | 2116         |\n",
            "|    total_timesteps      | 915456       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030386029 |\n",
            "|    clip_fraction        | 0.00518      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.71        |\n",
            "|    explained_variance   | 0.43         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00448      |\n",
            "|    n_updates            | 4460         |\n",
            "|    policy_gradient_loss | -0.00345     |\n",
            "|    reward               | -0.005388349 |\n",
            "|    std                  | 1.55         |\n",
            "|    value_loss           | 0.0786       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 448          |\n",
            "|    time_elapsed         | 2122         |\n",
            "|    total_timesteps      | 917504       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055547664 |\n",
            "|    clip_fraction        | 0.0308       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.71        |\n",
            "|    explained_variance   | 0.337        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0234      |\n",
            "|    n_updates            | 4470         |\n",
            "|    policy_gradient_loss | -0.00169     |\n",
            "|    reward               | -0.08304334  |\n",
            "|    std                  | 1.56         |\n",
            "|    value_loss           | 0.0283       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 449          |\n",
            "|    time_elapsed         | 2128         |\n",
            "|    total_timesteps      | 919552       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028673236 |\n",
            "|    clip_fraction        | 0.0217       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.71        |\n",
            "|    explained_variance   | 0.601        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.025       |\n",
            "|    n_updates            | 4480         |\n",
            "|    policy_gradient_loss | -0.00198     |\n",
            "|    reward               | 0.013150306  |\n",
            "|    std                  | 1.57         |\n",
            "|    value_loss           | 0.0165       |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 340\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -87318.50\n",
            "total_reward: -97318.50\n",
            "total_cost: 436.95\n",
            "total_trades: 2728\n",
            "Sharpe: -0.249\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 431           |\n",
            "|    iterations           | 450           |\n",
            "|    time_elapsed         | 2133          |\n",
            "|    total_timesteps      | 921600        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.007510408   |\n",
            "|    clip_fraction        | 0.0863        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.72         |\n",
            "|    explained_variance   | 0.324         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0106       |\n",
            "|    n_updates            | 4490          |\n",
            "|    policy_gradient_loss | -0.00569      |\n",
            "|    reward               | -0.0024100572 |\n",
            "|    std                  | 1.57          |\n",
            "|    value_loss           | 0.0561        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 431          |\n",
            "|    iterations           | 451          |\n",
            "|    time_elapsed         | 2139         |\n",
            "|    total_timesteps      | 923648       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046754233 |\n",
            "|    clip_fraction        | 0.0229       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.72        |\n",
            "|    explained_variance   | 0.253        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00911     |\n",
            "|    n_updates            | 4500         |\n",
            "|    policy_gradient_loss | -0.00121     |\n",
            "|    reward               | 0.00545278   |\n",
            "|    std                  | 1.57         |\n",
            "|    value_loss           | 0.0478       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 431          |\n",
            "|    iterations           | 452          |\n",
            "|    time_elapsed         | 2145         |\n",
            "|    total_timesteps      | 925696       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027104206 |\n",
            "|    clip_fraction        | 0.0206       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.74        |\n",
            "|    explained_variance   | 0.142        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0192      |\n",
            "|    n_updates            | 4510         |\n",
            "|    policy_gradient_loss | -0.00562     |\n",
            "|    reward               | -0.05881207  |\n",
            "|    std                  | 1.59         |\n",
            "|    value_loss           | 0.056        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 431         |\n",
            "|    iterations           | 453         |\n",
            "|    time_elapsed         | 2151        |\n",
            "|    total_timesteps      | 927744      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005018605 |\n",
            "|    clip_fraction        | 0.0384      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.75       |\n",
            "|    explained_variance   | 0.589       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0351     |\n",
            "|    n_updates            | 4520        |\n",
            "|    policy_gradient_loss | -0.00301    |\n",
            "|    reward               | -0.03857861 |\n",
            "|    std                  | 1.59        |\n",
            "|    value_loss           | 0.0187      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 431         |\n",
            "|    iterations           | 454         |\n",
            "|    time_elapsed         | 2157        |\n",
            "|    total_timesteps      | 929792      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007150555 |\n",
            "|    clip_fraction        | 0.0695      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.75       |\n",
            "|    explained_variance   | 0.389       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0154     |\n",
            "|    n_updates            | 4530        |\n",
            "|    policy_gradient_loss | -0.00304    |\n",
            "|    reward               | -0.04766179 |\n",
            "|    std                  | 1.59        |\n",
            "|    value_loss           | 0.0361      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 455          |\n",
            "|    time_elapsed         | 2163         |\n",
            "|    total_timesteps      | 931840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039976686 |\n",
            "|    clip_fraction        | 0.0343       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.75        |\n",
            "|    explained_variance   | 0.597        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0194      |\n",
            "|    n_updates            | 4540         |\n",
            "|    policy_gradient_loss | -0.00186     |\n",
            "|    reward               | 0.01201388   |\n",
            "|    std                  | 1.59         |\n",
            "|    value_loss           | 0.0244       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 430         |\n",
            "|    iterations           | 456         |\n",
            "|    time_elapsed         | 2168        |\n",
            "|    total_timesteps      | 933888      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008037136 |\n",
            "|    clip_fraction        | 0.0604      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.75       |\n",
            "|    explained_variance   | 0.234       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0115      |\n",
            "|    n_updates            | 4550        |\n",
            "|    policy_gradient_loss | -0.00408    |\n",
            "|    reward               | 0.062994696 |\n",
            "|    std                  | 1.59        |\n",
            "|    value_loss           | 0.0769      |\n",
            "-----------------------------------------\n",
            "day: 2707, episode: 345\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -68369.43\n",
            "total_reward: -78369.43\n",
            "total_cost: 417.50\n",
            "total_trades: 2638\n",
            "Sharpe: -0.421\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 457          |\n",
            "|    time_elapsed         | 2174         |\n",
            "|    total_timesteps      | 935936       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.003156373  |\n",
            "|    clip_fraction        | 0.0151       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.75        |\n",
            "|    explained_variance   | 0.346        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0265      |\n",
            "|    n_updates            | 4560         |\n",
            "|    policy_gradient_loss | -0.00173     |\n",
            "|    reward               | -0.019146372 |\n",
            "|    std                  | 1.59         |\n",
            "|    value_loss           | 0.0128       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 458          |\n",
            "|    time_elapsed         | 2179         |\n",
            "|    total_timesteps      | 937984       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025715316 |\n",
            "|    clip_fraction        | 0.0281       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.75        |\n",
            "|    explained_variance   | 0.559        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0314      |\n",
            "|    n_updates            | 4570         |\n",
            "|    policy_gradient_loss | -0.00216     |\n",
            "|    reward               | -0.03327234  |\n",
            "|    std                  | 1.6          |\n",
            "|    value_loss           | 0.0231       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 459          |\n",
            "|    time_elapsed         | 2185         |\n",
            "|    total_timesteps      | 940032       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030976264 |\n",
            "|    clip_fraction        | 0.024        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.74        |\n",
            "|    explained_variance   | 0.392        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00234     |\n",
            "|    n_updates            | 4580         |\n",
            "|    policy_gradient_loss | -0.00218     |\n",
            "|    reward               | -0.085927606 |\n",
            "|    std                  | 1.58         |\n",
            "|    value_loss           | 0.0592       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 429         |\n",
            "|    iterations           | 460         |\n",
            "|    time_elapsed         | 2191        |\n",
            "|    total_timesteps      | 942080      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.00657345  |\n",
            "|    clip_fraction        | 0.0342      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.73       |\n",
            "|    explained_variance   | 0.289       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.00354     |\n",
            "|    n_updates            | 4590        |\n",
            "|    policy_gradient_loss | -0.00249    |\n",
            "|    reward               | 0.067974724 |\n",
            "|    std                  | 1.57        |\n",
            "|    value_loss           | 0.12        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 429          |\n",
            "|    iterations           | 461          |\n",
            "|    time_elapsed         | 2197         |\n",
            "|    total_timesteps      | 944128       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044920356 |\n",
            "|    clip_fraction        | 0.0528       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.72        |\n",
            "|    explained_variance   | -0.0109      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00229     |\n",
            "|    n_updates            | 4600         |\n",
            "|    policy_gradient_loss | -0.00339     |\n",
            "|    reward               | -0.04156953  |\n",
            "|    std                  | 1.57         |\n",
            "|    value_loss           | 0.0555       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 429         |\n",
            "|    iterations           | 462         |\n",
            "|    time_elapsed         | 2203        |\n",
            "|    total_timesteps      | 946176      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004052542 |\n",
            "|    clip_fraction        | 0.0179      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.72       |\n",
            "|    explained_variance   | 0.365       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0364     |\n",
            "|    n_updates            | 4610        |\n",
            "|    policy_gradient_loss | -0.00383    |\n",
            "|    reward               | 0.072178386 |\n",
            "|    std                  | 1.57        |\n",
            "|    value_loss           | 0.0693      |\n",
            "-----------------------------------------\n",
            "day: 2707, episode: 350\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -172760.45\n",
            "total_reward: -182760.45\n",
            "total_cost: 356.04\n",
            "total_trades: 2504\n",
            "Sharpe: -0.062\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 429          |\n",
            "|    iterations           | 463          |\n",
            "|    time_elapsed         | 2208         |\n",
            "|    total_timesteps      | 948224       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021961096 |\n",
            "|    clip_fraction        | 0.00806      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.72        |\n",
            "|    explained_variance   | 0.209        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0672       |\n",
            "|    n_updates            | 4620         |\n",
            "|    policy_gradient_loss | -0.00141     |\n",
            "|    reward               | 0.0006196203 |\n",
            "|    std                  | 1.57         |\n",
            "|    value_loss           | 0.152        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 429         |\n",
            "|    iterations           | 464         |\n",
            "|    time_elapsed         | 2214        |\n",
            "|    total_timesteps      | 950272      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005441758 |\n",
            "|    clip_fraction        | 0.0102      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.72       |\n",
            "|    explained_variance   | 0.456       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0431      |\n",
            "|    n_updates            | 4630        |\n",
            "|    policy_gradient_loss | -0.00192    |\n",
            "|    reward               | -0.30136758 |\n",
            "|    std                  | 1.57        |\n",
            "|    value_loss           | 0.15        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 428          |\n",
            "|    iterations           | 465          |\n",
            "|    time_elapsed         | 2220         |\n",
            "|    total_timesteps      | 952320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015633233 |\n",
            "|    clip_fraction        | 0.00562      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.72        |\n",
            "|    explained_variance   | 0.222        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0106       |\n",
            "|    n_updates            | 4640         |\n",
            "|    policy_gradient_loss | -0.000526    |\n",
            "|    reward               | -0.028209798 |\n",
            "|    std                  | 1.57         |\n",
            "|    value_loss           | 0.0935       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 428          |\n",
            "|    iterations           | 466          |\n",
            "|    time_elapsed         | 2226         |\n",
            "|    total_timesteps      | 954368       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.007089057  |\n",
            "|    clip_fraction        | 0.0746       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.72        |\n",
            "|    explained_variance   | 0.525        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0139      |\n",
            "|    n_updates            | 4650         |\n",
            "|    policy_gradient_loss | -0.00706     |\n",
            "|    reward               | -0.027497493 |\n",
            "|    std                  | 1.57         |\n",
            "|    value_loss           | 0.126        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 428          |\n",
            "|    iterations           | 467          |\n",
            "|    time_elapsed         | 2231         |\n",
            "|    total_timesteps      | 956416       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004387277  |\n",
            "|    clip_fraction        | 0.0112       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.72        |\n",
            "|    explained_variance   | 0.382        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0886       |\n",
            "|    n_updates            | 4660         |\n",
            "|    policy_gradient_loss | -0.00184     |\n",
            "|    reward               | 0.0072031613 |\n",
            "|    std                  | 1.57         |\n",
            "|    value_loss           | 0.315        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 428         |\n",
            "|    iterations           | 468         |\n",
            "|    time_elapsed         | 2237        |\n",
            "|    total_timesteps      | 958464      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002287975 |\n",
            "|    clip_fraction        | 0.0198      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.72       |\n",
            "|    explained_variance   | 0.828       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.04       |\n",
            "|    n_updates            | 4670        |\n",
            "|    policy_gradient_loss | -0.00107    |\n",
            "|    reward               | -0.06373281 |\n",
            "|    std                  | 1.56        |\n",
            "|    value_loss           | 0.0106      |\n",
            "-----------------------------------------\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 428            |\n",
            "|    iterations           | 469            |\n",
            "|    time_elapsed         | 2242           |\n",
            "|    total_timesteps      | 960512         |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.0027310057   |\n",
            "|    clip_fraction        | 0.022          |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -3.72          |\n",
            "|    explained_variance   | 0.768          |\n",
            "|    learning_rate        | 0.00025        |\n",
            "|    loss                 | -0.046         |\n",
            "|    n_updates            | 4680           |\n",
            "|    policy_gradient_loss | -0.00403       |\n",
            "|    reward               | -0.00067173527 |\n",
            "|    std                  | 1.56           |\n",
            "|    value_loss           | 0.00725        |\n",
            "--------------------------------------------\n",
            "day: 2707, episode: 355\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -122729.85\n",
            "total_reward: -132729.85\n",
            "total_cost: 295.55\n",
            "total_trades: 2086\n",
            "Sharpe: 0.288\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 428          |\n",
            "|    iterations           | 470          |\n",
            "|    time_elapsed         | 2248         |\n",
            "|    total_timesteps      | 962560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029885662 |\n",
            "|    clip_fraction        | 0.0218       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.72        |\n",
            "|    explained_variance   | 0.518        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0355      |\n",
            "|    n_updates            | 4690         |\n",
            "|    policy_gradient_loss | -0.0023      |\n",
            "|    reward               | -0.023869017 |\n",
            "|    std                  | 1.57         |\n",
            "|    value_loss           | 0.0179       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 471          |\n",
            "|    time_elapsed         | 2254         |\n",
            "|    total_timesteps      | 964608       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004162508  |\n",
            "|    clip_fraction        | 0.00767      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.73        |\n",
            "|    explained_variance   | 0.428        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00932     |\n",
            "|    n_updates            | 4700         |\n",
            "|    policy_gradient_loss | -0.000972    |\n",
            "|    reward               | -0.012435691 |\n",
            "|    std                  | 1.57         |\n",
            "|    value_loss           | 0.0827       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 427         |\n",
            "|    iterations           | 472         |\n",
            "|    time_elapsed         | 2260        |\n",
            "|    total_timesteps      | 966656      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004079189 |\n",
            "|    clip_fraction        | 0.0289      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.74       |\n",
            "|    explained_variance   | 0.649       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0249     |\n",
            "|    n_updates            | 4710        |\n",
            "|    policy_gradient_loss | -0.00168    |\n",
            "|    reward               | 0.17228942  |\n",
            "|    std                  | 1.58        |\n",
            "|    value_loss           | 0.0216      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 473          |\n",
            "|    time_elapsed         | 2265         |\n",
            "|    total_timesteps      | 968704       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038217125 |\n",
            "|    clip_fraction        | 0.00435      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.74        |\n",
            "|    explained_variance   | 0.12         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.083        |\n",
            "|    n_updates            | 4720         |\n",
            "|    policy_gradient_loss | -0.00066     |\n",
            "|    reward               | 0.10500557   |\n",
            "|    std                  | 1.58         |\n",
            "|    value_loss           | 0.227        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 474          |\n",
            "|    time_elapsed         | 2271         |\n",
            "|    total_timesteps      | 970752       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044106124 |\n",
            "|    clip_fraction        | 0.0322       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.74        |\n",
            "|    explained_variance   | 0.593        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0134      |\n",
            "|    n_updates            | 4730         |\n",
            "|    policy_gradient_loss | -0.00409     |\n",
            "|    reward               | -0.17320095  |\n",
            "|    std                  | 1.58         |\n",
            "|    value_loss           | 0.0509       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 427           |\n",
            "|    iterations           | 475           |\n",
            "|    time_elapsed         | 2277          |\n",
            "|    total_timesteps      | 972800        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00061362237 |\n",
            "|    clip_fraction        | 0.00146       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.74         |\n",
            "|    explained_variance   | 0.336         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.00178       |\n",
            "|    n_updates            | 4740          |\n",
            "|    policy_gradient_loss | -0.000467     |\n",
            "|    reward               | -0.016907929  |\n",
            "|    std                  | 1.58          |\n",
            "|    value_loss           | 0.103         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 476          |\n",
            "|    time_elapsed         | 2282         |\n",
            "|    total_timesteps      | 974848       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024293752 |\n",
            "|    clip_fraction        | 0.0357       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.75        |\n",
            "|    explained_variance   | 0.344        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0801       |\n",
            "|    n_updates            | 4750         |\n",
            "|    policy_gradient_loss | -0.00153     |\n",
            "|    reward               | -0.29908654  |\n",
            "|    std                  | 1.59         |\n",
            "|    value_loss           | 0.269        |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 360\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -249832.72\n",
            "total_reward: -259832.72\n",
            "total_cost: 341.33\n",
            "total_trades: 2238\n",
            "Sharpe: -0.214\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 426         |\n",
            "|    iterations           | 477         |\n",
            "|    time_elapsed         | 2289        |\n",
            "|    total_timesteps      | 976896      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004758585 |\n",
            "|    clip_fraction        | 0.0442      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.76       |\n",
            "|    explained_variance   | 0.111       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.153       |\n",
            "|    n_updates            | 4760        |\n",
            "|    policy_gradient_loss | -0.001      |\n",
            "|    reward               | 0.024220299 |\n",
            "|    std                  | 1.59        |\n",
            "|    value_loss           | 0.322       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 478          |\n",
            "|    time_elapsed         | 2295         |\n",
            "|    total_timesteps      | 978944       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033316556 |\n",
            "|    clip_fraction        | 0.0223       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.76        |\n",
            "|    explained_variance   | 0.431        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00776     |\n",
            "|    n_updates            | 4770         |\n",
            "|    policy_gradient_loss | -0.00165     |\n",
            "|    reward               | 0.08281882   |\n",
            "|    std                  | 1.6          |\n",
            "|    value_loss           | 0.0791       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 426         |\n",
            "|    iterations           | 479         |\n",
            "|    time_elapsed         | 2301        |\n",
            "|    total_timesteps      | 980992      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.000925391 |\n",
            "|    clip_fraction        | 0.0082      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.77       |\n",
            "|    explained_variance   | 0.316       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0583      |\n",
            "|    n_updates            | 4780        |\n",
            "|    policy_gradient_loss | -0.000571   |\n",
            "|    reward               | 0.013807806 |\n",
            "|    std                  | 1.6         |\n",
            "|    value_loss           | 0.259       |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 426           |\n",
            "|    iterations           | 480           |\n",
            "|    time_elapsed         | 2307          |\n",
            "|    total_timesteps      | 983040        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0038879951  |\n",
            "|    clip_fraction        | 0.0209        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.78         |\n",
            "|    explained_variance   | 0.833         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0479       |\n",
            "|    n_updates            | 4790          |\n",
            "|    policy_gradient_loss | -0.00261      |\n",
            "|    reward               | -0.0017800366 |\n",
            "|    std                  | 1.61          |\n",
            "|    value_loss           | 0.0263        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 425          |\n",
            "|    iterations           | 481          |\n",
            "|    time_elapsed         | 2312         |\n",
            "|    total_timesteps      | 985088       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016156267 |\n",
            "|    clip_fraction        | 0.00645      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.78        |\n",
            "|    explained_variance   | 0.195        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.128        |\n",
            "|    n_updates            | 4800         |\n",
            "|    policy_gradient_loss | -0.00109     |\n",
            "|    reward               | 0.7959036    |\n",
            "|    std                  | 1.62         |\n",
            "|    value_loss           | 0.239        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 425          |\n",
            "|    iterations           | 482          |\n",
            "|    time_elapsed         | 2319         |\n",
            "|    total_timesteps      | 987136       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015137894 |\n",
            "|    clip_fraction        | 0.00659      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.8         |\n",
            "|    explained_variance   | 0.524        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0259      |\n",
            "|    n_updates            | 4810         |\n",
            "|    policy_gradient_loss | -5.44e-05    |\n",
            "|    reward               | -0.02165766  |\n",
            "|    std                  | 1.63         |\n",
            "|    value_loss           | 0.0325       |\n",
            "------------------------------------------\n",
            "day: 2707, episode: 365\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -103269.31\n",
            "total_reward: -113269.31\n",
            "total_cost: 343.89\n",
            "total_trades: 2520\n",
            "Sharpe: -0.242\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 425          |\n",
            "|    iterations           | 483          |\n",
            "|    time_elapsed         | 2324         |\n",
            "|    total_timesteps      | 989184       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.001284359  |\n",
            "|    clip_fraction        | 0.00425      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.8         |\n",
            "|    explained_variance   | 0.694        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0237      |\n",
            "|    n_updates            | 4820         |\n",
            "|    policy_gradient_loss | -0.00248     |\n",
            "|    reward               | -0.015342914 |\n",
            "|    std                  | 1.62         |\n",
            "|    value_loss           | 0.0763       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 425          |\n",
            "|    iterations           | 484          |\n",
            "|    time_elapsed         | 2329         |\n",
            "|    total_timesteps      | 991232       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0068420363 |\n",
            "|    clip_fraction        | 0.0359       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.8         |\n",
            "|    explained_variance   | 0.819        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00169     |\n",
            "|    n_updates            | 4830         |\n",
            "|    policy_gradient_loss | -0.00398     |\n",
            "|    reward               | 0.006769255  |\n",
            "|    std                  | 1.63         |\n",
            "|    value_loss           | 0.0489       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 425          |\n",
            "|    iterations           | 485          |\n",
            "|    time_elapsed         | 2335         |\n",
            "|    total_timesteps      | 993280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010087192 |\n",
            "|    clip_fraction        | 0.00771      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.8         |\n",
            "|    explained_variance   | 0.589        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0259      |\n",
            "|    n_updates            | 4840         |\n",
            "|    policy_gradient_loss | -0.000119    |\n",
            "|    reward               | 0.08038426   |\n",
            "|    std                  | 1.63         |\n",
            "|    value_loss           | 0.0316       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 425          |\n",
            "|    iterations           | 486          |\n",
            "|    time_elapsed         | 2341         |\n",
            "|    total_timesteps      | 995328       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042402963 |\n",
            "|    clip_fraction        | 0.00908      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.8         |\n",
            "|    explained_variance   | 0.276        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0464       |\n",
            "|    n_updates            | 4850         |\n",
            "|    policy_gradient_loss | -0.000198    |\n",
            "|    reward               | 0.17736085   |\n",
            "|    std                  | 1.63         |\n",
            "|    value_loss           | 0.162        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 487          |\n",
            "|    time_elapsed         | 2346         |\n",
            "|    total_timesteps      | 997376       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0063082064 |\n",
            "|    clip_fraction        | 0.0461       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.8         |\n",
            "|    explained_variance   | 0.19         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.175        |\n",
            "|    n_updates            | 4860         |\n",
            "|    policy_gradient_loss | -0.00254     |\n",
            "|    reward               | 0.007679915  |\n",
            "|    std                  | 1.62         |\n",
            "|    value_loss           | 0.472        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 488          |\n",
            "|    time_elapsed         | 2352         |\n",
            "|    total_timesteps      | 999424       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042715333 |\n",
            "|    clip_fraction        | 0.0287       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.79        |\n",
            "|    explained_variance   | 0.222        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.319        |\n",
            "|    n_updates            | 4870         |\n",
            "|    policy_gradient_loss | -0.00136     |\n",
            "|    reward               | 0.0042330967 |\n",
            "|    std                  | 1.62         |\n",
            "|    value_loss           | 0.761        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 489          |\n",
            "|    time_elapsed         | 2358         |\n",
            "|    total_timesteps      | 1001472      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009164163 |\n",
            "|    clip_fraction        | 0.00508      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.79        |\n",
            "|    explained_variance   | 0.499        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00767     |\n",
            "|    n_updates            | 4880         |\n",
            "|    policy_gradient_loss | -0.000463    |\n",
            "|    reward               | 0.01015912   |\n",
            "|    std                  | 1.62         |\n",
            "|    value_loss           | 0.0678       |\n",
            "------------------------------------------\n",
            "======PPO Validation from:  2021-01-04 to  2021-04-06\n",
            "PPO Sharpe Ratio:  -0.06478255810409449\n",
            "======Best Model Retraining from:  2010-04-01 to  2021-04-06\n",
            "======Trading from:  2021-04-06 to  2021-07-06\n",
            "[[1.00000000e+04 1.29873474e+02 4.58832581e+02 0.00000000e+00\n",
            "  0.00000000e+00 1.74376702e+00 4.65066338e+00 1.28886871e+02\n",
            "  4.69388153e+02 1.16377350e+02 4.13412140e+02 6.06303787e+01\n",
            "  5.49654160e+01 2.25215057e+02 1.10213203e+02 3.74220161e+01\n",
            "  6.06779385e+00 1.21544266e+02 4.39414581e+02 1.22726051e+02\n",
            "  4.38737152e+02]]\n",
            "============================================\n",
            "turbulence_threshold:  18.962438407024404\n",
            "======Model training from:  2010-04-01 to  2021-04-06\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo\\ppo_189_1\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    fps             | 413         |\n",
            "|    iterations      | 1           |\n",
            "|    time_elapsed    | 4           |\n",
            "|    total_timesteps | 2048        |\n",
            "| train/             |             |\n",
            "|    reward          | -0.05952631 |\n",
            "------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 388          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 10           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037666983 |\n",
            "|    clip_fraction        | 0.0211       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | -0.441       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0173      |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00181     |\n",
            "|    reward               | 0.0808777    |\n",
            "|    std                  | 0.998        |\n",
            "|    value_loss           | 0.0095       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 375          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 16           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052152113 |\n",
            "|    clip_fraction        | 0.0184       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.83        |\n",
            "|    explained_variance   | -0.0881      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00319     |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.000837    |\n",
            "|    reward               | 0.04415481   |\n",
            "|    std                  | 0.996        |\n",
            "|    value_loss           | 0.0373       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 366          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 22           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0008966371 |\n",
            "|    clip_fraction        | 0.00322      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.83        |\n",
            "|    explained_variance   | 0.00928      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00387     |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.000776    |\n",
            "|    reward               | -0.21202534  |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.0552       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 363          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 28           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041455096 |\n",
            "|    clip_fraction        | 0.00757      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | 0.0124       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.133        |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.000308    |\n",
            "|    reward               | -0.3636213   |\n",
            "|    std                  | 0.998        |\n",
            "|    value_loss           | 0.323        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 362         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 33          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003480284 |\n",
            "|    clip_fraction        | 0.0484      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.83       |\n",
            "|    explained_variance   | 0.111       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0212      |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -7.18e-05   |\n",
            "|    reward               | 0.015288099 |\n",
            "|    std                  | 0.999       |\n",
            "|    value_loss           | 0.139       |\n",
            "-----------------------------------------\n",
            "day: 2770, episode: 5\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -60559.86\n",
            "total_reward: -70559.86\n",
            "total_cost: 383.75\n",
            "total_trades: 2732\n",
            "Sharpe: -0.107\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 362           |\n",
            "|    iterations           | 7             |\n",
            "|    time_elapsed         | 39            |\n",
            "|    total_timesteps      | 14336         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.007917742   |\n",
            "|    clip_fraction        | 0.0709        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.85         |\n",
            "|    explained_variance   | 0.0199        |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.18          |\n",
            "|    n_updates            | 60            |\n",
            "|    policy_gradient_loss | -0.00563      |\n",
            "|    reward               | -0.0071174307 |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 0.461         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 44           |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027425194 |\n",
            "|    clip_fraction        | 0.0105       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | 0.132        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0171      |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.000377    |\n",
            "|    reward               | 0.58954763   |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.0273       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 50           |\n",
            "|    total_timesteps      | 18432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052219033 |\n",
            "|    clip_fraction        | 0.0337       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | 4.2e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.175        |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -0.00169     |\n",
            "|    reward               | 0.02215618   |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.476        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 56           |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029613273 |\n",
            "|    clip_fraction        | 0.0286       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.86        |\n",
            "|    explained_variance   | -0.00261     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.193        |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.00206     |\n",
            "|    reward               | -0.015872046 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.259        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 363           |\n",
            "|    iterations           | 11            |\n",
            "|    time_elapsed         | 61            |\n",
            "|    total_timesteps      | 22528         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00079883984 |\n",
            "|    clip_fraction        | 0.0108        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.87         |\n",
            "|    explained_variance   | 0.283         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0209       |\n",
            "|    n_updates            | 100           |\n",
            "|    policy_gradient_loss | -0.000107     |\n",
            "|    reward               | 0.045074034   |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 0.0133        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 67           |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.003964549  |\n",
            "|    clip_fraction        | 0.0404       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.88        |\n",
            "|    explained_variance   | 0.0755       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00575     |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.000558    |\n",
            "|    reward               | -0.049932018 |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 0.0451       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 73           |\n",
            "|    total_timesteps      | 26624        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042051394 |\n",
            "|    clip_fraction        | 0.0317       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.89        |\n",
            "|    explained_variance   | 0.00332      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00626     |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.00196     |\n",
            "|    reward               | -0.18879421  |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.0669       |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 10\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -369759.41\n",
            "total_reward: -379759.41\n",
            "total_cost: 419.76\n",
            "total_trades: 2694\n",
            "Sharpe: 0.370\n",
            "=================================\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 361            |\n",
            "|    iterations           | 14             |\n",
            "|    time_elapsed         | 79             |\n",
            "|    total_timesteps      | 28672          |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.0046511055   |\n",
            "|    clip_fraction        | 0.0345         |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -2.89          |\n",
            "|    explained_variance   | 0.0543         |\n",
            "|    learning_rate        | 0.00025        |\n",
            "|    loss                 | 0.0407         |\n",
            "|    n_updates            | 130            |\n",
            "|    policy_gradient_loss | -0.00316       |\n",
            "|    reward               | -0.00016210701 |\n",
            "|    std                  | 1.02           |\n",
            "|    value_loss           | 0.15           |\n",
            "--------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 84           |\n",
            "|    total_timesteps      | 30720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017022844 |\n",
            "|    clip_fraction        | 0.000342     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.88        |\n",
            "|    explained_variance   | 0.0954       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.202        |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.000236    |\n",
            "|    reward               | 0.0060547274 |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 0.603        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 360          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 90           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026705465 |\n",
            "|    clip_fraction        | 0.0112       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.88        |\n",
            "|    explained_variance   | 0.726        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0265      |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -0.00194     |\n",
            "|    reward               | -0.062307738 |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 0.0216       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 360          |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 96           |\n",
            "|    total_timesteps      | 34816        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023660199 |\n",
            "|    clip_fraction        | 0.00522      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.89        |\n",
            "|    explained_variance   | 0.49         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00951     |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -0.000201    |\n",
            "|    reward               | 0.12066233   |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.0537       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 359         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 102         |\n",
            "|    total_timesteps      | 36864       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004511253 |\n",
            "|    clip_fraction        | 0.043       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.9        |\n",
            "|    explained_variance   | 0.363       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0524      |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.00226    |\n",
            "|    reward               | 0.033036646 |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 0.131       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 360          |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 107          |\n",
            "|    total_timesteps      | 38912        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029086615 |\n",
            "|    clip_fraction        | 0.0196       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.91        |\n",
            "|    explained_variance   | 0.29         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0753       |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -0.00165     |\n",
            "|    reward               | -0.005317026 |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.301        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 359          |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 113          |\n",
            "|    total_timesteps      | 40960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039740046 |\n",
            "|    clip_fraction        | 0.0158       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.92        |\n",
            "|    explained_variance   | 0.219        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.113        |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | -0.00227     |\n",
            "|    reward               | -0.2206007   |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.335        |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 15\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -176149.89\n",
            "total_reward: -186149.89\n",
            "total_cost: 431.04\n",
            "total_trades: 2920\n",
            "Sharpe: -0.018\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 360          |\n",
            "|    iterations           | 21           |\n",
            "|    time_elapsed         | 119          |\n",
            "|    total_timesteps      | 43008        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044927867 |\n",
            "|    clip_fraction        | 0.025        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.92        |\n",
            "|    explained_variance   | 0.456        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0129      |\n",
            "|    n_updates            | 200          |\n",
            "|    policy_gradient_loss | -0.0022      |\n",
            "|    reward               | -0.02085206  |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.0503       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 360          |\n",
            "|    iterations           | 22           |\n",
            "|    time_elapsed         | 125          |\n",
            "|    total_timesteps      | 45056        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048896167 |\n",
            "|    clip_fraction        | 0.0427       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.92        |\n",
            "|    explained_variance   | 0.268        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00729      |\n",
            "|    n_updates            | 210          |\n",
            "|    policy_gradient_loss | -0.00701     |\n",
            "|    reward               | 0.006127201  |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.0895       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 360         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 130         |\n",
            "|    total_timesteps      | 47104       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001472541 |\n",
            "|    clip_fraction        | 0.0135      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.93       |\n",
            "|    explained_variance   | 0.223       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0184     |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.000209   |\n",
            "|    reward               | -0.20744005 |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 0.0324      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 360         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 136         |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005919438 |\n",
            "|    clip_fraction        | 0.0368      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.93       |\n",
            "|    explained_variance   | 0.177       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.00422     |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.00622    |\n",
            "|    reward               | 0.026877027 |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 0.0573      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 359          |\n",
            "|    iterations           | 25           |\n",
            "|    time_elapsed         | 142          |\n",
            "|    total_timesteps      | 51200        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033432771 |\n",
            "|    clip_fraction        | 0.025        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.93        |\n",
            "|    explained_variance   | 0.564        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0368      |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | -0.00149     |\n",
            "|    reward               | -0.057171725 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.00427      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 26           |\n",
            "|    time_elapsed         | 148          |\n",
            "|    total_timesteps      | 53248        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017329862 |\n",
            "|    clip_fraction        | 0.0127       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.95        |\n",
            "|    explained_variance   | 0.276        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0142      |\n",
            "|    n_updates            | 250          |\n",
            "|    policy_gradient_loss | -0.000566    |\n",
            "|    reward               | -0.007831003 |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.027        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 27           |\n",
            "|    time_elapsed         | 154          |\n",
            "|    total_timesteps      | 55296        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031248415 |\n",
            "|    clip_fraction        | 0.0116       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.97        |\n",
            "|    explained_variance   | 0.318        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00291      |\n",
            "|    n_updates            | 260          |\n",
            "|    policy_gradient_loss | -0.000445    |\n",
            "|    reward               | 0.1335821    |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.0676       |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 20\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -93374.57\n",
            "total_reward: -103374.57\n",
            "total_cost: 491.21\n",
            "total_trades: 2894\n",
            "Sharpe: 0.564\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 28           |\n",
            "|    time_elapsed         | 160          |\n",
            "|    total_timesteps      | 57344        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055068964 |\n",
            "|    clip_fraction        | 0.0389       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.97        |\n",
            "|    explained_variance   | 0.434        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0103      |\n",
            "|    n_updates            | 270          |\n",
            "|    policy_gradient_loss | -0.00123     |\n",
            "|    reward               | -0.103674896 |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.0378       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 357         |\n",
            "|    iterations           | 29          |\n",
            "|    time_elapsed         | 166         |\n",
            "|    total_timesteps      | 59392       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004533671 |\n",
            "|    clip_fraction        | 0.0373      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.98       |\n",
            "|    explained_variance   | 0.597       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0299     |\n",
            "|    n_updates            | 280         |\n",
            "|    policy_gradient_loss | -0.00316    |\n",
            "|    reward               | -0.14723271 |\n",
            "|    std                  | 1.07        |\n",
            "|    value_loss           | 0.0202      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 30           |\n",
            "|    time_elapsed         | 171          |\n",
            "|    total_timesteps      | 61440        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030652229 |\n",
            "|    clip_fraction        | 0.0228       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.98        |\n",
            "|    explained_variance   | 0.436        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00214     |\n",
            "|    n_updates            | 290          |\n",
            "|    policy_gradient_loss | -0.00154     |\n",
            "|    reward               | -0.025271421 |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.0542       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 358         |\n",
            "|    iterations           | 31          |\n",
            "|    time_elapsed         | 176         |\n",
            "|    total_timesteps      | 63488       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003819413 |\n",
            "|    clip_fraction        | 0.0143      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.98       |\n",
            "|    explained_variance   | 0.402       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.00833    |\n",
            "|    n_updates            | 300         |\n",
            "|    policy_gradient_loss | -0.00101    |\n",
            "|    reward               | 0.14402148  |\n",
            "|    std                  | 1.08        |\n",
            "|    value_loss           | 0.0486      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 32           |\n",
            "|    time_elapsed         | 181          |\n",
            "|    total_timesteps      | 65536        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.00921779   |\n",
            "|    clip_fraction        | 0.05         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.99        |\n",
            "|    explained_variance   | 0.442        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0153      |\n",
            "|    n_updates            | 310          |\n",
            "|    policy_gradient_loss | -0.00136     |\n",
            "|    reward               | 0.0016175815 |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 0.0173       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 363          |\n",
            "|    iterations           | 33           |\n",
            "|    time_elapsed         | 186          |\n",
            "|    total_timesteps      | 67584        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0078097507 |\n",
            "|    clip_fraction        | 0.0806       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3           |\n",
            "|    explained_variance   | 0.642        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0255      |\n",
            "|    n_updates            | 320          |\n",
            "|    policy_gradient_loss | -0.00603     |\n",
            "|    reward               | 0.1085248    |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.0123       |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 25\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -170452.55\n",
            "total_reward: -180452.55\n",
            "total_cost: 415.39\n",
            "total_trades: 2832\n",
            "Sharpe: 0.470\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 363          |\n",
            "|    iterations           | 34           |\n",
            "|    time_elapsed         | 191          |\n",
            "|    total_timesteps      | 69632        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005166907  |\n",
            "|    clip_fraction        | 0.0359       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3           |\n",
            "|    explained_variance   | 0.623        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0105      |\n",
            "|    n_updates            | 330          |\n",
            "|    policy_gradient_loss | -0.00244     |\n",
            "|    reward               | 0.0027095962 |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 0.0181       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 362          |\n",
            "|    iterations           | 35           |\n",
            "|    time_elapsed         | 197          |\n",
            "|    total_timesteps      | 71680        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041389456 |\n",
            "|    clip_fraction        | 0.0153       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.99        |\n",
            "|    explained_variance   | 0.208        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.015        |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | -0.00392     |\n",
            "|    reward               | -0.04654739  |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.0899       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 362          |\n",
            "|    iterations           | 36           |\n",
            "|    time_elapsed         | 203          |\n",
            "|    total_timesteps      | 73728        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005523219  |\n",
            "|    clip_fraction        | 0.0208       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.98        |\n",
            "|    explained_variance   | 0.66         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0228      |\n",
            "|    n_updates            | 350          |\n",
            "|    policy_gradient_loss | -0.00245     |\n",
            "|    reward               | -0.045306195 |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 0.00813      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 362          |\n",
            "|    iterations           | 37           |\n",
            "|    time_elapsed         | 209          |\n",
            "|    total_timesteps      | 75776        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012823675 |\n",
            "|    clip_fraction        | 0.0124       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.99        |\n",
            "|    explained_variance   | 0.411        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0125      |\n",
            "|    n_updates            | 360          |\n",
            "|    policy_gradient_loss | -0.000981    |\n",
            "|    reward               | 0.08178872   |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 0.023        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 362           |\n",
            "|    iterations           | 38            |\n",
            "|    time_elapsed         | 214           |\n",
            "|    total_timesteps      | 77824         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0061116866  |\n",
            "|    clip_fraction        | 0.0593        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3            |\n",
            "|    explained_variance   | 0.349         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0081       |\n",
            "|    n_updates            | 370           |\n",
            "|    policy_gradient_loss | -0.00411      |\n",
            "|    reward               | -0.0073213424 |\n",
            "|    std                  | 1.09          |\n",
            "|    value_loss           | 0.0625        |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 362         |\n",
            "|    iterations           | 39          |\n",
            "|    time_elapsed         | 220         |\n",
            "|    total_timesteps      | 79872       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004417995 |\n",
            "|    clip_fraction        | 0.0224      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3          |\n",
            "|    explained_variance   | 0.384       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.00419    |\n",
            "|    n_updates            | 380         |\n",
            "|    policy_gradient_loss | -0.00404    |\n",
            "|    reward               | -0.13268492 |\n",
            "|    std                  | 1.09        |\n",
            "|    value_loss           | 0.0772      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 362         |\n",
            "|    iterations           | 40          |\n",
            "|    time_elapsed         | 226         |\n",
            "|    total_timesteps      | 81920       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006332889 |\n",
            "|    clip_fraction        | 0.039       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.01       |\n",
            "|    explained_variance   | 0.547       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.027      |\n",
            "|    n_updates            | 390         |\n",
            "|    policy_gradient_loss | -0.00175    |\n",
            "|    reward               | 0.013110513 |\n",
            "|    std                  | 1.09        |\n",
            "|    value_loss           | 0.022       |\n",
            "-----------------------------------------\n",
            "day: 2770, episode: 30\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -139880.34\n",
            "total_reward: -149880.34\n",
            "total_cost: 510.64\n",
            "total_trades: 2980\n",
            "Sharpe: 0.215\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 362          |\n",
            "|    iterations           | 41           |\n",
            "|    time_elapsed         | 231          |\n",
            "|    total_timesteps      | 83968        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012358741 |\n",
            "|    clip_fraction        | 0.0186       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 0.383        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -9.54e-05    |\n",
            "|    n_updates            | 400          |\n",
            "|    policy_gradient_loss | -0.00115     |\n",
            "|    reward               | 0.0032147018 |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.0551       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 362          |\n",
            "|    iterations           | 42           |\n",
            "|    time_elapsed         | 237          |\n",
            "|    total_timesteps      | 86016        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.003093333  |\n",
            "|    clip_fraction        | 0.0335       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 0.471        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00573      |\n",
            "|    n_updates            | 410          |\n",
            "|    policy_gradient_loss | -0.00217     |\n",
            "|    reward               | -0.004732002 |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.0727       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 362          |\n",
            "|    iterations           | 43           |\n",
            "|    time_elapsed         | 243          |\n",
            "|    total_timesteps      | 88064        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033252938 |\n",
            "|    clip_fraction        | 0.0161       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 0.596        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.028       |\n",
            "|    n_updates            | 420          |\n",
            "|    policy_gradient_loss | -0.00138     |\n",
            "|    reward               | -0.03308143  |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.0364       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 361         |\n",
            "|    iterations           | 44          |\n",
            "|    time_elapsed         | 248         |\n",
            "|    total_timesteps      | 90112       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.00296069  |\n",
            "|    clip_fraction        | 0.00713     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.03       |\n",
            "|    explained_variance   | 0.839       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0353     |\n",
            "|    n_updates            | 430         |\n",
            "|    policy_gradient_loss | -0.000589   |\n",
            "|    reward               | 0.039431732 |\n",
            "|    std                  | 1.1         |\n",
            "|    value_loss           | 0.00734     |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 362           |\n",
            "|    iterations           | 45            |\n",
            "|    time_elapsed         | 254           |\n",
            "|    total_timesteps      | 92160         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0031419469  |\n",
            "|    clip_fraction        | 0.0143        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.04         |\n",
            "|    explained_variance   | 0.468         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.00976      |\n",
            "|    n_updates            | 440           |\n",
            "|    policy_gradient_loss | 0.000397      |\n",
            "|    reward               | -0.0043299883 |\n",
            "|    std                  | 1.11          |\n",
            "|    value_loss           | 0.0383        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 46           |\n",
            "|    time_elapsed         | 260          |\n",
            "|    total_timesteps      | 94208        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045694374 |\n",
            "|    clip_fraction        | 0.0398       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 0.252        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0242      |\n",
            "|    n_updates            | 450          |\n",
            "|    policy_gradient_loss | -0.00651     |\n",
            "|    reward               | -0.3473851   |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.0456       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 361         |\n",
            "|    iterations           | 47          |\n",
            "|    time_elapsed         | 266         |\n",
            "|    total_timesteps      | 96256       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004800354 |\n",
            "|    clip_fraction        | 0.0401      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.03       |\n",
            "|    explained_variance   | 0.353       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 5.2e-05     |\n",
            "|    n_updates            | 460         |\n",
            "|    policy_gradient_loss | -0.00142    |\n",
            "|    reward               | -0.03224074 |\n",
            "|    std                  | 1.1         |\n",
            "|    value_loss           | 0.0538      |\n",
            "-----------------------------------------\n",
            "day: 2770, episode: 35\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -61758.85\n",
            "total_reward: -71758.85\n",
            "total_cost: 504.95\n",
            "total_trades: 2932\n",
            "Sharpe: -0.310\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 48           |\n",
            "|    time_elapsed         | 271          |\n",
            "|    total_timesteps      | 98304        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060193595 |\n",
            "|    clip_fraction        | 0.0315       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 0.786        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0332      |\n",
            "|    n_updates            | 470          |\n",
            "|    policy_gradient_loss | -0.00269     |\n",
            "|    reward               | 0.11092802   |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.00597      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 49           |\n",
            "|    time_elapsed         | 277          |\n",
            "|    total_timesteps      | 100352       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015124113 |\n",
            "|    clip_fraction        | 0.00991      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 0.446        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0163      |\n",
            "|    n_updates            | 480          |\n",
            "|    policy_gradient_loss | -0.000495    |\n",
            "|    reward               | 0.012719299  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.0272       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 360          |\n",
            "|    iterations           | 50           |\n",
            "|    time_elapsed         | 284          |\n",
            "|    total_timesteps      | 102400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004488378  |\n",
            "|    clip_fraction        | 0.0252       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 0.289        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00583      |\n",
            "|    n_updates            | 490          |\n",
            "|    policy_gradient_loss | -0.000516    |\n",
            "|    reward               | -0.040837955 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.0759       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 359          |\n",
            "|    iterations           | 51           |\n",
            "|    time_elapsed         | 290          |\n",
            "|    total_timesteps      | 104448       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032098866 |\n",
            "|    clip_fraction        | 0.0222       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 0.315        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0277      |\n",
            "|    n_updates            | 500          |\n",
            "|    policy_gradient_loss | -0.00371     |\n",
            "|    reward               | -0.10346182  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.0444       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 358         |\n",
            "|    iterations           | 52          |\n",
            "|    time_elapsed         | 296         |\n",
            "|    total_timesteps      | 106496      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004692276 |\n",
            "|    clip_fraction        | 0.0295      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.04       |\n",
            "|    explained_variance   | 0.358       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0236      |\n",
            "|    n_updates            | 510         |\n",
            "|    policy_gradient_loss | -0.00433    |\n",
            "|    reward               | 0.12352893  |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 0.0964      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 357         |\n",
            "|    iterations           | 53          |\n",
            "|    time_elapsed         | 303         |\n",
            "|    total_timesteps      | 108544      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003447732 |\n",
            "|    clip_fraction        | 0.0189      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.05       |\n",
            "|    explained_variance   | 0.0924      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.159       |\n",
            "|    n_updates            | 520         |\n",
            "|    policy_gradient_loss | -0.00223    |\n",
            "|    reward               | 0.047371317 |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 0.377       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 54           |\n",
            "|    time_elapsed         | 309          |\n",
            "|    total_timesteps      | 110592       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044281995 |\n",
            "|    clip_fraction        | 0.0116       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 0.358        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0946       |\n",
            "|    n_updates            | 530          |\n",
            "|    policy_gradient_loss | -0.000433    |\n",
            "|    reward               | 0.2197295    |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.261        |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 40\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -277329.03\n",
            "total_reward: -287329.03\n",
            "total_cost: 417.24\n",
            "total_trades: 2836\n",
            "Sharpe: -0.299\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 55           |\n",
            "|    time_elapsed         | 315          |\n",
            "|    total_timesteps      | 112640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029067434 |\n",
            "|    clip_fraction        | 0.023        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 0.094        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.128        |\n",
            "|    n_updates            | 540          |\n",
            "|    policy_gradient_loss | -0.00174     |\n",
            "|    reward               | -0.06815176  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.284        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 56           |\n",
            "|    time_elapsed         | 320          |\n",
            "|    total_timesteps      | 114688       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027215919 |\n",
            "|    clip_fraction        | 0.00728      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 0.626        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0156       |\n",
            "|    n_updates            | 550          |\n",
            "|    policy_gradient_loss | -0.000852    |\n",
            "|    reward               | -0.037918046 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.132        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 57           |\n",
            "|    time_elapsed         | 326          |\n",
            "|    total_timesteps      | 116736       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021413253 |\n",
            "|    clip_fraction        | 0.0185       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 0.365        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.226        |\n",
            "|    n_updates            | 560          |\n",
            "|    policy_gradient_loss | 7.21e-05     |\n",
            "|    reward               | 0.062061682  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.482        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 58           |\n",
            "|    time_elapsed         | 332          |\n",
            "|    total_timesteps      | 118784       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0004894802 |\n",
            "|    clip_fraction        | 0.000732     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 0.637        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0424       |\n",
            "|    n_updates            | 570          |\n",
            "|    policy_gradient_loss | -0.00088     |\n",
            "|    reward               | 0.09950945   |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.219        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 59           |\n",
            "|    time_elapsed         | 338          |\n",
            "|    total_timesteps      | 120832       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028085478 |\n",
            "|    clip_fraction        | 0.0116       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 0.562        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.04         |\n",
            "|    n_updates            | 580          |\n",
            "|    policy_gradient_loss | -0.000315    |\n",
            "|    reward               | 0.111223355  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.135        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 60           |\n",
            "|    time_elapsed         | 344          |\n",
            "|    total_timesteps      | 122880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021600695 |\n",
            "|    clip_fraction        | 0.0152       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 0.569        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0604       |\n",
            "|    n_updates            | 590          |\n",
            "|    policy_gradient_loss | -0.00227     |\n",
            "|    reward               | -0.018911224 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.21         |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 45\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -102774.02\n",
            "total_reward: -112774.02\n",
            "total_cost: 392.17\n",
            "total_trades: 2802\n",
            "Sharpe: 0.378\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 61           |\n",
            "|    time_elapsed         | 350          |\n",
            "|    total_timesteps      | 124928       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022501817 |\n",
            "|    clip_fraction        | 0.0222       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 0.834        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00473     |\n",
            "|    n_updates            | 600          |\n",
            "|    policy_gradient_loss | -0.00224     |\n",
            "|    reward               | -0.048241373 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.0717       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 62           |\n",
            "|    time_elapsed         | 356          |\n",
            "|    total_timesteps      | 126976       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047230814 |\n",
            "|    clip_fraction        | 0.0244       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 0.665        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00903     |\n",
            "|    n_updates            | 610          |\n",
            "|    policy_gradient_loss | -0.00719     |\n",
            "|    reward               | -0.03857895  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.0562       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 355           |\n",
            "|    iterations           | 63            |\n",
            "|    time_elapsed         | 362           |\n",
            "|    total_timesteps      | 129024        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0019351175  |\n",
            "|    clip_fraction        | 0.0164        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.04         |\n",
            "|    explained_variance   | 0.909         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0249       |\n",
            "|    n_updates            | 620           |\n",
            "|    policy_gradient_loss | 0.00015       |\n",
            "|    reward               | 0.00032468262 |\n",
            "|    std                  | 1.1           |\n",
            "|    value_loss           | 0.00698       |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 64           |\n",
            "|    time_elapsed         | 369          |\n",
            "|    total_timesteps      | 131072       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005486558  |\n",
            "|    clip_fraction        | 0.0476       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 0.857        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0111      |\n",
            "|    n_updates            | 630          |\n",
            "|    policy_gradient_loss | -0.00186     |\n",
            "|    reward               | 0.0151839955 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.0133       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 354           |\n",
            "|    iterations           | 65            |\n",
            "|    time_elapsed         | 375           |\n",
            "|    total_timesteps      | 133120        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.005043455   |\n",
            "|    clip_fraction        | 0.0331        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.05         |\n",
            "|    explained_variance   | 0.866         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0386       |\n",
            "|    n_updates            | 640           |\n",
            "|    policy_gradient_loss | -0.00284      |\n",
            "|    reward               | -0.0005618558 |\n",
            "|    std                  | 1.11          |\n",
            "|    value_loss           | 0.0118        |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 354         |\n",
            "|    iterations           | 66          |\n",
            "|    time_elapsed         | 381         |\n",
            "|    total_timesteps      | 135168      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004028746 |\n",
            "|    clip_fraction        | 0.0291      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.04       |\n",
            "|    explained_variance   | 0.693       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0441     |\n",
            "|    n_updates            | 650         |\n",
            "|    policy_gradient_loss | -3.78e-05   |\n",
            "|    reward               | 0.06922477  |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 0.0132      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 354          |\n",
            "|    iterations           | 67           |\n",
            "|    time_elapsed         | 387          |\n",
            "|    total_timesteps      | 137216       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058271703 |\n",
            "|    clip_fraction        | 0.0458       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 0.339        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00636      |\n",
            "|    n_updates            | 660          |\n",
            "|    policy_gradient_loss | 0.00167      |\n",
            "|    reward               | -0.018933792 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.0546       |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 50\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -100735.68\n",
            "total_reward: -110735.68\n",
            "total_cost: 385.09\n",
            "total_trades: 2698\n",
            "Sharpe: -0.408\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 354          |\n",
            "|    iterations           | 68           |\n",
            "|    time_elapsed         | 392          |\n",
            "|    total_timesteps      | 139264       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017000736 |\n",
            "|    clip_fraction        | 0.0342       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 0.309        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0285       |\n",
            "|    n_updates            | 670          |\n",
            "|    policy_gradient_loss | -0.000804    |\n",
            "|    reward               | -0.025275564 |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.143        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 354         |\n",
            "|    iterations           | 69          |\n",
            "|    time_elapsed         | 398         |\n",
            "|    total_timesteps      | 141312      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003736085 |\n",
            "|    clip_fraction        | 0.053       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.06       |\n",
            "|    explained_variance   | 0.51        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.00317    |\n",
            "|    n_updates            | 680         |\n",
            "|    policy_gradient_loss | -0.00273    |\n",
            "|    reward               | 0.530861    |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 0.0644      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 70           |\n",
            "|    time_elapsed         | 403          |\n",
            "|    total_timesteps      | 143360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053850506 |\n",
            "|    clip_fraction        | 0.0282       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 0.267        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0918       |\n",
            "|    n_updates            | 690          |\n",
            "|    policy_gradient_loss | -0.00235     |\n",
            "|    reward               | -0.09711531  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.273        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 355         |\n",
            "|    iterations           | 71          |\n",
            "|    time_elapsed         | 409         |\n",
            "|    total_timesteps      | 145408      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002199486 |\n",
            "|    clip_fraction        | 0.0227      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.05       |\n",
            "|    explained_variance   | 0.527       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.000113   |\n",
            "|    n_updates            | 700         |\n",
            "|    policy_gradient_loss | -0.000871   |\n",
            "|    reward               | 0.048325256 |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 0.05        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 72           |\n",
            "|    time_elapsed         | 414          |\n",
            "|    total_timesteps      | 147456       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037873276 |\n",
            "|    clip_fraction        | 0.0111       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 0.487        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0661       |\n",
            "|    n_updates            | 710          |\n",
            "|    policy_gradient_loss | -0.00302     |\n",
            "|    reward               | -0.05223029  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.204        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 73           |\n",
            "|    time_elapsed         | 420          |\n",
            "|    total_timesteps      | 149504       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015929868 |\n",
            "|    clip_fraction        | 0.013        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 0.548        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0782       |\n",
            "|    n_updates            | 720          |\n",
            "|    policy_gradient_loss | 0.000544     |\n",
            "|    reward               | -0.31282327  |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.23         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 355         |\n",
            "|    iterations           | 74          |\n",
            "|    time_elapsed         | 426         |\n",
            "|    total_timesteps      | 151552      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003001031 |\n",
            "|    clip_fraction        | 0.0188      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.06       |\n",
            "|    explained_variance   | 0.457       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0223      |\n",
            "|    n_updates            | 730         |\n",
            "|    policy_gradient_loss | -0.000267   |\n",
            "|    reward               | 0.019721817 |\n",
            "|    std                  | 1.12        |\n",
            "|    value_loss           | 0.123       |\n",
            "-----------------------------------------\n",
            "day: 2770, episode: 55\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -42704.62\n",
            "total_reward: -52704.62\n",
            "total_cost: 412.02\n",
            "total_trades: 2592\n",
            "Sharpe: -0.509\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 355         |\n",
            "|    iterations           | 75          |\n",
            "|    time_elapsed         | 432         |\n",
            "|    total_timesteps      | 153600      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002206528 |\n",
            "|    clip_fraction        | 0.0256      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.06       |\n",
            "|    explained_variance   | 0.902       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0329     |\n",
            "|    n_updates            | 740         |\n",
            "|    policy_gradient_loss | -0.00227    |\n",
            "|    reward               | 0.013499078 |\n",
            "|    std                  | 1.12        |\n",
            "|    value_loss           | 0.025       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 355         |\n",
            "|    iterations           | 76          |\n",
            "|    time_elapsed         | 437         |\n",
            "|    total_timesteps      | 155648      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003404608 |\n",
            "|    clip_fraction        | 0.0495      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.05       |\n",
            "|    explained_variance   | 0.614       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0222     |\n",
            "|    n_updates            | 750         |\n",
            "|    policy_gradient_loss | -0.00281    |\n",
            "|    reward               | 0.003902726 |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 0.0269      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 355         |\n",
            "|    iterations           | 77          |\n",
            "|    time_elapsed         | 443         |\n",
            "|    total_timesteps      | 157696      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005284539 |\n",
            "|    clip_fraction        | 0.014       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.05       |\n",
            "|    explained_variance   | 0.546       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0493      |\n",
            "|    n_updates            | 760         |\n",
            "|    policy_gradient_loss | -0.000772   |\n",
            "|    reward               | -0.18730809 |\n",
            "|    std                  | 1.12        |\n",
            "|    value_loss           | 0.133       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 78           |\n",
            "|    time_elapsed         | 449          |\n",
            "|    total_timesteps      | 159744       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004512783  |\n",
            "|    clip_fraction        | 0.0229       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.06        |\n",
            "|    explained_variance   | 0.839        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.029       |\n",
            "|    n_updates            | 770          |\n",
            "|    policy_gradient_loss | -0.00158     |\n",
            "|    reward               | -0.005098074 |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.00963      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 354          |\n",
            "|    iterations           | 79           |\n",
            "|    time_elapsed         | 456          |\n",
            "|    total_timesteps      | 161792       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030745866 |\n",
            "|    clip_fraction        | 0.0353       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.07        |\n",
            "|    explained_variance   | 0.878        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0295      |\n",
            "|    n_updates            | 780          |\n",
            "|    policy_gradient_loss | -0.002       |\n",
            "|    reward               | -0.004199531 |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.00723      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 354          |\n",
            "|    iterations           | 80           |\n",
            "|    time_elapsed         | 462          |\n",
            "|    total_timesteps      | 163840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0067236284 |\n",
            "|    clip_fraction        | 0.0422       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.06        |\n",
            "|    explained_variance   | 0.669        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0329      |\n",
            "|    n_updates            | 790          |\n",
            "|    policy_gradient_loss | -0.00347     |\n",
            "|    reward               | 0.0062375804 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.0156       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 354          |\n",
            "|    iterations           | 81           |\n",
            "|    time_elapsed         | 468          |\n",
            "|    total_timesteps      | 165888       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034157662 |\n",
            "|    clip_fraction        | 0.0232       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 0.523        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 9.26e-05     |\n",
            "|    n_updates            | 800          |\n",
            "|    policy_gradient_loss | -0.00238     |\n",
            "|    reward               | -0.2840559   |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.0566       |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 60\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -217248.61\n",
            "total_reward: -227248.61\n",
            "total_cost: 394.42\n",
            "total_trades: 2640\n",
            "Sharpe: 0.292\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 354          |\n",
            "|    iterations           | 82           |\n",
            "|    time_elapsed         | 473          |\n",
            "|    total_timesteps      | 167936       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005405952  |\n",
            "|    clip_fraction        | 0.0183       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.06        |\n",
            "|    explained_variance   | 0.0287       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00336      |\n",
            "|    n_updates            | 810          |\n",
            "|    policy_gradient_loss | -0.00167     |\n",
            "|    reward               | -0.001654839 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.103        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 354          |\n",
            "|    iterations           | 83           |\n",
            "|    time_elapsed         | 479          |\n",
            "|    total_timesteps      | 169984       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035590734 |\n",
            "|    clip_fraction        | 0.0223       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.06        |\n",
            "|    explained_variance   | 0.138        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0674       |\n",
            "|    n_updates            | 820          |\n",
            "|    policy_gradient_loss | -0.00136     |\n",
            "|    reward               | -0.06297895  |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.139        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 354          |\n",
            "|    iterations           | 84           |\n",
            "|    time_elapsed         | 485          |\n",
            "|    total_timesteps      | 172032       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046893284 |\n",
            "|    clip_fraction        | 0.0157       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.06        |\n",
            "|    explained_variance   | 0.751        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0234      |\n",
            "|    n_updates            | 830          |\n",
            "|    policy_gradient_loss | 0.000282     |\n",
            "|    reward               | 0.018912006  |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.0257       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 353          |\n",
            "|    iterations           | 85           |\n",
            "|    time_elapsed         | 492          |\n",
            "|    total_timesteps      | 174080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046653175 |\n",
            "|    clip_fraction        | 0.0225       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.06        |\n",
            "|    explained_variance   | 0.522        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0124      |\n",
            "|    n_updates            | 840          |\n",
            "|    policy_gradient_loss | -0.00216     |\n",
            "|    reward               | 0.05568717   |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.045        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 352           |\n",
            "|    iterations           | 86            |\n",
            "|    time_elapsed         | 499           |\n",
            "|    total_timesteps      | 176128        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.004002356   |\n",
            "|    clip_fraction        | 0.0116        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.06         |\n",
            "|    explained_variance   | 0.415         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0327       |\n",
            "|    n_updates            | 850           |\n",
            "|    policy_gradient_loss | -0.000224     |\n",
            "|    reward               | -0.0077851107 |\n",
            "|    std                  | 1.12          |\n",
            "|    value_loss           | 0.0111        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 351          |\n",
            "|    iterations           | 87           |\n",
            "|    time_elapsed         | 507          |\n",
            "|    total_timesteps      | 178176       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018883023 |\n",
            "|    clip_fraction        | 0.0316       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.07        |\n",
            "|    explained_variance   | 0.396        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0124      |\n",
            "|    n_updates            | 860          |\n",
            "|    policy_gradient_loss | -0.00236     |\n",
            "|    reward               | 0.005869608  |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.0322       |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 65\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -88175.47\n",
            "total_reward: -98175.47\n",
            "total_cost: 394.39\n",
            "total_trades: 2748\n",
            "Sharpe: 0.317\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 350         |\n",
            "|    iterations           | 88          |\n",
            "|    time_elapsed         | 513         |\n",
            "|    total_timesteps      | 180224      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005561004 |\n",
            "|    clip_fraction        | 0.0247      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.07       |\n",
            "|    explained_variance   | 0.3         |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0163      |\n",
            "|    n_updates            | 870         |\n",
            "|    policy_gradient_loss | -0.00147    |\n",
            "|    reward               | 0.012082994 |\n",
            "|    std                  | 1.12        |\n",
            "|    value_loss           | 0.0866      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 350          |\n",
            "|    iterations           | 89           |\n",
            "|    time_elapsed         | 519          |\n",
            "|    total_timesteps      | 182272       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0065649664 |\n",
            "|    clip_fraction        | 0.0371       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.06        |\n",
            "|    explained_variance   | 0.357        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0184      |\n",
            "|    n_updates            | 880          |\n",
            "|    policy_gradient_loss | -0.00156     |\n",
            "|    reward               | 0.67745864   |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.0436       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 350          |\n",
            "|    iterations           | 90           |\n",
            "|    time_elapsed         | 525          |\n",
            "|    total_timesteps      | 184320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.003094086  |\n",
            "|    clip_fraction        | 0.00762      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.06        |\n",
            "|    explained_variance   | 0.121        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0241       |\n",
            "|    n_updates            | 890          |\n",
            "|    policy_gradient_loss | 0.000214     |\n",
            "|    reward               | -0.029707214 |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.151        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 351         |\n",
            "|    iterations           | 91          |\n",
            "|    time_elapsed         | 530         |\n",
            "|    total_timesteps      | 186368      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008787913 |\n",
            "|    clip_fraction        | 0.0783      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.06       |\n",
            "|    explained_variance   | 0.147       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.114       |\n",
            "|    n_updates            | 900         |\n",
            "|    policy_gradient_loss | -0.00293    |\n",
            "|    reward               | 0.004079969 |\n",
            "|    std                  | 1.12        |\n",
            "|    value_loss           | 0.447       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 352          |\n",
            "|    iterations           | 92           |\n",
            "|    time_elapsed         | 535          |\n",
            "|    total_timesteps      | 188416       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021180967 |\n",
            "|    clip_fraction        | 0.0108       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.06        |\n",
            "|    explained_variance   | 0.788        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00294     |\n",
            "|    n_updates            | 910          |\n",
            "|    policy_gradient_loss | -0.000597    |\n",
            "|    reward               | 1.0320914    |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.0572       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 353          |\n",
            "|    iterations           | 93           |\n",
            "|    time_elapsed         | 539          |\n",
            "|    total_timesteps      | 190464       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033127633 |\n",
            "|    clip_fraction        | 0.00835      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.07        |\n",
            "|    explained_variance   | 0.267        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.223        |\n",
            "|    n_updates            | 920          |\n",
            "|    policy_gradient_loss | -0.00147     |\n",
            "|    reward               | 0.18199754   |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.402        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 354          |\n",
            "|    iterations           | 94           |\n",
            "|    time_elapsed         | 543          |\n",
            "|    total_timesteps      | 192512       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028052398 |\n",
            "|    clip_fraction        | 0.0187       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.07        |\n",
            "|    explained_variance   | 0.314        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0242       |\n",
            "|    n_updates            | 930          |\n",
            "|    policy_gradient_loss | -0.000407    |\n",
            "|    reward               | 0.0067751426 |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.106        |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 70\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -86125.05\n",
            "total_reward: -96125.05\n",
            "total_cost: 379.26\n",
            "total_trades: 2684\n",
            "Sharpe: 0.292\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 354          |\n",
            "|    iterations           | 95           |\n",
            "|    time_elapsed         | 549          |\n",
            "|    total_timesteps      | 194560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039783292 |\n",
            "|    clip_fraction        | 0.0124       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.07        |\n",
            "|    explained_variance   | 0.261        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.202        |\n",
            "|    n_updates            | 940          |\n",
            "|    policy_gradient_loss | -0.00147     |\n",
            "|    reward               | 0.0064619845 |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.418        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 354          |\n",
            "|    iterations           | 96           |\n",
            "|    time_elapsed         | 554          |\n",
            "|    total_timesteps      | 196608       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035530035 |\n",
            "|    clip_fraction        | 0.0228       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.829        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00671     |\n",
            "|    n_updates            | 950          |\n",
            "|    policy_gradient_loss | -0.00293     |\n",
            "|    reward               | 0.2208215    |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.0597       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 354          |\n",
            "|    iterations           | 97           |\n",
            "|    time_elapsed         | 560          |\n",
            "|    total_timesteps      | 198656       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040174397 |\n",
            "|    clip_fraction        | 0.0241       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.79         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.000225     |\n",
            "|    n_updates            | 960          |\n",
            "|    policy_gradient_loss | -0.00153     |\n",
            "|    reward               | 0.1343267    |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.0506       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 354          |\n",
            "|    iterations           | 98           |\n",
            "|    time_elapsed         | 566          |\n",
            "|    total_timesteps      | 200704       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0076810475 |\n",
            "|    clip_fraction        | 0.0267       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.07        |\n",
            "|    explained_variance   | 0.832        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0261      |\n",
            "|    n_updates            | 970          |\n",
            "|    policy_gradient_loss | -0.00201     |\n",
            "|    reward               | 0.003588787  |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.0241       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 354          |\n",
            "|    iterations           | 99           |\n",
            "|    time_elapsed         | 572          |\n",
            "|    total_timesteps      | 202752       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034809166 |\n",
            "|    clip_fraction        | 0.0385       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.06        |\n",
            "|    explained_variance   | 0.701        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00938     |\n",
            "|    n_updates            | 980          |\n",
            "|    policy_gradient_loss | -0.000336    |\n",
            "|    reward               | -0.004621473 |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.0817       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 354          |\n",
            "|    iterations           | 100          |\n",
            "|    time_elapsed         | 578          |\n",
            "|    total_timesteps      | 204800       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059135035 |\n",
            "|    clip_fraction        | 0.0275       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.07        |\n",
            "|    explained_variance   | 0.462        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0114       |\n",
            "|    n_updates            | 990          |\n",
            "|    policy_gradient_loss | -0.00162     |\n",
            "|    reward               | 0.42004177   |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.118        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 354          |\n",
            "|    iterations           | 101          |\n",
            "|    time_elapsed         | 583          |\n",
            "|    total_timesteps      | 206848       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018925654 |\n",
            "|    clip_fraction        | 0.0134       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.07        |\n",
            "|    explained_variance   | 0.411        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00608      |\n",
            "|    n_updates            | 1000         |\n",
            "|    policy_gradient_loss | 0.00014      |\n",
            "|    reward               | 0.1445292    |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.0811       |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 75\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -80133.97\n",
            "total_reward: -90133.97\n",
            "total_cost: 379.80\n",
            "total_trades: 2702\n",
            "Sharpe: 0.327\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 354          |\n",
            "|    iterations           | 102          |\n",
            "|    time_elapsed         | 588          |\n",
            "|    total_timesteps      | 208896       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021610742 |\n",
            "|    clip_fraction        | 0.0145       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.07        |\n",
            "|    explained_variance   | 0.76         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0218      |\n",
            "|    n_updates            | 1010         |\n",
            "|    policy_gradient_loss | -0.00203     |\n",
            "|    reward               | -0.017736988 |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.0378       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 354          |\n",
            "|    iterations           | 103          |\n",
            "|    time_elapsed         | 594          |\n",
            "|    total_timesteps      | 210944       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054813884 |\n",
            "|    clip_fraction        | 0.0342       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.06        |\n",
            "|    explained_variance   | 0.745        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0241      |\n",
            "|    n_updates            | 1020         |\n",
            "|    policy_gradient_loss | -0.00248     |\n",
            "|    reward               | 0.008799149  |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.0478       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 104          |\n",
            "|    time_elapsed         | 599          |\n",
            "|    total_timesteps      | 212992       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029475116 |\n",
            "|    clip_fraction        | 0.0368       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.06        |\n",
            "|    explained_variance   | 0.685        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00296     |\n",
            "|    n_updates            | 1030         |\n",
            "|    policy_gradient_loss | -0.00102     |\n",
            "|    reward               | 0.15517427   |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.0565       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 355         |\n",
            "|    iterations           | 105         |\n",
            "|    time_elapsed         | 604         |\n",
            "|    total_timesteps      | 215040      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006987095 |\n",
            "|    clip_fraction        | 0.025       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.06       |\n",
            "|    explained_variance   | 0.706       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.019      |\n",
            "|    n_updates            | 1040        |\n",
            "|    policy_gradient_loss | -0.00153    |\n",
            "|    reward               | -0.11153104 |\n",
            "|    std                  | 1.12        |\n",
            "|    value_loss           | 0.0302      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 355         |\n",
            "|    iterations           | 106         |\n",
            "|    time_elapsed         | 610         |\n",
            "|    total_timesteps      | 217088      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002216629 |\n",
            "|    clip_fraction        | 0.0132      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.07       |\n",
            "|    explained_variance   | 0.499       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0105     |\n",
            "|    n_updates            | 1050        |\n",
            "|    policy_gradient_loss | -0.000265   |\n",
            "|    reward               | 0.008090213 |\n",
            "|    std                  | 1.12        |\n",
            "|    value_loss           | 0.0713      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 107          |\n",
            "|    time_elapsed         | 615          |\n",
            "|    total_timesteps      | 219136       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004370245  |\n",
            "|    clip_fraction        | 0.0335       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.09        |\n",
            "|    explained_variance   | 0.533        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0349       |\n",
            "|    n_updates            | 1060         |\n",
            "|    policy_gradient_loss | -0.00122     |\n",
            "|    reward               | -0.018775167 |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 0.15         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 108          |\n",
            "|    time_elapsed         | 621          |\n",
            "|    total_timesteps      | 221184       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056639155 |\n",
            "|    clip_fraction        | 0.0183       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.1         |\n",
            "|    explained_variance   | 0.324        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0321       |\n",
            "|    n_updates            | 1070         |\n",
            "|    policy_gradient_loss | -0.0016      |\n",
            "|    reward               | -0.03472878  |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 0.147        |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 80\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -130731.59\n",
            "total_reward: -140731.59\n",
            "total_cost: 401.01\n",
            "total_trades: 2742\n",
            "Sharpe: 0.146\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 109          |\n",
            "|    time_elapsed         | 626          |\n",
            "|    total_timesteps      | 223232       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.003925807  |\n",
            "|    clip_fraction        | 0.0298       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.09        |\n",
            "|    explained_variance   | 0.781        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0159      |\n",
            "|    n_updates            | 1080         |\n",
            "|    policy_gradient_loss | -0.00163     |\n",
            "|    reward               | -0.011554622 |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.0351       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 356           |\n",
            "|    iterations           | 110           |\n",
            "|    time_elapsed         | 632           |\n",
            "|    total_timesteps      | 225280        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00010215386 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.09         |\n",
            "|    explained_variance   | 0.567         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.00959       |\n",
            "|    n_updates            | 1090          |\n",
            "|    policy_gradient_loss | 1.79e-05      |\n",
            "|    reward               | 0.014452132   |\n",
            "|    std                  | 1.14          |\n",
            "|    value_loss           | 0.0998        |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 356           |\n",
            "|    iterations           | 111           |\n",
            "|    time_elapsed         | 637           |\n",
            "|    total_timesteps      | 227328        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00078999123 |\n",
            "|    clip_fraction        | 0.000488      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.1          |\n",
            "|    explained_variance   | 0.383         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0718        |\n",
            "|    n_updates            | 1100          |\n",
            "|    policy_gradient_loss | -5.61e-05     |\n",
            "|    reward               | -0.016519938  |\n",
            "|    std                  | 1.14          |\n",
            "|    value_loss           | 0.217         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 112          |\n",
            "|    time_elapsed         | 642          |\n",
            "|    total_timesteps      | 229376       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043405835 |\n",
            "|    clip_fraction        | 0.0177       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.1         |\n",
            "|    explained_variance   | 0.304        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0228       |\n",
            "|    n_updates            | 1110         |\n",
            "|    policy_gradient_loss | -0.00207     |\n",
            "|    reward               | 0.002596117  |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 0.143        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 357           |\n",
            "|    iterations           | 113           |\n",
            "|    time_elapsed         | 647           |\n",
            "|    total_timesteps      | 231424        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0054669604  |\n",
            "|    clip_fraction        | 0.0293        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.09         |\n",
            "|    explained_variance   | 0.839         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0197       |\n",
            "|    n_updates            | 1120          |\n",
            "|    policy_gradient_loss | -0.00226      |\n",
            "|    reward               | -0.0059485245 |\n",
            "|    std                  | 1.14          |\n",
            "|    value_loss           | 0.017         |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 357           |\n",
            "|    iterations           | 114           |\n",
            "|    time_elapsed         | 653           |\n",
            "|    total_timesteps      | 233472        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.005100484   |\n",
            "|    clip_fraction        | 0.021         |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.08         |\n",
            "|    explained_variance   | 0.662         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.00343      |\n",
            "|    n_updates            | 1130          |\n",
            "|    policy_gradient_loss | -0.00233      |\n",
            "|    reward               | 0.00021018254 |\n",
            "|    std                  | 1.13          |\n",
            "|    value_loss           | 0.0539        |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 357         |\n",
            "|    iterations           | 115         |\n",
            "|    time_elapsed         | 658         |\n",
            "|    total_timesteps      | 235520      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008057636 |\n",
            "|    clip_fraction        | 0.0446      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.07       |\n",
            "|    explained_variance   | 0.659       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0112     |\n",
            "|    n_updates            | 1140        |\n",
            "|    policy_gradient_loss | -0.00393    |\n",
            "|    reward               | -0.870895   |\n",
            "|    std                  | 1.13        |\n",
            "|    value_loss           | 0.0197      |\n",
            "-----------------------------------------\n",
            "day: 2770, episode: 85\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -258416.19\n",
            "total_reward: -268416.19\n",
            "total_cost: 420.16\n",
            "total_trades: 2764\n",
            "Sharpe: 0.223\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 357         |\n",
            "|    iterations           | 116         |\n",
            "|    time_elapsed         | 663         |\n",
            "|    total_timesteps      | 237568      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006257563 |\n",
            "|    clip_fraction        | 0.0437      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.07       |\n",
            "|    explained_variance   | 0.0465      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.127       |\n",
            "|    n_updates            | 1150        |\n",
            "|    policy_gradient_loss | -0.00699    |\n",
            "|    reward               | 0.16141002  |\n",
            "|    std                  | 1.13        |\n",
            "|    value_loss           | 0.306       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 117          |\n",
            "|    time_elapsed         | 669          |\n",
            "|    total_timesteps      | 239616       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050888546 |\n",
            "|    clip_fraction        | 0.038        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.444        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00798      |\n",
            "|    n_updates            | 1160         |\n",
            "|    policy_gradient_loss | -2.93e-05    |\n",
            "|    reward               | 0.0010989393 |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.0705       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 118          |\n",
            "|    time_elapsed         | 674          |\n",
            "|    total_timesteps      | 241664       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044187363 |\n",
            "|    clip_fraction        | 0.0399       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.456        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0815       |\n",
            "|    n_updates            | 1170         |\n",
            "|    policy_gradient_loss | -0.00402     |\n",
            "|    reward               | 0.002611153  |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.203        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 119          |\n",
            "|    time_elapsed         | 679          |\n",
            "|    total_timesteps      | 243712       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028098284 |\n",
            "|    clip_fraction        | 0.00571      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.789        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.024       |\n",
            "|    n_updates            | 1180         |\n",
            "|    policy_gradient_loss | -0.000467    |\n",
            "|    reward               | 0.26457787   |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.0134       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 120          |\n",
            "|    time_elapsed         | 685          |\n",
            "|    total_timesteps      | 245760       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0067459373 |\n",
            "|    clip_fraction        | 0.0271       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.0781       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.139        |\n",
            "|    n_updates            | 1190         |\n",
            "|    policy_gradient_loss | -0.00281     |\n",
            "|    reward               | -0.022416208 |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.274        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 358         |\n",
            "|    iterations           | 121         |\n",
            "|    time_elapsed         | 690         |\n",
            "|    total_timesteps      | 247808      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003158425 |\n",
            "|    clip_fraction        | 0.014       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.08       |\n",
            "|    explained_variance   | 0.407       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0497      |\n",
            "|    n_updates            | 1200        |\n",
            "|    policy_gradient_loss | -0.000998   |\n",
            "|    reward               | 0.014846451 |\n",
            "|    std                  | 1.13        |\n",
            "|    value_loss           | 0.159       |\n",
            "-----------------------------------------\n",
            "day: 2770, episode: 90\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -195655.94\n",
            "total_reward: -205655.94\n",
            "total_cost: 413.42\n",
            "total_trades: 2752\n",
            "Sharpe: 0.521\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 122          |\n",
            "|    time_elapsed         | 696          |\n",
            "|    total_timesteps      | 249856       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044780606 |\n",
            "|    clip_fraction        | 0.0141       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.224        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.454        |\n",
            "|    n_updates            | 1210         |\n",
            "|    policy_gradient_loss | -0.00239     |\n",
            "|    reward               | 0.017003885  |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.82         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 359         |\n",
            "|    iterations           | 123         |\n",
            "|    time_elapsed         | 701         |\n",
            "|    total_timesteps      | 251904      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005728895 |\n",
            "|    clip_fraction        | 0.0564      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.08       |\n",
            "|    explained_variance   | 0.523       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.05        |\n",
            "|    n_updates            | 1220        |\n",
            "|    policy_gradient_loss | -0.00394    |\n",
            "|    reward               | 0.19957893  |\n",
            "|    std                  | 1.13        |\n",
            "|    value_loss           | 0.209       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 359          |\n",
            "|    iterations           | 124          |\n",
            "|    time_elapsed         | 707          |\n",
            "|    total_timesteps      | 253952       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032746282 |\n",
            "|    clip_fraction        | 0.0103       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.785        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0214      |\n",
            "|    n_updates            | 1230         |\n",
            "|    policy_gradient_loss | -0.000249    |\n",
            "|    reward               | -0.25237834  |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.0238       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 359          |\n",
            "|    iterations           | 125          |\n",
            "|    time_elapsed         | 712          |\n",
            "|    total_timesteps      | 256000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0057107992 |\n",
            "|    clip_fraction        | 0.0379       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.513        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0286       |\n",
            "|    n_updates            | 1240         |\n",
            "|    policy_gradient_loss | -0.00346     |\n",
            "|    reward               | -0.012128602 |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.0902       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 359          |\n",
            "|    iterations           | 126          |\n",
            "|    time_elapsed         | 717          |\n",
            "|    total_timesteps      | 258048       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071532563 |\n",
            "|    clip_fraction        | 0.0409       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.368        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.24         |\n",
            "|    n_updates            | 1250         |\n",
            "|    policy_gradient_loss | -0.00178     |\n",
            "|    reward               | -0.048007675 |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.493        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 359          |\n",
            "|    iterations           | 127          |\n",
            "|    time_elapsed         | 723          |\n",
            "|    total_timesteps      | 260096       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037920019 |\n",
            "|    clip_fraction        | 0.0175       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.716        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0151      |\n",
            "|    n_updates            | 1260         |\n",
            "|    policy_gradient_loss | -0.00147     |\n",
            "|    reward               | -0.118889086 |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.0381       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 359          |\n",
            "|    iterations           | 128          |\n",
            "|    time_elapsed         | 728          |\n",
            "|    total_timesteps      | 262144       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036291648 |\n",
            "|    clip_fraction        | 0.0224       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.616        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00868     |\n",
            "|    n_updates            | 1270         |\n",
            "|    policy_gradient_loss | 0.000981     |\n",
            "|    reward               | -0.107606836 |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.0489       |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 95\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -308313.33\n",
            "total_reward: -318313.33\n",
            "total_cost: 419.58\n",
            "total_trades: 2752\n",
            "Sharpe: -0.050\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 359         |\n",
            "|    iterations           | 129         |\n",
            "|    time_elapsed         | 734         |\n",
            "|    total_timesteps      | 264192      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003022483 |\n",
            "|    clip_fraction        | 0.0142      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.08       |\n",
            "|    explained_variance   | 0.594       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.00114     |\n",
            "|    n_updates            | 1280        |\n",
            "|    policy_gradient_loss | 0.000315    |\n",
            "|    reward               | 0.008048884 |\n",
            "|    std                  | 1.13        |\n",
            "|    value_loss           | 0.0938      |\n",
            "-----------------------------------------\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 359            |\n",
            "|    iterations           | 130            |\n",
            "|    time_elapsed         | 740            |\n",
            "|    total_timesteps      | 266240         |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.004912949    |\n",
            "|    clip_fraction        | 0.00923        |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -3.08          |\n",
            "|    explained_variance   | 0.352          |\n",
            "|    learning_rate        | 0.00025        |\n",
            "|    loss                 | 0.101          |\n",
            "|    n_updates            | 1290           |\n",
            "|    policy_gradient_loss | -0.000285      |\n",
            "|    reward               | -0.00014626751 |\n",
            "|    std                  | 1.13           |\n",
            "|    value_loss           | 0.477          |\n",
            "--------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 359          |\n",
            "|    iterations           | 131          |\n",
            "|    time_elapsed         | 746          |\n",
            "|    total_timesteps      | 268288       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004543677  |\n",
            "|    clip_fraction        | 0.0216       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.802        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0123      |\n",
            "|    n_updates            | 1300         |\n",
            "|    policy_gradient_loss | -0.0021      |\n",
            "|    reward               | -0.013898749 |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.0235       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 359          |\n",
            "|    iterations           | 132          |\n",
            "|    time_elapsed         | 751          |\n",
            "|    total_timesteps      | 270336       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036812236 |\n",
            "|    clip_fraction        | 0.0403       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.904        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0308      |\n",
            "|    n_updates            | 1310         |\n",
            "|    policy_gradient_loss | -0.00022     |\n",
            "|    reward               | 0.007814479  |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 0.0128       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 359         |\n",
            "|    iterations           | 133         |\n",
            "|    time_elapsed         | 756         |\n",
            "|    total_timesteps      | 272384      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002332987 |\n",
            "|    clip_fraction        | 0.00791     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.09       |\n",
            "|    explained_variance   | 0.83        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0242     |\n",
            "|    n_updates            | 1320        |\n",
            "|    policy_gradient_loss | -0.00139    |\n",
            "|    reward               | 0.007743936 |\n",
            "|    std                  | 1.14        |\n",
            "|    value_loss           | 0.0234      |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 359           |\n",
            "|    iterations           | 134           |\n",
            "|    time_elapsed         | 762           |\n",
            "|    total_timesteps      | 274432        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0055106943  |\n",
            "|    clip_fraction        | 0.0159        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.09         |\n",
            "|    explained_variance   | 0.706         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0123       |\n",
            "|    n_updates            | 1330          |\n",
            "|    policy_gradient_loss | 0.000154      |\n",
            "|    reward               | -0.0055146823 |\n",
            "|    std                  | 1.13          |\n",
            "|    value_loss           | 0.0361        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 360          |\n",
            "|    iterations           | 135          |\n",
            "|    time_elapsed         | 767          |\n",
            "|    total_timesteps      | 276480       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038954397 |\n",
            "|    clip_fraction        | 0.036        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.47         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00657      |\n",
            "|    n_updates            | 1340         |\n",
            "|    policy_gradient_loss | -0.00225     |\n",
            "|    reward               | -0.13044828  |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.0425       |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 100\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -96362.81\n",
            "total_reward: -106362.81\n",
            "total_cost: 378.13\n",
            "total_trades: 2650\n",
            "Sharpe: 0.467\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 360         |\n",
            "|    iterations           | 136         |\n",
            "|    time_elapsed         | 773         |\n",
            "|    total_timesteps      | 278528      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011821764 |\n",
            "|    clip_fraction        | 0.133       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.08       |\n",
            "|    explained_variance   | 0.807       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0125     |\n",
            "|    n_updates            | 1350        |\n",
            "|    policy_gradient_loss | 0.00221     |\n",
            "|    reward               | 0.025655543 |\n",
            "|    std                  | 1.13        |\n",
            "|    value_loss           | 0.0149      |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 360           |\n",
            "|    iterations           | 137           |\n",
            "|    time_elapsed         | 778           |\n",
            "|    total_timesteps      | 280576        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.004251018   |\n",
            "|    clip_fraction        | 0.0407        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.07         |\n",
            "|    explained_variance   | 0.596         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0249       |\n",
            "|    n_updates            | 1360          |\n",
            "|    policy_gradient_loss | -0.00456      |\n",
            "|    reward               | 0.00072992017 |\n",
            "|    std                  | 1.13          |\n",
            "|    value_loss           | 0.0459        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 360          |\n",
            "|    iterations           | 138          |\n",
            "|    time_elapsed         | 784          |\n",
            "|    total_timesteps      | 282624       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071108383 |\n",
            "|    clip_fraction        | 0.0458       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.508        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00655      |\n",
            "|    n_updates            | 1370         |\n",
            "|    policy_gradient_loss | -0.00343     |\n",
            "|    reward               | 0.103663936  |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 0.0751       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 360         |\n",
            "|    iterations           | 139         |\n",
            "|    time_elapsed         | 789         |\n",
            "|    total_timesteps      | 284672      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007393326 |\n",
            "|    clip_fraction        | 0.0602      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.09       |\n",
            "|    explained_variance   | 0.339       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.00359    |\n",
            "|    n_updates            | 1380        |\n",
            "|    policy_gradient_loss | 4.1e-06     |\n",
            "|    reward               | 0.013737693 |\n",
            "|    std                  | 1.13        |\n",
            "|    value_loss           | 0.0609      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 360         |\n",
            "|    iterations           | 140         |\n",
            "|    time_elapsed         | 794         |\n",
            "|    total_timesteps      | 286720      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006865407 |\n",
            "|    clip_fraction        | 0.0514      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.08       |\n",
            "|    explained_variance   | 0.864       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0348     |\n",
            "|    n_updates            | 1390        |\n",
            "|    policy_gradient_loss | -0.00535    |\n",
            "|    reward               | 0.017465742 |\n",
            "|    std                  | 1.13        |\n",
            "|    value_loss           | 0.00608     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 141          |\n",
            "|    time_elapsed         | 799          |\n",
            "|    total_timesteps      | 288768       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.003220981  |\n",
            "|    clip_fraction        | 0.025        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.07        |\n",
            "|    explained_variance   | 0.62         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0397      |\n",
            "|    n_updates            | 1400         |\n",
            "|    policy_gradient_loss | -0.00397     |\n",
            "|    reward               | -0.021552386 |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.0149       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 361         |\n",
            "|    iterations           | 142         |\n",
            "|    time_elapsed         | 805         |\n",
            "|    total_timesteps      | 290816      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006018638 |\n",
            "|    clip_fraction        | 0.0392      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.06       |\n",
            "|    explained_variance   | 0.543       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.00408    |\n",
            "|    n_updates            | 1410        |\n",
            "|    policy_gradient_loss | -0.00596    |\n",
            "|    reward               | -0.1472701  |\n",
            "|    std                  | 1.12        |\n",
            "|    value_loss           | 0.0493      |\n",
            "-----------------------------------------\n",
            "day: 2770, episode: 105\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -183768.10\n",
            "total_reward: -193768.10\n",
            "total_cost: 411.51\n",
            "total_trades: 2848\n",
            "Sharpe: -0.428\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 143          |\n",
            "|    time_elapsed         | 810          |\n",
            "|    total_timesteps      | 292864       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030918506 |\n",
            "|    clip_fraction        | 0.0082       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.06        |\n",
            "|    explained_variance   | 0.147        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0358       |\n",
            "|    n_updates            | 1420         |\n",
            "|    policy_gradient_loss | 0.000264     |\n",
            "|    reward               | -0.3391229   |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.11         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 361         |\n",
            "|    iterations           | 144         |\n",
            "|    time_elapsed         | 815         |\n",
            "|    total_timesteps      | 294912      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003304338 |\n",
            "|    clip_fraction        | 0.012       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.07       |\n",
            "|    explained_variance   | 0.412       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0237      |\n",
            "|    n_updates            | 1430        |\n",
            "|    policy_gradient_loss | -0.00162    |\n",
            "|    reward               | 0.03625595  |\n",
            "|    std                  | 1.12        |\n",
            "|    value_loss           | 0.0906      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 145          |\n",
            "|    time_elapsed         | 821          |\n",
            "|    total_timesteps      | 296960       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025109446 |\n",
            "|    clip_fraction        | 0.00864      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.06        |\n",
            "|    explained_variance   | 0.332        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.191        |\n",
            "|    n_updates            | 1440         |\n",
            "|    policy_gradient_loss | -0.000328    |\n",
            "|    reward               | -0.067192756 |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.373        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 146          |\n",
            "|    time_elapsed         | 826          |\n",
            "|    total_timesteps      | 299008       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045168884 |\n",
            "|    clip_fraction        | 0.0246       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.06        |\n",
            "|    explained_variance   | 0.436        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0158       |\n",
            "|    n_updates            | 1450         |\n",
            "|    policy_gradient_loss | -0.00377     |\n",
            "|    reward               | -0.9978272   |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.12         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 147          |\n",
            "|    time_elapsed         | 832          |\n",
            "|    total_timesteps      | 301056       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004582374  |\n",
            "|    clip_fraction        | 0.0293       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.06        |\n",
            "|    explained_variance   | 0.13         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0805       |\n",
            "|    n_updates            | 1460         |\n",
            "|    policy_gradient_loss | -0.0019      |\n",
            "|    reward               | -0.118179396 |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.265        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 148          |\n",
            "|    time_elapsed         | 837          |\n",
            "|    total_timesteps      | 303104       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030417722 |\n",
            "|    clip_fraction        | 0.0119       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.06        |\n",
            "|    explained_variance   | 0.489        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0315       |\n",
            "|    n_updates            | 1470         |\n",
            "|    policy_gradient_loss | -0.00219     |\n",
            "|    reward               | -0.061668422 |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.0805       |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 110\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -325522.41\n",
            "total_reward: -335522.41\n",
            "total_cost: 403.90\n",
            "total_trades: 2622\n",
            "Sharpe: -0.157\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 362          |\n",
            "|    iterations           | 149          |\n",
            "|    time_elapsed         | 842          |\n",
            "|    total_timesteps      | 305152       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056621297 |\n",
            "|    clip_fraction        | 0.0304       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.06        |\n",
            "|    explained_variance   | 0.605        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0238       |\n",
            "|    n_updates            | 1480         |\n",
            "|    policy_gradient_loss | -0.00526     |\n",
            "|    reward               | -0.017541545 |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.0962       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 362         |\n",
            "|    iterations           | 150         |\n",
            "|    time_elapsed         | 848         |\n",
            "|    total_timesteps      | 307200      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010506475 |\n",
            "|    clip_fraction        | 0.0589      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.06       |\n",
            "|    explained_variance   | 0.25        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.233       |\n",
            "|    n_updates            | 1490        |\n",
            "|    policy_gradient_loss | -0.00165    |\n",
            "|    reward               | -0.08353133 |\n",
            "|    std                  | 1.12        |\n",
            "|    value_loss           | 0.544       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 362         |\n",
            "|    iterations           | 151         |\n",
            "|    time_elapsed         | 853         |\n",
            "|    total_timesteps      | 309248      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006370962 |\n",
            "|    clip_fraction        | 0.0188      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.06       |\n",
            "|    explained_variance   | 0.38        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.00361     |\n",
            "|    n_updates            | 1500        |\n",
            "|    policy_gradient_loss | 0.00105     |\n",
            "|    reward               | 0.050161    |\n",
            "|    std                  | 1.12        |\n",
            "|    value_loss           | 0.106       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 152          |\n",
            "|    time_elapsed         | 860          |\n",
            "|    total_timesteps      | 311296       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052413093 |\n",
            "|    clip_fraction        | 0.0297       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 0.559        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00735      |\n",
            "|    n_updates            | 1510         |\n",
            "|    policy_gradient_loss | -0.0052      |\n",
            "|    reward               | -0.005479317 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.124        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 153          |\n",
            "|    time_elapsed         | 866          |\n",
            "|    total_timesteps      | 313344       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033245774 |\n",
            "|    clip_fraction        | 0.032        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 0.63         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0463       |\n",
            "|    n_updates            | 1520         |\n",
            "|    policy_gradient_loss | -0.00441     |\n",
            "|    reward               | 0.02778159   |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.164        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 154          |\n",
            "|    time_elapsed         | 873          |\n",
            "|    total_timesteps      | 315392       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029548765 |\n",
            "|    clip_fraction        | 0.00488      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 0.354        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.294        |\n",
            "|    n_updates            | 1530         |\n",
            "|    policy_gradient_loss | -0.000345    |\n",
            "|    reward               | -0.017266387 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.627        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 360          |\n",
            "|    iterations           | 155          |\n",
            "|    time_elapsed         | 879          |\n",
            "|    total_timesteps      | 317440       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004530845  |\n",
            "|    clip_fraction        | 0.0236       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 0.78         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00375     |\n",
            "|    n_updates            | 1540         |\n",
            "|    policy_gradient_loss | -0.00069     |\n",
            "|    reward               | -0.053401005 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.0659       |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 115\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -248866.08\n",
            "total_reward: -258866.08\n",
            "total_cost: 423.08\n",
            "total_trades: 2854\n",
            "Sharpe: 0.209\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 360          |\n",
            "|    iterations           | 156          |\n",
            "|    time_elapsed         | 886          |\n",
            "|    total_timesteps      | 319488       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056217327 |\n",
            "|    clip_fraction        | 0.0559       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 0.748        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.000707     |\n",
            "|    n_updates            | 1550         |\n",
            "|    policy_gradient_loss | -0.00756     |\n",
            "|    reward               | -0.017454106 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.0984       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 360          |\n",
            "|    iterations           | 157          |\n",
            "|    time_elapsed         | 892          |\n",
            "|    total_timesteps      | 321536       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059764753 |\n",
            "|    clip_fraction        | 0.033        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 0.591        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0852       |\n",
            "|    n_updates            | 1560         |\n",
            "|    policy_gradient_loss | -0.00487     |\n",
            "|    reward               | 0.0069411173 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.189        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 360         |\n",
            "|    iterations           | 158         |\n",
            "|    time_elapsed         | 897         |\n",
            "|    total_timesteps      | 323584      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006700442 |\n",
            "|    clip_fraction        | 0.0445      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.03       |\n",
            "|    explained_variance   | 0.514       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0334     |\n",
            "|    n_updates            | 1570        |\n",
            "|    policy_gradient_loss | -0.000808   |\n",
            "|    reward               | 0.21524672  |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 0.0154      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 360          |\n",
            "|    iterations           | 159          |\n",
            "|    time_elapsed         | 903          |\n",
            "|    total_timesteps      | 325632       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011557591 |\n",
            "|    clip_fraction        | 0.0242       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 0.319        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0318       |\n",
            "|    n_updates            | 1580         |\n",
            "|    policy_gradient_loss | 7.07e-05     |\n",
            "|    reward               | -0.10994937  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.092        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 360         |\n",
            "|    iterations           | 160         |\n",
            "|    time_elapsed         | 908         |\n",
            "|    total_timesteps      | 327680      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002141441 |\n",
            "|    clip_fraction        | 0.0181      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.04       |\n",
            "|    explained_variance   | 0.116       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0962      |\n",
            "|    n_updates            | 1590        |\n",
            "|    policy_gradient_loss | -0.00151    |\n",
            "|    reward               | 0.01380071  |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 0.233       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 360         |\n",
            "|    iterations           | 161         |\n",
            "|    time_elapsed         | 913         |\n",
            "|    total_timesteps      | 329728      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007932924 |\n",
            "|    clip_fraction        | 0.0525      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.02       |\n",
            "|    explained_variance   | 0.185       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.363       |\n",
            "|    n_updates            | 1600        |\n",
            "|    policy_gradient_loss | -0.00138    |\n",
            "|    reward               | -0.06485726 |\n",
            "|    std                  | 1.1         |\n",
            "|    value_loss           | 0.542       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 360          |\n",
            "|    iterations           | 162          |\n",
            "|    time_elapsed         | 919          |\n",
            "|    total_timesteps      | 331776       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032742177 |\n",
            "|    clip_fraction        | 0.0226       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 0.746        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0169      |\n",
            "|    n_updates            | 1610         |\n",
            "|    policy_gradient_loss | -0.00141     |\n",
            "|    reward               | 0.15761518   |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.0173       |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 120\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -156937.96\n",
            "total_reward: -166937.96\n",
            "total_cost: 405.48\n",
            "total_trades: 2804\n",
            "Sharpe: -0.241\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 163          |\n",
            "|    time_elapsed         | 924          |\n",
            "|    total_timesteps      | 333824       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027693522 |\n",
            "|    clip_fraction        | 0.00664      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 0.75         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0229      |\n",
            "|    n_updates            | 1620         |\n",
            "|    policy_gradient_loss | -0.000186    |\n",
            "|    reward               | 0.030285968  |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.0325       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 164          |\n",
            "|    time_elapsed         | 929          |\n",
            "|    total_timesteps      | 335872       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039864006 |\n",
            "|    clip_fraction        | 0.0242       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 0.775        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00823     |\n",
            "|    n_updates            | 1630         |\n",
            "|    policy_gradient_loss | -0.00438     |\n",
            "|    reward               | 0.036162876  |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.0547       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 165          |\n",
            "|    time_elapsed         | 934          |\n",
            "|    total_timesteps      | 337920       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019899015 |\n",
            "|    clip_fraction        | 0.00728      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 0.755        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0251      |\n",
            "|    n_updates            | 1640         |\n",
            "|    policy_gradient_loss | 5.11e-05     |\n",
            "|    reward               | -0.01828949  |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.0142       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 166          |\n",
            "|    time_elapsed         | 940          |\n",
            "|    total_timesteps      | 339968       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054582967 |\n",
            "|    clip_fraction        | 0.0325       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3           |\n",
            "|    explained_variance   | 0.768        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0372      |\n",
            "|    n_updates            | 1650         |\n",
            "|    policy_gradient_loss | -0.00692     |\n",
            "|    reward               | 0.003510667  |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.0309       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 167          |\n",
            "|    time_elapsed         | 945          |\n",
            "|    total_timesteps      | 342016       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029208292 |\n",
            "|    clip_fraction        | 0.0135       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.99        |\n",
            "|    explained_variance   | 0.874        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0279      |\n",
            "|    n_updates            | 1660         |\n",
            "|    policy_gradient_loss | -0.0033      |\n",
            "|    reward               | -0.03324809  |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 0.0119       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 168          |\n",
            "|    time_elapsed         | 951          |\n",
            "|    total_timesteps      | 344064       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071448283 |\n",
            "|    clip_fraction        | 0.0525       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.98        |\n",
            "|    explained_variance   | 0.626        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0227      |\n",
            "|    n_updates            | 1670         |\n",
            "|    policy_gradient_loss | -0.00365     |\n",
            "|    reward               | 0.0029923152 |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.0159       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 169          |\n",
            "|    time_elapsed         | 956          |\n",
            "|    total_timesteps      | 346112       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058376747 |\n",
            "|    clip_fraction        | 0.0475       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.97        |\n",
            "|    explained_variance   | 0.756        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0123      |\n",
            "|    n_updates            | 1680         |\n",
            "|    policy_gradient_loss | -0.00711     |\n",
            "|    reward               | 0.008589448  |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.034        |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 125\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -148403.94\n",
            "total_reward: -158403.94\n",
            "total_cost: 409.73\n",
            "total_trades: 2796\n",
            "Sharpe: 0.322\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 362          |\n",
            "|    iterations           | 170          |\n",
            "|    time_elapsed         | 961          |\n",
            "|    total_timesteps      | 348160       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0063189445 |\n",
            "|    clip_fraction        | 0.0646       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.96        |\n",
            "|    explained_variance   | 0.485        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0193      |\n",
            "|    n_updates            | 1690         |\n",
            "|    policy_gradient_loss | -0.00513     |\n",
            "|    reward               | -0.017125132 |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.0601       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 362          |\n",
            "|    iterations           | 171          |\n",
            "|    time_elapsed         | 966          |\n",
            "|    total_timesteps      | 350208       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005196788  |\n",
            "|    clip_fraction        | 0.0348       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.96        |\n",
            "|    explained_variance   | 0.874        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0648      |\n",
            "|    n_updates            | 1700         |\n",
            "|    policy_gradient_loss | -0.00696     |\n",
            "|    reward               | -0.005894616 |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.0131       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 362           |\n",
            "|    iterations           | 172           |\n",
            "|    time_elapsed         | 972           |\n",
            "|    total_timesteps      | 352256        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00034066063 |\n",
            "|    clip_fraction        | 0.0314        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.96         |\n",
            "|    explained_variance   | 0.619         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0186       |\n",
            "|    n_updates            | 1710          |\n",
            "|    policy_gradient_loss | -0.000286     |\n",
            "|    reward               | 0.027320763   |\n",
            "|    std                  | 1.07          |\n",
            "|    value_loss           | 0.0166        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 362          |\n",
            "|    iterations           | 173          |\n",
            "|    time_elapsed         | 977          |\n",
            "|    total_timesteps      | 354304       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005350722  |\n",
            "|    clip_fraction        | 0.0421       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.97        |\n",
            "|    explained_variance   | 0.403        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0086      |\n",
            "|    n_updates            | 1720         |\n",
            "|    policy_gradient_loss | -0.000929    |\n",
            "|    reward               | -0.032520194 |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.0194       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 362          |\n",
            "|    iterations           | 174          |\n",
            "|    time_elapsed         | 982          |\n",
            "|    total_timesteps      | 356352       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031249535 |\n",
            "|    clip_fraction        | 0.0232       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.98        |\n",
            "|    explained_variance   | 0.231        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0179      |\n",
            "|    n_updates            | 1730         |\n",
            "|    policy_gradient_loss | -0.00056     |\n",
            "|    reward               | 0.0035744163 |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 0.0361       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 362          |\n",
            "|    iterations           | 175          |\n",
            "|    time_elapsed         | 988          |\n",
            "|    total_timesteps      | 358400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0065073576 |\n",
            "|    clip_fraction        | 0.0422       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.98        |\n",
            "|    explained_variance   | 0.506        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0283      |\n",
            "|    n_updates            | 1740         |\n",
            "|    policy_gradient_loss | -0.00368     |\n",
            "|    reward               | -0.012118913 |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 0.0298       |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 130\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -135279.67\n",
            "total_reward: -145279.67\n",
            "total_cost: 418.92\n",
            "total_trades: 2804\n",
            "Sharpe: 0.258\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 362          |\n",
            "|    iterations           | 176          |\n",
            "|    time_elapsed         | 993          |\n",
            "|    total_timesteps      | 360448       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0064382805 |\n",
            "|    clip_fraction        | 0.05         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.99        |\n",
            "|    explained_variance   | 0.3          |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0239      |\n",
            "|    n_updates            | 1750         |\n",
            "|    policy_gradient_loss | -0.00165     |\n",
            "|    reward               | -0.010473357 |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.0312       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 363          |\n",
            "|    iterations           | 177          |\n",
            "|    time_elapsed         | 998          |\n",
            "|    total_timesteps      | 362496       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006793316  |\n",
            "|    clip_fraction        | 0.0713       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3           |\n",
            "|    explained_variance   | 0.649        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0076      |\n",
            "|    n_updates            | 1760         |\n",
            "|    policy_gradient_loss | -0.00653     |\n",
            "|    reward               | -0.054705627 |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.0658       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 363          |\n",
            "|    iterations           | 178          |\n",
            "|    time_elapsed         | 1003         |\n",
            "|    total_timesteps      | 364544       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043813037 |\n",
            "|    clip_fraction        | 0.0453       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | 0.549        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0345      |\n",
            "|    n_updates            | 1770         |\n",
            "|    policy_gradient_loss | -0.00266     |\n",
            "|    reward               | -0.017786354 |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.0149       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 363          |\n",
            "|    iterations           | 179          |\n",
            "|    time_elapsed         | 1009         |\n",
            "|    total_timesteps      | 366592       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004213719  |\n",
            "|    clip_fraction        | 0.0304       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | 0.392        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0302      |\n",
            "|    n_updates            | 1780         |\n",
            "|    policy_gradient_loss | -0.0039      |\n",
            "|    reward               | -0.049214575 |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.0289       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 363          |\n",
            "|    iterations           | 180          |\n",
            "|    time_elapsed         | 1014         |\n",
            "|    total_timesteps      | 368640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0063766306 |\n",
            "|    clip_fraction        | 0.0619       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 0.44         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00218     |\n",
            "|    n_updates            | 1790         |\n",
            "|    policy_gradient_loss | -0.00146     |\n",
            "|    reward               | 0.012027743  |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.0649       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 363          |\n",
            "|    iterations           | 181          |\n",
            "|    time_elapsed         | 1019         |\n",
            "|    total_timesteps      | 370688       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014076793 |\n",
            "|    clip_fraction        | 0.0253       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 0.117        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0116       |\n",
            "|    n_updates            | 1800         |\n",
            "|    policy_gradient_loss | -0.000617    |\n",
            "|    reward               | 0.05395357   |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.0972       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 363          |\n",
            "|    iterations           | 182          |\n",
            "|    time_elapsed         | 1024         |\n",
            "|    total_timesteps      | 372736       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040635625 |\n",
            "|    clip_fraction        | 0.0229       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 0.866        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0339      |\n",
            "|    n_updates            | 1810         |\n",
            "|    policy_gradient_loss | -0.00157     |\n",
            "|    reward               | -0.019759553 |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.00738      |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 135\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -67378.19\n",
            "total_reward: -77378.19\n",
            "total_cost: 549.66\n",
            "total_trades: 2942\n",
            "Sharpe: -0.431\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 363          |\n",
            "|    iterations           | 183          |\n",
            "|    time_elapsed         | 1030         |\n",
            "|    total_timesteps      | 374784       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010048104 |\n",
            "|    clip_fraction        | 0.0107       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | 0.621        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0109      |\n",
            "|    n_updates            | 1820         |\n",
            "|    policy_gradient_loss | 0.000327     |\n",
            "|    reward               | -0.01132827  |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.0342       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 363          |\n",
            "|    iterations           | 184          |\n",
            "|    time_elapsed         | 1035         |\n",
            "|    total_timesteps      | 376832       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037255732 |\n",
            "|    clip_fraction        | 0.0161       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 0.722        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0181      |\n",
            "|    n_updates            | 1830         |\n",
            "|    policy_gradient_loss | -0.000187    |\n",
            "|    reward               | 0.096342914  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.0281       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 363          |\n",
            "|    iterations           | 185          |\n",
            "|    time_elapsed         | 1040         |\n",
            "|    total_timesteps      | 378880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046390276 |\n",
            "|    clip_fraction        | 0.039        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 0.479        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0147      |\n",
            "|    n_updates            | 1840         |\n",
            "|    policy_gradient_loss | -0.00245     |\n",
            "|    reward               | -0.026399495 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.0347       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 186          |\n",
            "|    time_elapsed         | 1046         |\n",
            "|    total_timesteps      | 380928       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031158575 |\n",
            "|    clip_fraction        | 0.00767      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 0.735        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0342      |\n",
            "|    n_updates            | 1850         |\n",
            "|    policy_gradient_loss | 0.000304     |\n",
            "|    reward               | 0.006204571  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.0164       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 187          |\n",
            "|    time_elapsed         | 1051         |\n",
            "|    total_timesteps      | 382976       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.007316644  |\n",
            "|    clip_fraction        | 0.0569       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 0.467        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0159       |\n",
            "|    n_updates            | 1860         |\n",
            "|    policy_gradient_loss | -0.00333     |\n",
            "|    reward               | -0.010981471 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.0718       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 188          |\n",
            "|    time_elapsed         | 1056         |\n",
            "|    total_timesteps      | 385024       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040499726 |\n",
            "|    clip_fraction        | 0.0228       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 0.577        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.011       |\n",
            "|    n_updates            | 1870         |\n",
            "|    policy_gradient_loss | -0.00156     |\n",
            "|    reward               | 0.16053775   |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.0418       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 189          |\n",
            "|    time_elapsed         | 1061         |\n",
            "|    total_timesteps      | 387072       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035772366 |\n",
            "|    clip_fraction        | 0.0292       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 0.533        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0196      |\n",
            "|    n_updates            | 1880         |\n",
            "|    policy_gradient_loss | -0.00105     |\n",
            "|    reward               | -0.032639097 |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.0235       |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 140\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -113354.90\n",
            "total_reward: -123354.90\n",
            "total_cost: 524.52\n",
            "total_trades: 2934\n",
            "Sharpe: 0.513\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 190          |\n",
            "|    time_elapsed         | 1067         |\n",
            "|    total_timesteps      | 389120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011764934 |\n",
            "|    clip_fraction        | 0.00889      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 0.654        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0152      |\n",
            "|    n_updates            | 1890         |\n",
            "|    policy_gradient_loss | -0.000543    |\n",
            "|    reward               | 0.062891334  |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.0152       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 191          |\n",
            "|    time_elapsed         | 1072         |\n",
            "|    total_timesteps      | 391168       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035032553 |\n",
            "|    clip_fraction        | 0.0353       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 0.45         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.000813     |\n",
            "|    n_updates            | 1900         |\n",
            "|    policy_gradient_loss | -0.0019      |\n",
            "|    reward               | -0.03477521  |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.0729       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 192          |\n",
            "|    time_elapsed         | 1077         |\n",
            "|    total_timesteps      | 393216       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0004925025 |\n",
            "|    clip_fraction        | 0.00327      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 0.454        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0116       |\n",
            "|    n_updates            | 1910         |\n",
            "|    policy_gradient_loss | 0.000185     |\n",
            "|    reward               | 0.62265      |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.0813       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 193          |\n",
            "|    time_elapsed         | 1083         |\n",
            "|    total_timesteps      | 395264       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044410964 |\n",
            "|    clip_fraction        | 0.0298       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 0.495        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0215      |\n",
            "|    n_updates            | 1920         |\n",
            "|    policy_gradient_loss | -0.00241     |\n",
            "|    reward               | -0.047509834 |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.0376       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 194          |\n",
            "|    time_elapsed         | 1088         |\n",
            "|    total_timesteps      | 397312       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021876465 |\n",
            "|    clip_fraction        | 0.0113       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 0.579        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.012       |\n",
            "|    n_updates            | 1930         |\n",
            "|    policy_gradient_loss | 0.000373     |\n",
            "|    reward               | -0.022972606 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.0321       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 195         |\n",
            "|    time_elapsed         | 1094        |\n",
            "|    total_timesteps      | 399360      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008061022 |\n",
            "|    clip_fraction        | 0.049       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.04       |\n",
            "|    explained_variance   | 0.738       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0385     |\n",
            "|    n_updates            | 1940        |\n",
            "|    policy_gradient_loss | -0.008      |\n",
            "|    reward               | 0.024161046 |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 0.024       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 196          |\n",
            "|    time_elapsed         | 1100         |\n",
            "|    total_timesteps      | 401408       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032250078 |\n",
            "|    clip_fraction        | 0.0209       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 0.593        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0229      |\n",
            "|    n_updates            | 1950         |\n",
            "|    policy_gradient_loss | -0.00203     |\n",
            "|    reward               | 0.04682966   |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.0476       |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 145\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -67904.82\n",
            "total_reward: -77904.82\n",
            "total_cost: 573.27\n",
            "total_trades: 3068\n",
            "Sharpe: 0.285\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 197          |\n",
            "|    time_elapsed         | 1106         |\n",
            "|    total_timesteps      | 403456       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017261247 |\n",
            "|    clip_fraction        | 0.0179       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 0.747        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0293      |\n",
            "|    n_updates            | 1960         |\n",
            "|    policy_gradient_loss | -0.000916    |\n",
            "|    reward               | -0.05001393  |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.0123       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 364         |\n",
            "|    iterations           | 198         |\n",
            "|    time_elapsed         | 1113        |\n",
            "|    total_timesteps      | 405504      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002890687 |\n",
            "|    clip_fraction        | 0.0173      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.03       |\n",
            "|    explained_variance   | 0.498       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.00794    |\n",
            "|    n_updates            | 1970        |\n",
            "|    policy_gradient_loss | -0.0006     |\n",
            "|    reward               | 0.006929295 |\n",
            "|    std                  | 1.1         |\n",
            "|    value_loss           | 0.0467      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 199          |\n",
            "|    time_elapsed         | 1119         |\n",
            "|    total_timesteps      | 407552       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0066540507 |\n",
            "|    clip_fraction        | 0.034        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 0.371        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0712       |\n",
            "|    n_updates            | 1980         |\n",
            "|    policy_gradient_loss | -0.00165     |\n",
            "|    reward               | -0.026980342 |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.139        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 363          |\n",
            "|    iterations           | 200          |\n",
            "|    time_elapsed         | 1125         |\n",
            "|    total_timesteps      | 409600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051183356 |\n",
            "|    clip_fraction        | 0.0398       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 0.669        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0117      |\n",
            "|    n_updates            | 1990         |\n",
            "|    policy_gradient_loss | -0.00233     |\n",
            "|    reward               | -0.09013988  |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.0354       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 363          |\n",
            "|    iterations           | 201          |\n",
            "|    time_elapsed         | 1131         |\n",
            "|    total_timesteps      | 411648       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033390918 |\n",
            "|    clip_fraction        | 0.0218       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | 0.713        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0114      |\n",
            "|    n_updates            | 2000         |\n",
            "|    policy_gradient_loss | -0.00101     |\n",
            "|    reward               | 0.016940515  |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.0319       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 363          |\n",
            "|    iterations           | 202          |\n",
            "|    time_elapsed         | 1137         |\n",
            "|    total_timesteps      | 413696       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004490492  |\n",
            "|    clip_fraction        | 0.00454      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | 0.5          |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00476     |\n",
            "|    n_updates            | 2010         |\n",
            "|    policy_gradient_loss | -8.33e-05    |\n",
            "|    reward               | -0.014378139 |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.0975       |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 150\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -59126.20\n",
            "total_reward: -69126.20\n",
            "total_cost: 510.50\n",
            "total_trades: 2866\n",
            "Sharpe: 0.219\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 363          |\n",
            "|    iterations           | 203          |\n",
            "|    time_elapsed         | 1142         |\n",
            "|    total_timesteps      | 415744       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032644738 |\n",
            "|    clip_fraction        | 0.0352       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | 0.434        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0803       |\n",
            "|    n_updates            | 2020         |\n",
            "|    policy_gradient_loss | -0.00253     |\n",
            "|    reward               | 0.0035062118 |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.174        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 363          |\n",
            "|    iterations           | 204          |\n",
            "|    time_elapsed         | 1148         |\n",
            "|    total_timesteps      | 417792       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.007087401  |\n",
            "|    clip_fraction        | 0.0604       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | 0.565        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -3.56e-05    |\n",
            "|    n_updates            | 2030         |\n",
            "|    policy_gradient_loss | -0.00346     |\n",
            "|    reward               | -0.040540513 |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.0334       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 363         |\n",
            "|    iterations           | 205         |\n",
            "|    time_elapsed         | 1153        |\n",
            "|    total_timesteps      | 419840      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005636531 |\n",
            "|    clip_fraction        | 0.0532      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.01       |\n",
            "|    explained_variance   | 0.784       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0292     |\n",
            "|    n_updates            | 2040        |\n",
            "|    policy_gradient_loss | -0.00384    |\n",
            "|    reward               | -0.20619571 |\n",
            "|    std                  | 1.1         |\n",
            "|    value_loss           | 0.0198      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 206          |\n",
            "|    time_elapsed         | 1158         |\n",
            "|    total_timesteps      | 421888       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046123546 |\n",
            "|    clip_fraction        | 0.0397       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 0.347        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0175      |\n",
            "|    n_updates            | 2050         |\n",
            "|    policy_gradient_loss | -0.0042      |\n",
            "|    reward               | 0.0062728697 |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.0761       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 207          |\n",
            "|    time_elapsed         | 1164         |\n",
            "|    total_timesteps      | 423936       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038151408 |\n",
            "|    clip_fraction        | 0.0378       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | 0.535        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0443       |\n",
            "|    n_updates            | 2060         |\n",
            "|    policy_gradient_loss | -0.00294     |\n",
            "|    reward               | 0.36795658   |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.109        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 208          |\n",
            "|    time_elapsed         | 1169         |\n",
            "|    total_timesteps      | 425984       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048039677 |\n",
            "|    clip_fraction        | 0.046        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | 0.463        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0176      |\n",
            "|    n_updates            | 2070         |\n",
            "|    policy_gradient_loss | -0.00182     |\n",
            "|    reward               | -0.059433907 |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.0335       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 209          |\n",
            "|    time_elapsed         | 1174         |\n",
            "|    total_timesteps      | 428032       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022333043 |\n",
            "|    clip_fraction        | 0.0181       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | 0.9          |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0318      |\n",
            "|    n_updates            | 2080         |\n",
            "|    policy_gradient_loss | -0.000363    |\n",
            "|    reward               | -0.16057588  |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.00527      |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 155\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -160088.95\n",
            "total_reward: -170088.95\n",
            "total_cost: 429.97\n",
            "total_trades: 2978\n",
            "Sharpe: 0.351\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 364        |\n",
            "|    iterations           | 210        |\n",
            "|    time_elapsed         | 1180       |\n",
            "|    total_timesteps      | 430080     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00870659 |\n",
            "|    clip_fraction        | 0.0483     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.01      |\n",
            "|    explained_variance   | 0.605      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.000967  |\n",
            "|    n_updates            | 2090       |\n",
            "|    policy_gradient_loss | -0.00397   |\n",
            "|    reward               | 0.03375112 |\n",
            "|    std                  | 1.09       |\n",
            "|    value_loss           | 0.0373     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 364         |\n",
            "|    iterations           | 211         |\n",
            "|    time_elapsed         | 1185        |\n",
            "|    total_timesteps      | 432128      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004795623 |\n",
            "|    clip_fraction        | 0.0446      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3          |\n",
            "|    explained_variance   | 0.388       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.00887    |\n",
            "|    n_updates            | 2100        |\n",
            "|    policy_gradient_loss | -0.00936    |\n",
            "|    reward               | -0.13935809 |\n",
            "|    std                  | 1.09        |\n",
            "|    value_loss           | 0.0663      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 364         |\n",
            "|    iterations           | 212         |\n",
            "|    time_elapsed         | 1190        |\n",
            "|    total_timesteps      | 434176      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005209748 |\n",
            "|    clip_fraction        | 0.0485      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3          |\n",
            "|    explained_variance   | 0.231       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.024       |\n",
            "|    n_updates            | 2110        |\n",
            "|    policy_gradient_loss | -0.00253    |\n",
            "|    reward               | 0.070728004 |\n",
            "|    std                  | 1.09        |\n",
            "|    value_loss           | 0.0823      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 213          |\n",
            "|    time_elapsed         | 1196         |\n",
            "|    total_timesteps      | 436224       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005748304  |\n",
            "|    clip_fraction        | 0.0241       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | 0.673        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0175      |\n",
            "|    n_updates            | 2120         |\n",
            "|    policy_gradient_loss | -0.000673    |\n",
            "|    reward               | -0.017688502 |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.0267       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 214          |\n",
            "|    time_elapsed         | 1201         |\n",
            "|    total_timesteps      | 438272       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027484358 |\n",
            "|    clip_fraction        | 0.043        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3           |\n",
            "|    explained_variance   | 0.358        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00871      |\n",
            "|    n_updates            | 2130         |\n",
            "|    policy_gradient_loss | -0.00087     |\n",
            "|    reward               | -0.007365438 |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.0828       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 215         |\n",
            "|    time_elapsed         | 1205        |\n",
            "|    total_timesteps      | 440320      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003420677 |\n",
            "|    clip_fraction        | 0.0476      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3          |\n",
            "|    explained_variance   | 0.553       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0147      |\n",
            "|    n_updates            | 2140        |\n",
            "|    policy_gradient_loss | -0.00171    |\n",
            "|    reward               | 0.33173415  |\n",
            "|    std                  | 1.09        |\n",
            "|    value_loss           | 0.0382      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 216          |\n",
            "|    time_elapsed         | 1210         |\n",
            "|    total_timesteps      | 442368       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036533303 |\n",
            "|    clip_fraction        | 0.00879      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3           |\n",
            "|    explained_variance   | 0.495        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0062      |\n",
            "|    n_updates            | 2150         |\n",
            "|    policy_gradient_loss | -0.00103     |\n",
            "|    reward               | 0.0062843026 |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.0235       |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 160\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -152825.75\n",
            "total_reward: -162825.75\n",
            "total_cost: 650.55\n",
            "total_trades: 3428\n",
            "Sharpe: 0.647\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 217         |\n",
            "|    time_elapsed         | 1215        |\n",
            "|    total_timesteps      | 444416      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010145221 |\n",
            "|    clip_fraction        | 0.0743      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.01       |\n",
            "|    explained_variance   | 0.493       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.00713    |\n",
            "|    n_updates            | 2160        |\n",
            "|    policy_gradient_loss | -0.00549    |\n",
            "|    reward               | 0.021367522 |\n",
            "|    std                  | 1.09        |\n",
            "|    value_loss           | 0.0322      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 218          |\n",
            "|    time_elapsed         | 1219         |\n",
            "|    total_timesteps      | 446464       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038612392 |\n",
            "|    clip_fraction        | 0.0118       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | 0.437        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00826      |\n",
            "|    n_updates            | 2170         |\n",
            "|    policy_gradient_loss | -0.000285    |\n",
            "|    reward               | 0.015891584  |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.112        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 219         |\n",
            "|    time_elapsed         | 1224        |\n",
            "|    total_timesteps      | 448512      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005027738 |\n",
            "|    clip_fraction        | 0.0341      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.02       |\n",
            "|    explained_variance   | 0.544       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.00209     |\n",
            "|    n_updates            | 2180        |\n",
            "|    policy_gradient_loss | -0.00243    |\n",
            "|    reward               | 0.0947457   |\n",
            "|    std                  | 1.1         |\n",
            "|    value_loss           | 0.0832      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 366          |\n",
            "|    iterations           | 220          |\n",
            "|    time_elapsed         | 1228         |\n",
            "|    total_timesteps      | 450560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004786236  |\n",
            "|    clip_fraction        | 0.0397       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 0.374        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0122      |\n",
            "|    n_updates            | 2190         |\n",
            "|    policy_gradient_loss | -0.002       |\n",
            "|    reward               | -0.025873572 |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.0503       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 366          |\n",
            "|    iterations           | 221          |\n",
            "|    time_elapsed         | 1233         |\n",
            "|    total_timesteps      | 452608       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056502633 |\n",
            "|    clip_fraction        | 0.0558       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 0.567        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.000373    |\n",
            "|    n_updates            | 2200         |\n",
            "|    policy_gradient_loss | -0.00204     |\n",
            "|    reward               | -0.011698665 |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.0792       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 367          |\n",
            "|    iterations           | 222          |\n",
            "|    time_elapsed         | 1238         |\n",
            "|    total_timesteps      | 454656       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0065149395 |\n",
            "|    clip_fraction        | 0.0571       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 0.774        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0132      |\n",
            "|    n_updates            | 2210         |\n",
            "|    policy_gradient_loss | -0.00762     |\n",
            "|    reward               | 0.011408849  |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.0192       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 367          |\n",
            "|    iterations           | 223          |\n",
            "|    time_elapsed         | 1242         |\n",
            "|    total_timesteps      | 456704       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021771616 |\n",
            "|    clip_fraction        | 0.00122      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 0.58         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0194      |\n",
            "|    n_updates            | 2220         |\n",
            "|    policy_gradient_loss | -0.000188    |\n",
            "|    reward               | 0.014488321  |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.0422       |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 165\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 10058.61\n",
            "total_reward: 58.61\n",
            "total_cost: 456.91\n",
            "total_trades: 3524\n",
            "Sharpe: 0.372\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 367         |\n",
            "|    iterations           | 224         |\n",
            "|    time_elapsed         | 1247        |\n",
            "|    total_timesteps      | 458752      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002750507 |\n",
            "|    clip_fraction        | 0.0195      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.02       |\n",
            "|    explained_variance   | 0.569       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0393     |\n",
            "|    n_updates            | 2230        |\n",
            "|    policy_gradient_loss | -0.00463    |\n",
            "|    reward               | -0.11119834 |\n",
            "|    std                  | 1.1         |\n",
            "|    value_loss           | 0.0135      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 225          |\n",
            "|    time_elapsed         | 1252         |\n",
            "|    total_timesteps      | 460800       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061111953 |\n",
            "|    clip_fraction        | 0.0466       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 0.327        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00568     |\n",
            "|    n_updates            | 2240         |\n",
            "|    policy_gradient_loss | -0.00537     |\n",
            "|    reward               | 0.0015233579 |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.0454       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 226          |\n",
            "|    time_elapsed         | 1256         |\n",
            "|    total_timesteps      | 462848       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069299424 |\n",
            "|    clip_fraction        | 0.0563       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | 0.367        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00267     |\n",
            "|    n_updates            | 2250         |\n",
            "|    policy_gradient_loss | -0.00772     |\n",
            "|    reward               | 0.006702975  |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.123        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 227         |\n",
            "|    time_elapsed         | 1261        |\n",
            "|    total_timesteps      | 464896      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007210096 |\n",
            "|    clip_fraction        | 0.0311      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.02       |\n",
            "|    explained_variance   | 0.547       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.00208     |\n",
            "|    n_updates            | 2260        |\n",
            "|    policy_gradient_loss | -0.00163    |\n",
            "|    reward               | 0.02523549  |\n",
            "|    std                  | 1.1         |\n",
            "|    value_loss           | 0.0378      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 228         |\n",
            "|    time_elapsed         | 1265        |\n",
            "|    total_timesteps      | 466944      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004991473 |\n",
            "|    clip_fraction        | 0.0355      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.01       |\n",
            "|    explained_variance   | 0.731       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0319     |\n",
            "|    n_updates            | 2270        |\n",
            "|    policy_gradient_loss | -0.00733    |\n",
            "|    reward               | 0.028695488 |\n",
            "|    std                  | 1.1         |\n",
            "|    value_loss           | 0.0107      |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 369           |\n",
            "|    iterations           | 229           |\n",
            "|    time_elapsed         | 1270          |\n",
            "|    total_timesteps      | 468992        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00786068    |\n",
            "|    clip_fraction        | 0.0671        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3            |\n",
            "|    explained_variance   | 0.49          |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0273       |\n",
            "|    n_updates            | 2280          |\n",
            "|    policy_gradient_loss | -0.00827      |\n",
            "|    reward               | -0.0093947025 |\n",
            "|    std                  | 1.09          |\n",
            "|    value_loss           | 0.0186        |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 369         |\n",
            "|    iterations           | 230         |\n",
            "|    time_elapsed         | 1276        |\n",
            "|    total_timesteps      | 471040      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006207689 |\n",
            "|    clip_fraction        | 0.0386      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.01       |\n",
            "|    explained_variance   | 0.502       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0179     |\n",
            "|    n_updates            | 2290        |\n",
            "|    policy_gradient_loss | -0.00543    |\n",
            "|    reward               | 0.20571062  |\n",
            "|    std                  | 1.1         |\n",
            "|    value_loss           | 0.0247      |\n",
            "-----------------------------------------\n",
            "day: 2770, episode: 170\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 20976.06\n",
            "total_reward: 10976.06\n",
            "total_cost: 811.03\n",
            "total_trades: 4128\n",
            "Sharpe: 0.379\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 369         |\n",
            "|    iterations           | 231         |\n",
            "|    time_elapsed         | 1282        |\n",
            "|    total_timesteps      | 473088      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006046493 |\n",
            "|    clip_fraction        | 0.047       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.02       |\n",
            "|    explained_variance   | 0.176       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0125     |\n",
            "|    n_updates            | 2300        |\n",
            "|    policy_gradient_loss | -0.00255    |\n",
            "|    reward               | 0.21597052  |\n",
            "|    std                  | 1.1         |\n",
            "|    value_loss           | 0.0486      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 369          |\n",
            "|    iterations           | 232          |\n",
            "|    time_elapsed         | 1287         |\n",
            "|    total_timesteps      | 475136       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038375542 |\n",
            "|    clip_fraction        | 0.0214       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 0.154        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0216      |\n",
            "|    n_updates            | 2310         |\n",
            "|    policy_gradient_loss | -0.00411     |\n",
            "|    reward               | 0.01838285   |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.0497       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 369          |\n",
            "|    iterations           | 233          |\n",
            "|    time_elapsed         | 1292         |\n",
            "|    total_timesteps      | 477184       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005838605  |\n",
            "|    clip_fraction        | 0.0479       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | -0.0935      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0742       |\n",
            "|    n_updates            | 2320         |\n",
            "|    policy_gradient_loss | -0.0069      |\n",
            "|    reward               | -0.027994517 |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.301        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 369          |\n",
            "|    iterations           | 234          |\n",
            "|    time_elapsed         | 1298         |\n",
            "|    total_timesteps      | 479232       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041183066 |\n",
            "|    clip_fraction        | 0.02         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | -0.0209      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.03         |\n",
            "|    n_updates            | 2330         |\n",
            "|    policy_gradient_loss | -0.00312     |\n",
            "|    reward               | -0.009247756 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.1          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 369         |\n",
            "|    iterations           | 235         |\n",
            "|    time_elapsed         | 1303        |\n",
            "|    total_timesteps      | 481280      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005081214 |\n",
            "|    clip_fraction        | 0.0474      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.03       |\n",
            "|    explained_variance   | 0.113       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.15        |\n",
            "|    n_updates            | 2340        |\n",
            "|    policy_gradient_loss | -0.00472    |\n",
            "|    reward               | -0.16402201 |\n",
            "|    std                  | 1.1         |\n",
            "|    value_loss           | 0.581       |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 369           |\n",
            "|    iterations           | 236           |\n",
            "|    time_elapsed         | 1309          |\n",
            "|    total_timesteps      | 483328        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.007873457   |\n",
            "|    clip_fraction        | 0.0547        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.02         |\n",
            "|    explained_variance   | 0.382         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0185        |\n",
            "|    n_updates            | 2350          |\n",
            "|    policy_gradient_loss | -0.00412      |\n",
            "|    reward               | -0.0038444605 |\n",
            "|    std                  | 1.09          |\n",
            "|    value_loss           | 0.131         |\n",
            "-------------------------------------------\n",
            "day: 2770, episode: 175\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 50564.67\n",
            "total_reward: 40564.67\n",
            "total_cost: 477.70\n",
            "total_trades: 3974\n",
            "Sharpe: 0.266\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 369         |\n",
            "|    iterations           | 237         |\n",
            "|    time_elapsed         | 1314        |\n",
            "|    total_timesteps      | 485376      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006995839 |\n",
            "|    clip_fraction        | 0.055       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.01       |\n",
            "|    explained_variance   | 0.575       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0674      |\n",
            "|    n_updates            | 2360        |\n",
            "|    policy_gradient_loss | -0.00768    |\n",
            "|    reward               | 0.007185383 |\n",
            "|    std                  | 1.09        |\n",
            "|    value_loss           | 0.201       |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 369           |\n",
            "|    iterations           | 238           |\n",
            "|    time_elapsed         | 1320          |\n",
            "|    total_timesteps      | 487424        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0058408417  |\n",
            "|    clip_fraction        | 0.0382        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.02         |\n",
            "|    explained_variance   | 0.444         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.00167       |\n",
            "|    n_updates            | 2370          |\n",
            "|    policy_gradient_loss | -0.00936      |\n",
            "|    reward               | -0.0024587314 |\n",
            "|    std                  | 1.1           |\n",
            "|    value_loss           | 0.0935        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 369          |\n",
            "|    iterations           | 239          |\n",
            "|    time_elapsed         | 1325         |\n",
            "|    total_timesteps      | 489472       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006249597  |\n",
            "|    clip_fraction        | 0.0485       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 0.566        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0292      |\n",
            "|    n_updates            | 2380         |\n",
            "|    policy_gradient_loss | -0.00877     |\n",
            "|    reward               | -0.042478297 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.0304       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 369          |\n",
            "|    iterations           | 240          |\n",
            "|    time_elapsed         | 1331         |\n",
            "|    total_timesteps      | 491520       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061687026 |\n",
            "|    clip_fraction        | 0.0392       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 0.681        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0263      |\n",
            "|    n_updates            | 2390         |\n",
            "|    policy_gradient_loss | -0.00869     |\n",
            "|    reward               | -0.007150115 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.0393       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 369          |\n",
            "|    iterations           | 241          |\n",
            "|    time_elapsed         | 1337         |\n",
            "|    total_timesteps      | 493568       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0077041257 |\n",
            "|    clip_fraction        | 0.0443       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 0.494        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0269       |\n",
            "|    n_updates            | 2400         |\n",
            "|    policy_gradient_loss | -0.00338     |\n",
            "|    reward               | 0.007219258  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.227        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 369          |\n",
            "|    iterations           | 242          |\n",
            "|    time_elapsed         | 1343         |\n",
            "|    total_timesteps      | 495616       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029831696 |\n",
            "|    clip_fraction        | 0.0194       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 0.22         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.256        |\n",
            "|    n_updates            | 2410         |\n",
            "|    policy_gradient_loss | -0.00312     |\n",
            "|    reward               | 0.05832121   |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.777        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 243          |\n",
            "|    time_elapsed         | 1348         |\n",
            "|    total_timesteps      | 497664       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0074101463 |\n",
            "|    clip_fraction        | 0.0395       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 0.457        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0425       |\n",
            "|    n_updates            | 2420         |\n",
            "|    policy_gradient_loss | -0.00467     |\n",
            "|    reward               | -0.037765887 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.114        |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 180\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 319428.83\n",
            "total_reward: 309428.83\n",
            "total_cost: 378.45\n",
            "total_trades: 3828\n",
            "Sharpe: 0.882\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 244          |\n",
            "|    time_elapsed         | 1354         |\n",
            "|    total_timesteps      | 499712       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006882883  |\n",
            "|    clip_fraction        | 0.0369       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 0.445        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0079       |\n",
            "|    n_updates            | 2430         |\n",
            "|    policy_gradient_loss | -0.00597     |\n",
            "|    reward               | -0.047664825 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.152        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 245          |\n",
            "|    time_elapsed         | 1359         |\n",
            "|    total_timesteps      | 501760       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0072366134 |\n",
            "|    clip_fraction        | 0.0614       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 0.391        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.288        |\n",
            "|    n_updates            | 2440         |\n",
            "|    policy_gradient_loss | -0.00465     |\n",
            "|    reward               | 0.014473192  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.635        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 246         |\n",
            "|    time_elapsed         | 1365        |\n",
            "|    total_timesteps      | 503808      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003676232 |\n",
            "|    clip_fraction        | 0.0292      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.04       |\n",
            "|    explained_variance   | 0.236       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.385       |\n",
            "|    n_updates            | 2450        |\n",
            "|    policy_gradient_loss | -0.0031     |\n",
            "|    reward               | 0.047086664 |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 0.925       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 247          |\n",
            "|    time_elapsed         | 1371         |\n",
            "|    total_timesteps      | 505856       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006693832  |\n",
            "|    clip_fraction        | 0.0541       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 0.771        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0275      |\n",
            "|    n_updates            | 2460         |\n",
            "|    policy_gradient_loss | -0.00736     |\n",
            "|    reward               | -0.018483972 |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.0354       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 248         |\n",
            "|    time_elapsed         | 1377        |\n",
            "|    total_timesteps      | 507904      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004070687 |\n",
            "|    clip_fraction        | 0.0369      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.05       |\n",
            "|    explained_variance   | 0.783       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.00991    |\n",
            "|    n_updates            | 2470        |\n",
            "|    policy_gradient_loss | -0.00198    |\n",
            "|    reward               | -0.02530521 |\n",
            "|    std                  | 1.12        |\n",
            "|    value_loss           | 0.0522      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 249          |\n",
            "|    time_elapsed         | 1383         |\n",
            "|    total_timesteps      | 509952       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.00543532   |\n",
            "|    clip_fraction        | 0.0364       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 0.799        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00509     |\n",
            "|    n_updates            | 2480         |\n",
            "|    policy_gradient_loss | -0.00472     |\n",
            "|    reward               | -0.004649306 |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.0538       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 250         |\n",
            "|    time_elapsed         | 1388        |\n",
            "|    total_timesteps      | 512000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009188864 |\n",
            "|    clip_fraction        | 0.0664      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.07       |\n",
            "|    explained_variance   | 0.656       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0015     |\n",
            "|    n_updates            | 2490        |\n",
            "|    policy_gradient_loss | -0.00773    |\n",
            "|    reward               | -0.22083187 |\n",
            "|    std                  | 1.13        |\n",
            "|    value_loss           | 0.0824      |\n",
            "-----------------------------------------\n",
            "day: 2770, episode: 185\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 322423.45\n",
            "total_reward: 312423.45\n",
            "total_cost: 400.15\n",
            "total_trades: 3956\n",
            "Sharpe: 0.873\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 251          |\n",
            "|    time_elapsed         | 1394         |\n",
            "|    total_timesteps      | 514048       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0067942743 |\n",
            "|    clip_fraction        | 0.054        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.07        |\n",
            "|    explained_variance   | 0.145        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0607       |\n",
            "|    n_updates            | 2500         |\n",
            "|    policy_gradient_loss | -0.00492     |\n",
            "|    reward               | -0.47611648  |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.21         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 252          |\n",
            "|    time_elapsed         | 1399         |\n",
            "|    total_timesteps      | 516096       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052385377 |\n",
            "|    clip_fraction        | 0.0395       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.06        |\n",
            "|    explained_variance   | 0.358        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.25         |\n",
            "|    n_updates            | 2510         |\n",
            "|    policy_gradient_loss | -0.00224     |\n",
            "|    reward               | 0.008660122  |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.528        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 253          |\n",
            "|    time_elapsed         | 1405         |\n",
            "|    total_timesteps      | 518144       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0077579725 |\n",
            "|    clip_fraction        | 0.0666       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.06        |\n",
            "|    explained_variance   | 0.473        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.321        |\n",
            "|    n_updates            | 2520         |\n",
            "|    policy_gradient_loss | -0.00587     |\n",
            "|    reward               | -0.74480194  |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.59         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 254         |\n",
            "|    time_elapsed         | 1411        |\n",
            "|    total_timesteps      | 520192      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005021617 |\n",
            "|    clip_fraction        | 0.0324      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.06       |\n",
            "|    explained_variance   | 0.485       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.148       |\n",
            "|    n_updates            | 2530        |\n",
            "|    policy_gradient_loss | -0.00223    |\n",
            "|    reward               | 0.01803418  |\n",
            "|    std                  | 1.12        |\n",
            "|    value_loss           | 0.356       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 255          |\n",
            "|    time_elapsed         | 1417         |\n",
            "|    total_timesteps      | 522240       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036359583 |\n",
            "|    clip_fraction        | 0.0414       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.06        |\n",
            "|    explained_variance   | 0.412        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.052        |\n",
            "|    n_updates            | 2540         |\n",
            "|    policy_gradient_loss | -0.00415     |\n",
            "|    reward               | -0.057697922 |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.217        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 256          |\n",
            "|    time_elapsed         | 1422         |\n",
            "|    total_timesteps      | 524288       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005496097  |\n",
            "|    clip_fraction        | 0.0351       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 0.448        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.352        |\n",
            "|    n_updates            | 2550         |\n",
            "|    policy_gradient_loss | -0.00338     |\n",
            "|    reward               | -0.016875906 |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.832        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 257         |\n",
            "|    time_elapsed         | 1428        |\n",
            "|    total_timesteps      | 526336      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005192685 |\n",
            "|    clip_fraction        | 0.0397      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.05       |\n",
            "|    explained_variance   | 0.45        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.397       |\n",
            "|    n_updates            | 2560        |\n",
            "|    policy_gradient_loss | -0.00524    |\n",
            "|    reward               | 0.5438144   |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 0.88        |\n",
            "-----------------------------------------\n",
            "day: 2770, episode: 190\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 381041.51\n",
            "total_reward: 371041.51\n",
            "total_cost: 373.77\n",
            "total_trades: 3944\n",
            "Sharpe: 0.896\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 258         |\n",
            "|    time_elapsed         | 1434        |\n",
            "|    total_timesteps      | 528384      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007566871 |\n",
            "|    clip_fraction        | 0.0589      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.04       |\n",
            "|    explained_variance   | 0.335       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.249       |\n",
            "|    n_updates            | 2570        |\n",
            "|    policy_gradient_loss | -0.00409    |\n",
            "|    reward               | 0.043011446 |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 0.73        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 259          |\n",
            "|    time_elapsed         | 1439         |\n",
            "|    total_timesteps      | 530432       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0057575414 |\n",
            "|    clip_fraction        | 0.0503       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 0.765        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0643       |\n",
            "|    n_updates            | 2580         |\n",
            "|    policy_gradient_loss | -0.00358     |\n",
            "|    reward               | 0.07868264   |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.274        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 260          |\n",
            "|    time_elapsed         | 1445         |\n",
            "|    total_timesteps      | 532480       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0063768863 |\n",
            "|    clip_fraction        | 0.046        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 0.589        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.359        |\n",
            "|    n_updates            | 2590         |\n",
            "|    policy_gradient_loss | -0.00177     |\n",
            "|    reward               | -0.012353817 |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.878        |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 368        |\n",
            "|    iterations           | 261        |\n",
            "|    time_elapsed         | 1451       |\n",
            "|    total_timesteps      | 534528     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01209316 |\n",
            "|    clip_fraction        | 0.0816     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.02      |\n",
            "|    explained_variance   | 0.549      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 0.305      |\n",
            "|    n_updates            | 2600       |\n",
            "|    policy_gradient_loss | -0.00622   |\n",
            "|    reward               | -0.7513241 |\n",
            "|    std                  | 1.1        |\n",
            "|    value_loss           | 0.976      |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 262          |\n",
            "|    time_elapsed         | 1457         |\n",
            "|    total_timesteps      | 536576       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.007687021  |\n",
            "|    clip_fraction        | 0.0584       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 0.638        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.143        |\n",
            "|    n_updates            | 2610         |\n",
            "|    policy_gradient_loss | -0.0039      |\n",
            "|    reward               | -0.021887274 |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.392        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 368           |\n",
            "|    iterations           | 263           |\n",
            "|    time_elapsed         | 1463          |\n",
            "|    total_timesteps      | 538624        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0044394806  |\n",
            "|    clip_fraction        | 0.0425        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.03         |\n",
            "|    explained_variance   | 0.809         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.135         |\n",
            "|    n_updates            | 2620          |\n",
            "|    policy_gradient_loss | -0.00367      |\n",
            "|    reward               | -0.0049078506 |\n",
            "|    std                  | 1.11          |\n",
            "|    value_loss           | 0.299         |\n",
            "-------------------------------------------\n",
            "day: 2770, episode: 195\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 394659.28\n",
            "total_reward: 384659.28\n",
            "total_cost: 365.22\n",
            "total_trades: 3936\n",
            "Sharpe: 0.899\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 264          |\n",
            "|    time_elapsed         | 1468         |\n",
            "|    total_timesteps      | 540672       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050789975 |\n",
            "|    clip_fraction        | 0.0364       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 0.522        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.812        |\n",
            "|    n_updates            | 2630         |\n",
            "|    policy_gradient_loss | -0.00262     |\n",
            "|    reward               | -0.0152759   |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 1.16         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 265          |\n",
            "|    time_elapsed         | 1474         |\n",
            "|    total_timesteps      | 542720       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0063876007 |\n",
            "|    clip_fraction        | 0.0522       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 0.506        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.289        |\n",
            "|    n_updates            | 2640         |\n",
            "|    policy_gradient_loss | -0.00208     |\n",
            "|    reward               | 0.07799877   |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.967        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 266          |\n",
            "|    time_elapsed         | 1479         |\n",
            "|    total_timesteps      | 544768       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0075998916 |\n",
            "|    clip_fraction        | 0.0595       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 0.521        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.159        |\n",
            "|    n_updates            | 2650         |\n",
            "|    policy_gradient_loss | -0.00461     |\n",
            "|    reward               | 0.0147295855 |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.411        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 267         |\n",
            "|    time_elapsed         | 1485        |\n",
            "|    total_timesteps      | 546816      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008878673 |\n",
            "|    clip_fraction        | 0.0386      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.03       |\n",
            "|    explained_variance   | 0.707       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.145       |\n",
            "|    n_updates            | 2660        |\n",
            "|    policy_gradient_loss | -0.00342    |\n",
            "|    reward               | 0.012169659 |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 0.552       |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 368           |\n",
            "|    iterations           | 268           |\n",
            "|    time_elapsed         | 1490          |\n",
            "|    total_timesteps      | 548864        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.007151671   |\n",
            "|    clip_fraction        | 0.0688        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.03         |\n",
            "|    explained_variance   | 0.667         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.485         |\n",
            "|    n_updates            | 2670          |\n",
            "|    policy_gradient_loss | -0.00644      |\n",
            "|    reward               | 0.00069876417 |\n",
            "|    std                  | 1.11          |\n",
            "|    value_loss           | 0.975         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 269          |\n",
            "|    time_elapsed         | 1496         |\n",
            "|    total_timesteps      | 550912       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0075534186 |\n",
            "|    clip_fraction        | 0.0666       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 0.577        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.421        |\n",
            "|    n_updates            | 2680         |\n",
            "|    policy_gradient_loss | -0.00455     |\n",
            "|    reward               | 0.38577747   |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 1            |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 270          |\n",
            "|    time_elapsed         | 1501         |\n",
            "|    total_timesteps      | 552960       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071860617 |\n",
            "|    clip_fraction        | 0.0703       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 0.744        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.168        |\n",
            "|    n_updates            | 2690         |\n",
            "|    policy_gradient_loss | -0.00302     |\n",
            "|    reward               | -0.07209981  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.284        |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 200\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 370346.09\n",
            "total_reward: 360346.09\n",
            "total_cost: 393.07\n",
            "total_trades: 4104\n",
            "Sharpe: 0.887\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 271         |\n",
            "|    time_elapsed         | 1507        |\n",
            "|    total_timesteps      | 555008      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008621668 |\n",
            "|    clip_fraction        | 0.0579      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.04       |\n",
            "|    explained_variance   | 0.707       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.161       |\n",
            "|    n_updates            | 2700        |\n",
            "|    policy_gradient_loss | -0.00311    |\n",
            "|    reward               | 0.01414193  |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 0.627       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 272         |\n",
            "|    time_elapsed         | 1512        |\n",
            "|    total_timesteps      | 557056      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008711355 |\n",
            "|    clip_fraction        | 0.0774      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.04       |\n",
            "|    explained_variance   | 0.731       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.238       |\n",
            "|    n_updates            | 2710        |\n",
            "|    policy_gradient_loss | -0.00522    |\n",
            "|    reward               | 0.012465642 |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 0.761       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 273         |\n",
            "|    time_elapsed         | 1517        |\n",
            "|    total_timesteps      | 559104      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008697605 |\n",
            "|    clip_fraction        | 0.0618      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.04       |\n",
            "|    explained_variance   | 0.589       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.344       |\n",
            "|    n_updates            | 2720        |\n",
            "|    policy_gradient_loss | -0.00423    |\n",
            "|    reward               | 0.13074392  |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 0.989       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 274          |\n",
            "|    time_elapsed         | 1523         |\n",
            "|    total_timesteps      | 561152       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069230525 |\n",
            "|    clip_fraction        | 0.0583       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 0.716        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0673       |\n",
            "|    n_updates            | 2730         |\n",
            "|    policy_gradient_loss | -0.00348     |\n",
            "|    reward               | -0.30630383  |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.303        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 275          |\n",
            "|    time_elapsed         | 1528         |\n",
            "|    total_timesteps      | 563200       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048152586 |\n",
            "|    clip_fraction        | 0.0546       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.06        |\n",
            "|    explained_variance   | 0.756        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.541        |\n",
            "|    n_updates            | 2740         |\n",
            "|    policy_gradient_loss | -0.00183     |\n",
            "|    reward               | -0.010232336 |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.784        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 276         |\n",
            "|    time_elapsed         | 1534        |\n",
            "|    total_timesteps      | 565248      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008661192 |\n",
            "|    clip_fraction        | 0.0646      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.06       |\n",
            "|    explained_variance   | 0.706       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.536       |\n",
            "|    n_updates            | 2750        |\n",
            "|    policy_gradient_loss | -0.00368    |\n",
            "|    reward               | 0.7495518   |\n",
            "|    std                  | 1.12        |\n",
            "|    value_loss           | 1           |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 277          |\n",
            "|    time_elapsed         | 1539         |\n",
            "|    total_timesteps      | 567296       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034082928 |\n",
            "|    clip_fraction        | 0.0293       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.06        |\n",
            "|    explained_variance   | 0.574        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.317        |\n",
            "|    n_updates            | 2760         |\n",
            "|    policy_gradient_loss | -0.00317     |\n",
            "|    reward               | -0.18218628  |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 1.05         |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 205\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 418875.78\n",
            "total_reward: 408875.78\n",
            "total_cost: 371.62\n",
            "total_trades: 4060\n",
            "Sharpe: 0.906\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 278         |\n",
            "|    time_elapsed         | 1545        |\n",
            "|    total_timesteps      | 569344      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007217105 |\n",
            "|    clip_fraction        | 0.0661      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.06       |\n",
            "|    explained_variance   | 0.738       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0616      |\n",
            "|    n_updates            | 2770        |\n",
            "|    policy_gradient_loss | -0.00345    |\n",
            "|    reward               | 0.09257381  |\n",
            "|    std                  | 1.13        |\n",
            "|    value_loss           | 0.258       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 279          |\n",
            "|    time_elapsed         | 1551         |\n",
            "|    total_timesteps      | 571392       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.007963644  |\n",
            "|    clip_fraction        | 0.065        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.07        |\n",
            "|    explained_variance   | 0.606        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.464        |\n",
            "|    n_updates            | 2780         |\n",
            "|    policy_gradient_loss | -0.00525     |\n",
            "|    reward               | 0.0036475325 |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 1.16         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 280          |\n",
            "|    time_elapsed         | 1556         |\n",
            "|    total_timesteps      | 573440       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0125925485 |\n",
            "|    clip_fraction        | 0.101        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.592        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.588        |\n",
            "|    n_updates            | 2790         |\n",
            "|    policy_gradient_loss | -0.0026      |\n",
            "|    reward               | 0.054396536  |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 1.09         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 281          |\n",
            "|    time_elapsed         | 1562         |\n",
            "|    total_timesteps      | 575488       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0066006226 |\n",
            "|    clip_fraction        | 0.0587       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.435        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.372        |\n",
            "|    n_updates            | 2800         |\n",
            "|    policy_gradient_loss | -0.00157     |\n",
            "|    reward               | 0.1744298    |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 0.779        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 282         |\n",
            "|    time_elapsed         | 1567        |\n",
            "|    total_timesteps      | 577536      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009250588 |\n",
            "|    clip_fraction        | 0.0815      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.09       |\n",
            "|    explained_variance   | 0.852       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.141       |\n",
            "|    n_updates            | 2810        |\n",
            "|    policy_gradient_loss | -0.00264    |\n",
            "|    reward               | -0.18875004 |\n",
            "|    std                  | 1.15        |\n",
            "|    value_loss           | 0.321       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 283          |\n",
            "|    time_elapsed         | 1573         |\n",
            "|    total_timesteps      | 579584       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050814096 |\n",
            "|    clip_fraction        | 0.0307       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.1         |\n",
            "|    explained_variance   | 0.701        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.406        |\n",
            "|    n_updates            | 2820         |\n",
            "|    policy_gradient_loss | -0.000542    |\n",
            "|    reward               | -0.02815013  |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 0.965        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 284         |\n",
            "|    time_elapsed         | 1578        |\n",
            "|    total_timesteps      | 581632      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010353323 |\n",
            "|    clip_fraction        | 0.0693      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.1        |\n",
            "|    explained_variance   | 0.679       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.44        |\n",
            "|    n_updates            | 2830        |\n",
            "|    policy_gradient_loss | -0.00176    |\n",
            "|    reward               | -1.2125816  |\n",
            "|    std                  | 1.15        |\n",
            "|    value_loss           | 0.97        |\n",
            "-----------------------------------------\n",
            "day: 2770, episode: 210\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 388281.57\n",
            "total_reward: 378281.57\n",
            "total_cost: 365.05\n",
            "total_trades: 3968\n",
            "Sharpe: 0.895\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 285         |\n",
            "|    time_elapsed         | 1584        |\n",
            "|    total_timesteps      | 583680      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005796812 |\n",
            "|    clip_fraction        | 0.0394      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.11       |\n",
            "|    explained_variance   | 0.387       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.247       |\n",
            "|    n_updates            | 2840        |\n",
            "|    policy_gradient_loss | -0.00368    |\n",
            "|    reward               | -0.84211886 |\n",
            "|    std                  | 1.15        |\n",
            "|    value_loss           | 0.541       |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 368           |\n",
            "|    iterations           | 286           |\n",
            "|    time_elapsed         | 1589          |\n",
            "|    total_timesteps      | 585728        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.007444778   |\n",
            "|    clip_fraction        | 0.0541        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.1          |\n",
            "|    explained_variance   | 0.801         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.129         |\n",
            "|    n_updates            | 2850          |\n",
            "|    policy_gradient_loss | -0.00198      |\n",
            "|    reward               | -0.0079340385 |\n",
            "|    std                  | 1.14          |\n",
            "|    value_loss           | 0.424         |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 287         |\n",
            "|    time_elapsed         | 1595        |\n",
            "|    total_timesteps      | 587776      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006945665 |\n",
            "|    clip_fraction        | 0.0404      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.09       |\n",
            "|    explained_variance   | 0.685       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.348       |\n",
            "|    n_updates            | 2860        |\n",
            "|    policy_gradient_loss | -0.00265    |\n",
            "|    reward               | 0.018914001 |\n",
            "|    std                  | 1.14        |\n",
            "|    value_loss           | 0.912       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 288         |\n",
            "|    time_elapsed         | 1600        |\n",
            "|    total_timesteps      | 589824      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009573598 |\n",
            "|    clip_fraction        | 0.0635      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.09       |\n",
            "|    explained_variance   | 0.651       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.383       |\n",
            "|    n_updates            | 2870        |\n",
            "|    policy_gradient_loss | -0.00236    |\n",
            "|    reward               | 0.97741556  |\n",
            "|    std                  | 1.14        |\n",
            "|    value_loss           | 0.993       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 289         |\n",
            "|    time_elapsed         | 1606        |\n",
            "|    total_timesteps      | 591872      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004796394 |\n",
            "|    clip_fraction        | 0.0321      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.08       |\n",
            "|    explained_variance   | 0.651       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.16        |\n",
            "|    n_updates            | 2880        |\n",
            "|    policy_gradient_loss | -0.000761   |\n",
            "|    reward               | 0.30863777  |\n",
            "|    std                  | 1.14        |\n",
            "|    value_loss           | 0.431       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 290          |\n",
            "|    time_elapsed         | 1612         |\n",
            "|    total_timesteps      | 593920       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004479033  |\n",
            "|    clip_fraction        | 0.0244       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.769        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.304        |\n",
            "|    n_updates            | 2890         |\n",
            "|    policy_gradient_loss | -0.00322     |\n",
            "|    reward               | -0.064200096 |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 0.646        |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 215\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 424331.20\n",
            "total_reward: 414331.20\n",
            "total_cost: 361.79\n",
            "total_trades: 4024\n",
            "Sharpe: 0.907\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 291         |\n",
            "|    time_elapsed         | 1617        |\n",
            "|    total_timesteps      | 595968      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005221527 |\n",
            "|    clip_fraction        | 0.0369      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.08       |\n",
            "|    explained_variance   | 0.714       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.666       |\n",
            "|    n_updates            | 2900        |\n",
            "|    policy_gradient_loss | -0.00257    |\n",
            "|    reward               | 0.002161563 |\n",
            "|    std                  | 1.14        |\n",
            "|    value_loss           | 1.01        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 292         |\n",
            "|    time_elapsed         | 1623        |\n",
            "|    total_timesteps      | 598016      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012494469 |\n",
            "|    clip_fraction        | 0.0683      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.08       |\n",
            "|    explained_variance   | 0.661       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.481       |\n",
            "|    n_updates            | 2910        |\n",
            "|    policy_gradient_loss | 0.00158     |\n",
            "|    reward               | 0.15349054  |\n",
            "|    std                  | 1.14        |\n",
            "|    value_loss           | 1.04        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 293          |\n",
            "|    time_elapsed         | 1628         |\n",
            "|    total_timesteps      | 600064       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0067898873 |\n",
            "|    clip_fraction        | 0.0862       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.09        |\n",
            "|    explained_variance   | 0.51         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0861       |\n",
            "|    n_updates            | 2920         |\n",
            "|    policy_gradient_loss | -0.00352     |\n",
            "|    reward               | 0.04572566   |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 0.351        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 294          |\n",
            "|    time_elapsed         | 1634         |\n",
            "|    total_timesteps      | 602112       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0089320075 |\n",
            "|    clip_fraction        | 0.0609       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.09        |\n",
            "|    explained_variance   | 0.745        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.273        |\n",
            "|    n_updates            | 2930         |\n",
            "|    policy_gradient_loss | -0.00451     |\n",
            "|    reward               | 0.046117395  |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 0.71         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 295          |\n",
            "|    time_elapsed         | 1641         |\n",
            "|    total_timesteps      | 604160       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0093703605 |\n",
            "|    clip_fraction        | 0.0693       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.721        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.242        |\n",
            "|    n_updates            | 2940         |\n",
            "|    policy_gradient_loss | 0.00314      |\n",
            "|    reward               | 0.008538748  |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 0.952        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 367          |\n",
            "|    iterations           | 296          |\n",
            "|    time_elapsed         | 1647         |\n",
            "|    total_timesteps      | 606208       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0057576764 |\n",
            "|    clip_fraction        | 0.0308       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.64         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.402        |\n",
            "|    n_updates            | 2950         |\n",
            "|    policy_gradient_loss | -0.0033      |\n",
            "|    reward               | -0.20080397  |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 1.03         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 367          |\n",
            "|    iterations           | 297          |\n",
            "|    time_elapsed         | 1654         |\n",
            "|    total_timesteps      | 608256       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0101469    |\n",
            "|    clip_fraction        | 0.0668       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.661        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0639       |\n",
            "|    n_updates            | 2960         |\n",
            "|    policy_gradient_loss | -0.00205     |\n",
            "|    reward               | -0.043168847 |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 0.267        |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 220\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 421607.76\n",
            "total_reward: 411607.76\n",
            "total_cost: 367.12\n",
            "total_trades: 4064\n",
            "Sharpe: 0.906\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 367          |\n",
            "|    iterations           | 298          |\n",
            "|    time_elapsed         | 1661         |\n",
            "|    total_timesteps      | 610304       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.009421573  |\n",
            "|    clip_fraction        | 0.0556       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.1         |\n",
            "|    explained_variance   | 0.706        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.244        |\n",
            "|    n_updates            | 2970         |\n",
            "|    policy_gradient_loss | -0.00214     |\n",
            "|    reward               | -0.021286445 |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 0.719        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 367          |\n",
            "|    iterations           | 299          |\n",
            "|    time_elapsed         | 1668         |\n",
            "|    total_timesteps      | 612352       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050287116 |\n",
            "|    clip_fraction        | 0.0402       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.1         |\n",
            "|    explained_variance   | 0.704        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.449        |\n",
            "|    n_updates            | 2980         |\n",
            "|    policy_gradient_loss | -0.000623    |\n",
            "|    reward               | 0.7884206    |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 0.995        |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 366        |\n",
            "|    iterations           | 300        |\n",
            "|    time_elapsed         | 1674       |\n",
            "|    total_timesteps      | 614400     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00975332 |\n",
            "|    clip_fraction        | 0.0674     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.1       |\n",
            "|    explained_variance   | 0.638      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 0.347      |\n",
            "|    n_updates            | 2990       |\n",
            "|    policy_gradient_loss | -0.00388   |\n",
            "|    reward               | 0.27147055 |\n",
            "|    std                  | 1.15       |\n",
            "|    value_loss           | 0.881      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 301         |\n",
            "|    time_elapsed         | 1680        |\n",
            "|    total_timesteps      | 616448      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011226996 |\n",
            "|    clip_fraction        | 0.0959      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.1        |\n",
            "|    explained_variance   | 0.757       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.089       |\n",
            "|    n_updates            | 3000        |\n",
            "|    policy_gradient_loss | -0.00555    |\n",
            "|    reward               | 0.10543689  |\n",
            "|    std                  | 1.14        |\n",
            "|    value_loss           | 0.231       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 302         |\n",
            "|    time_elapsed         | 1685        |\n",
            "|    total_timesteps      | 618496      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009217313 |\n",
            "|    clip_fraction        | 0.0634      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.09       |\n",
            "|    explained_variance   | 0.597       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.566       |\n",
            "|    n_updates            | 3010        |\n",
            "|    policy_gradient_loss | -0.00492    |\n",
            "|    reward               | 0.03604339  |\n",
            "|    std                  | 1.14        |\n",
            "|    value_loss           | 1.1         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 367         |\n",
            "|    iterations           | 303         |\n",
            "|    time_elapsed         | 1690        |\n",
            "|    total_timesteps      | 620544      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019918576 |\n",
            "|    clip_fraction        | 0.0509      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.09       |\n",
            "|    explained_variance   | 0.551       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.492       |\n",
            "|    n_updates            | 3020        |\n",
            "|    policy_gradient_loss | -0.000894   |\n",
            "|    reward               | 0.016442945 |\n",
            "|    std                  | 1.14        |\n",
            "|    value_loss           | 1.05        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 367          |\n",
            "|    iterations           | 304          |\n",
            "|    time_elapsed         | 1696         |\n",
            "|    total_timesteps      | 622592       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.014380564  |\n",
            "|    clip_fraction        | 0.0704       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.09        |\n",
            "|    explained_variance   | 0.405        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.35         |\n",
            "|    n_updates            | 3030         |\n",
            "|    policy_gradient_loss | -0.00475     |\n",
            "|    reward               | -0.073252834 |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 0.853        |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 225\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 418443.03\n",
            "total_reward: 408443.03\n",
            "total_cost: 359.94\n",
            "total_trades: 4002\n",
            "Sharpe: 0.906\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 367        |\n",
            "|    iterations           | 305        |\n",
            "|    time_elapsed         | 1701       |\n",
            "|    total_timesteps      | 624640     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01803203 |\n",
            "|    clip_fraction        | 0.0835     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.08      |\n",
            "|    explained_variance   | 0.846      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 0.0881     |\n",
            "|    n_updates            | 3040       |\n",
            "|    policy_gradient_loss | 0.00332    |\n",
            "|    reward               | 0.12344973 |\n",
            "|    std                  | 1.14       |\n",
            "|    value_loss           | 0.263      |\n",
            "----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 367           |\n",
            "|    iterations           | 306           |\n",
            "|    time_elapsed         | 1707          |\n",
            "|    total_timesteps      | 626688        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.009451967   |\n",
            "|    clip_fraction        | 0.0416        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.08         |\n",
            "|    explained_variance   | 0.601         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.371         |\n",
            "|    n_updates            | 3050          |\n",
            "|    policy_gradient_loss | 0.00265       |\n",
            "|    reward               | -0.0035425234 |\n",
            "|    std                  | 1.14          |\n",
            "|    value_loss           | 1.18          |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 367         |\n",
            "|    iterations           | 307         |\n",
            "|    time_elapsed         | 1712        |\n",
            "|    total_timesteps      | 628736      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010429124 |\n",
            "|    clip_fraction        | 0.0567      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.08       |\n",
            "|    explained_variance   | 0.587       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.413       |\n",
            "|    n_updates            | 3060        |\n",
            "|    policy_gradient_loss | -0.00368    |\n",
            "|    reward               | -0.8559242  |\n",
            "|    std                  | 1.14        |\n",
            "|    value_loss           | 0.942       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 367         |\n",
            "|    iterations           | 308         |\n",
            "|    time_elapsed         | 1718        |\n",
            "|    total_timesteps      | 630784      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006121403 |\n",
            "|    clip_fraction        | 0.0435      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.08       |\n",
            "|    explained_variance   | 0.572       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.232       |\n",
            "|    n_updates            | 3070        |\n",
            "|    policy_gradient_loss | -0.000877   |\n",
            "|    reward               | 0.12134594  |\n",
            "|    std                  | 1.13        |\n",
            "|    value_loss           | 0.507       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 367         |\n",
            "|    iterations           | 309         |\n",
            "|    time_elapsed         | 1723        |\n",
            "|    total_timesteps      | 632832      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005795008 |\n",
            "|    clip_fraction        | 0.0411      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.08       |\n",
            "|    explained_variance   | 0.802       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.107       |\n",
            "|    n_updates            | 3080        |\n",
            "|    policy_gradient_loss | -0.00143    |\n",
            "|    reward               | 0.020588012 |\n",
            "|    std                  | 1.14        |\n",
            "|    value_loss           | 0.409       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 367          |\n",
            "|    iterations           | 310          |\n",
            "|    time_elapsed         | 1729         |\n",
            "|    total_timesteps      | 634880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0075124064 |\n",
            "|    clip_fraction        | 0.0348       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.09        |\n",
            "|    explained_variance   | 0.645        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.42         |\n",
            "|    n_updates            | 3090         |\n",
            "|    policy_gradient_loss | -0.000227    |\n",
            "|    reward               | 0.019535653  |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 0.914        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 367         |\n",
            "|    iterations           | 311         |\n",
            "|    time_elapsed         | 1735        |\n",
            "|    total_timesteps      | 636928      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008772474 |\n",
            "|    clip_fraction        | 0.0675      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.1        |\n",
            "|    explained_variance   | 0.574       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.32        |\n",
            "|    n_updates            | 3100        |\n",
            "|    policy_gradient_loss | -0.00433    |\n",
            "|    reward               | 0.7272979   |\n",
            "|    std                  | 1.15        |\n",
            "|    value_loss           | 0.916       |\n",
            "-----------------------------------------\n",
            "day: 2770, episode: 230\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 414982.80\n",
            "total_reward: 404982.80\n",
            "total_cost: 363.92\n",
            "total_trades: 4006\n",
            "Sharpe: 0.906\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 367          |\n",
            "|    iterations           | 312          |\n",
            "|    time_elapsed         | 1740         |\n",
            "|    total_timesteps      | 638976       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.01236642   |\n",
            "|    clip_fraction        | 0.0583       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.09        |\n",
            "|    explained_variance   | 0.632        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.184        |\n",
            "|    n_updates            | 3110         |\n",
            "|    policy_gradient_loss | -0.00247     |\n",
            "|    reward               | -0.117303856 |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 0.41         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 313         |\n",
            "|    time_elapsed         | 1746        |\n",
            "|    total_timesteps      | 641024      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.00524922  |\n",
            "|    clip_fraction        | 0.0375      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.08       |\n",
            "|    explained_variance   | 0.762       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.179       |\n",
            "|    n_updates            | 3120        |\n",
            "|    policy_gradient_loss | -0.000166   |\n",
            "|    reward               | 0.020145683 |\n",
            "|    std                  | 1.14        |\n",
            "|    value_loss           | 0.584       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 314         |\n",
            "|    time_elapsed         | 1752        |\n",
            "|    total_timesteps      | 643072      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009457117 |\n",
            "|    clip_fraction        | 0.0626      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.08       |\n",
            "|    explained_variance   | 0.681       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.377       |\n",
            "|    n_updates            | 3130        |\n",
            "|    policy_gradient_loss | 0.00159     |\n",
            "|    reward               | 0.003163669 |\n",
            "|    std                  | 1.14        |\n",
            "|    value_loss           | 0.939       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 367          |\n",
            "|    iterations           | 315          |\n",
            "|    time_elapsed         | 1757         |\n",
            "|    total_timesteps      | 645120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0063966326 |\n",
            "|    clip_fraction        | 0.0323       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.09        |\n",
            "|    explained_variance   | 0.593        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.341        |\n",
            "|    n_updates            | 3140         |\n",
            "|    policy_gradient_loss | 0.000944     |\n",
            "|    reward               | -0.04232282  |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 0.999        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 366          |\n",
            "|    iterations           | 316          |\n",
            "|    time_elapsed         | 1763         |\n",
            "|    total_timesteps      | 647168       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.019773614  |\n",
            "|    clip_fraction        | 0.0744       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.09        |\n",
            "|    explained_variance   | 0.685        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.112        |\n",
            "|    n_updates            | 3150         |\n",
            "|    policy_gradient_loss | -0.00331     |\n",
            "|    reward               | -0.075139984 |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 0.303        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 366           |\n",
            "|    iterations           | 317           |\n",
            "|    time_elapsed         | 1769          |\n",
            "|    total_timesteps      | 649216        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.009771367   |\n",
            "|    clip_fraction        | 0.0429        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.09         |\n",
            "|    explained_variance   | 0.718         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.194         |\n",
            "|    n_updates            | 3160          |\n",
            "|    policy_gradient_loss | -0.0024       |\n",
            "|    reward               | 0.00048741398 |\n",
            "|    std                  | 1.15          |\n",
            "|    value_loss           | 0.685         |\n",
            "-------------------------------------------\n",
            "day: 2770, episode: 235\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 312303.09\n",
            "total_reward: 302303.09\n",
            "total_cost: 379.51\n",
            "total_trades: 3980\n",
            "Sharpe: 0.890\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 366          |\n",
            "|    iterations           | 318          |\n",
            "|    time_elapsed         | 1774         |\n",
            "|    total_timesteps      | 651264       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.007661098  |\n",
            "|    clip_fraction        | 0.0543       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.1         |\n",
            "|    explained_variance   | 0.635        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.273        |\n",
            "|    n_updates            | 3170         |\n",
            "|    policy_gradient_loss | -0.0031      |\n",
            "|    reward               | -0.005079771 |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 0.709        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 319         |\n",
            "|    time_elapsed         | 1780        |\n",
            "|    total_timesteps      | 653312      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008459369 |\n",
            "|    clip_fraction        | 0.0671      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.1        |\n",
            "|    explained_variance   | 0.47        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.385       |\n",
            "|    n_updates            | 3180        |\n",
            "|    policy_gradient_loss | -0.000781   |\n",
            "|    reward               | -0.325264   |\n",
            "|    std                  | 1.15        |\n",
            "|    value_loss           | 0.915       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 320         |\n",
            "|    time_elapsed         | 1786        |\n",
            "|    total_timesteps      | 655360      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008450845 |\n",
            "|    clip_fraction        | 0.0839      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.12       |\n",
            "|    explained_variance   | 0.709       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.104       |\n",
            "|    n_updates            | 3190        |\n",
            "|    policy_gradient_loss | -0.00396    |\n",
            "|    reward               | 0.4288598   |\n",
            "|    std                  | 1.17        |\n",
            "|    value_loss           | 0.254       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 366          |\n",
            "|    iterations           | 321          |\n",
            "|    time_elapsed         | 1792         |\n",
            "|    total_timesteps      | 657408       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.013937715  |\n",
            "|    clip_fraction        | 0.0708       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.14        |\n",
            "|    explained_variance   | 0.633        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.218        |\n",
            "|    n_updates            | 3200         |\n",
            "|    policy_gradient_loss | 0.000131     |\n",
            "|    reward               | 0.0020095936 |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 0.568        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 322         |\n",
            "|    time_elapsed         | 1798        |\n",
            "|    total_timesteps      | 659456      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014027683 |\n",
            "|    clip_fraction        | 0.0775      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.15       |\n",
            "|    explained_variance   | 0.524       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.321       |\n",
            "|    n_updates            | 3210        |\n",
            "|    policy_gradient_loss | -0.00143    |\n",
            "|    reward               | -1.2344064  |\n",
            "|    std                  | 1.18        |\n",
            "|    value_loss           | 0.927       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 366          |\n",
            "|    iterations           | 323          |\n",
            "|    time_elapsed         | 1804         |\n",
            "|    total_timesteps      | 661504       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047823093 |\n",
            "|    clip_fraction        | 0.0454       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.15        |\n",
            "|    explained_variance   | 0.582        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.31         |\n",
            "|    n_updates            | 3220         |\n",
            "|    policy_gradient_loss | -0.00213     |\n",
            "|    reward               | 0.81284684   |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 0.78         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 366          |\n",
            "|    iterations           | 324          |\n",
            "|    time_elapsed         | 1809         |\n",
            "|    total_timesteps      | 663552       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059093433 |\n",
            "|    clip_fraction        | 0.0549       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.15        |\n",
            "|    explained_variance   | 0.78         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0785       |\n",
            "|    n_updates            | 3230         |\n",
            "|    policy_gradient_loss | -0.00173     |\n",
            "|    reward               | 0.5001183    |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 0.223        |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 240\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 399623.20\n",
            "total_reward: 389623.20\n",
            "total_cost: 349.83\n",
            "total_trades: 3868\n",
            "Sharpe: 0.905\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 325         |\n",
            "|    time_elapsed         | 1815        |\n",
            "|    total_timesteps      | 665600      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004431489 |\n",
            "|    clip_fraction        | 0.0317      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.15       |\n",
            "|    explained_variance   | 0.723       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.298       |\n",
            "|    n_updates            | 3240        |\n",
            "|    policy_gradient_loss | -0.00231    |\n",
            "|    reward               | 0.043704953 |\n",
            "|    std                  | 1.18        |\n",
            "|    value_loss           | 0.624       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 326         |\n",
            "|    time_elapsed         | 1820        |\n",
            "|    total_timesteps      | 667648      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010748692 |\n",
            "|    clip_fraction        | 0.0393      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.15       |\n",
            "|    explained_variance   | 0.701       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.333       |\n",
            "|    n_updates            | 3250        |\n",
            "|    policy_gradient_loss | 0.00219     |\n",
            "|    reward               | -0.26945218 |\n",
            "|    std                  | 1.18        |\n",
            "|    value_loss           | 0.817       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 327         |\n",
            "|    time_elapsed         | 1826        |\n",
            "|    total_timesteps      | 669696      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008733241 |\n",
            "|    clip_fraction        | 0.0556      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.15       |\n",
            "|    explained_variance   | 0.58        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.237       |\n",
            "|    n_updates            | 3260        |\n",
            "|    policy_gradient_loss | 0.000484    |\n",
            "|    reward               | 0.26726812  |\n",
            "|    std                  | 1.18        |\n",
            "|    value_loss           | 0.659       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 366          |\n",
            "|    iterations           | 328          |\n",
            "|    time_elapsed         | 1832         |\n",
            "|    total_timesteps      | 671744       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004237084  |\n",
            "|    clip_fraction        | 0.0537       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.16        |\n",
            "|    explained_variance   | 0.854        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.137        |\n",
            "|    n_updates            | 3270         |\n",
            "|    policy_gradient_loss | 0.000378     |\n",
            "|    reward               | 0.0020508096 |\n",
            "|    std                  | 1.2          |\n",
            "|    value_loss           | 0.243        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 366          |\n",
            "|    iterations           | 329          |\n",
            "|    time_elapsed         | 1838         |\n",
            "|    total_timesteps      | 673792       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.007805074  |\n",
            "|    clip_fraction        | 0.0338       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.18        |\n",
            "|    explained_variance   | 0.747        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.307        |\n",
            "|    n_updates            | 3280         |\n",
            "|    policy_gradient_loss | 0.000437     |\n",
            "|    reward               | 0.0023469173 |\n",
            "|    std                  | 1.2          |\n",
            "|    value_loss           | 0.672        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 330         |\n",
            "|    time_elapsed         | 1843        |\n",
            "|    total_timesteps      | 675840      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010297356 |\n",
            "|    clip_fraction        | 0.0633      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.18       |\n",
            "|    explained_variance   | 0.526       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.211       |\n",
            "|    n_updates            | 3290        |\n",
            "|    policy_gradient_loss | -0.00251    |\n",
            "|    reward               | 0.47360528  |\n",
            "|    std                  | 1.2         |\n",
            "|    value_loss           | 0.657       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 331         |\n",
            "|    time_elapsed         | 1849        |\n",
            "|    total_timesteps      | 677888      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024472265 |\n",
            "|    clip_fraction        | 0.0758      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.18       |\n",
            "|    explained_variance   | 0.573       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.268       |\n",
            "|    n_updates            | 3300        |\n",
            "|    policy_gradient_loss | 0.00166     |\n",
            "|    reward               | 0.09466693  |\n",
            "|    std                  | 1.2         |\n",
            "|    value_loss           | 0.432       |\n",
            "-----------------------------------------\n",
            "day: 2770, episode: 245\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 395794.89\n",
            "total_reward: 385794.89\n",
            "total_cost: 366.02\n",
            "total_trades: 3908\n",
            "Sharpe: 0.904\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 332         |\n",
            "|    time_elapsed         | 1855        |\n",
            "|    total_timesteps      | 679936      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.00463299  |\n",
            "|    clip_fraction        | 0.0333      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.18       |\n",
            "|    explained_variance   | 0.773       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.256       |\n",
            "|    n_updates            | 3310        |\n",
            "|    policy_gradient_loss | -0.0018     |\n",
            "|    reward               | 0.016378466 |\n",
            "|    std                  | 1.19        |\n",
            "|    value_loss           | 0.431       |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 366           |\n",
            "|    iterations           | 333           |\n",
            "|    time_elapsed         | 1860          |\n",
            "|    total_timesteps      | 681984        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.010367053   |\n",
            "|    clip_fraction        | 0.0426        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.17         |\n",
            "|    explained_variance   | 0.652         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.318         |\n",
            "|    n_updates            | 3320          |\n",
            "|    policy_gradient_loss | -0.00267      |\n",
            "|    reward               | -0.0018326594 |\n",
            "|    std                  | 1.19          |\n",
            "|    value_loss           | 0.784         |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 334         |\n",
            "|    time_elapsed         | 1866        |\n",
            "|    total_timesteps      | 684032      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006124734 |\n",
            "|    clip_fraction        | 0.0374      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.18       |\n",
            "|    explained_variance   | 0.603       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.391       |\n",
            "|    n_updates            | 3330        |\n",
            "|    policy_gradient_loss | -0.00119    |\n",
            "|    reward               | 0.5308415   |\n",
            "|    std                  | 1.2         |\n",
            "|    value_loss           | 0.93        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 335         |\n",
            "|    time_elapsed         | 1872        |\n",
            "|    total_timesteps      | 686080      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009270113 |\n",
            "|    clip_fraction        | 0.0771      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.19       |\n",
            "|    explained_variance   | 0.661       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.164       |\n",
            "|    n_updates            | 3340        |\n",
            "|    policy_gradient_loss | -0.00338    |\n",
            "|    reward               | 0.014970075 |\n",
            "|    std                  | 1.21        |\n",
            "|    value_loss           | 0.369       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 336         |\n",
            "|    time_elapsed         | 1878        |\n",
            "|    total_timesteps      | 688128      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007901014 |\n",
            "|    clip_fraction        | 0.0611      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.19       |\n",
            "|    explained_variance   | 0.666       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.16        |\n",
            "|    n_updates            | 3350        |\n",
            "|    policy_gradient_loss | -0.00404    |\n",
            "|    reward               | 0.07167538  |\n",
            "|    std                  | 1.2         |\n",
            "|    value_loss           | 0.671       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 366          |\n",
            "|    iterations           | 337          |\n",
            "|    time_elapsed         | 1884         |\n",
            "|    total_timesteps      | 690176       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.011570469  |\n",
            "|    clip_fraction        | 0.0593       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.19        |\n",
            "|    explained_variance   | 0.644        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.335        |\n",
            "|    n_updates            | 3360         |\n",
            "|    policy_gradient_loss | -0.00281     |\n",
            "|    reward               | -0.010102965 |\n",
            "|    std                  | 1.2          |\n",
            "|    value_loss           | 0.815        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 338         |\n",
            "|    time_elapsed         | 1889        |\n",
            "|    total_timesteps      | 692224      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009859124 |\n",
            "|    clip_fraction        | 0.0622      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.19       |\n",
            "|    explained_variance   | 0.612       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.36        |\n",
            "|    n_updates            | 3370        |\n",
            "|    policy_gradient_loss | -0.00488    |\n",
            "|    reward               | 0.268701    |\n",
            "|    std                  | 1.21        |\n",
            "|    value_loss           | 0.754       |\n",
            "-----------------------------------------\n",
            "day: 2770, episode: 250\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 374823.89\n",
            "total_reward: 364823.89\n",
            "total_cost: 361.20\n",
            "total_trades: 3766\n",
            "Sharpe: 0.901\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 366          |\n",
            "|    iterations           | 339          |\n",
            "|    time_elapsed         | 1895         |\n",
            "|    total_timesteps      | 694272       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0073357294 |\n",
            "|    clip_fraction        | 0.0596       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.19        |\n",
            "|    explained_variance   | 0.754        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.103        |\n",
            "|    n_updates            | 3380         |\n",
            "|    policy_gradient_loss | -0.0014      |\n",
            "|    reward               | -0.46855006  |\n",
            "|    std                  | 1.2          |\n",
            "|    value_loss           | 0.235        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 340         |\n",
            "|    time_elapsed         | 1902        |\n",
            "|    total_timesteps      | 696320      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008545938 |\n",
            "|    clip_fraction        | 0.0577      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.18       |\n",
            "|    explained_variance   | 0.733       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.247       |\n",
            "|    n_updates            | 3390        |\n",
            "|    policy_gradient_loss | -0.00631    |\n",
            "|    reward               | 0.008321985 |\n",
            "|    std                  | 1.19        |\n",
            "|    value_loss           | 0.49        |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 365           |\n",
            "|    iterations           | 341           |\n",
            "|    time_elapsed         | 1908          |\n",
            "|    total_timesteps      | 698368        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0061546746  |\n",
            "|    clip_fraction        | 0.0455        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.18         |\n",
            "|    explained_variance   | 0.737         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.202         |\n",
            "|    n_updates            | 3400          |\n",
            "|    policy_gradient_loss | -0.00241      |\n",
            "|    reward               | -0.0018442714 |\n",
            "|    std                  | 1.19          |\n",
            "|    value_loss           | 0.623         |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 342         |\n",
            "|    time_elapsed         | 1913        |\n",
            "|    total_timesteps      | 700416      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011660658 |\n",
            "|    clip_fraction        | 0.0708      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.17       |\n",
            "|    explained_variance   | 0.659       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.199       |\n",
            "|    n_updates            | 3410        |\n",
            "|    policy_gradient_loss | -0.00347    |\n",
            "|    reward               | 1.7053416   |\n",
            "|    std                  | 1.19        |\n",
            "|    value_loss           | 0.684       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 343         |\n",
            "|    time_elapsed         | 1919        |\n",
            "|    total_timesteps      | 702464      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011610586 |\n",
            "|    clip_fraction        | 0.061       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.17       |\n",
            "|    explained_variance   | 0.776       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.052       |\n",
            "|    n_updates            | 3420        |\n",
            "|    policy_gradient_loss | -0.000988   |\n",
            "|    reward               | 0.26284623  |\n",
            "|    std                  | 1.19        |\n",
            "|    value_loss           | 0.208       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 344         |\n",
            "|    time_elapsed         | 1924        |\n",
            "|    total_timesteps      | 704512      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007789082 |\n",
            "|    clip_fraction        | 0.0497      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.16       |\n",
            "|    explained_variance   | 0.717       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.309       |\n",
            "|    n_updates            | 3430        |\n",
            "|    policy_gradient_loss | -0.00429    |\n",
            "|    reward               | -0.02618225 |\n",
            "|    std                  | 1.18        |\n",
            "|    value_loss           | 0.595       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 345         |\n",
            "|    time_elapsed         | 1930        |\n",
            "|    total_timesteps      | 706560      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010076754 |\n",
            "|    clip_fraction        | 0.0599      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.16       |\n",
            "|    explained_variance   | 0.686       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.186       |\n",
            "|    n_updates            | 3440        |\n",
            "|    policy_gradient_loss | -0.000798   |\n",
            "|    reward               | 0.043374497 |\n",
            "|    std                  | 1.19        |\n",
            "|    value_loss           | 0.689       |\n",
            "-----------------------------------------\n",
            "day: 2770, episode: 255\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 381222.66\n",
            "total_reward: 371222.66\n",
            "total_cost: 336.83\n",
            "total_trades: 3684\n",
            "Sharpe: 0.904\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 346         |\n",
            "|    time_elapsed         | 1936        |\n",
            "|    total_timesteps      | 708608      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021324456 |\n",
            "|    clip_fraction        | 0.0931      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.17       |\n",
            "|    explained_variance   | 0.721       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.25        |\n",
            "|    n_updates            | 3450        |\n",
            "|    policy_gradient_loss | -0.00136    |\n",
            "|    reward               | -1.2296393  |\n",
            "|    std                  | 1.19        |\n",
            "|    value_loss           | 0.636       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 347         |\n",
            "|    time_elapsed         | 1942        |\n",
            "|    total_timesteps      | 710656      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007001411 |\n",
            "|    clip_fraction        | 0.0386      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.18       |\n",
            "|    explained_variance   | 0.866       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0133      |\n",
            "|    n_updates            | 3460        |\n",
            "|    policy_gradient_loss | -0.00133    |\n",
            "|    reward               | -0.1526176  |\n",
            "|    std                  | 1.2         |\n",
            "|    value_loss           | 0.14        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 348          |\n",
            "|    time_elapsed         | 1947         |\n",
            "|    total_timesteps      | 712704       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006380002  |\n",
            "|    clip_fraction        | 0.0276       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.18        |\n",
            "|    explained_variance   | 0.761        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.205        |\n",
            "|    n_updates            | 3470         |\n",
            "|    policy_gradient_loss | -0.00185     |\n",
            "|    reward               | 0.0010687764 |\n",
            "|    std                  | 1.2          |\n",
            "|    value_loss           | 0.485        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 349         |\n",
            "|    time_elapsed         | 1953        |\n",
            "|    total_timesteps      | 714752      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007343866 |\n",
            "|    clip_fraction        | 0.0437      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.18       |\n",
            "|    explained_variance   | 0.625       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.387       |\n",
            "|    n_updates            | 3480        |\n",
            "|    policy_gradient_loss | -0.00402    |\n",
            "|    reward               | 0.015600679 |\n",
            "|    std                  | 1.2         |\n",
            "|    value_loss           | 0.769       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 350         |\n",
            "|    time_elapsed         | 1959        |\n",
            "|    total_timesteps      | 716800      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008574297 |\n",
            "|    clip_fraction        | 0.0788      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.18       |\n",
            "|    explained_variance   | 0.585       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.181       |\n",
            "|    n_updates            | 3490        |\n",
            "|    policy_gradient_loss | -0.00334    |\n",
            "|    reward               | -0.22903407 |\n",
            "|    std                  | 1.2         |\n",
            "|    value_loss           | 0.619       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 351          |\n",
            "|    time_elapsed         | 1964         |\n",
            "|    total_timesteps      | 718848       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0129710995 |\n",
            "|    clip_fraction        | 0.0902       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.19        |\n",
            "|    explained_variance   | 0.908        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0364       |\n",
            "|    n_updates            | 3500         |\n",
            "|    policy_gradient_loss | -0.00174     |\n",
            "|    reward               | -0.060050815 |\n",
            "|    std                  | 1.21         |\n",
            "|    value_loss           | 0.168        |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 260\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 389234.13\n",
            "total_reward: 379234.13\n",
            "total_cost: 365.31\n",
            "total_trades: 3868\n",
            "Sharpe: 0.905\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 352          |\n",
            "|    time_elapsed         | 1970         |\n",
            "|    total_timesteps      | 720896       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.01010482   |\n",
            "|    clip_fraction        | 0.0508       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.19        |\n",
            "|    explained_variance   | 0.785        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.172        |\n",
            "|    n_updates            | 3510         |\n",
            "|    policy_gradient_loss | -0.00155     |\n",
            "|    reward               | -0.010701608 |\n",
            "|    std                  | 1.2          |\n",
            "|    value_loss           | 0.53         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 353          |\n",
            "|    time_elapsed         | 1975         |\n",
            "|    total_timesteps      | 722944       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.010571832  |\n",
            "|    clip_fraction        | 0.0591       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.18        |\n",
            "|    explained_variance   | 0.711        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.303        |\n",
            "|    n_updates            | 3520         |\n",
            "|    policy_gradient_loss | -0.00325     |\n",
            "|    reward               | -0.076551236 |\n",
            "|    std                  | 1.2          |\n",
            "|    value_loss           | 0.674        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 354         |\n",
            "|    time_elapsed         | 1981        |\n",
            "|    total_timesteps      | 724992      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012140015 |\n",
            "|    clip_fraction        | 0.0781      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.18       |\n",
            "|    explained_variance   | 0.612       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0925      |\n",
            "|    n_updates            | 3530        |\n",
            "|    policy_gradient_loss | -0.00377    |\n",
            "|    reward               | -0.14810994 |\n",
            "|    std                  | 1.2         |\n",
            "|    value_loss           | 0.359       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 355          |\n",
            "|    time_elapsed         | 1986         |\n",
            "|    total_timesteps      | 727040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.01622444   |\n",
            "|    clip_fraction        | 0.0818       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.18        |\n",
            "|    explained_variance   | 0.807        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0939       |\n",
            "|    n_updates            | 3540         |\n",
            "|    policy_gradient_loss | -0.000576    |\n",
            "|    reward               | 0.0014898607 |\n",
            "|    std                  | 1.2          |\n",
            "|    value_loss           | 0.381        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 365           |\n",
            "|    iterations           | 356           |\n",
            "|    time_elapsed         | 1992          |\n",
            "|    total_timesteps      | 729088        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.010407469   |\n",
            "|    clip_fraction        | 0.0622        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.19         |\n",
            "|    explained_variance   | 0.683         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.279         |\n",
            "|    n_updates            | 3550          |\n",
            "|    policy_gradient_loss | -0.00147      |\n",
            "|    reward               | -0.0079112165 |\n",
            "|    std                  | 1.21          |\n",
            "|    value_loss           | 0.796         |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 357         |\n",
            "|    time_elapsed         | 1997        |\n",
            "|    total_timesteps      | 731136      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008793237 |\n",
            "|    clip_fraction        | 0.083       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.19       |\n",
            "|    explained_variance   | 0.647       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.492       |\n",
            "|    n_updates            | 3560        |\n",
            "|    policy_gradient_loss | -0.00422    |\n",
            "|    reward               | 0.6102872   |\n",
            "|    std                  | 1.21        |\n",
            "|    value_loss           | 0.843       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 358         |\n",
            "|    time_elapsed         | 2003        |\n",
            "|    total_timesteps      | 733184      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011994822 |\n",
            "|    clip_fraction        | 0.0472      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.19       |\n",
            "|    explained_variance   | 0.764       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.00317    |\n",
            "|    n_updates            | 3570        |\n",
            "|    policy_gradient_loss | 0.000483    |\n",
            "|    reward               | 0.38437778  |\n",
            "|    std                  | 1.2         |\n",
            "|    value_loss           | 0.271       |\n",
            "-----------------------------------------\n",
            "day: 2770, episode: 265\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 380156.53\n",
            "total_reward: 370156.53\n",
            "total_cost: 355.86\n",
            "total_trades: 3784\n",
            "Sharpe: 0.901\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 359          |\n",
            "|    time_elapsed         | 2009         |\n",
            "|    total_timesteps      | 735232       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006348121  |\n",
            "|    clip_fraction        | 0.0589       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.19        |\n",
            "|    explained_variance   | 0.783        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.142        |\n",
            "|    n_updates            | 3580         |\n",
            "|    policy_gradient_loss | 0.000796     |\n",
            "|    reward               | 0.0024467197 |\n",
            "|    std                  | 1.21         |\n",
            "|    value_loss           | 0.484        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 360         |\n",
            "|    time_elapsed         | 2014        |\n",
            "|    total_timesteps      | 737280      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011251762 |\n",
            "|    clip_fraction        | 0.0758      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.2        |\n",
            "|    explained_variance   | 0.761       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.258       |\n",
            "|    n_updates            | 3590        |\n",
            "|    policy_gradient_loss | -0.00336    |\n",
            "|    reward               | 0.005087229 |\n",
            "|    std                  | 1.21        |\n",
            "|    value_loss           | 0.638       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 361         |\n",
            "|    time_elapsed         | 2020        |\n",
            "|    total_timesteps      | 739328      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016821649 |\n",
            "|    clip_fraction        | 0.0514      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.2        |\n",
            "|    explained_variance   | 0.737       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.36        |\n",
            "|    n_updates            | 3600        |\n",
            "|    policy_gradient_loss | -0.000287   |\n",
            "|    reward               | 0.39811963  |\n",
            "|    std                  | 1.21        |\n",
            "|    value_loss           | 0.685       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 362          |\n",
            "|    time_elapsed         | 2026         |\n",
            "|    total_timesteps      | 741376       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061674584 |\n",
            "|    clip_fraction        | 0.0608       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.19        |\n",
            "|    explained_variance   | 0.816        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0842       |\n",
            "|    n_updates            | 3610         |\n",
            "|    policy_gradient_loss | -0.000581    |\n",
            "|    reward               | -0.07507416  |\n",
            "|    std                  | 1.21         |\n",
            "|    value_loss           | 0.19         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 363         |\n",
            "|    time_elapsed         | 2031        |\n",
            "|    total_timesteps      | 743424      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006842224 |\n",
            "|    clip_fraction        | 0.0354      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.19       |\n",
            "|    explained_variance   | 0.826       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.368       |\n",
            "|    n_updates            | 3620        |\n",
            "|    policy_gradient_loss | -0.00193    |\n",
            "|    reward               | 0.026960392 |\n",
            "|    std                  | 1.21        |\n",
            "|    value_loss           | 0.482       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 364         |\n",
            "|    time_elapsed         | 2037        |\n",
            "|    total_timesteps      | 745472      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010956211 |\n",
            "|    clip_fraction        | 0.0663      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.2        |\n",
            "|    explained_variance   | 0.821       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.33        |\n",
            "|    n_updates            | 3630        |\n",
            "|    policy_gradient_loss | 0.000835    |\n",
            "|    reward               | 0.016726403 |\n",
            "|    std                  | 1.21        |\n",
            "|    value_loss           | 0.582       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 365         |\n",
            "|    time_elapsed         | 2042        |\n",
            "|    total_timesteps      | 747520      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011813701 |\n",
            "|    clip_fraction        | 0.116       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.2        |\n",
            "|    explained_variance   | 0.649       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.127       |\n",
            "|    n_updates            | 3640        |\n",
            "|    policy_gradient_loss | -0.00406    |\n",
            "|    reward               | 0.07607501  |\n",
            "|    std                  | 1.21        |\n",
            "|    value_loss           | 0.417       |\n",
            "-----------------------------------------\n",
            "day: 2770, episode: 270\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 372040.22\n",
            "total_reward: 362040.22\n",
            "total_cost: 339.15\n",
            "total_trades: 3674\n",
            "Sharpe: 0.882\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 366         |\n",
            "|    time_elapsed         | 2048        |\n",
            "|    total_timesteps      | 749568      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014209371 |\n",
            "|    clip_fraction        | 0.0793      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.21       |\n",
            "|    explained_variance   | 0.762       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0131      |\n",
            "|    n_updates            | 3650        |\n",
            "|    policy_gradient_loss | -0.00273    |\n",
            "|    reward               | 0.072216496 |\n",
            "|    std                  | 1.22        |\n",
            "|    value_loss           | 0.152       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 367          |\n",
            "|    time_elapsed         | 2054         |\n",
            "|    total_timesteps      | 751616       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.007623802  |\n",
            "|    clip_fraction        | 0.0541       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.21        |\n",
            "|    explained_variance   | 0.71         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.144        |\n",
            "|    n_updates            | 3660         |\n",
            "|    policy_gradient_loss | -0.00226     |\n",
            "|    reward               | -0.040269587 |\n",
            "|    std                  | 1.22         |\n",
            "|    value_loss           | 0.538        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 368         |\n",
            "|    time_elapsed         | 2059        |\n",
            "|    total_timesteps      | 753664      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015108865 |\n",
            "|    clip_fraction        | 0.0729      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.21       |\n",
            "|    explained_variance   | 0.653       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.333       |\n",
            "|    n_updates            | 3670        |\n",
            "|    policy_gradient_loss | 0.00042     |\n",
            "|    reward               | 0.09754679  |\n",
            "|    std                  | 1.23        |\n",
            "|    value_loss           | 0.787       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 369         |\n",
            "|    time_elapsed         | 2065        |\n",
            "|    total_timesteps      | 755712      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014363176 |\n",
            "|    clip_fraction        | 0.0747      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.23       |\n",
            "|    explained_variance   | 0.564       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.246       |\n",
            "|    n_updates            | 3680        |\n",
            "|    policy_gradient_loss | -0.00274    |\n",
            "|    reward               | -0.15355323 |\n",
            "|    std                  | 1.23        |\n",
            "|    value_loss           | 0.73        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 370          |\n",
            "|    time_elapsed         | 2071         |\n",
            "|    total_timesteps      | 757760       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.010214575  |\n",
            "|    clip_fraction        | 0.0603       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.23        |\n",
            "|    explained_variance   | 0.83         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0046      |\n",
            "|    n_updates            | 3690         |\n",
            "|    policy_gradient_loss | -0.00489     |\n",
            "|    reward               | -0.011377113 |\n",
            "|    std                  | 1.23         |\n",
            "|    value_loss           | 0.129        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 371         |\n",
            "|    time_elapsed         | 2076        |\n",
            "|    total_timesteps      | 759808      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011408374 |\n",
            "|    clip_fraction        | 0.063       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.24       |\n",
            "|    explained_variance   | 0.691       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.212       |\n",
            "|    n_updates            | 3700        |\n",
            "|    policy_gradient_loss | -0.00455    |\n",
            "|    reward               | 0.004770602 |\n",
            "|    std                  | 1.23        |\n",
            "|    value_loss           | 0.543       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 372         |\n",
            "|    time_elapsed         | 2082        |\n",
            "|    total_timesteps      | 761856      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.028834589 |\n",
            "|    clip_fraction        | 0.0767      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.24       |\n",
            "|    explained_variance   | 0.739       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.359       |\n",
            "|    n_updates            | 3710        |\n",
            "|    policy_gradient_loss | -0.00247    |\n",
            "|    reward               | 0.13059904  |\n",
            "|    std                  | 1.23        |\n",
            "|    value_loss           | 0.694       |\n",
            "-----------------------------------------\n",
            "day: 2770, episode: 275\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 383792.34\n",
            "total_reward: 373792.34\n",
            "total_cost: 378.89\n",
            "total_trades: 3924\n",
            "Sharpe: 0.901\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 373          |\n",
            "|    time_elapsed         | 2087         |\n",
            "|    total_timesteps      | 763904       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0083065145 |\n",
            "|    clip_fraction        | 0.051        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.24        |\n",
            "|    explained_variance   | 0.585        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.237        |\n",
            "|    n_updates            | 3720         |\n",
            "|    policy_gradient_loss | -0.00566     |\n",
            "|    reward               | 0.013586829  |\n",
            "|    std                  | 1.23         |\n",
            "|    value_loss           | 0.572        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 374         |\n",
            "|    time_elapsed         | 2093        |\n",
            "|    total_timesteps      | 765952      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012704115 |\n",
            "|    clip_fraction        | 0.108       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.24       |\n",
            "|    explained_variance   | 0.905       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0221      |\n",
            "|    n_updates            | 3730        |\n",
            "|    policy_gradient_loss | -0.000768   |\n",
            "|    reward               | -0.13335502 |\n",
            "|    std                  | 1.24        |\n",
            "|    value_loss           | 0.165       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 375          |\n",
            "|    time_elapsed         | 2099         |\n",
            "|    total_timesteps      | 768000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.023014236  |\n",
            "|    clip_fraction        | 0.11         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.25        |\n",
            "|    explained_variance   | 0.789        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.329        |\n",
            "|    n_updates            | 3740         |\n",
            "|    policy_gradient_loss | -0.00366     |\n",
            "|    reward               | 0.0044436706 |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 0.597        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 376         |\n",
            "|    time_elapsed         | 2104        |\n",
            "|    total_timesteps      | 770048      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013266218 |\n",
            "|    clip_fraction        | 0.0711      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.24       |\n",
            "|    explained_variance   | 0.759       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.41        |\n",
            "|    n_updates            | 3750        |\n",
            "|    policy_gradient_loss | 0.0034      |\n",
            "|    reward               | -0.2844359  |\n",
            "|    std                  | 1.23        |\n",
            "|    value_loss           | 0.649       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 377          |\n",
            "|    time_elapsed         | 2110         |\n",
            "|    total_timesteps      | 772096       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0136392675 |\n",
            "|    clip_fraction        | 0.0701       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.24        |\n",
            "|    explained_variance   | 0.676        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.177        |\n",
            "|    n_updates            | 3760         |\n",
            "|    policy_gradient_loss | -0.00203     |\n",
            "|    reward               | -0.012947383 |\n",
            "|    std                  | 1.23         |\n",
            "|    value_loss           | 0.345        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 378          |\n",
            "|    time_elapsed         | 2116         |\n",
            "|    total_timesteps      | 774144       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006479741  |\n",
            "|    clip_fraction        | 0.0706       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.24        |\n",
            "|    explained_variance   | 0.853        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0937       |\n",
            "|    n_updates            | 3770         |\n",
            "|    policy_gradient_loss | -0.00398     |\n",
            "|    reward               | -0.057122804 |\n",
            "|    std                  | 1.23         |\n",
            "|    value_loss           | 0.334        |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 280\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 395049.90\n",
            "total_reward: 385049.90\n",
            "total_cost: 355.00\n",
            "total_trades: 3860\n",
            "Sharpe: 0.903\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 379          |\n",
            "|    time_elapsed         | 2121         |\n",
            "|    total_timesteps      | 776192       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.013548942  |\n",
            "|    clip_fraction        | 0.0681       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.24        |\n",
            "|    explained_variance   | 0.809        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.178        |\n",
            "|    n_updates            | 3780         |\n",
            "|    policy_gradient_loss | 0.0039       |\n",
            "|    reward               | -0.011215305 |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 0.618        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 380         |\n",
            "|    time_elapsed         | 2127        |\n",
            "|    total_timesteps      | 778240      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013196951 |\n",
            "|    clip_fraction        | 0.105       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.25       |\n",
            "|    explained_variance   | 0.788       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.227       |\n",
            "|    n_updates            | 3790        |\n",
            "|    policy_gradient_loss | -0.00303    |\n",
            "|    reward               | 0.3609796   |\n",
            "|    std                  | 1.24        |\n",
            "|    value_loss           | 0.675       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 381         |\n",
            "|    time_elapsed         | 2133        |\n",
            "|    total_timesteps      | 780288      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019611683 |\n",
            "|    clip_fraction        | 0.0774      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.26       |\n",
            "|    explained_variance   | 0.734       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0914      |\n",
            "|    n_updates            | 3800        |\n",
            "|    policy_gradient_loss | 0.000296    |\n",
            "|    reward               | -0.09826285 |\n",
            "|    std                  | 1.25        |\n",
            "|    value_loss           | 0.284       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 382         |\n",
            "|    time_elapsed         | 2139        |\n",
            "|    total_timesteps      | 782336      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006158492 |\n",
            "|    clip_fraction        | 0.0521      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.27       |\n",
            "|    explained_variance   | 0.85        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.133       |\n",
            "|    n_updates            | 3810        |\n",
            "|    policy_gradient_loss | 0.00123     |\n",
            "|    reward               | -0.17508449 |\n",
            "|    std                  | 1.25        |\n",
            "|    value_loss           | 0.464       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 383          |\n",
            "|    time_elapsed         | 2145         |\n",
            "|    total_timesteps      | 784384       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006714704  |\n",
            "|    clip_fraction        | 0.0498       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.27        |\n",
            "|    explained_variance   | 0.775        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.333        |\n",
            "|    n_updates            | 3820         |\n",
            "|    policy_gradient_loss | -0.000476    |\n",
            "|    reward               | -0.017103331 |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.721        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 384          |\n",
            "|    time_elapsed         | 2151         |\n",
            "|    total_timesteps      | 786432       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0076477183 |\n",
            "|    clip_fraction        | 0.0676       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.27        |\n",
            "|    explained_variance   | 0.766        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.408        |\n",
            "|    n_updates            | 3830         |\n",
            "|    policy_gradient_loss | -0.00112     |\n",
            "|    reward               | 0.0933727    |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.677        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 385          |\n",
            "|    time_elapsed         | 2157         |\n",
            "|    total_timesteps      | 788480       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0104936045 |\n",
            "|    clip_fraction        | 0.0706       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.27        |\n",
            "|    explained_variance   | 0.695        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0697       |\n",
            "|    n_updates            | 3840         |\n",
            "|    policy_gradient_loss | -0.00194     |\n",
            "|    reward               | -0.035593443 |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.256        |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 285\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 386891.14\n",
            "total_reward: 376891.14\n",
            "total_cost: 368.46\n",
            "total_trades: 3900\n",
            "Sharpe: 0.898\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 386          |\n",
            "|    time_elapsed         | 2163         |\n",
            "|    total_timesteps      | 790528       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.009424826  |\n",
            "|    clip_fraction        | 0.0507       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.27        |\n",
            "|    explained_variance   | 0.808        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.184        |\n",
            "|    n_updates            | 3850         |\n",
            "|    policy_gradient_loss | -0.000998    |\n",
            "|    reward               | -0.029263807 |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.452        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 387          |\n",
            "|    time_elapsed         | 2169         |\n",
            "|    total_timesteps      | 792576       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.009031507  |\n",
            "|    clip_fraction        | 0.0617       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.27        |\n",
            "|    explained_variance   | 0.834        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.175        |\n",
            "|    n_updates            | 3860         |\n",
            "|    policy_gradient_loss | 0.00158      |\n",
            "|    reward               | -0.005346255 |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.586        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 388         |\n",
            "|    time_elapsed         | 2175        |\n",
            "|    total_timesteps      | 794624      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010409373 |\n",
            "|    clip_fraction        | 0.0489      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.27       |\n",
            "|    explained_variance   | 0.703       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.46        |\n",
            "|    n_updates            | 3870        |\n",
            "|    policy_gradient_loss | -0.00215    |\n",
            "|    reward               | 0.016493944 |\n",
            "|    std                  | 1.25        |\n",
            "|    value_loss           | 0.881       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 389         |\n",
            "|    time_elapsed         | 2181        |\n",
            "|    total_timesteps      | 796672      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016565686 |\n",
            "|    clip_fraction        | 0.0664      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.27       |\n",
            "|    explained_variance   | 0.759       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0791      |\n",
            "|    n_updates            | 3880        |\n",
            "|    policy_gradient_loss | 0.00182     |\n",
            "|    reward               | 0.36250252  |\n",
            "|    std                  | 1.25        |\n",
            "|    value_loss           | 0.194       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 390          |\n",
            "|    time_elapsed         | 2186         |\n",
            "|    total_timesteps      | 798720       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.013695395  |\n",
            "|    clip_fraction        | 0.06         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.27        |\n",
            "|    explained_variance   | 0.755        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.234        |\n",
            "|    n_updates            | 3890         |\n",
            "|    policy_gradient_loss | 0.00227      |\n",
            "|    reward               | 0.0024004166 |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.531        |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 365        |\n",
            "|    iterations           | 391        |\n",
            "|    time_elapsed         | 2192       |\n",
            "|    total_timesteps      | 800768     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.0175435  |\n",
            "|    clip_fraction        | 0.0842     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.27      |\n",
            "|    explained_variance   | 0.814      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 0.302      |\n",
            "|    n_updates            | 3900       |\n",
            "|    policy_gradient_loss | -0.0018    |\n",
            "|    reward               | 0.72420293 |\n",
            "|    std                  | 1.25       |\n",
            "|    value_loss           | 0.727      |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 392          |\n",
            "|    time_elapsed         | 2198         |\n",
            "|    total_timesteps      | 802816       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.016938597  |\n",
            "|    clip_fraction        | 0.0523       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | 0.721        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.264        |\n",
            "|    n_updates            | 3910         |\n",
            "|    policy_gradient_loss | -0.000373    |\n",
            "|    reward               | -0.030314831 |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.653        |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 290\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 400033.96\n",
            "total_reward: 390033.96\n",
            "total_cost: 358.61\n",
            "total_trades: 3890\n",
            "Sharpe: 0.905\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 393         |\n",
            "|    time_elapsed         | 2204        |\n",
            "|    total_timesteps      | 804864      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016914524 |\n",
            "|    clip_fraction        | 0.0632      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.27       |\n",
            "|    explained_variance   | 0.865       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.053       |\n",
            "|    n_updates            | 3920        |\n",
            "|    policy_gradient_loss | -0.00246    |\n",
            "|    reward               | -0.40952504 |\n",
            "|    std                  | 1.25        |\n",
            "|    value_loss           | 0.126       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 394          |\n",
            "|    time_elapsed         | 2209         |\n",
            "|    total_timesteps      | 806912       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005354313  |\n",
            "|    clip_fraction        | 0.0328       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.26        |\n",
            "|    explained_variance   | 0.796        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.158        |\n",
            "|    n_updates            | 3930         |\n",
            "|    policy_gradient_loss | 0.00198      |\n",
            "|    reward               | -0.008543738 |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.509        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 395         |\n",
            "|    time_elapsed         | 2215        |\n",
            "|    total_timesteps      | 808960      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019082561 |\n",
            "|    clip_fraction        | 0.06        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.27       |\n",
            "|    explained_variance   | 0.823       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.303       |\n",
            "|    n_updates            | 3940        |\n",
            "|    policy_gradient_loss | -0.00129    |\n",
            "|    reward               | -0.07348069 |\n",
            "|    std                  | 1.25        |\n",
            "|    value_loss           | 0.66        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 396          |\n",
            "|    time_elapsed         | 2221         |\n",
            "|    total_timesteps      | 811008       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.011026671  |\n",
            "|    clip_fraction        | 0.0743       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.26        |\n",
            "|    explained_variance   | 0.566        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.135        |\n",
            "|    n_updates            | 3950         |\n",
            "|    policy_gradient_loss | -0.000223    |\n",
            "|    reward               | 0.0012600452 |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.52         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 397         |\n",
            "|    time_elapsed         | 2227        |\n",
            "|    total_timesteps      | 813056      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016173836 |\n",
            "|    clip_fraction        | 0.0935      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.26       |\n",
            "|    explained_variance   | 0.936       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0126      |\n",
            "|    n_updates            | 3960        |\n",
            "|    policy_gradient_loss | -0.00604    |\n",
            "|    reward               | 0.06673772  |\n",
            "|    std                  | 1.25        |\n",
            "|    value_loss           | 0.163       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 364         |\n",
            "|    iterations           | 398         |\n",
            "|    time_elapsed         | 2233        |\n",
            "|    total_timesteps      | 815104      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015472027 |\n",
            "|    clip_fraction        | 0.0829      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.27       |\n",
            "|    explained_variance   | 0.843       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.111       |\n",
            "|    n_updates            | 3970        |\n",
            "|    policy_gradient_loss | 0.00168     |\n",
            "|    reward               | 0.013063057 |\n",
            "|    std                  | 1.25        |\n",
            "|    value_loss           | 0.512       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 364         |\n",
            "|    iterations           | 399         |\n",
            "|    time_elapsed         | 2238        |\n",
            "|    total_timesteps      | 817152      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007000913 |\n",
            "|    clip_fraction        | 0.0652      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.27       |\n",
            "|    explained_variance   | 0.845       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.242       |\n",
            "|    n_updates            | 3980        |\n",
            "|    policy_gradient_loss | -0.00484    |\n",
            "|    reward               | 0.4383907   |\n",
            "|    std                  | 1.25        |\n",
            "|    value_loss           | 0.542       |\n",
            "-----------------------------------------\n",
            "day: 2770, episode: 295\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 383152.66\n",
            "total_reward: 373152.66\n",
            "total_cost: 351.52\n",
            "total_trades: 3802\n",
            "Sharpe: 0.905\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 364         |\n",
            "|    iterations           | 400         |\n",
            "|    time_elapsed         | 2245        |\n",
            "|    total_timesteps      | 819200      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009618754 |\n",
            "|    clip_fraction        | 0.0934      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.27       |\n",
            "|    explained_variance   | 0.628       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.192       |\n",
            "|    n_updates            | 3990        |\n",
            "|    policy_gradient_loss | -0.00164    |\n",
            "|    reward               | 0.07843896  |\n",
            "|    std                  | 1.25        |\n",
            "|    value_loss           | 0.313       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 364         |\n",
            "|    iterations           | 401         |\n",
            "|    time_elapsed         | 2251        |\n",
            "|    total_timesteps      | 821248      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011545718 |\n",
            "|    clip_fraction        | 0.0667      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.26       |\n",
            "|    explained_variance   | 0.897       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0664      |\n",
            "|    n_updates            | 4000        |\n",
            "|    policy_gradient_loss | -0.00111    |\n",
            "|    reward               | 0.04419019  |\n",
            "|    std                  | 1.24        |\n",
            "|    value_loss           | 0.283       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 364         |\n",
            "|    iterations           | 402         |\n",
            "|    time_elapsed         | 2257        |\n",
            "|    total_timesteps      | 823296      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011001773 |\n",
            "|    clip_fraction        | 0.0601      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.26       |\n",
            "|    explained_variance   | 0.829       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.166       |\n",
            "|    n_updates            | 4010        |\n",
            "|    policy_gradient_loss | -0.001      |\n",
            "|    reward               | 0.06397268  |\n",
            "|    std                  | 1.24        |\n",
            "|    value_loss           | 0.476       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 364        |\n",
            "|    iterations           | 403        |\n",
            "|    time_elapsed         | 2262       |\n",
            "|    total_timesteps      | 825344     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.0104423  |\n",
            "|    clip_fraction        | 0.0708     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.26      |\n",
            "|    explained_variance   | 0.725      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 0.16       |\n",
            "|    n_updates            | 4020       |\n",
            "|    policy_gradient_loss | -0.00307   |\n",
            "|    reward               | 0.76014584 |\n",
            "|    std                  | 1.24       |\n",
            "|    value_loss           | 0.557      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 364         |\n",
            "|    iterations           | 404         |\n",
            "|    time_elapsed         | 2268        |\n",
            "|    total_timesteps      | 827392      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016251132 |\n",
            "|    clip_fraction        | 0.047       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.25       |\n",
            "|    explained_variance   | 0.7         |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.12        |\n",
            "|    n_updates            | 4030        |\n",
            "|    policy_gradient_loss | -0.00191    |\n",
            "|    reward               | 0.4076913   |\n",
            "|    std                  | 1.23        |\n",
            "|    value_loss           | 0.3         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 405          |\n",
            "|    time_elapsed         | 2273         |\n",
            "|    total_timesteps      | 829440       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0081117675 |\n",
            "|    clip_fraction        | 0.052        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.25        |\n",
            "|    explained_variance   | 0.831        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.179        |\n",
            "|    n_updates            | 4040         |\n",
            "|    policy_gradient_loss | -0.00459     |\n",
            "|    reward               | 0.06541085   |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 0.415        |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 300\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 401336.97\n",
            "total_reward: 391336.97\n",
            "total_cost: 373.93\n",
            "total_trades: 3942\n",
            "Sharpe: 0.903\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 364           |\n",
            "|    iterations           | 406           |\n",
            "|    time_elapsed         | 2279          |\n",
            "|    total_timesteps      | 831488        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.011820633   |\n",
            "|    clip_fraction        | 0.0998        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.26         |\n",
            "|    explained_variance   | 0.782         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.233         |\n",
            "|    n_updates            | 4050          |\n",
            "|    policy_gradient_loss | -0.00249      |\n",
            "|    reward               | 0.00068451057 |\n",
            "|    std                  | 1.25          |\n",
            "|    value_loss           | 0.674         |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 364         |\n",
            "|    iterations           | 407         |\n",
            "|    time_elapsed         | 2285        |\n",
            "|    total_timesteps      | 833536      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009261423 |\n",
            "|    clip_fraction        | 0.0618      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.27       |\n",
            "|    explained_variance   | 0.788       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.179       |\n",
            "|    n_updates            | 4060        |\n",
            "|    policy_gradient_loss | -0.0019     |\n",
            "|    reward               | 0.04761491  |\n",
            "|    std                  | 1.25        |\n",
            "|    value_loss           | 0.633       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 364         |\n",
            "|    iterations           | 408         |\n",
            "|    time_elapsed         | 2291        |\n",
            "|    total_timesteps      | 835584      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015378975 |\n",
            "|    clip_fraction        | 0.059       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.27       |\n",
            "|    explained_variance   | 0.642       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0737      |\n",
            "|    n_updates            | 4070        |\n",
            "|    policy_gradient_loss | -0.000354   |\n",
            "|    reward               | 0.12340788  |\n",
            "|    std                  | 1.26        |\n",
            "|    value_loss           | 0.364       |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 364           |\n",
            "|    iterations           | 409           |\n",
            "|    time_elapsed         | 2296          |\n",
            "|    total_timesteps      | 837632        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.01247789    |\n",
            "|    clip_fraction        | 0.0704        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.28         |\n",
            "|    explained_variance   | 0.771         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.139         |\n",
            "|    n_updates            | 4080          |\n",
            "|    policy_gradient_loss | -0.00183      |\n",
            "|    reward               | 0.00073000713 |\n",
            "|    std                  | 1.26          |\n",
            "|    value_loss           | 0.436         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 410          |\n",
            "|    time_elapsed         | 2302         |\n",
            "|    total_timesteps      | 839680       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.010080984  |\n",
            "|    clip_fraction        | 0.0565       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | 0.836        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.251        |\n",
            "|    n_updates            | 4090         |\n",
            "|    policy_gradient_loss | -0.00111     |\n",
            "|    reward               | -0.002534887 |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.586        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 364         |\n",
            "|    iterations           | 411         |\n",
            "|    time_elapsed         | 2307        |\n",
            "|    total_timesteps      | 841728      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013700691 |\n",
            "|    clip_fraction        | 0.109       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.27       |\n",
            "|    explained_variance   | 0.743       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.322       |\n",
            "|    n_updates            | 4100        |\n",
            "|    policy_gradient_loss | -0.00274    |\n",
            "|    reward               | 0.33770287  |\n",
            "|    std                  | 1.25        |\n",
            "|    value_loss           | 0.602       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 364         |\n",
            "|    iterations           | 412         |\n",
            "|    time_elapsed         | 2313        |\n",
            "|    total_timesteps      | 843776      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.026864542 |\n",
            "|    clip_fraction        | 0.107       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.27       |\n",
            "|    explained_variance   | 0.833       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0697      |\n",
            "|    n_updates            | 4110        |\n",
            "|    policy_gradient_loss | 0.00228     |\n",
            "|    reward               | 0.11064448  |\n",
            "|    std                  | 1.25        |\n",
            "|    value_loss           | 0.171       |\n",
            "-----------------------------------------\n",
            "day: 2770, episode: 305\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 410822.50\n",
            "total_reward: 400822.50\n",
            "total_cost: 382.89\n",
            "total_trades: 4078\n",
            "Sharpe: 0.904\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 364         |\n",
            "|    iterations           | 413         |\n",
            "|    time_elapsed         | 2318        |\n",
            "|    total_timesteps      | 845824      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009280991 |\n",
            "|    clip_fraction        | 0.0521      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.26       |\n",
            "|    explained_variance   | 0.875       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.162       |\n",
            "|    n_updates            | 4120        |\n",
            "|    policy_gradient_loss | 0.000346    |\n",
            "|    reward               | 0.010478677 |\n",
            "|    std                  | 1.24        |\n",
            "|    value_loss           | 0.456       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 414          |\n",
            "|    time_elapsed         | 2323         |\n",
            "|    total_timesteps      | 847872       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0093656145 |\n",
            "|    clip_fraction        | 0.078        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.26        |\n",
            "|    explained_variance   | 0.729        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.302        |\n",
            "|    n_updates            | 4130         |\n",
            "|    policy_gradient_loss | 0.00301      |\n",
            "|    reward               | -0.79446393  |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 1.05         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 364         |\n",
            "|    iterations           | 415         |\n",
            "|    time_elapsed         | 2329        |\n",
            "|    total_timesteps      | 849920      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009560994 |\n",
            "|    clip_fraction        | 0.0887      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.26       |\n",
            "|    explained_variance   | 0.632       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.282       |\n",
            "|    n_updates            | 4140        |\n",
            "|    policy_gradient_loss | 0.00139     |\n",
            "|    reward               | -0.41970417 |\n",
            "|    std                  | 1.25        |\n",
            "|    value_loss           | 0.654       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 364         |\n",
            "|    iterations           | 416         |\n",
            "|    time_elapsed         | 2334        |\n",
            "|    total_timesteps      | 851968      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016234428 |\n",
            "|    clip_fraction        | 0.0781      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.27       |\n",
            "|    explained_variance   | 0.855       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0576      |\n",
            "|    n_updates            | 4150        |\n",
            "|    policy_gradient_loss | -0.000754   |\n",
            "|    reward               | 0.044668045 |\n",
            "|    std                  | 1.25        |\n",
            "|    value_loss           | 0.139       |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 364           |\n",
            "|    iterations           | 417           |\n",
            "|    time_elapsed         | 2339          |\n",
            "|    total_timesteps      | 854016        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.013485061   |\n",
            "|    clip_fraction        | 0.0769        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.28         |\n",
            "|    explained_variance   | 0.79          |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.199         |\n",
            "|    n_updates            | 4160          |\n",
            "|    policy_gradient_loss | 0.0038        |\n",
            "|    reward               | -0.0014210469 |\n",
            "|    std                  | 1.26          |\n",
            "|    value_loss           | 0.51          |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 418         |\n",
            "|    time_elapsed         | 2343        |\n",
            "|    total_timesteps      | 856064      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005082493 |\n",
            "|    clip_fraction        | 0.0587      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.28       |\n",
            "|    explained_variance   | 0.792       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.296       |\n",
            "|    n_updates            | 4170        |\n",
            "|    policy_gradient_loss | -0.00307    |\n",
            "|    reward               | -0.19990557 |\n",
            "|    std                  | 1.26        |\n",
            "|    value_loss           | 0.603       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 419         |\n",
            "|    time_elapsed         | 2349        |\n",
            "|    total_timesteps      | 858112      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011863489 |\n",
            "|    clip_fraction        | 0.0851      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.27       |\n",
            "|    explained_variance   | 0.699       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.291       |\n",
            "|    n_updates            | 4180        |\n",
            "|    policy_gradient_loss | -0.00521    |\n",
            "|    reward               | -0.2415567  |\n",
            "|    std                  | 1.25        |\n",
            "|    value_loss           | 0.576       |\n",
            "-----------------------------------------\n",
            "day: 2770, episode: 310\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 412736.42\n",
            "total_reward: 402736.42\n",
            "total_cost: 376.77\n",
            "total_trades: 4000\n",
            "Sharpe: 0.905\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 420         |\n",
            "|    time_elapsed         | 2355        |\n",
            "|    total_timesteps      | 860160      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008869043 |\n",
            "|    clip_fraction        | 0.0603      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.27       |\n",
            "|    explained_variance   | 0.912       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0315      |\n",
            "|    n_updates            | 4190        |\n",
            "|    policy_gradient_loss | -0.000406   |\n",
            "|    reward               | 0.012291931 |\n",
            "|    std                  | 1.25        |\n",
            "|    value_loss           | 0.19        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 365        |\n",
            "|    iterations           | 421        |\n",
            "|    time_elapsed         | 2361       |\n",
            "|    total_timesteps      | 862208     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01131325 |\n",
            "|    clip_fraction        | 0.0632     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.27      |\n",
            "|    explained_variance   | 0.869      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 0.136      |\n",
            "|    n_updates            | 4200       |\n",
            "|    policy_gradient_loss | -0.00263   |\n",
            "|    reward               | 0.06132831 |\n",
            "|    std                  | 1.25       |\n",
            "|    value_loss           | 0.538      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 422         |\n",
            "|    time_elapsed         | 2366        |\n",
            "|    total_timesteps      | 864256      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009453721 |\n",
            "|    clip_fraction        | 0.0641      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.28       |\n",
            "|    explained_variance   | 0.783       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.285       |\n",
            "|    n_updates            | 4210        |\n",
            "|    policy_gradient_loss | -0.000132   |\n",
            "|    reward               | -0.89962286 |\n",
            "|    std                  | 1.26        |\n",
            "|    value_loss           | 0.641       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 423         |\n",
            "|    time_elapsed         | 2372        |\n",
            "|    total_timesteps      | 866304      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011754998 |\n",
            "|    clip_fraction        | 0.0767      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.29       |\n",
            "|    explained_variance   | 0.617       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.203       |\n",
            "|    n_updates            | 4220        |\n",
            "|    policy_gradient_loss | 0.000419    |\n",
            "|    reward               | -0.16133517 |\n",
            "|    std                  | 1.26        |\n",
            "|    value_loss           | 0.411       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 424         |\n",
            "|    time_elapsed         | 2377        |\n",
            "|    total_timesteps      | 868352      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018728271 |\n",
            "|    clip_fraction        | 0.0917      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.29       |\n",
            "|    explained_variance   | 0.918       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.162       |\n",
            "|    n_updates            | 4230        |\n",
            "|    policy_gradient_loss | -0.00018    |\n",
            "|    reward               | -0.05784703 |\n",
            "|    std                  | 1.27        |\n",
            "|    value_loss           | 0.287       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 425          |\n",
            "|    time_elapsed         | 2382         |\n",
            "|    total_timesteps      | 870400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.008773891  |\n",
            "|    clip_fraction        | 0.075        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.3         |\n",
            "|    explained_variance   | 0.838        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.202        |\n",
            "|    n_updates            | 4240         |\n",
            "|    policy_gradient_loss | -0.000555    |\n",
            "|    reward               | -0.029339978 |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.527        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 426          |\n",
            "|    time_elapsed         | 2388         |\n",
            "|    total_timesteps      | 872448       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0101337815 |\n",
            "|    clip_fraction        | 0.073        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.3         |\n",
            "|    explained_variance   | 0.688        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.285        |\n",
            "|    n_updates            | 4250         |\n",
            "|    policy_gradient_loss | -0.00139     |\n",
            "|    reward               | -0.11287997  |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 1.07         |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 315\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 402590.68\n",
            "total_reward: 392590.68\n",
            "total_cost: 362.53\n",
            "total_trades: 3962\n",
            "Sharpe: 0.886\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 427          |\n",
            "|    time_elapsed         | 2394         |\n",
            "|    total_timesteps      | 874496       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0117196245 |\n",
            "|    clip_fraction        | 0.108        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.29        |\n",
            "|    explained_variance   | 0.781        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0469       |\n",
            "|    n_updates            | 4260         |\n",
            "|    policy_gradient_loss | -0.00214     |\n",
            "|    reward               | -0.1868096   |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.252        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 428          |\n",
            "|    time_elapsed         | 2400         |\n",
            "|    total_timesteps      | 876544       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.008640996  |\n",
            "|    clip_fraction        | 0.0896       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.29        |\n",
            "|    explained_variance   | 0.797        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.138        |\n",
            "|    n_updates            | 4270         |\n",
            "|    policy_gradient_loss | -2.59e-05    |\n",
            "|    reward               | -0.047778074 |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.422        |\n",
            "------------------------------------------\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 365            |\n",
            "|    iterations           | 429            |\n",
            "|    time_elapsed         | 2406           |\n",
            "|    total_timesteps      | 878592         |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.007362902    |\n",
            "|    clip_fraction        | 0.0351         |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -3.29          |\n",
            "|    explained_variance   | 0.775          |\n",
            "|    learning_rate        | 0.00025        |\n",
            "|    loss                 | 0.202          |\n",
            "|    n_updates            | 4280           |\n",
            "|    policy_gradient_loss | -0.00195       |\n",
            "|    reward               | -0.00032643395 |\n",
            "|    std                  | 1.26           |\n",
            "|    value_loss           | 0.643          |\n",
            "--------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 430         |\n",
            "|    time_elapsed         | 2411        |\n",
            "|    total_timesteps      | 880640      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.01497378  |\n",
            "|    clip_fraction        | 0.0838      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.29       |\n",
            "|    explained_variance   | 0.81        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.266       |\n",
            "|    n_updates            | 4290        |\n",
            "|    policy_gradient_loss | 0.00045     |\n",
            "|    reward               | 0.051052116 |\n",
            "|    std                  | 1.26        |\n",
            "|    value_loss           | 0.613       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 431         |\n",
            "|    time_elapsed         | 2417        |\n",
            "|    total_timesteps      | 882688      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011009378 |\n",
            "|    clip_fraction        | 0.0687      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.28       |\n",
            "|    explained_variance   | 0.817       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.12        |\n",
            "|    n_updates            | 4300        |\n",
            "|    policy_gradient_loss | 0.00447     |\n",
            "|    reward               | 0.26255512  |\n",
            "|    std                  | 1.25        |\n",
            "|    value_loss           | 0.236       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 432          |\n",
            "|    time_elapsed         | 2422         |\n",
            "|    total_timesteps      | 884736       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.014401747  |\n",
            "|    clip_fraction        | 0.0825       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.27        |\n",
            "|    explained_variance   | 0.885        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.292        |\n",
            "|    n_updates            | 4310         |\n",
            "|    policy_gradient_loss | 0.00269      |\n",
            "|    reward               | -0.021915704 |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.415        |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 320\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 408740.23\n",
            "total_reward: 398740.23\n",
            "total_cost: 354.21\n",
            "total_trades: 3888\n",
            "Sharpe: 0.886\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 433          |\n",
            "|    time_elapsed         | 2428         |\n",
            "|    total_timesteps      | 886784       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0102475975 |\n",
            "|    clip_fraction        | 0.051        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.26        |\n",
            "|    explained_variance   | 0.842        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.246        |\n",
            "|    n_updates            | 4320         |\n",
            "|    policy_gradient_loss | -0.0033      |\n",
            "|    reward               | 0.0069959485 |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.544        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 434         |\n",
            "|    time_elapsed         | 2433        |\n",
            "|    total_timesteps      | 888832      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012753465 |\n",
            "|    clip_fraction        | 0.045       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.26       |\n",
            "|    explained_variance   | 0.787       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.182       |\n",
            "|    n_updates            | 4330        |\n",
            "|    policy_gradient_loss | 0.00122     |\n",
            "|    reward               | 0.35402107  |\n",
            "|    std                  | 1.25        |\n",
            "|    value_loss           | 0.6         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 435         |\n",
            "|    time_elapsed         | 2438        |\n",
            "|    total_timesteps      | 890880      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008543529 |\n",
            "|    clip_fraction        | 0.0591      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.27       |\n",
            "|    explained_variance   | 0.811       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.035       |\n",
            "|    n_updates            | 4340        |\n",
            "|    policy_gradient_loss | 0.000191    |\n",
            "|    reward               | 0.071513355 |\n",
            "|    std                  | 1.26        |\n",
            "|    value_loss           | 0.19        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 436         |\n",
            "|    time_elapsed         | 2444        |\n",
            "|    total_timesteps      | 892928      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023321714 |\n",
            "|    clip_fraction        | 0.0456      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.29       |\n",
            "|    explained_variance   | 0.885       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.178       |\n",
            "|    n_updates            | 4350        |\n",
            "|    policy_gradient_loss | 0.0012      |\n",
            "|    reward               | 0.022558397 |\n",
            "|    std                  | 1.27        |\n",
            "|    value_loss           | 0.431       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 437          |\n",
            "|    time_elapsed         | 2449         |\n",
            "|    total_timesteps      | 894976       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0138842985 |\n",
            "|    clip_fraction        | 0.0894       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.29        |\n",
            "|    explained_variance   | 0.863        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.263        |\n",
            "|    n_updates            | 4360         |\n",
            "|    policy_gradient_loss | -0.0021      |\n",
            "|    reward               | 0.62039495   |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.601        |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 365        |\n",
            "|    iterations           | 438        |\n",
            "|    time_elapsed         | 2454       |\n",
            "|    total_timesteps      | 897024     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.08231659 |\n",
            "|    clip_fraction        | 0.142      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.29      |\n",
            "|    explained_variance   | 0.839      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 0.224      |\n",
            "|    n_updates            | 4370       |\n",
            "|    policy_gradient_loss | 0.0448     |\n",
            "|    reward               | -0.5194061 |\n",
            "|    std                  | 1.26       |\n",
            "|    value_loss           | 0.584      |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 439          |\n",
            "|    time_elapsed         | 2459         |\n",
            "|    total_timesteps      | 899072       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.012969359  |\n",
            "|    clip_fraction        | 0.0653       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | 0.817        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0272       |\n",
            "|    n_updates            | 4380         |\n",
            "|    policy_gradient_loss | 0.00127      |\n",
            "|    reward               | -0.022961834 |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.154        |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 325\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 412779.19\n",
            "total_reward: 402779.19\n",
            "total_cost: 336.81\n",
            "total_trades: 3816\n",
            "Sharpe: 0.906\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 440          |\n",
            "|    time_elapsed         | 2465         |\n",
            "|    total_timesteps      | 901120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.015392893  |\n",
            "|    clip_fraction        | 0.0567       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | 0.821        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.137        |\n",
            "|    n_updates            | 4390         |\n",
            "|    policy_gradient_loss | 0.00122      |\n",
            "|    reward               | -0.019063948 |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.501        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 441         |\n",
            "|    time_elapsed         | 2470        |\n",
            "|    total_timesteps      | 903168      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008992214 |\n",
            "|    clip_fraction        | 0.0427      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.29       |\n",
            "|    explained_variance   | 0.691       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.251       |\n",
            "|    n_updates            | 4400        |\n",
            "|    policy_gradient_loss | -0.00248    |\n",
            "|    reward               | -0.45655864 |\n",
            "|    std                  | 1.26        |\n",
            "|    value_loss           | 1.02        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 442         |\n",
            "|    time_elapsed         | 2476        |\n",
            "|    total_timesteps      | 905216      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012300998 |\n",
            "|    clip_fraction        | 0.0939      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.28       |\n",
            "|    explained_variance   | 0.73        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.142       |\n",
            "|    n_updates            | 4410        |\n",
            "|    policy_gradient_loss | 0.00118     |\n",
            "|    reward               | -0.38477135 |\n",
            "|    std                  | 1.26        |\n",
            "|    value_loss           | 0.497       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 443         |\n",
            "|    time_elapsed         | 2481        |\n",
            "|    total_timesteps      | 907264      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009821189 |\n",
            "|    clip_fraction        | 0.0566      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.28       |\n",
            "|    explained_variance   | 0.905       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0727      |\n",
            "|    n_updates            | 4420        |\n",
            "|    policy_gradient_loss | -0.000917   |\n",
            "|    reward               | 0.24904084  |\n",
            "|    std                  | 1.26        |\n",
            "|    value_loss           | 0.193       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 444          |\n",
            "|    time_elapsed         | 2486         |\n",
            "|    total_timesteps      | 909312       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0129802665 |\n",
            "|    clip_fraction        | 0.0709       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | 0.868        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.214        |\n",
            "|    n_updates            | 4430         |\n",
            "|    policy_gradient_loss | 0.00045      |\n",
            "|    reward               | -0.014149848 |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.559        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 445         |\n",
            "|    time_elapsed         | 2492        |\n",
            "|    total_timesteps      | 911360      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007803226 |\n",
            "|    clip_fraction        | 0.0669      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.28       |\n",
            "|    explained_variance   | 0.809       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.267       |\n",
            "|    n_updates            | 4440        |\n",
            "|    policy_gradient_loss | -0.00212    |\n",
            "|    reward               | 1.0062102   |\n",
            "|    std                  | 1.26        |\n",
            "|    value_loss           | 0.627       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 446         |\n",
            "|    time_elapsed         | 2497        |\n",
            "|    total_timesteps      | 913408      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007451863 |\n",
            "|    clip_fraction        | 0.046       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.28       |\n",
            "|    explained_variance   | 0.711       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.294       |\n",
            "|    n_updates            | 4450        |\n",
            "|    policy_gradient_loss | 0.000994    |\n",
            "|    reward               | -0.18791078 |\n",
            "|    std                  | 1.25        |\n",
            "|    value_loss           | 0.534       |\n",
            "-----------------------------------------\n",
            "day: 2770, episode: 330\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 417115.77\n",
            "total_reward: 407115.77\n",
            "total_cost: 314.64\n",
            "total_trades: 3718\n",
            "Sharpe: 0.906\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 447         |\n",
            "|    time_elapsed         | 2503        |\n",
            "|    total_timesteps      | 915456      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008135768 |\n",
            "|    clip_fraction        | 0.0664      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.27       |\n",
            "|    explained_variance   | 0.815       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.273       |\n",
            "|    n_updates            | 4460        |\n",
            "|    policy_gradient_loss | 0.001       |\n",
            "|    reward               | 0.14296542  |\n",
            "|    std                  | 1.25        |\n",
            "|    value_loss           | 0.515       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 448          |\n",
            "|    time_elapsed         | 2508         |\n",
            "|    total_timesteps      | 917504       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020463294 |\n",
            "|    clip_fraction        | 0.0203       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.26        |\n",
            "|    explained_variance   | 0.767        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.368        |\n",
            "|    n_updates            | 4470         |\n",
            "|    policy_gradient_loss | -0.00203     |\n",
            "|    reward               | -0.023730388 |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.855        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 449         |\n",
            "|    time_elapsed         | 2513        |\n",
            "|    total_timesteps      | 919552      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016522858 |\n",
            "|    clip_fraction        | 0.0813      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.27       |\n",
            "|    explained_variance   | 0.831       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.351       |\n",
            "|    n_updates            | 4480        |\n",
            "|    policy_gradient_loss | 0.000246    |\n",
            "|    reward               | -0.9335949  |\n",
            "|    std                  | 1.26        |\n",
            "|    value_loss           | 0.591       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 450          |\n",
            "|    time_elapsed         | 2519         |\n",
            "|    total_timesteps      | 921600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.011034714  |\n",
            "|    clip_fraction        | 0.0655       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | 0.849        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0715       |\n",
            "|    n_updates            | 4490         |\n",
            "|    policy_gradient_loss | -0.00177     |\n",
            "|    reward               | -0.049356163 |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.274        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 451         |\n",
            "|    time_elapsed         | 2524        |\n",
            "|    total_timesteps      | 923648      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012552252 |\n",
            "|    clip_fraction        | 0.0814      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.29       |\n",
            "|    explained_variance   | 0.875       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.202       |\n",
            "|    n_updates            | 4500        |\n",
            "|    policy_gradient_loss | 0.000814    |\n",
            "|    reward               | 0.013891939 |\n",
            "|    std                  | 1.26        |\n",
            "|    value_loss           | 0.383       |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 365           |\n",
            "|    iterations           | 452           |\n",
            "|    time_elapsed         | 2530          |\n",
            "|    total_timesteps      | 925696        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.024163898   |\n",
            "|    clip_fraction        | 0.1           |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.29         |\n",
            "|    explained_variance   | 0.706         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.117         |\n",
            "|    n_updates            | 4510          |\n",
            "|    policy_gradient_loss | 0.00435       |\n",
            "|    reward               | -0.0063117417 |\n",
            "|    std                  | 1.27          |\n",
            "|    value_loss           | 0.363         |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 453         |\n",
            "|    time_elapsed         | 2536        |\n",
            "|    total_timesteps      | 927744      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023164235 |\n",
            "|    clip_fraction        | 0.0762      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.31       |\n",
            "|    explained_variance   | 0.599       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.193       |\n",
            "|    n_updates            | 4520        |\n",
            "|    policy_gradient_loss | -0.00119    |\n",
            "|    reward               | 0.1474938   |\n",
            "|    std                  | 1.28        |\n",
            "|    value_loss           | 0.633       |\n",
            "-----------------------------------------\n",
            "day: 2770, episode: 335\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 415299.47\n",
            "total_reward: 405299.47\n",
            "total_cost: 346.13\n",
            "total_trades: 3870\n",
            "Sharpe: 0.906\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 454         |\n",
            "|    time_elapsed         | 2542        |\n",
            "|    total_timesteps      | 929792      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011898976 |\n",
            "|    clip_fraction        | 0.0988      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.31       |\n",
            "|    explained_variance   | 0.767       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0543      |\n",
            "|    n_updates            | 4530        |\n",
            "|    policy_gradient_loss | -0.00496    |\n",
            "|    reward               | 0.019687898 |\n",
            "|    std                  | 1.29        |\n",
            "|    value_loss           | 0.234       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 455          |\n",
            "|    time_elapsed         | 2547         |\n",
            "|    total_timesteps      | 931840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.008873824  |\n",
            "|    clip_fraction        | 0.0474       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.33        |\n",
            "|    explained_variance   | 0.817        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.168        |\n",
            "|    n_updates            | 4540         |\n",
            "|    policy_gradient_loss | -0.00273     |\n",
            "|    reward               | -0.048963692 |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.403        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 456          |\n",
            "|    time_elapsed         | 2553         |\n",
            "|    total_timesteps      | 933888       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056493487 |\n",
            "|    clip_fraction        | 0.0401       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.33        |\n",
            "|    explained_variance   | 0.849        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.201        |\n",
            "|    n_updates            | 4550         |\n",
            "|    policy_gradient_loss | -0.00309     |\n",
            "|    reward               | 0.013810729  |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.569        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 457          |\n",
            "|    time_elapsed         | 2559         |\n",
            "|    total_timesteps      | 935936       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061235772 |\n",
            "|    clip_fraction        | 0.0448       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.32        |\n",
            "|    explained_variance   | 0.489        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.228        |\n",
            "|    n_updates            | 4560         |\n",
            "|    policy_gradient_loss | -0.00436     |\n",
            "|    reward               | 0.12566906   |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.92         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 365           |\n",
            "|    iterations           | 458           |\n",
            "|    time_elapsed         | 2565          |\n",
            "|    total_timesteps      | 937984        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0068147415  |\n",
            "|    clip_fraction        | 0.0488        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.33         |\n",
            "|    explained_variance   | 0.77          |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.018         |\n",
            "|    n_updates            | 4570          |\n",
            "|    policy_gradient_loss | -0.00273      |\n",
            "|    reward               | -0.0036617187 |\n",
            "|    std                  | 1.29          |\n",
            "|    value_loss           | 0.186         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 459          |\n",
            "|    time_elapsed         | 2571         |\n",
            "|    total_timesteps      | 940032       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.009912061  |\n",
            "|    clip_fraction        | 0.0608       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.32        |\n",
            "|    explained_variance   | 0.782        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.115        |\n",
            "|    n_updates            | 4580         |\n",
            "|    policy_gradient_loss | -0.00371     |\n",
            "|    reward               | -0.017942088 |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.479        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 460          |\n",
            "|    time_elapsed         | 2577         |\n",
            "|    total_timesteps      | 942080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0120142335 |\n",
            "|    clip_fraction        | 0.062        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.3         |\n",
            "|    explained_variance   | 0.756        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.161        |\n",
            "|    n_updates            | 4590         |\n",
            "|    policy_gradient_loss | -0.00837     |\n",
            "|    reward               | 1.7498397    |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.612        |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 340\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 418571.31\n",
            "total_reward: 408571.31\n",
            "total_cost: 356.88\n",
            "total_trades: 3922\n",
            "Sharpe: 0.902\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 461          |\n",
            "|    time_elapsed         | 2582         |\n",
            "|    total_timesteps      | 944128       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071701785 |\n",
            "|    clip_fraction        | 0.0511       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.3         |\n",
            "|    explained_variance   | 0.725        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.188        |\n",
            "|    n_updates            | 4600         |\n",
            "|    policy_gradient_loss | -0.00234     |\n",
            "|    reward               | 0.47984898   |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.543        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 462         |\n",
            "|    time_elapsed         | 2588        |\n",
            "|    total_timesteps      | 946176      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010214148 |\n",
            "|    clip_fraction        | 0.058       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.3        |\n",
            "|    explained_variance   | 0.795       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0282      |\n",
            "|    n_updates            | 4610        |\n",
            "|    policy_gradient_loss | -0.00493    |\n",
            "|    reward               | -0.07622245 |\n",
            "|    std                  | 1.28        |\n",
            "|    value_loss           | 0.161       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 463         |\n",
            "|    time_elapsed         | 2593        |\n",
            "|    total_timesteps      | 948224      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010642634 |\n",
            "|    clip_fraction        | 0.052       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.31       |\n",
            "|    explained_variance   | 0.734       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.26        |\n",
            "|    n_updates            | 4620        |\n",
            "|    policy_gradient_loss | -0.00402    |\n",
            "|    reward               | -0.04934518 |\n",
            "|    std                  | 1.28        |\n",
            "|    value_loss           | 0.589       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 464         |\n",
            "|    time_elapsed         | 2598        |\n",
            "|    total_timesteps      | 950272      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010878589 |\n",
            "|    clip_fraction        | 0.0689      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.31       |\n",
            "|    explained_variance   | 0.764       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.258       |\n",
            "|    n_updates            | 4630        |\n",
            "|    policy_gradient_loss | -0.0023     |\n",
            "|    reward               | -0.29540968 |\n",
            "|    std                  | 1.28        |\n",
            "|    value_loss           | 0.811       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 465          |\n",
            "|    time_elapsed         | 2604         |\n",
            "|    total_timesteps      | 952320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037605595 |\n",
            "|    clip_fraction        | 0.0336       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.31        |\n",
            "|    explained_variance   | 0.438        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.516        |\n",
            "|    n_updates            | 4640         |\n",
            "|    policy_gradient_loss | -0.00307     |\n",
            "|    reward               | 0.40500838   |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.903        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 466         |\n",
            "|    time_elapsed         | 2610        |\n",
            "|    total_timesteps      | 954368      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008761811 |\n",
            "|    clip_fraction        | 0.0678      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.31       |\n",
            "|    explained_variance   | 0.821       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.102       |\n",
            "|    n_updates            | 4650        |\n",
            "|    policy_gradient_loss | -0.00576    |\n",
            "|    reward               | 0.26552597  |\n",
            "|    std                  | 1.28        |\n",
            "|    value_loss           | 0.259       |\n",
            "-----------------------------------------\n",
            "day: 2770, episode: 345\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 412777.90\n",
            "total_reward: 402777.90\n",
            "total_cost: 346.82\n",
            "total_trades: 3764\n",
            "Sharpe: 0.904\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 467          |\n",
            "|    time_elapsed         | 2615         |\n",
            "|    total_timesteps      | 956416       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004641638  |\n",
            "|    clip_fraction        | 0.0505       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.31        |\n",
            "|    explained_variance   | 0.644        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.446        |\n",
            "|    n_updates            | 4660         |\n",
            "|    policy_gradient_loss | -0.00518     |\n",
            "|    reward               | -0.054406956 |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.752        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 468         |\n",
            "|    time_elapsed         | 2621        |\n",
            "|    total_timesteps      | 958464      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016521476 |\n",
            "|    clip_fraction        | 0.0882      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.31       |\n",
            "|    explained_variance   | 0.601       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.445       |\n",
            "|    n_updates            | 4670        |\n",
            "|    policy_gradient_loss | -0.00182    |\n",
            "|    reward               | 0.9244171   |\n",
            "|    std                  | 1.28        |\n",
            "|    value_loss           | 1.06        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 469          |\n",
            "|    time_elapsed         | 2626         |\n",
            "|    total_timesteps      | 960512       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0150121255 |\n",
            "|    clip_fraction        | 0.0771       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.32        |\n",
            "|    explained_variance   | 0.732        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.153        |\n",
            "|    n_updates            | 4680         |\n",
            "|    policy_gradient_loss | -0.00112     |\n",
            "|    reward               | 0.24665453   |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.378        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 470         |\n",
            "|    time_elapsed         | 2631        |\n",
            "|    total_timesteps      | 962560      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009237288 |\n",
            "|    clip_fraction        | 0.0895      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.31       |\n",
            "|    explained_variance   | 0.864       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.125       |\n",
            "|    n_updates            | 4690        |\n",
            "|    policy_gradient_loss | -0.000129   |\n",
            "|    reward               | -0.16642782 |\n",
            "|    std                  | 1.27        |\n",
            "|    value_loss           | 0.32        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 471          |\n",
            "|    time_elapsed         | 2636         |\n",
            "|    total_timesteps      | 964608       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005300259  |\n",
            "|    clip_fraction        | 0.0326       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.3         |\n",
            "|    explained_variance   | 0.84         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.153        |\n",
            "|    n_updates            | 4700         |\n",
            "|    policy_gradient_loss | -0.00328     |\n",
            "|    reward               | -0.011551151 |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.552        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 472          |\n",
            "|    time_elapsed         | 2642         |\n",
            "|    total_timesteps      | 966656       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035167907 |\n",
            "|    clip_fraction        | 0.0181       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.3         |\n",
            "|    explained_variance   | 0.811        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.241        |\n",
            "|    n_updates            | 4710         |\n",
            "|    policy_gradient_loss | -0.00258     |\n",
            "|    reward               | -0.9996613   |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.561        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 473         |\n",
            "|    time_elapsed         | 2647        |\n",
            "|    total_timesteps      | 968704      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007567012 |\n",
            "|    clip_fraction        | 0.059       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.31       |\n",
            "|    explained_variance   | 0.754       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0891      |\n",
            "|    n_updates            | 4720        |\n",
            "|    policy_gradient_loss | -0.000668   |\n",
            "|    reward               | 0.32869986  |\n",
            "|    std                  | 1.28        |\n",
            "|    value_loss           | 0.307       |\n",
            "-----------------------------------------\n",
            "day: 2770, episode: 350\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 288685.57\n",
            "total_reward: 278685.57\n",
            "total_cost: 369.34\n",
            "total_trades: 3916\n",
            "Sharpe: 0.879\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 474          |\n",
            "|    time_elapsed         | 2652         |\n",
            "|    total_timesteps      | 970752       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.007844019  |\n",
            "|    clip_fraction        | 0.0427       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.32        |\n",
            "|    explained_variance   | 0.746        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.103        |\n",
            "|    n_updates            | 4730         |\n",
            "|    policy_gradient_loss | -0.00357     |\n",
            "|    reward               | -0.026587483 |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.481        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 475         |\n",
            "|    time_elapsed         | 2658        |\n",
            "|    total_timesteps      | 972800      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006707879 |\n",
            "|    clip_fraction        | 0.0534      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.32       |\n",
            "|    explained_variance   | 0.5         |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.314       |\n",
            "|    n_updates            | 4740        |\n",
            "|    policy_gradient_loss | -0.000787   |\n",
            "|    reward               | 0.009482988 |\n",
            "|    std                  | 1.28        |\n",
            "|    value_loss           | 0.849       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 476         |\n",
            "|    time_elapsed         | 2664        |\n",
            "|    total_timesteps      | 974848      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014828032 |\n",
            "|    clip_fraction        | 0.0796      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.32       |\n",
            "|    explained_variance   | 0.491       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.251       |\n",
            "|    n_updates            | 4750        |\n",
            "|    policy_gradient_loss | 0.00534     |\n",
            "|    reward               | 0.7248229   |\n",
            "|    std                  | 1.29        |\n",
            "|    value_loss           | 0.896       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 477         |\n",
            "|    time_elapsed         | 2669        |\n",
            "|    total_timesteps      | 976896      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017173804 |\n",
            "|    clip_fraction        | 0.0726      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.33       |\n",
            "|    explained_variance   | 0.77        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.158       |\n",
            "|    n_updates            | 4760        |\n",
            "|    policy_gradient_loss | 0.0104      |\n",
            "|    reward               | -0.12490418 |\n",
            "|    std                  | 1.29        |\n",
            "|    value_loss           | 0.316       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 478         |\n",
            "|    time_elapsed         | 2675        |\n",
            "|    total_timesteps      | 978944      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008089669 |\n",
            "|    clip_fraction        | 0.0646      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.34       |\n",
            "|    explained_variance   | 0.756       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.126       |\n",
            "|    n_updates            | 4770        |\n",
            "|    policy_gradient_loss | -0.0018     |\n",
            "|    reward               | 0.00828865  |\n",
            "|    std                  | 1.3         |\n",
            "|    value_loss           | 0.558       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 479         |\n",
            "|    time_elapsed         | 2680        |\n",
            "|    total_timesteps      | 980992      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.00584206  |\n",
            "|    clip_fraction        | 0.0252      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.35       |\n",
            "|    explained_variance   | 0.732       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.324       |\n",
            "|    n_updates            | 4780        |\n",
            "|    policy_gradient_loss | -0.0037     |\n",
            "|    reward               | 0.009642854 |\n",
            "|    std                  | 1.3         |\n",
            "|    value_loss           | 0.783       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 480          |\n",
            "|    time_elapsed         | 2685         |\n",
            "|    total_timesteps      | 983040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006380505  |\n",
            "|    clip_fraction        | 0.0336       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.35        |\n",
            "|    explained_variance   | 0.561        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.6          |\n",
            "|    n_updates            | 4790         |\n",
            "|    policy_gradient_loss | -0.00186     |\n",
            "|    reward               | -0.043797184 |\n",
            "|    std                  | 1.3          |\n",
            "|    value_loss           | 0.937        |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 355\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 222245.35\n",
            "total_reward: 212245.35\n",
            "total_cost: 363.53\n",
            "total_trades: 3814\n",
            "Sharpe: 0.845\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 481         |\n",
            "|    time_elapsed         | 2691        |\n",
            "|    total_timesteps      | 985088      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012375535 |\n",
            "|    clip_fraction        | 0.0715      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.33       |\n",
            "|    explained_variance   | 0.818       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0229      |\n",
            "|    n_updates            | 4800        |\n",
            "|    policy_gradient_loss | -0.00252    |\n",
            "|    reward               | -0.1659293  |\n",
            "|    std                  | 1.29        |\n",
            "|    value_loss           | 0.152       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 482         |\n",
            "|    time_elapsed         | 2696        |\n",
            "|    total_timesteps      | 987136      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009410465 |\n",
            "|    clip_fraction        | 0.092       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.34       |\n",
            "|    explained_variance   | 0.851       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0226      |\n",
            "|    n_updates            | 4810        |\n",
            "|    policy_gradient_loss | -0.00321    |\n",
            "|    reward               | 0.025523614 |\n",
            "|    std                  | 1.3         |\n",
            "|    value_loss           | 0.167       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 483         |\n",
            "|    time_elapsed         | 2700        |\n",
            "|    total_timesteps      | 989184      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008754171 |\n",
            "|    clip_fraction        | 0.0507      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.34       |\n",
            "|    explained_variance   | 0.598       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.446       |\n",
            "|    n_updates            | 4820        |\n",
            "|    policy_gradient_loss | 0.00226     |\n",
            "|    reward               | -1.0455774  |\n",
            "|    std                  | 1.3         |\n",
            "|    value_loss           | 0.765       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 484         |\n",
            "|    time_elapsed         | 2704        |\n",
            "|    total_timesteps      | 991232      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010589387 |\n",
            "|    clip_fraction        | 0.0814      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.34       |\n",
            "|    explained_variance   | 0.541       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.175       |\n",
            "|    n_updates            | 4830        |\n",
            "|    policy_gradient_loss | -0.00311    |\n",
            "|    reward               | 0.2112032   |\n",
            "|    std                  | 1.3         |\n",
            "|    value_loss           | 0.337       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 366          |\n",
            "|    iterations           | 485          |\n",
            "|    time_elapsed         | 2709         |\n",
            "|    total_timesteps      | 993280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0066067465 |\n",
            "|    clip_fraction        | 0.0622       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.34        |\n",
            "|    explained_variance   | 0.75         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.049        |\n",
            "|    n_updates            | 4840         |\n",
            "|    policy_gradient_loss | -0.00631     |\n",
            "|    reward               | 0.13252118   |\n",
            "|    std                  | 1.3          |\n",
            "|    value_loss           | 0.162        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 486          |\n",
            "|    time_elapsed         | 2722         |\n",
            "|    total_timesteps      | 995328       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0068204748 |\n",
            "|    clip_fraction        | 0.0397       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.33        |\n",
            "|    explained_variance   | 0.674        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.186        |\n",
            "|    n_updates            | 4850         |\n",
            "|    policy_gradient_loss | -0.00132     |\n",
            "|    reward               | -0.018955097 |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.565        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 487          |\n",
            "|    time_elapsed         | 2726         |\n",
            "|    total_timesteps      | 997376       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0082682185 |\n",
            "|    clip_fraction        | 0.0705       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.32        |\n",
            "|    explained_variance   | 0.765        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.237        |\n",
            "|    n_updates            | 4860         |\n",
            "|    policy_gradient_loss | -0.00424     |\n",
            "|    reward               | -0.9711392   |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.816        |\n",
            "------------------------------------------\n",
            "day: 2770, episode: 360\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 420682.80\n",
            "total_reward: 410682.80\n",
            "total_cost: 365.66\n",
            "total_trades: 3856\n",
            "Sharpe: 0.906\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 488          |\n",
            "|    time_elapsed         | 2731         |\n",
            "|    total_timesteps      | 999424       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053731548 |\n",
            "|    clip_fraction        | 0.0209       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.32        |\n",
            "|    explained_variance   | 0.523        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.397        |\n",
            "|    n_updates            | 4870         |\n",
            "|    policy_gradient_loss | -0.0036      |\n",
            "|    reward               | -1.0288157   |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.814        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 366          |\n",
            "|    iterations           | 489          |\n",
            "|    time_elapsed         | 2736         |\n",
            "|    total_timesteps      | 1001472      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0092506055 |\n",
            "|    clip_fraction        | 0.0781       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.32        |\n",
            "|    explained_variance   | 0.889        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.09         |\n",
            "|    n_updates            | 4880         |\n",
            "|    policy_gradient_loss | -0.00462     |\n",
            "|    reward               | -0.12825888  |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.228        |\n",
            "------------------------------------------\n",
            "======PPO Validation from:  2021-04-06 to  2021-07-06\n",
            "PPO Sharpe Ratio:  -0.11220621847994751\n",
            "======Best Model Retraining from:  2010-04-01 to  2021-07-06\n",
            "======Trading from:  2021-07-06 to  2021-10-04\n",
            "[[ 2.5402062e+04  1.4784787e+02  4.5230356e+02 -2.4000000e+01\n",
            "  -2.8000000e+01  3.1223810e+00  3.5672274e+00  1.5008388e+02\n",
            "   4.5665942e+02  1.3879756e+02  4.3660876e+02  6.6720070e+01\n",
            "   5.3663338e+01  9.5907761e+01  8.8577713e+01  3.7719433e+01\n",
            "   1.6090811e+01  1.4126389e+02  4.4520511e+02  1.3640550e+02\n",
            "   4.3844110e+02]]\n",
            "============================================\n",
            "turbulence_threshold:  18.962438407024404\n",
            "======Model training from:  2010-04-01 to  2021-07-06\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo\\ppo_252_1\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    fps             | 446         |\n",
            "|    iterations      | 1           |\n",
            "|    time_elapsed    | 4           |\n",
            "|    total_timesteps | 2048        |\n",
            "| train/             |             |\n",
            "|    reward          | -0.05952631 |\n",
            "------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 9            |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037666983 |\n",
            "|    clip_fraction        | 0.0211       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | -0.441       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0173      |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00181     |\n",
            "|    reward               | -0.011087143 |\n",
            "|    std                  | 0.998        |\n",
            "|    value_loss           | 0.0095       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 407         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 15          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002291395 |\n",
            "|    clip_fraction        | 0.0113      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.83       |\n",
            "|    explained_variance   | -0.0603     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0268     |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.000608   |\n",
            "|    reward               | 0.006703472 |\n",
            "|    std                  | 0.998       |\n",
            "|    value_loss           | 0.0374      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 409          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 20           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025350114 |\n",
            "|    clip_fraction        | 0.00405      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.83        |\n",
            "|    explained_variance   | -0.00557     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00136      |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.000356    |\n",
            "|    reward               | -0.26243317  |\n",
            "|    std                  | 0.993        |\n",
            "|    value_loss           | 0.047        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 24           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.00396858   |\n",
            "|    clip_fraction        | 0.0103       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.82        |\n",
            "|    explained_variance   | -0.00124     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.176        |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.000764    |\n",
            "|    reward               | -0.122421205 |\n",
            "|    std                  | 0.992        |\n",
            "|    value_loss           | 0.524        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 418          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 29           |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052415812 |\n",
            "|    clip_fraction        | 0.0375       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.82        |\n",
            "|    explained_variance   | -0.000321    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.163        |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.00232     |\n",
            "|    reward               | 0.043365918  |\n",
            "|    std                  | 0.994        |\n",
            "|    value_loss           | 0.349        |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 5\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -365452.46\n",
            "total_reward: -375452.46\n",
            "total_cost: 465.79\n",
            "total_trades: 2906\n",
            "Sharpe: 0.456\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 422          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 33           |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024325163 |\n",
            "|    clip_fraction        | 0.00791      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.82        |\n",
            "|    explained_variance   | -0.0823      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.102        |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.00212     |\n",
            "|    reward               | 0.0008644241 |\n",
            "|    std                  | 0.993        |\n",
            "|    value_loss           | 0.3          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 38           |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021625608 |\n",
            "|    clip_fraction        | 0.0121       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.82        |\n",
            "|    explained_variance   | 0.0147       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.272        |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.00128     |\n",
            "|    reward               | -0.29647684  |\n",
            "|    std                  | 0.99         |\n",
            "|    value_loss           | 0.733        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 436         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 42          |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005899703 |\n",
            "|    clip_fraction        | 0.0279      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.82       |\n",
            "|    explained_variance   | 0.042       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0786      |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.00316    |\n",
            "|    reward               | 0.023654135 |\n",
            "|    std                  | 0.99        |\n",
            "|    value_loss           | 0.231       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 441          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 46           |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017807493 |\n",
            "|    clip_fraction        | 0.0153       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.82        |\n",
            "|    explained_variance   | 0.106        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.284        |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.000426    |\n",
            "|    reward               | -0.06678245  |\n",
            "|    std                  | 0.992        |\n",
            "|    value_loss           | 0.617        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 446          |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 50           |\n",
            "|    total_timesteps      | 22528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015321609 |\n",
            "|    clip_fraction        | 0.00361      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.82        |\n",
            "|    explained_variance   | 0.717        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0204      |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -0.000106    |\n",
            "|    reward               | -0.3552889   |\n",
            "|    std                  | 0.994        |\n",
            "|    value_loss           | 0.0363       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 451          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 54           |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030846181 |\n",
            "|    clip_fraction        | 0.0021       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.83        |\n",
            "|    explained_variance   | 0.201        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.136        |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.000992    |\n",
            "|    reward               | 0.009036894  |\n",
            "|    std                  | 0.996        |\n",
            "|    value_loss           | 0.292        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 450           |\n",
            "|    iterations           | 13            |\n",
            "|    time_elapsed         | 59            |\n",
            "|    total_timesteps      | 26624         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0048710387  |\n",
            "|    clip_fraction        | 0.0243        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.83         |\n",
            "|    explained_variance   | 0.428         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.00239      |\n",
            "|    n_updates            | 120           |\n",
            "|    policy_gradient_loss | -0.00108      |\n",
            "|    reward               | -0.0113919005 |\n",
            "|    std                  | 0.995         |\n",
            "|    value_loss           | 0.078         |\n",
            "-------------------------------------------\n",
            "day: 2833, episode: 10\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -82757.15\n",
            "total_reward: -92757.15\n",
            "total_cost: 413.70\n",
            "total_trades: 2814\n",
            "Sharpe: 0.312\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 453          |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 63           |\n",
            "|    total_timesteps      | 28672        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016401369 |\n",
            "|    clip_fraction        | 0.00918      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | 0.331        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.126        |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -0.000908    |\n",
            "|    reward               | 0.019418463  |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.223        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 455          |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 67           |\n",
            "|    total_timesteps      | 30720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035792114 |\n",
            "|    clip_fraction        | 0.00645      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | 0.67         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0201      |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.00117     |\n",
            "|    reward               | 0.066218816  |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.0495       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 459          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 71           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004003387  |\n",
            "|    clip_fraction        | 0.0159       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | 0.442        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00273      |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -0.000889    |\n",
            "|    reward               | -0.054880783 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.0405       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 460          |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 75           |\n",
            "|    total_timesteps      | 34816        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054883584 |\n",
            "|    clip_fraction        | 0.0456       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.86        |\n",
            "|    explained_variance   | 0.49         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00755      |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -0.00282     |\n",
            "|    reward               | -0.032915726 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.0798       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 463          |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 79           |\n",
            "|    total_timesteps      | 36864        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0078004356 |\n",
            "|    clip_fraction        | 0.0442       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.86        |\n",
            "|    explained_variance   | 0.197        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.17         |\n",
            "|    n_updates            | 170          |\n",
            "|    policy_gradient_loss | -0.00182     |\n",
            "|    reward               | 0.039719097  |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 0.441        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 464          |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 83           |\n",
            "|    total_timesteps      | 38912        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042650527 |\n",
            "|    clip_fraction        | 0.026        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.87        |\n",
            "|    explained_variance   | 0.504        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0414       |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -0.00215     |\n",
            "|    reward               | 0.038542293  |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 0.175        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 466         |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 87          |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006607836 |\n",
            "|    clip_fraction        | 0.0301      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.87       |\n",
            "|    explained_variance   | 0.254       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0124     |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.0013     |\n",
            "|    reward               | -0.04867824 |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 0.0362      |\n",
            "-----------------------------------------\n",
            "day: 2833, episode: 15\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -177802.73\n",
            "total_reward: -187802.73\n",
            "total_cost: 426.37\n",
            "total_trades: 2938\n",
            "Sharpe: 0.204\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 468           |\n",
            "|    iterations           | 21            |\n",
            "|    time_elapsed         | 91            |\n",
            "|    total_timesteps      | 43008         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00049333484 |\n",
            "|    clip_fraction        | 0.00425       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.88         |\n",
            "|    explained_variance   | 0.544         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0695        |\n",
            "|    n_updates            | 200           |\n",
            "|    policy_gradient_loss | -0.000469     |\n",
            "|    reward               | 0.020181267   |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 0.134         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 470          |\n",
            "|    iterations           | 22           |\n",
            "|    time_elapsed         | 95           |\n",
            "|    total_timesteps      | 45056        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052033216 |\n",
            "|    clip_fraction        | 0.0485       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.89        |\n",
            "|    explained_variance   | 0.456        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0251       |\n",
            "|    n_updates            | 210          |\n",
            "|    policy_gradient_loss | -0.00477     |\n",
            "|    reward               | 0.023086729  |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.131        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 472          |\n",
            "|    iterations           | 23           |\n",
            "|    time_elapsed         | 99           |\n",
            "|    total_timesteps      | 47104        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032597107 |\n",
            "|    clip_fraction        | 0.0108       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.89        |\n",
            "|    explained_variance   | 0.68         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0174      |\n",
            "|    n_updates            | 220          |\n",
            "|    policy_gradient_loss | -0.00238     |\n",
            "|    reward               | 0.016618041  |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.0278       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 471          |\n",
            "|    iterations           | 24           |\n",
            "|    time_elapsed         | 104          |\n",
            "|    total_timesteps      | 49152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018609123 |\n",
            "|    clip_fraction        | 0.00562      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.9         |\n",
            "|    explained_variance   | 0.254        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0146      |\n",
            "|    n_updates            | 230          |\n",
            "|    policy_gradient_loss | -0.00303     |\n",
            "|    reward               | -0.009354942 |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.0397       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 470           |\n",
            "|    iterations           | 25            |\n",
            "|    time_elapsed         | 108           |\n",
            "|    total_timesteps      | 51200         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0025596377  |\n",
            "|    clip_fraction        | 0.0469        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.9          |\n",
            "|    explained_variance   | 0.531         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0166        |\n",
            "|    n_updates            | 240           |\n",
            "|    policy_gradient_loss | -0.00309      |\n",
            "|    reward               | -0.0018383629 |\n",
            "|    std                  | 1.03          |\n",
            "|    value_loss           | 0.101         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 468          |\n",
            "|    iterations           | 26           |\n",
            "|    time_elapsed         | 113          |\n",
            "|    total_timesteps      | 53248        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052705803 |\n",
            "|    clip_fraction        | 0.0118       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.89        |\n",
            "|    explained_variance   | 0.554        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0102      |\n",
            "|    n_updates            | 250          |\n",
            "|    policy_gradient_loss | -0.00207     |\n",
            "|    reward               | -0.089062065 |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.0557       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 467         |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 118         |\n",
            "|    total_timesteps      | 55296       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001083324 |\n",
            "|    clip_fraction        | 0.00234     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.89       |\n",
            "|    explained_variance   | 0.362       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.00422    |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | 0.00022     |\n",
            "|    reward               | 0.026789611 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 0.0508      |\n",
            "-----------------------------------------\n",
            "day: 2833, episode: 20\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -50871.90\n",
            "total_reward: -60871.90\n",
            "total_cost: 454.74\n",
            "total_trades: 2672\n",
            "Sharpe: 0.375\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 465          |\n",
            "|    iterations           | 28           |\n",
            "|    time_elapsed         | 123          |\n",
            "|    total_timesteps      | 57344        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017871795 |\n",
            "|    clip_fraction        | 0.0103       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.89        |\n",
            "|    explained_variance   | 0.608        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00809      |\n",
            "|    n_updates            | 270          |\n",
            "|    policy_gradient_loss | -0.000119    |\n",
            "|    reward               | -0.09187845  |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.091        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 464         |\n",
            "|    iterations           | 29          |\n",
            "|    time_elapsed         | 127         |\n",
            "|    total_timesteps      | 59392       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004160514 |\n",
            "|    clip_fraction        | 0.04        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.89       |\n",
            "|    explained_variance   | 0.717       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0256     |\n",
            "|    n_updates            | 280         |\n",
            "|    policy_gradient_loss | -0.00078    |\n",
            "|    reward               | -0.10936257 |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 0.0198      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 463         |\n",
            "|    iterations           | 30          |\n",
            "|    time_elapsed         | 132         |\n",
            "|    total_timesteps      | 61440       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004854056 |\n",
            "|    clip_fraction        | 0.0353      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.89       |\n",
            "|    explained_variance   | 0.345       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0369      |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | -0.000846   |\n",
            "|    reward               | 0.0949147   |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 0.128       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 461          |\n",
            "|    iterations           | 31           |\n",
            "|    time_elapsed         | 137          |\n",
            "|    total_timesteps      | 63488        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013545672 |\n",
            "|    clip_fraction        | 0.00244      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.9         |\n",
            "|    explained_variance   | 0.28         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0198       |\n",
            "|    n_updates            | 300          |\n",
            "|    policy_gradient_loss | -0.000378    |\n",
            "|    reward               | 0.42937666   |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.0664       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 461          |\n",
            "|    iterations           | 32           |\n",
            "|    time_elapsed         | 142          |\n",
            "|    total_timesteps      | 65536        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016916153 |\n",
            "|    clip_fraction        | 0.00684      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.9         |\n",
            "|    explained_variance   | 0.227        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.194        |\n",
            "|    n_updates            | 310          |\n",
            "|    policy_gradient_loss | -2.6e-06     |\n",
            "|    reward               | 0.005834165  |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.34         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 460         |\n",
            "|    iterations           | 33          |\n",
            "|    time_elapsed         | 146         |\n",
            "|    total_timesteps      | 67584       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004517209 |\n",
            "|    clip_fraction        | 0.0113      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.92       |\n",
            "|    explained_variance   | 0.157       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.144       |\n",
            "|    n_updates            | 320         |\n",
            "|    policy_gradient_loss | -6.62e-05   |\n",
            "|    reward               | 0.043061737 |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 0.415       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 459          |\n",
            "|    iterations           | 34           |\n",
            "|    time_elapsed         | 151          |\n",
            "|    total_timesteps      | 69632        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014465926 |\n",
            "|    clip_fraction        | 0.00303      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.92        |\n",
            "|    explained_variance   | 0.348        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0175      |\n",
            "|    n_updates            | 330          |\n",
            "|    policy_gradient_loss | 0.000407     |\n",
            "|    reward               | 0.013650367  |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.0244       |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 25\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -104889.54\n",
            "total_reward: -114889.54\n",
            "total_cost: 389.82\n",
            "total_trades: 2672\n",
            "Sharpe: -0.305\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 458          |\n",
            "|    iterations           | 35           |\n",
            "|    time_elapsed         | 156          |\n",
            "|    total_timesteps      | 71680        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059674485 |\n",
            "|    clip_fraction        | 0.0511       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.92        |\n",
            "|    explained_variance   | 0.347        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0112      |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | -0.002       |\n",
            "|    reward               | -0.008132764 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.0484       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 457          |\n",
            "|    iterations           | 36           |\n",
            "|    time_elapsed         | 161          |\n",
            "|    total_timesteps      | 73728        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030098446 |\n",
            "|    clip_fraction        | 0.0257       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.92        |\n",
            "|    explained_variance   | 0.729        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00374     |\n",
            "|    n_updates            | 350          |\n",
            "|    policy_gradient_loss | -0.000304    |\n",
            "|    reward               | 0.0239465    |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.064        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 457          |\n",
            "|    iterations           | 37           |\n",
            "|    time_elapsed         | 165          |\n",
            "|    total_timesteps      | 75776        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.003416011  |\n",
            "|    clip_fraction        | 0.0124       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.91        |\n",
            "|    explained_variance   | 0.619        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0187      |\n",
            "|    n_updates            | 360          |\n",
            "|    policy_gradient_loss | -0.000206    |\n",
            "|    reward               | -0.064157985 |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.047        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 456          |\n",
            "|    iterations           | 38           |\n",
            "|    time_elapsed         | 170          |\n",
            "|    total_timesteps      | 77824        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012077211 |\n",
            "|    clip_fraction        | 0.00269      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.9         |\n",
            "|    explained_variance   | 0.228        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0152       |\n",
            "|    n_updates            | 370          |\n",
            "|    policy_gradient_loss | -0.000245    |\n",
            "|    reward               | -0.044040523 |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.0858       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 456          |\n",
            "|    iterations           | 39           |\n",
            "|    time_elapsed         | 175          |\n",
            "|    total_timesteps      | 79872        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015052038 |\n",
            "|    clip_fraction        | 0.00171      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.9         |\n",
            "|    explained_variance   | 0.286        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0737       |\n",
            "|    n_updates            | 380          |\n",
            "|    policy_gradient_loss | -2.28e-06    |\n",
            "|    reward               | 0.03605992   |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.311        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 455         |\n",
            "|    iterations           | 40          |\n",
            "|    time_elapsed         | 179         |\n",
            "|    total_timesteps      | 81920       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.00576489  |\n",
            "|    clip_fraction        | 0.0205      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.89       |\n",
            "|    explained_variance   | 0.544       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.013      |\n",
            "|    n_updates            | 390         |\n",
            "|    policy_gradient_loss | -0.00115    |\n",
            "|    reward               | -0.18683529 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 0.0748      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 455          |\n",
            "|    iterations           | 41           |\n",
            "|    time_elapsed         | 184          |\n",
            "|    total_timesteps      | 83968        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.003524765  |\n",
            "|    clip_fraction        | 0.0185       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.89        |\n",
            "|    explained_variance   | 0.0259       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0256       |\n",
            "|    n_updates            | 400          |\n",
            "|    policy_gradient_loss | -0.00206     |\n",
            "|    reward               | -0.017168172 |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.195        |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 30\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -87961.47\n",
            "total_reward: -97961.47\n",
            "total_cost: 397.90\n",
            "total_trades: 2660\n",
            "Sharpe: 0.448\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 454          |\n",
            "|    iterations           | 42           |\n",
            "|    time_elapsed         | 189          |\n",
            "|    total_timesteps      | 86016        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059346333 |\n",
            "|    clip_fraction        | 0.0613       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.89        |\n",
            "|    explained_variance   | 0.268        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00171     |\n",
            "|    n_updates            | 410          |\n",
            "|    policy_gradient_loss | -0.00221     |\n",
            "|    reward               | -0.026746457 |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 0.087        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 453          |\n",
            "|    iterations           | 43           |\n",
            "|    time_elapsed         | 194          |\n",
            "|    total_timesteps      | 88064        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038421126 |\n",
            "|    clip_fraction        | 0.0328       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.88        |\n",
            "|    explained_variance   | 0.54         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00243     |\n",
            "|    n_updates            | 420          |\n",
            "|    policy_gradient_loss | -0.00185     |\n",
            "|    reward               | -0.011183126 |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 0.0589       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 452          |\n",
            "|    iterations           | 44           |\n",
            "|    time_elapsed         | 199          |\n",
            "|    total_timesteps      | 90112        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030451645 |\n",
            "|    clip_fraction        | 0.0121       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.88        |\n",
            "|    explained_variance   | 0.355        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0596       |\n",
            "|    n_updates            | 430          |\n",
            "|    policy_gradient_loss | -0.000704    |\n",
            "|    reward               | 0.11257301   |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 0.113        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 452         |\n",
            "|    iterations           | 45          |\n",
            "|    time_elapsed         | 203         |\n",
            "|    total_timesteps      | 92160       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006756803 |\n",
            "|    clip_fraction        | 0.0685      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.87       |\n",
            "|    explained_variance   | 0.741       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0349     |\n",
            "|    n_updates            | 440         |\n",
            "|    policy_gradient_loss | -0.0049     |\n",
            "|    reward               | 0.40048352  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 0.0146      |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 451           |\n",
            "|    iterations           | 46            |\n",
            "|    time_elapsed         | 208           |\n",
            "|    total_timesteps      | 94208         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0063256565  |\n",
            "|    clip_fraction        | 0.0397        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.85         |\n",
            "|    explained_variance   | 0.592         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0247        |\n",
            "|    n_updates            | 450           |\n",
            "|    policy_gradient_loss | -0.00291      |\n",
            "|    reward               | -0.0083145555 |\n",
            "|    std                  | 1             |\n",
            "|    value_loss           | 0.0745        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 451          |\n",
            "|    iterations           | 47           |\n",
            "|    time_elapsed         | 213          |\n",
            "|    total_timesteps      | 96256        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036283927 |\n",
            "|    clip_fraction        | 0.0127       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | 0.314        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.145        |\n",
            "|    n_updates            | 460          |\n",
            "|    policy_gradient_loss | -0.00149     |\n",
            "|    reward               | 0.055881333  |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.341        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 451          |\n",
            "|    iterations           | 48           |\n",
            "|    time_elapsed         | 217          |\n",
            "|    total_timesteps      | 98304        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0057804924 |\n",
            "|    clip_fraction        | 0.0475       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | 0.569        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0142       |\n",
            "|    n_updates            | 470          |\n",
            "|    policy_gradient_loss | -0.00273     |\n",
            "|    reward               | 0.039500847  |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.0906       |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 35\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -66172.70\n",
            "total_reward: -76172.70\n",
            "total_cost: 399.50\n",
            "total_trades: 2716\n",
            "Sharpe: -0.430\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 450           |\n",
            "|    iterations           | 49            |\n",
            "|    time_elapsed         | 222           |\n",
            "|    total_timesteps      | 100352        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0041959323  |\n",
            "|    clip_fraction        | 0.0371        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.85         |\n",
            "|    explained_variance   | 0.773         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0166       |\n",
            "|    n_updates            | 480           |\n",
            "|    policy_gradient_loss | -0.00179      |\n",
            "|    reward               | -0.0050608404 |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 0.0161        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 450          |\n",
            "|    iterations           | 50           |\n",
            "|    time_elapsed         | 227          |\n",
            "|    total_timesteps      | 102400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058818134 |\n",
            "|    clip_fraction        | 0.0601       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | 0.788        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00675     |\n",
            "|    n_updates            | 490          |\n",
            "|    policy_gradient_loss | -0.00243     |\n",
            "|    reward               | -0.018332934 |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.0269       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 450         |\n",
            "|    iterations           | 51          |\n",
            "|    time_elapsed         | 232         |\n",
            "|    total_timesteps      | 104448      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004139017 |\n",
            "|    clip_fraction        | 0.0291      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.84       |\n",
            "|    explained_variance   | 0.498       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.00268    |\n",
            "|    n_updates            | 500         |\n",
            "|    policy_gradient_loss | -0.00152    |\n",
            "|    reward               | -0.07422606 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 0.0417      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 449         |\n",
            "|    iterations           | 52          |\n",
            "|    time_elapsed         | 236         |\n",
            "|    total_timesteps      | 106496      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006067027 |\n",
            "|    clip_fraction        | 0.0377      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.84       |\n",
            "|    explained_variance   | 0.73        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0337     |\n",
            "|    n_updates            | 510         |\n",
            "|    policy_gradient_loss | -0.00302    |\n",
            "|    reward               | 0.03673217  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 0.0131      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 449          |\n",
            "|    iterations           | 53           |\n",
            "|    time_elapsed         | 241          |\n",
            "|    total_timesteps      | 108544       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006017615  |\n",
            "|    clip_fraction        | 0.0644       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | 0.644        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.019       |\n",
            "|    n_updates            | 520          |\n",
            "|    policy_gradient_loss | -0.00388     |\n",
            "|    reward               | -0.014846699 |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.0221       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 449          |\n",
            "|    iterations           | 54           |\n",
            "|    time_elapsed         | 246          |\n",
            "|    total_timesteps      | 110592       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005513978  |\n",
            "|    clip_fraction        | 0.0448       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.83        |\n",
            "|    explained_variance   | 0.403        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00526     |\n",
            "|    n_updates            | 530          |\n",
            "|    policy_gradient_loss | -0.00271     |\n",
            "|    reward               | -0.009573597 |\n",
            "|    std                  | 0.994        |\n",
            "|    value_loss           | 0.0535       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 448         |\n",
            "|    iterations           | 55          |\n",
            "|    time_elapsed         | 250         |\n",
            "|    total_timesteps      | 112640      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003764643 |\n",
            "|    clip_fraction        | 0.0499      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.83       |\n",
            "|    explained_variance   | 0.0933      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0225      |\n",
            "|    n_updates            | 540         |\n",
            "|    policy_gradient_loss | -0.00348    |\n",
            "|    reward               | 0.026568675 |\n",
            "|    std                  | 0.999       |\n",
            "|    value_loss           | 0.0897      |\n",
            "-----------------------------------------\n",
            "day: 2833, episode: 40\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -82748.31\n",
            "total_reward: -92748.31\n",
            "total_cost: 407.82\n",
            "total_trades: 2740\n",
            "Sharpe: 0.148\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 448          |\n",
            "|    iterations           | 56           |\n",
            "|    time_elapsed         | 255          |\n",
            "|    total_timesteps      | 114688       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040602493 |\n",
            "|    clip_fraction        | 0.0119       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.83        |\n",
            "|    explained_variance   | 0.595        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0369      |\n",
            "|    n_updates            | 550          |\n",
            "|    policy_gradient_loss | -0.00102     |\n",
            "|    reward               | 0.0041174814 |\n",
            "|    std                  | 0.993        |\n",
            "|    value_loss           | 0.00866      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 447          |\n",
            "|    iterations           | 57           |\n",
            "|    time_elapsed         | 260          |\n",
            "|    total_timesteps      | 116736       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052529504 |\n",
            "|    clip_fraction        | 0.0543       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.82        |\n",
            "|    explained_variance   | 0.318        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00261     |\n",
            "|    n_updates            | 560          |\n",
            "|    policy_gradient_loss | -0.00311     |\n",
            "|    reward               | 0.012634556  |\n",
            "|    std                  | 0.992        |\n",
            "|    value_loss           | 0.0422       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 447          |\n",
            "|    iterations           | 58           |\n",
            "|    time_elapsed         | 265          |\n",
            "|    total_timesteps      | 118784       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047957767 |\n",
            "|    clip_fraction        | 0.0201       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.82        |\n",
            "|    explained_variance   | 0.189        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.044        |\n",
            "|    n_updates            | 570          |\n",
            "|    policy_gradient_loss | -0.000953    |\n",
            "|    reward               | 0.09183775   |\n",
            "|    std                  | 0.991        |\n",
            "|    value_loss           | 0.121        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 447          |\n",
            "|    iterations           | 59           |\n",
            "|    time_elapsed         | 270          |\n",
            "|    total_timesteps      | 120832       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030654727 |\n",
            "|    clip_fraction        | 0.0106       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.81        |\n",
            "|    explained_variance   | 0.189        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0466       |\n",
            "|    n_updates            | 580          |\n",
            "|    policy_gradient_loss | -0.000514    |\n",
            "|    reward               | 0.0795157    |\n",
            "|    std                  | 0.987        |\n",
            "|    value_loss           | 0.114        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 446          |\n",
            "|    iterations           | 60           |\n",
            "|    time_elapsed         | 275          |\n",
            "|    total_timesteps      | 122880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011640724 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.81        |\n",
            "|    explained_variance   | 0.418        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0237       |\n",
            "|    n_updates            | 590          |\n",
            "|    policy_gradient_loss | -0.000236    |\n",
            "|    reward               | -0.03380837  |\n",
            "|    std                  | 0.984        |\n",
            "|    value_loss           | 0.0636       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 446          |\n",
            "|    iterations           | 61           |\n",
            "|    time_elapsed         | 279          |\n",
            "|    total_timesteps      | 124928       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005583388  |\n",
            "|    clip_fraction        | 0.0378       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.81        |\n",
            "|    explained_variance   | 0.388        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.028        |\n",
            "|    n_updates            | 600          |\n",
            "|    policy_gradient_loss | -0.00205     |\n",
            "|    reward               | -0.018326508 |\n",
            "|    std                  | 0.988        |\n",
            "|    value_loss           | 0.0787       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 446         |\n",
            "|    iterations           | 62          |\n",
            "|    time_elapsed         | 284         |\n",
            "|    total_timesteps      | 126976      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005247646 |\n",
            "|    clip_fraction        | 0.0583      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.81       |\n",
            "|    explained_variance   | 0.101       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0256      |\n",
            "|    n_updates            | 610         |\n",
            "|    policy_gradient_loss | -0.00427    |\n",
            "|    reward               | 0.05793553  |\n",
            "|    std                  | 0.989       |\n",
            "|    value_loss           | 0.167       |\n",
            "-----------------------------------------\n",
            "day: 2833, episode: 45\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -200248.26\n",
            "total_reward: -210248.26\n",
            "total_cost: 485.22\n",
            "total_trades: 2904\n",
            "Sharpe: 0.191\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 446          |\n",
            "|    iterations           | 63           |\n",
            "|    time_elapsed         | 289          |\n",
            "|    total_timesteps      | 129024       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024130072 |\n",
            "|    clip_fraction        | 0.0134       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.82        |\n",
            "|    explained_variance   | 0.368        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0157       |\n",
            "|    n_updates            | 620          |\n",
            "|    policy_gradient_loss | -0.000826    |\n",
            "|    reward               | -0.063150935 |\n",
            "|    std                  | 0.992        |\n",
            "|    value_loss           | 0.0727       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 445          |\n",
            "|    iterations           | 64           |\n",
            "|    time_elapsed         | 294          |\n",
            "|    total_timesteps      | 131072       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044398345 |\n",
            "|    clip_fraction        | 0.0117       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.82        |\n",
            "|    explained_variance   | 0.171        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0929       |\n",
            "|    n_updates            | 630          |\n",
            "|    policy_gradient_loss | -0.00139     |\n",
            "|    reward               | 0.0057766917 |\n",
            "|    std                  | 0.995        |\n",
            "|    value_loss           | 0.272        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 445          |\n",
            "|    iterations           | 65           |\n",
            "|    time_elapsed         | 298          |\n",
            "|    total_timesteps      | 133120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0074050305 |\n",
            "|    clip_fraction        | 0.0217       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.82        |\n",
            "|    explained_variance   | 0.126        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.182        |\n",
            "|    n_updates            | 640          |\n",
            "|    policy_gradient_loss | -0.00078     |\n",
            "|    reward               | -1.4723328   |\n",
            "|    std                  | 0.99         |\n",
            "|    value_loss           | 0.378        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 445         |\n",
            "|    iterations           | 66          |\n",
            "|    time_elapsed         | 303         |\n",
            "|    total_timesteps      | 135168      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002912715 |\n",
            "|    clip_fraction        | 0.00801     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.82       |\n",
            "|    explained_variance   | 0.037       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.187       |\n",
            "|    n_updates            | 650         |\n",
            "|    policy_gradient_loss | -0.00161    |\n",
            "|    reward               | 0.25377873  |\n",
            "|    std                  | 0.992       |\n",
            "|    value_loss           | 0.527       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 445          |\n",
            "|    iterations           | 67           |\n",
            "|    time_elapsed         | 308          |\n",
            "|    total_timesteps      | 137216       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047813742 |\n",
            "|    clip_fraction        | 0.0376       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.82        |\n",
            "|    explained_variance   | 0.413        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0219      |\n",
            "|    n_updates            | 660          |\n",
            "|    policy_gradient_loss | -0.00328     |\n",
            "|    reward               | 0.0466825    |\n",
            "|    std                  | 0.994        |\n",
            "|    value_loss           | 0.0819       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 445         |\n",
            "|    iterations           | 68          |\n",
            "|    time_elapsed         | 312         |\n",
            "|    total_timesteps      | 139264      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008653177 |\n",
            "|    clip_fraction        | 0.0879      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.83       |\n",
            "|    explained_variance   | 0.158       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.279       |\n",
            "|    n_updates            | 670         |\n",
            "|    policy_gradient_loss | -0.00612    |\n",
            "|    reward               | -0.07072038 |\n",
            "|    std                  | 0.996       |\n",
            "|    value_loss           | 0.512       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 444         |\n",
            "|    iterations           | 69          |\n",
            "|    time_elapsed         | 317         |\n",
            "|    total_timesteps      | 141312      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.00710642  |\n",
            "|    clip_fraction        | 0.0667      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.84       |\n",
            "|    explained_variance   | 0.0754      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.175       |\n",
            "|    n_updates            | 680         |\n",
            "|    policy_gradient_loss | -0.00546    |\n",
            "|    reward               | -0.22315861 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 0.646       |\n",
            "-----------------------------------------\n",
            "day: 2833, episode: 50\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -252337.07\n",
            "total_reward: -262337.07\n",
            "total_cost: 522.30\n",
            "total_trades: 3036\n",
            "Sharpe: 0.241\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 443          |\n",
            "|    iterations           | 70           |\n",
            "|    time_elapsed         | 323          |\n",
            "|    total_timesteps      | 143360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0074262368 |\n",
            "|    clip_fraction        | 0.0368       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | 0.368        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0175       |\n",
            "|    n_updates            | 690          |\n",
            "|    policy_gradient_loss | -0.00171     |\n",
            "|    reward               | -0.18603703  |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.17         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 443          |\n",
            "|    iterations           | 71           |\n",
            "|    time_elapsed         | 327          |\n",
            "|    total_timesteps      | 145408       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024860362 |\n",
            "|    clip_fraction        | 0.029        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | 0.276        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.121        |\n",
            "|    n_updates            | 700          |\n",
            "|    policy_gradient_loss | -0.00144     |\n",
            "|    reward               | -0.032473583 |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.418        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 442           |\n",
            "|    iterations           | 72            |\n",
            "|    time_elapsed         | 332           |\n",
            "|    total_timesteps      | 147456        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0013935892  |\n",
            "|    clip_fraction        | 0.000146      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.84         |\n",
            "|    explained_variance   | 0.085         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.369         |\n",
            "|    n_updates            | 710           |\n",
            "|    policy_gradient_loss | -0.000155     |\n",
            "|    reward               | -0.0029685353 |\n",
            "|    std                  | 1             |\n",
            "|    value_loss           | 1.07          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 442          |\n",
            "|    iterations           | 73           |\n",
            "|    time_elapsed         | 337          |\n",
            "|    total_timesteps      | 149504       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012706851 |\n",
            "|    clip_fraction        | 0.0162       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | -0.0146      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.745        |\n",
            "|    n_updates            | 720          |\n",
            "|    policy_gradient_loss | -0.000584    |\n",
            "|    reward               | 0.13123833   |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.1          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 442         |\n",
            "|    iterations           | 74          |\n",
            "|    time_elapsed         | 342         |\n",
            "|    total_timesteps      | 151552      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003812923 |\n",
            "|    clip_fraction        | 0.0165      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.85       |\n",
            "|    explained_variance   | 0.0484      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0269      |\n",
            "|    n_updates            | 730         |\n",
            "|    policy_gradient_loss | -0.00124    |\n",
            "|    reward               | -0.07071203 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 0.151       |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 442           |\n",
            "|    iterations           | 75            |\n",
            "|    time_elapsed         | 347           |\n",
            "|    total_timesteps      | 153600        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0072188005  |\n",
            "|    clip_fraction        | 0.0542        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.85         |\n",
            "|    explained_variance   | -0.00458      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.503         |\n",
            "|    n_updates            | 740           |\n",
            "|    policy_gradient_loss | -0.00306      |\n",
            "|    reward               | -0.0071083843 |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 1.09          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 441          |\n",
            "|    iterations           | 76           |\n",
            "|    time_elapsed         | 352          |\n",
            "|    total_timesteps      | 155648       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052437284 |\n",
            "|    clip_fraction        | 0.0354       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | -0.00298     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.602        |\n",
            "|    n_updates            | 750          |\n",
            "|    policy_gradient_loss | -0.00115     |\n",
            "|    reward               | -0.29435933  |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 1.51         |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 55\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -446351.90\n",
            "total_reward: -456351.90\n",
            "total_cost: 731.74\n",
            "total_trades: 3508\n",
            "Sharpe: -0.298\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 441         |\n",
            "|    iterations           | 77          |\n",
            "|    time_elapsed         | 356         |\n",
            "|    total_timesteps      | 157696      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002292844 |\n",
            "|    clip_fraction        | 0.0127      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.86       |\n",
            "|    explained_variance   | 0.0326      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.47        |\n",
            "|    n_updates            | 760         |\n",
            "|    policy_gradient_loss | -0.00019    |\n",
            "|    reward               | 0.2550057   |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 1.04        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 441          |\n",
            "|    iterations           | 78           |\n",
            "|    time_elapsed         | 361          |\n",
            "|    total_timesteps      | 159744       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028560339 |\n",
            "|    clip_fraction        | 0.0278       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.88        |\n",
            "|    explained_variance   | -0.0156      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.209        |\n",
            "|    n_updates            | 770          |\n",
            "|    policy_gradient_loss | -0.00122     |\n",
            "|    reward               | 0.036340445  |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.675        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 441         |\n",
            "|    iterations           | 79          |\n",
            "|    time_elapsed         | 366         |\n",
            "|    total_timesteps      | 161792      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.0038392   |\n",
            "|    clip_fraction        | 0.0484      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.9        |\n",
            "|    explained_variance   | 3.44e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.763       |\n",
            "|    n_updates            | 780         |\n",
            "|    policy_gradient_loss | -0.00166    |\n",
            "|    reward               | 0.011067091 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 1.73        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 441         |\n",
            "|    iterations           | 80          |\n",
            "|    time_elapsed         | 371         |\n",
            "|    total_timesteps      | 163840      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003665094 |\n",
            "|    clip_fraction        | 0.0458      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.91       |\n",
            "|    explained_variance   | 4.21e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.588       |\n",
            "|    n_updates            | 790         |\n",
            "|    policy_gradient_loss | -0.00214    |\n",
            "|    reward               | 0.41073442  |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 1.8         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 440          |\n",
            "|    iterations           | 81           |\n",
            "|    time_elapsed         | 376          |\n",
            "|    total_timesteps      | 165888       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052965353 |\n",
            "|    clip_fraction        | 0.043        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.93        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.249        |\n",
            "|    n_updates            | 800          |\n",
            "|    policy_gradient_loss | -0.00167     |\n",
            "|    reward               | 0.034579646  |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.42         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 440           |\n",
            "|    iterations           | 82            |\n",
            "|    time_elapsed         | 381           |\n",
            "|    total_timesteps      | 167936        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.004626235   |\n",
            "|    clip_fraction        | 0.0135        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.92         |\n",
            "|    explained_variance   | 5.17e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.736         |\n",
            "|    n_updates            | 810           |\n",
            "|    policy_gradient_loss | -0.000287     |\n",
            "|    reward               | -0.0020969147 |\n",
            "|    std                  | 1.04          |\n",
            "|    value_loss           | 1.54          |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 440         |\n",
            "|    iterations           | 83          |\n",
            "|    time_elapsed         | 385         |\n",
            "|    total_timesteps      | 169984      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006671257 |\n",
            "|    clip_fraction        | 0.0445      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.92       |\n",
            "|    explained_variance   | 4.61e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.32        |\n",
            "|    n_updates            | 820         |\n",
            "|    policy_gradient_loss | -0.00259    |\n",
            "|    reward               | -0.37020758 |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 2.34        |\n",
            "-----------------------------------------\n",
            "day: 2833, episode: 60\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -454646.98\n",
            "total_reward: -464646.98\n",
            "total_cost: 620.54\n",
            "total_trades: 3406\n",
            "Sharpe: -0.013\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 440          |\n",
            "|    iterations           | 84           |\n",
            "|    time_elapsed         | 390          |\n",
            "|    total_timesteps      | 172032       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028456147 |\n",
            "|    clip_fraction        | 0.0169       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.91        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.64         |\n",
            "|    n_updates            | 830          |\n",
            "|    policy_gradient_loss | -0.00127     |\n",
            "|    reward               | 0.27825376   |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 1.65         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 439          |\n",
            "|    iterations           | 85           |\n",
            "|    time_elapsed         | 395          |\n",
            "|    total_timesteps      | 174080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0063425405 |\n",
            "|    clip_fraction        | 0.0536       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.91        |\n",
            "|    explained_variance   | 3.92e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0627       |\n",
            "|    n_updates            | 840          |\n",
            "|    policy_gradient_loss | -0.00304     |\n",
            "|    reward               | 0.10239428   |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.221        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 439           |\n",
            "|    iterations           | 86            |\n",
            "|    time_elapsed         | 400           |\n",
            "|    total_timesteps      | 176128        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0018246612  |\n",
            "|    clip_fraction        | 0.00488       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.9          |\n",
            "|    explained_variance   | 3.52e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.638         |\n",
            "|    n_updates            | 850           |\n",
            "|    policy_gradient_loss | -0.000541     |\n",
            "|    reward               | -0.0028014763 |\n",
            "|    std                  | 1.03          |\n",
            "|    value_loss           | 1.62          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 439          |\n",
            "|    iterations           | 87           |\n",
            "|    time_elapsed         | 405          |\n",
            "|    total_timesteps      | 178176       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039576716 |\n",
            "|    clip_fraction        | 0.0216       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.9         |\n",
            "|    explained_variance   | 4.98e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.753        |\n",
            "|    n_updates            | 860          |\n",
            "|    policy_gradient_loss | -0.00122     |\n",
            "|    reward               | -0.42599335  |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 1.39         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 439         |\n",
            "|    iterations           | 88          |\n",
            "|    time_elapsed         | 410         |\n",
            "|    total_timesteps      | 180224      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004662823 |\n",
            "|    clip_fraction        | 0.0589      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.89       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0904      |\n",
            "|    n_updates            | 870         |\n",
            "|    policy_gradient_loss | -0.00364    |\n",
            "|    reward               | -0.09388946 |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 0.299       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 439          |\n",
            "|    iterations           | 89           |\n",
            "|    time_elapsed         | 414          |\n",
            "|    total_timesteps      | 182272       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040440084 |\n",
            "|    clip_fraction        | 0.0261       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.89        |\n",
            "|    explained_variance   | 1.28e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.329        |\n",
            "|    n_updates            | 880          |\n",
            "|    policy_gradient_loss | -0.00128     |\n",
            "|    reward               | 0.011609984  |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.765        |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 65\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -307267.49\n",
            "total_reward: -317267.49\n",
            "total_cost: 562.93\n",
            "total_trades: 3052\n",
            "Sharpe: 0.002\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 439          |\n",
            "|    iterations           | 90           |\n",
            "|    time_elapsed         | 419          |\n",
            "|    total_timesteps      | 184320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.001722274  |\n",
            "|    clip_fraction        | 0.00518      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.92        |\n",
            "|    explained_variance   | 4.78e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.467        |\n",
            "|    n_updates            | 890          |\n",
            "|    policy_gradient_loss | -0.000413    |\n",
            "|    reward               | 0.0033260388 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.764        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 439          |\n",
            "|    iterations           | 91           |\n",
            "|    time_elapsed         | 424          |\n",
            "|    total_timesteps      | 186368       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042684064 |\n",
            "|    clip_fraction        | 0.0318       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.93        |\n",
            "|    explained_variance   | 3.39e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.371        |\n",
            "|    n_updates            | 900          |\n",
            "|    policy_gradient_loss | -0.00189     |\n",
            "|    reward               | -0.19952625  |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.822        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 439          |\n",
            "|    iterations           | 92           |\n",
            "|    time_elapsed         | 429          |\n",
            "|    total_timesteps      | 188416       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0068622013 |\n",
            "|    clip_fraction        | 0.0487       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.93        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0114      |\n",
            "|    n_updates            | 910          |\n",
            "|    policy_gradient_loss | -0.00362     |\n",
            "|    reward               | -0.000729599 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.0836       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 438          |\n",
            "|    iterations           | 93           |\n",
            "|    time_elapsed         | 434          |\n",
            "|    total_timesteps      | 190464       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034628608 |\n",
            "|    clip_fraction        | 0.0178       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.94        |\n",
            "|    explained_variance   | 5.55e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.228        |\n",
            "|    n_updates            | 920          |\n",
            "|    policy_gradient_loss | -0.000922    |\n",
            "|    reward               | -0.026183035 |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.487        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 438           |\n",
            "|    iterations           | 94            |\n",
            "|    time_elapsed         | 439           |\n",
            "|    total_timesteps      | 192512        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00051533594 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.95         |\n",
            "|    explained_variance   | 1.7e-05       |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.119         |\n",
            "|    n_updates            | 930           |\n",
            "|    policy_gradient_loss | 0.000152      |\n",
            "|    reward               | 0.08678455    |\n",
            "|    std                  | 1.06          |\n",
            "|    value_loss           | 0.551         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 438          |\n",
            "|    iterations           | 95           |\n",
            "|    time_elapsed         | 443          |\n",
            "|    total_timesteps      | 194560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040814085 |\n",
            "|    clip_fraction        | 0.0211       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.94        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.249        |\n",
            "|    n_updates            | 940          |\n",
            "|    policy_gradient_loss | -0.00112     |\n",
            "|    reward               | 0.15132675   |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.476        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 438          |\n",
            "|    iterations           | 96           |\n",
            "|    time_elapsed         | 448          |\n",
            "|    total_timesteps      | 196608       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004190667  |\n",
            "|    clip_fraction        | 0.037        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.94        |\n",
            "|    explained_variance   | -4.77e-07    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.19         |\n",
            "|    n_updates            | 950          |\n",
            "|    policy_gradient_loss | -0.00158     |\n",
            "|    reward               | -0.020221027 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.247        |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 70\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -286226.62\n",
            "total_reward: -296226.62\n",
            "total_cost: 527.86\n",
            "total_trades: 3016\n",
            "Sharpe: -0.304\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 437          |\n",
            "|    iterations           | 97           |\n",
            "|    time_elapsed         | 453          |\n",
            "|    total_timesteps      | 198656       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.003344533  |\n",
            "|    clip_fraction        | 0.0112       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.93        |\n",
            "|    explained_variance   | 1.91e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.345        |\n",
            "|    n_updates            | 960          |\n",
            "|    policy_gradient_loss | -0.00024     |\n",
            "|    reward               | 0.0039773965 |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.629        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 437         |\n",
            "|    iterations           | 98          |\n",
            "|    time_elapsed         | 458         |\n",
            "|    total_timesteps      | 200704      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006803281 |\n",
            "|    clip_fraction        | 0.0741      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.92       |\n",
            "|    explained_variance   | 6.91e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.33        |\n",
            "|    n_updates            | 970         |\n",
            "|    policy_gradient_loss | -0.00495    |\n",
            "|    reward               | -0.2357877  |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 0.683       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 437          |\n",
            "|    iterations           | 99           |\n",
            "|    time_elapsed         | 462          |\n",
            "|    total_timesteps      | 202752       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0074834577 |\n",
            "|    clip_fraction        | 0.049        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.92        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0486       |\n",
            "|    n_updates            | 980          |\n",
            "|    policy_gradient_loss | -0.00356     |\n",
            "|    reward               | 0.023744578  |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.0972       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 437           |\n",
            "|    iterations           | 100           |\n",
            "|    time_elapsed         | 467           |\n",
            "|    total_timesteps      | 204800        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.004464692   |\n",
            "|    clip_fraction        | 0.0309        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.92         |\n",
            "|    explained_variance   | 6.07e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.112         |\n",
            "|    n_updates            | 990           |\n",
            "|    policy_gradient_loss | -0.00177      |\n",
            "|    reward               | -0.0049782875 |\n",
            "|    std                  | 1.04          |\n",
            "|    value_loss           | 0.29          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 437          |\n",
            "|    iterations           | 101          |\n",
            "|    time_elapsed         | 472          |\n",
            "|    total_timesteps      | 206848       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046293167 |\n",
            "|    clip_fraction        | 0.0361       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.92        |\n",
            "|    explained_variance   | 6.7e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.272        |\n",
            "|    n_updates            | 1000         |\n",
            "|    policy_gradient_loss | -0.00241     |\n",
            "|    reward               | 0.107898146  |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.549        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 437          |\n",
            "|    iterations           | 102          |\n",
            "|    time_elapsed         | 477          |\n",
            "|    total_timesteps      | 208896       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038118758 |\n",
            "|    clip_fraction        | 0.0102       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.9         |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.16         |\n",
            "|    n_updates            | 1010         |\n",
            "|    policy_gradient_loss | -0.00131     |\n",
            "|    reward               | -0.4349667   |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.373        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 437          |\n",
            "|    iterations           | 103          |\n",
            "|    time_elapsed         | 481          |\n",
            "|    total_timesteps      | 210944       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039889286 |\n",
            "|    clip_fraction        | 0.0126       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.9         |\n",
            "|    explained_variance   | 0.00014      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00447     |\n",
            "|    n_updates            | 1020         |\n",
            "|    policy_gradient_loss | -0.000647    |\n",
            "|    reward               | 0.015018799  |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.0538       |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 75\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -230667.19\n",
            "total_reward: -240667.19\n",
            "total_cost: 520.80\n",
            "total_trades: 3002\n",
            "Sharpe: 0.211\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 437          |\n",
            "|    iterations           | 104          |\n",
            "|    time_elapsed         | 486          |\n",
            "|    total_timesteps      | 212992       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027786926 |\n",
            "|    clip_fraction        | 0.00815      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.9         |\n",
            "|    explained_variance   | 5.73e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.169        |\n",
            "|    n_updates            | 1030         |\n",
            "|    policy_gradient_loss | -0.000134    |\n",
            "|    reward               | 0.0057750954 |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.42         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 437          |\n",
            "|    iterations           | 105          |\n",
            "|    time_elapsed         | 491          |\n",
            "|    total_timesteps      | 215040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035436782 |\n",
            "|    clip_fraction        | 0.0101       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.9         |\n",
            "|    explained_variance   | 6.42e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.211        |\n",
            "|    n_updates            | 1040         |\n",
            "|    policy_gradient_loss | -0.000757    |\n",
            "|    reward               | 0.91778296   |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.464        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 437          |\n",
            "|    iterations           | 106          |\n",
            "|    time_elapsed         | 495          |\n",
            "|    total_timesteps      | 217088       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042758537 |\n",
            "|    clip_fraction        | 0.00767      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.89        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0782       |\n",
            "|    n_updates            | 1050         |\n",
            "|    policy_gradient_loss | -0.000448    |\n",
            "|    reward               | -0.108866125 |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.216        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 437          |\n",
            "|    iterations           | 107          |\n",
            "|    time_elapsed         | 500          |\n",
            "|    total_timesteps      | 219136       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041395747 |\n",
            "|    clip_fraction        | 0.0274       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.88        |\n",
            "|    explained_variance   | 3.25e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.15         |\n",
            "|    n_updates            | 1060         |\n",
            "|    policy_gradient_loss | -0.00124     |\n",
            "|    reward               | -0.012620243 |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 0.408        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 436          |\n",
            "|    iterations           | 108          |\n",
            "|    time_elapsed         | 506          |\n",
            "|    total_timesteps      | 221184       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005827738  |\n",
            "|    clip_fraction        | 0.0518       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.88        |\n",
            "|    explained_variance   | 4.76e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.254        |\n",
            "|    n_updates            | 1070         |\n",
            "|    policy_gradient_loss | -0.00384     |\n",
            "|    reward               | -0.006186673 |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 0.614        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 436          |\n",
            "|    iterations           | 109          |\n",
            "|    time_elapsed         | 511          |\n",
            "|    total_timesteps      | 223232       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061367056 |\n",
            "|    clip_fraction        | 0.0599       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.88        |\n",
            "|    explained_variance   | 6.35e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.389        |\n",
            "|    n_updates            | 1080         |\n",
            "|    policy_gradient_loss | -0.00374     |\n",
            "|    reward               | -0.03425296  |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 0.685        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 436          |\n",
            "|    iterations           | 110          |\n",
            "|    time_elapsed         | 515          |\n",
            "|    total_timesteps      | 225280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049200067 |\n",
            "|    clip_fraction        | 0.0358       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.88        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0088       |\n",
            "|    n_updates            | 1090         |\n",
            "|    policy_gradient_loss | -0.00308     |\n",
            "|    reward               | -0.12692589  |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 0.113        |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 80\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -263738.45\n",
            "total_reward: -273738.45\n",
            "total_cost: 543.30\n",
            "total_trades: 3024\n",
            "Sharpe: -0.038\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 436           |\n",
            "|    iterations           | 111           |\n",
            "|    time_elapsed         | 520           |\n",
            "|    total_timesteps      | 227328        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0032757996  |\n",
            "|    clip_fraction        | 0.0103        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.88         |\n",
            "|    explained_variance   | 2.53e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.298         |\n",
            "|    n_updates            | 1100          |\n",
            "|    policy_gradient_loss | -0.000598     |\n",
            "|    reward               | -0.0039630756 |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 0.698         |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 436         |\n",
            "|    iterations           | 112         |\n",
            "|    time_elapsed         | 525         |\n",
            "|    total_timesteps      | 229376      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005577065 |\n",
            "|    clip_fraction        | 0.0221      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.87       |\n",
            "|    explained_variance   | 4.27e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.272       |\n",
            "|    n_updates            | 1110        |\n",
            "|    policy_gradient_loss | -0.0012     |\n",
            "|    reward               | 0.25740862  |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 0.608       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 436         |\n",
            "|    iterations           | 113         |\n",
            "|    time_elapsed         | 530         |\n",
            "|    total_timesteps      | 231424      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005271656 |\n",
            "|    clip_fraction        | 0.0449      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.87       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.321       |\n",
            "|    n_updates            | 1120        |\n",
            "|    policy_gradient_loss | -0.00359    |\n",
            "|    reward               | 0.22584061  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 0.609       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 436         |\n",
            "|    iterations           | 114         |\n",
            "|    time_elapsed         | 535         |\n",
            "|    total_timesteps      | 233472      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006092225 |\n",
            "|    clip_fraction        | 0.0491      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.86       |\n",
            "|    explained_variance   | 8.43e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0865      |\n",
            "|    n_updates            | 1130        |\n",
            "|    policy_gradient_loss | -0.00263    |\n",
            "|    reward               | 0.058724172 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 0.315       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 436          |\n",
            "|    iterations           | 115          |\n",
            "|    time_elapsed         | 539          |\n",
            "|    total_timesteps      | 235520       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036793815 |\n",
            "|    clip_fraction        | 0.0214       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | 3.8e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.599        |\n",
            "|    n_updates            | 1140         |\n",
            "|    policy_gradient_loss | -0.00129     |\n",
            "|    reward               | -0.01110486  |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.976        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 436          |\n",
            "|    iterations           | 116          |\n",
            "|    time_elapsed         | 544          |\n",
            "|    total_timesteps      | 237568       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071320636 |\n",
            "|    clip_fraction        | 0.0716       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | 4.79e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.399        |\n",
            "|    n_updates            | 1150         |\n",
            "|    policy_gradient_loss | -0.00477     |\n",
            "|    reward               | -0.08068882  |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.06         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 436         |\n",
            "|    iterations           | 117         |\n",
            "|    time_elapsed         | 549         |\n",
            "|    total_timesteps      | 239616      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005628868 |\n",
            "|    clip_fraction        | 0.0388      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.85       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0845      |\n",
            "|    n_updates            | 1160        |\n",
            "|    policy_gradient_loss | -0.00238    |\n",
            "|    reward               | 0.046723437 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 0.364       |\n",
            "-----------------------------------------\n",
            "day: 2833, episode: 85\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -371861.00\n",
            "total_reward: -381861.00\n",
            "total_cost: 615.01\n",
            "total_trades: 3284\n",
            "Sharpe: -0.181\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 436         |\n",
            "|    iterations           | 118         |\n",
            "|    time_elapsed         | 553         |\n",
            "|    total_timesteps      | 241664      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005037945 |\n",
            "|    clip_fraction        | 0.0259      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.86       |\n",
            "|    explained_variance   | 3.99e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.465       |\n",
            "|    n_updates            | 1170        |\n",
            "|    policy_gradient_loss | -0.00177    |\n",
            "|    reward               | 0.015015112 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 1.09        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 436          |\n",
            "|    iterations           | 119          |\n",
            "|    time_elapsed         | 558          |\n",
            "|    total_timesteps      | 243712       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060371463 |\n",
            "|    clip_fraction        | 0.0523       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.86        |\n",
            "|    explained_variance   | 4.13e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.545        |\n",
            "|    n_updates            | 1180         |\n",
            "|    policy_gradient_loss | -0.00403     |\n",
            "|    reward               | -0.53660053  |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 1.18         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 436          |\n",
            "|    iterations           | 120          |\n",
            "|    time_elapsed         | 563          |\n",
            "|    total_timesteps      | 245760       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031568706 |\n",
            "|    clip_fraction        | 0.0169       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.406        |\n",
            "|    n_updates            | 1190         |\n",
            "|    policy_gradient_loss | -0.000988    |\n",
            "|    reward               | 0.22231525   |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.908        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 436         |\n",
            "|    iterations           | 121         |\n",
            "|    time_elapsed         | 567         |\n",
            "|    total_timesteps      | 247808      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.00566924  |\n",
            "|    clip_fraction        | 0.0281      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.83       |\n",
            "|    explained_variance   | 0.000101    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0108      |\n",
            "|    n_updates            | 1200        |\n",
            "|    policy_gradient_loss | -0.00195    |\n",
            "|    reward               | -0.05073581 |\n",
            "|    std                  | 0.994       |\n",
            "|    value_loss           | 0.0879      |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 436           |\n",
            "|    iterations           | 122           |\n",
            "|    time_elapsed         | 572           |\n",
            "|    total_timesteps      | 249856        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.004548057   |\n",
            "|    clip_fraction        | 0.038         |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.83         |\n",
            "|    explained_variance   | 4.15e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.354         |\n",
            "|    n_updates            | 1210          |\n",
            "|    policy_gradient_loss | -0.00225      |\n",
            "|    reward               | -0.0018894188 |\n",
            "|    std                  | 0.999         |\n",
            "|    value_loss           | 0.898         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 436          |\n",
            "|    iterations           | 123          |\n",
            "|    time_elapsed         | 577          |\n",
            "|    total_timesteps      | 251904       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027795932 |\n",
            "|    clip_fraction        | 0.00937      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | 4.05e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.381        |\n",
            "|    n_updates            | 1220         |\n",
            "|    policy_gradient_loss | -0.000655    |\n",
            "|    reward               | -0.49225563  |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.11         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 436          |\n",
            "|    iterations           | 124          |\n",
            "|    time_elapsed         | 581          |\n",
            "|    total_timesteps      | 253952       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040936144 |\n",
            "|    clip_fraction        | 0.0273       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.83        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.541        |\n",
            "|    n_updates            | 1230         |\n",
            "|    policy_gradient_loss | -0.00149     |\n",
            "|    reward               | -0.06586253  |\n",
            "|    std                  | 0.998        |\n",
            "|    value_loss           | 0.729        |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 90\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -393408.61\n",
            "total_reward: -403408.61\n",
            "total_cost: 621.19\n",
            "total_trades: 3346\n",
            "Sharpe: 0.436\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 436          |\n",
            "|    iterations           | 125          |\n",
            "|    time_elapsed         | 586          |\n",
            "|    total_timesteps      | 256000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031448486 |\n",
            "|    clip_fraction        | 0.0109       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.83        |\n",
            "|    explained_variance   | 7.04e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.533        |\n",
            "|    n_updates            | 1240         |\n",
            "|    policy_gradient_loss | -0.000174    |\n",
            "|    reward               | -0.017316123 |\n",
            "|    std                  | 0.997        |\n",
            "|    value_loss           | 0.662        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 436          |\n",
            "|    iterations           | 126          |\n",
            "|    time_elapsed         | 591          |\n",
            "|    total_timesteps      | 258048       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015212754 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.83        |\n",
            "|    explained_variance   | 2.93e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.42         |\n",
            "|    n_updates            | 1250         |\n",
            "|    policy_gradient_loss | -9.46e-05    |\n",
            "|    reward               | 0.010888852  |\n",
            "|    std                  | 0.997        |\n",
            "|    value_loss           | 1.3          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 436          |\n",
            "|    iterations           | 127          |\n",
            "|    time_elapsed         | 596          |\n",
            "|    total_timesteps      | 260096       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.00393565   |\n",
            "|    clip_fraction        | 0.0357       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.83        |\n",
            "|    explained_variance   | 2.9e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.55         |\n",
            "|    n_updates            | 1260         |\n",
            "|    policy_gradient_loss | -0.00201     |\n",
            "|    reward               | -0.067803554 |\n",
            "|    std                  | 0.993        |\n",
            "|    value_loss           | 1.21         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 436          |\n",
            "|    iterations           | 128          |\n",
            "|    time_elapsed         | 600          |\n",
            "|    total_timesteps      | 262144       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056072795 |\n",
            "|    clip_fraction        | 0.036        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.82        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0559       |\n",
            "|    n_updates            | 1270         |\n",
            "|    policy_gradient_loss | -0.00215     |\n",
            "|    reward               | 0.13268031   |\n",
            "|    std                  | 0.993        |\n",
            "|    value_loss           | 0.207        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 436          |\n",
            "|    iterations           | 129          |\n",
            "|    time_elapsed         | 605          |\n",
            "|    total_timesteps      | 264192       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029379358 |\n",
            "|    clip_fraction        | 0.0259       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.83        |\n",
            "|    explained_variance   | 3.44e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.661        |\n",
            "|    n_updates            | 1280         |\n",
            "|    policy_gradient_loss | -0.00156     |\n",
            "|    reward               | 0.0009879195 |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.16         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 436         |\n",
            "|    iterations           | 130         |\n",
            "|    time_elapsed         | 610         |\n",
            "|    total_timesteps      | 266240      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004887319 |\n",
            "|    clip_fraction        | 0.0206      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.84       |\n",
            "|    explained_variance   | 2.21e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.06        |\n",
            "|    n_updates            | 1290        |\n",
            "|    policy_gradient_loss | -0.00146    |\n",
            "|    reward               | 0.45053193  |\n",
            "|    std                  | 0.997       |\n",
            "|    value_loss           | 2.4         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 436         |\n",
            "|    iterations           | 131         |\n",
            "|    time_elapsed         | 614         |\n",
            "|    total_timesteps      | 268288      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002506039 |\n",
            "|    clip_fraction        | 0.0141      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.83       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.611       |\n",
            "|    n_updates            | 1300        |\n",
            "|    policy_gradient_loss | -0.00135    |\n",
            "|    reward               | -0.13130797 |\n",
            "|    std                  | 0.999       |\n",
            "|    value_loss           | 1.58        |\n",
            "-----------------------------------------\n",
            "day: 2833, episode: 95\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -450740.91\n",
            "total_reward: -460740.91\n",
            "total_cost: 696.95\n",
            "total_trades: 3626\n",
            "Sharpe: 0.549\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 436          |\n",
            "|    iterations           | 132          |\n",
            "|    time_elapsed         | 619          |\n",
            "|    total_timesteps      | 270336       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043538986 |\n",
            "|    clip_fraction        | 0.0383       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | 4.18e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.24         |\n",
            "|    n_updates            | 1310         |\n",
            "|    policy_gradient_loss | -0.0025      |\n",
            "|    reward               | 0.0048631798 |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.617        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 436          |\n",
            "|    iterations           | 133          |\n",
            "|    time_elapsed         | 624          |\n",
            "|    total_timesteps      | 272384       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047709662 |\n",
            "|    clip_fraction        | 0.0259       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | 1.55e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.638        |\n",
            "|    n_updates            | 1320         |\n",
            "|    policy_gradient_loss | -0.00215     |\n",
            "|    reward               | 0.025755962  |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 1.74         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 436          |\n",
            "|    iterations           | 134          |\n",
            "|    time_elapsed         | 629          |\n",
            "|    total_timesteps      | 274432       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038830931 |\n",
            "|    clip_fraction        | 0.0335       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | 1.95e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.12         |\n",
            "|    n_updates            | 1330         |\n",
            "|    policy_gradient_loss | -0.00248     |\n",
            "|    reward               | -0.11789128  |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 2.34         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 436          |\n",
            "|    iterations           | 135          |\n",
            "|    time_elapsed         | 633          |\n",
            "|    total_timesteps      | 276480       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053527914 |\n",
            "|    clip_fraction        | 0.0336       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.86        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.279        |\n",
            "|    n_updates            | 1340         |\n",
            "|    policy_gradient_loss | -0.00135     |\n",
            "|    reward               | -0.2508797   |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.703        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 136          |\n",
            "|    time_elapsed         | 639          |\n",
            "|    total_timesteps      | 278528       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021539063 |\n",
            "|    clip_fraction        | 0.00635      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.87        |\n",
            "|    explained_variance   | 1.96e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.803        |\n",
            "|    n_updates            | 1350         |\n",
            "|    policy_gradient_loss | -0.000689    |\n",
            "|    reward               | 0.0064301114 |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 2.26         |\n",
            "------------------------------------------\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 435            |\n",
            "|    iterations           | 137            |\n",
            "|    time_elapsed         | 643            |\n",
            "|    total_timesteps      | 280576         |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.0043126293   |\n",
            "|    clip_fraction        | 0.0139         |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -2.88          |\n",
            "|    explained_variance   | 1.45e-05       |\n",
            "|    learning_rate        | 0.00025        |\n",
            "|    loss                 | 1.21           |\n",
            "|    n_updates            | 1360           |\n",
            "|    policy_gradient_loss | -0.00122       |\n",
            "|    reward               | -0.00011654015 |\n",
            "|    std                  | 1.03           |\n",
            "|    value_loss           | 3.02           |\n",
            "--------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 138          |\n",
            "|    time_elapsed         | 648          |\n",
            "|    total_timesteps      | 282624       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042130137 |\n",
            "|    clip_fraction        | 0.0197       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.89        |\n",
            "|    explained_variance   | 1.17e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.692        |\n",
            "|    n_updates            | 1370         |\n",
            "|    policy_gradient_loss | -0.00163     |\n",
            "|    reward               | -0.07828528  |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 1.84         |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 100\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -454148.82\n",
            "total_reward: -464148.82\n",
            "total_cost: 765.26\n",
            "total_trades: 3538\n",
            "Sharpe: 0.343\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 435         |\n",
            "|    iterations           | 139         |\n",
            "|    time_elapsed         | 653         |\n",
            "|    total_timesteps      | 284672      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005929306 |\n",
            "|    clip_fraction        | 0.0462      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.89       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0239      |\n",
            "|    n_updates            | 1380        |\n",
            "|    policy_gradient_loss | -0.00311    |\n",
            "|    reward               | -0.24280122 |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 0.151       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 435         |\n",
            "|    iterations           | 140         |\n",
            "|    time_elapsed         | 658         |\n",
            "|    total_timesteps      | 286720      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003940879 |\n",
            "|    clip_fraction        | 0.0197      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.89       |\n",
            "|    explained_variance   | 2e-05       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.653       |\n",
            "|    n_updates            | 1390        |\n",
            "|    policy_gradient_loss | -0.00121    |\n",
            "|    reward               | 0.007165262 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 1.6         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 141          |\n",
            "|    time_elapsed         | 663          |\n",
            "|    total_timesteps      | 288768       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0067264093 |\n",
            "|    clip_fraction        | 0.0765       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.9         |\n",
            "|    explained_variance   | 1.97e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.859        |\n",
            "|    n_updates            | 1400         |\n",
            "|    policy_gradient_loss | -0.00623     |\n",
            "|    reward               | -0.35372147  |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 1.52         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 142          |\n",
            "|    time_elapsed         | 668          |\n",
            "|    total_timesteps      | 290816       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035390826 |\n",
            "|    clip_fraction        | 0.0201       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.9         |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.258        |\n",
            "|    n_updates            | 1410         |\n",
            "|    policy_gradient_loss | -0.00114     |\n",
            "|    reward               | -0.008216074 |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.667        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 143          |\n",
            "|    time_elapsed         | 672          |\n",
            "|    total_timesteps      | 292864       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031711543 |\n",
            "|    clip_fraction        | 0.0321       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.9         |\n",
            "|    explained_variance   | 5.85e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.304        |\n",
            "|    n_updates            | 1420         |\n",
            "|    policy_gradient_loss | -0.00229     |\n",
            "|    reward               | -0.007007383 |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.56         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 435           |\n",
            "|    iterations           | 144           |\n",
            "|    time_elapsed         | 677           |\n",
            "|    total_timesteps      | 294912        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0033052037  |\n",
            "|    clip_fraction        | 0.0131        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.9          |\n",
            "|    explained_variance   | 2.78e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.493         |\n",
            "|    n_updates            | 1430          |\n",
            "|    policy_gradient_loss | -0.000639     |\n",
            "|    reward               | -0.0057196943 |\n",
            "|    std                  | 1.03          |\n",
            "|    value_loss           | 1.25          |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 435         |\n",
            "|    iterations           | 145         |\n",
            "|    time_elapsed         | 682         |\n",
            "|    total_timesteps      | 296960      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004115251 |\n",
            "|    clip_fraction        | 0.0322      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.9        |\n",
            "|    explained_variance   | 3.74e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.529       |\n",
            "|    n_updates            | 1440        |\n",
            "|    policy_gradient_loss | -0.00168    |\n",
            "|    reward               | 0.10822017  |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 0.969       |\n",
            "-----------------------------------------\n",
            "day: 2833, episode: 105\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -335828.19\n",
            "total_reward: -345828.19\n",
            "total_cost: 580.15\n",
            "total_trades: 3104\n",
            "Sharpe: 0.463\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 435         |\n",
            "|    iterations           | 146         |\n",
            "|    time_elapsed         | 687         |\n",
            "|    total_timesteps      | 299008      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005412357 |\n",
            "|    clip_fraction        | 0.0412      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.91       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0162      |\n",
            "|    n_updates            | 1450        |\n",
            "|    policy_gradient_loss | -0.00206    |\n",
            "|    reward               | -0.04984639 |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 0.164       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 435         |\n",
            "|    iterations           | 147         |\n",
            "|    time_elapsed         | 691         |\n",
            "|    total_timesteps      | 301056      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006211511 |\n",
            "|    clip_fraction        | 0.0648      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.92       |\n",
            "|    explained_variance   | 2.15e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.219       |\n",
            "|    n_updates            | 1460        |\n",
            "|    policy_gradient_loss | -0.00466    |\n",
            "|    reward               | -0.03996098 |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 0.836       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 435         |\n",
            "|    iterations           | 148         |\n",
            "|    time_elapsed         | 696         |\n",
            "|    total_timesteps      | 303104      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005395622 |\n",
            "|    clip_fraction        | 0.0375      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.94       |\n",
            "|    explained_variance   | 3e-05       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.421       |\n",
            "|    n_updates            | 1470        |\n",
            "|    policy_gradient_loss | -0.00275    |\n",
            "|    reward               | 0.40957806  |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 0.73        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 149          |\n",
            "|    time_elapsed         | 701          |\n",
            "|    total_timesteps      | 305152       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011490879 |\n",
            "|    clip_fraction        | 0.000586     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.94        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.144        |\n",
            "|    n_updates            | 1480         |\n",
            "|    policy_gradient_loss | -0.000392    |\n",
            "|    reward               | -0.1628137   |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.449        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 150          |\n",
            "|    time_elapsed         | 706          |\n",
            "|    total_timesteps      | 307200       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004214667  |\n",
            "|    clip_fraction        | 0.024        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.92        |\n",
            "|    explained_variance   | 9.64e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.121        |\n",
            "|    n_updates            | 1490         |\n",
            "|    policy_gradient_loss | -0.000837    |\n",
            "|    reward               | -0.050073158 |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.117        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 151          |\n",
            "|    time_elapsed         | 711          |\n",
            "|    total_timesteps      | 309248       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030560317 |\n",
            "|    clip_fraction        | 0.019        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.93        |\n",
            "|    explained_variance   | 2.49e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.138        |\n",
            "|    n_updates            | 1500         |\n",
            "|    policy_gradient_loss | -0.00159     |\n",
            "|    reward               | -0.03170887  |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.459        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 434           |\n",
            "|    iterations           | 152           |\n",
            "|    time_elapsed         | 716           |\n",
            "|    total_timesteps      | 311296        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00085507374 |\n",
            "|    clip_fraction        | 0.000146      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.94         |\n",
            "|    explained_variance   | 3.81e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.256         |\n",
            "|    n_updates            | 1510          |\n",
            "|    policy_gradient_loss | -0.000396     |\n",
            "|    reward               | -0.118899725  |\n",
            "|    std                  | 1.05          |\n",
            "|    value_loss           | 0.525         |\n",
            "-------------------------------------------\n",
            "day: 2833, episode: 110\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -246042.00\n",
            "total_reward: -256042.00\n",
            "total_cost: 511.90\n",
            "total_trades: 2834\n",
            "Sharpe: 0.438\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 153          |\n",
            "|    time_elapsed         | 721          |\n",
            "|    total_timesteps      | 313344       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0006966694 |\n",
            "|    clip_fraction        | 0.00117      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.93        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0219       |\n",
            "|    n_updates            | 1520         |\n",
            "|    policy_gradient_loss | 0.000262     |\n",
            "|    reward               | -0.11029825  |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.141        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 154          |\n",
            "|    time_elapsed         | 725          |\n",
            "|    total_timesteps      | 315392       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033898249 |\n",
            "|    clip_fraction        | 0.00771      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.92        |\n",
            "|    explained_variance   | 6.12e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.182        |\n",
            "|    n_updates            | 1530         |\n",
            "|    policy_gradient_loss | -0.000762    |\n",
            "|    reward               | -0.012064352 |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.42         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 155          |\n",
            "|    time_elapsed         | 730          |\n",
            "|    total_timesteps      | 317440       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034614506 |\n",
            "|    clip_fraction        | 0.0151       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.91        |\n",
            "|    explained_variance   | 2.39e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.125        |\n",
            "|    n_updates            | 1540         |\n",
            "|    policy_gradient_loss | -0.00102     |\n",
            "|    reward               | 0.059677027  |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.412        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 434         |\n",
            "|    iterations           | 156         |\n",
            "|    time_elapsed         | 735         |\n",
            "|    total_timesteps      | 319488      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003504253 |\n",
            "|    clip_fraction        | 0.0083      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.91       |\n",
            "|    explained_variance   | 5.19e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.251       |\n",
            "|    n_updates            | 1550        |\n",
            "|    policy_gradient_loss | -0.000289   |\n",
            "|    reward               | -0.11190847 |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 0.509       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 157          |\n",
            "|    time_elapsed         | 740          |\n",
            "|    total_timesteps      | 321536       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047105355 |\n",
            "|    clip_fraction        | 0.0328       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.92        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00157     |\n",
            "|    n_updates            | 1560         |\n",
            "|    policy_gradient_loss | -0.00231     |\n",
            "|    reward               | -0.077777155 |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.0463       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 158          |\n",
            "|    time_elapsed         | 745          |\n",
            "|    total_timesteps      | 323584       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036208227 |\n",
            "|    clip_fraction        | 0.0324       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.92        |\n",
            "|    explained_variance   | 3e-05        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.143        |\n",
            "|    n_updates            | 1570         |\n",
            "|    policy_gradient_loss | -0.002       |\n",
            "|    reward               | -0.014542376 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.38         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 159          |\n",
            "|    time_elapsed         | 750          |\n",
            "|    total_timesteps      | 325632       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046507055 |\n",
            "|    clip_fraction        | 0.0373       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.93        |\n",
            "|    explained_variance   | 7.18e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.155        |\n",
            "|    n_updates            | 1580         |\n",
            "|    policy_gradient_loss | -0.00336     |\n",
            "|    reward               | 0.25452828   |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.32         |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 115\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -217167.50\n",
            "total_reward: -227167.50\n",
            "total_cost: 492.78\n",
            "total_trades: 2902\n",
            "Sharpe: 0.246\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 160          |\n",
            "|    time_elapsed         | 754          |\n",
            "|    total_timesteps      | 327680       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0068372865 |\n",
            "|    clip_fraction        | 0.0374       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.93        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0552       |\n",
            "|    n_updates            | 1590         |\n",
            "|    policy_gradient_loss | -0.0022      |\n",
            "|    reward               | 0.3245705    |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.241        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 161          |\n",
            "|    time_elapsed         | 759          |\n",
            "|    total_timesteps      | 329728       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005300396  |\n",
            "|    clip_fraction        | 0.0478       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.93        |\n",
            "|    explained_variance   | 2.91e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0264       |\n",
            "|    n_updates            | 1600         |\n",
            "|    policy_gradient_loss | -0.00289     |\n",
            "|    reward               | -0.011198671 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.181        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 434         |\n",
            "|    iterations           | 162         |\n",
            "|    time_elapsed         | 764         |\n",
            "|    total_timesteps      | 331776      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004943536 |\n",
            "|    clip_fraction        | 0.0506      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.93       |\n",
            "|    explained_variance   | 5.85e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.153       |\n",
            "|    n_updates            | 1610        |\n",
            "|    policy_gradient_loss | -0.0042     |\n",
            "|    reward               | 0.001001978 |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 0.382       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 163          |\n",
            "|    time_elapsed         | 768          |\n",
            "|    total_timesteps      | 333824       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024689904 |\n",
            "|    clip_fraction        | 0.0062       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.94        |\n",
            "|    explained_variance   | 3.86e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.157        |\n",
            "|    n_updates            | 1620         |\n",
            "|    policy_gradient_loss | -0.00114     |\n",
            "|    reward               | 0.24860546   |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.396        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 164          |\n",
            "|    time_elapsed         | 773          |\n",
            "|    total_timesteps      | 335872       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030181569 |\n",
            "|    clip_fraction        | 0.02         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.95        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00232     |\n",
            "|    n_updates            | 1630         |\n",
            "|    policy_gradient_loss | -0.00154     |\n",
            "|    reward               | -0.091344826 |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.0589       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 165          |\n",
            "|    time_elapsed         | 778          |\n",
            "|    total_timesteps      | 337920       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024718174 |\n",
            "|    clip_fraction        | 0.0125       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.95        |\n",
            "|    explained_variance   | 3.02e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.136        |\n",
            "|    n_updates            | 1640         |\n",
            "|    policy_gradient_loss | -0.000847    |\n",
            "|    reward               | -0.003727354 |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.282        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 433         |\n",
            "|    iterations           | 166         |\n",
            "|    time_elapsed         | 783         |\n",
            "|    total_timesteps      | 339968      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004922013 |\n",
            "|    clip_fraction        | 0.0535      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.96       |\n",
            "|    explained_variance   | 2.69e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0803      |\n",
            "|    n_updates            | 1650        |\n",
            "|    policy_gradient_loss | -0.00481    |\n",
            "|    reward               | 0.01429637  |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 0.267       |\n",
            "-----------------------------------------\n",
            "day: 2833, episode: 120\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -184123.73\n",
            "total_reward: -194123.73\n",
            "total_cost: 419.43\n",
            "total_trades: 2582\n",
            "Sharpe: 0.535\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 433           |\n",
            "|    iterations           | 167           |\n",
            "|    time_elapsed         | 788           |\n",
            "|    total_timesteps      | 342016        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0056060003  |\n",
            "|    clip_fraction        | 0.03          |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.95         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0929        |\n",
            "|    n_updates            | 1660          |\n",
            "|    policy_gradient_loss | -0.00144      |\n",
            "|    reward               | -0.0042163497 |\n",
            "|    std                  | 1.06          |\n",
            "|    value_loss           | 0.25          |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 433         |\n",
            "|    iterations           | 168         |\n",
            "|    time_elapsed         | 793         |\n",
            "|    total_timesteps      | 344064      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001279124 |\n",
            "|    clip_fraction        | 0.000439    |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.95       |\n",
            "|    explained_variance   | -0.000108   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0206     |\n",
            "|    n_updates            | 1670        |\n",
            "|    policy_gradient_loss | -7.44e-05   |\n",
            "|    reward               | -0.01406818 |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 0.0549      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 434         |\n",
            "|    iterations           | 169         |\n",
            "|    time_elapsed         | 797         |\n",
            "|    total_timesteps      | 346112      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003301194 |\n",
            "|    clip_fraction        | 0.0195      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.94       |\n",
            "|    explained_variance   | 6.06e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.159       |\n",
            "|    n_updates            | 1680        |\n",
            "|    policy_gradient_loss | -0.00124    |\n",
            "|    reward               | 0.014581838 |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 0.28        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 170          |\n",
            "|    time_elapsed         | 801          |\n",
            "|    total_timesteps      | 348160       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045193504 |\n",
            "|    clip_fraction        | 0.0316       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.96        |\n",
            "|    explained_variance   | 5.79e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.136        |\n",
            "|    n_updates            | 1690         |\n",
            "|    policy_gradient_loss | -0.00281     |\n",
            "|    reward               | -0.12119565  |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.396        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 434         |\n",
            "|    iterations           | 171         |\n",
            "|    time_elapsed         | 805         |\n",
            "|    total_timesteps      | 350208      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005250846 |\n",
            "|    clip_fraction        | 0.0176      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.98       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0523      |\n",
            "|    n_updates            | 1700        |\n",
            "|    policy_gradient_loss | -0.000793   |\n",
            "|    reward               | -0.15967041 |\n",
            "|    std                  | 1.07        |\n",
            "|    value_loss           | 0.139       |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 435           |\n",
            "|    iterations           | 172           |\n",
            "|    time_elapsed         | 809           |\n",
            "|    total_timesteps      | 352256        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.005280476   |\n",
            "|    clip_fraction        | 0.0422        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.97         |\n",
            "|    explained_variance   | 3.19e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.148         |\n",
            "|    n_updates            | 1710          |\n",
            "|    policy_gradient_loss | -0.00284      |\n",
            "|    reward               | -0.0061471267 |\n",
            "|    std                  | 1.07          |\n",
            "|    value_loss           | 0.39          |\n",
            "-------------------------------------------\n",
            "day: 2833, episode: 125\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -247194.41\n",
            "total_reward: -257194.41\n",
            "total_cost: 503.83\n",
            "total_trades: 2778\n",
            "Sharpe: 0.592\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 435           |\n",
            "|    iterations           | 173           |\n",
            "|    time_elapsed         | 814           |\n",
            "|    total_timesteps      | 354304        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.005006915   |\n",
            "|    clip_fraction        | 0.033         |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.98         |\n",
            "|    explained_variance   | 5.46e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.242         |\n",
            "|    n_updates            | 1720          |\n",
            "|    policy_gradient_loss | -0.0028       |\n",
            "|    reward               | -0.0009444083 |\n",
            "|    std                  | 1.08          |\n",
            "|    value_loss           | 0.605         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 174          |\n",
            "|    time_elapsed         | 818          |\n",
            "|    total_timesteps      | 356352       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045557506 |\n",
            "|    clip_fraction        | 0.0398       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.98        |\n",
            "|    explained_variance   | 3.33e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.218        |\n",
            "|    n_updates            | 1730         |\n",
            "|    policy_gradient_loss | -0.00355     |\n",
            "|    reward               | -0.17017575  |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.538        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 175          |\n",
            "|    time_elapsed         | 822          |\n",
            "|    total_timesteps      | 358400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0072164508 |\n",
            "|    clip_fraction        | 0.0717       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.97        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00803     |\n",
            "|    n_updates            | 1740         |\n",
            "|    policy_gradient_loss | -0.00627     |\n",
            "|    reward               | 0.043030307  |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.0586       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 176          |\n",
            "|    time_elapsed         | 827          |\n",
            "|    total_timesteps      | 360448       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038012106 |\n",
            "|    clip_fraction        | 0.0248       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.97        |\n",
            "|    explained_variance   | 3.08e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.096        |\n",
            "|    n_updates            | 1750         |\n",
            "|    policy_gradient_loss | -0.0017      |\n",
            "|    reward               | 0.0003141126 |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.422        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 436          |\n",
            "|    iterations           | 177          |\n",
            "|    time_elapsed         | 831          |\n",
            "|    total_timesteps      | 362496       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060108877 |\n",
            "|    clip_fraction        | 0.0383       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.96        |\n",
            "|    explained_variance   | 2.99e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.138        |\n",
            "|    n_updates            | 1760         |\n",
            "|    policy_gradient_loss | -0.00287     |\n",
            "|    reward               | -0.16352925  |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.478        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 178          |\n",
            "|    time_elapsed         | 836          |\n",
            "|    total_timesteps      | 364544       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049963053 |\n",
            "|    clip_fraction        | 0.0244       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.96        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.107        |\n",
            "|    n_updates            | 1770         |\n",
            "|    policy_gradient_loss | -0.00181     |\n",
            "|    reward               | -0.111086935 |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.329        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 179          |\n",
            "|    time_elapsed         | 841          |\n",
            "|    total_timesteps      | 366592       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0077513536 |\n",
            "|    clip_fraction        | 0.0663       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.95        |\n",
            "|    explained_variance   | 4.94e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0675       |\n",
            "|    n_updates            | 1780         |\n",
            "|    policy_gradient_loss | -0.00345     |\n",
            "|    reward               | -0.016130669 |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.217        |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 130\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -184745.31\n",
            "total_reward: -194745.31\n",
            "total_cost: 397.56\n",
            "total_trades: 2430\n",
            "Sharpe: 0.448\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 180          |\n",
            "|    time_elapsed         | 845          |\n",
            "|    total_timesteps      | 368640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018796432 |\n",
            "|    clip_fraction        | 0.00278      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.96        |\n",
            "|    explained_variance   | 2.56e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.137        |\n",
            "|    n_updates            | 1790         |\n",
            "|    policy_gradient_loss | -0.000212    |\n",
            "|    reward               | 0.0007605808 |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.287        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 181          |\n",
            "|    time_elapsed         | 850          |\n",
            "|    total_timesteps      | 370688       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005526459 |\n",
            "|    clip_fraction        | 0.000439     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.98        |\n",
            "|    explained_variance   | 7.56e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0976       |\n",
            "|    n_updates            | 1800         |\n",
            "|    policy_gradient_loss | 0.000189     |\n",
            "|    reward               | -0.0859285   |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 0.281        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 435         |\n",
            "|    iterations           | 182         |\n",
            "|    time_elapsed         | 855         |\n",
            "|    total_timesteps      | 372736      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004860089 |\n",
            "|    clip_fraction        | 0.0206      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.98       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0128     |\n",
            "|    n_updates            | 1810        |\n",
            "|    policy_gradient_loss | -0.00115    |\n",
            "|    reward               | -0.06370368 |\n",
            "|    std                  | 1.08        |\n",
            "|    value_loss           | 0.0437      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 183          |\n",
            "|    time_elapsed         | 860          |\n",
            "|    total_timesteps      | 374784       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031210126 |\n",
            "|    clip_fraction        | 0.0238       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.99        |\n",
            "|    explained_variance   | 7.4e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0533       |\n",
            "|    n_updates            | 1820         |\n",
            "|    policy_gradient_loss | -0.00112     |\n",
            "|    reward               | 0.005649472  |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 0.182        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 435         |\n",
            "|    iterations           | 184         |\n",
            "|    time_elapsed         | 865         |\n",
            "|    total_timesteps      | 376832      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004555683 |\n",
            "|    clip_fraction        | 0.0218      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.99       |\n",
            "|    explained_variance   | 3.05e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0989      |\n",
            "|    n_updates            | 1830        |\n",
            "|    policy_gradient_loss | -0.00175    |\n",
            "|    reward               | 1.0605406   |\n",
            "|    std                  | 1.08        |\n",
            "|    value_loss           | 0.319       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 435         |\n",
            "|    iterations           | 185         |\n",
            "|    time_elapsed         | 869         |\n",
            "|    total_timesteps      | 378880      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004735706 |\n",
            "|    clip_fraction        | 0.0307      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.99       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0759      |\n",
            "|    n_updates            | 1840        |\n",
            "|    policy_gradient_loss | -0.00238    |\n",
            "|    reward               | 0.18790147  |\n",
            "|    std                  | 1.08        |\n",
            "|    value_loss           | 0.192       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 186          |\n",
            "|    time_elapsed         | 874          |\n",
            "|    total_timesteps      | 380928       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004835318  |\n",
            "|    clip_fraction        | 0.0199       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.99        |\n",
            "|    explained_variance   | 3.7e-06      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00532      |\n",
            "|    n_updates            | 1850         |\n",
            "|    policy_gradient_loss | -0.00189     |\n",
            "|    reward               | -0.004287611 |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 0.0425       |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 135\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -169654.76\n",
            "total_reward: -179654.76\n",
            "total_cost: 437.02\n",
            "total_trades: 2546\n",
            "Sharpe: -0.037\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 187          |\n",
            "|    time_elapsed         | 879          |\n",
            "|    total_timesteps      | 382976       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043466664 |\n",
            "|    clip_fraction        | 0.0237       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.98        |\n",
            "|    explained_variance   | 3.99e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.045        |\n",
            "|    n_updates            | 1860         |\n",
            "|    policy_gradient_loss | -0.00138     |\n",
            "|    reward               | -0.004470315 |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.241        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 435         |\n",
            "|    iterations           | 188         |\n",
            "|    time_elapsed         | 883         |\n",
            "|    total_timesteps      | 385024      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003981806 |\n",
            "|    clip_fraction        | 0.0162      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.97       |\n",
            "|    explained_variance   | 3.52e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.114       |\n",
            "|    n_updates            | 1870        |\n",
            "|    policy_gradient_loss | -0.0014     |\n",
            "|    reward               | 0.21036156  |\n",
            "|    std                  | 1.07        |\n",
            "|    value_loss           | 0.24        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 189          |\n",
            "|    time_elapsed         | 888          |\n",
            "|    total_timesteps      | 387072       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037740392 |\n",
            "|    clip_fraction        | 0.00991      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.95        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00675      |\n",
            "|    n_updates            | 1880         |\n",
            "|    policy_gradient_loss | -0.000595    |\n",
            "|    reward               | 0.022932604  |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.0601       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 190          |\n",
            "|    time_elapsed         | 893          |\n",
            "|    total_timesteps      | 389120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038502356 |\n",
            "|    clip_fraction        | 0.0329       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.95        |\n",
            "|    explained_variance   | 1.13e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.025        |\n",
            "|    n_updates            | 1890         |\n",
            "|    policy_gradient_loss | -0.00211     |\n",
            "|    reward               | -0.017641636 |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.151        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 435           |\n",
            "|    iterations           | 191           |\n",
            "|    time_elapsed         | 898           |\n",
            "|    total_timesteps      | 391168        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0073320023  |\n",
            "|    clip_fraction        | 0.061         |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.95         |\n",
            "|    explained_variance   | 2.25e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0292        |\n",
            "|    n_updates            | 1900          |\n",
            "|    policy_gradient_loss | -0.0038       |\n",
            "|    reward               | -0.0007191341 |\n",
            "|    std                  | 1.06          |\n",
            "|    value_loss           | 0.114         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 192          |\n",
            "|    time_elapsed         | 903          |\n",
            "|    total_timesteps      | 393216       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055445232 |\n",
            "|    clip_fraction        | 0.0296       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.95        |\n",
            "|    explained_variance   | 4.25e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0628       |\n",
            "|    n_updates            | 1910         |\n",
            "|    policy_gradient_loss | -0.0018      |\n",
            "|    reward               | -0.37927964  |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.165        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 193          |\n",
            "|    time_elapsed         | 907          |\n",
            "|    total_timesteps      | 395264       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035546613 |\n",
            "|    clip_fraction        | 0.00698      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.96        |\n",
            "|    explained_variance   | -2.38e-07    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.015       |\n",
            "|    n_updates            | 1920         |\n",
            "|    policy_gradient_loss | -0.000176    |\n",
            "|    reward               | 0.085694     |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.0179       |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 140\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -172281.47\n",
            "total_reward: -182281.47\n",
            "total_cost: 468.47\n",
            "total_trades: 2792\n",
            "Sharpe: -0.164\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 194          |\n",
            "|    time_elapsed         | 912          |\n",
            "|    total_timesteps      | 397312       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0057515083 |\n",
            "|    clip_fraction        | 0.0368       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.96        |\n",
            "|    explained_variance   | 7.17e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00205      |\n",
            "|    n_updates            | 1930         |\n",
            "|    policy_gradient_loss | -0.00286     |\n",
            "|    reward               | -0.010020977 |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.0973       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 195          |\n",
            "|    time_elapsed         | 917          |\n",
            "|    total_timesteps      | 399360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026701856 |\n",
            "|    clip_fraction        | 0.00386      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.94        |\n",
            "|    explained_variance   | 3.87e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0993       |\n",
            "|    n_updates            | 1940         |\n",
            "|    policy_gradient_loss | -0.000629    |\n",
            "|    reward               | -0.13047867  |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.244        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 435         |\n",
            "|    iterations           | 196         |\n",
            "|    time_elapsed         | 922         |\n",
            "|    total_timesteps      | 401408      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004883712 |\n",
            "|    clip_fraction        | 0.0282      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.93       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0357      |\n",
            "|    n_updates            | 1950        |\n",
            "|    policy_gradient_loss | -0.00131    |\n",
            "|    reward               | 0.048403334 |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 0.145       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 197          |\n",
            "|    time_elapsed         | 927          |\n",
            "|    total_timesteps      | 403456       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042810086 |\n",
            "|    clip_fraction        | 0.0318       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.94        |\n",
            "|    explained_variance   | 5.51e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0239       |\n",
            "|    n_updates            | 1960         |\n",
            "|    policy_gradient_loss | -0.00177     |\n",
            "|    reward               | -0.014117159 |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.0903       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 435           |\n",
            "|    iterations           | 198           |\n",
            "|    time_elapsed         | 931           |\n",
            "|    total_timesteps      | 405504        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0046093995  |\n",
            "|    clip_fraction        | 0.0241        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.94         |\n",
            "|    explained_variance   | 3.94e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.112         |\n",
            "|    n_updates            | 1970          |\n",
            "|    policy_gradient_loss | -0.00145      |\n",
            "|    reward               | -0.0014116839 |\n",
            "|    std                  | 1.06          |\n",
            "|    value_loss           | 0.22          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 199          |\n",
            "|    time_elapsed         | 936          |\n",
            "|    total_timesteps      | 407552       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028487176 |\n",
            "|    clip_fraction        | 0.0169       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.95        |\n",
            "|    explained_variance   | 6.46e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0564       |\n",
            "|    n_updates            | 1980         |\n",
            "|    policy_gradient_loss | -0.0021      |\n",
            "|    reward               | 0.13870203   |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.147        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 200          |\n",
            "|    time_elapsed         | 940          |\n",
            "|    total_timesteps      | 409600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044956864 |\n",
            "|    clip_fraction        | 0.0369       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.96        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00189      |\n",
            "|    n_updates            | 1990         |\n",
            "|    policy_gradient_loss | -0.00266     |\n",
            "|    reward               | 0.056307394  |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.0474       |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 145\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -197081.04\n",
            "total_reward: -207081.04\n",
            "total_cost: 468.10\n",
            "total_trades: 2736\n",
            "Sharpe: -0.050\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 201          |\n",
            "|    time_elapsed         | 945          |\n",
            "|    total_timesteps      | 411648       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046403916 |\n",
            "|    clip_fraction        | 0.0338       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.95        |\n",
            "|    explained_variance   | 7.76e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0733       |\n",
            "|    n_updates            | 2000         |\n",
            "|    policy_gradient_loss | -0.00401     |\n",
            "|    reward               | 0.011369228  |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.166        |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 435        |\n",
            "|    iterations           | 202        |\n",
            "|    time_elapsed         | 950        |\n",
            "|    total_timesteps      | 413696     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00417429 |\n",
            "|    clip_fraction        | 0.0162     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.94      |\n",
            "|    explained_variance   | 3.99e-05   |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 0.17       |\n",
            "|    n_updates            | 2010       |\n",
            "|    policy_gradient_loss | -0.000795  |\n",
            "|    reward               | 0.41418552 |\n",
            "|    std                  | 1.06       |\n",
            "|    value_loss           | 0.331      |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 203          |\n",
            "|    time_elapsed         | 955          |\n",
            "|    total_timesteps      | 415744       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033134301 |\n",
            "|    clip_fraction        | 0.00757      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.94        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0789       |\n",
            "|    n_updates            | 2020         |\n",
            "|    policy_gradient_loss | -0.000609    |\n",
            "|    reward               | -0.34161076  |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.189        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 204          |\n",
            "|    time_elapsed         | 960          |\n",
            "|    total_timesteps      | 417792       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018914439 |\n",
            "|    clip_fraction        | 0.000977     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.94        |\n",
            "|    explained_variance   | 0.000147     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00835     |\n",
            "|    n_updates            | 2030         |\n",
            "|    policy_gradient_loss | -2.8e-05     |\n",
            "|    reward               | -0.018011082 |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.0424       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 205          |\n",
            "|    time_elapsed         | 965          |\n",
            "|    total_timesteps      | 419840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.000606016  |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.94        |\n",
            "|    explained_variance   | 2.53e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.126        |\n",
            "|    n_updates            | 2040         |\n",
            "|    policy_gradient_loss | 0.000116     |\n",
            "|    reward               | -0.010647219 |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.325        |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 434        |\n",
            "|    iterations           | 206        |\n",
            "|    time_elapsed         | 970        |\n",
            "|    total_timesteps      | 421888     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00427197 |\n",
            "|    clip_fraction        | 0.0218     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.94      |\n",
            "|    explained_variance   | 3.05e-05   |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 0.141      |\n",
            "|    n_updates            | 2050       |\n",
            "|    policy_gradient_loss | -0.00143   |\n",
            "|    reward               | 0.29372358 |\n",
            "|    std                  | 1.06       |\n",
            "|    value_loss           | 0.37       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 434         |\n",
            "|    iterations           | 207         |\n",
            "|    time_elapsed         | 975         |\n",
            "|    total_timesteps      | 423936      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002782287 |\n",
            "|    clip_fraction        | 0.00444     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.94       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.00558    |\n",
            "|    n_updates            | 2060        |\n",
            "|    policy_gradient_loss | -0.000726   |\n",
            "|    reward               | -0.03806164 |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 0.0588      |\n",
            "-----------------------------------------\n",
            "day: 2833, episode: 150\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -127177.74\n",
            "total_reward: -137177.74\n",
            "total_cost: 419.58\n",
            "total_trades: 2760\n",
            "Sharpe: -0.144\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 208          |\n",
            "|    time_elapsed         | 980          |\n",
            "|    total_timesteps      | 425984       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046926197 |\n",
            "|    clip_fraction        | 0.0185       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.94        |\n",
            "|    explained_variance   | 2.83e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0244       |\n",
            "|    n_updates            | 2070         |\n",
            "|    policy_gradient_loss | -0.00123     |\n",
            "|    reward               | -0.009384899 |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.122        |\n",
            "------------------------------------------\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 434            |\n",
            "|    iterations           | 209            |\n",
            "|    time_elapsed         | 984            |\n",
            "|    total_timesteps      | 428032         |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.0022434026   |\n",
            "|    clip_fraction        | 0.00313        |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -2.94          |\n",
            "|    explained_variance   | 3.01e-05       |\n",
            "|    learning_rate        | 0.00025        |\n",
            "|    loss                 | 0.0282         |\n",
            "|    n_updates            | 2080           |\n",
            "|    policy_gradient_loss | -0.00112       |\n",
            "|    reward               | -0.00048195713 |\n",
            "|    std                  | 1.05           |\n",
            "|    value_loss           | 0.121          |\n",
            "--------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 210          |\n",
            "|    time_elapsed         | 989          |\n",
            "|    total_timesteps      | 430080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.002346149  |\n",
            "|    clip_fraction        | 0.000928     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.92        |\n",
            "|    explained_variance   | 3.22e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.018        |\n",
            "|    n_updates            | 2090         |\n",
            "|    policy_gradient_loss | -0.000458    |\n",
            "|    reward               | -0.098837204 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.117        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 434         |\n",
            "|    iterations           | 211         |\n",
            "|    time_elapsed         | 994         |\n",
            "|    total_timesteps      | 432128      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005066669 |\n",
            "|    clip_fraction        | 0.0402      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.92       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.00967    |\n",
            "|    n_updates            | 2100        |\n",
            "|    policy_gradient_loss | -0.0029     |\n",
            "|    reward               | -0.20872203 |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 0.0295      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 212          |\n",
            "|    time_elapsed         | 999          |\n",
            "|    total_timesteps      | 434176       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016997352 |\n",
            "|    clip_fraction        | 0.00137      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.91        |\n",
            "|    explained_variance   | 8.78e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.028        |\n",
            "|    n_updates            | 2110         |\n",
            "|    policy_gradient_loss | -0.000527    |\n",
            "|    reward               | 0.007069997  |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.129        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 434         |\n",
            "|    iterations           | 213         |\n",
            "|    time_elapsed         | 1003        |\n",
            "|    total_timesteps      | 436224      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004323996 |\n",
            "|    clip_fraction        | 0.0156      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.91       |\n",
            "|    explained_variance   | 3.07e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.119       |\n",
            "|    n_updates            | 2120        |\n",
            "|    policy_gradient_loss | -0.00128    |\n",
            "|    reward               | -0.09091481 |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 0.278       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 214          |\n",
            "|    time_elapsed         | 1008         |\n",
            "|    total_timesteps      | 438272       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041770516 |\n",
            "|    clip_fraction        | 0.0126       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.92        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0572       |\n",
            "|    n_updates            | 2130         |\n",
            "|    policy_gradient_loss | -0.00082     |\n",
            "|    reward               | -0.032097545 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.123        |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 155\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -120632.67\n",
            "total_reward: -130632.67\n",
            "total_cost: 413.10\n",
            "total_trades: 2774\n",
            "Sharpe: 0.218\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 215          |\n",
            "|    time_elapsed         | 1013         |\n",
            "|    total_timesteps      | 440320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029798646 |\n",
            "|    clip_fraction        | 0.0136       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.92        |\n",
            "|    explained_variance   | 3.13e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0318       |\n",
            "|    n_updates            | 2140         |\n",
            "|    policy_gradient_loss | -0.000875    |\n",
            "|    reward               | -0.004336021 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.0637       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 434         |\n",
            "|    iterations           | 216         |\n",
            "|    time_elapsed         | 1018        |\n",
            "|    total_timesteps      | 442368      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004621285 |\n",
            "|    clip_fraction        | 0.0246      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.92       |\n",
            "|    explained_variance   | 8.74e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0208      |\n",
            "|    n_updates            | 2150        |\n",
            "|    policy_gradient_loss | -0.00171    |\n",
            "|    reward               | 0.011666192 |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 0.104       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 217          |\n",
            "|    time_elapsed         | 1022         |\n",
            "|    total_timesteps      | 444416       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016024732 |\n",
            "|    clip_fraction        | 0.00503      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.93        |\n",
            "|    explained_variance   | 0.0108       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0272       |\n",
            "|    n_updates            | 2160         |\n",
            "|    policy_gradient_loss | -0.000506    |\n",
            "|    reward               | -0.12789278  |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.073        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 434         |\n",
            "|    iterations           | 218         |\n",
            "|    time_elapsed         | 1027        |\n",
            "|    total_timesteps      | 446464      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004817912 |\n",
            "|    clip_fraction        | 0.0291      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.93       |\n",
            "|    explained_variance   | 5.96e-08    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0282     |\n",
            "|    n_updates            | 2170        |\n",
            "|    policy_gradient_loss | -0.00124    |\n",
            "|    reward               | 0.028214797 |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 0.027       |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 434           |\n",
            "|    iterations           | 219           |\n",
            "|    time_elapsed         | 1032          |\n",
            "|    total_timesteps      | 448512        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.003926607   |\n",
            "|    clip_fraction        | 0.0132        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.92         |\n",
            "|    explained_variance   | 7.06e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0092       |\n",
            "|    n_updates            | 2180          |\n",
            "|    policy_gradient_loss | -0.000856     |\n",
            "|    reward               | -0.0011868946 |\n",
            "|    std                  | 1.05          |\n",
            "|    value_loss           | 0.0704        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 220          |\n",
            "|    time_elapsed         | 1036         |\n",
            "|    total_timesteps      | 450560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041983295 |\n",
            "|    clip_fraction        | 0.0253       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.91        |\n",
            "|    explained_variance   | 3.61e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0436       |\n",
            "|    n_updates            | 2190         |\n",
            "|    policy_gradient_loss | -0.00189     |\n",
            "|    reward               | -0.13813475  |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.128        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 434         |\n",
            "|    iterations           | 221         |\n",
            "|    time_elapsed         | 1041        |\n",
            "|    total_timesteps      | 452608      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004392241 |\n",
            "|    clip_fraction        | 0.0266      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.91       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.00944     |\n",
            "|    n_updates            | 2200        |\n",
            "|    policy_gradient_loss | -0.00245    |\n",
            "|    reward               | -0.07653234 |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 0.0582      |\n",
            "-----------------------------------------\n",
            "day: 2833, episode: 160\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -65664.50\n",
            "total_reward: -75664.50\n",
            "total_cost: 386.27\n",
            "total_trades: 2586\n",
            "Sharpe: -0.005\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 434         |\n",
            "|    iterations           | 222         |\n",
            "|    time_elapsed         | 1046        |\n",
            "|    total_timesteps      | 454656      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005764393 |\n",
            "|    clip_fraction        | 0.0315      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.9        |\n",
            "|    explained_variance   | 0.00612     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.021      |\n",
            "|    n_updates            | 2210        |\n",
            "|    policy_gradient_loss | -0.0021     |\n",
            "|    reward               | 0.18183516  |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 0.00781     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 434         |\n",
            "|    iterations           | 223         |\n",
            "|    time_elapsed         | 1051        |\n",
            "|    total_timesteps      | 456704      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005453151 |\n",
            "|    clip_fraction        | 0.0472      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.89       |\n",
            "|    explained_variance   | 0.0159      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0231     |\n",
            "|    n_updates            | 2220        |\n",
            "|    policy_gradient_loss | -0.00351    |\n",
            "|    reward               | 0.02603325  |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 0.0272      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 224          |\n",
            "|    time_elapsed         | 1055         |\n",
            "|    total_timesteps      | 458752       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045405356 |\n",
            "|    clip_fraction        | 0.0287       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.89        |\n",
            "|    explained_variance   | 0.0317       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.108        |\n",
            "|    n_updates            | 2230         |\n",
            "|    policy_gradient_loss | -0.00251     |\n",
            "|    reward               | -0.41823637  |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.3          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 434         |\n",
            "|    iterations           | 225         |\n",
            "|    time_elapsed         | 1060        |\n",
            "|    total_timesteps      | 460800      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001670879 |\n",
            "|    clip_fraction        | 0.0116      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.9        |\n",
            "|    explained_variance   | 0.0143      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0878      |\n",
            "|    n_updates            | 2240        |\n",
            "|    policy_gradient_loss | -0.000834   |\n",
            "|    reward               | -0.05141783 |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 0.288       |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 434           |\n",
            "|    iterations           | 226           |\n",
            "|    time_elapsed         | 1065          |\n",
            "|    total_timesteps      | 462848        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0043434566  |\n",
            "|    clip_fraction        | 0.0276        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.9          |\n",
            "|    explained_variance   | 0.127         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.274         |\n",
            "|    n_updates            | 2250          |\n",
            "|    policy_gradient_loss | -0.00172      |\n",
            "|    reward               | 0.00032239698 |\n",
            "|    std                  | 1.04          |\n",
            "|    value_loss           | 0.36          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 227          |\n",
            "|    time_elapsed         | 1070         |\n",
            "|    total_timesteps      | 464896       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046109054 |\n",
            "|    clip_fraction        | 0.0294       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.89        |\n",
            "|    explained_variance   | 0.417        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.024        |\n",
            "|    n_updates            | 2260         |\n",
            "|    policy_gradient_loss | -0.00376     |\n",
            "|    reward               | 0.004868993  |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.195        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 228          |\n",
            "|    time_elapsed         | 1075         |\n",
            "|    total_timesteps      | 466944       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025807503 |\n",
            "|    clip_fraction        | 0.00952      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.89        |\n",
            "|    explained_variance   | 0.355        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.115        |\n",
            "|    n_updates            | 2270         |\n",
            "|    policy_gradient_loss | -0.00239     |\n",
            "|    reward               | -0.01846131  |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.263        |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 165\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -53678.90\n",
            "total_reward: -63678.90\n",
            "total_cost: 405.83\n",
            "total_trades: 2714\n",
            "Sharpe: 0.057\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 229          |\n",
            "|    time_elapsed         | 1079         |\n",
            "|    total_timesteps      | 468992       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032809516 |\n",
            "|    clip_fraction        | 0.00771      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.9         |\n",
            "|    explained_variance   | 0.738        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0341      |\n",
            "|    n_updates            | 2280         |\n",
            "|    policy_gradient_loss | -0.00182     |\n",
            "|    reward               | 0.06857078   |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.0192       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 230          |\n",
            "|    time_elapsed         | 1084         |\n",
            "|    total_timesteps      | 471040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044520143 |\n",
            "|    clip_fraction        | 0.0131       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.9         |\n",
            "|    explained_variance   | 0.867        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0197      |\n",
            "|    n_updates            | 2290         |\n",
            "|    policy_gradient_loss | -0.0028      |\n",
            "|    reward               | 0.0058844932 |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.0149       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 231          |\n",
            "|    time_elapsed         | 1089         |\n",
            "|    total_timesteps      | 473088       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053191753 |\n",
            "|    clip_fraction        | 0.0551       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.9         |\n",
            "|    explained_variance   | 0.805        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0244      |\n",
            "|    n_updates            | 2300         |\n",
            "|    policy_gradient_loss | -0.004       |\n",
            "|    reward               | -0.051567376 |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.0169       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 434         |\n",
            "|    iterations           | 232         |\n",
            "|    time_elapsed         | 1094        |\n",
            "|    total_timesteps      | 475136      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002457791 |\n",
            "|    clip_fraction        | 0.0373      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.9        |\n",
            "|    explained_variance   | 0.489       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0123     |\n",
            "|    n_updates            | 2310        |\n",
            "|    policy_gradient_loss | -0.0035     |\n",
            "|    reward               | 0.11432891  |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 0.0333      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 233          |\n",
            "|    time_elapsed         | 1098         |\n",
            "|    total_timesteps      | 477184       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013513372 |\n",
            "|    clip_fraction        | 0.00981      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.91        |\n",
            "|    explained_variance   | 0.677        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0299      |\n",
            "|    n_updates            | 2320         |\n",
            "|    policy_gradient_loss | -0.00215     |\n",
            "|    reward               | 0.051276036  |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.0147       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 234          |\n",
            "|    time_elapsed         | 1103         |\n",
            "|    total_timesteps      | 479232       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011559173 |\n",
            "|    clip_fraction        | 0.00376      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.91        |\n",
            "|    explained_variance   | 0.539        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0107      |\n",
            "|    n_updates            | 2330         |\n",
            "|    policy_gradient_loss | -0.00072     |\n",
            "|    reward               | 0.008291163  |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.0377       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 235          |\n",
            "|    time_elapsed         | 1108         |\n",
            "|    total_timesteps      | 481280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023488374 |\n",
            "|    clip_fraction        | 0.0318       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.91        |\n",
            "|    explained_variance   | 0.0187       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.459        |\n",
            "|    n_updates            | 2340         |\n",
            "|    policy_gradient_loss | -0.00197     |\n",
            "|    reward               | 0.0007958908 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.802        |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 170\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -205575.44\n",
            "total_reward: -215575.44\n",
            "total_cost: 416.70\n",
            "total_trades: 2672\n",
            "Sharpe: -0.104\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 434         |\n",
            "|    iterations           | 236         |\n",
            "|    time_elapsed         | 1113        |\n",
            "|    total_timesteps      | 483328      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001267533 |\n",
            "|    clip_fraction        | 0.0109      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.91       |\n",
            "|    explained_variance   | 0.328       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0107      |\n",
            "|    n_updates            | 2350        |\n",
            "|    policy_gradient_loss | -0.000883   |\n",
            "|    reward               | -0.04819676 |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 0.0837      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 237          |\n",
            "|    time_elapsed         | 1118         |\n",
            "|    total_timesteps      | 485376       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059011457 |\n",
            "|    clip_fraction        | 0.00977      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.91        |\n",
            "|    explained_variance   | 0.249        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0891       |\n",
            "|    n_updates            | 2360         |\n",
            "|    policy_gradient_loss | -0.000263    |\n",
            "|    reward               | 0.004883821  |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.185        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 238          |\n",
            "|    time_elapsed         | 1122         |\n",
            "|    total_timesteps      | 487424       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026032827 |\n",
            "|    clip_fraction        | 0.0157       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.92        |\n",
            "|    explained_variance   | 0.304        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.019        |\n",
            "|    n_updates            | 2370         |\n",
            "|    policy_gradient_loss | -0.00017     |\n",
            "|    reward               | 0.15459304   |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.128        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 239          |\n",
            "|    time_elapsed         | 1127         |\n",
            "|    total_timesteps      | 489472       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.001897692  |\n",
            "|    clip_fraction        | 0.00249      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.91        |\n",
            "|    explained_variance   | 0.145        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0422       |\n",
            "|    n_updates            | 2380         |\n",
            "|    policy_gradient_loss | 0.00012      |\n",
            "|    reward               | -0.046943337 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.156        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 434         |\n",
            "|    iterations           | 240         |\n",
            "|    time_elapsed         | 1132        |\n",
            "|    total_timesteps      | 491520      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002242444 |\n",
            "|    clip_fraction        | 0.0149      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.92       |\n",
            "|    explained_variance   | 0.789       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.02       |\n",
            "|    n_updates            | 2390        |\n",
            "|    policy_gradient_loss | -0.00051    |\n",
            "|    reward               | -0.02092191 |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 0.016       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 241          |\n",
            "|    time_elapsed         | 1137         |\n",
            "|    total_timesteps      | 493568       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053443476 |\n",
            "|    clip_fraction        | 0.0126       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.93        |\n",
            "|    explained_variance   | 0.474        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.013       |\n",
            "|    n_updates            | 2400         |\n",
            "|    policy_gradient_loss | -0.00153     |\n",
            "|    reward               | -0.010920355 |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.0739       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 242          |\n",
            "|    time_elapsed         | 1141         |\n",
            "|    total_timesteps      | 495616       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026163557 |\n",
            "|    clip_fraction        | 0.000732     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.93        |\n",
            "|    explained_variance   | 0.18         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.035        |\n",
            "|    n_updates            | 2410         |\n",
            "|    policy_gradient_loss | 6.34e-05     |\n",
            "|    reward               | 0.6415886    |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.153        |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 175\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -118503.29\n",
            "total_reward: -128503.29\n",
            "total_cost: 406.58\n",
            "total_trades: 2658\n",
            "Sharpe: -0.422\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 243          |\n",
            "|    time_elapsed         | 1146         |\n",
            "|    total_timesteps      | 497664       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021091094 |\n",
            "|    clip_fraction        | 0.0212       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.94        |\n",
            "|    explained_variance   | 0.412        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0175      |\n",
            "|    n_updates            | 2420         |\n",
            "|    policy_gradient_loss | -0.000683    |\n",
            "|    reward               | 0.0038650527 |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.0532       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 244          |\n",
            "|    time_elapsed         | 1151         |\n",
            "|    total_timesteps      | 499712       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053626206 |\n",
            "|    clip_fraction        | 0.0445       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.95        |\n",
            "|    explained_variance   | 0.504        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0184      |\n",
            "|    n_updates            | 2430         |\n",
            "|    policy_gradient_loss | -0.00356     |\n",
            "|    reward               | -0.006400482 |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.0622       |\n",
            "------------------------------------------\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 433            |\n",
            "|    iterations           | 245            |\n",
            "|    time_elapsed         | 1156           |\n",
            "|    total_timesteps      | 501760         |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.00010454285  |\n",
            "|    clip_fraction        | 0              |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -2.95          |\n",
            "|    explained_variance   | 0.158          |\n",
            "|    learning_rate        | 0.00025        |\n",
            "|    loss                 | 0.0266         |\n",
            "|    n_updates            | 2440           |\n",
            "|    policy_gradient_loss | -5.81e-06      |\n",
            "|    reward               | -0.00046859437 |\n",
            "|    std                  | 1.07           |\n",
            "|    value_loss           | 0.177          |\n",
            "--------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 246          |\n",
            "|    time_elapsed         | 1161         |\n",
            "|    total_timesteps      | 503808       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047683557 |\n",
            "|    clip_fraction        | 0.0174       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.96        |\n",
            "|    explained_variance   | 0.0923       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0799       |\n",
            "|    n_updates            | 2450         |\n",
            "|    policy_gradient_loss | -0.000545    |\n",
            "|    reward               | -0.20045172  |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 0.166        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 247          |\n",
            "|    time_elapsed         | 1165         |\n",
            "|    total_timesteps      | 505856       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029829938 |\n",
            "|    clip_fraction        | 0.0226       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.97        |\n",
            "|    explained_variance   | 0.686        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0123      |\n",
            "|    n_updates            | 2460         |\n",
            "|    policy_gradient_loss | -0.00127     |\n",
            "|    reward               | -0.077011764 |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.0232       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 433           |\n",
            "|    iterations           | 248           |\n",
            "|    time_elapsed         | 1170          |\n",
            "|    total_timesteps      | 507904        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00059488555 |\n",
            "|    clip_fraction        | 0.000537      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.98         |\n",
            "|    explained_variance   | 0.403         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.00158       |\n",
            "|    n_updates            | 2470          |\n",
            "|    policy_gradient_loss | 0.000205      |\n",
            "|    reward               | 0.00020170498 |\n",
            "|    std                  | 1.09          |\n",
            "|    value_loss           | 0.0872        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 249          |\n",
            "|    time_elapsed         | 1175         |\n",
            "|    total_timesteps      | 509952       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030507662 |\n",
            "|    clip_fraction        | 0.0184       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.99        |\n",
            "|    explained_variance   | 0.496        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00276      |\n",
            "|    n_updates            | 2480         |\n",
            "|    policy_gradient_loss | -0.000144    |\n",
            "|    reward               | -0.08416232  |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.0496       |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 180\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -73680.53\n",
            "total_reward: -83680.53\n",
            "total_cost: 392.22\n",
            "total_trades: 2622\n",
            "Sharpe: 0.712\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 250          |\n",
            "|    time_elapsed         | 1180         |\n",
            "|    total_timesteps      | 512000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055047455 |\n",
            "|    clip_fraction        | 0.0171       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.99        |\n",
            "|    explained_variance   | 0.583        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0292      |\n",
            "|    n_updates            | 2490         |\n",
            "|    policy_gradient_loss | -0.00115     |\n",
            "|    reward               | 0.0007712898 |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.0244       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 251          |\n",
            "|    time_elapsed         | 1184         |\n",
            "|    total_timesteps      | 514048       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032855552 |\n",
            "|    clip_fraction        | 0.0402       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.99        |\n",
            "|    explained_variance   | 0.743        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0309      |\n",
            "|    n_updates            | 2500         |\n",
            "|    policy_gradient_loss | -0.00168     |\n",
            "|    reward               | -0.005526428 |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.0174       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 252          |\n",
            "|    time_elapsed         | 1189         |\n",
            "|    total_timesteps      | 516096       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020830731 |\n",
            "|    clip_fraction        | 0.0164       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.99        |\n",
            "|    explained_variance   | 0.301        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0344       |\n",
            "|    n_updates            | 2510         |\n",
            "|    policy_gradient_loss | 0.00107      |\n",
            "|    reward               | -0.019233128 |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.126        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 253          |\n",
            "|    time_elapsed         | 1194         |\n",
            "|    total_timesteps      | 518144       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0065081697 |\n",
            "|    clip_fraction        | 0.031        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3           |\n",
            "|    explained_variance   | 0.248        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0417       |\n",
            "|    n_updates            | 2520         |\n",
            "|    policy_gradient_loss | -0.00153     |\n",
            "|    reward               | 0.013372704  |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.0909       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 433         |\n",
            "|    iterations           | 254         |\n",
            "|    time_elapsed         | 1199        |\n",
            "|    total_timesteps      | 520192      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003949049 |\n",
            "|    clip_fraction        | 0.00654     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.99       |\n",
            "|    explained_variance   | 0.433       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0162     |\n",
            "|    n_updates            | 2530        |\n",
            "|    policy_gradient_loss | -0.000652   |\n",
            "|    reward               | 0.16221438  |\n",
            "|    std                  | 1.1         |\n",
            "|    value_loss           | 0.0641      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 433         |\n",
            "|    iterations           | 255         |\n",
            "|    time_elapsed         | 1203        |\n",
            "|    total_timesteps      | 522240      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005361775 |\n",
            "|    clip_fraction        | 0.0544      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3          |\n",
            "|    explained_variance   | 0.267       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0765      |\n",
            "|    n_updates            | 2540        |\n",
            "|    policy_gradient_loss | -0.00401    |\n",
            "|    reward               | -0.00847515 |\n",
            "|    std                  | 1.1         |\n",
            "|    value_loss           | 0.169       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 256          |\n",
            "|    time_elapsed         | 1208         |\n",
            "|    total_timesteps      | 524288       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069005163 |\n",
            "|    clip_fraction        | 0.0521       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | 0.167        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.118        |\n",
            "|    n_updates            | 2550         |\n",
            "|    policy_gradient_loss | -0.00272     |\n",
            "|    reward               | 0.43279275   |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.256        |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 185\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -206734.83\n",
            "total_reward: -216734.83\n",
            "total_cost: 468.31\n",
            "total_trades: 2756\n",
            "Sharpe: 0.239\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 257          |\n",
            "|    time_elapsed         | 1213         |\n",
            "|    total_timesteps      | 526336       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052194986 |\n",
            "|    clip_fraction        | 0.0105       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | -0.0251      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.211        |\n",
            "|    n_updates            | 2560         |\n",
            "|    policy_gradient_loss | -0.000937    |\n",
            "|    reward               | 0.0363409    |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.361        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 258          |\n",
            "|    time_elapsed         | 1217         |\n",
            "|    total_timesteps      | 528384       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059368927 |\n",
            "|    clip_fraction        | 0.0363       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 0.631        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0265      |\n",
            "|    n_updates            | 2570         |\n",
            "|    policy_gradient_loss | -0.00197     |\n",
            "|    reward               | -0.021214759 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.0352       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 259          |\n",
            "|    time_elapsed         | 1222         |\n",
            "|    total_timesteps      | 530432       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032764585 |\n",
            "|    clip_fraction        | 0.00859      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 0.21         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0898       |\n",
            "|    n_updates            | 2580         |\n",
            "|    policy_gradient_loss | -0.000187    |\n",
            "|    reward               | -0.015813146 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.316        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 260          |\n",
            "|    time_elapsed         | 1227         |\n",
            "|    total_timesteps      | 532480       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005356752 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 0.0601       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.136        |\n",
            "|    n_updates            | 2590         |\n",
            "|    policy_gradient_loss | -1.77e-05    |\n",
            "|    reward               | -0.32269466  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.301        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 433         |\n",
            "|    iterations           | 261         |\n",
            "|    time_elapsed         | 1232        |\n",
            "|    total_timesteps      | 534528      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004584357 |\n",
            "|    clip_fraction        | 0.0247      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.03       |\n",
            "|    explained_variance   | 0.251       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.041       |\n",
            "|    n_updates            | 2600        |\n",
            "|    policy_gradient_loss | -0.000705   |\n",
            "|    reward               | 0.094693646 |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 0.13        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 262          |\n",
            "|    time_elapsed         | 1236         |\n",
            "|    total_timesteps      | 536576       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037667777 |\n",
            "|    clip_fraction        | 0.0109       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 0.501        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0257       |\n",
            "|    n_updates            | 2610         |\n",
            "|    policy_gradient_loss | -0.000299    |\n",
            "|    reward               | 0.009619583  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.0891       |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 190\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -152805.31\n",
            "total_reward: -162805.31\n",
            "total_cost: 442.19\n",
            "total_trades: 2782\n",
            "Sharpe: 0.554\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 263          |\n",
            "|    time_elapsed         | 1241         |\n",
            "|    total_timesteps      | 538624       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018688675 |\n",
            "|    clip_fraction        | 0.00083      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | 0.302        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0774       |\n",
            "|    n_updates            | 2620         |\n",
            "|    policy_gradient_loss | -0.000223    |\n",
            "|    reward               | 0.009479418  |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.235        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 264          |\n",
            "|    time_elapsed         | 1246         |\n",
            "|    total_timesteps      | 540672       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051584095 |\n",
            "|    clip_fraction        | 0.0662       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 0.143        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.049        |\n",
            "|    n_updates            | 2630         |\n",
            "|    policy_gradient_loss | -0.00332     |\n",
            "|    reward               | -0.24987498  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.193        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 265          |\n",
            "|    time_elapsed         | 1251         |\n",
            "|    total_timesteps      | 542720       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040261624 |\n",
            "|    clip_fraction        | 0.00293      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 0.6          |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00405     |\n",
            "|    n_updates            | 2640         |\n",
            "|    policy_gradient_loss | 5.69e-05     |\n",
            "|    reward               | -0.013150188 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.0582       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 433         |\n",
            "|    iterations           | 266         |\n",
            "|    time_elapsed         | 1256        |\n",
            "|    total_timesteps      | 544768      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.000279724 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.02       |\n",
            "|    explained_variance   | 0.179       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.155       |\n",
            "|    n_updates            | 2650        |\n",
            "|    policy_gradient_loss | -0.000246   |\n",
            "|    reward               | 0.004852634 |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 0.345       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 267          |\n",
            "|    time_elapsed         | 1261         |\n",
            "|    total_timesteps      | 546816       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048472094 |\n",
            "|    clip_fraction        | 0.0464       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | -0.0492      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.307        |\n",
            "|    n_updates            | 2660         |\n",
            "|    policy_gradient_loss | -0.00308     |\n",
            "|    reward               | 0.24487635   |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.559        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 268          |\n",
            "|    time_elapsed         | 1266         |\n",
            "|    total_timesteps      | 548864       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012421897 |\n",
            "|    clip_fraction        | 0.024        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.107        |\n",
            "|    n_updates            | 2670         |\n",
            "|    policy_gradient_loss | -0.000817    |\n",
            "|    reward               | -0.01253555  |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.301        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 433           |\n",
            "|    iterations           | 269           |\n",
            "|    time_elapsed         | 1271          |\n",
            "|    total_timesteps      | 550912        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0014652731  |\n",
            "|    clip_fraction        | 0.0117        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.07         |\n",
            "|    explained_variance   | -0.00381      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0139        |\n",
            "|    n_updates            | 2680          |\n",
            "|    policy_gradient_loss | 5.98e-05      |\n",
            "|    reward               | -0.0046502706 |\n",
            "|    std                  | 1.13          |\n",
            "|    value_loss           | 0.0969        |\n",
            "-------------------------------------------\n",
            "day: 2833, episode: 195\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -193984.41\n",
            "total_reward: -203984.41\n",
            "total_cost: 478.21\n",
            "total_trades: 2766\n",
            "Sharpe: -0.346\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 433           |\n",
            "|    iterations           | 270           |\n",
            "|    time_elapsed         | 1276          |\n",
            "|    total_timesteps      | 552960        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0060406616  |\n",
            "|    clip_fraction        | 0.0136        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.07         |\n",
            "|    explained_variance   | 0.0876        |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.117         |\n",
            "|    n_updates            | 2690          |\n",
            "|    policy_gradient_loss | -0.000856     |\n",
            "|    reward               | -0.0023666937 |\n",
            "|    std                  | 1.13          |\n",
            "|    value_loss           | 0.305         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 271          |\n",
            "|    time_elapsed         | 1281         |\n",
            "|    total_timesteps      | 555008       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050287293 |\n",
            "|    clip_fraction        | 0.0444       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 0.0769       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.146        |\n",
            "|    n_updates            | 2700         |\n",
            "|    policy_gradient_loss | -0.00155     |\n",
            "|    reward               | -0.122378014 |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 0.324        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 433         |\n",
            "|    iterations           | 272         |\n",
            "|    time_elapsed         | 1285        |\n",
            "|    total_timesteps      | 557056      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004409573 |\n",
            "|    clip_fraction        | 0.0147      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.09       |\n",
            "|    explained_variance   | -0.000158   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.00839     |\n",
            "|    n_updates            | 2710        |\n",
            "|    policy_gradient_loss | -0.000792   |\n",
            "|    reward               | 0.046497382 |\n",
            "|    std                  | 1.14        |\n",
            "|    value_loss           | 0.0982      |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 433           |\n",
            "|    iterations           | 273           |\n",
            "|    time_elapsed         | 1290          |\n",
            "|    total_timesteps      | 559104        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0019255548  |\n",
            "|    clip_fraction        | 0.0182        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.1          |\n",
            "|    explained_variance   | 0.0821        |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.138         |\n",
            "|    n_updates            | 2720          |\n",
            "|    policy_gradient_loss | -0.00182      |\n",
            "|    reward               | -0.0056901393 |\n",
            "|    std                  | 1.15          |\n",
            "|    value_loss           | 0.255         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 274          |\n",
            "|    time_elapsed         | 1295         |\n",
            "|    total_timesteps      | 561152       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041044503 |\n",
            "|    clip_fraction        | 0.026        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.11        |\n",
            "|    explained_variance   | 0.0587       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.12         |\n",
            "|    n_updates            | 2730         |\n",
            "|    policy_gradient_loss | -0.00241     |\n",
            "|    reward               | 0.025209656  |\n",
            "|    std                  | 1.16         |\n",
            "|    value_loss           | 0.382        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 275          |\n",
            "|    time_elapsed         | 1300         |\n",
            "|    total_timesteps      | 563200       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020402977 |\n",
            "|    clip_fraction        | 0.017        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.12        |\n",
            "|    explained_variance   | -0.00064     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.157        |\n",
            "|    n_updates            | 2740         |\n",
            "|    policy_gradient_loss | -0.000878    |\n",
            "|    reward               | 0.009992926  |\n",
            "|    std                  | 1.16         |\n",
            "|    value_loss           | 0.491        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 276          |\n",
            "|    time_elapsed         | 1304         |\n",
            "|    total_timesteps      | 565248       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005599484  |\n",
            "|    clip_fraction        | 0.0573       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.11        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0279      |\n",
            "|    n_updates            | 2750         |\n",
            "|    policy_gradient_loss | -0.00399     |\n",
            "|    reward               | 0.0002507324 |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 0.0493       |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 200\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -203199.09\n",
            "total_reward: -213199.09\n",
            "total_cost: 486.91\n",
            "total_trades: 2754\n",
            "Sharpe: -0.116\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 277          |\n",
            "|    time_elapsed         | 1310         |\n",
            "|    total_timesteps      | 567296       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035403515 |\n",
            "|    clip_fraction        | 0.0189       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.1         |\n",
            "|    explained_variance   | 0.0677       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.136        |\n",
            "|    n_updates            | 2760         |\n",
            "|    policy_gradient_loss | -0.00203     |\n",
            "|    reward               | 0.005090147  |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 0.402        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 278          |\n",
            "|    time_elapsed         | 1314         |\n",
            "|    total_timesteps      | 569344       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018126371 |\n",
            "|    clip_fraction        | 0.00176      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.1         |\n",
            "|    explained_variance   | 0.0706       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.135        |\n",
            "|    n_updates            | 2770         |\n",
            "|    policy_gradient_loss | -0.000771    |\n",
            "|    reward               | -0.030875972 |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 0.352        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 433           |\n",
            "|    iterations           | 279           |\n",
            "|    time_elapsed         | 1319          |\n",
            "|    total_timesteps      | 571392        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.004490227   |\n",
            "|    clip_fraction        | 0.0284        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.11         |\n",
            "|    explained_variance   | 7.99e-06      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.139         |\n",
            "|    n_updates            | 2780          |\n",
            "|    policy_gradient_loss | -0.00231      |\n",
            "|    reward               | -0.0039415983 |\n",
            "|    std                  | 1.16          |\n",
            "|    value_loss           | 0.277         |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 433         |\n",
            "|    iterations           | 280         |\n",
            "|    time_elapsed         | 1324        |\n",
            "|    total_timesteps      | 573440      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.0010698   |\n",
            "|    clip_fraction        | 0.000977    |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.13       |\n",
            "|    explained_variance   | 0.00586     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.137       |\n",
            "|    n_updates            | 2790        |\n",
            "|    policy_gradient_loss | -9.76e-05   |\n",
            "|    reward               | -0.04089761 |\n",
            "|    std                  | 1.17        |\n",
            "|    value_loss           | 0.217       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 281          |\n",
            "|    time_elapsed         | 1328         |\n",
            "|    total_timesteps      | 575488       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.002310477  |\n",
            "|    clip_fraction        | 0.000781     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.14        |\n",
            "|    explained_variance   | 0.0225       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.118        |\n",
            "|    n_updates            | 2800         |\n",
            "|    policy_gradient_loss | -0.000351    |\n",
            "|    reward               | -0.012820006 |\n",
            "|    std                  | 1.17         |\n",
            "|    value_loss           | 0.346        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 282          |\n",
            "|    time_elapsed         | 1333         |\n",
            "|    total_timesteps      | 577536       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054483176 |\n",
            "|    clip_fraction        | 0.0354       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.14        |\n",
            "|    explained_variance   | 0.0488       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0703       |\n",
            "|    n_updates            | 2810         |\n",
            "|    policy_gradient_loss | -0.00191     |\n",
            "|    reward               | -0.027609307 |\n",
            "|    std                  | 1.17         |\n",
            "|    value_loss           | 0.276        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 283          |\n",
            "|    time_elapsed         | 1338         |\n",
            "|    total_timesteps      | 579584       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017624274 |\n",
            "|    clip_fraction        | 0.0116       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.15        |\n",
            "|    explained_variance   | 0.362        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00596      |\n",
            "|    n_updates            | 2820         |\n",
            "|    policy_gradient_loss | -0.000678    |\n",
            "|    reward               | 0.063316725  |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 0.084        |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 205\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -184180.08\n",
            "total_reward: -194180.08\n",
            "total_cost: 428.78\n",
            "total_trades: 2698\n",
            "Sharpe: -0.231\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 432         |\n",
            "|    iterations           | 284         |\n",
            "|    time_elapsed         | 1343        |\n",
            "|    total_timesteps      | 581632      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004995595 |\n",
            "|    clip_fraction        | 0.00786     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.16       |\n",
            "|    explained_variance   | 0.164       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.152       |\n",
            "|    n_updates            | 2830        |\n",
            "|    policy_gradient_loss | -0.000382   |\n",
            "|    reward               | 0.014082536 |\n",
            "|    std                  | 1.18        |\n",
            "|    value_loss           | 0.365       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 285          |\n",
            "|    time_elapsed         | 1348         |\n",
            "|    total_timesteps      | 583680       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018979694 |\n",
            "|    clip_fraction        | 0.00693      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.15        |\n",
            "|    explained_variance   | 0.262        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0769       |\n",
            "|    n_updates            | 2840         |\n",
            "|    policy_gradient_loss | -0.000647    |\n",
            "|    reward               | 0.078688666  |\n",
            "|    std                  | 1.17         |\n",
            "|    value_loss           | 0.276        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 432         |\n",
            "|    iterations           | 286         |\n",
            "|    time_elapsed         | 1352        |\n",
            "|    total_timesteps      | 585728      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003197468 |\n",
            "|    clip_fraction        | 0.0102      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.14       |\n",
            "|    explained_variance   | 0.283       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0581      |\n",
            "|    n_updates            | 2850        |\n",
            "|    policy_gradient_loss | -0.00117    |\n",
            "|    reward               | -0.08814465 |\n",
            "|    std                  | 1.17        |\n",
            "|    value_loss           | 0.111       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 432         |\n",
            "|    iterations           | 287         |\n",
            "|    time_elapsed         | 1357        |\n",
            "|    total_timesteps      | 587776      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001529834 |\n",
            "|    clip_fraction        | 0.00806     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.14       |\n",
            "|    explained_variance   | 0.726       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0279     |\n",
            "|    n_updates            | 2860        |\n",
            "|    policy_gradient_loss | -0.000714   |\n",
            "|    reward               | -0.05953543 |\n",
            "|    std                  | 1.17        |\n",
            "|    value_loss           | 0.0328      |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 432           |\n",
            "|    iterations           | 288           |\n",
            "|    time_elapsed         | 1362          |\n",
            "|    total_timesteps      | 589824        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00066227023 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.14         |\n",
            "|    explained_variance   | 0.369         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0319        |\n",
            "|    n_updates            | 2870          |\n",
            "|    policy_gradient_loss | -0.000331     |\n",
            "|    reward               | -0.04221865   |\n",
            "|    std                  | 1.17          |\n",
            "|    value_loss           | 0.159         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 289          |\n",
            "|    time_elapsed         | 1366         |\n",
            "|    total_timesteps      | 591872       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052075144 |\n",
            "|    clip_fraction        | 0.0479       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.14        |\n",
            "|    explained_variance   | 0.135        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.065        |\n",
            "|    n_updates            | 2880         |\n",
            "|    policy_gradient_loss | -0.00361     |\n",
            "|    reward               | -0.028867396 |\n",
            "|    std                  | 1.17         |\n",
            "|    value_loss           | 0.306        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 290          |\n",
            "|    time_elapsed         | 1371         |\n",
            "|    total_timesteps      | 593920       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005252293  |\n",
            "|    clip_fraction        | 0.0247       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.15        |\n",
            "|    explained_variance   | 0.477        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0213      |\n",
            "|    n_updates            | 2890         |\n",
            "|    policy_gradient_loss | -0.00196     |\n",
            "|    reward               | -0.009653736 |\n",
            "|    std                  | 1.17         |\n",
            "|    value_loss           | 0.0699       |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 210\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -143795.21\n",
            "total_reward: -153795.21\n",
            "total_cost: 384.58\n",
            "total_trades: 2550\n",
            "Sharpe: -0.392\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 291          |\n",
            "|    time_elapsed         | 1376         |\n",
            "|    total_timesteps      | 595968       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004845857  |\n",
            "|    clip_fraction        | 0.0341       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.14        |\n",
            "|    explained_variance   | 0.344        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0389       |\n",
            "|    n_updates            | 2900         |\n",
            "|    policy_gradient_loss | -0.0013      |\n",
            "|    reward               | 0.0020219763 |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 0.181        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 292          |\n",
            "|    time_elapsed         | 1381         |\n",
            "|    total_timesteps      | 598016       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044643814 |\n",
            "|    clip_fraction        | 0.0225       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.14        |\n",
            "|    explained_variance   | 0.406        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.046        |\n",
            "|    n_updates            | 2910         |\n",
            "|    policy_gradient_loss | -0.00135     |\n",
            "|    reward               | -0.008388997 |\n",
            "|    std                  | 1.17         |\n",
            "|    value_loss           | 0.156        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 293          |\n",
            "|    time_elapsed         | 1386         |\n",
            "|    total_timesteps      | 600064       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.003282003  |\n",
            "|    clip_fraction        | 0.015        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.14        |\n",
            "|    explained_variance   | 0.199        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0384       |\n",
            "|    n_updates            | 2920         |\n",
            "|    policy_gradient_loss | -0.000688    |\n",
            "|    reward               | 0.0044046347 |\n",
            "|    std                  | 1.17         |\n",
            "|    value_loss           | 0.111        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 294          |\n",
            "|    time_elapsed         | 1391         |\n",
            "|    total_timesteps      | 602112       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036356922 |\n",
            "|    clip_fraction        | 0.015        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.14        |\n",
            "|    explained_variance   | 0.841        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0245      |\n",
            "|    n_updates            | 2930         |\n",
            "|    policy_gradient_loss | -0.000203    |\n",
            "|    reward               | 0.07733978   |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 0.011        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 432         |\n",
            "|    iterations           | 295         |\n",
            "|    time_elapsed         | 1396        |\n",
            "|    total_timesteps      | 604160      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005228923 |\n",
            "|    clip_fraction        | 0.0369      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.14       |\n",
            "|    explained_variance   | 0.554       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.00105    |\n",
            "|    n_updates            | 2940        |\n",
            "|    policy_gradient_loss | -0.00195    |\n",
            "|    reward               | 0.013124167 |\n",
            "|    std                  | 1.17        |\n",
            "|    value_loss           | 0.0561      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 296          |\n",
            "|    time_elapsed         | 1400         |\n",
            "|    total_timesteps      | 606208       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048714764 |\n",
            "|    clip_fraction        | 0.019        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.14        |\n",
            "|    explained_variance   | 0.42         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00077      |\n",
            "|    n_updates            | 2950         |\n",
            "|    policy_gradient_loss | -0.000784    |\n",
            "|    reward               | 0.436182     |\n",
            "|    std                  | 1.17         |\n",
            "|    value_loss           | 0.0787       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 297          |\n",
            "|    time_elapsed         | 1405         |\n",
            "|    total_timesteps      | 608256       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013071896 |\n",
            "|    clip_fraction        | 0.0114       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.14        |\n",
            "|    explained_variance   | 0.494        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0141      |\n",
            "|    n_updates            | 2960         |\n",
            "|    policy_gradient_loss | -0.000275    |\n",
            "|    reward               | -0.02500719  |\n",
            "|    std                  | 1.17         |\n",
            "|    value_loss           | 0.033        |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 215\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -67893.38\n",
            "total_reward: -77893.38\n",
            "total_cost: 388.45\n",
            "total_trades: 2674\n",
            "Sharpe: 0.560\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 298          |\n",
            "|    time_elapsed         | 1410         |\n",
            "|    total_timesteps      | 610304       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004262449  |\n",
            "|    clip_fraction        | 0.00532      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.14        |\n",
            "|    explained_variance   | 0.731        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0193      |\n",
            "|    n_updates            | 2970         |\n",
            "|    policy_gradient_loss | -0.00145     |\n",
            "|    reward               | 0.0043075164 |\n",
            "|    std                  | 1.17         |\n",
            "|    value_loss           | 0.0192       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 299          |\n",
            "|    time_elapsed         | 1415         |\n",
            "|    total_timesteps      | 612352       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010230012 |\n",
            "|    clip_fraction        | 4.88e-05     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.15        |\n",
            "|    explained_variance   | 0.629        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00792     |\n",
            "|    n_updates            | 2980         |\n",
            "|    policy_gradient_loss | 0.000106     |\n",
            "|    reward               | 0.0019818465 |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 0.0275       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 300          |\n",
            "|    time_elapsed         | 1420         |\n",
            "|    total_timesteps      | 614400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031343712 |\n",
            "|    clip_fraction        | 0.0102       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.15        |\n",
            "|    explained_variance   | 0.275        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00915     |\n",
            "|    n_updates            | 2990         |\n",
            "|    policy_gradient_loss | -0.0005      |\n",
            "|    reward               | 0.0863629    |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 0.0444       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 432           |\n",
            "|    iterations           | 301           |\n",
            "|    time_elapsed         | 1424          |\n",
            "|    total_timesteps      | 616448        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00028619176 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.15         |\n",
            "|    explained_variance   | 0.517         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0219       |\n",
            "|    n_updates            | 3000          |\n",
            "|    policy_gradient_loss | -6.92e-05     |\n",
            "|    reward               | 0.01298658    |\n",
            "|    std                  | 1.18          |\n",
            "|    value_loss           | 0.0166        |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 432         |\n",
            "|    iterations           | 302         |\n",
            "|    time_elapsed         | 1429        |\n",
            "|    total_timesteps      | 618496      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004477335 |\n",
            "|    clip_fraction        | 0.0178      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.16       |\n",
            "|    explained_variance   | 0.479       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0132     |\n",
            "|    n_updates            | 3010        |\n",
            "|    policy_gradient_loss | -0.00227    |\n",
            "|    reward               | -0.04090083 |\n",
            "|    std                  | 1.18        |\n",
            "|    value_loss           | 0.0387      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 432         |\n",
            "|    iterations           | 303         |\n",
            "|    time_elapsed         | 1434        |\n",
            "|    total_timesteps      | 620544      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.00436623  |\n",
            "|    clip_fraction        | 0.0309      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.16       |\n",
            "|    explained_variance   | 0.407       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0151     |\n",
            "|    n_updates            | 3020        |\n",
            "|    policy_gradient_loss | -0.00188    |\n",
            "|    reward               | -0.27981743 |\n",
            "|    std                  | 1.19        |\n",
            "|    value_loss           | 0.0265      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 304          |\n",
            "|    time_elapsed         | 1439         |\n",
            "|    total_timesteps      | 622592       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045741578 |\n",
            "|    clip_fraction        | 0.0504       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.17        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.088        |\n",
            "|    n_updates            | 3030         |\n",
            "|    policy_gradient_loss | -0.000796    |\n",
            "|    reward               | 0.17184293   |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 0.338        |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 220\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -293005.20\n",
            "total_reward: -303005.20\n",
            "total_cost: 428.97\n",
            "total_trades: 2672\n",
            "Sharpe: 0.145\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 305          |\n",
            "|    time_elapsed         | 1444         |\n",
            "|    total_timesteps      | 624640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035884406 |\n",
            "|    clip_fraction        | 0.0508       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.18        |\n",
            "|    explained_variance   | 0.214        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00309      |\n",
            "|    n_updates            | 3040         |\n",
            "|    policy_gradient_loss | -0.00239     |\n",
            "|    reward               | 0.12734245   |\n",
            "|    std                  | 1.2          |\n",
            "|    value_loss           | 0.0974       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 306          |\n",
            "|    time_elapsed         | 1448         |\n",
            "|    total_timesteps      | 626688       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004975323  |\n",
            "|    clip_fraction        | 0.0258       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.2         |\n",
            "|    explained_variance   | 0.137        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.167        |\n",
            "|    n_updates            | 3050         |\n",
            "|    policy_gradient_loss | -0.000361    |\n",
            "|    reward               | -0.028733145 |\n",
            "|    std                  | 1.2          |\n",
            "|    value_loss           | 0.394        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 432         |\n",
            "|    iterations           | 307         |\n",
            "|    time_elapsed         | 1453        |\n",
            "|    total_timesteps      | 628736      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002383603 |\n",
            "|    clip_fraction        | 0.0256      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.2        |\n",
            "|    explained_variance   | 0.131       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.228       |\n",
            "|    n_updates            | 3060        |\n",
            "|    policy_gradient_loss | -0.000463   |\n",
            "|    reward               | 0.0649614   |\n",
            "|    std                  | 1.2         |\n",
            "|    value_loss           | 0.378       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 308          |\n",
            "|    time_elapsed         | 1458         |\n",
            "|    total_timesteps      | 630784       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058357324 |\n",
            "|    clip_fraction        | 0.0407       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.2         |\n",
            "|    explained_variance   | 0.463        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0042       |\n",
            "|    n_updates            | 3070         |\n",
            "|    policy_gradient_loss | -0.00182     |\n",
            "|    reward               | -0.03693643  |\n",
            "|    std                  | 1.2          |\n",
            "|    value_loss           | 0.0849       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 432           |\n",
            "|    iterations           | 309           |\n",
            "|    time_elapsed         | 1463          |\n",
            "|    total_timesteps      | 632832        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.007133431   |\n",
            "|    clip_fraction        | 0.0401        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.2          |\n",
            "|    explained_variance   | 0.252         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0959        |\n",
            "|    n_updates            | 3080          |\n",
            "|    policy_gradient_loss | -0.00438      |\n",
            "|    reward               | -0.0008568142 |\n",
            "|    std                  | 1.21          |\n",
            "|    value_loss           | 0.16          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 310          |\n",
            "|    time_elapsed         | 1468         |\n",
            "|    total_timesteps      | 634880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013814078 |\n",
            "|    clip_fraction        | 0.0211       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.22        |\n",
            "|    explained_variance   | 0.293        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.11         |\n",
            "|    n_updates            | 3090         |\n",
            "|    policy_gradient_loss | -0.00232     |\n",
            "|    reward               | 0.004884897  |\n",
            "|    std                  | 1.22         |\n",
            "|    value_loss           | 0.326        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 311          |\n",
            "|    time_elapsed         | 1473         |\n",
            "|    total_timesteps      | 636928       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018302123 |\n",
            "|    clip_fraction        | 0.00723      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.23        |\n",
            "|    explained_variance   | 0.289        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0117      |\n",
            "|    n_updates            | 3100         |\n",
            "|    policy_gradient_loss | -0.000272    |\n",
            "|    reward               | -0.065256745 |\n",
            "|    std                  | 1.22         |\n",
            "|    value_loss           | 0.0534       |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 225\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -75691.44\n",
            "total_reward: -85691.44\n",
            "total_cost: 411.53\n",
            "total_trades: 2832\n",
            "Sharpe: 0.307\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 312          |\n",
            "|    time_elapsed         | 1478         |\n",
            "|    total_timesteps      | 638976       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025742939 |\n",
            "|    clip_fraction        | 0.0218       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.23        |\n",
            "|    explained_variance   | 0.877        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0183      |\n",
            "|    n_updates            | 3110         |\n",
            "|    policy_gradient_loss | -0.000488    |\n",
            "|    reward               | 0.17009446   |\n",
            "|    std                  | 1.22         |\n",
            "|    value_loss           | 0.0102       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 313          |\n",
            "|    time_elapsed         | 1483         |\n",
            "|    total_timesteps      | 641024       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019932315 |\n",
            "|    clip_fraction        | 0.0239       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.23        |\n",
            "|    explained_variance   | 0.461        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.000738     |\n",
            "|    n_updates            | 3120         |\n",
            "|    policy_gradient_loss | -0.000658    |\n",
            "|    reward               | -0.0117002   |\n",
            "|    std                  | 1.22         |\n",
            "|    value_loss           | 0.0564       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 314          |\n",
            "|    time_elapsed         | 1487         |\n",
            "|    total_timesteps      | 643072       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037205187 |\n",
            "|    clip_fraction        | 0.0271       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.24        |\n",
            "|    explained_variance   | 0.168        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.297        |\n",
            "|    n_updates            | 3130         |\n",
            "|    policy_gradient_loss | 0.00117      |\n",
            "|    reward               | -0.08202759  |\n",
            "|    std                  | 1.23         |\n",
            "|    value_loss           | 0.534        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 315          |\n",
            "|    time_elapsed         | 1492         |\n",
            "|    total_timesteps      | 645120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044052806 |\n",
            "|    clip_fraction        | 0.0144       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.24        |\n",
            "|    explained_variance   | 0.677        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.025       |\n",
            "|    n_updates            | 3140         |\n",
            "|    policy_gradient_loss | -0.00107     |\n",
            "|    reward               | 0.03866815   |\n",
            "|    std                  | 1.23         |\n",
            "|    value_loss           | 0.0275       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 316          |\n",
            "|    time_elapsed         | 1497         |\n",
            "|    total_timesteps      | 647168       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.002234162  |\n",
            "|    clip_fraction        | 0.0246       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.26        |\n",
            "|    explained_variance   | 0.542        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0078      |\n",
            "|    n_updates            | 3150         |\n",
            "|    policy_gradient_loss | -0.00174     |\n",
            "|    reward               | -0.007157216 |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 0.0577       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 317          |\n",
            "|    time_elapsed         | 1502         |\n",
            "|    total_timesteps      | 649216       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021585743 |\n",
            "|    clip_fraction        | 0.0145       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.27        |\n",
            "|    explained_variance   | 0.153        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.23         |\n",
            "|    n_updates            | 3160         |\n",
            "|    policy_gradient_loss | -0.000271    |\n",
            "|    reward               | 0.03904216   |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.426        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 432          |\n",
            "|    iterations           | 318          |\n",
            "|    time_elapsed         | 1507         |\n",
            "|    total_timesteps      | 651264       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015896338 |\n",
            "|    clip_fraction        | 0.0239       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | 0.518        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0319      |\n",
            "|    n_updates            | 3170         |\n",
            "|    policy_gradient_loss | 0.000531     |\n",
            "|    reward               | 0.08444808   |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 0.0378       |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 230\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -108373.12\n",
            "total_reward: -118373.12\n",
            "total_cost: 430.81\n",
            "total_trades: 2748\n",
            "Sharpe: 0.313\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 431         |\n",
            "|    iterations           | 319         |\n",
            "|    time_elapsed         | 1512        |\n",
            "|    total_timesteps      | 653312      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004463503 |\n",
            "|    clip_fraction        | 0.0294      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.28       |\n",
            "|    explained_variance   | 0.777       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0152     |\n",
            "|    n_updates            | 3180        |\n",
            "|    policy_gradient_loss | -0.00184    |\n",
            "|    reward               | 0.038014486 |\n",
            "|    std                  | 1.25        |\n",
            "|    value_loss           | 0.0216      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 431          |\n",
            "|    iterations           | 320          |\n",
            "|    time_elapsed         | 1517         |\n",
            "|    total_timesteps      | 655360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037133335 |\n",
            "|    clip_fraction        | 0.026        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | 0.551        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00176     |\n",
            "|    n_updates            | 3190         |\n",
            "|    policy_gradient_loss | -0.00191     |\n",
            "|    reward               | -0.005183749 |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.0662       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 431         |\n",
            "|    iterations           | 321         |\n",
            "|    time_elapsed         | 1522        |\n",
            "|    total_timesteps      | 657408      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.00591907  |\n",
            "|    clip_fraction        | 0.0227      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.29       |\n",
            "|    explained_variance   | 0.527       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.00808     |\n",
            "|    n_updates            | 3200        |\n",
            "|    policy_gradient_loss | -0.00122    |\n",
            "|    reward               | -0.16458936 |\n",
            "|    std                  | 1.25        |\n",
            "|    value_loss           | 0.0693      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 431          |\n",
            "|    iterations           | 322          |\n",
            "|    time_elapsed         | 1527         |\n",
            "|    total_timesteps      | 659456       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010130961 |\n",
            "|    clip_fraction        | 0.0147       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.29        |\n",
            "|    explained_variance   | 0.518        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0204      |\n",
            "|    n_updates            | 3210         |\n",
            "|    policy_gradient_loss | -0.000503    |\n",
            "|    reward               | 0.4090538    |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.0185       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 431          |\n",
            "|    iterations           | 323          |\n",
            "|    time_elapsed         | 1532         |\n",
            "|    total_timesteps      | 661504       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048306137 |\n",
            "|    clip_fraction        | 0.0541       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.29        |\n",
            "|    explained_variance   | 0.378        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0137      |\n",
            "|    n_updates            | 3220         |\n",
            "|    policy_gradient_loss | -0.00342     |\n",
            "|    reward               | 0.19742635   |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.0648       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 431          |\n",
            "|    iterations           | 324          |\n",
            "|    time_elapsed         | 1537         |\n",
            "|    total_timesteps      | 663552       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031260941 |\n",
            "|    clip_fraction        | 0.012        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.29        |\n",
            "|    explained_variance   | 0.123        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0997       |\n",
            "|    n_updates            | 3230         |\n",
            "|    policy_gradient_loss | -0.00088     |\n",
            "|    reward               | 0.056631397  |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.361        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 431         |\n",
            "|    iterations           | 325         |\n",
            "|    time_elapsed         | 1543        |\n",
            "|    total_timesteps      | 665600      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010392126 |\n",
            "|    clip_fraction        | 0.0869      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.29       |\n",
            "|    explained_variance   | 0.114       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.139       |\n",
            "|    n_updates            | 3240        |\n",
            "|    policy_gradient_loss | -0.00449    |\n",
            "|    reward               | -0.3961327  |\n",
            "|    std                  | 1.26        |\n",
            "|    value_loss           | 0.579       |\n",
            "-----------------------------------------\n",
            "day: 2833, episode: 235\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -252931.24\n",
            "total_reward: -262931.24\n",
            "total_cost: 407.69\n",
            "total_trades: 2582\n",
            "Sharpe: 0.253\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 431          |\n",
            "|    iterations           | 326          |\n",
            "|    time_elapsed         | 1548         |\n",
            "|    total_timesteps      | 667648       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024119052 |\n",
            "|    clip_fraction        | 0.0153       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.29        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0534       |\n",
            "|    n_updates            | 3250         |\n",
            "|    policy_gradient_loss | -0.000846    |\n",
            "|    reward               | -0.059372578 |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.163        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 431         |\n",
            "|    iterations           | 327         |\n",
            "|    time_elapsed         | 1553        |\n",
            "|    total_timesteps      | 669696      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002433272 |\n",
            "|    clip_fraction        | 0.0108      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.3        |\n",
            "|    explained_variance   | 0.208       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0824      |\n",
            "|    n_updates            | 3260        |\n",
            "|    policy_gradient_loss | -0.00173    |\n",
            "|    reward               | -0.02703874 |\n",
            "|    std                  | 1.26        |\n",
            "|    value_loss           | 0.282       |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 431           |\n",
            "|    iterations           | 328           |\n",
            "|    time_elapsed         | 1558          |\n",
            "|    total_timesteps      | 671744        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.004450025   |\n",
            "|    clip_fraction        | 0.0348        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.31         |\n",
            "|    explained_variance   | 0.203         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.119         |\n",
            "|    n_updates            | 3270          |\n",
            "|    policy_gradient_loss | -0.00104      |\n",
            "|    reward               | -0.0047507198 |\n",
            "|    std                  | 1.27          |\n",
            "|    value_loss           | 0.36          |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 430         |\n",
            "|    iterations           | 329         |\n",
            "|    time_elapsed         | 1563        |\n",
            "|    total_timesteps      | 673792      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006563563 |\n",
            "|    clip_fraction        | 0.0441      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.31       |\n",
            "|    explained_variance   | 0.183       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0204      |\n",
            "|    n_updates            | 3280        |\n",
            "|    policy_gradient_loss | -0.00346    |\n",
            "|    reward               | 0.007375337 |\n",
            "|    std                  | 1.27        |\n",
            "|    value_loss           | 0.111       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 330          |\n",
            "|    time_elapsed         | 1568         |\n",
            "|    total_timesteps      | 675840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005642214 |\n",
            "|    clip_fraction        | 0.00342      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.31        |\n",
            "|    explained_variance   | 0.933        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0282      |\n",
            "|    n_updates            | 3290         |\n",
            "|    policy_gradient_loss | 1.76e-05     |\n",
            "|    reward               | -0.118935384 |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.00942      |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 430           |\n",
            "|    iterations           | 331           |\n",
            "|    time_elapsed         | 1573          |\n",
            "|    total_timesteps      | 677888        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0032201568  |\n",
            "|    clip_fraction        | 0.0355        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.32         |\n",
            "|    explained_variance   | 0.764         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0295       |\n",
            "|    n_updates            | 3300          |\n",
            "|    policy_gradient_loss | -0.00279      |\n",
            "|    reward               | -0.0016397551 |\n",
            "|    std                  | 1.27          |\n",
            "|    value_loss           | 0.0166        |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 430           |\n",
            "|    iterations           | 332           |\n",
            "|    time_elapsed         | 1578          |\n",
            "|    total_timesteps      | 679936        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.004551878   |\n",
            "|    clip_fraction        | 0.0224        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.32         |\n",
            "|    explained_variance   | 0.346         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0389        |\n",
            "|    n_updates            | 3310          |\n",
            "|    policy_gradient_loss | -0.0018       |\n",
            "|    reward               | -0.0018981567 |\n",
            "|    std                  | 1.27          |\n",
            "|    value_loss           | 0.148         |\n",
            "-------------------------------------------\n",
            "day: 2833, episode: 240\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -133876.67\n",
            "total_reward: -143876.67\n",
            "total_cost: 401.80\n",
            "total_trades: 2696\n",
            "Sharpe: 0.529\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 333          |\n",
            "|    time_elapsed         | 1582         |\n",
            "|    total_timesteps      | 681984       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029152955 |\n",
            "|    clip_fraction        | 0.0239       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.32        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00087      |\n",
            "|    n_updates            | 3320         |\n",
            "|    policy_gradient_loss | -0.000712    |\n",
            "|    reward               | 0.1477073    |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.0642       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 334          |\n",
            "|    time_elapsed         | 1587         |\n",
            "|    total_timesteps      | 684032       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044978857 |\n",
            "|    clip_fraction        | 0.00996      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.33        |\n",
            "|    explained_variance   | 0.506        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0292      |\n",
            "|    n_updates            | 3330         |\n",
            "|    policy_gradient_loss | -0.000527    |\n",
            "|    reward               | -0.03303161  |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.0402       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 335          |\n",
            "|    time_elapsed         | 1592         |\n",
            "|    total_timesteps      | 686080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040392643 |\n",
            "|    clip_fraction        | 0.0265       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.33        |\n",
            "|    explained_variance   | 0.337        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00287      |\n",
            "|    n_updates            | 3340         |\n",
            "|    policy_gradient_loss | -0.00239     |\n",
            "|    reward               | 0.007265956  |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.0747       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 336          |\n",
            "|    time_elapsed         | 1597         |\n",
            "|    total_timesteps      | 688128       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043058833 |\n",
            "|    clip_fraction        | 0.0289       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.32        |\n",
            "|    explained_variance   | 0.128        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.11         |\n",
            "|    n_updates            | 3350         |\n",
            "|    policy_gradient_loss | -0.00391     |\n",
            "|    reward               | 0.16180292   |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.275        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 337          |\n",
            "|    time_elapsed         | 1601         |\n",
            "|    total_timesteps      | 690176       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041137678 |\n",
            "|    clip_fraction        | 0.0169       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.32        |\n",
            "|    explained_variance   | 0.178        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00563     |\n",
            "|    n_updates            | 3360         |\n",
            "|    policy_gradient_loss | 3.2e-06      |\n",
            "|    reward               | 0.13426577   |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.0636       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 338          |\n",
            "|    time_elapsed         | 1606         |\n",
            "|    total_timesteps      | 692224       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045072655 |\n",
            "|    clip_fraction        | 0.0235       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.32        |\n",
            "|    explained_variance   | 0.266        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0282       |\n",
            "|    n_updates            | 3370         |\n",
            "|    policy_gradient_loss | -0.00194     |\n",
            "|    reward               | -0.021801608 |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.133        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 339          |\n",
            "|    time_elapsed         | 1611         |\n",
            "|    total_timesteps      | 694272       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023299763 |\n",
            "|    clip_fraction        | 0.0147       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.32        |\n",
            "|    explained_variance   | 0.206        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0483       |\n",
            "|    n_updates            | 3380         |\n",
            "|    policy_gradient_loss | -0.000511    |\n",
            "|    reward               | -0.1927603   |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.209        |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 245\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -209723.94\n",
            "total_reward: -219723.94\n",
            "total_cost: 387.99\n",
            "total_trades: 2542\n",
            "Sharpe: -0.305\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 340          |\n",
            "|    time_elapsed         | 1616         |\n",
            "|    total_timesteps      | 696320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023079254 |\n",
            "|    clip_fraction        | 0.024        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.31        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0407       |\n",
            "|    n_updates            | 3390         |\n",
            "|    policy_gradient_loss | -0.00211     |\n",
            "|    reward               | 0.0637361    |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.172        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 430         |\n",
            "|    iterations           | 341         |\n",
            "|    time_elapsed         | 1621        |\n",
            "|    total_timesteps      | 698368      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004238769 |\n",
            "|    clip_fraction        | 0.0622      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.31       |\n",
            "|    explained_variance   | 0.831       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0349     |\n",
            "|    n_updates            | 3400        |\n",
            "|    policy_gradient_loss | -0.00219    |\n",
            "|    reward               | 0.026621262 |\n",
            "|    std                  | 1.27        |\n",
            "|    value_loss           | 0.0166      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 342          |\n",
            "|    time_elapsed         | 1625         |\n",
            "|    total_timesteps      | 700416       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026819273 |\n",
            "|    clip_fraction        | 0.0348       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.32        |\n",
            "|    explained_variance   | 0.629        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0111      |\n",
            "|    n_updates            | 3410         |\n",
            "|    policy_gradient_loss | -3.25e-06    |\n",
            "|    reward               | 0.0032757975 |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.0227       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 343          |\n",
            "|    time_elapsed         | 1630         |\n",
            "|    total_timesteps      | 702464       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0066254064 |\n",
            "|    clip_fraction        | 0.0572       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.33        |\n",
            "|    explained_variance   | 0.366        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0378      |\n",
            "|    n_updates            | 3420         |\n",
            "|    policy_gradient_loss | -0.00881     |\n",
            "|    reward               | -0.036017902 |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.0303       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 430        |\n",
            "|    iterations           | 344        |\n",
            "|    time_elapsed         | 1635       |\n",
            "|    total_timesteps      | 704512     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00385249 |\n",
            "|    clip_fraction        | 0.00981    |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.32      |\n",
            "|    explained_variance   | 0.774      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.0164    |\n",
            "|    n_updates            | 3430       |\n",
            "|    policy_gradient_loss | -0.000894  |\n",
            "|    reward               | 0.29347575 |\n",
            "|    std                  | 1.27       |\n",
            "|    value_loss           | 0.00877    |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 430         |\n",
            "|    iterations           | 345         |\n",
            "|    time_elapsed         | 1640        |\n",
            "|    total_timesteps      | 706560      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003409388 |\n",
            "|    clip_fraction        | 0.0217      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.31       |\n",
            "|    explained_variance   | 0.355       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0135     |\n",
            "|    n_updates            | 3440        |\n",
            "|    policy_gradient_loss | -0.000325   |\n",
            "|    reward               | -0.03655601 |\n",
            "|    std                  | 1.27        |\n",
            "|    value_loss           | 0.0495      |\n",
            "-----------------------------------------\n",
            "day: 2833, episode: 250\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -131171.55\n",
            "total_reward: -141171.55\n",
            "total_cost: 374.12\n",
            "total_trades: 2514\n",
            "Sharpe: 0.602\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 346          |\n",
            "|    time_elapsed         | 1644         |\n",
            "|    total_timesteps      | 708608       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044435016 |\n",
            "|    clip_fraction        | 0.0379       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.31        |\n",
            "|    explained_variance   | 0.19         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 3.16e-05     |\n",
            "|    n_updates            | 3450         |\n",
            "|    policy_gradient_loss | -0.00898     |\n",
            "|    reward               | -0.008812158 |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.139        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 430         |\n",
            "|    iterations           | 347         |\n",
            "|    time_elapsed         | 1649        |\n",
            "|    total_timesteps      | 710656      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007578494 |\n",
            "|    clip_fraction        | 0.0642      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.31       |\n",
            "|    explained_variance   | 0.0406      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0132     |\n",
            "|    n_updates            | 3460        |\n",
            "|    policy_gradient_loss | -0.00733    |\n",
            "|    reward               | 0.12784226  |\n",
            "|    std                  | 1.27        |\n",
            "|    value_loss           | 0.0553      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 348          |\n",
            "|    time_elapsed         | 1654         |\n",
            "|    total_timesteps      | 712704       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034332478 |\n",
            "|    clip_fraction        | 0.0111       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.32        |\n",
            "|    explained_variance   | 0.491        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.023       |\n",
            "|    n_updates            | 3470         |\n",
            "|    policy_gradient_loss | 0.000467     |\n",
            "|    reward               | -0.016041234 |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.0161       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 349          |\n",
            "|    time_elapsed         | 1659         |\n",
            "|    total_timesteps      | 714752       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006050204  |\n",
            "|    clip_fraction        | 0.0238       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.32        |\n",
            "|    explained_variance   | 0.284        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0313       |\n",
            "|    n_updates            | 3480         |\n",
            "|    policy_gradient_loss | 0.00112      |\n",
            "|    reward               | -0.017972527 |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.058        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 350          |\n",
            "|    time_elapsed         | 1664         |\n",
            "|    total_timesteps      | 716800       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034820093 |\n",
            "|    clip_fraction        | 0.0307       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.31        |\n",
            "|    explained_variance   | 0.364        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0101      |\n",
            "|    n_updates            | 3490         |\n",
            "|    policy_gradient_loss | -0.00117     |\n",
            "|    reward               | -0.11414941  |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.0417       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 351          |\n",
            "|    time_elapsed         | 1668         |\n",
            "|    total_timesteps      | 718848       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039184126 |\n",
            "|    clip_fraction        | 0.0189       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.31        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00637     |\n",
            "|    n_updates            | 3500         |\n",
            "|    policy_gradient_loss | -0.00166     |\n",
            "|    reward               | -0.014732299 |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.0642       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 352          |\n",
            "|    time_elapsed         | 1673         |\n",
            "|    total_timesteps      | 720896       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005862667  |\n",
            "|    clip_fraction        | 0.0535       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.33        |\n",
            "|    explained_variance   | 0.4          |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0155      |\n",
            "|    n_updates            | 3510         |\n",
            "|    policy_gradient_loss | -0.00232     |\n",
            "|    reward               | -0.008283032 |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.0423       |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 255\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -89041.95\n",
            "total_reward: -99041.95\n",
            "total_cost: 585.67\n",
            "total_trades: 3010\n",
            "Sharpe: -0.373\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 353          |\n",
            "|    time_elapsed         | 1678         |\n",
            "|    total_timesteps      | 722944       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028392305 |\n",
            "|    clip_fraction        | 0.0116       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.34        |\n",
            "|    explained_variance   | 0.0925       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00602      |\n",
            "|    n_updates            | 3520         |\n",
            "|    policy_gradient_loss | -0.00123     |\n",
            "|    reward               | -0.012044751 |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.096        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 354          |\n",
            "|    time_elapsed         | 1682         |\n",
            "|    total_timesteps      | 724992       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046469537 |\n",
            "|    clip_fraction        | 0.0215       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.35        |\n",
            "|    explained_variance   | 0.153        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00855     |\n",
            "|    n_updates            | 3530         |\n",
            "|    policy_gradient_loss | -0.000771    |\n",
            "|    reward               | -0.034374    |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.0578       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 355          |\n",
            "|    time_elapsed         | 1687         |\n",
            "|    total_timesteps      | 727040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037523997 |\n",
            "|    clip_fraction        | 0.021        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.35        |\n",
            "|    explained_variance   | -0.0644      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0116      |\n",
            "|    n_updates            | 3540         |\n",
            "|    policy_gradient_loss | -0.00386     |\n",
            "|    reward               | 0.0066012954 |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.0401       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 356          |\n",
            "|    time_elapsed         | 1692         |\n",
            "|    total_timesteps      | 729088       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054859845 |\n",
            "|    clip_fraction        | 0.0349       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.35        |\n",
            "|    explained_variance   | 0.0698       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.013       |\n",
            "|    n_updates            | 3550         |\n",
            "|    policy_gradient_loss | -0.00707     |\n",
            "|    reward               | -0.010444664 |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.0471       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 430         |\n",
            "|    iterations           | 357         |\n",
            "|    time_elapsed         | 1697        |\n",
            "|    total_timesteps      | 731136      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004595677 |\n",
            "|    clip_fraction        | 0.0181      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.35       |\n",
            "|    explained_variance   | 0.313       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0244      |\n",
            "|    n_updates            | 3560        |\n",
            "|    policy_gradient_loss | -0.000856   |\n",
            "|    reward               | -0.11160454 |\n",
            "|    std                  | 1.29        |\n",
            "|    value_loss           | 0.101       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 358          |\n",
            "|    time_elapsed         | 1702         |\n",
            "|    total_timesteps      | 733184       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.00746316   |\n",
            "|    clip_fraction        | 0.0449       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.35        |\n",
            "|    explained_variance   | 0.239        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0097      |\n",
            "|    n_updates            | 3570         |\n",
            "|    policy_gradient_loss | -0.00196     |\n",
            "|    reward               | -0.025446078 |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.0407       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 359          |\n",
            "|    time_elapsed         | 1707         |\n",
            "|    total_timesteps      | 735232       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048462227 |\n",
            "|    clip_fraction        | 0.0381       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.36        |\n",
            "|    explained_variance   | 0.782        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0375      |\n",
            "|    n_updates            | 3580         |\n",
            "|    policy_gradient_loss | -0.00179     |\n",
            "|    reward               | -0.010212533 |\n",
            "|    std                  | 1.3          |\n",
            "|    value_loss           | 0.00901      |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 260\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -153617.63\n",
            "total_reward: -163617.63\n",
            "total_cost: 656.08\n",
            "total_trades: 3242\n",
            "Sharpe: 0.459\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 430         |\n",
            "|    iterations           | 360         |\n",
            "|    time_elapsed         | 1711        |\n",
            "|    total_timesteps      | 737280      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004661725 |\n",
            "|    clip_fraction        | 0.0322      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.37       |\n",
            "|    explained_variance   | 0.31        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.00513    |\n",
            "|    n_updates            | 3590        |\n",
            "|    policy_gradient_loss | -0.00173    |\n",
            "|    reward               | 0.02466995  |\n",
            "|    std                  | 1.3         |\n",
            "|    value_loss           | 0.0457      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 361          |\n",
            "|    time_elapsed         | 1715         |\n",
            "|    total_timesteps      | 739328       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045613153 |\n",
            "|    clip_fraction        | 0.0534       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.36        |\n",
            "|    explained_variance   | 0.211        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0249       |\n",
            "|    n_updates            | 3600         |\n",
            "|    policy_gradient_loss | -0.00414     |\n",
            "|    reward               | 0.09924823   |\n",
            "|    std                  | 1.3          |\n",
            "|    value_loss           | 0.113        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 362          |\n",
            "|    time_elapsed         | 1720         |\n",
            "|    total_timesteps      | 741376       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037842696 |\n",
            "|    clip_fraction        | 0.0306       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.36        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0225      |\n",
            "|    n_updates            | 3610         |\n",
            "|    policy_gradient_loss | -0.00119     |\n",
            "|    reward               | -0.047309916 |\n",
            "|    std                  | 1.3          |\n",
            "|    value_loss           | 0.0213       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 363          |\n",
            "|    time_elapsed         | 1726         |\n",
            "|    total_timesteps      | 743424       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039376654 |\n",
            "|    clip_fraction        | 0.0302       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.36        |\n",
            "|    explained_variance   | 0.398        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0049      |\n",
            "|    n_updates            | 3620         |\n",
            "|    policy_gradient_loss | -0.00193     |\n",
            "|    reward               | 0.009881828  |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.0452       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 364          |\n",
            "|    time_elapsed         | 1731         |\n",
            "|    total_timesteps      | 745472       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024664886 |\n",
            "|    clip_fraction        | 0.00278      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.35        |\n",
            "|    explained_variance   | 0.259        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00613      |\n",
            "|    n_updates            | 3630         |\n",
            "|    policy_gradient_loss | 0.000405     |\n",
            "|    reward               | 0.0039398647 |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.113        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 365          |\n",
            "|    time_elapsed         | 1736         |\n",
            "|    total_timesteps      | 747520       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005296958  |\n",
            "|    clip_fraction        | 0.0389       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.35        |\n",
            "|    explained_variance   | 0.3          |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0213      |\n",
            "|    n_updates            | 3640         |\n",
            "|    policy_gradient_loss | -0.00203     |\n",
            "|    reward               | -0.046984624 |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.0319       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 366          |\n",
            "|    time_elapsed         | 1741         |\n",
            "|    total_timesteps      | 749568       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011193277 |\n",
            "|    clip_fraction        | 0.00703      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.34        |\n",
            "|    explained_variance   | 0.506        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0238      |\n",
            "|    n_updates            | 3650         |\n",
            "|    policy_gradient_loss | -0.00106     |\n",
            "|    reward               | 0.007551447  |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.0196       |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 265\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -81918.10\n",
            "total_reward: -91918.10\n",
            "total_cost: 581.56\n",
            "total_trades: 2848\n",
            "Sharpe: -0.096\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 367          |\n",
            "|    time_elapsed         | 1747         |\n",
            "|    total_timesteps      | 751616       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047587412 |\n",
            "|    clip_fraction        | 0.0104       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.33        |\n",
            "|    explained_variance   | 0.269        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0367       |\n",
            "|    n_updates            | 3660         |\n",
            "|    policy_gradient_loss | -0.000398    |\n",
            "|    reward               | -0.010111925 |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.0829       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 430          |\n",
            "|    iterations           | 368          |\n",
            "|    time_elapsed         | 1752         |\n",
            "|    total_timesteps      | 753664       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.002364922  |\n",
            "|    clip_fraction        | 0.0134       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.33        |\n",
            "|    explained_variance   | 0.405        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00741     |\n",
            "|    n_updates            | 3670         |\n",
            "|    policy_gradient_loss | -0.000621    |\n",
            "|    reward               | -0.025575897 |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.0456       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 429          |\n",
            "|    iterations           | 369          |\n",
            "|    time_elapsed         | 1757         |\n",
            "|    total_timesteps      | 755712       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016625229 |\n",
            "|    clip_fraction        | 0.00801      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.34        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00749     |\n",
            "|    n_updates            | 3680         |\n",
            "|    policy_gradient_loss | -0.000661    |\n",
            "|    reward               | -0.045677073 |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.0605       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 429          |\n",
            "|    iterations           | 370          |\n",
            "|    time_elapsed         | 1763         |\n",
            "|    total_timesteps      | 757760       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034850435 |\n",
            "|    clip_fraction        | 0.0302       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.36        |\n",
            "|    explained_variance   | 0.467        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0108      |\n",
            "|    n_updates            | 3690         |\n",
            "|    policy_gradient_loss | -0.000555    |\n",
            "|    reward               | -0.031958275 |\n",
            "|    std                  | 1.3          |\n",
            "|    value_loss           | 0.0287       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 429         |\n",
            "|    iterations           | 371         |\n",
            "|    time_elapsed         | 1768        |\n",
            "|    total_timesteps      | 759808      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005011298 |\n",
            "|    clip_fraction        | 0.0446      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.37       |\n",
            "|    explained_variance   | 0.398       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0143     |\n",
            "|    n_updates            | 3700        |\n",
            "|    policy_gradient_loss | -0.00107    |\n",
            "|    reward               | 0.016984478 |\n",
            "|    std                  | 1.31        |\n",
            "|    value_loss           | 0.0362      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 429         |\n",
            "|    iterations           | 372         |\n",
            "|    time_elapsed         | 1773        |\n",
            "|    total_timesteps      | 761856      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003789227 |\n",
            "|    clip_fraction        | 0.0212      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.37       |\n",
            "|    explained_variance   | 0.195       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0324      |\n",
            "|    n_updates            | 3710        |\n",
            "|    policy_gradient_loss | -0.00152    |\n",
            "|    reward               | -0.0077638  |\n",
            "|    std                  | 1.3         |\n",
            "|    value_loss           | 0.103       |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 429           |\n",
            "|    iterations           | 373           |\n",
            "|    time_elapsed         | 1779          |\n",
            "|    total_timesteps      | 763904        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.005107973   |\n",
            "|    clip_fraction        | 0.0317        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.37         |\n",
            "|    explained_variance   | 0.137         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.023        |\n",
            "|    n_updates            | 3720          |\n",
            "|    policy_gradient_loss | -0.00175      |\n",
            "|    reward               | 0.00013255245 |\n",
            "|    std                  | 1.3           |\n",
            "|    value_loss           | 0.0299        |\n",
            "-------------------------------------------\n",
            "day: 2833, episode: 270\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -187663.48\n",
            "total_reward: -197663.48\n",
            "total_cost: 536.14\n",
            "total_trades: 2838\n",
            "Sharpe: 0.337\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 429          |\n",
            "|    iterations           | 374          |\n",
            "|    time_elapsed         | 1784         |\n",
            "|    total_timesteps      | 765952       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045016883 |\n",
            "|    clip_fraction        | 0.0285       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.37        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00696     |\n",
            "|    n_updates            | 3730         |\n",
            "|    policy_gradient_loss | -0.00221     |\n",
            "|    reward               | 0.027866496  |\n",
            "|    std                  | 1.3          |\n",
            "|    value_loss           | 0.0666       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 429          |\n",
            "|    iterations           | 375          |\n",
            "|    time_elapsed         | 1789         |\n",
            "|    total_timesteps      | 768000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.002690047  |\n",
            "|    clip_fraction        | 0.00723      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.36        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0469       |\n",
            "|    n_updates            | 3740         |\n",
            "|    policy_gradient_loss | -0.000764    |\n",
            "|    reward               | -0.031509575 |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.177        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 429         |\n",
            "|    iterations           | 376         |\n",
            "|    time_elapsed         | 1794        |\n",
            "|    total_timesteps      | 770048      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007102937 |\n",
            "|    clip_fraction        | 0.0597      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.35       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0131     |\n",
            "|    n_updates            | 3750        |\n",
            "|    policy_gradient_loss | -0.00507    |\n",
            "|    reward               | -0.0518537  |\n",
            "|    std                  | 1.3         |\n",
            "|    value_loss           | 0.0426      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 428          |\n",
            "|    iterations           | 377          |\n",
            "|    time_elapsed         | 1800         |\n",
            "|    total_timesteps      | 772096       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037173838 |\n",
            "|    clip_fraction        | 0.00605      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.35        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0326      |\n",
            "|    n_updates            | 3760         |\n",
            "|    policy_gradient_loss | 0.000135     |\n",
            "|    reward               | -0.05757434  |\n",
            "|    std                  | 1.3          |\n",
            "|    value_loss           | 0.0135       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 428          |\n",
            "|    iterations           | 378          |\n",
            "|    time_elapsed         | 1805         |\n",
            "|    total_timesteps      | 774144       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019220803 |\n",
            "|    clip_fraction        | 0.0101       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.35        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0235       |\n",
            "|    n_updates            | 3770         |\n",
            "|    policy_gradient_loss | -0.00059     |\n",
            "|    reward               | 0.005615648  |\n",
            "|    std                  | 1.3          |\n",
            "|    value_loss           | 0.0973       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 428         |\n",
            "|    iterations           | 379         |\n",
            "|    time_elapsed         | 1810        |\n",
            "|    total_timesteps      | 776192      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004708563 |\n",
            "|    clip_fraction        | 0.0347      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.35       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 4.17e-05    |\n",
            "|    n_updates            | 3780        |\n",
            "|    policy_gradient_loss | -0.00221    |\n",
            "|    reward               | 0.29951498  |\n",
            "|    std                  | 1.29        |\n",
            "|    value_loss           | 0.0646      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 428          |\n",
            "|    iterations           | 380          |\n",
            "|    time_elapsed         | 1816         |\n",
            "|    total_timesteps      | 778240       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036583415 |\n",
            "|    clip_fraction        | 0.0155       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.34        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00576     |\n",
            "|    n_updates            | 3790         |\n",
            "|    policy_gradient_loss | -0.000911    |\n",
            "|    reward               | 0.014264398  |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.0433       |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 275\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -142946.29\n",
            "total_reward: -152946.29\n",
            "total_cost: 599.52\n",
            "total_trades: 3226\n",
            "Sharpe: 0.643\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 428          |\n",
            "|    iterations           | 381          |\n",
            "|    time_elapsed         | 1821         |\n",
            "|    total_timesteps      | 780288       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038607875 |\n",
            "|    clip_fraction        | 0.0323       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.35        |\n",
            "|    explained_variance   | -1.55e-06    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.000508    |\n",
            "|    n_updates            | 3800         |\n",
            "|    policy_gradient_loss | -0.00168     |\n",
            "|    reward               | 0.023945944  |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.05         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 428           |\n",
            "|    iterations           | 382           |\n",
            "|    time_elapsed         | 1826          |\n",
            "|    total_timesteps      | 782336        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.004224707   |\n",
            "|    clip_fraction        | 0.0206        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.34         |\n",
            "|    explained_variance   | -0.00291      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0216        |\n",
            "|    n_updates            | 3810          |\n",
            "|    policy_gradient_loss | -0.00141      |\n",
            "|    reward               | -0.0060988367 |\n",
            "|    std                  | 1.29          |\n",
            "|    value_loss           | 0.109         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 428          |\n",
            "|    iterations           | 383          |\n",
            "|    time_elapsed         | 1831         |\n",
            "|    total_timesteps      | 784384       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025295704 |\n",
            "|    clip_fraction        | 0.0225       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.34        |\n",
            "|    explained_variance   | 0.0703       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00638     |\n",
            "|    n_updates            | 3820         |\n",
            "|    policy_gradient_loss | -0.00342     |\n",
            "|    reward               | -0.079960145 |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.0862       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 428           |\n",
            "|    iterations           | 384           |\n",
            "|    time_elapsed         | 1837          |\n",
            "|    total_timesteps      | 786432        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00089847075 |\n",
            "|    clip_fraction        | 0.0185        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.34         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0288       |\n",
            "|    n_updates            | 3830          |\n",
            "|    policy_gradient_loss | 0.00134       |\n",
            "|    reward               | 0.010877312   |\n",
            "|    std                  | 1.29          |\n",
            "|    value_loss           | 0.011         |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 427           |\n",
            "|    iterations           | 385           |\n",
            "|    time_elapsed         | 1842          |\n",
            "|    total_timesteps      | 788480        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0048637995  |\n",
            "|    clip_fraction        | 0.0388        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.34         |\n",
            "|    explained_variance   | -0.00402      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0117       |\n",
            "|    n_updates            | 3840          |\n",
            "|    policy_gradient_loss | -0.00242      |\n",
            "|    reward               | -0.0044977795 |\n",
            "|    std                  | 1.29          |\n",
            "|    value_loss           | 0.0547        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 386          |\n",
            "|    time_elapsed         | 1847         |\n",
            "|    total_timesteps      | 790528       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061360127 |\n",
            "|    clip_fraction        | 0.0597       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.34        |\n",
            "|    explained_variance   | 0.476        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0256      |\n",
            "|    n_updates            | 3850         |\n",
            "|    policy_gradient_loss | -0.00585     |\n",
            "|    reward               | -0.08758284  |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.0233       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 387          |\n",
            "|    time_elapsed         | 1852         |\n",
            "|    total_timesteps      | 792576       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032871254 |\n",
            "|    clip_fraction        | 0.0186       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.34        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0166      |\n",
            "|    n_updates            | 3860         |\n",
            "|    policy_gradient_loss | -0.00102     |\n",
            "|    reward               | -0.034253392 |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.081        |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 280\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -170864.17\n",
            "total_reward: -180864.17\n",
            "total_cost: 656.30\n",
            "total_trades: 3186\n",
            "Sharpe: -0.128\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 427           |\n",
            "|    iterations           | 388           |\n",
            "|    time_elapsed         | 1858          |\n",
            "|    total_timesteps      | 794624        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0061464924  |\n",
            "|    clip_fraction        | 0.0674        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.35         |\n",
            "|    explained_variance   | -0.000532     |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0178       |\n",
            "|    n_updates            | 3870          |\n",
            "|    policy_gradient_loss | -0.00401      |\n",
            "|    reward               | -0.0068277144 |\n",
            "|    std                  | 1.29          |\n",
            "|    value_loss           | 0.0617        |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 427           |\n",
            "|    iterations           | 389           |\n",
            "|    time_elapsed         | 1863          |\n",
            "|    total_timesteps      | 796672        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.005842302   |\n",
            "|    clip_fraction        | 0.0644        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.35         |\n",
            "|    explained_variance   | -0.000182     |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0324        |\n",
            "|    n_updates            | 3880          |\n",
            "|    policy_gradient_loss | -0.00381      |\n",
            "|    reward               | -0.0020433867 |\n",
            "|    std                  | 1.29          |\n",
            "|    value_loss           | 0.161         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 390          |\n",
            "|    time_elapsed         | 1868         |\n",
            "|    total_timesteps      | 798720       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032137032 |\n",
            "|    clip_fraction        | 0.0226       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.35        |\n",
            "|    explained_variance   | -0.000576    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00661     |\n",
            "|    n_updates            | 3890         |\n",
            "|    policy_gradient_loss | -0.0011      |\n",
            "|    reward               | -0.010145137 |\n",
            "|    std                  | 1.3          |\n",
            "|    value_loss           | 0.0334       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 391          |\n",
            "|    time_elapsed         | 1873         |\n",
            "|    total_timesteps      | 800768       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040620114 |\n",
            "|    clip_fraction        | 0.0393       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.37        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0209      |\n",
            "|    n_updates            | 3900         |\n",
            "|    policy_gradient_loss | -0.00189     |\n",
            "|    reward               | -0.051431548 |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 0.0219       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 392          |\n",
            "|    time_elapsed         | 1878         |\n",
            "|    total_timesteps      | 802816       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010750098 |\n",
            "|    clip_fraction        | 0.0135       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.39        |\n",
            "|    explained_variance   | -0.00089     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00837     |\n",
            "|    n_updates            | 3910         |\n",
            "|    policy_gradient_loss | -0.000756    |\n",
            "|    reward               | 0.0063086096 |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 0.0464       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 427           |\n",
            "|    iterations           | 393           |\n",
            "|    time_elapsed         | 1884          |\n",
            "|    total_timesteps      | 804864        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0023780055  |\n",
            "|    clip_fraction        | 0.00571       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.41         |\n",
            "|    explained_variance   | 0.0849        |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.00936       |\n",
            "|    n_updates            | 3920          |\n",
            "|    policy_gradient_loss | -0.000625     |\n",
            "|    reward               | -0.0040581035 |\n",
            "|    std                  | 1.33          |\n",
            "|    value_loss           | 0.0649        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 394          |\n",
            "|    time_elapsed         | 1889         |\n",
            "|    total_timesteps      | 806912       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005184622  |\n",
            "|    clip_fraction        | 0.0642       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.41        |\n",
            "|    explained_variance   | 0.29         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0487      |\n",
            "|    n_updates            | 3930         |\n",
            "|    policy_gradient_loss | -0.00767     |\n",
            "|    reward               | -0.059332363 |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 0.015        |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 285\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -76591.28\n",
            "total_reward: -86591.28\n",
            "total_cost: 662.39\n",
            "total_trades: 3154\n",
            "Sharpe: -0.146\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 395          |\n",
            "|    time_elapsed         | 1894         |\n",
            "|    total_timesteps      | 808960       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043873265 |\n",
            "|    clip_fraction        | 0.0261       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.43        |\n",
            "|    explained_variance   | 0.0475       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0388      |\n",
            "|    n_updates            | 3940         |\n",
            "|    policy_gradient_loss | -0.0021      |\n",
            "|    reward               | -0.010599113 |\n",
            "|    std                  | 1.35         |\n",
            "|    value_loss           | 0.00477      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 396          |\n",
            "|    time_elapsed         | 1899         |\n",
            "|    total_timesteps      | 811008       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0063318103 |\n",
            "|    clip_fraction        | 0.0448       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.44        |\n",
            "|    explained_variance   | 0.105        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0121      |\n",
            "|    n_updates            | 3950         |\n",
            "|    policy_gradient_loss | -0.00267     |\n",
            "|    reward               | 0.011513016  |\n",
            "|    std                  | 1.35         |\n",
            "|    value_loss           | 0.0372       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 397          |\n",
            "|    time_elapsed         | 1905         |\n",
            "|    total_timesteps      | 813056       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049551874 |\n",
            "|    clip_fraction        | 0.025        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.44        |\n",
            "|    explained_variance   | 0.0524       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0062      |\n",
            "|    n_updates            | 3960         |\n",
            "|    policy_gradient_loss | -0.00143     |\n",
            "|    reward               | 0.007191738  |\n",
            "|    std                  | 1.35         |\n",
            "|    value_loss           | 0.067        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 398          |\n",
            "|    time_elapsed         | 1910         |\n",
            "|    total_timesteps      | 815104       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019105624 |\n",
            "|    clip_fraction        | 0.00483      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.44        |\n",
            "|    explained_variance   | 0.117        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0211      |\n",
            "|    n_updates            | 3970         |\n",
            "|    policy_gradient_loss | -0.000184    |\n",
            "|    reward               | -0.01604459  |\n",
            "|    std                  | 1.35         |\n",
            "|    value_loss           | 0.0232       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 426         |\n",
            "|    iterations           | 399         |\n",
            "|    time_elapsed         | 1915        |\n",
            "|    total_timesteps      | 817152      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007571771 |\n",
            "|    clip_fraction        | 0.0667      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.44       |\n",
            "|    explained_variance   | 0.239       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0317     |\n",
            "|    n_updates            | 3980        |\n",
            "|    policy_gradient_loss | -0.003      |\n",
            "|    reward               | 0.038780484 |\n",
            "|    std                  | 1.35        |\n",
            "|    value_loss           | 0.0216      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 400          |\n",
            "|    time_elapsed         | 1920         |\n",
            "|    total_timesteps      | 819200       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045270007 |\n",
            "|    clip_fraction        | 0.0331       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.43        |\n",
            "|    explained_variance   | 0.0901       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0273      |\n",
            "|    n_updates            | 3990         |\n",
            "|    policy_gradient_loss | -0.00193     |\n",
            "|    reward               | 0.002058557  |\n",
            "|    std                  | 1.35         |\n",
            "|    value_loss           | 0.0396       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 426         |\n",
            "|    iterations           | 401         |\n",
            "|    time_elapsed         | 1926        |\n",
            "|    total_timesteps      | 821248      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002652842 |\n",
            "|    clip_fraction        | 0.00376     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.43       |\n",
            "|    explained_variance   | 0.165       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0141     |\n",
            "|    n_updates            | 4000        |\n",
            "|    policy_gradient_loss | 0.000171    |\n",
            "|    reward               | -0.20825651 |\n",
            "|    std                  | 1.35        |\n",
            "|    value_loss           | 0.0387      |\n",
            "-----------------------------------------\n",
            "day: 2833, episode: 290\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -142894.40\n",
            "total_reward: -152894.40\n",
            "total_cost: 566.62\n",
            "total_trades: 2968\n",
            "Sharpe: 0.502\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 402          |\n",
            "|    time_elapsed         | 1931         |\n",
            "|    total_timesteps      | 823296       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050325086 |\n",
            "|    clip_fraction        | 0.0232       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.43        |\n",
            "|    explained_variance   | 0.0697       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0203      |\n",
            "|    n_updates            | 4010         |\n",
            "|    policy_gradient_loss | -0.00208     |\n",
            "|    reward               | 0.0017897981 |\n",
            "|    std                  | 1.35         |\n",
            "|    value_loss           | 0.0217       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 403          |\n",
            "|    time_elapsed         | 1936         |\n",
            "|    total_timesteps      | 825344       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005798191  |\n",
            "|    clip_fraction        | 0.0403       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.43        |\n",
            "|    explained_variance   | 0.0304       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0246       |\n",
            "|    n_updates            | 4020         |\n",
            "|    policy_gradient_loss | -0.00199     |\n",
            "|    reward               | 0.0048338077 |\n",
            "|    std                  | 1.35         |\n",
            "|    value_loss           | 0.0803       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 426         |\n",
            "|    iterations           | 404         |\n",
            "|    time_elapsed         | 1941        |\n",
            "|    total_timesteps      | 827392      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008219251 |\n",
            "|    clip_fraction        | 0.0664      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.43       |\n",
            "|    explained_variance   | 0.643       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0359     |\n",
            "|    n_updates            | 4030        |\n",
            "|    policy_gradient_loss | -0.00918    |\n",
            "|    reward               | -0.15379809 |\n",
            "|    std                  | 1.34        |\n",
            "|    value_loss           | 0.0188      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 425          |\n",
            "|    iterations           | 405          |\n",
            "|    time_elapsed         | 1947         |\n",
            "|    total_timesteps      | 829440       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061432514 |\n",
            "|    clip_fraction        | 0.0467       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.42        |\n",
            "|    explained_variance   | 0.274        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0288      |\n",
            "|    n_updates            | 4040         |\n",
            "|    policy_gradient_loss | -0.00836     |\n",
            "|    reward               | -0.007920056 |\n",
            "|    std                  | 1.34         |\n",
            "|    value_loss           | 0.0456       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 425          |\n",
            "|    iterations           | 406          |\n",
            "|    time_elapsed         | 1952         |\n",
            "|    total_timesteps      | 831488       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035622392 |\n",
            "|    clip_fraction        | 0.0218       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.42        |\n",
            "|    explained_variance   | 0.624        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0423      |\n",
            "|    n_updates            | 4050         |\n",
            "|    policy_gradient_loss | -0.00535     |\n",
            "|    reward               | 0.04110568   |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 0.0155       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 425          |\n",
            "|    iterations           | 407          |\n",
            "|    time_elapsed         | 1957         |\n",
            "|    total_timesteps      | 833536       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050650937 |\n",
            "|    clip_fraction        | 0.0157       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.41        |\n",
            "|    explained_variance   | 0.164        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00359     |\n",
            "|    n_updates            | 4060         |\n",
            "|    policy_gradient_loss | -0.001       |\n",
            "|    reward               | -0.01404653  |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 0.0831       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 425          |\n",
            "|    iterations           | 408          |\n",
            "|    time_elapsed         | 1962         |\n",
            "|    total_timesteps      | 835584       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015301083 |\n",
            "|    clip_fraction        | 0.0043       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.4         |\n",
            "|    explained_variance   | -0.0225      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0332       |\n",
            "|    n_updates            | 4070         |\n",
            "|    policy_gradient_loss | -0.000121    |\n",
            "|    reward               | 0.0064255316 |\n",
            "|    std                  | 1.32         |\n",
            "|    value_loss           | 0.137        |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 295\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -17463.60\n",
            "total_reward: -27463.60\n",
            "total_cost: 432.00\n",
            "total_trades: 2948\n",
            "Sharpe: 0.230\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 425         |\n",
            "|    iterations           | 409         |\n",
            "|    time_elapsed         | 1968        |\n",
            "|    total_timesteps      | 837632      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002216837 |\n",
            "|    clip_fraction        | 0.0227      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.4        |\n",
            "|    explained_variance   | 0.509       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0428     |\n",
            "|    n_updates            | 4080        |\n",
            "|    policy_gradient_loss | -0.00695    |\n",
            "|    reward               | -0.05847328 |\n",
            "|    std                  | 1.32        |\n",
            "|    value_loss           | 0.00866     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 425          |\n",
            "|    iterations           | 410          |\n",
            "|    time_elapsed         | 1973         |\n",
            "|    total_timesteps      | 839680       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038956439 |\n",
            "|    clip_fraction        | 0.0243       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.4         |\n",
            "|    explained_variance   | 0.457        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0279      |\n",
            "|    n_updates            | 4090         |\n",
            "|    policy_gradient_loss | -0.00394     |\n",
            "|    reward               | 0.0029366966 |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 0.0212       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 425         |\n",
            "|    iterations           | 411         |\n",
            "|    time_elapsed         | 1979        |\n",
            "|    total_timesteps      | 841728      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007106954 |\n",
            "|    clip_fraction        | 0.0498      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.4        |\n",
            "|    explained_variance   | 0.0934      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.022       |\n",
            "|    n_updates            | 4100        |\n",
            "|    policy_gradient_loss | -0.00458    |\n",
            "|    reward               | 0.011134266 |\n",
            "|    std                  | 1.33        |\n",
            "|    value_loss           | 0.106       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 425          |\n",
            "|    iterations           | 412          |\n",
            "|    time_elapsed         | 1984         |\n",
            "|    total_timesteps      | 843776       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0064961556 |\n",
            "|    clip_fraction        | 0.0462       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.41        |\n",
            "|    explained_variance   | 0.27         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0319      |\n",
            "|    n_updates            | 4110         |\n",
            "|    policy_gradient_loss | -0.00788     |\n",
            "|    reward               | 0.0044946554 |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 0.0151       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 425           |\n",
            "|    iterations           | 413           |\n",
            "|    time_elapsed         | 1989          |\n",
            "|    total_timesteps      | 845824        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00082148076 |\n",
            "|    clip_fraction        | 0.00366       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.41         |\n",
            "|    explained_variance   | 0.311         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0246       |\n",
            "|    n_updates            | 4120          |\n",
            "|    policy_gradient_loss | 0.000619      |\n",
            "|    reward               | -0.015925987  |\n",
            "|    std                  | 1.33          |\n",
            "|    value_loss           | 0.0147        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 425          |\n",
            "|    iterations           | 414          |\n",
            "|    time_elapsed         | 1994         |\n",
            "|    total_timesteps      | 847872       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006489345  |\n",
            "|    clip_fraction        | 0.0485       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.4         |\n",
            "|    explained_variance   | 0.201        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.037       |\n",
            "|    n_updates            | 4130         |\n",
            "|    policy_gradient_loss | -0.00625     |\n",
            "|    reward               | -0.005848059 |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 0.034        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 415          |\n",
            "|    time_elapsed         | 1999         |\n",
            "|    total_timesteps      | 849920       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0062540164 |\n",
            "|    clip_fraction        | 0.0437       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.41        |\n",
            "|    explained_variance   | 0.168        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0075      |\n",
            "|    n_updates            | 4140         |\n",
            "|    policy_gradient_loss | -0.00664     |\n",
            "|    reward               | 0.020965494  |\n",
            "|    std                  | 1.34         |\n",
            "|    value_loss           | 0.0895       |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 300\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -9024.07\n",
            "total_reward: -19024.07\n",
            "total_cost: 423.89\n",
            "total_trades: 3240\n",
            "Sharpe: 0.260\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 416          |\n",
            "|    time_elapsed         | 2005         |\n",
            "|    total_timesteps      | 851968       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005550864  |\n",
            "|    clip_fraction        | 0.0307       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.41        |\n",
            "|    explained_variance   | 0.162        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.034       |\n",
            "|    n_updates            | 4150         |\n",
            "|    policy_gradient_loss | -0.00573     |\n",
            "|    reward               | 0.0067167566 |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 0.012        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 424         |\n",
            "|    iterations           | 417         |\n",
            "|    time_elapsed         | 2010        |\n",
            "|    total_timesteps      | 854016      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006950816 |\n",
            "|    clip_fraction        | 0.0545      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.41       |\n",
            "|    explained_variance   | 0.461       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.044      |\n",
            "|    n_updates            | 4160        |\n",
            "|    policy_gradient_loss | -0.00383    |\n",
            "|    reward               | 0.10170778  |\n",
            "|    std                  | 1.33        |\n",
            "|    value_loss           | 0.0114      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 418          |\n",
            "|    time_elapsed         | 2015         |\n",
            "|    total_timesteps      | 856064       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0004965337 |\n",
            "|    clip_fraction        | 0.01         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.41        |\n",
            "|    explained_variance   | 0.102        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0105      |\n",
            "|    n_updates            | 4170         |\n",
            "|    policy_gradient_loss | 0.000377     |\n",
            "|    reward               | -0.004524934 |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 0.0476       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 424         |\n",
            "|    iterations           | 419         |\n",
            "|    time_elapsed         | 2022        |\n",
            "|    total_timesteps      | 858112      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.00496295  |\n",
            "|    clip_fraction        | 0.0237      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.42       |\n",
            "|    explained_variance   | 0.245       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.00625    |\n",
            "|    n_updates            | 4180        |\n",
            "|    policy_gradient_loss | -0.000249   |\n",
            "|    reward               | 0.120082065 |\n",
            "|    std                  | 1.34        |\n",
            "|    value_loss           | 0.0478      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 423         |\n",
            "|    iterations           | 420         |\n",
            "|    time_elapsed         | 2029        |\n",
            "|    total_timesteps      | 860160      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004490156 |\n",
            "|    clip_fraction        | 0.0297      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.42       |\n",
            "|    explained_variance   | 0.197       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.00915     |\n",
            "|    n_updates            | 4190        |\n",
            "|    policy_gradient_loss | -0.00439    |\n",
            "|    reward               | 0.124105774 |\n",
            "|    std                  | 1.33        |\n",
            "|    value_loss           | 0.0502      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 423          |\n",
            "|    iterations           | 421          |\n",
            "|    time_elapsed         | 2036         |\n",
            "|    total_timesteps      | 862208       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042793895 |\n",
            "|    clip_fraction        | 0.0317       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.41        |\n",
            "|    explained_variance   | 0.285        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0311      |\n",
            "|    n_updates            | 4200         |\n",
            "|    policy_gradient_loss | -0.00415     |\n",
            "|    reward               | 0.0010666283 |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 0.0752       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 422         |\n",
            "|    iterations           | 422         |\n",
            "|    time_elapsed         | 2043        |\n",
            "|    total_timesteps      | 864256      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008815219 |\n",
            "|    clip_fraction        | 0.0546      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.41       |\n",
            "|    explained_variance   | 0.183       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.003       |\n",
            "|    n_updates            | 4210        |\n",
            "|    policy_gradient_loss | -0.00484    |\n",
            "|    reward               | 0.35858256  |\n",
            "|    std                  | 1.34        |\n",
            "|    value_loss           | 0.105       |\n",
            "-----------------------------------------\n",
            "day: 2833, episode: 305\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 112635.08\n",
            "total_reward: 102635.08\n",
            "total_cost: 375.33\n",
            "total_trades: 3190\n",
            "Sharpe: 0.663\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 422          |\n",
            "|    iterations           | 423          |\n",
            "|    time_elapsed         | 2050         |\n",
            "|    total_timesteps      | 866304       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059657097 |\n",
            "|    clip_fraction        | 0.0636       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.41        |\n",
            "|    explained_variance   | 0.101        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.045        |\n",
            "|    n_updates            | 4220         |\n",
            "|    policy_gradient_loss | -0.00816     |\n",
            "|    reward               | -0.09786702  |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 0.155        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 422          |\n",
            "|    iterations           | 424          |\n",
            "|    time_elapsed         | 2057         |\n",
            "|    total_timesteps      | 868352       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004835008  |\n",
            "|    clip_fraction        | 0.0395       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.41        |\n",
            "|    explained_variance   | 0.258        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -2.81e-05    |\n",
            "|    n_updates            | 4230         |\n",
            "|    policy_gradient_loss | -0.00438     |\n",
            "|    reward               | -0.022155778 |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 0.0833       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 422          |\n",
            "|    iterations           | 425          |\n",
            "|    time_elapsed         | 2062         |\n",
            "|    total_timesteps      | 870400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004289519  |\n",
            "|    clip_fraction        | 0.0415       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.41        |\n",
            "|    explained_variance   | 0.0794       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0875       |\n",
            "|    n_updates            | 4240         |\n",
            "|    policy_gradient_loss | -0.0053      |\n",
            "|    reward               | -0.020947842 |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 0.457        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 422          |\n",
            "|    iterations           | 426          |\n",
            "|    time_elapsed         | 2067         |\n",
            "|    total_timesteps      | 872448       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047762413 |\n",
            "|    clip_fraction        | 0.0352       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.41        |\n",
            "|    explained_variance   | 0.164        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0765       |\n",
            "|    n_updates            | 4250         |\n",
            "|    policy_gradient_loss | -0.00699     |\n",
            "|    reward               | -0.017698029 |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 0.394        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 421          |\n",
            "|    iterations           | 427          |\n",
            "|    time_elapsed         | 2072         |\n",
            "|    total_timesteps      | 874496       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0068273107 |\n",
            "|    clip_fraction        | 0.0706       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.41        |\n",
            "|    explained_variance   | 0.134        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0251      |\n",
            "|    n_updates            | 4260         |\n",
            "|    policy_gradient_loss | -0.0095      |\n",
            "|    reward               | 0.04222812   |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 0.0155       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 421          |\n",
            "|    iterations           | 428          |\n",
            "|    time_elapsed         | 2078         |\n",
            "|    total_timesteps      | 876544       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031811537 |\n",
            "|    clip_fraction        | 0.0171       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.4         |\n",
            "|    explained_variance   | 0.387        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0404      |\n",
            "|    n_updates            | 4270         |\n",
            "|    policy_gradient_loss | -0.0085      |\n",
            "|    reward               | 0.005759075  |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 0.017        |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 310\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -114422.73\n",
            "total_reward: -124422.73\n",
            "total_cost: 571.81\n",
            "total_trades: 3476\n",
            "Sharpe: -0.548\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 421           |\n",
            "|    iterations           | 429           |\n",
            "|    time_elapsed         | 2083          |\n",
            "|    total_timesteps      | 878592        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0030522803  |\n",
            "|    clip_fraction        | 0.0197        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.4          |\n",
            "|    explained_variance   | 0.199         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0257       |\n",
            "|    n_updates            | 4280          |\n",
            "|    policy_gradient_loss | -0.00348      |\n",
            "|    reward               | -0.0032590432 |\n",
            "|    std                  | 1.32          |\n",
            "|    value_loss           | 0.0295        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 420          |\n",
            "|    iterations           | 430          |\n",
            "|    time_elapsed         | 2093         |\n",
            "|    total_timesteps      | 880640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036488953 |\n",
            "|    clip_fraction        | 0.0504       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.4         |\n",
            "|    explained_variance   | 0.289        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.014       |\n",
            "|    n_updates            | 4290         |\n",
            "|    policy_gradient_loss | -0.00452     |\n",
            "|    reward               | 0.0015158524 |\n",
            "|    std                  | 1.32         |\n",
            "|    value_loss           | 0.0728       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 420          |\n",
            "|    iterations           | 431          |\n",
            "|    time_elapsed         | 2100         |\n",
            "|    total_timesteps      | 882688       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006525874  |\n",
            "|    clip_fraction        | 0.0459       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.39        |\n",
            "|    explained_variance   | 0.826        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0454      |\n",
            "|    n_updates            | 4300         |\n",
            "|    policy_gradient_loss | -0.0084      |\n",
            "|    reward               | -0.022335349 |\n",
            "|    std                  | 1.32         |\n",
            "|    value_loss           | 0.0062       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 419          |\n",
            "|    iterations           | 432          |\n",
            "|    time_elapsed         | 2107         |\n",
            "|    total_timesteps      | 884736       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053054136 |\n",
            "|    clip_fraction        | 0.0324       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.39        |\n",
            "|    explained_variance   | 0.741        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0378      |\n",
            "|    n_updates            | 4310         |\n",
            "|    policy_gradient_loss | -0.00674     |\n",
            "|    reward               | 0.07951842   |\n",
            "|    std                  | 1.32         |\n",
            "|    value_loss           | 0.018        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 419          |\n",
            "|    iterations           | 433          |\n",
            "|    time_elapsed         | 2114         |\n",
            "|    total_timesteps      | 886784       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0072184755 |\n",
            "|    clip_fraction        | 0.0556       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.39        |\n",
            "|    explained_variance   | 0.511        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00468     |\n",
            "|    n_updates            | 4320         |\n",
            "|    policy_gradient_loss | -0.00655     |\n",
            "|    reward               | -0.08281837  |\n",
            "|    std                  | 1.32         |\n",
            "|    value_loss           | 0.0951       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 419           |\n",
            "|    iterations           | 434           |\n",
            "|    time_elapsed         | 2120          |\n",
            "|    total_timesteps      | 888832        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0068321284  |\n",
            "|    clip_fraction        | 0.0379        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.38         |\n",
            "|    explained_variance   | 0.351         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.00942      |\n",
            "|    n_updates            | 4330          |\n",
            "|    policy_gradient_loss | -0.00492      |\n",
            "|    reward               | -0.0128203025 |\n",
            "|    std                  | 1.31          |\n",
            "|    value_loss           | 0.097         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 418          |\n",
            "|    iterations           | 435          |\n",
            "|    time_elapsed         | 2126         |\n",
            "|    total_timesteps      | 890880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054418575 |\n",
            "|    clip_fraction        | 0.0531       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.38        |\n",
            "|    explained_variance   | 0.732        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0182      |\n",
            "|    n_updates            | 4340         |\n",
            "|    policy_gradient_loss | -0.00756     |\n",
            "|    reward               | 0.054022126  |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 0.0662       |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 315\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 124477.02\n",
            "total_reward: 114477.02\n",
            "total_cost: 558.29\n",
            "total_trades: 3770\n",
            "Sharpe: 0.635\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 418          |\n",
            "|    iterations           | 436          |\n",
            "|    time_elapsed         | 2132         |\n",
            "|    total_timesteps      | 892928       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037726064 |\n",
            "|    clip_fraction        | 0.0367       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.38        |\n",
            "|    explained_variance   | 0.213        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.154        |\n",
            "|    n_updates            | 4350         |\n",
            "|    policy_gradient_loss | -0.0018      |\n",
            "|    reward               | -0.01324754  |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 0.455        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 418          |\n",
            "|    iterations           | 437          |\n",
            "|    time_elapsed         | 2137         |\n",
            "|    total_timesteps      | 894976       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005561668  |\n",
            "|    clip_fraction        | 0.0283       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.38        |\n",
            "|    explained_variance   | 0.349        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0824       |\n",
            "|    n_updates            | 4360         |\n",
            "|    policy_gradient_loss | -0.00335     |\n",
            "|    reward               | -0.009102075 |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 0.241        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 418          |\n",
            "|    iterations           | 438          |\n",
            "|    time_elapsed         | 2143         |\n",
            "|    total_timesteps      | 897024       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045775063 |\n",
            "|    clip_fraction        | 0.0391       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.38        |\n",
            "|    explained_variance   | 0.551        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0115      |\n",
            "|    n_updates            | 4370         |\n",
            "|    policy_gradient_loss | -0.00387     |\n",
            "|    reward               | -0.14577356  |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 0.0799       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 418          |\n",
            "|    iterations           | 439          |\n",
            "|    time_elapsed         | 2148         |\n",
            "|    total_timesteps      | 899072       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044746576 |\n",
            "|    clip_fraction        | 0.0389       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.38        |\n",
            "|    explained_variance   | 0.342        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0161       |\n",
            "|    n_updates            | 4380         |\n",
            "|    policy_gradient_loss | -0.00817     |\n",
            "|    reward               | -0.000639896 |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 0.159        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 418         |\n",
            "|    iterations           | 440         |\n",
            "|    time_elapsed         | 2153        |\n",
            "|    total_timesteps      | 901120      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008075099 |\n",
            "|    clip_fraction        | 0.0493      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.38       |\n",
            "|    explained_variance   | 0.462       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.169       |\n",
            "|    n_updates            | 4390        |\n",
            "|    policy_gradient_loss | -0.00656    |\n",
            "|    reward               | -0.26587322 |\n",
            "|    std                  | 1.31        |\n",
            "|    value_loss           | 0.356       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 418         |\n",
            "|    iterations           | 441         |\n",
            "|    time_elapsed         | 2159        |\n",
            "|    total_timesteps      | 903168      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008570853 |\n",
            "|    clip_fraction        | 0.0562      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.37       |\n",
            "|    explained_variance   | 0.33        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.128       |\n",
            "|    n_updates            | 4400        |\n",
            "|    policy_gradient_loss | -0.00487    |\n",
            "|    reward               | 0.04057485  |\n",
            "|    std                  | 1.31        |\n",
            "|    value_loss           | 0.508       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 418          |\n",
            "|    iterations           | 442          |\n",
            "|    time_elapsed         | 2165         |\n",
            "|    total_timesteps      | 905216       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0066581485 |\n",
            "|    clip_fraction        | 0.0498       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.37        |\n",
            "|    explained_variance   | 0.576        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00995     |\n",
            "|    n_updates            | 4410         |\n",
            "|    policy_gradient_loss | -0.00887     |\n",
            "|    reward               | -0.07097662  |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 0.15         |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 320\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 284499.77\n",
            "total_reward: 274499.77\n",
            "total_cost: 347.64\n",
            "total_trades: 3520\n",
            "Sharpe: 0.861\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 443         |\n",
            "|    time_elapsed         | 2170        |\n",
            "|    total_timesteps      | 907264      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006829855 |\n",
            "|    clip_fraction        | 0.0346      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.37       |\n",
            "|    explained_variance   | 0.239       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.329       |\n",
            "|    n_updates            | 4420        |\n",
            "|    policy_gradient_loss | -0.00417    |\n",
            "|    reward               | 0.06321372  |\n",
            "|    std                  | 1.31        |\n",
            "|    value_loss           | 0.693       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 444         |\n",
            "|    time_elapsed         | 2175        |\n",
            "|    total_timesteps      | 909312      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005082541 |\n",
            "|    clip_fraction        | 0.0295      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.38       |\n",
            "|    explained_variance   | 0.305       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.253       |\n",
            "|    n_updates            | 4430        |\n",
            "|    policy_gradient_loss | -0.00317    |\n",
            "|    reward               | 0.20032874  |\n",
            "|    std                  | 1.31        |\n",
            "|    value_loss           | 0.717       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 417          |\n",
            "|    iterations           | 445          |\n",
            "|    time_elapsed         | 2181         |\n",
            "|    total_timesteps      | 911360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055974023 |\n",
            "|    clip_fraction        | 0.0397       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.38        |\n",
            "|    explained_variance   | 0.43         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.112        |\n",
            "|    n_updates            | 4440         |\n",
            "|    policy_gradient_loss | -0.00458     |\n",
            "|    reward               | -0.097609565 |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 0.345        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 417          |\n",
            "|    iterations           | 446          |\n",
            "|    time_elapsed         | 2186         |\n",
            "|    total_timesteps      | 913408       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0068378476 |\n",
            "|    clip_fraction        | 0.0636       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.38        |\n",
            "|    explained_variance   | 0.301        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.143        |\n",
            "|    n_updates            | 4450         |\n",
            "|    policy_gradient_loss | -0.00789     |\n",
            "|    reward               | -0.010712267 |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 0.556        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 417           |\n",
            "|    iterations           | 447           |\n",
            "|    time_elapsed         | 2191          |\n",
            "|    total_timesteps      | 915456        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.005177724   |\n",
            "|    clip_fraction        | 0.0437        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.38         |\n",
            "|    explained_variance   | 0.373         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.617         |\n",
            "|    n_updates            | 4460          |\n",
            "|    policy_gradient_loss | -0.0038       |\n",
            "|    reward               | -0.0051847044 |\n",
            "|    std                  | 1.31          |\n",
            "|    value_loss           | 0.751         |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 448         |\n",
            "|    time_elapsed         | 2197        |\n",
            "|    total_timesteps      | 917504      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009166177 |\n",
            "|    clip_fraction        | 0.0541      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.38       |\n",
            "|    explained_variance   | 0.305       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.231       |\n",
            "|    n_updates            | 4470        |\n",
            "|    policy_gradient_loss | -0.00286    |\n",
            "|    reward               | 0.2284895   |\n",
            "|    std                  | 1.32        |\n",
            "|    value_loss           | 0.598       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 417          |\n",
            "|    iterations           | 449          |\n",
            "|    time_elapsed         | 2202         |\n",
            "|    total_timesteps      | 919552       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059921597 |\n",
            "|    clip_fraction        | 0.0393       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.38        |\n",
            "|    explained_variance   | 0.556        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0806       |\n",
            "|    n_updates            | 4480         |\n",
            "|    policy_gradient_loss | -0.0039      |\n",
            "|    reward               | 0.20793636   |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 0.189        |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 325\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 317498.53\n",
            "total_reward: 307498.53\n",
            "total_cost: 373.60\n",
            "total_trades: 3706\n",
            "Sharpe: 0.866\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 417          |\n",
            "|    iterations           | 450          |\n",
            "|    time_elapsed         | 2207         |\n",
            "|    total_timesteps      | 921600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006954035  |\n",
            "|    clip_fraction        | 0.0487       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.37        |\n",
            "|    explained_variance   | 0.284        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.282        |\n",
            "|    n_updates            | 4490         |\n",
            "|    policy_gradient_loss | -0.00194     |\n",
            "|    reward               | -0.007993416 |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 0.603        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 417          |\n",
            "|    iterations           | 451          |\n",
            "|    time_elapsed         | 2212         |\n",
            "|    total_timesteps      | 923648       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051583173 |\n",
            "|    clip_fraction        | 0.0437       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.38        |\n",
            "|    explained_variance   | 0.43         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.486        |\n",
            "|    n_updates            | 4500         |\n",
            "|    policy_gradient_loss | -0.00599     |\n",
            "|    reward               | -0.29437622  |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 0.778        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 417          |\n",
            "|    iterations           | 452          |\n",
            "|    time_elapsed         | 2218         |\n",
            "|    total_timesteps      | 925696       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.00432414   |\n",
            "|    clip_fraction        | 0.0412       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.38        |\n",
            "|    explained_variance   | 0.412        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.233        |\n",
            "|    n_updates            | 4510         |\n",
            "|    policy_gradient_loss | -0.00263     |\n",
            "|    reward               | -0.011101741 |\n",
            "|    std                  | 1.32         |\n",
            "|    value_loss           | 0.522        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 417          |\n",
            "|    iterations           | 453          |\n",
            "|    time_elapsed         | 2222         |\n",
            "|    total_timesteps      | 927744       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0070063053 |\n",
            "|    clip_fraction        | 0.0646       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.38        |\n",
            "|    explained_variance   | 0.584        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0871       |\n",
            "|    n_updates            | 4520         |\n",
            "|    policy_gradient_loss | -0.00384     |\n",
            "|    reward               | 0.11909447   |\n",
            "|    std                  | 1.32         |\n",
            "|    value_loss           | 0.281        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 454         |\n",
            "|    time_elapsed         | 2226        |\n",
            "|    total_timesteps      | 929792      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006958518 |\n",
            "|    clip_fraction        | 0.0491      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.38       |\n",
            "|    explained_variance   | 0.429       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.357       |\n",
            "|    n_updates            | 4530        |\n",
            "|    policy_gradient_loss | -0.00403    |\n",
            "|    reward               | 0.023298467 |\n",
            "|    std                  | 1.31        |\n",
            "|    value_loss           | 0.7         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 455         |\n",
            "|    time_elapsed         | 2232        |\n",
            "|    total_timesteps      | 931840      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005092091 |\n",
            "|    clip_fraction        | 0.0331      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.38       |\n",
            "|    explained_variance   | 0.419       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.344       |\n",
            "|    n_updates            | 4540        |\n",
            "|    policy_gradient_loss | -0.0025     |\n",
            "|    reward               | -0.43037122 |\n",
            "|    std                  | 1.32        |\n",
            "|    value_loss           | 0.818       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 417          |\n",
            "|    iterations           | 456          |\n",
            "|    time_elapsed         | 2237         |\n",
            "|    total_timesteps      | 933888       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054617715 |\n",
            "|    clip_fraction        | 0.055        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.39        |\n",
            "|    explained_variance   | 0.635        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0767       |\n",
            "|    n_updates            | 4550         |\n",
            "|    policy_gradient_loss | -0.00594     |\n",
            "|    reward               | 0.104978666  |\n",
            "|    std                  | 1.32         |\n",
            "|    value_loss           | 0.286        |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 330\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 333528.68\n",
            "total_reward: 323528.68\n",
            "total_cost: 367.89\n",
            "total_trades: 3788\n",
            "Sharpe: 0.870\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 417          |\n",
            "|    iterations           | 457          |\n",
            "|    time_elapsed         | 2242         |\n",
            "|    total_timesteps      | 935936       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047152955 |\n",
            "|    clip_fraction        | 0.0272       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.39        |\n",
            "|    explained_variance   | 0.47         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.237        |\n",
            "|    n_updates            | 4560         |\n",
            "|    policy_gradient_loss | -0.00307     |\n",
            "|    reward               | -0.025234275 |\n",
            "|    std                  | 1.32         |\n",
            "|    value_loss           | 0.587        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 417          |\n",
            "|    iterations           | 458          |\n",
            "|    time_elapsed         | 2247         |\n",
            "|    total_timesteps      | 937984       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048870705 |\n",
            "|    clip_fraction        | 0.0521       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.38        |\n",
            "|    explained_variance   | 0.538        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.293        |\n",
            "|    n_updates            | 4570         |\n",
            "|    policy_gradient_loss | -0.0012      |\n",
            "|    reward               | 0.35815877   |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 0.773        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 459         |\n",
            "|    time_elapsed         | 2253        |\n",
            "|    total_timesteps      | 940032      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.00803661  |\n",
            "|    clip_fraction        | 0.0646      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.38       |\n",
            "|    explained_variance   | 0.308       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.454       |\n",
            "|    n_updates            | 4580        |\n",
            "|    policy_gradient_loss | -0.00498    |\n",
            "|    reward               | -0.32284695 |\n",
            "|    std                  | 1.31        |\n",
            "|    value_loss           | 0.832       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 417          |\n",
            "|    iterations           | 460          |\n",
            "|    time_elapsed         | 2258         |\n",
            "|    total_timesteps      | 942080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055695353 |\n",
            "|    clip_fraction        | 0.0423       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.39        |\n",
            "|    explained_variance   | 0.697        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.064        |\n",
            "|    n_updates            | 4590         |\n",
            "|    policy_gradient_loss | -0.00558     |\n",
            "|    reward               | 0.021707194  |\n",
            "|    std                  | 1.32         |\n",
            "|    value_loss           | 0.183        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 417          |\n",
            "|    iterations           | 461          |\n",
            "|    time_elapsed         | 2263         |\n",
            "|    total_timesteps      | 944128       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055123153 |\n",
            "|    clip_fraction        | 0.042        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.4         |\n",
            "|    explained_variance   | 0.47         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.158        |\n",
            "|    n_updates            | 4600         |\n",
            "|    policy_gradient_loss | -0.00146     |\n",
            "|    reward               | -0.029974    |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 0.489        |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 416        |\n",
            "|    iterations           | 462        |\n",
            "|    time_elapsed         | 2269       |\n",
            "|    total_timesteps      | 946176     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.0118538  |\n",
            "|    clip_fraction        | 0.0788     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.4       |\n",
            "|    explained_variance   | 0.41       |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 0.417      |\n",
            "|    n_updates            | 4610       |\n",
            "|    policy_gradient_loss | -0.00225   |\n",
            "|    reward               | 0.21656108 |\n",
            "|    std                  | 1.33       |\n",
            "|    value_loss           | 0.865      |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 463          |\n",
            "|    time_elapsed         | 2275         |\n",
            "|    total_timesteps      | 948224       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047669336 |\n",
            "|    clip_fraction        | 0.0474       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.4         |\n",
            "|    explained_variance   | 0.541        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.101        |\n",
            "|    n_updates            | 4620         |\n",
            "|    policy_gradient_loss | -0.00161     |\n",
            "|    reward               | -0.2231813   |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 0.353        |\n",
            "------------------------------------------\n",
            "day: 2833, episode: 335\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 326829.96\n",
            "total_reward: 316829.96\n",
            "total_cost: 358.02\n",
            "total_trades: 3682\n",
            "Sharpe: 0.869\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 464         |\n",
            "|    time_elapsed         | 2280        |\n",
            "|    total_timesteps      | 950272      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004408654 |\n",
            "|    clip_fraction        | 0.0299      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.4        |\n",
            "|    explained_variance   | 0.531       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.168       |\n",
            "|    n_updates            | 4630        |\n",
            "|    policy_gradient_loss | -0.00384    |\n",
            "|    reward               | 0.018739562 |\n",
            "|    std                  | 1.33        |\n",
            "|    value_loss           | 0.495       |\n",
            "-----------------------------------------\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 416            |\n",
            "|    iterations           | 465            |\n",
            "|    time_elapsed         | 2285           |\n",
            "|    total_timesteps      | 952320         |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.0067972797   |\n",
            "|    clip_fraction        | 0.0515         |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -3.4           |\n",
            "|    explained_variance   | 0.534          |\n",
            "|    learning_rate        | 0.00025        |\n",
            "|    loss                 | 0.324          |\n",
            "|    n_updates            | 4640           |\n",
            "|    policy_gradient_loss | -0.00676       |\n",
            "|    reward               | -0.00023914526 |\n",
            "|    std                  | 1.33           |\n",
            "|    value_loss           | 0.757          |\n",
            "--------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 466         |\n",
            "|    time_elapsed         | 2291        |\n",
            "|    total_timesteps      | 954368      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008470939 |\n",
            "|    clip_fraction        | 0.0698      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.4        |\n",
            "|    explained_variance   | 0.456       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.364       |\n",
            "|    n_updates            | 4650        |\n",
            "|    policy_gradient_loss | -0.00443    |\n",
            "|    reward               | -0.33844018 |\n",
            "|    std                  | 1.33        |\n",
            "|    value_loss           | 0.814       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 467         |\n",
            "|    time_elapsed         | 2296        |\n",
            "|    total_timesteps      | 956416      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013605623 |\n",
            "|    clip_fraction        | 0.0842      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.41       |\n",
            "|    explained_variance   | 0.721       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0469      |\n",
            "|    n_updates            | 4660        |\n",
            "|    policy_gradient_loss | -0.00526    |\n",
            "|    reward               | 0.0490667   |\n",
            "|    std                  | 1.34        |\n",
            "|    value_loss           | 0.208       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 468          |\n",
            "|    time_elapsed         | 2301         |\n",
            "|    total_timesteps      | 958464       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005775273  |\n",
            "|    clip_fraction        | 0.0394       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.4         |\n",
            "|    explained_variance   | 0.563        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.15         |\n",
            "|    n_updates            | 4670         |\n",
            "|    policy_gradient_loss | -0.00486     |\n",
            "|    reward               | -0.030714968 |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 0.54         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 469          |\n",
            "|    time_elapsed         | 2307         |\n",
            "|    total_timesteps      | 960512       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.010142581  |\n",
            "|    clip_fraction        | 0.0824       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.4         |\n",
            "|    explained_variance   | 0.607        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.319        |\n",
            "|    n_updates            | 4680         |\n",
            "|    policy_gradient_loss | -0.00201     |\n",
            "|    reward               | -0.018102339 |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 0.754        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 470         |\n",
            "|    time_elapsed         | 2312        |\n",
            "|    total_timesteps      | 962560      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006889162 |\n",
            "|    clip_fraction        | 0.0611      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.4        |\n",
            "|    explained_variance   | 0.414       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.258       |\n",
            "|    n_updates            | 4690        |\n",
            "|    policy_gradient_loss | -0.00228    |\n",
            "|    reward               | 0.24965642  |\n",
            "|    std                  | 1.32        |\n",
            "|    value_loss           | 0.618       |\n",
            "-----------------------------------------\n",
            "day: 2833, episode: 340\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 339229.90\n",
            "total_reward: 329229.90\n",
            "total_cost: 372.91\n",
            "total_trades: 3832\n",
            "Sharpe: 0.869\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 471         |\n",
            "|    time_elapsed         | 2318        |\n",
            "|    total_timesteps      | 964608      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006514688 |\n",
            "|    clip_fraction        | 0.0755      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.4        |\n",
            "|    explained_variance   | 0.721       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0734      |\n",
            "|    n_updates            | 4700        |\n",
            "|    policy_gradient_loss | -0.00759    |\n",
            "|    reward               | 0.07091379  |\n",
            "|    std                  | 1.33        |\n",
            "|    value_loss           | 0.253       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 472          |\n",
            "|    time_elapsed         | 2324         |\n",
            "|    total_timesteps      | 966656       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006861875  |\n",
            "|    clip_fraction        | 0.0504       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.39        |\n",
            "|    explained_variance   | 0.568        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.318        |\n",
            "|    n_updates            | 4710         |\n",
            "|    policy_gradient_loss | -0.00148     |\n",
            "|    reward               | -0.013219545 |\n",
            "|    std                  | 1.32         |\n",
            "|    value_loss           | 0.736        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 473         |\n",
            "|    time_elapsed         | 2329        |\n",
            "|    total_timesteps      | 968704      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008258559 |\n",
            "|    clip_fraction        | 0.0561      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.39       |\n",
            "|    explained_variance   | 0.547       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.334       |\n",
            "|    n_updates            | 4720        |\n",
            "|    policy_gradient_loss | -0.00236    |\n",
            "|    reward               | 0.62397546  |\n",
            "|    std                  | 1.33        |\n",
            "|    value_loss           | 0.79        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 474          |\n",
            "|    time_elapsed         | 2334         |\n",
            "|    total_timesteps      | 970752       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0065099024 |\n",
            "|    clip_fraction        | 0.0636       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.39        |\n",
            "|    explained_variance   | 0.645        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0864       |\n",
            "|    n_updates            | 4730         |\n",
            "|    policy_gradient_loss | -0.00276     |\n",
            "|    reward               | -0.22989121  |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 0.302        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 475         |\n",
            "|    time_elapsed         | 2339        |\n",
            "|    total_timesteps      | 972800      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010033467 |\n",
            "|    clip_fraction        | 0.0849      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.4        |\n",
            "|    explained_variance   | 0.617       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0988      |\n",
            "|    n_updates            | 4740        |\n",
            "|    policy_gradient_loss | -0.00822    |\n",
            "|    reward               | 0.025892567 |\n",
            "|    std                  | 1.33        |\n",
            "|    value_loss           | 0.481       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 476          |\n",
            "|    time_elapsed         | 2345         |\n",
            "|    total_timesteps      | 974848       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071328785 |\n",
            "|    clip_fraction        | 0.0949       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.41        |\n",
            "|    explained_variance   | 0.596        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.473        |\n",
            "|    n_updates            | 4750         |\n",
            "|    policy_gradient_loss | -0.00562     |\n",
            "|    reward               | -0.49857336  |\n",
            "|    std                  | 1.34         |\n",
            "|    value_loss           | 0.76         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 477         |\n",
            "|    time_elapsed         | 2350        |\n",
            "|    total_timesteps      | 976896      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008266207 |\n",
            "|    clip_fraction        | 0.0617      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.42       |\n",
            "|    explained_variance   | 0.432       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.447       |\n",
            "|    n_updates            | 4760        |\n",
            "|    policy_gradient_loss | -0.00466    |\n",
            "|    reward               | -0.15190554 |\n",
            "|    std                  | 1.34        |\n",
            "|    value_loss           | 0.801       |\n",
            "-----------------------------------------\n",
            "day: 2833, episode: 345\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 327601.06\n",
            "total_reward: 317601.06\n",
            "total_cost: 358.35\n",
            "total_trades: 3680\n",
            "Sharpe: 0.868\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 478          |\n",
            "|    time_elapsed         | 2355         |\n",
            "|    total_timesteps      | 978944       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0074758637 |\n",
            "|    clip_fraction        | 0.081        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.42        |\n",
            "|    explained_variance   | 0.772        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0478       |\n",
            "|    n_updates            | 4770         |\n",
            "|    policy_gradient_loss | -0.00295     |\n",
            "|    reward               | 0.09768118   |\n",
            "|    std                  | 1.35         |\n",
            "|    value_loss           | 0.169        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 479          |\n",
            "|    time_elapsed         | 2360         |\n",
            "|    total_timesteps      | 980992       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040442357 |\n",
            "|    clip_fraction        | 0.0345       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.43        |\n",
            "|    explained_variance   | 0.581        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.209        |\n",
            "|    n_updates            | 4780         |\n",
            "|    policy_gradient_loss | -0.00253     |\n",
            "|    reward               | -0.03095629  |\n",
            "|    std                  | 1.35         |\n",
            "|    value_loss           | 0.632        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 480         |\n",
            "|    time_elapsed         | 2366        |\n",
            "|    total_timesteps      | 983040      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010466407 |\n",
            "|    clip_fraction        | 0.0898      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.43       |\n",
            "|    explained_variance   | 0.582       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.461       |\n",
            "|    n_updates            | 4790        |\n",
            "|    policy_gradient_loss | -0.00559    |\n",
            "|    reward               | 0.060224213 |\n",
            "|    std                  | 1.35        |\n",
            "|    value_loss           | 0.817       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 481         |\n",
            "|    time_elapsed         | 2372        |\n",
            "|    total_timesteps      | 985088      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005974034 |\n",
            "|    clip_fraction        | 0.0515      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.43       |\n",
            "|    explained_variance   | 0.616       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.119       |\n",
            "|    n_updates            | 4800        |\n",
            "|    policy_gradient_loss | -0.00291    |\n",
            "|    reward               | 0.1715115   |\n",
            "|    std                  | 1.35        |\n",
            "|    value_loss           | 0.358       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 482          |\n",
            "|    time_elapsed         | 2377         |\n",
            "|    total_timesteps      | 987136       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004725957  |\n",
            "|    clip_fraction        | 0.0545       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.42        |\n",
            "|    explained_variance   | 0.7          |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0993       |\n",
            "|    n_updates            | 4810         |\n",
            "|    policy_gradient_loss | -0.00423     |\n",
            "|    reward               | -0.062629566 |\n",
            "|    std                  | 1.35         |\n",
            "|    value_loss           | 0.407        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 415           |\n",
            "|    iterations           | 483           |\n",
            "|    time_elapsed         | 2382          |\n",
            "|    total_timesteps      | 989184        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0072188564  |\n",
            "|    clip_fraction        | 0.0469        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.42         |\n",
            "|    explained_variance   | 0.619         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.258         |\n",
            "|    n_updates            | 4820          |\n",
            "|    policy_gradient_loss | 0.00113       |\n",
            "|    reward               | -0.0029242248 |\n",
            "|    std                  | 1.35          |\n",
            "|    value_loss           | 0.716         |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 484         |\n",
            "|    time_elapsed         | 2388        |\n",
            "|    total_timesteps      | 991232      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005364105 |\n",
            "|    clip_fraction        | 0.0543      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.42       |\n",
            "|    explained_variance   | 0.459       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.43        |\n",
            "|    n_updates            | 4830        |\n",
            "|    policy_gradient_loss | -0.00482    |\n",
            "|    reward               | 0.7702489   |\n",
            "|    std                  | 1.34        |\n",
            "|    value_loss           | 0.807       |\n",
            "-----------------------------------------\n",
            "day: 2833, episode: 350\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: 313597.07\n",
            "total_reward: 303597.07\n",
            "total_cost: 348.87\n",
            "total_trades: 3568\n",
            "Sharpe: 0.865\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 485         |\n",
            "|    time_elapsed         | 2393        |\n",
            "|    total_timesteps      | 993280      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007849552 |\n",
            "|    clip_fraction        | 0.0467      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.41       |\n",
            "|    explained_variance   | 0.722       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.083       |\n",
            "|    n_updates            | 4840        |\n",
            "|    policy_gradient_loss | -0.00535    |\n",
            "|    reward               | -0.08109243 |\n",
            "|    std                  | 1.33        |\n",
            "|    value_loss           | 0.21        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 486          |\n",
            "|    time_elapsed         | 2399         |\n",
            "|    total_timesteps      | 995328       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005318884  |\n",
            "|    clip_fraction        | 0.0302       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.41        |\n",
            "|    explained_variance   | 0.624        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.174        |\n",
            "|    n_updates            | 4850         |\n",
            "|    policy_gradient_loss | -0.00176     |\n",
            "|    reward               | -0.013525894 |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 0.482        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 414         |\n",
            "|    iterations           | 487         |\n",
            "|    time_elapsed         | 2404        |\n",
            "|    total_timesteps      | 997376      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008017873 |\n",
            "|    clip_fraction        | 0.0503      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.4        |\n",
            "|    explained_variance   | 0.6         |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.346       |\n",
            "|    n_updates            | 4860        |\n",
            "|    policy_gradient_loss | 5.34e-05    |\n",
            "|    reward               | -0.41187742 |\n",
            "|    std                  | 1.33        |\n",
            "|    value_loss           | 0.684       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 414         |\n",
            "|    iterations           | 488         |\n",
            "|    time_elapsed         | 2410        |\n",
            "|    total_timesteps      | 999424      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007943907 |\n",
            "|    clip_fraction        | 0.0472      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.41       |\n",
            "|    explained_variance   | 0.479       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.272       |\n",
            "|    n_updates            | 4870        |\n",
            "|    policy_gradient_loss | 0.00109     |\n",
            "|    reward               | 0.29659647  |\n",
            "|    std                  | 1.34        |\n",
            "|    value_loss           | 0.596       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 414         |\n",
            "|    iterations           | 489         |\n",
            "|    time_elapsed         | 2415        |\n",
            "|    total_timesteps      | 1001472     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005928636 |\n",
            "|    clip_fraction        | 0.0334      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.41       |\n",
            "|    explained_variance   | 0.813       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.043       |\n",
            "|    n_updates            | 4880        |\n",
            "|    policy_gradient_loss | -0.00289    |\n",
            "|    reward               | 0.03289482  |\n",
            "|    std                  | 1.33        |\n",
            "|    value_loss           | 0.208       |\n",
            "-----------------------------------------\n",
            "======PPO Validation from:  2021-07-06 to  2021-10-04\n",
            "PPO Sharpe Ratio:  0.08435618577260197\n",
            "======Best Model Retraining from:  2010-04-01 to  2021-10-04\n",
            "======Trading from:  2021-10-04 to  2022-01-03\n",
            "[[ 8.2802529e+03  1.5139046e+02  4.5818875e+02 -8.0000000e+01\n",
            "   2.8000000e+01 -3.0756192e+00 -1.5466686e-01  1.8381166e+02\n",
            "   4.9193375e+02  1.5252879e+02  4.6105872e+02  3.8965439e+01\n",
            "   4.6421917e+01 -2.4250757e+02 -1.6717531e+02  4.8588673e+01\n",
            "   2.3755117e+01  1.6987848e+02  4.7400714e+02  1.6155258e+02\n",
            "   4.6655853e+02]]\n",
            "============================================\n",
            "turbulence_threshold:  18.962438407024404\n",
            "======Model training from:  2010-04-01 to  2021-10-04\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cpu device\n",
            "Logging to tensorboard_log/ppo\\ppo_315_1\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    fps             | 421         |\n",
            "|    iterations      | 1           |\n",
            "|    time_elapsed    | 4           |\n",
            "|    total_timesteps | 2048        |\n",
            "| train/             |             |\n",
            "|    reward          | -0.05952631 |\n",
            "------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 395          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 10           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037666983 |\n",
            "|    clip_fraction        | 0.0211       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | -0.441       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0173      |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00181     |\n",
            "|    reward               | 0.036110435  |\n",
            "|    std                  | 0.998        |\n",
            "|    value_loss           | 0.0095       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 391          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 15           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036655637 |\n",
            "|    clip_fraction        | 0.0229       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.83        |\n",
            "|    explained_variance   | -0.07        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0197      |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00135     |\n",
            "|    reward               | 0.009173845  |\n",
            "|    std                  | 0.999        |\n",
            "|    value_loss           | 0.0393       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 392          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 20           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.003111651  |\n",
            "|    clip_fraction        | 0.0177       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | -0.00736     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00837     |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00144     |\n",
            "|    reward               | -0.031197434 |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.0483       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 389          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 26           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059063956 |\n",
            "|    clip_fraction        | 0.0353       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | 0.000154     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0238      |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00323     |\n",
            "|    reward               | 0.0047235005 |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.0207       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 386          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 31           |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040801717 |\n",
            "|    clip_fraction        | 0.0119       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | -0.000211    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00281      |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.00102     |\n",
            "|    reward               | -0.033522684 |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.0547       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 381          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 37           |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0006640245 |\n",
            "|    clip_fraction        | 4.88e-05     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | -0.00956     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00797     |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.000202    |\n",
            "|    reward               | 1.1997572    |\n",
            "|    std                  | 0.998        |\n",
            "|    value_loss           | 0.0513       |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 5\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -320397.03\n",
            "total_reward: -330397.03\n",
            "total_cost: 491.28\n",
            "total_trades: 2986\n",
            "Sharpe: 0.327\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 379         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 43          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004682433 |\n",
            "|    clip_fraction        | 0.0359      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.83       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.175       |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.00226    |\n",
            "|    reward               | 0.03152921  |\n",
            "|    std                  | 0.998       |\n",
            "|    value_loss           | 0.522       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 378          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 48           |\n",
            "|    total_timesteps      | 18432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037308238 |\n",
            "|    clip_fraction        | 0.0368       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.83        |\n",
            "|    explained_variance   | -1.9e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0224      |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -0.00352     |\n",
            "|    reward               | -0.006256942 |\n",
            "|    std                  | 0.995        |\n",
            "|    value_loss           | 0.0766       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 378          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 54           |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023853113 |\n",
            "|    clip_fraction        | 0.0172       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.83        |\n",
            "|    explained_variance   | -2.35e-05    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0596       |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.00062     |\n",
            "|    reward               | -0.010328209 |\n",
            "|    std                  | 0.997        |\n",
            "|    value_loss           | 0.121        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 377          |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 59           |\n",
            "|    total_timesteps      | 22528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036467914 |\n",
            "|    clip_fraction        | 0.0242       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.84        |\n",
            "|    explained_variance   | -2.09e-05    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0864       |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -0.0012      |\n",
            "|    reward               | -0.12135784  |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.134        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 376          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 65           |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012363528 |\n",
            "|    clip_fraction        | 0.00835      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.85        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0207      |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.000646    |\n",
            "|    reward               | -0.07005751  |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.0208       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 377           |\n",
            "|    iterations           | 13            |\n",
            "|    time_elapsed         | 70            |\n",
            "|    total_timesteps      | 26624         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0023089554  |\n",
            "|    clip_fraction        | 0.0246        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.86         |\n",
            "|    explained_variance   | -3.49e-05     |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.00768       |\n",
            "|    n_updates            | 120           |\n",
            "|    policy_gradient_loss | -0.00156      |\n",
            "|    reward               | -0.0028853633 |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 0.0751        |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 377         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 75          |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003983247 |\n",
            "|    clip_fraction        | 0.0326      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.87       |\n",
            "|    explained_variance   | 0.00131     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0195     |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0022     |\n",
            "|    reward               | -0.06567385 |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 0.0545      |\n",
            "-----------------------------------------\n",
            "day: 2896, episode: 10\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -80310.27\n",
            "total_reward: -90310.27\n",
            "total_cost: 445.38\n",
            "total_trades: 2896\n",
            "Sharpe: 0.705\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 376          |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 81           |\n",
            "|    total_timesteps      | 30720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069400277 |\n",
            "|    clip_fraction        | 0.0487       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.87        |\n",
            "|    explained_variance   | -0.0323      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0219      |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.00219     |\n",
            "|    reward               | -0.047267817 |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 0.0235       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 377           |\n",
            "|    iterations           | 16            |\n",
            "|    time_elapsed         | 86            |\n",
            "|    total_timesteps      | 32768         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.004304285   |\n",
            "|    clip_fraction        | 0.0232        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.86         |\n",
            "|    explained_variance   | 0.0227        |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0173       |\n",
            "|    n_updates            | 150           |\n",
            "|    policy_gradient_loss | -0.00102      |\n",
            "|    reward               | -0.0060085054 |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 0.0174        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 377          |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 92           |\n",
            "|    total_timesteps      | 34816        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030795417 |\n",
            "|    clip_fraction        | 0.0102       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.86        |\n",
            "|    explained_variance   | 0.105        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00181     |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -0.000223    |\n",
            "|    reward               | -0.010110414 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.0497       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 377          |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 97           |\n",
            "|    total_timesteps      | 36864        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.003767139  |\n",
            "|    clip_fraction        | 0.041        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.87        |\n",
            "|    explained_variance   | 0.0458       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00243      |\n",
            "|    n_updates            | 170          |\n",
            "|    policy_gradient_loss | -0.00219     |\n",
            "|    reward               | -0.039244924 |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 0.0758       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 377          |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 103          |\n",
            "|    total_timesteps      | 38912        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036980305 |\n",
            "|    clip_fraction        | 0.0336       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.88        |\n",
            "|    explained_variance   | 0.0503       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0359      |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -0.00144     |\n",
            "|    reward               | -0.019504923 |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.0172       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 377          |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 108          |\n",
            "|    total_timesteps      | 40960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043920623 |\n",
            "|    clip_fraction        | 0.0226       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.9         |\n",
            "|    explained_variance   | 0.0741       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0115       |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | -0.00258     |\n",
            "|    reward               | -0.003103655 |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.0879       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 375          |\n",
            "|    iterations           | 21           |\n",
            "|    time_elapsed         | 114          |\n",
            "|    total_timesteps      | 43008        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.00416187   |\n",
            "|    clip_fraction        | 0.025        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.9         |\n",
            "|    explained_variance   | 0.16         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0128       |\n",
            "|    n_updates            | 200          |\n",
            "|    policy_gradient_loss | -0.00164     |\n",
            "|    reward               | -0.023290897 |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.0735       |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 15\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -114100.48\n",
            "total_reward: -124100.48\n",
            "total_cost: 462.64\n",
            "total_trades: 2954\n",
            "Sharpe: -0.234\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 375          |\n",
            "|    iterations           | 22           |\n",
            "|    time_elapsed         | 119          |\n",
            "|    total_timesteps      | 45056        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005389182  |\n",
            "|    clip_fraction        | 0.0347       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.9         |\n",
            "|    explained_variance   | 0.199        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.019       |\n",
            "|    n_updates            | 210          |\n",
            "|    policy_gradient_loss | -0.00171     |\n",
            "|    reward               | -0.010387122 |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.0296       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 374           |\n",
            "|    iterations           | 23            |\n",
            "|    time_elapsed         | 125           |\n",
            "|    total_timesteps      | 47104         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0046662935  |\n",
            "|    clip_fraction        | 0.0293        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.89         |\n",
            "|    explained_variance   | 0.186         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.0028       |\n",
            "|    n_updates            | 220           |\n",
            "|    policy_gradient_loss | -0.00185      |\n",
            "|    reward               | -0.0046272767 |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 0.0587        |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 373         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 131         |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003002132 |\n",
            "|    clip_fraction        | 0.0149      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.89       |\n",
            "|    explained_variance   | 0.272       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.00133     |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | 0.000885    |\n",
            "|    reward               | 0.06279477  |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 0.0575      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 372          |\n",
            "|    iterations           | 25           |\n",
            "|    time_elapsed         | 137          |\n",
            "|    total_timesteps      | 51200        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0063055065 |\n",
            "|    clip_fraction        | 0.062        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.9         |\n",
            "|    explained_variance   | 0.082        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00773      |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | 0.000472     |\n",
            "|    reward               | 0.08732612   |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.129        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 372          |\n",
            "|    iterations           | 26           |\n",
            "|    time_elapsed         | 142          |\n",
            "|    total_timesteps      | 53248        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032372428 |\n",
            "|    clip_fraction        | 0.0175       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.92        |\n",
            "|    explained_variance   | 0.149        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0316      |\n",
            "|    n_updates            | 250          |\n",
            "|    policy_gradient_loss | -0.00108     |\n",
            "|    reward               | -0.024681946 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.0219       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 371           |\n",
            "|    iterations           | 27            |\n",
            "|    time_elapsed         | 148           |\n",
            "|    total_timesteps      | 55296         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0051045893  |\n",
            "|    clip_fraction        | 0.0245        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.94         |\n",
            "|    explained_variance   | 0.0379        |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0382        |\n",
            "|    n_updates            | 260           |\n",
            "|    policy_gradient_loss | -0.00197      |\n",
            "|    reward               | -0.0044884714 |\n",
            "|    std                  | 1.06          |\n",
            "|    value_loss           | 0.121         |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 370         |\n",
            "|    iterations           | 28          |\n",
            "|    time_elapsed         | 154         |\n",
            "|    total_timesteps      | 57344       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005185498 |\n",
            "|    clip_fraction        | 0.0195      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.93       |\n",
            "|    explained_variance   | 0.0178      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.00764     |\n",
            "|    n_updates            | 270         |\n",
            "|    policy_gradient_loss | -0.00207    |\n",
            "|    reward               | 0.25916728  |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 0.103       |\n",
            "-----------------------------------------\n",
            "day: 2896, episode: 20\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -133829.79\n",
            "total_reward: -143829.79\n",
            "total_cost: 478.57\n",
            "total_trades: 2956\n",
            "Sharpe: -0.034\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 370          |\n",
            "|    iterations           | 29           |\n",
            "|    time_elapsed         | 160          |\n",
            "|    total_timesteps      | 59392        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045101116 |\n",
            "|    clip_fraction        | 0.0287       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.93        |\n",
            "|    explained_variance   | 0.0892       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.000477     |\n",
            "|    n_updates            | 280          |\n",
            "|    policy_gradient_loss | -0.00272     |\n",
            "|    reward               | 0.08585967   |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.0379       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 371          |\n",
            "|    iterations           | 30           |\n",
            "|    time_elapsed         | 165          |\n",
            "|    total_timesteps      | 61440        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038893975 |\n",
            "|    clip_fraction        | 0.0304       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.93        |\n",
            "|    explained_variance   | 0.118        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0166       |\n",
            "|    n_updates            | 290          |\n",
            "|    policy_gradient_loss | -0.0028      |\n",
            "|    reward               | -0.009454982 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.0903       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 370         |\n",
            "|    iterations           | 31          |\n",
            "|    time_elapsed         | 171         |\n",
            "|    total_timesteps      | 63488       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006166353 |\n",
            "|    clip_fraction        | 0.0355      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.93       |\n",
            "|    explained_variance   | 0.25        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0153     |\n",
            "|    n_updates            | 300         |\n",
            "|    policy_gradient_loss | -0.00362    |\n",
            "|    reward               | -0.15761285 |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 0.0734      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 371         |\n",
            "|    iterations           | 32          |\n",
            "|    time_elapsed         | 176         |\n",
            "|    total_timesteps      | 65536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003340737 |\n",
            "|    clip_fraction        | 0.00732     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.93       |\n",
            "|    explained_variance   | 0.239       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0122     |\n",
            "|    n_updates            | 310         |\n",
            "|    policy_gradient_loss | -0.000927   |\n",
            "|    reward               | 0.015748508 |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 0.0647      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 371          |\n",
            "|    iterations           | 33           |\n",
            "|    time_elapsed         | 181          |\n",
            "|    total_timesteps      | 67584        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055340473 |\n",
            "|    clip_fraction        | 0.0419       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.93        |\n",
            "|    explained_variance   | 0.32         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.00645     |\n",
            "|    n_updates            | 320          |\n",
            "|    policy_gradient_loss | -0.00204     |\n",
            "|    reward               | -0.05707772  |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.0355       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 371          |\n",
            "|    iterations           | 34           |\n",
            "|    time_elapsed         | 187          |\n",
            "|    total_timesteps      | 69632        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016732134 |\n",
            "|    clip_fraction        | 0.0101       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.95        |\n",
            "|    explained_variance   | 0.3          |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0198       |\n",
            "|    n_updates            | 330          |\n",
            "|    policy_gradient_loss | -0.000696    |\n",
            "|    reward               | 0.0041242    |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.0831       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 371          |\n",
            "|    iterations           | 35           |\n",
            "|    time_elapsed         | 193          |\n",
            "|    total_timesteps      | 71680        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026250114 |\n",
            "|    clip_fraction        | 0.00815      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.96        |\n",
            "|    explained_variance   | 0.234        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0299       |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | -0.00141     |\n",
            "|    reward               | 0.024102831  |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.0916       |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 25\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -101520.87\n",
            "total_reward: -111520.87\n",
            "total_cost: 482.22\n",
            "total_trades: 2940\n",
            "Sharpe: 0.480\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 370          |\n",
            "|    iterations           | 36           |\n",
            "|    time_elapsed         | 198          |\n",
            "|    total_timesteps      | 73728        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005200632  |\n",
            "|    clip_fraction        | 0.0166       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.96        |\n",
            "|    explained_variance   | 0.371        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0152      |\n",
            "|    n_updates            | 350          |\n",
            "|    policy_gradient_loss | -0.00127     |\n",
            "|    reward               | -0.035352487 |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.0141       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 367           |\n",
            "|    iterations           | 37            |\n",
            "|    time_elapsed         | 206           |\n",
            "|    total_timesteps      | 75776         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0049228845  |\n",
            "|    clip_fraction        | 0.0187        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.96         |\n",
            "|    explained_variance   | 0.257         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.0212        |\n",
            "|    n_updates            | 360           |\n",
            "|    policy_gradient_loss | -0.00098      |\n",
            "|    reward               | -0.0061914073 |\n",
            "|    std                  | 1.06          |\n",
            "|    value_loss           | 0.0608        |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 364         |\n",
            "|    iterations           | 38          |\n",
            "|    time_elapsed         | 213         |\n",
            "|    total_timesteps      | 77824       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003523155 |\n",
            "|    clip_fraction        | 0.00913     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.96       |\n",
            "|    explained_variance   | 0.283       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.00599    |\n",
            "|    n_updates            | 370         |\n",
            "|    policy_gradient_loss | -0.0014     |\n",
            "|    reward               | 0.75211614  |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 0.052       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 363          |\n",
            "|    iterations           | 39           |\n",
            "|    time_elapsed         | 219          |\n",
            "|    total_timesteps      | 79872        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0003245844 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.95        |\n",
            "|    explained_variance   | -0.000322    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0405       |\n",
            "|    n_updates            | 380          |\n",
            "|    policy_gradient_loss | 0.000307     |\n",
            "|    reward               | -0.043751128 |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.124        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 360          |\n",
            "|    iterations           | 40           |\n",
            "|    time_elapsed         | 227          |\n",
            "|    total_timesteps      | 81920        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047997735 |\n",
            "|    clip_fraction        | 0.0194       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.95        |\n",
            "|    explained_variance   | 0.0978       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.013        |\n",
            "|    n_updates            | 390          |\n",
            "|    policy_gradient_loss | -0.00114     |\n",
            "|    reward               | 0.008469273  |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.102        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 356           |\n",
            "|    iterations           | 41            |\n",
            "|    time_elapsed         | 235           |\n",
            "|    total_timesteps      | 83968         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00028727573 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.94         |\n",
            "|    explained_variance   | 0.449         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.00411      |\n",
            "|    n_updates            | 400           |\n",
            "|    policy_gradient_loss | 0.000105      |\n",
            "|    reward               | -0.03683572   |\n",
            "|    std                  | 1.05          |\n",
            "|    value_loss           | 0.0564        |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 355         |\n",
            "|    iterations           | 42          |\n",
            "|    time_elapsed         | 242         |\n",
            "|    total_timesteps      | 86016       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007911291 |\n",
            "|    clip_fraction        | 0.0739      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.94       |\n",
            "|    explained_variance   | 0.201       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.00527     |\n",
            "|    n_updates            | 410         |\n",
            "|    policy_gradient_loss | -0.00507    |\n",
            "|    reward               | 0.3216166   |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 0.0807      |\n",
            "-----------------------------------------\n",
            "day: 2896, episode: 30\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -130222.54\n",
            "total_reward: -140222.54\n",
            "total_cost: 475.79\n",
            "total_trades: 2970\n",
            "Sharpe: 0.298\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 43           |\n",
            "|    time_elapsed         | 247          |\n",
            "|    total_timesteps      | 88064        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038156027 |\n",
            "|    clip_fraction        | 0.0245       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.93        |\n",
            "|    explained_variance   | 0.0203       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0177      |\n",
            "|    n_updates            | 420          |\n",
            "|    policy_gradient_loss | -0.0011      |\n",
            "|    reward               | 0.11940829   |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.0173       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 44           |\n",
            "|    time_elapsed         | 253          |\n",
            "|    total_timesteps      | 90112        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055233473 |\n",
            "|    clip_fraction        | 0.0458       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.92        |\n",
            "|    explained_variance   | 0.0662       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00528      |\n",
            "|    n_updates            | 430          |\n",
            "|    policy_gradient_loss | -0.00272     |\n",
            "|    reward               | 0.0043116417 |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.114        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 45           |\n",
            "|    time_elapsed         | 259          |\n",
            "|    total_timesteps      | 92160        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025040284 |\n",
            "|    clip_fraction        | 0.00103      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.92        |\n",
            "|    explained_variance   | 0.0308       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.203        |\n",
            "|    n_updates            | 440          |\n",
            "|    policy_gradient_loss | -0.000345    |\n",
            "|    reward               | -0.11376839  |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.573        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 46           |\n",
            "|    time_elapsed         | 265          |\n",
            "|    total_timesteps      | 94208        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059139617 |\n",
            "|    clip_fraction        | 0.0489       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.91        |\n",
            "|    explained_variance   | 0.312        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00578      |\n",
            "|    n_updates            | 450          |\n",
            "|    policy_gradient_loss | -0.00378     |\n",
            "|    reward               | 0.049842186  |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.0458       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 354          |\n",
            "|    iterations           | 47           |\n",
            "|    time_elapsed         | 271          |\n",
            "|    total_timesteps      | 96256        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049915635 |\n",
            "|    clip_fraction        | 0.0382       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.91        |\n",
            "|    explained_variance   | 0.237        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.024        |\n",
            "|    n_updates            | 460          |\n",
            "|    policy_gradient_loss | -0.00215     |\n",
            "|    reward               | -0.02534286  |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.113        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 354          |\n",
            "|    iterations           | 48           |\n",
            "|    time_elapsed         | 277          |\n",
            "|    total_timesteps      | 98304        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021808208 |\n",
            "|    clip_fraction        | 0.0194       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.91        |\n",
            "|    explained_variance   | 0.243        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.111        |\n",
            "|    n_updates            | 470          |\n",
            "|    policy_gradient_loss | -0.00167     |\n",
            "|    reward               | -0.25295314  |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.198        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 49           |\n",
            "|    time_elapsed         | 282          |\n",
            "|    total_timesteps      | 100352       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051247505 |\n",
            "|    clip_fraction        | 0.0553       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.9         |\n",
            "|    explained_variance   | 0.269        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.03         |\n",
            "|    n_updates            | 480          |\n",
            "|    policy_gradient_loss | -0.00266     |\n",
            "|    reward               | -0.11693923  |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.171        |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 35\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -190286.75\n",
            "total_reward: -200286.75\n",
            "total_cost: 488.27\n",
            "total_trades: 2904\n",
            "Sharpe: 0.716\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 50           |\n",
            "|    time_elapsed         | 288          |\n",
            "|    total_timesteps      | 102400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059356918 |\n",
            "|    clip_fraction        | 0.0213       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.9         |\n",
            "|    explained_variance   | 0.333        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0246       |\n",
            "|    n_updates            | 490          |\n",
            "|    policy_gradient_loss | -0.00126     |\n",
            "|    reward               | -0.01408268  |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.0579       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 51           |\n",
            "|    time_elapsed         | 294          |\n",
            "|    total_timesteps      | 104448       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.003628898  |\n",
            "|    clip_fraction        | 0.0339       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.9         |\n",
            "|    explained_variance   | 0.239        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.102        |\n",
            "|    n_updates            | 500          |\n",
            "|    policy_gradient_loss | -0.00259     |\n",
            "|    reward               | -0.009635737 |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.243        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 354          |\n",
            "|    iterations           | 52           |\n",
            "|    time_elapsed         | 300          |\n",
            "|    total_timesteps      | 106496       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0074430644 |\n",
            "|    clip_fraction        | 0.0199       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.9         |\n",
            "|    explained_variance   | 0.277        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0944       |\n",
            "|    n_updates            | 510          |\n",
            "|    policy_gradient_loss | -0.00113     |\n",
            "|    reward               | 0.62958235   |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.205        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 355         |\n",
            "|    iterations           | 53          |\n",
            "|    time_elapsed         | 305         |\n",
            "|    total_timesteps      | 108544      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004564887 |\n",
            "|    clip_fraction        | 0.0383      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.9        |\n",
            "|    explained_variance   | 0.414       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0199     |\n",
            "|    n_updates            | 520         |\n",
            "|    policy_gradient_loss | -0.00125    |\n",
            "|    reward               | 0.022987615 |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 0.0305      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 54           |\n",
            "|    time_elapsed         | 311          |\n",
            "|    total_timesteps      | 110592       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040602824 |\n",
            "|    clip_fraction        | 0.0125       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.93        |\n",
            "|    explained_variance   | 0.312        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0207       |\n",
            "|    n_updates            | 530          |\n",
            "|    policy_gradient_loss | -0.00147     |\n",
            "|    reward               | 0.004181891  |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.122        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 355         |\n",
            "|    iterations           | 55          |\n",
            "|    time_elapsed         | 317         |\n",
            "|    total_timesteps      | 112640      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004633863 |\n",
            "|    clip_fraction        | 0.0202      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.95       |\n",
            "|    explained_variance   | 0.227       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.134       |\n",
            "|    n_updates            | 540         |\n",
            "|    policy_gradient_loss | -0.00157    |\n",
            "|    reward               | -0.25314313 |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 0.249       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 56           |\n",
            "|    time_elapsed         | 322          |\n",
            "|    total_timesteps      | 114688       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021977564 |\n",
            "|    clip_fraction        | 0.00737      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.95        |\n",
            "|    explained_variance   | 0.15         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0579       |\n",
            "|    n_updates            | 550          |\n",
            "|    policy_gradient_loss | -0.000293    |\n",
            "|    reward               | -0.012377581 |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.152        |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 40\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -195688.54\n",
            "total_reward: -205688.54\n",
            "total_cost: 495.46\n",
            "total_trades: 2776\n",
            "Sharpe: 0.317\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 354          |\n",
            "|    iterations           | 57           |\n",
            "|    time_elapsed         | 328          |\n",
            "|    total_timesteps      | 116736       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053308667 |\n",
            "|    clip_fraction        | 0.0164       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.96        |\n",
            "|    explained_variance   | 0.328        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0304       |\n",
            "|    n_updates            | 560          |\n",
            "|    policy_gradient_loss | -0.000864    |\n",
            "|    reward               | -0.014795452 |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 0.0992       |\n",
            "------------------------------------------\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 353            |\n",
            "|    iterations           | 58             |\n",
            "|    time_elapsed         | 335            |\n",
            "|    total_timesteps      | 118784         |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.0052375756   |\n",
            "|    clip_fraction        | 0.0248         |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -2.96          |\n",
            "|    explained_variance   | 0.336          |\n",
            "|    learning_rate        | 0.00025        |\n",
            "|    loss                 | 0.0915         |\n",
            "|    n_updates            | 570            |\n",
            "|    policy_gradient_loss | -0.000769      |\n",
            "|    reward               | -0.00010389372 |\n",
            "|    std                  | 1.06           |\n",
            "|    value_loss           | 0.286          |\n",
            "--------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 353         |\n",
            "|    iterations           | 59          |\n",
            "|    time_elapsed         | 342         |\n",
            "|    total_timesteps      | 120832      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002532137 |\n",
            "|    clip_fraction        | 0.0149      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.96       |\n",
            "|    explained_variance   | 0.24        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.214       |\n",
            "|    n_updates            | 580         |\n",
            "|    policy_gradient_loss | -0.00183    |\n",
            "|    reward               | -0.11595269 |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 0.463       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 352         |\n",
            "|    iterations           | 60          |\n",
            "|    time_elapsed         | 348         |\n",
            "|    total_timesteps      | 122880      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005571209 |\n",
            "|    clip_fraction        | 0.0421      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.96       |\n",
            "|    explained_variance   | 0.412       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.00985    |\n",
            "|    n_updates            | 590         |\n",
            "|    policy_gradient_loss | -0.003      |\n",
            "|    reward               | 0.07102959  |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 0.0465      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 352          |\n",
            "|    iterations           | 61           |\n",
            "|    time_elapsed         | 354          |\n",
            "|    total_timesteps      | 124928       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034429627 |\n",
            "|    clip_fraction        | 0.00854      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.96        |\n",
            "|    explained_variance   | 0.235        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.22         |\n",
            "|    n_updates            | 600          |\n",
            "|    policy_gradient_loss | 0.000392     |\n",
            "|    reward               | -0.002613586 |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.462        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 351           |\n",
            "|    iterations           | 62            |\n",
            "|    time_elapsed         | 360           |\n",
            "|    total_timesteps      | 126976        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00031878526 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.97         |\n",
            "|    explained_variance   | 0.132         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.371         |\n",
            "|    n_updates            | 610           |\n",
            "|    policy_gradient_loss | 0.000141      |\n",
            "|    reward               | -0.21606435   |\n",
            "|    std                  | 1.07          |\n",
            "|    value_loss           | 0.697         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 351          |\n",
            "|    iterations           | 63           |\n",
            "|    time_elapsed         | 366          |\n",
            "|    total_timesteps      | 129024       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041727005 |\n",
            "|    clip_fraction        | 0.0393       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.97        |\n",
            "|    explained_variance   | 0.322        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0883       |\n",
            "|    n_updates            | 620          |\n",
            "|    policy_gradient_loss | -0.000738    |\n",
            "|    reward               | -0.094927475 |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.227        |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 45\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -350794.07\n",
            "total_reward: -360794.07\n",
            "total_cost: 602.21\n",
            "total_trades: 3218\n",
            "Sharpe: 0.336\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 351          |\n",
            "|    iterations           | 64           |\n",
            "|    time_elapsed         | 373          |\n",
            "|    total_timesteps      | 131072       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020964877 |\n",
            "|    clip_fraction        | 0.0301       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.98        |\n",
            "|    explained_variance   | 0.256        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.114        |\n",
            "|    n_updates            | 630          |\n",
            "|    policy_gradient_loss | -0.00154     |\n",
            "|    reward               | 0.0030988208 |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 0.6          |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 351           |\n",
            "|    iterations           | 65            |\n",
            "|    time_elapsed         | 378           |\n",
            "|    total_timesteps      | 133120        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00026944175 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.98         |\n",
            "|    explained_variance   | 0.268         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.488         |\n",
            "|    n_updates            | 640           |\n",
            "|    policy_gradient_loss | 6.92e-05      |\n",
            "|    reward               | 0.22801521    |\n",
            "|    std                  | 1.08          |\n",
            "|    value_loss           | 0.966         |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 351         |\n",
            "|    iterations           | 66          |\n",
            "|    time_elapsed         | 384         |\n",
            "|    total_timesteps      | 135168      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.000764544 |\n",
            "|    clip_fraction        | 0.0101      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.99       |\n",
            "|    explained_variance   | 0.301       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.358       |\n",
            "|    n_updates            | 650         |\n",
            "|    policy_gradient_loss | -0.00104    |\n",
            "|    reward               | 0.10625478  |\n",
            "|    std                  | 1.08        |\n",
            "|    value_loss           | 0.771       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 351          |\n",
            "|    iterations           | 67           |\n",
            "|    time_elapsed         | 389          |\n",
            "|    total_timesteps      | 137216       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036492709 |\n",
            "|    clip_fraction        | 0.00977      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.99        |\n",
            "|    explained_variance   | 0.415        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0603       |\n",
            "|    n_updates            | 660          |\n",
            "|    policy_gradient_loss | -0.000161    |\n",
            "|    reward               | 0.009879779  |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 0.161        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 351           |\n",
            "|    iterations           | 68            |\n",
            "|    time_elapsed         | 395           |\n",
            "|    total_timesteps      | 139264        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0006530489  |\n",
            "|    clip_fraction        | 0.0223        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.99         |\n",
            "|    explained_variance   | 0.297         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.611         |\n",
            "|    n_updates            | 670           |\n",
            "|    policy_gradient_loss | -0.00152      |\n",
            "|    reward               | -0.0035522443 |\n",
            "|    std                  | 1.08          |\n",
            "|    value_loss           | 0.838         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 351          |\n",
            "|    iterations           | 69           |\n",
            "|    time_elapsed         | 401          |\n",
            "|    total_timesteps      | 141312       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034966352 |\n",
            "|    clip_fraction        | 0.0188       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.99        |\n",
            "|    explained_variance   | 0.295        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.352        |\n",
            "|    n_updates            | 680          |\n",
            "|    policy_gradient_loss | -0.000672    |\n",
            "|    reward               | 0.42042208   |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 0.824        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 351          |\n",
            "|    iterations           | 70           |\n",
            "|    time_elapsed         | 407          |\n",
            "|    total_timesteps      | 143360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0073302872 |\n",
            "|    clip_fraction        | 0.0596       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.99        |\n",
            "|    explained_variance   | 0.521        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0684       |\n",
            "|    n_updates            | 690          |\n",
            "|    policy_gradient_loss | -0.00218     |\n",
            "|    reward               | -0.034033697 |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 0.185        |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 50\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -313582.25\n",
            "total_reward: -323582.25\n",
            "total_cost: 656.73\n",
            "total_trades: 2986\n",
            "Sharpe: 0.168\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 351           |\n",
            "|    iterations           | 71            |\n",
            "|    time_elapsed         | 413           |\n",
            "|    total_timesteps      | 145408        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00057403924 |\n",
            "|    clip_fraction        | 0.0165        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.99         |\n",
            "|    explained_variance   | 0.327         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.136         |\n",
            "|    n_updates            | 700           |\n",
            "|    policy_gradient_loss | -0.000458     |\n",
            "|    reward               | -0.012762669  |\n",
            "|    std                  | 1.08          |\n",
            "|    value_loss           | 0.797         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 351          |\n",
            "|    iterations           | 72           |\n",
            "|    time_elapsed         | 419          |\n",
            "|    total_timesteps      | 147456       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024010742 |\n",
            "|    clip_fraction        | 0.00288      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.99        |\n",
            "|    explained_variance   | 0.355        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.51         |\n",
            "|    n_updates            | 710          |\n",
            "|    policy_gradient_loss | 9.12e-05     |\n",
            "|    reward               | 0.267367     |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 0.849        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 351          |\n",
            "|    iterations           | 73           |\n",
            "|    time_elapsed         | 425          |\n",
            "|    total_timesteps      | 149504       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051765074 |\n",
            "|    clip_fraction        | 0.0219       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3           |\n",
            "|    explained_variance   | 0.351        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.153        |\n",
            "|    n_updates            | 720          |\n",
            "|    policy_gradient_loss | -0.00167     |\n",
            "|    reward               | -0.12622602  |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.543        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 351          |\n",
            "|    iterations           | 74           |\n",
            "|    time_elapsed         | 430          |\n",
            "|    total_timesteps      | 151552       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013863628 |\n",
            "|    clip_fraction        | 0.0179       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | 0.446        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0636       |\n",
            "|    n_updates            | 730          |\n",
            "|    policy_gradient_loss | 7.71e-05     |\n",
            "|    reward               | 0.05784367   |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.334        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 351          |\n",
            "|    iterations           | 75           |\n",
            "|    time_elapsed         | 437          |\n",
            "|    total_timesteps      | 153600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040259864 |\n",
            "|    clip_fraction        | 0.00728      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | -0.0276      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.07         |\n",
            "|    n_updates            | 740          |\n",
            "|    policy_gradient_loss | -0.000148    |\n",
            "|    reward               | 0.0005009268 |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 1.57         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 350          |\n",
            "|    iterations           | 76           |\n",
            "|    time_elapsed         | 443          |\n",
            "|    total_timesteps      | 155648       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033598747 |\n",
            "|    clip_fraction        | 0.024        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | -0.000825    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.59         |\n",
            "|    n_updates            | 750          |\n",
            "|    policy_gradient_loss | -0.00145     |\n",
            "|    reward               | 0.26467878   |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 1.23         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 351         |\n",
            "|    iterations           | 77          |\n",
            "|    time_elapsed         | 449         |\n",
            "|    total_timesteps      | 157696      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003279002 |\n",
            "|    clip_fraction        | 0.0236      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.03       |\n",
            "|    explained_variance   | 1.19e-07    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0259      |\n",
            "|    n_updates            | 760         |\n",
            "|    policy_gradient_loss | -0.000889   |\n",
            "|    reward               | 0.05607619  |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 0.135       |\n",
            "-----------------------------------------\n",
            "day: 2896, episode: 55\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -371526.82\n",
            "total_reward: -381526.82\n",
            "total_cost: 624.99\n",
            "total_trades: 3192\n",
            "Sharpe: -0.101\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 350          |\n",
            "|    iterations           | 78           |\n",
            "|    time_elapsed         | 455          |\n",
            "|    total_timesteps      | 159744       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036353334 |\n",
            "|    clip_fraction        | 0.0241       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | -0.000753    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.775        |\n",
            "|    n_updates            | 770          |\n",
            "|    policy_gradient_loss | -0.00225     |\n",
            "|    reward               | -0.02192826  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.929        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 350          |\n",
            "|    iterations           | 79           |\n",
            "|    time_elapsed         | 461          |\n",
            "|    total_timesteps      | 161792       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039722715 |\n",
            "|    clip_fraction        | 0.0106       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | -0.000538    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.523        |\n",
            "|    n_updates            | 780          |\n",
            "|    policy_gradient_loss | -0.000575    |\n",
            "|    reward               | 0.03865823   |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 1.08         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 350          |\n",
            "|    iterations           | 80           |\n",
            "|    time_elapsed         | 468          |\n",
            "|    total_timesteps      | 163840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055741463 |\n",
            "|    clip_fraction        | 0.0437       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.166        |\n",
            "|    n_updates            | 790          |\n",
            "|    policy_gradient_loss | -0.00252     |\n",
            "|    reward               | -0.06247316  |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.293        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 350           |\n",
            "|    iterations           | 81            |\n",
            "|    time_elapsed         | 473           |\n",
            "|    total_timesteps      | 165888        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0056231176  |\n",
            "|    clip_fraction        | 0.0342        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.02         |\n",
            "|    explained_variance   | -0.000541     |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.399         |\n",
            "|    n_updates            | 800           |\n",
            "|    policy_gradient_loss | -0.00184      |\n",
            "|    reward               | -0.0032279033 |\n",
            "|    std                  | 1.1           |\n",
            "|    value_loss           | 0.8           |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 350          |\n",
            "|    iterations           | 82           |\n",
            "|    time_elapsed         | 479          |\n",
            "|    total_timesteps      | 167936       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0008475354 |\n",
            "|    clip_fraction        | 0.00142      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | -0.000332    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.754        |\n",
            "|    n_updates            | 810          |\n",
            "|    policy_gradient_loss | 0.0003       |\n",
            "|    reward               | -0.12637557  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 1.31         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 350          |\n",
            "|    iterations           | 83           |\n",
            "|    time_elapsed         | 485          |\n",
            "|    total_timesteps      | 169984       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029526143 |\n",
            "|    clip_fraction        | 0.017        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.873        |\n",
            "|    n_updates            | 820          |\n",
            "|    policy_gradient_loss | -0.00119     |\n",
            "|    reward               | 0.44492164   |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 2            |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 350          |\n",
            "|    iterations           | 84           |\n",
            "|    time_elapsed         | 491          |\n",
            "|    total_timesteps      | 172032       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.003234222  |\n",
            "|    clip_fraction        | 0.0108       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | -0.000981    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.425        |\n",
            "|    n_updates            | 830          |\n",
            "|    policy_gradient_loss | -0.00051     |\n",
            "|    reward               | -0.006093286 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.305        |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 60\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -548207.73\n",
            "total_reward: -558207.73\n",
            "total_cost: 791.46\n",
            "total_trades: 3516\n",
            "Sharpe: 0.113\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 350          |\n",
            "|    iterations           | 85           |\n",
            "|    time_elapsed         | 496          |\n",
            "|    total_timesteps      | 174080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040716045 |\n",
            "|    clip_fraction        | 0.0161       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | -0.00018     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.01         |\n",
            "|    n_updates            | 840          |\n",
            "|    policy_gradient_loss | -0.000907    |\n",
            "|    reward               | 0.009146505  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 1.72         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 350          |\n",
            "|    iterations           | 86           |\n",
            "|    time_elapsed         | 502          |\n",
            "|    total_timesteps      | 176128       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012963782 |\n",
            "|    clip_fraction        | 0.00933      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | -0.000147    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.07         |\n",
            "|    n_updates            | 850          |\n",
            "|    policy_gradient_loss | -0.000275    |\n",
            "|    reward               | -1.3164202   |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 2.3          |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 350           |\n",
            "|    iterations           | 87            |\n",
            "|    time_elapsed         | 507           |\n",
            "|    total_timesteps      | 178176        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.005225658   |\n",
            "|    clip_fraction        | 0.0194        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.05         |\n",
            "|    explained_variance   | 5.96e-08      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.208         |\n",
            "|    n_updates            | 860           |\n",
            "|    policy_gradient_loss | -0.00159      |\n",
            "|    reward               | -0.0064102043 |\n",
            "|    std                  | 1.12          |\n",
            "|    value_loss           | 0.46          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 350          |\n",
            "|    iterations           | 88           |\n",
            "|    time_elapsed         | 513          |\n",
            "|    total_timesteps      | 180224       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038358625 |\n",
            "|    clip_fraction        | 0.0246       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.07        |\n",
            "|    explained_variance   | -0.00012     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.882        |\n",
            "|    n_updates            | 870          |\n",
            "|    policy_gradient_loss | -0.000735    |\n",
            "|    reward               | 0.015179891  |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 1.66         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 351         |\n",
            "|    iterations           | 89          |\n",
            "|    time_elapsed         | 519         |\n",
            "|    total_timesteps      | 182272      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001759868 |\n",
            "|    clip_fraction        | 0.00278     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.07       |\n",
            "|    explained_variance   | -0.000104   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.07        |\n",
            "|    n_updates            | 880         |\n",
            "|    policy_gradient_loss | -0.000433   |\n",
            "|    reward               | 0.73473173  |\n",
            "|    std                  | 1.12        |\n",
            "|    value_loss           | 2.11        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 351          |\n",
            "|    iterations           | 90           |\n",
            "|    time_elapsed         | 524          |\n",
            "|    total_timesteps      | 184320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037522442 |\n",
            "|    clip_fraction        | 0.0258       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.23         |\n",
            "|    n_updates            | 890          |\n",
            "|    policy_gradient_loss | -0.00124     |\n",
            "|    reward               | -0.048379354 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 1.7          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 351         |\n",
            "|    iterations           | 91          |\n",
            "|    time_elapsed         | 530         |\n",
            "|    total_timesteps      | 186368      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002241122 |\n",
            "|    clip_fraction        | 0.0321      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.05       |\n",
            "|    explained_variance   | -0.000106   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.594       |\n",
            "|    n_updates            | 900         |\n",
            "|    policy_gradient_loss | -0.00102    |\n",
            "|    reward               | 0.07570126  |\n",
            "|    std                  | 1.12        |\n",
            "|    value_loss           | 1.03        |\n",
            "-----------------------------------------\n",
            "day: 2896, episode: 65\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -554541.02\n",
            "total_reward: -564541.02\n",
            "total_cost: 746.85\n",
            "total_trades: 3644\n",
            "Sharpe: 0.433\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 351          |\n",
            "|    iterations           | 92           |\n",
            "|    time_elapsed         | 536          |\n",
            "|    total_timesteps      | 188416       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051934244 |\n",
            "|    clip_fraction        | 0.0216       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | -4.47e-05    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.959        |\n",
            "|    n_updates            | 910          |\n",
            "|    policy_gradient_loss | -0.00127     |\n",
            "|    reward               | 0.0018212314 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 2.68         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 350          |\n",
            "|    iterations           | 93           |\n",
            "|    time_elapsed         | 542          |\n",
            "|    total_timesteps      | 190464       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022239068 |\n",
            "|    clip_fraction        | 0.0109       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | -4.18e-05    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.3          |\n",
            "|    n_updates            | 920          |\n",
            "|    policy_gradient_loss | -0.000475    |\n",
            "|    reward               | 0.94371223   |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 2.35         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 351          |\n",
            "|    iterations           | 94           |\n",
            "|    time_elapsed         | 548          |\n",
            "|    total_timesteps      | 192512       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041327514 |\n",
            "|    clip_fraction        | 0.00806      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.07        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0498       |\n",
            "|    n_updates            | 930          |\n",
            "|    policy_gradient_loss | -0.000396    |\n",
            "|    reward               | 0.0712954    |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.293        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 351          |\n",
            "|    iterations           | 95           |\n",
            "|    time_elapsed         | 554          |\n",
            "|    total_timesteps      | 194560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005704766  |\n",
            "|    clip_fraction        | 0.0486       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.07        |\n",
            "|    explained_variance   | -3.31e-05    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.03         |\n",
            "|    n_updates            | 940          |\n",
            "|    policy_gradient_loss | -0.00365     |\n",
            "|    reward               | 0.0008561195 |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 1.99         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 350         |\n",
            "|    iterations           | 96          |\n",
            "|    time_elapsed         | 560         |\n",
            "|    total_timesteps      | 196608      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004292331 |\n",
            "|    clip_fraction        | 0.0323      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.07       |\n",
            "|    explained_variance   | -1.31e-05   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.5         |\n",
            "|    n_updates            | 950         |\n",
            "|    policy_gradient_loss | -0.00214    |\n",
            "|    reward               | -0.21055591 |\n",
            "|    std                  | 1.13        |\n",
            "|    value_loss           | 3.16        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 350         |\n",
            "|    iterations           | 97          |\n",
            "|    time_elapsed         | 567         |\n",
            "|    total_timesteps      | 198656      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004821971 |\n",
            "|    clip_fraction        | 0.039       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.07       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.651       |\n",
            "|    n_updates            | 960         |\n",
            "|    policy_gradient_loss | -0.00274    |\n",
            "|    reward               | -0.27369106 |\n",
            "|    std                  | 1.13        |\n",
            "|    value_loss           | 1.9         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 348          |\n",
            "|    iterations           | 98           |\n",
            "|    time_elapsed         | 575          |\n",
            "|    total_timesteps      | 200704       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035820934 |\n",
            "|    clip_fraction        | 0.0125       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.07        |\n",
            "|    explained_variance   | -1.03e-05    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.608        |\n",
            "|    n_updates            | 970          |\n",
            "|    policy_gradient_loss | -0.000751    |\n",
            "|    reward               | -0.014659212 |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 1.73         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 348          |\n",
            "|    iterations           | 99           |\n",
            "|    time_elapsed         | 581          |\n",
            "|    total_timesteps      | 202752       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0082192235 |\n",
            "|    clip_fraction        | 0.0868       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.07        |\n",
            "|    explained_variance   | -2.5e-06     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.05         |\n",
            "|    n_updates            | 980          |\n",
            "|    policy_gradient_loss | -0.00467     |\n",
            "|    reward               | 0.3470344    |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 2.18         |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 70\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -584919.24\n",
            "total_reward: -594919.24\n",
            "total_cost: 822.93\n",
            "total_trades: 3580\n",
            "Sharpe: 0.016\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 347          |\n",
            "|    iterations           | 100          |\n",
            "|    time_elapsed         | 589          |\n",
            "|    total_timesteps      | 204800       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052748276 |\n",
            "|    clip_fraction        | 0.0606       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.22         |\n",
            "|    n_updates            | 990          |\n",
            "|    policy_gradient_loss | -0.00369     |\n",
            "|    reward               | 0.33283642   |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 2.46         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 346         |\n",
            "|    iterations           | 101         |\n",
            "|    time_elapsed         | 596         |\n",
            "|    total_timesteps      | 206848      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005775147 |\n",
            "|    clip_fraction        | 0.0229      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.07       |\n",
            "|    explained_variance   | -0.00318    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.077       |\n",
            "|    n_updates            | 1000        |\n",
            "|    policy_gradient_loss | -0.0005     |\n",
            "|    reward               | -0.04779536 |\n",
            "|    std                  | 1.13        |\n",
            "|    value_loss           | 0.319       |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 346           |\n",
            "|    iterations           | 102           |\n",
            "|    time_elapsed         | 602           |\n",
            "|    total_timesteps      | 208896        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0044714413  |\n",
            "|    clip_fraction        | 0.0171        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.06         |\n",
            "|    explained_variance   | 1.05e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 1.58          |\n",
            "|    n_updates            | 1010          |\n",
            "|    policy_gradient_loss | -0.00125      |\n",
            "|    reward               | -0.0010495727 |\n",
            "|    std                  | 1.12          |\n",
            "|    value_loss           | 3.01          |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 346         |\n",
            "|    iterations           | 103         |\n",
            "|    time_elapsed         | 608         |\n",
            "|    total_timesteps      | 210944      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005208786 |\n",
            "|    clip_fraction        | 0.0304      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.05       |\n",
            "|    explained_variance   | 1.73e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.55        |\n",
            "|    n_updates            | 1020        |\n",
            "|    policy_gradient_loss | -0.0022     |\n",
            "|    reward               | -0.5501114  |\n",
            "|    std                  | 1.12        |\n",
            "|    value_loss           | 2.48        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 346         |\n",
            "|    iterations           | 104         |\n",
            "|    time_elapsed         | 614         |\n",
            "|    total_timesteps      | 212992      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004833468 |\n",
            "|    clip_fraction        | 0.0589      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.04       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.225       |\n",
            "|    n_updates            | 1030        |\n",
            "|    policy_gradient_loss | -0.00317    |\n",
            "|    reward               | 0.12151578  |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 0.449       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 347         |\n",
            "|    iterations           | 105         |\n",
            "|    time_elapsed         | 619         |\n",
            "|    total_timesteps      | 215040      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004428885 |\n",
            "|    clip_fraction        | 0.0373      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.04       |\n",
            "|    explained_variance   | 2.24e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.75        |\n",
            "|    n_updates            | 1040        |\n",
            "|    policy_gradient_loss | -0.00181    |\n",
            "|    reward               | 0.026222948 |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 1.6         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 347         |\n",
            "|    iterations           | 106         |\n",
            "|    time_elapsed         | 624         |\n",
            "|    total_timesteps      | 217088      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002935498 |\n",
            "|    clip_fraction        | 0.0129      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.05       |\n",
            "|    explained_variance   | 2.09e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.44        |\n",
            "|    n_updates            | 1050        |\n",
            "|    policy_gradient_loss | -0.00125    |\n",
            "|    reward               | 0.24461761  |\n",
            "|    std                  | 1.12        |\n",
            "|    value_loss           | 2.5         |\n",
            "-----------------------------------------\n",
            "day: 2896, episode: 75\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -617429.42\n",
            "total_reward: -627429.42\n",
            "total_cost: 728.26\n",
            "total_trades: 3842\n",
            "Sharpe: 0.391\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 347          |\n",
            "|    iterations           | 107          |\n",
            "|    time_elapsed         | 630          |\n",
            "|    total_timesteps      | 219136       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033463542 |\n",
            "|    clip_fraction        | 0.0351       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.965        |\n",
            "|    n_updates            | 1060         |\n",
            "|    policy_gradient_loss | -0.00237     |\n",
            "|    reward               | -0.48866007  |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 2.08         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 348          |\n",
            "|    iterations           | 108          |\n",
            "|    time_elapsed         | 635          |\n",
            "|    total_timesteps      | 221184       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050391564 |\n",
            "|    clip_fraction        | 0.044        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 2.52e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.309        |\n",
            "|    n_updates            | 1070         |\n",
            "|    policy_gradient_loss | -0.00253     |\n",
            "|    reward               | -0.10476281  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.556        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 348           |\n",
            "|    iterations           | 109           |\n",
            "|    time_elapsed         | 640           |\n",
            "|    total_timesteps      | 223232        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0039335527  |\n",
            "|    clip_fraction        | 0.0143        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.04         |\n",
            "|    explained_variance   | 2.06e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 1.07          |\n",
            "|    n_updates            | 1080          |\n",
            "|    policy_gradient_loss | -0.000727     |\n",
            "|    reward               | -0.0014396143 |\n",
            "|    std                  | 1.11          |\n",
            "|    value_loss           | 2.46          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 348          |\n",
            "|    iterations           | 110          |\n",
            "|    time_elapsed         | 646          |\n",
            "|    total_timesteps      | 225280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006952779  |\n",
            "|    clip_fraction        | 0.0403       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 2.77e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.58         |\n",
            "|    n_updates            | 1090         |\n",
            "|    policy_gradient_loss | -0.00367     |\n",
            "|    reward               | -0.030158186 |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 2.54         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 348         |\n",
            "|    iterations           | 111         |\n",
            "|    time_elapsed         | 652         |\n",
            "|    total_timesteps      | 227328      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003541559 |\n",
            "|    clip_fraction        | 0.0139      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.03       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.17        |\n",
            "|    n_updates            | 1100        |\n",
            "|    policy_gradient_loss | -0.000445   |\n",
            "|    reward               | -0.07805516 |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 0.322       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 348          |\n",
            "|    iterations           | 112          |\n",
            "|    time_elapsed         | 657          |\n",
            "|    total_timesteps      | 229376       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052423747 |\n",
            "|    clip_fraction        | 0.0358       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 2.78e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.603        |\n",
            "|    n_updates            | 1110         |\n",
            "|    policy_gradient_loss | -0.00228     |\n",
            "|    reward               | 0.02924949   |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 2.33         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 349          |\n",
            "|    iterations           | 113          |\n",
            "|    time_elapsed         | 663          |\n",
            "|    total_timesteps      | 231424       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0066115204 |\n",
            "|    clip_fraction        | 0.07         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 3.25e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.06         |\n",
            "|    n_updates            | 1120         |\n",
            "|    policy_gradient_loss | -0.00471     |\n",
            "|    reward               | 0.035091493  |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 2.13         |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 80\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -529800.61\n",
            "total_reward: -539800.61\n",
            "total_cost: 775.12\n",
            "total_trades: 3730\n",
            "Sharpe: 0.297\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 349          |\n",
            "|    iterations           | 114          |\n",
            "|    time_elapsed         | 668          |\n",
            "|    total_timesteps      | 233472       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024545789 |\n",
            "|    clip_fraction        | 0.00562      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.532        |\n",
            "|    n_updates            | 1130         |\n",
            "|    policy_gradient_loss | 0.000126     |\n",
            "|    reward               | -0.03684037  |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 1.23         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 348          |\n",
            "|    iterations           | 115          |\n",
            "|    time_elapsed         | 674          |\n",
            "|    total_timesteps      | 235520       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005765718  |\n",
            "|    clip_fraction        | 0.0377       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 4.01e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.337        |\n",
            "|    n_updates            | 1140         |\n",
            "|    policy_gradient_loss | -0.00271     |\n",
            "|    reward               | 0.0073780734 |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 0.957        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 349           |\n",
            "|    iterations           | 116           |\n",
            "|    time_elapsed         | 680           |\n",
            "|    total_timesteps      | 237568        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.003981086   |\n",
            "|    clip_fraction        | 0.0576        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.03         |\n",
            "|    explained_variance   | 2.53e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.728         |\n",
            "|    n_updates            | 1150          |\n",
            "|    policy_gradient_loss | -0.00346      |\n",
            "|    reward               | 0.00031811692 |\n",
            "|    std                  | 1.1           |\n",
            "|    value_loss           | 2.12          |\n",
            "-------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 349        |\n",
            "|    iterations           | 117        |\n",
            "|    time_elapsed         | 685        |\n",
            "|    total_timesteps      | 239616     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00393181 |\n",
            "|    clip_fraction        | 0.0178     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.04      |\n",
            "|    explained_variance   | 2.53e-05   |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 0.898      |\n",
            "|    n_updates            | 1160       |\n",
            "|    policy_gradient_loss | -0.000933  |\n",
            "|    reward               | -0.2997208 |\n",
            "|    std                  | 1.11       |\n",
            "|    value_loss           | 2.02       |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 349          |\n",
            "|    iterations           | 118          |\n",
            "|    time_elapsed         | 691          |\n",
            "|    total_timesteps      | 241664       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036656954 |\n",
            "|    clip_fraction        | 0.0237       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0736       |\n",
            "|    n_updates            | 1170         |\n",
            "|    policy_gradient_loss | -0.00174     |\n",
            "|    reward               | 0.11531094   |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.219        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 349          |\n",
            "|    iterations           | 119          |\n",
            "|    time_elapsed         | 696          |\n",
            "|    total_timesteps      | 243712       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038861148 |\n",
            "|    clip_fraction        | 0.0144       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 2.85e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.25         |\n",
            "|    n_updates            | 1180         |\n",
            "|    policy_gradient_loss | -0.00122     |\n",
            "|    reward               | 0.02007224   |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 2.48         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 349         |\n",
            "|    iterations           | 120         |\n",
            "|    time_elapsed         | 702         |\n",
            "|    total_timesteps      | 245760      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003777967 |\n",
            "|    clip_fraction        | 0.0214      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.02       |\n",
            "|    explained_variance   | 3.03e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.33        |\n",
            "|    n_updates            | 1190        |\n",
            "|    policy_gradient_loss | -0.00089    |\n",
            "|    reward               | -0.25938877 |\n",
            "|    std                  | 1.1         |\n",
            "|    value_loss           | 3.18        |\n",
            "-----------------------------------------\n",
            "day: 2896, episode: 85\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -561188.99\n",
            "total_reward: -571188.99\n",
            "total_cost: 834.54\n",
            "total_trades: 3974\n",
            "Sharpe: 0.444\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 349          |\n",
            "|    iterations           | 121          |\n",
            "|    time_elapsed         | 708          |\n",
            "|    total_timesteps      | 247808       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038618534 |\n",
            "|    clip_fraction        | 0.0168       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.28         |\n",
            "|    n_updates            | 1200         |\n",
            "|    policy_gradient_loss | -0.00116     |\n",
            "|    reward               | -0.02651885  |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.606        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 350          |\n",
            "|    iterations           | 122          |\n",
            "|    time_elapsed         | 712          |\n",
            "|    total_timesteps      | 249856       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044070273 |\n",
            "|    clip_fraction        | 0.0313       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | 3.45e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.816        |\n",
            "|    n_updates            | 1210         |\n",
            "|    policy_gradient_loss | -0.00165     |\n",
            "|    reward               | -0.020470107 |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 1.88         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 350          |\n",
            "|    iterations           | 123          |\n",
            "|    time_elapsed         | 718          |\n",
            "|    total_timesteps      | 251904       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049354346 |\n",
            "|    clip_fraction        | 0.0273       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | 2.6e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.46         |\n",
            "|    n_updates            | 1220         |\n",
            "|    policy_gradient_loss | -0.00135     |\n",
            "|    reward               | 2.149441     |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 2.91         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 350          |\n",
            "|    iterations           | 124          |\n",
            "|    time_elapsed         | 723          |\n",
            "|    total_timesteps      | 253952       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054361615 |\n",
            "|    clip_fraction        | 0.0261       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 3.04         |\n",
            "|    n_updates            | 1230         |\n",
            "|    policy_gradient_loss | -0.001       |\n",
            "|    reward               | -1.3613868   |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 3.35         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 350          |\n",
            "|    iterations           | 125          |\n",
            "|    time_elapsed         | 729          |\n",
            "|    total_timesteps      | 256000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048372513 |\n",
            "|    clip_fraction        | 0.0223       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3           |\n",
            "|    explained_variance   | 3.24e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.533        |\n",
            "|    n_updates            | 1240         |\n",
            "|    policy_gradient_loss | -0.0014      |\n",
            "|    reward               | 0.0410629    |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.77         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 350          |\n",
            "|    iterations           | 126          |\n",
            "|    time_elapsed         | 735          |\n",
            "|    total_timesteps      | 258048       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054159956 |\n",
            "|    clip_fraction        | 0.0279       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.99        |\n",
            "|    explained_variance   | 2.1e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.14         |\n",
            "|    n_updates            | 1250         |\n",
            "|    policy_gradient_loss | -0.00193     |\n",
            "|    reward               | -0.025115922 |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 2.72         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 350          |\n",
            "|    iterations           | 127          |\n",
            "|    time_elapsed         | 741          |\n",
            "|    total_timesteps      | 260096       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031710383 |\n",
            "|    clip_fraction        | 0.026        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.98        |\n",
            "|    explained_variance   | 3.2e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.47         |\n",
            "|    n_updates            | 1260         |\n",
            "|    policy_gradient_loss | -0.00147     |\n",
            "|    reward               | -0.25299856  |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 3.7          |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 90\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -645012.09\n",
            "total_reward: -655012.09\n",
            "total_cost: 806.41\n",
            "total_trades: 4116\n",
            "Sharpe: -0.420\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 350          |\n",
            "|    iterations           | 128          |\n",
            "|    time_elapsed         | 747          |\n",
            "|    total_timesteps      | 262144       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029680817 |\n",
            "|    clip_fraction        | 0.0147       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.99        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.22         |\n",
            "|    n_updates            | 1270         |\n",
            "|    policy_gradient_loss | -0.000701    |\n",
            "|    reward               | 0.026863456  |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 0.569        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 350          |\n",
            "|    iterations           | 129          |\n",
            "|    time_elapsed         | 753          |\n",
            "|    total_timesteps      | 264192       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019049686 |\n",
            "|    clip_fraction        | 0.00161      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.99        |\n",
            "|    explained_variance   | 2.79e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.05         |\n",
            "|    n_updates            | 1280         |\n",
            "|    policy_gradient_loss | -2.92e-06    |\n",
            "|    reward               | -0.017809574 |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 2.69         |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 350        |\n",
            "|    iterations           | 130        |\n",
            "|    time_elapsed         | 759        |\n",
            "|    total_timesteps      | 266240     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00624437 |\n",
            "|    clip_fraction        | 0.0521     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.99      |\n",
            "|    explained_variance   | 2.86e-05   |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 1.62       |\n",
            "|    n_updates            | 1290       |\n",
            "|    policy_gradient_loss | -0.00245   |\n",
            "|    reward               | 0.2838428  |\n",
            "|    std                  | 1.08       |\n",
            "|    value_loss           | 3.43       |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 349          |\n",
            "|    iterations           | 131          |\n",
            "|    time_elapsed         | 766          |\n",
            "|    total_timesteps      | 268288       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005240118  |\n",
            "|    clip_fraction        | 0.0665       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.99        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.561        |\n",
            "|    n_updates            | 1300         |\n",
            "|    policy_gradient_loss | -0.00533     |\n",
            "|    reward               | -0.016198533 |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 2.08         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 349          |\n",
            "|    iterations           | 132          |\n",
            "|    time_elapsed         | 774          |\n",
            "|    total_timesteps      | 270336       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069083944 |\n",
            "|    clip_fraction        | 0.0702       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3           |\n",
            "|    explained_variance   | 4.94e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1            |\n",
            "|    n_updates            | 1310         |\n",
            "|    policy_gradient_loss | -0.00489     |\n",
            "|    reward               | 0.036610138  |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 1.74         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 348         |\n",
            "|    iterations           | 133         |\n",
            "|    time_elapsed         | 780         |\n",
            "|    total_timesteps      | 272384      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001383924 |\n",
            "|    clip_fraction        | 0.000488    |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.98       |\n",
            "|    explained_variance   | 2.41e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.85        |\n",
            "|    n_updates            | 1320        |\n",
            "|    policy_gradient_loss | -0.000288   |\n",
            "|    reward               | -0.02211644 |\n",
            "|    std                  | 1.07        |\n",
            "|    value_loss           | 3.26        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 348          |\n",
            "|    iterations           | 134          |\n",
            "|    time_elapsed         | 787          |\n",
            "|    total_timesteps      | 274432       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049951617 |\n",
            "|    clip_fraction        | 0.0227       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.97        |\n",
            "|    explained_variance   | 3.95e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.89         |\n",
            "|    n_updates            | 1330         |\n",
            "|    policy_gradient_loss | -0.000709    |\n",
            "|    reward               | 0.23383789   |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 3.28         |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 95\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -634153.10\n",
            "total_reward: -644153.10\n",
            "total_cost: 860.37\n",
            "total_trades: 4218\n",
            "Sharpe: -0.029\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 347          |\n",
            "|    iterations           | 135          |\n",
            "|    time_elapsed         | 794          |\n",
            "|    total_timesteps      | 276480       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044387365 |\n",
            "|    clip_fraction        | 0.0278       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.98        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.129        |\n",
            "|    n_updates            | 1340         |\n",
            "|    policy_gradient_loss | -0.00138     |\n",
            "|    reward               | 0.09921616   |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 0.368        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 347          |\n",
            "|    iterations           | 136          |\n",
            "|    time_elapsed         | 801          |\n",
            "|    total_timesteps      | 278528       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047063557 |\n",
            "|    clip_fraction        | 0.0285       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.99        |\n",
            "|    explained_variance   | 3.8e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.51         |\n",
            "|    n_updates            | 1350         |\n",
            "|    policy_gradient_loss | -0.0019      |\n",
            "|    reward               | 0.0036284481 |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 2.86         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 347          |\n",
            "|    iterations           | 137          |\n",
            "|    time_elapsed         | 807          |\n",
            "|    total_timesteps      | 280576       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060619847 |\n",
            "|    clip_fraction        | 0.0432       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.99        |\n",
            "|    explained_variance   | -6.79e-05    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.94         |\n",
            "|    n_updates            | 1360         |\n",
            "|    policy_gradient_loss | -0.00358     |\n",
            "|    reward               | 0.7494476    |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 3.57         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 347          |\n",
            "|    iterations           | 138          |\n",
            "|    time_elapsed         | 813          |\n",
            "|    total_timesteps      | 282624       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0070956433 |\n",
            "|    clip_fraction        | 0.0761       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.98        |\n",
            "|    explained_variance   | -2.38e-07    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.27         |\n",
            "|    n_updates            | 1370         |\n",
            "|    policy_gradient_loss | -0.00501     |\n",
            "|    reward               | 0.036450393  |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 1.06         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 347          |\n",
            "|    iterations           | 139          |\n",
            "|    time_elapsed         | 819          |\n",
            "|    total_timesteps      | 284672       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029541836 |\n",
            "|    clip_fraction        | 0.0123       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.98        |\n",
            "|    explained_variance   | 2.68e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.5          |\n",
            "|    n_updates            | 1380         |\n",
            "|    policy_gradient_loss | -0.000235    |\n",
            "|    reward               | 0.04381404   |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 2.79         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 347         |\n",
            "|    iterations           | 140         |\n",
            "|    time_elapsed         | 825         |\n",
            "|    total_timesteps      | 286720      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003063074 |\n",
            "|    clip_fraction        | 0.00254     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.99       |\n",
            "|    explained_variance   | 3.21e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.42        |\n",
            "|    n_updates            | 1390        |\n",
            "|    policy_gradient_loss | 0.000115    |\n",
            "|    reward               | 1.9985945   |\n",
            "|    std                  | 1.08        |\n",
            "|    value_loss           | 4.25        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 347          |\n",
            "|    iterations           | 141          |\n",
            "|    time_elapsed         | 830          |\n",
            "|    total_timesteps      | 288768       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020486976 |\n",
            "|    clip_fraction        | 0.015        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.97        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.47         |\n",
            "|    n_updates            | 1400         |\n",
            "|    policy_gradient_loss | -0.00216     |\n",
            "|    reward               | 0.4427267    |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 3.1          |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 100\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -597535.80\n",
            "total_reward: -607535.80\n",
            "total_cost: 806.46\n",
            "total_trades: 4068\n",
            "Sharpe: -0.165\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 347          |\n",
            "|    iterations           | 142          |\n",
            "|    time_elapsed         | 837          |\n",
            "|    total_timesteps      | 290816       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005157886  |\n",
            "|    clip_fraction        | 0.0505       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.97        |\n",
            "|    explained_variance   | 0.000107     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.112        |\n",
            "|    n_updates            | 1410         |\n",
            "|    policy_gradient_loss | -0.00222     |\n",
            "|    reward               | -0.016031558 |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.312        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 347           |\n",
            "|    iterations           | 143           |\n",
            "|    time_elapsed         | 843           |\n",
            "|    total_timesteps      | 292864        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0042868173  |\n",
            "|    clip_fraction        | 0.0125        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -2.97         |\n",
            "|    explained_variance   | 3.24e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 1.52          |\n",
            "|    n_updates            | 1420          |\n",
            "|    policy_gradient_loss | -0.00138      |\n",
            "|    reward               | -0.0071176337 |\n",
            "|    std                  | 1.07          |\n",
            "|    value_loss           | 2.69          |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 347         |\n",
            "|    iterations           | 144         |\n",
            "|    time_elapsed         | 848         |\n",
            "|    total_timesteps      | 294912      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004766359 |\n",
            "|    clip_fraction        | 0.0281      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.97       |\n",
            "|    explained_variance   | 4.18e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.828       |\n",
            "|    n_updates            | 1430        |\n",
            "|    policy_gradient_loss | -0.00188    |\n",
            "|    reward               | -0.21950099 |\n",
            "|    std                  | 1.07        |\n",
            "|    value_loss           | 2.78        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 347          |\n",
            "|    iterations           | 145          |\n",
            "|    time_elapsed         | 854          |\n",
            "|    total_timesteps      | 296960       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0064236843 |\n",
            "|    clip_fraction        | 0.0332       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.97        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.134        |\n",
            "|    n_updates            | 1440         |\n",
            "|    policy_gradient_loss | -0.00124     |\n",
            "|    reward               | -0.25055122  |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.541        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 347          |\n",
            "|    iterations           | 146          |\n",
            "|    time_elapsed         | 860          |\n",
            "|    total_timesteps      | 299008       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061114095 |\n",
            "|    clip_fraction        | 0.0506       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.98        |\n",
            "|    explained_variance   | 3.21e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.992        |\n",
            "|    n_updates            | 1450         |\n",
            "|    policy_gradient_loss | -0.00369     |\n",
            "|    reward               | 0.0060375133 |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 1.82         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 347         |\n",
            "|    iterations           | 147         |\n",
            "|    time_elapsed         | 866         |\n",
            "|    total_timesteps      | 301056      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004592506 |\n",
            "|    clip_fraction        | 0.0385      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.99       |\n",
            "|    explained_variance   | 3.95e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.49        |\n",
            "|    n_updates            | 1460        |\n",
            "|    policy_gradient_loss | -0.00214    |\n",
            "|    reward               | 0.69573236  |\n",
            "|    std                  | 1.08        |\n",
            "|    value_loss           | 2.33        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 347          |\n",
            "|    iterations           | 148          |\n",
            "|    time_elapsed         | 872          |\n",
            "|    total_timesteps      | 303104       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054822867 |\n",
            "|    clip_fraction        | 0.047        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.99        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.652        |\n",
            "|    n_updates            | 1470         |\n",
            "|    policy_gradient_loss | -0.0028      |\n",
            "|    reward               | -0.40043658  |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 1.28         |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 105\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -508350.74\n",
            "total_reward: -518350.74\n",
            "total_cost: 708.69\n",
            "total_trades: 3642\n",
            "Sharpe: 0.286\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 347          |\n",
            "|    iterations           | 149          |\n",
            "|    time_elapsed         | 878          |\n",
            "|    total_timesteps      | 305152       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026538642 |\n",
            "|    clip_fraction        | 0.00928      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.98        |\n",
            "|    explained_variance   | 5.82e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.662        |\n",
            "|    n_updates            | 1480         |\n",
            "|    policy_gradient_loss | -0.000919    |\n",
            "|    reward               | -0.0394264   |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.864        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 347          |\n",
            "|    iterations           | 150          |\n",
            "|    time_elapsed         | 884          |\n",
            "|    total_timesteps      | 307200       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032370617 |\n",
            "|    clip_fraction        | 0.0145       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.96        |\n",
            "|    explained_variance   | 3.97e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.918        |\n",
            "|    n_updates            | 1490         |\n",
            "|    policy_gradient_loss | -0.000656    |\n",
            "|    reward               | -0.007858507 |\n",
            "|    std                  | 1.06         |\n",
            "|    value_loss           | 2            |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 347         |\n",
            "|    iterations           | 151         |\n",
            "|    time_elapsed         | 891         |\n",
            "|    total_timesteps      | 309248      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003735179 |\n",
            "|    clip_fraction        | 0.0165      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.95       |\n",
            "|    explained_variance   | 5.61e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.39        |\n",
            "|    n_updates            | 1500        |\n",
            "|    policy_gradient_loss | -0.00135    |\n",
            "|    reward               | -0.8376826  |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 2.77        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 347          |\n",
            "|    iterations           | 152          |\n",
            "|    time_elapsed         | 896          |\n",
            "|    total_timesteps      | 311296       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040578134 |\n",
            "|    clip_fraction        | 0.0085       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.93        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0623       |\n",
            "|    n_updates            | 1510         |\n",
            "|    policy_gradient_loss | -0.00025     |\n",
            "|    reward               | 0.04514048   |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.284        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 347          |\n",
            "|    iterations           | 153          |\n",
            "|    time_elapsed         | 902          |\n",
            "|    total_timesteps      | 313344       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069102496 |\n",
            "|    clip_fraction        | 0.0551       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.93        |\n",
            "|    explained_variance   | 4.94e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.803        |\n",
            "|    n_updates            | 1520         |\n",
            "|    policy_gradient_loss | -0.00248     |\n",
            "|    reward               | -0.009242218 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 1.99         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 347          |\n",
            "|    iterations           | 154          |\n",
            "|    time_elapsed         | 908          |\n",
            "|    total_timesteps      | 315392       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034933663 |\n",
            "|    clip_fraction        | 0.0281       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.94        |\n",
            "|    explained_variance   | 4.68e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.06         |\n",
            "|    n_updates            | 1530         |\n",
            "|    policy_gradient_loss | -0.00154     |\n",
            "|    reward               | 0.44756898   |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 2.62         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 347         |\n",
            "|    iterations           | 155         |\n",
            "|    time_elapsed         | 914         |\n",
            "|    total_timesteps      | 317440      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003782285 |\n",
            "|    clip_fraction        | 0.0193      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.93       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.49        |\n",
            "|    n_updates            | 1540        |\n",
            "|    policy_gradient_loss | -0.000854   |\n",
            "|    reward               | 0.03515828  |\n",
            "|    std                  | 1.05        |\n",
            "|    value_loss           | 1.22        |\n",
            "-----------------------------------------\n",
            "day: 2896, episode: 110\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -676350.26\n",
            "total_reward: -686350.26\n",
            "total_cost: 850.93\n",
            "total_trades: 3686\n",
            "Sharpe: 0.657\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 347          |\n",
            "|    iterations           | 156          |\n",
            "|    time_elapsed         | 920          |\n",
            "|    total_timesteps      | 319488       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049763424 |\n",
            "|    clip_fraction        | 0.0355       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.94        |\n",
            "|    explained_variance   | 7.99e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.699        |\n",
            "|    n_updates            | 1550         |\n",
            "|    policy_gradient_loss | -0.00242     |\n",
            "|    reward               | -0.028152384 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 1.24         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 346          |\n",
            "|    iterations           | 157          |\n",
            "|    time_elapsed         | 926          |\n",
            "|    total_timesteps      | 321536       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036325823 |\n",
            "|    clip_fraction        | 0.00498      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.94        |\n",
            "|    explained_variance   | 3.8e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.47         |\n",
            "|    n_updates            | 1560         |\n",
            "|    policy_gradient_loss | -0.000168    |\n",
            "|    reward               | -1.2039465   |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 2.85         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 346          |\n",
            "|    iterations           | 158          |\n",
            "|    time_elapsed         | 933          |\n",
            "|    total_timesteps      | 323584       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024659713 |\n",
            "|    clip_fraction        | 0.0177       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.94        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.1          |\n",
            "|    n_updates            | 1570         |\n",
            "|    policy_gradient_loss | -0.000953    |\n",
            "|    reward               | 0.66440505   |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 2.83         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 346         |\n",
            "|    iterations           | 159         |\n",
            "|    time_elapsed         | 941         |\n",
            "|    total_timesteps      | 325632      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.00444295  |\n",
            "|    clip_fraction        | 0.0328      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.94       |\n",
            "|    explained_variance   | -7.31e-05   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0604      |\n",
            "|    n_updates            | 1580        |\n",
            "|    policy_gradient_loss | -0.00239    |\n",
            "|    reward               | 0.106081605 |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 0.265       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 345          |\n",
            "|    iterations           | 160          |\n",
            "|    time_elapsed         | 947          |\n",
            "|    total_timesteps      | 327680       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050447485 |\n",
            "|    clip_fraction        | 0.0159       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.94        |\n",
            "|    explained_variance   | 2.8e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.01         |\n",
            "|    n_updates            | 1590         |\n",
            "|    policy_gradient_loss | -0.000458    |\n",
            "|    reward               | 0.0016539865 |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 1.83         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 345         |\n",
            "|    iterations           | 161         |\n",
            "|    time_elapsed         | 955         |\n",
            "|    total_timesteps      | 329728      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002780122 |\n",
            "|    clip_fraction        | 0.00586     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.95       |\n",
            "|    explained_variance   | 4.73e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.814       |\n",
            "|    n_updates            | 1600        |\n",
            "|    policy_gradient_loss | -0.000153   |\n",
            "|    reward               | 0.18663302  |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 1.97        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 344          |\n",
            "|    iterations           | 162          |\n",
            "|    time_elapsed         | 961          |\n",
            "|    total_timesteps      | 331776       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037653218 |\n",
            "|    clip_fraction        | 0.0174       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.97        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.273        |\n",
            "|    n_updates            | 1610         |\n",
            "|    policy_gradient_loss | -0.00199     |\n",
            "|    reward               | -0.28692576  |\n",
            "|    std                  | 1.08         |\n",
            "|    value_loss           | 0.498        |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 115\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -529105.96\n",
            "total_reward: -539105.96\n",
            "total_cost: 727.13\n",
            "total_trades: 3734\n",
            "Sharpe: 0.528\n",
            "=================================\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 344            |\n",
            "|    iterations           | 163            |\n",
            "|    time_elapsed         | 967            |\n",
            "|    total_timesteps      | 333824         |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.0035585521   |\n",
            "|    clip_fraction        | 0.0125         |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -2.99          |\n",
            "|    explained_variance   | 3.86e-05       |\n",
            "|    learning_rate        | 0.00025        |\n",
            "|    loss                 | 1.22           |\n",
            "|    n_updates            | 1620           |\n",
            "|    policy_gradient_loss | -0.000937      |\n",
            "|    reward               | -0.00093805586 |\n",
            "|    std                  | 1.08           |\n",
            "|    value_loss           | 1.83           |\n",
            "--------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 345          |\n",
            "|    iterations           | 164          |\n",
            "|    time_elapsed         | 972          |\n",
            "|    total_timesteps      | 335872       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028068495 |\n",
            "|    clip_fraction        | 0.00942      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.99        |\n",
            "|    explained_variance   | 3.24e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.08         |\n",
            "|    n_updates            | 1630         |\n",
            "|    policy_gradient_loss | -0.000457    |\n",
            "|    reward               | 0.8883528    |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 2.16         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 345          |\n",
            "|    iterations           | 165          |\n",
            "|    time_elapsed         | 977          |\n",
            "|    total_timesteps      | 337920       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020007747 |\n",
            "|    clip_fraction        | 0.0128       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.625        |\n",
            "|    n_updates            | 1640         |\n",
            "|    policy_gradient_loss | -0.000948    |\n",
            "|    reward               | -0.5255229   |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 1.73         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 346          |\n",
            "|    iterations           | 166          |\n",
            "|    time_elapsed         | 982          |\n",
            "|    total_timesteps      | 339968       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0064281938 |\n",
            "|    clip_fraction        | 0.0702       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | 5.36e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.315        |\n",
            "|    n_updates            | 1650         |\n",
            "|    policy_gradient_loss | -0.00376     |\n",
            "|    reward               | -0.0479425   |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.719        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 346          |\n",
            "|    iterations           | 167          |\n",
            "|    time_elapsed         | 986          |\n",
            "|    total_timesteps      | 342016       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046290737 |\n",
            "|    clip_fraction        | 0.0185       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | 3.47e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.48         |\n",
            "|    n_updates            | 1660         |\n",
            "|    policy_gradient_loss | -0.000958    |\n",
            "|    reward               | -0.018006563 |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 2.74         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 346         |\n",
            "|    iterations           | 168         |\n",
            "|    time_elapsed         | 991         |\n",
            "|    total_timesteps      | 344064      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005601002 |\n",
            "|    clip_fraction        | 0.0395      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.01       |\n",
            "|    explained_variance   | 4.35e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.982       |\n",
            "|    n_updates            | 1670        |\n",
            "|    policy_gradient_loss | -0.00306    |\n",
            "|    reward               | -0.75056225 |\n",
            "|    std                  | 1.09        |\n",
            "|    value_loss           | 3.18        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 347          |\n",
            "|    iterations           | 169          |\n",
            "|    time_elapsed         | 996          |\n",
            "|    total_timesteps      | 346112       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036121141 |\n",
            "|    clip_fraction        | 0.0206       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.214        |\n",
            "|    n_updates            | 1680         |\n",
            "|    policy_gradient_loss | -0.00065     |\n",
            "|    reward               | 0.13302909   |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.442        |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 120\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -569693.89\n",
            "total_reward: -579693.89\n",
            "total_cost: 751.44\n",
            "total_trades: 3730\n",
            "Sharpe: -0.151\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 347         |\n",
            "|    iterations           | 170         |\n",
            "|    time_elapsed         | 1001        |\n",
            "|    total_timesteps      | 348160      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003051831 |\n",
            "|    clip_fraction        | 0.0113      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.01       |\n",
            "|    explained_variance   | 3.84e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.16        |\n",
            "|    n_updates            | 1690        |\n",
            "|    policy_gradient_loss | -0.000397   |\n",
            "|    reward               | 0.02119442  |\n",
            "|    std                  | 1.09        |\n",
            "|    value_loss           | 2.4         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 347         |\n",
            "|    iterations           | 171         |\n",
            "|    time_elapsed         | 1006        |\n",
            "|    total_timesteps      | 350208      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004558364 |\n",
            "|    clip_fraction        | 0.0241      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.01       |\n",
            "|    explained_variance   | 4.67e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.912       |\n",
            "|    n_updates            | 1700        |\n",
            "|    policy_gradient_loss | -0.00226    |\n",
            "|    reward               | -0.5428682  |\n",
            "|    std                  | 1.1         |\n",
            "|    value_loss           | 2.36        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 348          |\n",
            "|    iterations           | 172          |\n",
            "|    time_elapsed         | 1011         |\n",
            "|    total_timesteps      | 352256       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029664123 |\n",
            "|    clip_fraction        | 0.0108       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.92         |\n",
            "|    n_updates            | 1710         |\n",
            "|    policy_gradient_loss | -0.000743    |\n",
            "|    reward               | 0.2010796    |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 1.47         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 348          |\n",
            "|    iterations           | 173          |\n",
            "|    time_elapsed         | 1016         |\n",
            "|    total_timesteps      | 354304       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046284245 |\n",
            "|    clip_fraction        | 0.0158       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 7.09e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.539        |\n",
            "|    n_updates            | 1720         |\n",
            "|    policy_gradient_loss | -0.000827    |\n",
            "|    reward               | -0.011603793 |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 1.04         |\n",
            "------------------------------------------\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 349            |\n",
            "|    iterations           | 174            |\n",
            "|    time_elapsed         | 1020           |\n",
            "|    total_timesteps      | 356352         |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.0073468965   |\n",
            "|    clip_fraction        | 0.0478         |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -3.03          |\n",
            "|    explained_variance   | 4.19e-05       |\n",
            "|    learning_rate        | 0.00025        |\n",
            "|    loss                 | 1.06           |\n",
            "|    n_updates            | 1730           |\n",
            "|    policy_gradient_loss | -0.00276       |\n",
            "|    reward               | -0.00019210167 |\n",
            "|    std                  | 1.1            |\n",
            "|    value_loss           | 2.02           |\n",
            "--------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 349          |\n",
            "|    iterations           | 175          |\n",
            "|    time_elapsed         | 1025         |\n",
            "|    total_timesteps      | 358400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042919116 |\n",
            "|    clip_fraction        | 0.0334       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 3.84e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.685        |\n",
            "|    n_updates            | 1740         |\n",
            "|    policy_gradient_loss | -0.0027      |\n",
            "|    reward               | 0.01551516   |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 2.41         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 349          |\n",
            "|    iterations           | 176          |\n",
            "|    time_elapsed         | 1030         |\n",
            "|    total_timesteps      | 360448       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056701414 |\n",
            "|    clip_fraction        | 0.0573       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0271       |\n",
            "|    n_updates            | 1750         |\n",
            "|    policy_gradient_loss | -0.00355     |\n",
            "|    reward               | -0.06573142  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.167        |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 125\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -422696.93\n",
            "total_reward: -432696.93\n",
            "total_cost: 667.62\n",
            "total_trades: 3364\n",
            "Sharpe: 0.070\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 350         |\n",
            "|    iterations           | 177         |\n",
            "|    time_elapsed         | 1035        |\n",
            "|    total_timesteps      | 362496      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005054229 |\n",
            "|    clip_fraction        | 0.0232      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.04       |\n",
            "|    explained_variance   | 3.02e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.03        |\n",
            "|    n_updates            | 1760        |\n",
            "|    policy_gradient_loss | -0.00193    |\n",
            "|    reward               | 0.012474144 |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 1.86        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 350          |\n",
            "|    iterations           | 178          |\n",
            "|    time_elapsed         | 1040         |\n",
            "|    total_timesteps      | 364544       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0066196406 |\n",
            "|    clip_fraction        | 0.0534       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 3.25e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.776        |\n",
            "|    n_updates            | 1770         |\n",
            "|    policy_gradient_loss | -0.00319     |\n",
            "|    reward               | -0.21737032  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 1.4          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 350          |\n",
            "|    iterations           | 179          |\n",
            "|    time_elapsed         | 1045         |\n",
            "|    total_timesteps      | 366592       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040362813 |\n",
            "|    clip_fraction        | 0.063        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.143        |\n",
            "|    n_updates            | 1780         |\n",
            "|    policy_gradient_loss | -0.00391     |\n",
            "|    reward               | 0.29576266   |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.505        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 351          |\n",
            "|    iterations           | 180          |\n",
            "|    time_elapsed         | 1049         |\n",
            "|    total_timesteps      | 368640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038255733 |\n",
            "|    clip_fraction        | 0.0188       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 4.51e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.608        |\n",
            "|    n_updates            | 1790         |\n",
            "|    policy_gradient_loss | -0.000993    |\n",
            "|    reward               | 0.0063226516 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 1.47         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 351         |\n",
            "|    iterations           | 181         |\n",
            "|    time_elapsed         | 1054        |\n",
            "|    total_timesteps      | 370688      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003801844 |\n",
            "|    clip_fraction        | 0.0393      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.04       |\n",
            "|    explained_variance   | 3.71e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.721       |\n",
            "|    n_updates            | 1800        |\n",
            "|    policy_gradient_loss | -0.00278    |\n",
            "|    reward               | -1.5637916  |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 1.74        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 351          |\n",
            "|    iterations           | 182          |\n",
            "|    time_elapsed         | 1059         |\n",
            "|    total_timesteps      | 372736       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029714042 |\n",
            "|    clip_fraction        | 0.0108       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.609        |\n",
            "|    n_updates            | 1810         |\n",
            "|    policy_gradient_loss | -0.000596    |\n",
            "|    reward               | 0.11926641   |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 1.71         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 352          |\n",
            "|    iterations           | 183          |\n",
            "|    time_elapsed         | 1064         |\n",
            "|    total_timesteps      | 374784       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055655693 |\n",
            "|    clip_fraction        | 0.0548       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 6.25e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.163        |\n",
            "|    n_updates            | 1820         |\n",
            "|    policy_gradient_loss | -0.00297     |\n",
            "|    reward               | -0.03600479  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.354        |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 130\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -591958.61\n",
            "total_reward: -601958.61\n",
            "total_cost: 812.89\n",
            "total_trades: 3540\n",
            "Sharpe: -0.071\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 352          |\n",
            "|    iterations           | 184          |\n",
            "|    time_elapsed         | 1069         |\n",
            "|    total_timesteps      | 376832       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044651143 |\n",
            "|    clip_fraction        | 0.0442       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 2.52e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.559        |\n",
            "|    n_updates            | 1830         |\n",
            "|    policy_gradient_loss | -0.00269     |\n",
            "|    reward               | -0.012840219 |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 1.33         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 352          |\n",
            "|    iterations           | 185          |\n",
            "|    time_elapsed         | 1074         |\n",
            "|    total_timesteps      | 378880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046268934 |\n",
            "|    clip_fraction        | 0.0363       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 3.83e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.21         |\n",
            "|    n_updates            | 1840         |\n",
            "|    policy_gradient_loss | -0.00265     |\n",
            "|    reward               | 0.10797927   |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 2.55         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 353         |\n",
            "|    iterations           | 186         |\n",
            "|    time_elapsed         | 1079        |\n",
            "|    total_timesteps      | 380928      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004789947 |\n",
            "|    clip_fraction        | 0.0264      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.04       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.19        |\n",
            "|    n_updates            | 1850        |\n",
            "|    policy_gradient_loss | -0.00236    |\n",
            "|    reward               | -0.07624588 |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 0.358       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 353          |\n",
            "|    iterations           | 187          |\n",
            "|    time_elapsed         | 1083         |\n",
            "|    total_timesteps      | 382976       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031598876 |\n",
            "|    clip_fraction        | 0.0192       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 3.78e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.897        |\n",
            "|    n_updates            | 1860         |\n",
            "|    policy_gradient_loss | -0.0013      |\n",
            "|    reward               | 0.02877921   |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 1.94         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 353         |\n",
            "|    iterations           | 188         |\n",
            "|    time_elapsed         | 1088        |\n",
            "|    total_timesteps      | 385024      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004112279 |\n",
            "|    clip_fraction        | 0.0329      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.06       |\n",
            "|    explained_variance   | 4.67e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.14        |\n",
            "|    n_updates            | 1870        |\n",
            "|    policy_gradient_loss | -0.00197    |\n",
            "|    reward               | 0.062460665 |\n",
            "|    std                  | 1.12        |\n",
            "|    value_loss           | 2.51        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 353          |\n",
            "|    iterations           | 189          |\n",
            "|    time_elapsed         | 1093         |\n",
            "|    total_timesteps      | 387072       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049545188 |\n",
            "|    clip_fraction        | 0.0406       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.07        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.414        |\n",
            "|    n_updates            | 1880         |\n",
            "|    policy_gradient_loss | -0.0027      |\n",
            "|    reward               | -0.14727882  |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.975        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 354           |\n",
            "|    iterations           | 190           |\n",
            "|    time_elapsed         | 1098          |\n",
            "|    total_timesteps      | 389120        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00030262241 |\n",
            "|    clip_fraction        | 0.00278       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.08         |\n",
            "|    explained_variance   | 4.6e-05       |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.397         |\n",
            "|    n_updates            | 1890          |\n",
            "|    policy_gradient_loss | 0.000162      |\n",
            "|    reward               | 0.0017699543  |\n",
            "|    std                  | 1.14          |\n",
            "|    value_loss           | 0.697         |\n",
            "-------------------------------------------\n",
            "day: 2896, episode: 135\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -483635.35\n",
            "total_reward: -493635.35\n",
            "total_cost: 912.81\n",
            "total_trades: 3570\n",
            "Sharpe: -0.295\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 354         |\n",
            "|    iterations           | 191         |\n",
            "|    time_elapsed         | 1103        |\n",
            "|    total_timesteps      | 391168      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003208836 |\n",
            "|    clip_fraction        | 0.0189      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.1        |\n",
            "|    explained_variance   | 2.89e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.28        |\n",
            "|    n_updates            | 1900        |\n",
            "|    policy_gradient_loss | -0.00147    |\n",
            "|    reward               | 0.033070456 |\n",
            "|    std                  | 1.15        |\n",
            "|    value_loss           | 1.71        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 354          |\n",
            "|    iterations           | 192          |\n",
            "|    time_elapsed         | 1108         |\n",
            "|    total_timesteps      | 393216       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030877024 |\n",
            "|    clip_fraction        | 0.0188       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.12        |\n",
            "|    explained_variance   | 4.27e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.741        |\n",
            "|    n_updates            | 1910         |\n",
            "|    policy_gradient_loss | -0.001       |\n",
            "|    reward               | -0.03073001  |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 1.82         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 355         |\n",
            "|    iterations           | 193         |\n",
            "|    time_elapsed         | 1112        |\n",
            "|    total_timesteps      | 395264      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004636778 |\n",
            "|    clip_fraction        | 0.0427      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.12       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0631      |\n",
            "|    n_updates            | 1920        |\n",
            "|    policy_gradient_loss | -0.00248    |\n",
            "|    reward               | -0.2416119  |\n",
            "|    std                  | 1.15        |\n",
            "|    value_loss           | 0.158       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 194          |\n",
            "|    time_elapsed         | 1117         |\n",
            "|    total_timesteps      | 397312       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046738144 |\n",
            "|    clip_fraction        | 0.0358       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.11        |\n",
            "|    explained_variance   | 4.06e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.534        |\n",
            "|    n_updates            | 1930         |\n",
            "|    policy_gradient_loss | -0.00322     |\n",
            "|    reward               | -0.008848442 |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 1.25         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 195          |\n",
            "|    time_elapsed         | 1122         |\n",
            "|    total_timesteps      | 399360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041520717 |\n",
            "|    clip_fraction        | 0.0295       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.11        |\n",
            "|    explained_variance   | 5.26e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.929        |\n",
            "|    n_updates            | 1940         |\n",
            "|    policy_gradient_loss | -0.00283     |\n",
            "|    reward               | 2.1089566    |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 1.85         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 196          |\n",
            "|    time_elapsed         | 1127         |\n",
            "|    total_timesteps      | 401408       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011848889 |\n",
            "|    clip_fraction        | 0.00195      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.11        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.265        |\n",
            "|    n_updates            | 1950         |\n",
            "|    policy_gradient_loss | -0.000161    |\n",
            "|    reward               | 0.5630207    |\n",
            "|    std                  | 1.16         |\n",
            "|    value_loss           | 0.72         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 197          |\n",
            "|    time_elapsed         | 1132         |\n",
            "|    total_timesteps      | 403456       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069268337 |\n",
            "|    clip_fraction        | 0.0587       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.12        |\n",
            "|    explained_variance   | 4.24e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.64         |\n",
            "|    n_updates            | 1960         |\n",
            "|    policy_gradient_loss | -0.0064      |\n",
            "|    reward               | -0.015198672 |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 2.23         |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 356        |\n",
            "|    iterations           | 198        |\n",
            "|    time_elapsed         | 1137       |\n",
            "|    total_timesteps      | 405504     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00460591 |\n",
            "|    clip_fraction        | 0.0205     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.11      |\n",
            "|    explained_variance   | 3.29e-05   |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 1.06       |\n",
            "|    n_updates            | 1970       |\n",
            "|    policy_gradient_loss | -0.00142   |\n",
            "|    reward               | 0.7938795  |\n",
            "|    std                  | 1.15       |\n",
            "|    value_loss           | 2.64       |\n",
            "----------------------------------------\n",
            "day: 2896, episode: 140\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -568335.56\n",
            "total_reward: -578335.56\n",
            "total_cost: 747.23\n",
            "total_trades: 3756\n",
            "Sharpe: 0.305\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 199          |\n",
            "|    time_elapsed         | 1142         |\n",
            "|    total_timesteps      | 407552       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037880847 |\n",
            "|    clip_fraction        | 0.0378       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.11        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.47         |\n",
            "|    n_updates            | 1980         |\n",
            "|    policy_gradient_loss | -0.0025      |\n",
            "|    reward               | -0.7437207   |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 2.36         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 200          |\n",
            "|    time_elapsed         | 1147         |\n",
            "|    total_timesteps      | 409600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041826144 |\n",
            "|    clip_fraction        | 0.0144       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.1         |\n",
            "|    explained_variance   | 9.42e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.163        |\n",
            "|    n_updates            | 1990         |\n",
            "|    policy_gradient_loss | -0.000926    |\n",
            "|    reward               | -0.010924055 |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 0.272        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 357         |\n",
            "|    iterations           | 201         |\n",
            "|    time_elapsed         | 1151        |\n",
            "|    total_timesteps      | 411648      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005824046 |\n",
            "|    clip_fraction        | 0.034       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.09       |\n",
            "|    explained_variance   | 3.45e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.806       |\n",
            "|    n_updates            | 2000        |\n",
            "|    policy_gradient_loss | -0.00156    |\n",
            "|    reward               | 0.008373816 |\n",
            "|    std                  | 1.14        |\n",
            "|    value_loss           | 2.72        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 357         |\n",
            "|    iterations           | 202         |\n",
            "|    time_elapsed         | 1156        |\n",
            "|    total_timesteps      | 413696      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004885324 |\n",
            "|    clip_fraction        | 0.0231      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.1        |\n",
            "|    explained_variance   | 4.58e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.6         |\n",
            "|    n_updates            | 2010        |\n",
            "|    policy_gradient_loss | -0.00149    |\n",
            "|    reward               | -0.6039127  |\n",
            "|    std                  | 1.14        |\n",
            "|    value_loss           | 2.38        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 357         |\n",
            "|    iterations           | 203         |\n",
            "|    time_elapsed         | 1161        |\n",
            "|    total_timesteps      | 415744      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004847434 |\n",
            "|    clip_fraction        | 0.0261      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.09       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.241       |\n",
            "|    n_updates            | 2020        |\n",
            "|    policy_gradient_loss | -0.00242    |\n",
            "|    reward               | 0.43759558  |\n",
            "|    std                  | 1.13        |\n",
            "|    value_loss           | 0.577       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 204          |\n",
            "|    time_elapsed         | 1166         |\n",
            "|    total_timesteps      | 417792       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058342326 |\n",
            "|    clip_fraction        | 0.0561       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.07        |\n",
            "|    explained_variance   | 2.63e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.789        |\n",
            "|    n_updates            | 2030         |\n",
            "|    policy_gradient_loss | -0.00285     |\n",
            "|    reward               | 0.03861934   |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 1.95         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 205          |\n",
            "|    time_elapsed         | 1171         |\n",
            "|    total_timesteps      | 419840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020777471 |\n",
            "|    clip_fraction        | 0.00293      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.07        |\n",
            "|    explained_variance   | 4.46e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.895        |\n",
            "|    n_updates            | 2040         |\n",
            "|    policy_gradient_loss | -0.000183    |\n",
            "|    reward               | 1.6251645    |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 2.35         |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 145\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -517667.29\n",
            "total_reward: -527667.29\n",
            "total_cost: 934.91\n",
            "total_trades: 3728\n",
            "Sharpe: -0.569\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 206          |\n",
            "|    time_elapsed         | 1176         |\n",
            "|    total_timesteps      | 421888       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051469174 |\n",
            "|    clip_fraction        | 0.0351       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.07        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.725        |\n",
            "|    n_updates            | 2050         |\n",
            "|    policy_gradient_loss | -0.00225     |\n",
            "|    reward               | -0.4025477   |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 1.29         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 358           |\n",
            "|    iterations           | 207           |\n",
            "|    time_elapsed         | 1181          |\n",
            "|    total_timesteps      | 423936        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.006499609   |\n",
            "|    clip_fraction        | 0.0843        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.06         |\n",
            "|    explained_variance   | 3.7e-05       |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.339         |\n",
            "|    n_updates            | 2060          |\n",
            "|    policy_gradient_loss | -0.00628      |\n",
            "|    reward               | -0.0061987345 |\n",
            "|    std                  | 1.11          |\n",
            "|    value_loss           | 0.824         |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 359           |\n",
            "|    iterations           | 208           |\n",
            "|    time_elapsed         | 1186          |\n",
            "|    total_timesteps      | 425984        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0049190056  |\n",
            "|    clip_fraction        | 0.039         |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.04         |\n",
            "|    explained_variance   | 3.23e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 1.13          |\n",
            "|    n_updates            | 2070          |\n",
            "|    policy_gradient_loss | -0.0032       |\n",
            "|    reward               | -0.0052413126 |\n",
            "|    std                  | 1.11          |\n",
            "|    value_loss           | 2.2           |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 359         |\n",
            "|    iterations           | 209         |\n",
            "|    time_elapsed         | 1191        |\n",
            "|    total_timesteps      | 428032      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004602902 |\n",
            "|    clip_fraction        | 0.0223      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.04       |\n",
            "|    explained_variance   | 5.26e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.35        |\n",
            "|    n_updates            | 2080        |\n",
            "|    policy_gradient_loss | -0.0015     |\n",
            "|    reward               | -1.2977049  |\n",
            "|    std                  | 1.11        |\n",
            "|    value_loss           | 2.51        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 359        |\n",
            "|    iterations           | 210        |\n",
            "|    time_elapsed         | 1195       |\n",
            "|    total_timesteps      | 430080     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00544456 |\n",
            "|    clip_fraction        | 0.0316     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.03      |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 0.159      |\n",
            "|    n_updates            | 2090       |\n",
            "|    policy_gradient_loss | -0.00186   |\n",
            "|    reward               | 0.0804676  |\n",
            "|    std                  | 1.1        |\n",
            "|    value_loss           | 0.341      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 359         |\n",
            "|    iterations           | 211         |\n",
            "|    time_elapsed         | 1200        |\n",
            "|    total_timesteps      | 432128      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004220454 |\n",
            "|    clip_fraction        | 0.0174      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.03       |\n",
            "|    explained_variance   | 4.48e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.13        |\n",
            "|    n_updates            | 2100        |\n",
            "|    policy_gradient_loss | -0.000476   |\n",
            "|    reward               | 0.019959245 |\n",
            "|    std                  | 1.1         |\n",
            "|    value_loss           | 2.95        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 360          |\n",
            "|    iterations           | 212          |\n",
            "|    time_elapsed         | 1205         |\n",
            "|    total_timesteps      | 434176       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030470924 |\n",
            "|    clip_fraction        | 0.00239      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 4.46e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.37         |\n",
            "|    n_updates            | 2110         |\n",
            "|    policy_gradient_loss | 6.09e-05     |\n",
            "|    reward               | 0.976312     |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 2.86         |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 150\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -658827.83\n",
            "total_reward: -668827.83\n",
            "total_cost: 900.11\n",
            "total_trades: 4060\n",
            "Sharpe: 0.553\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 360          |\n",
            "|    iterations           | 213          |\n",
            "|    time_elapsed         | 1210         |\n",
            "|    total_timesteps      | 436224       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028388882 |\n",
            "|    clip_fraction        | 0.0237       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.296        |\n",
            "|    n_updates            | 2120         |\n",
            "|    policy_gradient_loss | -0.00215     |\n",
            "|    reward               | -0.33551648  |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 1.45         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 360           |\n",
            "|    iterations           | 214           |\n",
            "|    time_elapsed         | 1215          |\n",
            "|    total_timesteps      | 438272        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0069123437  |\n",
            "|    clip_fraction        | 0.0996        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.02         |\n",
            "|    explained_variance   | 5.14e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 1.02          |\n",
            "|    n_updates            | 2130          |\n",
            "|    policy_gradient_loss | -0.00701      |\n",
            "|    reward               | -0.0120634595 |\n",
            "|    std                  | 1.1           |\n",
            "|    value_loss           | 1.7           |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 360         |\n",
            "|    iterations           | 215         |\n",
            "|    time_elapsed         | 1220        |\n",
            "|    total_timesteps      | 440320      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004168468 |\n",
            "|    clip_fraction        | 0.0231      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.02       |\n",
            "|    explained_variance   | 3.99e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.663       |\n",
            "|    n_updates            | 2140        |\n",
            "|    policy_gradient_loss | -0.00174    |\n",
            "|    reward               | -0.8572471  |\n",
            "|    std                  | 1.1         |\n",
            "|    value_loss           | 2.67        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 361         |\n",
            "|    iterations           | 216         |\n",
            "|    time_elapsed         | 1225        |\n",
            "|    total_timesteps      | 442368      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.00504026  |\n",
            "|    clip_fraction        | 0.0507      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.02       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.832       |\n",
            "|    n_updates            | 2150        |\n",
            "|    policy_gradient_loss | -0.00342    |\n",
            "|    reward               | -0.21703456 |\n",
            "|    std                  | 1.1         |\n",
            "|    value_loss           | 2.08        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 361         |\n",
            "|    iterations           | 217         |\n",
            "|    time_elapsed         | 1230        |\n",
            "|    total_timesteps      | 444416      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008421015 |\n",
            "|    clip_fraction        | 0.0666      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.02       |\n",
            "|    explained_variance   | 2.41e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.131       |\n",
            "|    n_updates            | 2160        |\n",
            "|    policy_gradient_loss | -0.00377    |\n",
            "|    reward               | 0.14442354  |\n",
            "|    std                  | 1.1         |\n",
            "|    value_loss           | 0.291       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 218          |\n",
            "|    time_elapsed         | 1234         |\n",
            "|    total_timesteps      | 446464       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0093133785 |\n",
            "|    clip_fraction        | 0.0717       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 4.3e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.14         |\n",
            "|    n_updates            | 2170         |\n",
            "|    policy_gradient_loss | -0.00551     |\n",
            "|    reward               | 0.020235125  |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 2.53         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 219          |\n",
            "|    time_elapsed         | 1239         |\n",
            "|    total_timesteps      | 448512       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0062538334 |\n",
            "|    clip_fraction        | 0.0612       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 3.78e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.26         |\n",
            "|    n_updates            | 2180         |\n",
            "|    policy_gradient_loss | -0.00408     |\n",
            "|    reward               | -0.18630047  |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 2.75         |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 155\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -628766.54\n",
            "total_reward: -638766.54\n",
            "total_cost: 805.83\n",
            "total_trades: 3890\n",
            "Sharpe: 0.613\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 362         |\n",
            "|    iterations           | 220         |\n",
            "|    time_elapsed         | 1244        |\n",
            "|    total_timesteps      | 450560      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004567952 |\n",
            "|    clip_fraction        | 0.0431      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.02       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.153       |\n",
            "|    n_updates            | 2190        |\n",
            "|    policy_gradient_loss | -0.00248    |\n",
            "|    reward               | 0.07040204  |\n",
            "|    std                  | 1.1         |\n",
            "|    value_loss           | 0.72        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 362          |\n",
            "|    iterations           | 221          |\n",
            "|    time_elapsed         | 1249         |\n",
            "|    total_timesteps      | 452608       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041322894 |\n",
            "|    clip_fraction        | 0.0166       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 4.31e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.47         |\n",
            "|    n_updates            | 2200         |\n",
            "|    policy_gradient_loss | -0.000747    |\n",
            "|    reward               | -0.012633858 |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 2.35         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 362          |\n",
            "|    iterations           | 222          |\n",
            "|    time_elapsed         | 1254         |\n",
            "|    total_timesteps      | 454656       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044215764 |\n",
            "|    clip_fraction        | 0.0373       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 4.45e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.19         |\n",
            "|    n_updates            | 2210         |\n",
            "|    policy_gradient_loss | -0.00271     |\n",
            "|    reward               | 3.2474005    |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 2.89         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 362          |\n",
            "|    iterations           | 223          |\n",
            "|    time_elapsed         | 1259         |\n",
            "|    total_timesteps      | 456704       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048483233 |\n",
            "|    clip_fraction        | 0.035        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.858        |\n",
            "|    n_updates            | 2220         |\n",
            "|    policy_gradient_loss | -0.00112     |\n",
            "|    reward               | 0.052568     |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 1.98         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 362          |\n",
            "|    iterations           | 224          |\n",
            "|    time_elapsed         | 1264         |\n",
            "|    total_timesteps      | 458752       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041797087 |\n",
            "|    clip_fraction        | 0.0533       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 4.82e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.349        |\n",
            "|    n_updates            | 2230         |\n",
            "|    policy_gradient_loss | -0.00327     |\n",
            "|    reward               | -0.11844958  |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.646        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 363          |\n",
            "|    iterations           | 225          |\n",
            "|    time_elapsed         | 1269         |\n",
            "|    total_timesteps      | 460800       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049023787 |\n",
            "|    clip_fraction        | 0.0193       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 3.7e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.2          |\n",
            "|    n_updates            | 2240         |\n",
            "|    policy_gradient_loss | -0.00125     |\n",
            "|    reward               | -0.003987207 |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 2.78         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 363          |\n",
            "|    iterations           | 226          |\n",
            "|    time_elapsed         | 1273         |\n",
            "|    total_timesteps      | 462848       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048352233 |\n",
            "|    clip_fraction        | 0.02         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | 5.29e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.85         |\n",
            "|    n_updates            | 2250         |\n",
            "|    policy_gradient_loss | -0.00107     |\n",
            "|    reward               | -0.58113986  |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 2.21         |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 160\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -564279.51\n",
            "total_reward: -574279.51\n",
            "total_cost: 943.20\n",
            "total_trades: 3778\n",
            "Sharpe: 0.159\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 363          |\n",
            "|    iterations           | 227          |\n",
            "|    time_elapsed         | 1278         |\n",
            "|    total_timesteps      | 464896       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044749994 |\n",
            "|    clip_fraction        | 0.0571       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3           |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.173        |\n",
            "|    n_updates            | 2260         |\n",
            "|    policy_gradient_loss | -0.00271     |\n",
            "|    reward               | 0.18564077   |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 0.361        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 363          |\n",
            "|    iterations           | 228          |\n",
            "|    time_elapsed         | 1283         |\n",
            "|    total_timesteps      | 466944       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042853826 |\n",
            "|    clip_fraction        | 0.0231       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3           |\n",
            "|    explained_variance   | 4.05e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.793        |\n",
            "|    n_updates            | 2270         |\n",
            "|    policy_gradient_loss | -0.0015      |\n",
            "|    reward               | 0.037116554  |\n",
            "|    std                  | 1.09         |\n",
            "|    value_loss           | 2.1          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 363          |\n",
            "|    iterations           | 229          |\n",
            "|    time_elapsed         | 1288         |\n",
            "|    total_timesteps      | 468992       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0065929913 |\n",
            "|    clip_fraction        | 0.037        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3           |\n",
            "|    explained_variance   | 5.33e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.714        |\n",
            "|    n_updates            | 2280         |\n",
            "|    policy_gradient_loss | -0.00222     |\n",
            "|    reward               | 0.91266423   |\n",
            "|    std                  | 1.1          |\n",
            "|    value_loss           | 2            |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 230          |\n",
            "|    time_elapsed         | 1293         |\n",
            "|    total_timesteps      | 471040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011265376 |\n",
            "|    clip_fraction        | 0.00732      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.803        |\n",
            "|    n_updates            | 2290         |\n",
            "|    policy_gradient_loss | -3.11e-05    |\n",
            "|    reward               | -0.0805457   |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 1.81         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 231          |\n",
            "|    time_elapsed         | 1298         |\n",
            "|    total_timesteps      | 473088       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022300761 |\n",
            "|    clip_fraction        | 0.0134       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.02        |\n",
            "|    explained_variance   | 7.41e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.444        |\n",
            "|    n_updates            | 2300         |\n",
            "|    policy_gradient_loss | -0.000424    |\n",
            "|    reward               | 0.005965509  |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 1.35         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 232          |\n",
            "|    time_elapsed         | 1303         |\n",
            "|    total_timesteps      | 475136       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.002168714  |\n",
            "|    clip_fraction        | 0.00786      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 4.29e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.63         |\n",
            "|    n_updates            | 2310         |\n",
            "|    policy_gradient_loss | -0.000541    |\n",
            "|    reward               | -0.001592059 |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 3.2          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 233          |\n",
            "|    time_elapsed         | 1308         |\n",
            "|    total_timesteps      | 477184       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042587947 |\n",
            "|    clip_fraction        | 0.0245       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.04        |\n",
            "|    explained_variance   | 4.4e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.05         |\n",
            "|    n_updates            | 2320         |\n",
            "|    policy_gradient_loss | -0.00208     |\n",
            "|    reward               | 0.18488291   |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 2.6          |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 165\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -598550.39\n",
            "total_reward: -608550.39\n",
            "total_cost: 812.32\n",
            "total_trades: 3994\n",
            "Sharpe: 0.700\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 234          |\n",
            "|    time_elapsed         | 1312         |\n",
            "|    total_timesteps      | 479232       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037860447 |\n",
            "|    clip_fraction        | 0.0182       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0593       |\n",
            "|    n_updates            | 2330         |\n",
            "|    policy_gradient_loss | -0.00081     |\n",
            "|    reward               | -0.043164123 |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.202        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 235          |\n",
            "|    time_elapsed         | 1317         |\n",
            "|    total_timesteps      | 481280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045500067 |\n",
            "|    clip_fraction        | 0.0304       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.06        |\n",
            "|    explained_variance   | 4.57e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.27         |\n",
            "|    n_updates            | 2340         |\n",
            "|    policy_gradient_loss | -0.0018      |\n",
            "|    reward               | -0.010507106 |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 2.54         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 236          |\n",
            "|    time_elapsed         | 1322         |\n",
            "|    total_timesteps      | 483328       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025437295 |\n",
            "|    clip_fraction        | 0.00405      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.07        |\n",
            "|    explained_variance   | 4.32e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.64         |\n",
            "|    n_updates            | 2350         |\n",
            "|    policy_gradient_loss | -0.000314    |\n",
            "|    reward               | -0.7236352   |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 2.26         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 237          |\n",
            "|    time_elapsed         | 1327         |\n",
            "|    total_timesteps      | 485376       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0064520165 |\n",
            "|    clip_fraction        | 0.0542       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.07        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.133        |\n",
            "|    n_updates            | 2360         |\n",
            "|    policy_gradient_loss | -0.00376     |\n",
            "|    reward               | -0.023994436 |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 0.487        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 238          |\n",
            "|    time_elapsed         | 1332         |\n",
            "|    total_timesteps      | 487424       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.003773475  |\n",
            "|    clip_fraction        | 0.0361       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.06        |\n",
            "|    explained_variance   | 4.49e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.927        |\n",
            "|    n_updates            | 2370         |\n",
            "|    policy_gradient_loss | -0.000784    |\n",
            "|    reward               | -0.013203214 |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 1.52         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 239         |\n",
            "|    time_elapsed         | 1337        |\n",
            "|    total_timesteps      | 489472      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005476649 |\n",
            "|    clip_fraction        | 0.0511      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.08       |\n",
            "|    explained_variance   | 3.64e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.03        |\n",
            "|    n_updates            | 2380        |\n",
            "|    policy_gradient_loss | -0.0028     |\n",
            "|    reward               | -0.16385195 |\n",
            "|    std                  | 1.14        |\n",
            "|    value_loss           | 2.1         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 366          |\n",
            "|    iterations           | 240          |\n",
            "|    time_elapsed         | 1342         |\n",
            "|    total_timesteps      | 491520       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019619009 |\n",
            "|    clip_fraction        | 0.00405      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.837        |\n",
            "|    n_updates            | 2390         |\n",
            "|    policy_gradient_loss | -0.000218    |\n",
            "|    reward               | -0.5202468   |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 1.42         |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 170\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -413040.22\n",
            "total_reward: -423040.22\n",
            "total_cost: 906.62\n",
            "total_trades: 3564\n",
            "Sharpe: 0.330\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 366          |\n",
            "|    iterations           | 241          |\n",
            "|    time_elapsed         | 1347         |\n",
            "|    total_timesteps      | 493568       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054771816 |\n",
            "|    clip_fraction        | 0.0149       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | -2.07e-05    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.207        |\n",
            "|    n_updates            | 2400         |\n",
            "|    policy_gradient_loss | -0.000238    |\n",
            "|    reward               | 0.02479253   |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 0.304        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 366          |\n",
            "|    iterations           | 242          |\n",
            "|    time_elapsed         | 1352         |\n",
            "|    total_timesteps      | 495616       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045015006 |\n",
            "|    clip_fraction        | 0.0207       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 3.69e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.876        |\n",
            "|    n_updates            | 2410         |\n",
            "|    policy_gradient_loss | -0.00136     |\n",
            "|    reward               | 0.007272607  |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 1.51         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 243         |\n",
            "|    time_elapsed         | 1356        |\n",
            "|    total_timesteps      | 497664      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005720446 |\n",
            "|    clip_fraction        | 0.0507      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.08       |\n",
            "|    explained_variance   | 6.2e-05     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.783       |\n",
            "|    n_updates            | 2420        |\n",
            "|    policy_gradient_loss | -0.00292    |\n",
            "|    reward               | 0.15442564  |\n",
            "|    std                  | 1.15        |\n",
            "|    value_loss           | 1.49        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 366          |\n",
            "|    iterations           | 244          |\n",
            "|    time_elapsed         | 1361         |\n",
            "|    total_timesteps      | 499712       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047876523 |\n",
            "|    clip_fraction        | 0.0527       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0938       |\n",
            "|    n_updates            | 2430         |\n",
            "|    policy_gradient_loss | -0.00244     |\n",
            "|    reward               | 0.04127124   |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 0.24         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 367          |\n",
            "|    iterations           | 245          |\n",
            "|    time_elapsed         | 1366         |\n",
            "|    total_timesteps      | 501760       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006821271  |\n",
            "|    clip_fraction        | 0.0667       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.07        |\n",
            "|    explained_variance   | 3.91e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.307        |\n",
            "|    n_updates            | 2440         |\n",
            "|    policy_gradient_loss | -0.00454     |\n",
            "|    reward               | -0.022778856 |\n",
            "|    std                  | 1.14         |\n",
            "|    value_loss           | 1.05         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 367          |\n",
            "|    iterations           | 246          |\n",
            "|    time_elapsed         | 1371         |\n",
            "|    total_timesteps      | 503808       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025455966 |\n",
            "|    clip_fraction        | 0.0126       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | 3.9e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.525        |\n",
            "|    n_updates            | 2450         |\n",
            "|    policy_gradient_loss | -0.00153     |\n",
            "|    reward               | 1.1919131    |\n",
            "|    std                  | 1.16         |\n",
            "|    value_loss           | 1.31         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 367         |\n",
            "|    iterations           | 247         |\n",
            "|    time_elapsed         | 1376        |\n",
            "|    total_timesteps      | 505856      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.00568888  |\n",
            "|    clip_fraction        | 0.0311      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.1        |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.425       |\n",
            "|    n_updates            | 2460        |\n",
            "|    policy_gradient_loss | -0.00196    |\n",
            "|    reward               | -0.10438501 |\n",
            "|    std                  | 1.16        |\n",
            "|    value_loss           | 0.71        |\n",
            "-----------------------------------------\n",
            "day: 2896, episode: 175\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -327119.11\n",
            "total_reward: -337119.11\n",
            "total_cost: 597.14\n",
            "total_trades: 3188\n",
            "Sharpe: 0.124\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 367          |\n",
            "|    iterations           | 248          |\n",
            "|    time_elapsed         | 1381         |\n",
            "|    total_timesteps      | 507904       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.007151218  |\n",
            "|    clip_fraction        | 0.0448       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.12        |\n",
            "|    explained_variance   | 6.88e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.19         |\n",
            "|    n_updates            | 2470         |\n",
            "|    policy_gradient_loss | -0.00322     |\n",
            "|    reward               | -0.012283568 |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 0.41         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 367         |\n",
            "|    iterations           | 249         |\n",
            "|    time_elapsed         | 1386        |\n",
            "|    total_timesteps      | 509952      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004929751 |\n",
            "|    clip_fraction        | 0.0354      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.13       |\n",
            "|    explained_variance   | 1.4e-05     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.336       |\n",
            "|    n_updates            | 2480        |\n",
            "|    policy_gradient_loss | -0.00157    |\n",
            "|    reward               | 0.010736219 |\n",
            "|    std                  | 1.18        |\n",
            "|    value_loss           | 0.815       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 250          |\n",
            "|    time_elapsed         | 1391         |\n",
            "|    total_timesteps      | 512000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035505039 |\n",
            "|    clip_fraction        | 0.0229       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.15        |\n",
            "|    explained_variance   | 3.61e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.305        |\n",
            "|    n_updates            | 2490         |\n",
            "|    policy_gradient_loss | -0.00167     |\n",
            "|    reward               | -0.3422416   |\n",
            "|    std                  | 1.19         |\n",
            "|    value_loss           | 0.612        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 251          |\n",
            "|    time_elapsed         | 1396         |\n",
            "|    total_timesteps      | 514048       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047425823 |\n",
            "|    clip_fraction        | 0.0314       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.17        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.00436      |\n",
            "|    n_updates            | 2500         |\n",
            "|    policy_gradient_loss | -0.00157     |\n",
            "|    reward               | -0.21023276  |\n",
            "|    std                  | 1.2          |\n",
            "|    value_loss           | 0.0982       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 252          |\n",
            "|    time_elapsed         | 1401         |\n",
            "|    total_timesteps      | 516096       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009413591 |\n",
            "|    clip_fraction        | 0.00688      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.19        |\n",
            "|    explained_variance   | 1.53e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.305        |\n",
            "|    n_updates            | 2510         |\n",
            "|    policy_gradient_loss | -0.000372    |\n",
            "|    reward               | 0.009038173  |\n",
            "|    std                  | 1.21         |\n",
            "|    value_loss           | 0.669        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 253          |\n",
            "|    time_elapsed         | 1406         |\n",
            "|    total_timesteps      | 518144       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035237018 |\n",
            "|    clip_fraction        | 0.0043       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.2         |\n",
            "|    explained_variance   | 6.51e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.424        |\n",
            "|    n_updates            | 2520         |\n",
            "|    policy_gradient_loss | -4.21e-05    |\n",
            "|    reward               | -0.48727793  |\n",
            "|    std                  | 1.21         |\n",
            "|    value_loss           | 0.706        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 254         |\n",
            "|    time_elapsed         | 1411        |\n",
            "|    total_timesteps      | 520192      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004927829 |\n",
            "|    clip_fraction        | 0.0292      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.19       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0982      |\n",
            "|    n_updates            | 2530        |\n",
            "|    policy_gradient_loss | -0.00237    |\n",
            "|    reward               | 0.11465655  |\n",
            "|    std                  | 1.21        |\n",
            "|    value_loss           | 0.279       |\n",
            "-----------------------------------------\n",
            "day: 2896, episode: 180\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -339637.31\n",
            "total_reward: -349637.31\n",
            "total_cost: 616.28\n",
            "total_trades: 3098\n",
            "Sharpe: -0.137\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 255          |\n",
            "|    time_elapsed         | 1415         |\n",
            "|    total_timesteps      | 522240       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033711884 |\n",
            "|    clip_fraction        | 0.0115       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.2         |\n",
            "|    explained_variance   | 6.15e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.512        |\n",
            "|    n_updates            | 2540         |\n",
            "|    policy_gradient_loss | -0.00109     |\n",
            "|    reward               | -0.027894748 |\n",
            "|    std                  | 1.22         |\n",
            "|    value_loss           | 0.709        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 369          |\n",
            "|    iterations           | 256          |\n",
            "|    time_elapsed         | 1420         |\n",
            "|    total_timesteps      | 524288       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034732572 |\n",
            "|    clip_fraction        | 0.0185       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.2         |\n",
            "|    explained_variance   | 3.28e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.322        |\n",
            "|    n_updates            | 2550         |\n",
            "|    policy_gradient_loss | -0.000896    |\n",
            "|    reward               | 0.8427819    |\n",
            "|    std                  | 1.22         |\n",
            "|    value_loss           | 0.882        |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 369        |\n",
            "|    iterations           | 257        |\n",
            "|    time_elapsed         | 1425       |\n",
            "|    total_timesteps      | 526336     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00365084 |\n",
            "|    clip_fraction        | 0.0234     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.21      |\n",
            "|    explained_variance   | -1.19e-07  |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 0.613      |\n",
            "|    n_updates            | 2560       |\n",
            "|    policy_gradient_loss | -0.00193   |\n",
            "|    reward               | -0.4085227 |\n",
            "|    std                  | 1.23       |\n",
            "|    value_loss           | 1.05       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 369         |\n",
            "|    iterations           | 258         |\n",
            "|    time_elapsed         | 1430        |\n",
            "|    total_timesteps      | 528384      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003990722 |\n",
            "|    clip_fraction        | 0.0308      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.22       |\n",
            "|    explained_variance   | 0.000108    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0297      |\n",
            "|    n_updates            | 2570        |\n",
            "|    policy_gradient_loss | -0.00113    |\n",
            "|    reward               | -0.03506576 |\n",
            "|    std                  | 1.23        |\n",
            "|    value_loss           | 0.129       |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 369           |\n",
            "|    iterations           | 259           |\n",
            "|    time_elapsed         | 1435          |\n",
            "|    total_timesteps      | 530432        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.003907469   |\n",
            "|    clip_fraction        | 0.0328        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.22         |\n",
            "|    explained_variance   | 2.46e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.467         |\n",
            "|    n_updates            | 2580          |\n",
            "|    policy_gradient_loss | -0.00165      |\n",
            "|    reward               | -0.0004573799 |\n",
            "|    std                  | 1.24          |\n",
            "|    value_loss           | 1.06          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 369          |\n",
            "|    iterations           | 260          |\n",
            "|    time_elapsed         | 1439         |\n",
            "|    total_timesteps      | 532480       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060449746 |\n",
            "|    clip_fraction        | 0.0505       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.22        |\n",
            "|    explained_variance   | 5.38e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.573        |\n",
            "|    n_updates            | 2590         |\n",
            "|    policy_gradient_loss | -0.00332     |\n",
            "|    reward               | 0.9875524    |\n",
            "|    std                  | 1.23         |\n",
            "|    value_loss           | 1.44         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 369         |\n",
            "|    iterations           | 261         |\n",
            "|    time_elapsed         | 1444        |\n",
            "|    total_timesteps      | 534528      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005064221 |\n",
            "|    clip_fraction        | 0.0276      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.23       |\n",
            "|    explained_variance   | 5.96e-08    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.121       |\n",
            "|    n_updates            | 2600        |\n",
            "|    policy_gradient_loss | -0.00155    |\n",
            "|    reward               | 0.19541796  |\n",
            "|    std                  | 1.24        |\n",
            "|    value_loss           | 0.36        |\n",
            "-----------------------------------------\n",
            "day: 2896, episode: 185\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -485096.80\n",
            "total_reward: -495096.80\n",
            "total_cost: 851.14\n",
            "total_trades: 3426\n",
            "Sharpe: -0.209\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 370           |\n",
            "|    iterations           | 262           |\n",
            "|    time_elapsed         | 1449          |\n",
            "|    total_timesteps      | 536576        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.002987776   |\n",
            "|    clip_fraction        | 0.0306        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.23         |\n",
            "|    explained_variance   | 3.22e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.596         |\n",
            "|    n_updates            | 2610          |\n",
            "|    policy_gradient_loss | -0.00172      |\n",
            "|    reward               | 0.00013871727 |\n",
            "|    std                  | 1.24          |\n",
            "|    value_loss           | 1.17          |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 370         |\n",
            "|    iterations           | 263         |\n",
            "|    time_elapsed         | 1454        |\n",
            "|    total_timesteps      | 538624      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006826008 |\n",
            "|    clip_fraction        | 0.0378      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.23       |\n",
            "|    explained_variance   | 3.97e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.722       |\n",
            "|    n_updates            | 2620        |\n",
            "|    policy_gradient_loss | -0.00256    |\n",
            "|    reward               | -0.41393942 |\n",
            "|    std                  | 1.23        |\n",
            "|    value_loss           | 1.73        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 370          |\n",
            "|    iterations           | 264          |\n",
            "|    time_elapsed         | 1459         |\n",
            "|    total_timesteps      | 540672       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027158968 |\n",
            "|    clip_fraction        | 0.011        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.23        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.368        |\n",
            "|    n_updates            | 2630         |\n",
            "|    policy_gradient_loss | -0.000804    |\n",
            "|    reward               | -0.1556783   |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 0.91         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 370          |\n",
            "|    iterations           | 265          |\n",
            "|    time_elapsed         | 1464         |\n",
            "|    total_timesteps      | 542720       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034390604 |\n",
            "|    clip_fraction        | 0.0217       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.24        |\n",
            "|    explained_variance   | 3.31e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.334        |\n",
            "|    n_updates            | 2640         |\n",
            "|    policy_gradient_loss | -0.0009      |\n",
            "|    reward               | 0.021794971  |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 0.567        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 370           |\n",
            "|    iterations           | 266           |\n",
            "|    time_elapsed         | 1469          |\n",
            "|    total_timesteps      | 544768        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0024668803  |\n",
            "|    clip_fraction        | 0.00649       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.25         |\n",
            "|    explained_variance   | 3.85e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.86          |\n",
            "|    n_updates            | 2650          |\n",
            "|    policy_gradient_loss | -0.000372     |\n",
            "|    reward               | -0.0036084978 |\n",
            "|    std                  | 1.25          |\n",
            "|    value_loss           | 1.6           |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 370          |\n",
            "|    iterations           | 267          |\n",
            "|    time_elapsed         | 1474         |\n",
            "|    total_timesteps      | 546816       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022439226 |\n",
            "|    clip_fraction        | 0.00498      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.25        |\n",
            "|    explained_variance   | 3.71e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.973        |\n",
            "|    n_updates            | 2660         |\n",
            "|    policy_gradient_loss | -0.000409    |\n",
            "|    reward               | -0.049369097 |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 2.07         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 370          |\n",
            "|    iterations           | 268          |\n",
            "|    time_elapsed         | 1479         |\n",
            "|    total_timesteps      | 548864       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040888926 |\n",
            "|    clip_fraction        | 0.0151       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.24        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.112        |\n",
            "|    n_updates            | 2670         |\n",
            "|    policy_gradient_loss | -0.00125     |\n",
            "|    reward               | -0.17641748  |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 0.236        |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 190\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -618222.19\n",
            "total_reward: -628222.19\n",
            "total_cost: 751.89\n",
            "total_trades: 3742\n",
            "Sharpe: -0.263\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 371          |\n",
            "|    iterations           | 269          |\n",
            "|    time_elapsed         | 1484         |\n",
            "|    total_timesteps      | 550912       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0068228776 |\n",
            "|    clip_fraction        | 0.0641       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.24        |\n",
            "|    explained_variance   | 3.35e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.892        |\n",
            "|    n_updates            | 2680         |\n",
            "|    policy_gradient_loss | -0.00482     |\n",
            "|    reward               | -0.013253766 |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 1.98         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 371          |\n",
            "|    iterations           | 270          |\n",
            "|    time_elapsed         | 1489         |\n",
            "|    total_timesteps      | 552960       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032961285 |\n",
            "|    clip_fraction        | 0.0119       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.24        |\n",
            "|    explained_variance   | 4.16e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.42         |\n",
            "|    n_updates            | 2690         |\n",
            "|    policy_gradient_loss | -0.000944    |\n",
            "|    reward               | 2.0366347    |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 2.71         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 371          |\n",
            "|    iterations           | 271          |\n",
            "|    time_elapsed         | 1494         |\n",
            "|    total_timesteps      | 555008       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039396435 |\n",
            "|    clip_fraction        | 0.0406       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.24        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.452        |\n",
            "|    n_updates            | 2700         |\n",
            "|    policy_gradient_loss | -0.00244     |\n",
            "|    reward               | -0.10833446  |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 1.47         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 371          |\n",
            "|    iterations           | 272          |\n",
            "|    time_elapsed         | 1499         |\n",
            "|    total_timesteps      | 557056       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.00396189   |\n",
            "|    clip_fraction        | 0.021        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.24        |\n",
            "|    explained_variance   | 6.45e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.602        |\n",
            "|    n_updates            | 2710         |\n",
            "|    policy_gradient_loss | -0.00169     |\n",
            "|    reward               | 0.0082638245 |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 1.73         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 371         |\n",
            "|    iterations           | 273         |\n",
            "|    time_elapsed         | 1506        |\n",
            "|    total_timesteps      | 559104      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004363414 |\n",
            "|    clip_fraction        | 0.0286      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.24       |\n",
            "|    explained_variance   | 4.65e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.72        |\n",
            "|    n_updates            | 2720        |\n",
            "|    policy_gradient_loss | -0.00204    |\n",
            "|    reward               | 0.29185775  |\n",
            "|    std                  | 1.24        |\n",
            "|    value_loss           | 2.78        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 370         |\n",
            "|    iterations           | 274         |\n",
            "|    time_elapsed         | 1513        |\n",
            "|    total_timesteps      | 561152      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004366355 |\n",
            "|    clip_fraction        | 0.0223      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.24       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.19        |\n",
            "|    n_updates            | 2730        |\n",
            "|    policy_gradient_loss | -0.00106    |\n",
            "|    reward               | -0.1373827  |\n",
            "|    std                  | 1.23        |\n",
            "|    value_loss           | 2.15        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 370          |\n",
            "|    iterations           | 275          |\n",
            "|    time_elapsed         | 1519         |\n",
            "|    total_timesteps      | 563200       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048718737 |\n",
            "|    clip_fraction        | 0.0336       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.23        |\n",
            "|    explained_variance   | 2.35e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0606       |\n",
            "|    n_updates            | 2740         |\n",
            "|    policy_gradient_loss | -0.00224     |\n",
            "|    reward               | 0.19595797   |\n",
            "|    std                  | 1.23         |\n",
            "|    value_loss           | 0.256        |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 195\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -568104.99\n",
            "total_reward: -578104.99\n",
            "total_cost: 773.11\n",
            "total_trades: 3764\n",
            "Sharpe: 0.560\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 370          |\n",
            "|    iterations           | 276          |\n",
            "|    time_elapsed         | 1525         |\n",
            "|    total_timesteps      | 565248       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045452616 |\n",
            "|    clip_fraction        | 0.0151       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.23        |\n",
            "|    explained_variance   | 3.53e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.7          |\n",
            "|    n_updates            | 2750         |\n",
            "|    policy_gradient_loss | -0.000838    |\n",
            "|    reward               | 0.07832231   |\n",
            "|    std                  | 1.23         |\n",
            "|    value_loss           | 2.96         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 370          |\n",
            "|    iterations           | 277          |\n",
            "|    time_elapsed         | 1532         |\n",
            "|    total_timesteps      | 567296       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034827283 |\n",
            "|    clip_fraction        | 0.0154       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.23        |\n",
            "|    explained_variance   | 4.95e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.22         |\n",
            "|    n_updates            | 2760         |\n",
            "|    policy_gradient_loss | -0.00076     |\n",
            "|    reward               | 0.032906055  |\n",
            "|    std                  | 1.23         |\n",
            "|    value_loss           | 2.46         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 369          |\n",
            "|    iterations           | 278          |\n",
            "|    time_elapsed         | 1539         |\n",
            "|    total_timesteps      | 569344       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019189275 |\n",
            "|    clip_fraction        | 0.00405      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.22        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.153        |\n",
            "|    n_updates            | 2770         |\n",
            "|    policy_gradient_loss | -0.000469    |\n",
            "|    reward               | 0.23363252   |\n",
            "|    std                  | 1.22         |\n",
            "|    value_loss           | 0.679        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 369          |\n",
            "|    iterations           | 279          |\n",
            "|    time_elapsed         | 1545         |\n",
            "|    total_timesteps      | 571392       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051705786 |\n",
            "|    clip_fraction        | 0.0178       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.21        |\n",
            "|    explained_variance   | 4.26e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.905        |\n",
            "|    n_updates            | 2780         |\n",
            "|    policy_gradient_loss | -0.00102     |\n",
            "|    reward               | -0.03373373  |\n",
            "|    std                  | 1.21         |\n",
            "|    value_loss           | 2.19         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 369         |\n",
            "|    iterations           | 280         |\n",
            "|    time_elapsed         | 1551        |\n",
            "|    total_timesteps      | 573440      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006217013 |\n",
            "|    clip_fraction        | 0.0649      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.2        |\n",
            "|    explained_variance   | 3.96e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.74        |\n",
            "|    n_updates            | 2790        |\n",
            "|    policy_gradient_loss | -0.00475    |\n",
            "|    reward               | 0.77592057  |\n",
            "|    std                  | 1.21        |\n",
            "|    value_loss           | 2.91        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 369         |\n",
            "|    iterations           | 281         |\n",
            "|    time_elapsed         | 1557        |\n",
            "|    total_timesteps      | 575488      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006555801 |\n",
            "|    clip_fraction        | 0.0281      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.19       |\n",
            "|    explained_variance   | 1.19e-07    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.73        |\n",
            "|    n_updates            | 2800        |\n",
            "|    policy_gradient_loss | -0.000965   |\n",
            "|    reward               | 0.26581097  |\n",
            "|    std                  | 1.2         |\n",
            "|    value_loss           | 2.5         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 369          |\n",
            "|    iterations           | 282          |\n",
            "|    time_elapsed         | 1563         |\n",
            "|    total_timesteps      | 577536       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052608494 |\n",
            "|    clip_fraction        | 0.0563       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.18        |\n",
            "|    explained_variance   | 4.71e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.152        |\n",
            "|    n_updates            | 2810         |\n",
            "|    policy_gradient_loss | -0.00385     |\n",
            "|    reward               | 0.029270303  |\n",
            "|    std                  | 1.2          |\n",
            "|    value_loss           | 0.599        |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 200\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -663200.88\n",
            "total_reward: -673200.88\n",
            "total_cost: 802.19\n",
            "total_trades: 4198\n",
            "Sharpe: 0.383\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 369           |\n",
            "|    iterations           | 283           |\n",
            "|    time_elapsed         | 1570          |\n",
            "|    total_timesteps      | 579584        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0017095653  |\n",
            "|    clip_fraction        | 0.0191        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.18         |\n",
            "|    explained_variance   | 3.2e-05       |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 1.72          |\n",
            "|    n_updates            | 2820          |\n",
            "|    policy_gradient_loss | -0.00144      |\n",
            "|    reward               | -0.0022773326 |\n",
            "|    std                  | 1.2           |\n",
            "|    value_loss           | 3.16          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 284          |\n",
            "|    time_elapsed         | 1576         |\n",
            "|    total_timesteps      | 581632       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040381914 |\n",
            "|    clip_fraction        | 0.0437       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.19        |\n",
            "|    explained_variance   | 3.63e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.77         |\n",
            "|    n_updates            | 2830         |\n",
            "|    policy_gradient_loss | -0.00222     |\n",
            "|    reward               | -0.29273617  |\n",
            "|    std                  | 1.2          |\n",
            "|    value_loss           | 3.31         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 285         |\n",
            "|    time_elapsed         | 1582        |\n",
            "|    total_timesteps      | 583680      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006866188 |\n",
            "|    clip_fraction        | 0.0611      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.19       |\n",
            "|    explained_variance   | 1.19e-07    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.259       |\n",
            "|    n_updates            | 2840        |\n",
            "|    policy_gradient_loss | -0.00351    |\n",
            "|    reward               | 0.090172075 |\n",
            "|    std                  | 1.2         |\n",
            "|    value_loss           | 0.66        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 286          |\n",
            "|    time_elapsed         | 1589         |\n",
            "|    total_timesteps      | 585728       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060210503 |\n",
            "|    clip_fraction        | 0.0578       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.18        |\n",
            "|    explained_variance   | 3.39e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.58         |\n",
            "|    n_updates            | 2850         |\n",
            "|    policy_gradient_loss | -0.00363     |\n",
            "|    reward               | -0.014785207 |\n",
            "|    std                  | 1.2          |\n",
            "|    value_loss           | 3.86         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 368         |\n",
            "|    iterations           | 287         |\n",
            "|    time_elapsed         | 1596        |\n",
            "|    total_timesteps      | 587776      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006565051 |\n",
            "|    clip_fraction        | 0.0578      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.17       |\n",
            "|    explained_variance   | 5.09e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.99        |\n",
            "|    n_updates            | 2860        |\n",
            "|    policy_gradient_loss | -0.00314    |\n",
            "|    reward               | -0.6002203  |\n",
            "|    std                  | 1.19        |\n",
            "|    value_loss           | 4.89        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 368          |\n",
            "|    iterations           | 288          |\n",
            "|    time_elapsed         | 1602         |\n",
            "|    total_timesteps      | 589824       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040922565 |\n",
            "|    clip_fraction        | 0.0316       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.17        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.6          |\n",
            "|    n_updates            | 2870         |\n",
            "|    policy_gradient_loss | -0.00166     |\n",
            "|    reward               | -0.28884125  |\n",
            "|    std                  | 1.19         |\n",
            "|    value_loss           | 2.48         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 367          |\n",
            "|    iterations           | 289          |\n",
            "|    time_elapsed         | 1608         |\n",
            "|    total_timesteps      | 591872       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045692567 |\n",
            "|    clip_fraction        | 0.0263       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.17        |\n",
            "|    explained_variance   | 5.37e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.2          |\n",
            "|    n_updates            | 2880         |\n",
            "|    policy_gradient_loss | -0.00123     |\n",
            "|    reward               | -0.032960035 |\n",
            "|    std                  | 1.19         |\n",
            "|    value_loss           | 2.07         |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 205\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -753106.06\n",
            "total_reward: -763106.06\n",
            "total_cost: 839.22\n",
            "total_trades: 4460\n",
            "Sharpe: 0.406\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 367          |\n",
            "|    iterations           | 290          |\n",
            "|    time_elapsed         | 1614         |\n",
            "|    total_timesteps      | 593920       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061296048 |\n",
            "|    clip_fraction        | 0.0275       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.17        |\n",
            "|    explained_variance   | 3.06e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.19         |\n",
            "|    n_updates            | 2890         |\n",
            "|    policy_gradient_loss | -0.00162     |\n",
            "|    reward               | 0.0010621811 |\n",
            "|    std                  | 1.19         |\n",
            "|    value_loss           | 3.98         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 367          |\n",
            "|    iterations           | 291          |\n",
            "|    time_elapsed         | 1621         |\n",
            "|    total_timesteps      | 595968       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043934523 |\n",
            "|    clip_fraction        | 0.025        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.16        |\n",
            "|    explained_variance   | 3e-05        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.1          |\n",
            "|    n_updates            | 2900         |\n",
            "|    policy_gradient_loss | -0.00208     |\n",
            "|    reward               | 0.92416686   |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 4.08         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 367          |\n",
            "|    iterations           | 292          |\n",
            "|    time_elapsed         | 1627         |\n",
            "|    total_timesteps      | 598016       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050737336 |\n",
            "|    clip_fraction        | 0.0207       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.16        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.129        |\n",
            "|    n_updates            | 2910         |\n",
            "|    policy_gradient_loss | -0.000654    |\n",
            "|    reward               | -1.0892701   |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 0.312        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 367          |\n",
            "|    iterations           | 293          |\n",
            "|    time_elapsed         | 1634         |\n",
            "|    total_timesteps      | 600064       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039772554 |\n",
            "|    clip_fraction        | 0.00771      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.16        |\n",
            "|    explained_variance   | 3.2e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.75         |\n",
            "|    n_updates            | 2920         |\n",
            "|    policy_gradient_loss | -0.000375    |\n",
            "|    reward               | -0.04004483  |\n",
            "|    std                  | 1.19         |\n",
            "|    value_loss           | 3.2          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 367          |\n",
            "|    iterations           | 294          |\n",
            "|    time_elapsed         | 1640         |\n",
            "|    total_timesteps      | 602112       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039451607 |\n",
            "|    clip_fraction        | 0.0145       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.17        |\n",
            "|    explained_variance   | 3.3e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.79         |\n",
            "|    n_updates            | 2930         |\n",
            "|    policy_gradient_loss | -0.000474    |\n",
            "|    reward               | 0.3742977    |\n",
            "|    std                  | 1.19         |\n",
            "|    value_loss           | 3.53         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 295         |\n",
            "|    time_elapsed         | 1646        |\n",
            "|    total_timesteps      | 604160      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002687097 |\n",
            "|    clip_fraction        | 0.0062      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.17       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.553       |\n",
            "|    n_updates            | 2940        |\n",
            "|    policy_gradient_loss | -0.00038    |\n",
            "|    reward               | -0.10919377 |\n",
            "|    std                  | 1.19        |\n",
            "|    value_loss           | 1.17        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 366          |\n",
            "|    iterations           | 296          |\n",
            "|    time_elapsed         | 1653         |\n",
            "|    total_timesteps      | 606208       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004945006  |\n",
            "|    clip_fraction        | 0.0485       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.17        |\n",
            "|    explained_variance   | 3.24e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.18         |\n",
            "|    n_updates            | 2950         |\n",
            "|    policy_gradient_loss | -0.00202     |\n",
            "|    reward               | -0.017752828 |\n",
            "|    std                  | 1.19         |\n",
            "|    value_loss           | 3.15         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 366          |\n",
            "|    iterations           | 297          |\n",
            "|    time_elapsed         | 1660         |\n",
            "|    total_timesteps      | 608256       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033299779 |\n",
            "|    clip_fraction        | 0.0214       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.16        |\n",
            "|    explained_variance   | 3.47e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.72         |\n",
            "|    n_updates            | 2960         |\n",
            "|    policy_gradient_loss | -0.00174     |\n",
            "|    reward               | 0.82651126   |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 4.02         |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 210\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -785835.01\n",
            "total_reward: -795835.01\n",
            "total_cost: 882.52\n",
            "total_trades: 4296\n",
            "Sharpe: 0.282\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 366         |\n",
            "|    iterations           | 298         |\n",
            "|    time_elapsed         | 1666        |\n",
            "|    total_timesteps      | 610304      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003083595 |\n",
            "|    clip_fraction        | 0.00396     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.15       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.72        |\n",
            "|    n_updates            | 2970        |\n",
            "|    policy_gradient_loss | -0.000342   |\n",
            "|    reward               | 0.27940506  |\n",
            "|    std                  | 1.18        |\n",
            "|    value_loss           | 4.07        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 299          |\n",
            "|    time_elapsed         | 1673         |\n",
            "|    total_timesteps      | 612352       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047930293 |\n",
            "|    clip_fraction        | 0.0229       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.15        |\n",
            "|    explained_variance   | 7.4e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.256        |\n",
            "|    n_updates            | 2980         |\n",
            "|    policy_gradient_loss | -0.00132     |\n",
            "|    reward               | 0.075506166  |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 0.716        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 365         |\n",
            "|    iterations           | 300         |\n",
            "|    time_elapsed         | 1679        |\n",
            "|    total_timesteps      | 614400      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005478429 |\n",
            "|    clip_fraction        | 0.0139      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.14       |\n",
            "|    explained_variance   | 2.37e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.24        |\n",
            "|    n_updates            | 2990        |\n",
            "|    policy_gradient_loss | -0.000595   |\n",
            "|    reward               | 0.016407765 |\n",
            "|    std                  | 1.17        |\n",
            "|    value_loss           | 4.13        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 301          |\n",
            "|    time_elapsed         | 1685         |\n",
            "|    total_timesteps      | 616448       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043987012 |\n",
            "|    clip_fraction        | 0.0333       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.14        |\n",
            "|    explained_variance   | 4.27e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.9          |\n",
            "|    n_updates            | 3000         |\n",
            "|    policy_gradient_loss | -0.00191     |\n",
            "|    reward               | -0.9380538   |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 4.01         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 302          |\n",
            "|    time_elapsed         | 1691         |\n",
            "|    total_timesteps      | 618496       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017528215 |\n",
            "|    clip_fraction        | 0.00742      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.15        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.45         |\n",
            "|    n_updates            | 3010         |\n",
            "|    policy_gradient_loss | -3.13e-05    |\n",
            "|    reward               | 0.30807215   |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 0.763        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 303          |\n",
            "|    time_elapsed         | 1698         |\n",
            "|    total_timesteps      | 620544       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042802207 |\n",
            "|    clip_fraction        | 0.0735       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.16        |\n",
            "|    explained_variance   | 3.52e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.88         |\n",
            "|    n_updates            | 3020         |\n",
            "|    policy_gradient_loss | -0.00398     |\n",
            "|    reward               | -0.027725538 |\n",
            "|    std                  | 1.19         |\n",
            "|    value_loss           | 3.55         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 304          |\n",
            "|    time_elapsed         | 1704         |\n",
            "|    total_timesteps      | 622592       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022342026 |\n",
            "|    clip_fraction        | 0.0141       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.16        |\n",
            "|    explained_variance   | 3.99e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.42         |\n",
            "|    n_updates            | 3030         |\n",
            "|    policy_gradient_loss | -0.000776    |\n",
            "|    reward               | 0.20734937   |\n",
            "|    std                  | 1.19         |\n",
            "|    value_loss           | 3.7          |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 215\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -696335.23\n",
            "total_reward: -706335.23\n",
            "total_cost: 842.43\n",
            "total_trades: 4238\n",
            "Sharpe: -0.185\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 365          |\n",
            "|    iterations           | 305          |\n",
            "|    time_elapsed         | 1711         |\n",
            "|    total_timesteps      | 624640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011460738 |\n",
            "|    clip_fraction        | 0.00122      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.18        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.7          |\n",
            "|    n_updates            | 3040         |\n",
            "|    policy_gradient_loss | -0.00025     |\n",
            "|    reward               | 0.15007332   |\n",
            "|    std                  | 1.21         |\n",
            "|    value_loss           | 2.52         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 306          |\n",
            "|    time_elapsed         | 1717         |\n",
            "|    total_timesteps      | 626688       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031266676 |\n",
            "|    clip_fraction        | 0.0108       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.2         |\n",
            "|    explained_variance   | 3.7e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.475        |\n",
            "|    n_updates            | 3050         |\n",
            "|    policy_gradient_loss | -0.000348    |\n",
            "|    reward               | -0.020175276 |\n",
            "|    std                  | 1.21         |\n",
            "|    value_loss           | 1.42         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 364           |\n",
            "|    iterations           | 307           |\n",
            "|    time_elapsed         | 1723          |\n",
            "|    total_timesteps      | 628736        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.004708139   |\n",
            "|    clip_fraction        | 0.03          |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.2          |\n",
            "|    explained_variance   | 3.57e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 1.79          |\n",
            "|    n_updates            | 3060          |\n",
            "|    policy_gradient_loss | -0.00191      |\n",
            "|    reward               | -0.0011904251 |\n",
            "|    std                  | 1.21          |\n",
            "|    value_loss           | 3.68          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 308          |\n",
            "|    time_elapsed         | 1730         |\n",
            "|    total_timesteps      | 630784       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058454643 |\n",
            "|    clip_fraction        | 0.0338       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.21        |\n",
            "|    explained_variance   | 4.6e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.05         |\n",
            "|    n_updates            | 3070         |\n",
            "|    policy_gradient_loss | -0.00195     |\n",
            "|    reward               | -0.18142615  |\n",
            "|    std                  | 1.22         |\n",
            "|    value_loss           | 3.85         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 309          |\n",
            "|    time_elapsed         | 1736         |\n",
            "|    total_timesteps      | 632832       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028868834 |\n",
            "|    clip_fraction        | 0.0222       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.21        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.115        |\n",
            "|    n_updates            | 3080         |\n",
            "|    policy_gradient_loss | -0.00103     |\n",
            "|    reward               | 0.0365883    |\n",
            "|    std                  | 1.22         |\n",
            "|    value_loss           | 0.518        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 310          |\n",
            "|    time_elapsed         | 1742         |\n",
            "|    total_timesteps      | 634880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037152905 |\n",
            "|    clip_fraction        | 0.00781      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.21        |\n",
            "|    explained_variance   | 3.96e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.46         |\n",
            "|    n_updates            | 3090         |\n",
            "|    policy_gradient_loss | -0.000149    |\n",
            "|    reward               | -0.028362578 |\n",
            "|    std                  | 1.22         |\n",
            "|    value_loss           | 4.64         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 311          |\n",
            "|    time_elapsed         | 1748         |\n",
            "|    total_timesteps      | 636928       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022010093 |\n",
            "|    clip_fraction        | 0.00757      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.22        |\n",
            "|    explained_variance   | 4.16e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.52         |\n",
            "|    n_updates            | 3100         |\n",
            "|    policy_gradient_loss | -0.000359    |\n",
            "|    reward               | 0.951906     |\n",
            "|    std                  | 1.23         |\n",
            "|    value_loss           | 3.53         |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 220\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -739683.30\n",
            "total_reward: -749683.30\n",
            "total_cost: 797.38\n",
            "total_trades: 4196\n",
            "Sharpe: 0.613\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 312          |\n",
            "|    time_elapsed         | 1754         |\n",
            "|    total_timesteps      | 638976       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049586045 |\n",
            "|    clip_fraction        | 0.0313       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.23        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.472        |\n",
            "|    n_updates            | 3110         |\n",
            "|    policy_gradient_loss | -0.00236     |\n",
            "|    reward               | -0.16433708  |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 1.1          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 364          |\n",
            "|    iterations           | 313          |\n",
            "|    time_elapsed         | 1760         |\n",
            "|    total_timesteps      | 641024       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005595811  |\n",
            "|    clip_fraction        | 0.034        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.23        |\n",
            "|    explained_variance   | 5.19e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.04         |\n",
            "|    n_updates            | 3120         |\n",
            "|    policy_gradient_loss | -0.00229     |\n",
            "|    reward               | -0.014913324 |\n",
            "|    std                  | 1.23         |\n",
            "|    value_loss           | 2.63         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 363          |\n",
            "|    iterations           | 314          |\n",
            "|    time_elapsed         | 1766         |\n",
            "|    total_timesteps      | 643072       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044171354 |\n",
            "|    clip_fraction        | 0.0126       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.22        |\n",
            "|    explained_variance   | 3.92e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.7          |\n",
            "|    n_updates            | 3130         |\n",
            "|    policy_gradient_loss | -0.000715    |\n",
            "|    reward               | 0.65291953   |\n",
            "|    std                  | 1.22         |\n",
            "|    value_loss           | 3.67         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 363          |\n",
            "|    iterations           | 315          |\n",
            "|    time_elapsed         | 1773         |\n",
            "|    total_timesteps      | 645120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010989828 |\n",
            "|    clip_fraction        | 0.0082       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.21        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.31         |\n",
            "|    n_updates            | 3140         |\n",
            "|    policy_gradient_loss | -0.000133    |\n",
            "|    reward               | 0.12054248   |\n",
            "|    std                  | 1.22         |\n",
            "|    value_loss           | 4.36         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 363          |\n",
            "|    iterations           | 316          |\n",
            "|    time_elapsed         | 1779         |\n",
            "|    total_timesteps      | 647168       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052975984 |\n",
            "|    clip_fraction        | 0.0473       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.21        |\n",
            "|    explained_variance   | -4.89e-06    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.133        |\n",
            "|    n_updates            | 3150         |\n",
            "|    policy_gradient_loss | -0.00255     |\n",
            "|    reward               | 0.15472667   |\n",
            "|    std                  | 1.22         |\n",
            "|    value_loss           | 0.5          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 363          |\n",
            "|    iterations           | 317          |\n",
            "|    time_elapsed         | 1785         |\n",
            "|    total_timesteps      | 649216       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037598435 |\n",
            "|    clip_fraction        | 0.00796      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.2         |\n",
            "|    explained_variance   | 3.64e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.79         |\n",
            "|    n_updates            | 3160         |\n",
            "|    policy_gradient_loss | -0.000607    |\n",
            "|    reward               | 0.042706557  |\n",
            "|    std                  | 1.21         |\n",
            "|    value_loss           | 3.56         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 363         |\n",
            "|    iterations           | 318         |\n",
            "|    time_elapsed         | 1792        |\n",
            "|    total_timesteps      | 651264      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004655749 |\n",
            "|    clip_fraction        | 0.0243      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.2        |\n",
            "|    explained_variance   | 4.28e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.66        |\n",
            "|    n_updates            | 3170        |\n",
            "|    policy_gradient_loss | -0.00118    |\n",
            "|    reward               | -0.3554862  |\n",
            "|    std                  | 1.21        |\n",
            "|    value_loss           | 3.17        |\n",
            "-----------------------------------------\n",
            "day: 2896, episode: 225\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -708411.10\n",
            "total_reward: -718411.10\n",
            "total_cost: 859.88\n",
            "total_trades: 4298\n",
            "Sharpe: -0.380\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 363         |\n",
            "|    iterations           | 319         |\n",
            "|    time_elapsed         | 1799        |\n",
            "|    total_timesteps      | 653312      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005164778 |\n",
            "|    clip_fraction        | 0.0355      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.19       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.488       |\n",
            "|    n_updates            | 3180        |\n",
            "|    policy_gradient_loss | -0.0018     |\n",
            "|    reward               | -0.07811784 |\n",
            "|    std                  | 1.21        |\n",
            "|    value_loss           | 0.895       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 362          |\n",
            "|    iterations           | 320          |\n",
            "|    time_elapsed         | 1805         |\n",
            "|    total_timesteps      | 655360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036485575 |\n",
            "|    clip_fraction        | 0.00249      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.18        |\n",
            "|    explained_variance   | 3.88e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.19         |\n",
            "|    n_updates            | 3190         |\n",
            "|    policy_gradient_loss | -0.000641    |\n",
            "|    reward               | 0.033374667  |\n",
            "|    std                  | 1.2          |\n",
            "|    value_loss           | 3.1          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 362          |\n",
            "|    iterations           | 321          |\n",
            "|    time_elapsed         | 1811         |\n",
            "|    total_timesteps      | 657408       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035278238 |\n",
            "|    clip_fraction        | 0.0146       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.17        |\n",
            "|    explained_variance   | 4.11e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.58         |\n",
            "|    n_updates            | 3200         |\n",
            "|    policy_gradient_loss | -0.00148     |\n",
            "|    reward               | -0.23323296  |\n",
            "|    std                  | 1.2          |\n",
            "|    value_loss           | 3.89         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 362         |\n",
            "|    iterations           | 322         |\n",
            "|    time_elapsed         | 1818        |\n",
            "|    total_timesteps      | 659456      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004978552 |\n",
            "|    clip_fraction        | 0.0291      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.17       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.31        |\n",
            "|    n_updates            | 3210        |\n",
            "|    policy_gradient_loss | -0.00152    |\n",
            "|    reward               | -0.40259957 |\n",
            "|    std                  | 1.2         |\n",
            "|    value_loss           | 2.73        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 362          |\n",
            "|    iterations           | 323          |\n",
            "|    time_elapsed         | 1824         |\n",
            "|    total_timesteps      | 661504       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019956655 |\n",
            "|    clip_fraction        | 0.00791      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.18        |\n",
            "|    explained_variance   | 5.66e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.733        |\n",
            "|    n_updates            | 3220         |\n",
            "|    policy_gradient_loss | -0.00107     |\n",
            "|    reward               | -0.06252155  |\n",
            "|    std                  | 1.22         |\n",
            "|    value_loss           | 1.5          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 362          |\n",
            "|    iterations           | 324          |\n",
            "|    time_elapsed         | 1831         |\n",
            "|    total_timesteps      | 663552       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024627838 |\n",
            "|    clip_fraction        | 0.00293      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.19        |\n",
            "|    explained_variance   | 3.37e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.92         |\n",
            "|    n_updates            | 3230         |\n",
            "|    policy_gradient_loss | -0.000103    |\n",
            "|    reward               | 0.020152528  |\n",
            "|    std                  | 1.22         |\n",
            "|    value_loss           | 4.08         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 362          |\n",
            "|    iterations           | 325          |\n",
            "|    time_elapsed         | 1837         |\n",
            "|    total_timesteps      | 665600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049733557 |\n",
            "|    clip_fraction        | 0.0189       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.2         |\n",
            "|    explained_variance   | 4.42e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.54         |\n",
            "|    n_updates            | 3240         |\n",
            "|    policy_gradient_loss | -0.00129     |\n",
            "|    reward               | -0.18370616  |\n",
            "|    std                  | 1.23         |\n",
            "|    value_loss           | 4.23         |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 230\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -749219.41\n",
            "total_reward: -759219.41\n",
            "total_cost: 884.76\n",
            "total_trades: 4368\n",
            "Sharpe: 0.348\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 362          |\n",
            "|    iterations           | 326          |\n",
            "|    time_elapsed         | 1844         |\n",
            "|    total_timesteps      | 667648       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061228517 |\n",
            "|    clip_fraction        | 0.0236       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.2         |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.185        |\n",
            "|    n_updates            | 3250         |\n",
            "|    policy_gradient_loss | -0.00255     |\n",
            "|    reward               | 0.26248845   |\n",
            "|    std                  | 1.22         |\n",
            "|    value_loss           | 0.517        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 327          |\n",
            "|    time_elapsed         | 1850         |\n",
            "|    total_timesteps      | 669696       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005098506  |\n",
            "|    clip_fraction        | 0.0307       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.21        |\n",
            "|    explained_variance   | 3.8e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.72         |\n",
            "|    n_updates            | 3260         |\n",
            "|    policy_gradient_loss | -0.00174     |\n",
            "|    reward               | -0.009566074 |\n",
            "|    std                  | 1.23         |\n",
            "|    value_loss           | 3.82         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 361         |\n",
            "|    iterations           | 328         |\n",
            "|    time_elapsed         | 1856        |\n",
            "|    total_timesteps      | 671744      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004244268 |\n",
            "|    clip_fraction        | 0.0225      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.22       |\n",
            "|    explained_variance   | 4.42e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.8         |\n",
            "|    n_updates            | 3270        |\n",
            "|    policy_gradient_loss | -0.00137    |\n",
            "|    reward               | 0.90100336  |\n",
            "|    std                  | 1.24        |\n",
            "|    value_loss           | 3.61        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 329          |\n",
            "|    time_elapsed         | 1863         |\n",
            "|    total_timesteps      | 673792       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028904872 |\n",
            "|    clip_fraction        | 0.0296       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.23        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.31         |\n",
            "|    n_updates            | 3280         |\n",
            "|    policy_gradient_loss | -0.00177     |\n",
            "|    reward               | -0.10907293  |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 2            |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 330          |\n",
            "|    time_elapsed         | 1869         |\n",
            "|    total_timesteps      | 675840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031340357 |\n",
            "|    clip_fraction        | 0.0126       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.25        |\n",
            "|    explained_variance   | 7.61e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.849        |\n",
            "|    n_updates            | 3290         |\n",
            "|    policy_gradient_loss | -0.00047     |\n",
            "|    reward               | -0.033217825 |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 1.83         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 331          |\n",
            "|    time_elapsed         | 1875         |\n",
            "|    total_timesteps      | 677888       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041224295 |\n",
            "|    clip_fraction        | 0.0237       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.25        |\n",
            "|    explained_variance   | 3.03e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.2          |\n",
            "|    n_updates            | 3300         |\n",
            "|    policy_gradient_loss | -0.0012      |\n",
            "|    reward               | 1.7471112    |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 2.67         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 332          |\n",
            "|    time_elapsed         | 1882         |\n",
            "|    total_timesteps      | 679936       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033255047 |\n",
            "|    clip_fraction        | 0.0262       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.24        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.02         |\n",
            "|    n_updates            | 3310         |\n",
            "|    policy_gradient_loss | -0.00109     |\n",
            "|    reward               | -0.52603495  |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 2.2          |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 235\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -650889.28\n",
            "total_reward: -660889.28\n",
            "total_cost: 876.89\n",
            "total_trades: 3726\n",
            "Sharpe: -0.109\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 361          |\n",
            "|    iterations           | 333          |\n",
            "|    time_elapsed         | 1888         |\n",
            "|    total_timesteps      | 681984       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020283265 |\n",
            "|    clip_fraction        | 0.00522      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.23        |\n",
            "|    explained_variance   | -0.000225    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.161        |\n",
            "|    n_updates            | 3320         |\n",
            "|    policy_gradient_loss | -0.000495    |\n",
            "|    reward               | 0.07261456   |\n",
            "|    std                  | 1.23         |\n",
            "|    value_loss           | 0.215        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 360         |\n",
            "|    iterations           | 334         |\n",
            "|    time_elapsed         | 1894        |\n",
            "|    total_timesteps      | 684032      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002496459 |\n",
            "|    clip_fraction        | 0.00566     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.21       |\n",
            "|    explained_variance   | 3.39e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.32        |\n",
            "|    n_updates            | 3330        |\n",
            "|    policy_gradient_loss | -2.96e-05   |\n",
            "|    reward               | 0.027318818 |\n",
            "|    std                  | 1.24        |\n",
            "|    value_loss           | 2.72        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 360          |\n",
            "|    iterations           | 335          |\n",
            "|    time_elapsed         | 1901         |\n",
            "|    total_timesteps      | 686080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027538587 |\n",
            "|    clip_fraction        | 0.0195       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.22        |\n",
            "|    explained_variance   | 5.3e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.01         |\n",
            "|    n_updates            | 3340         |\n",
            "|    policy_gradient_loss | -0.00105     |\n",
            "|    reward               | -0.1485588   |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 2.33         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 360          |\n",
            "|    iterations           | 336          |\n",
            "|    time_elapsed         | 1907         |\n",
            "|    total_timesteps      | 688128       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019067718 |\n",
            "|    clip_fraction        | 0.0169       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.23        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.307        |\n",
            "|    n_updates            | 3350         |\n",
            "|    policy_gradient_loss | -0.000868    |\n",
            "|    reward               | 0.19742416   |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 0.649        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 360          |\n",
            "|    iterations           | 337          |\n",
            "|    time_elapsed         | 1914         |\n",
            "|    total_timesteps      | 690176       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0064733597 |\n",
            "|    clip_fraction        | 0.0386       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.22        |\n",
            "|    explained_variance   | 2.4e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.16         |\n",
            "|    n_updates            | 3360         |\n",
            "|    policy_gradient_loss | -0.00125     |\n",
            "|    reward               | -0.01596044  |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 1.96         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 360         |\n",
            "|    iterations           | 338         |\n",
            "|    time_elapsed         | 1920        |\n",
            "|    total_timesteps      | 692224      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004904149 |\n",
            "|    clip_fraction        | 0.0351      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.23       |\n",
            "|    explained_variance   | 3.62e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.19        |\n",
            "|    n_updates            | 3370        |\n",
            "|    policy_gradient_loss | -0.00256    |\n",
            "|    reward               | 0.8539058   |\n",
            "|    std                  | 1.24        |\n",
            "|    value_loss           | 2.44        |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 359           |\n",
            "|    iterations           | 339           |\n",
            "|    time_elapsed         | 1929          |\n",
            "|    total_timesteps      | 694272        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00094740314 |\n",
            "|    clip_fraction        | 0.0109        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.24         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 1.4           |\n",
            "|    n_updates            | 3380          |\n",
            "|    policy_gradient_loss | -0.0012       |\n",
            "|    reward               | 0.18616292    |\n",
            "|    std                  | 1.26          |\n",
            "|    value_loss           | 2.66          |\n",
            "-------------------------------------------\n",
            "day: 2896, episode: 240\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -630598.99\n",
            "total_reward: -640598.99\n",
            "total_cost: 817.22\n",
            "total_trades: 3808\n",
            "Sharpe: 0.281\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 359         |\n",
            "|    iterations           | 340         |\n",
            "|    time_elapsed         | 1936        |\n",
            "|    total_timesteps      | 696320      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002866997 |\n",
            "|    clip_fraction        | 0.0225      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.26       |\n",
            "|    explained_variance   | 3.89e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.233       |\n",
            "|    n_updates            | 3390        |\n",
            "|    policy_gradient_loss | -0.00169    |\n",
            "|    reward               | 0.042165205 |\n",
            "|    std                  | 1.26        |\n",
            "|    value_loss           | 0.606       |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 359           |\n",
            "|    iterations           | 341           |\n",
            "|    time_elapsed         | 1942          |\n",
            "|    total_timesteps      | 698368        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.002667967   |\n",
            "|    clip_fraction        | 0.00283       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.26         |\n",
            "|    explained_variance   | 3.65e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 1.1           |\n",
            "|    n_updates            | 3400          |\n",
            "|    policy_gradient_loss | -0.000362     |\n",
            "|    reward               | -0.0027891276 |\n",
            "|    std                  | 1.25          |\n",
            "|    value_loss           | 2.97          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 359          |\n",
            "|    iterations           | 342          |\n",
            "|    time_elapsed         | 1948         |\n",
            "|    total_timesteps      | 700416       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049322853 |\n",
            "|    clip_fraction        | 0.0297       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.25        |\n",
            "|    explained_variance   | 4.86e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.1          |\n",
            "|    n_updates            | 3410         |\n",
            "|    policy_gradient_loss | -0.00175     |\n",
            "|    reward               | -0.3424685   |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 2.96         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 359         |\n",
            "|    iterations           | 343         |\n",
            "|    time_elapsed         | 1954        |\n",
            "|    total_timesteps      | 702464      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002686724 |\n",
            "|    clip_fraction        | 0.00581     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.25       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.238       |\n",
            "|    n_updates            | 3420        |\n",
            "|    policy_gradient_loss | -0.000527   |\n",
            "|    reward               | 0.14322402  |\n",
            "|    std                  | 1.25        |\n",
            "|    value_loss           | 0.603       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 359         |\n",
            "|    iterations           | 344         |\n",
            "|    time_elapsed         | 1960        |\n",
            "|    total_timesteps      | 704512      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004817481 |\n",
            "|    clip_fraction        | 0.0394      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.24       |\n",
            "|    explained_variance   | 2.44e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.5         |\n",
            "|    n_updates            | 3430        |\n",
            "|    policy_gradient_loss | -0.00276    |\n",
            "|    reward               | -0.06594216 |\n",
            "|    std                  | 1.24        |\n",
            "|    value_loss           | 3.01        |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 359           |\n",
            "|    iterations           | 345           |\n",
            "|    time_elapsed         | 1967          |\n",
            "|    total_timesteps      | 706560        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0037531308  |\n",
            "|    clip_fraction        | 0.0176        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.23         |\n",
            "|    explained_variance   | 3.48e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 1.59          |\n",
            "|    n_updates            | 3440          |\n",
            "|    policy_gradient_loss | -0.000602     |\n",
            "|    reward               | 0.00032111054 |\n",
            "|    std                  | 1.24          |\n",
            "|    value_loss           | 3.36          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 359          |\n",
            "|    iterations           | 346          |\n",
            "|    time_elapsed         | 1973         |\n",
            "|    total_timesteps      | 708608       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046773837 |\n",
            "|    clip_fraction        | 0.0219       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.23        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.28         |\n",
            "|    n_updates            | 3450         |\n",
            "|    policy_gradient_loss | -0.00132     |\n",
            "|    reward               | -0.3864822   |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 2.41         |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 245\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -678927.42\n",
            "total_reward: -688927.42\n",
            "total_cost: 760.06\n",
            "total_trades: 3892\n",
            "Sharpe: 0.462\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 347          |\n",
            "|    time_elapsed         | 1979         |\n",
            "|    total_timesteps      | 710656       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035455772 |\n",
            "|    clip_fraction        | 0.0624       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.25        |\n",
            "|    explained_variance   | 6.57e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.687        |\n",
            "|    n_updates            | 3460         |\n",
            "|    policy_gradient_loss | -0.003       |\n",
            "|    reward               | 0.023214197  |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 1.72         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 348          |\n",
            "|    time_elapsed         | 1986         |\n",
            "|    total_timesteps      | 712704       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016227034 |\n",
            "|    clip_fraction        | 0.0169       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.26        |\n",
            "|    explained_variance   | 3.67e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.37         |\n",
            "|    n_updates            | 3470         |\n",
            "|    policy_gradient_loss | -0.00128     |\n",
            "|    reward               | -0.004028049 |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 3.27         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 349          |\n",
            "|    time_elapsed         | 1992         |\n",
            "|    total_timesteps      | 714752       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052602375 |\n",
            "|    clip_fraction        | 0.027        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.27        |\n",
            "|    explained_variance   | 4.5e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.57         |\n",
            "|    n_updates            | 3480         |\n",
            "|    policy_gradient_loss | -0.00219     |\n",
            "|    reward               | 0.014098286  |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 2.83         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 350          |\n",
            "|    time_elapsed         | 1999         |\n",
            "|    total_timesteps      | 716800       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061124247 |\n",
            "|    clip_fraction        | 0.0501       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.26        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0763       |\n",
            "|    n_updates            | 3490         |\n",
            "|    policy_gradient_loss | -0.00301     |\n",
            "|    reward               | 0.041731533  |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.31         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 351          |\n",
            "|    time_elapsed         | 2005         |\n",
            "|    total_timesteps      | 718848       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032390493 |\n",
            "|    clip_fraction        | 0.0108       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.25        |\n",
            "|    explained_variance   | 3.37e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.878        |\n",
            "|    n_updates            | 3500         |\n",
            "|    policy_gradient_loss | -0.000559    |\n",
            "|    reward               | 0.023356963  |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 2.42         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 352          |\n",
            "|    time_elapsed         | 2011         |\n",
            "|    total_timesteps      | 720896       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054708715 |\n",
            "|    clip_fraction        | 0.0599       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.25        |\n",
            "|    explained_variance   | 4.79e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.02         |\n",
            "|    n_updates            | 3510         |\n",
            "|    policy_gradient_loss | -0.00548     |\n",
            "|    reward               | -0.096681006 |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 2.94         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 358         |\n",
            "|    iterations           | 353         |\n",
            "|    time_elapsed         | 2018        |\n",
            "|    total_timesteps      | 722944      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007114739 |\n",
            "|    clip_fraction        | 0.0499      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.25       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.373       |\n",
            "|    n_updates            | 3520        |\n",
            "|    policy_gradient_loss | -0.00321    |\n",
            "|    reward               | -0.1771094  |\n",
            "|    std                  | 1.25        |\n",
            "|    value_loss           | 0.661       |\n",
            "-----------------------------------------\n",
            "day: 2896, episode: 250\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -637118.38\n",
            "total_reward: -647118.38\n",
            "total_cost: 730.65\n",
            "total_trades: 3664\n",
            "Sharpe: 0.394\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 354          |\n",
            "|    time_elapsed         | 2024         |\n",
            "|    total_timesteps      | 724992       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044033034 |\n",
            "|    clip_fraction        | 0.0269       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.25        |\n",
            "|    explained_variance   | 2.42e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.682        |\n",
            "|    n_updates            | 3530         |\n",
            "|    policy_gradient_loss | -0.0017      |\n",
            "|    reward               | -0.02260362  |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 1.9          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 358         |\n",
            "|    iterations           | 355         |\n",
            "|    time_elapsed         | 2030        |\n",
            "|    total_timesteps      | 727040      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004263692 |\n",
            "|    clip_fraction        | 0.0302      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.27       |\n",
            "|    explained_variance   | 3.43e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.79        |\n",
            "|    n_updates            | 3540        |\n",
            "|    policy_gradient_loss | -0.0019     |\n",
            "|    reward               | 1.0049655   |\n",
            "|    std                  | 1.26        |\n",
            "|    value_loss           | 2.89        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 356          |\n",
            "|    time_elapsed         | 2036         |\n",
            "|    total_timesteps      | 729088       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060153175 |\n",
            "|    clip_fraction        | 0.0489       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.27        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.41         |\n",
            "|    n_updates            | 3550         |\n",
            "|    policy_gradient_loss | -0.00282     |\n",
            "|    reward               | 0.25200486   |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 2.86         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 357          |\n",
            "|    time_elapsed         | 2042         |\n",
            "|    total_timesteps      | 731136       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029256807 |\n",
            "|    clip_fraction        | 0.00752      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | 6.15e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.314        |\n",
            "|    n_updates            | 3560         |\n",
            "|    policy_gradient_loss | -0.000131    |\n",
            "|    reward               | -0.045975853 |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.594        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 358          |\n",
            "|    time_elapsed         | 2048         |\n",
            "|    total_timesteps      | 733184       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022000032 |\n",
            "|    clip_fraction        | 0.00239      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.29        |\n",
            "|    explained_variance   | 3.42e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.24         |\n",
            "|    n_updates            | 3570         |\n",
            "|    policy_gradient_loss | -0.000315    |\n",
            "|    reward               | -0.008711937 |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 2.31         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 359          |\n",
            "|    time_elapsed         | 2055         |\n",
            "|    total_timesteps      | 735232       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031697568 |\n",
            "|    clip_fraction        | 0.0172       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.29        |\n",
            "|    explained_variance   | 5.13e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.02         |\n",
            "|    n_updates            | 3580         |\n",
            "|    policy_gradient_loss | -0.000601    |\n",
            "|    reward               | -0.096433245 |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 2.49         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 357         |\n",
            "|    iterations           | 360         |\n",
            "|    time_elapsed         | 2061        |\n",
            "|    total_timesteps      | 737280      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003999974 |\n",
            "|    clip_fraction        | 0.0365      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.28       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.21        |\n",
            "|    n_updates            | 3590        |\n",
            "|    policy_gradient_loss | -0.00195    |\n",
            "|    reward               | 0.04458596  |\n",
            "|    std                  | 1.27        |\n",
            "|    value_loss           | 0.516       |\n",
            "-----------------------------------------\n",
            "day: 2896, episode: 255\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -633766.81\n",
            "total_reward: -643766.81\n",
            "total_cost: 737.26\n",
            "total_trades: 3728\n",
            "Sharpe: 0.503\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 361          |\n",
            "|    time_elapsed         | 2067         |\n",
            "|    total_timesteps      | 739328       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032924553 |\n",
            "|    clip_fraction        | 0.0153       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | 2.89e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.18         |\n",
            "|    n_updates            | 3600         |\n",
            "|    policy_gradient_loss | -0.000898    |\n",
            "|    reward               | -0.014398673 |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 2.11         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 362          |\n",
            "|    time_elapsed         | 2073         |\n",
            "|    total_timesteps      | 741376       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0057646735 |\n",
            "|    clip_fraction        | 0.0382       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | 4.32e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.73         |\n",
            "|    n_updates            | 3610         |\n",
            "|    policy_gradient_loss | -0.00246     |\n",
            "|    reward               | -1.5667725   |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 3.05         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 363          |\n",
            "|    time_elapsed         | 2080         |\n",
            "|    total_timesteps      | 743424       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024040788 |\n",
            "|    clip_fraction        | 0.0124       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.569        |\n",
            "|    n_updates            | 3620         |\n",
            "|    policy_gradient_loss | -0.000903    |\n",
            "|    reward               | -0.27154785  |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 1.72         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 364          |\n",
            "|    time_elapsed         | 2086         |\n",
            "|    total_timesteps      | 745472       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034299707 |\n",
            "|    clip_fraction        | 0.0224       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | 6.47e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.299        |\n",
            "|    n_updates            | 3630         |\n",
            "|    policy_gradient_loss | -0.0006      |\n",
            "|    reward               | 0.0034616531 |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.99         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 365          |\n",
            "|    time_elapsed         | 2092         |\n",
            "|    total_timesteps      | 747520       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005572032  |\n",
            "|    clip_fraction        | 0.0387       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | 2.74e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.85         |\n",
            "|    n_updates            | 3640         |\n",
            "|    policy_gradient_loss | -0.00175     |\n",
            "|    reward               | 0.0005559046 |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 2.57         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 366          |\n",
            "|    time_elapsed         | 2098         |\n",
            "|    total_timesteps      | 749568       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048213503 |\n",
            "|    clip_fraction        | 0.0292       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | 4.89e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.816        |\n",
            "|    n_updates            | 3650         |\n",
            "|    policy_gradient_loss | -0.00128     |\n",
            "|    reward               | -0.13807604  |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 2.65         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 367          |\n",
            "|    time_elapsed         | 2104         |\n",
            "|    total_timesteps      | 751616       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018479278 |\n",
            "|    clip_fraction        | 0.015        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0813       |\n",
            "|    n_updates            | 3660         |\n",
            "|    policy_gradient_loss | -0.000605    |\n",
            "|    reward               | -0.026753515 |\n",
            "|    std                  | 1.26         |\n",
            "|    value_loss           | 0.296        |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 260\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -531290.98\n",
            "total_reward: -541290.98\n",
            "total_cost: 738.96\n",
            "total_trades: 3472\n",
            "Sharpe: 0.423\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 368          |\n",
            "|    time_elapsed         | 2111         |\n",
            "|    total_timesteps      | 753664       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0004274175 |\n",
            "|    clip_fraction        | 0.000146     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.28        |\n",
            "|    explained_variance   | 4.95e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.547        |\n",
            "|    n_updates            | 3670         |\n",
            "|    policy_gradient_loss | 0.000116     |\n",
            "|    reward               | 0.011194426  |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 2.52         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 369          |\n",
            "|    time_elapsed         | 2117         |\n",
            "|    total_timesteps      | 755712       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022356007 |\n",
            "|    clip_fraction        | 0.0123       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.3         |\n",
            "|    explained_variance   | 4.76e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.627        |\n",
            "|    n_updates            | 3680         |\n",
            "|    policy_gradient_loss | -0.00131     |\n",
            "|    reward               | -0.4033508   |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 2.23         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 370          |\n",
            "|    time_elapsed         | 2124         |\n",
            "|    total_timesteps      | 757760       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034153177 |\n",
            "|    clip_fraction        | 0.0201       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.31        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.17         |\n",
            "|    n_updates            | 3690         |\n",
            "|    policy_gradient_loss | -0.00155     |\n",
            "|    reward               | -0.04439239  |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.694        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 371          |\n",
            "|    time_elapsed         | 2129         |\n",
            "|    total_timesteps      | 759808       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028566238 |\n",
            "|    clip_fraction        | 0.00273      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.31        |\n",
            "|    explained_variance   | 7.37e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.01         |\n",
            "|    n_updates            | 3700         |\n",
            "|    policy_gradient_loss | -2.97e-06    |\n",
            "|    reward               | 0.0025101537 |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 1.42         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 372          |\n",
            "|    time_elapsed         | 2136         |\n",
            "|    total_timesteps      | 761856       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031639808 |\n",
            "|    clip_fraction        | 0.016        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.31        |\n",
            "|    explained_variance   | 4.83e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.24         |\n",
            "|    n_updates            | 3710         |\n",
            "|    policy_gradient_loss | -0.00102     |\n",
            "|    reward               | 1.454354     |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 2.72         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 373          |\n",
            "|    time_elapsed         | 2142         |\n",
            "|    total_timesteps      | 763904       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0065733735 |\n",
            "|    clip_fraction        | 0.0571       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.31        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.09         |\n",
            "|    n_updates            | 3720         |\n",
            "|    policy_gradient_loss | -0.00356     |\n",
            "|    reward               | -0.7467364   |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 2.75         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 374          |\n",
            "|    time_elapsed         | 2148         |\n",
            "|    total_timesteps      | 765952       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044877147 |\n",
            "|    clip_fraction        | 0.0278       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.31        |\n",
            "|    explained_variance   | 5.26e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.212        |\n",
            "|    n_updates            | 3730         |\n",
            "|    policy_gradient_loss | -0.00129     |\n",
            "|    reward               | -0.17261551  |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.352        |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 265\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -621514.05\n",
            "total_reward: -631514.05\n",
            "total_cost: 755.72\n",
            "total_trades: 3858\n",
            "Sharpe: 0.319\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 375          |\n",
            "|    time_elapsed         | 2154         |\n",
            "|    total_timesteps      | 768000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030292575 |\n",
            "|    clip_fraction        | 0.0214       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.31        |\n",
            "|    explained_variance   | 2.63e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.23         |\n",
            "|    n_updates            | 3740         |\n",
            "|    policy_gradient_loss | -0.00187     |\n",
            "|    reward               | 0.00555838   |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 2.55         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 376          |\n",
            "|    time_elapsed         | 2160         |\n",
            "|    total_timesteps      | 770048       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028407676 |\n",
            "|    clip_fraction        | 0.0145       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.31        |\n",
            "|    explained_variance   | 3.38e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.31         |\n",
            "|    n_updates            | 3750         |\n",
            "|    policy_gradient_loss | -0.00148     |\n",
            "|    reward               | -0.40652975  |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 3            |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 356         |\n",
            "|    iterations           | 377         |\n",
            "|    time_elapsed         | 2166        |\n",
            "|    total_timesteps      | 772096      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005526119 |\n",
            "|    clip_fraction        | 0.0564      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.31       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.37        |\n",
            "|    n_updates            | 3760        |\n",
            "|    policy_gradient_loss | -0.00372    |\n",
            "|    reward               | -0.17936495 |\n",
            "|    std                  | 1.28        |\n",
            "|    value_loss           | 0.793       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 378          |\n",
            "|    time_elapsed         | 2172         |\n",
            "|    total_timesteps      | 774144       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035282588 |\n",
            "|    clip_fraction        | 0.0102       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.32        |\n",
            "|    explained_variance   | 2.84e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.2          |\n",
            "|    n_updates            | 3770         |\n",
            "|    policy_gradient_loss | -0.000824    |\n",
            "|    reward               | 0.034406353  |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 2.67         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 379          |\n",
            "|    time_elapsed         | 2179         |\n",
            "|    total_timesteps      | 776192       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039266255 |\n",
            "|    clip_fraction        | 0.0307       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.33        |\n",
            "|    explained_variance   | 3.86e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.52         |\n",
            "|    n_updates            | 3780         |\n",
            "|    policy_gradient_loss | -0.0022      |\n",
            "|    reward               | 0.9359008    |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 3.2          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 380          |\n",
            "|    time_elapsed         | 2185         |\n",
            "|    total_timesteps      | 778240       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035738382 |\n",
            "|    clip_fraction        | 0.0229       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.34        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.972        |\n",
            "|    n_updates            | 3790         |\n",
            "|    policy_gradient_loss | -0.00169     |\n",
            "|    reward               | 0.040771075  |\n",
            "|    std                  | 1.3          |\n",
            "|    value_loss           | 2.39         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 381          |\n",
            "|    time_elapsed         | 2191         |\n",
            "|    total_timesteps      | 780288       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030761731 |\n",
            "|    clip_fraction        | 0.00439      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.34        |\n",
            "|    explained_variance   | 2.87e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.411        |\n",
            "|    n_updates            | 3800         |\n",
            "|    policy_gradient_loss | -0.000531    |\n",
            "|    reward               | -0.03613734  |\n",
            "|    std                  | 1.3          |\n",
            "|    value_loss           | 0.8          |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 270\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -612576.89\n",
            "total_reward: -622576.89\n",
            "total_cost: 783.24\n",
            "total_trades: 3848\n",
            "Sharpe: -0.197\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 355           |\n",
            "|    iterations           | 382           |\n",
            "|    time_elapsed         | 2198          |\n",
            "|    total_timesteps      | 782336        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0031493139  |\n",
            "|    clip_fraction        | 0.00352       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.34         |\n",
            "|    explained_variance   | 3.5e-05       |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 1.64          |\n",
            "|    n_updates            | 3810          |\n",
            "|    policy_gradient_loss | 0.000122      |\n",
            "|    reward               | -0.0047828704 |\n",
            "|    std                  | 1.3           |\n",
            "|    value_loss           | 2.84          |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 355         |\n",
            "|    iterations           | 383         |\n",
            "|    time_elapsed         | 2204        |\n",
            "|    total_timesteps      | 784384      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003260034 |\n",
            "|    clip_fraction        | 0.0196      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.34       |\n",
            "|    explained_variance   | 4.11e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.4         |\n",
            "|    n_updates            | 3820        |\n",
            "|    policy_gradient_loss | -0.00101    |\n",
            "|    reward               | 0.20578721  |\n",
            "|    std                  | 1.3         |\n",
            "|    value_loss           | 2.74        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 384          |\n",
            "|    time_elapsed         | 2210         |\n",
            "|    total_timesteps      | 786432       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018270983 |\n",
            "|    clip_fraction        | 0.0084       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.35        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.157        |\n",
            "|    n_updates            | 3830         |\n",
            "|    policy_gradient_loss | -0.00061     |\n",
            "|    reward               | -0.085677594 |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 0.355        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 385          |\n",
            "|    time_elapsed         | 2216         |\n",
            "|    total_timesteps      | 788480       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042028227 |\n",
            "|    clip_fraction        | 0.0567       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.35        |\n",
            "|    explained_variance   | 2.97e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.731        |\n",
            "|    n_updates            | 3840         |\n",
            "|    policy_gradient_loss | -0.00257     |\n",
            "|    reward               | 0.0062667714 |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 2.28         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 386          |\n",
            "|    time_elapsed         | 2222         |\n",
            "|    total_timesteps      | 790528       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039816676 |\n",
            "|    clip_fraction        | 0.0226       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.35        |\n",
            "|    explained_variance   | 4.61e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.26         |\n",
            "|    n_updates            | 3850         |\n",
            "|    policy_gradient_loss | -0.000924    |\n",
            "|    reward               | -0.05644651  |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 2.8          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 387          |\n",
            "|    time_elapsed         | 2228         |\n",
            "|    total_timesteps      | 792576       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055906484 |\n",
            "|    clip_fraction        | 0.0399       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.35        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.276        |\n",
            "|    n_updates            | 3860         |\n",
            "|    policy_gradient_loss | -0.0032      |\n",
            "|    reward               | 0.14197683   |\n",
            "|    std                  | 1.3          |\n",
            "|    value_loss           | 1.25         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 388          |\n",
            "|    time_elapsed         | 2234         |\n",
            "|    total_timesteps      | 794624       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058323815 |\n",
            "|    clip_fraction        | 0.0252       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.35        |\n",
            "|    explained_variance   | 8.17e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.586        |\n",
            "|    n_updates            | 3870         |\n",
            "|    policy_gradient_loss | -0.00159     |\n",
            "|    reward               | -0.034622975 |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 1.23         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 355         |\n",
            "|    iterations           | 389         |\n",
            "|    time_elapsed         | 2239        |\n",
            "|    total_timesteps      | 796672      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005296911 |\n",
            "|    clip_fraction        | 0.0427      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.35       |\n",
            "|    explained_variance   | 4.37e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.22        |\n",
            "|    n_updates            | 3880        |\n",
            "|    policy_gradient_loss | -0.00317    |\n",
            "|    reward               | 0.2541691   |\n",
            "|    std                  | 1.31        |\n",
            "|    value_loss           | 2.87        |\n",
            "-----------------------------------------\n",
            "day: 2896, episode: 275\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -610714.57\n",
            "total_reward: -620714.57\n",
            "total_cost: 767.81\n",
            "total_trades: 3836\n",
            "Sharpe: 0.503\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 355        |\n",
            "|    iterations           | 390        |\n",
            "|    time_elapsed         | 2245       |\n",
            "|    total_timesteps      | 798720     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.0049972  |\n",
            "|    clip_fraction        | 0.0412     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.35      |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 1.31       |\n",
            "|    n_updates            | 3890       |\n",
            "|    policy_gradient_loss | -0.00273   |\n",
            "|    reward               | 0.13096048 |\n",
            "|    std                  | 1.3        |\n",
            "|    value_loss           | 2.76       |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 391          |\n",
            "|    time_elapsed         | 2251         |\n",
            "|    total_timesteps      | 800768       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042226594 |\n",
            "|    clip_fraction        | 0.0409       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.35        |\n",
            "|    explained_variance   | 8.31e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.102        |\n",
            "|    n_updates            | 3900         |\n",
            "|    policy_gradient_loss | -0.00261     |\n",
            "|    reward               | 0.014601182  |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 0.224        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 392          |\n",
            "|    time_elapsed         | 2257         |\n",
            "|    total_timesteps      | 802816       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0057499316 |\n",
            "|    clip_fraction        | 0.0599       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.35        |\n",
            "|    explained_variance   | 3.78e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.923        |\n",
            "|    n_updates            | 3910         |\n",
            "|    policy_gradient_loss | -0.00367     |\n",
            "|    reward               | 0.02293287   |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 2.32         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 355         |\n",
            "|    iterations           | 393         |\n",
            "|    time_elapsed         | 2262        |\n",
            "|    total_timesteps      | 804864      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005239037 |\n",
            "|    clip_fraction        | 0.0455      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.35       |\n",
            "|    explained_variance   | 4.71e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.18        |\n",
            "|    n_updates            | 3920        |\n",
            "|    policy_gradient_loss | -0.00356    |\n",
            "|    reward               | 0.7304087   |\n",
            "|    std                  | 1.31        |\n",
            "|    value_loss           | 2.28        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 394          |\n",
            "|    time_elapsed         | 2268         |\n",
            "|    total_timesteps      | 806912       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.002991027  |\n",
            "|    clip_fraction        | 0.0141       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.36        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.488        |\n",
            "|    n_updates            | 3930         |\n",
            "|    policy_gradient_loss | -0.000726    |\n",
            "|    reward               | -0.095300764 |\n",
            "|    std                  | 1.32         |\n",
            "|    value_loss           | 0.713        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 355         |\n",
            "|    iterations           | 395         |\n",
            "|    time_elapsed         | 2273        |\n",
            "|    total_timesteps      | 808960      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005269156 |\n",
            "|    clip_fraction        | 0.0438      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.36       |\n",
            "|    explained_variance   | 3.25e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.48        |\n",
            "|    n_updates            | 3940        |\n",
            "|    policy_gradient_loss | -0.00236    |\n",
            "|    reward               | 0.010412669 |\n",
            "|    std                  | 1.31        |\n",
            "|    value_loss           | 2.16        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 396          |\n",
            "|    time_elapsed         | 2279         |\n",
            "|    total_timesteps      | 811008       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031774826 |\n",
            "|    clip_fraction        | 0.0183       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.36        |\n",
            "|    explained_variance   | 3.73e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.53         |\n",
            "|    n_updates            | 3950         |\n",
            "|    policy_gradient_loss | -0.000762    |\n",
            "|    reward               | -2.18924     |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 4.17         |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 280\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -715278.62\n",
            "total_reward: -725278.62\n",
            "total_cost: 847.59\n",
            "total_trades: 4138\n",
            "Sharpe: -0.326\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 397          |\n",
            "|    time_elapsed         | 2285         |\n",
            "|    total_timesteps      | 813056       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053715827 |\n",
            "|    clip_fraction        | 0.0347       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.36        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.57         |\n",
            "|    n_updates            | 3960         |\n",
            "|    policy_gradient_loss | -0.00139     |\n",
            "|    reward               | -0.46348926  |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 3.25         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 398          |\n",
            "|    time_elapsed         | 2291         |\n",
            "|    total_timesteps      | 815104       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035935515 |\n",
            "|    clip_fraction        | 0.014        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.37        |\n",
            "|    explained_variance   | 5.45e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.155        |\n",
            "|    n_updates            | 3970         |\n",
            "|    policy_gradient_loss | -0.00044     |\n",
            "|    reward               | 0.00719209   |\n",
            "|    std                  | 1.32         |\n",
            "|    value_loss           | 0.734        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 399          |\n",
            "|    time_elapsed         | 2296         |\n",
            "|    total_timesteps      | 817152       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035865696 |\n",
            "|    clip_fraction        | 0.0152       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.38        |\n",
            "|    explained_variance   | 3.09e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.74         |\n",
            "|    n_updates            | 3980         |\n",
            "|    policy_gradient_loss | -0.000748    |\n",
            "|    reward               | 0.007850021  |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 3.68         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 400          |\n",
            "|    time_elapsed         | 2302         |\n",
            "|    total_timesteps      | 819200       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041242884 |\n",
            "|    clip_fraction        | 0.0148       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.39        |\n",
            "|    explained_variance   | 3.99e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.32         |\n",
            "|    n_updates            | 3990         |\n",
            "|    policy_gradient_loss | -0.000818    |\n",
            "|    reward               | 0.74402565   |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 4.27         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 401          |\n",
            "|    time_elapsed         | 2307         |\n",
            "|    total_timesteps      | 821248       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034728507 |\n",
            "|    clip_fraction        | 0.0222       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.39        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.229        |\n",
            "|    n_updates            | 4000         |\n",
            "|    policy_gradient_loss | -0.000909    |\n",
            "|    reward               | 0.15152311   |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 0.503        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 402          |\n",
            "|    time_elapsed         | 2313         |\n",
            "|    total_timesteps      | 823296       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012395032 |\n",
            "|    clip_fraction        | 0.00356      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.39        |\n",
            "|    explained_variance   | 3.72e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.17         |\n",
            "|    n_updates            | 4010         |\n",
            "|    policy_gradient_loss | -0.00046     |\n",
            "|    reward               | 0.014390421  |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 3.39         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 355         |\n",
            "|    iterations           | 403         |\n",
            "|    time_elapsed         | 2319        |\n",
            "|    total_timesteps      | 825344      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006346119 |\n",
            "|    clip_fraction        | 0.0404      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.38       |\n",
            "|    explained_variance   | 4.39e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.79        |\n",
            "|    n_updates            | 4020        |\n",
            "|    policy_gradient_loss | -0.0019     |\n",
            "|    reward               | 0.6776614   |\n",
            "|    std                  | 1.32        |\n",
            "|    value_loss           | 3.4         |\n",
            "-----------------------------------------\n",
            "day: 2896, episode: 285\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -640231.29\n",
            "total_reward: -650231.29\n",
            "total_cost: 839.06\n",
            "total_trades: 4190\n",
            "Sharpe: 0.609\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 404          |\n",
            "|    time_elapsed         | 2325         |\n",
            "|    total_timesteps      | 827392       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030739342 |\n",
            "|    clip_fraction        | 0.0217       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.37        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.708        |\n",
            "|    n_updates            | 4030         |\n",
            "|    policy_gradient_loss | -0.00107     |\n",
            "|    reward               | -0.4009826   |\n",
            "|    std                  | 1.32         |\n",
            "|    value_loss           | 1.95         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 405          |\n",
            "|    time_elapsed         | 2330         |\n",
            "|    total_timesteps      | 829440       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006471681  |\n",
            "|    clip_fraction        | 0.0395       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.37        |\n",
            "|    explained_variance   | 4.28e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.337        |\n",
            "|    n_updates            | 4040         |\n",
            "|    policy_gradient_loss | -0.00227     |\n",
            "|    reward               | -0.006560722 |\n",
            "|    std                  | 1.32         |\n",
            "|    value_loss           | 1.37         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 355           |\n",
            "|    iterations           | 406           |\n",
            "|    time_elapsed         | 2336          |\n",
            "|    total_timesteps      | 831488        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.005268596   |\n",
            "|    clip_fraction        | 0.0304        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.38         |\n",
            "|    explained_variance   | 3.86e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 2.03          |\n",
            "|    n_updates            | 4050          |\n",
            "|    policy_gradient_loss | -0.00346      |\n",
            "|    reward               | -0.0038661445 |\n",
            "|    std                  | 1.33          |\n",
            "|    value_loss           | 3.48          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 407          |\n",
            "|    time_elapsed         | 2342         |\n",
            "|    total_timesteps      | 833536       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060239616 |\n",
            "|    clip_fraction        | 0.0511       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.39        |\n",
            "|    explained_variance   | 4.13e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.02         |\n",
            "|    n_updates            | 4060         |\n",
            "|    policy_gradient_loss | -0.00393     |\n",
            "|    reward               | 0.35680968   |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 3.07         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 408          |\n",
            "|    time_elapsed         | 2347         |\n",
            "|    total_timesteps      | 835584       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054976847 |\n",
            "|    clip_fraction        | 0.0377       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.39        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0984       |\n",
            "|    n_updates            | 4070         |\n",
            "|    policy_gradient_loss | -0.00258     |\n",
            "|    reward               | -0.111103304 |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 0.32         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 355           |\n",
            "|    iterations           | 409           |\n",
            "|    time_elapsed         | 2353          |\n",
            "|    total_timesteps      | 837632        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00032811137 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.4          |\n",
            "|    explained_variance   | 3.77e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 1.77          |\n",
            "|    n_updates            | 4080          |\n",
            "|    policy_gradient_loss | -0.000178     |\n",
            "|    reward               | -0.0007457753 |\n",
            "|    std                  | 1.35          |\n",
            "|    value_loss           | 2.81          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 355          |\n",
            "|    iterations           | 410          |\n",
            "|    time_elapsed         | 2358         |\n",
            "|    total_timesteps      | 839680       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061116493 |\n",
            "|    clip_fraction        | 0.0542       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.41        |\n",
            "|    explained_variance   | 4.57e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.41         |\n",
            "|    n_updates            | 4090         |\n",
            "|    policy_gradient_loss | -0.00287     |\n",
            "|    reward               | 0.41331202   |\n",
            "|    std                  | 1.35         |\n",
            "|    value_loss           | 2.96         |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 290\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -664829.65\n",
            "total_reward: -674829.65\n",
            "total_cost: 808.76\n",
            "total_trades: 4132\n",
            "Sharpe: 0.632\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 355         |\n",
            "|    iterations           | 411         |\n",
            "|    time_elapsed         | 2364        |\n",
            "|    total_timesteps      | 841728      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.00412992  |\n",
            "|    clip_fraction        | 0.0238      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.41       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.453       |\n",
            "|    n_updates            | 4100        |\n",
            "|    policy_gradient_loss | -0.00242    |\n",
            "|    reward               | -0.25566903 |\n",
            "|    std                  | 1.34        |\n",
            "|    value_loss           | 0.942       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 356         |\n",
            "|    iterations           | 412         |\n",
            "|    time_elapsed         | 2370        |\n",
            "|    total_timesteps      | 843776      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005011718 |\n",
            "|    clip_fraction        | 0.0418      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.4        |\n",
            "|    explained_variance   | 4.14e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.58        |\n",
            "|    n_updates            | 4110        |\n",
            "|    policy_gradient_loss | -0.00363    |\n",
            "|    reward               | 0.011205074 |\n",
            "|    std                  | 1.33        |\n",
            "|    value_loss           | 2.53        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 413          |\n",
            "|    time_elapsed         | 2375         |\n",
            "|    total_timesteps      | 845824       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031073992 |\n",
            "|    clip_fraction        | 0.0136       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.4         |\n",
            "|    explained_variance   | 4.23e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.1          |\n",
            "|    n_updates            | 4120         |\n",
            "|    policy_gradient_loss | -0.000803    |\n",
            "|    reward               | 3.0833805    |\n",
            "|    std                  | 1.34         |\n",
            "|    value_loss           | 3.37         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 356         |\n",
            "|    iterations           | 414         |\n",
            "|    time_elapsed         | 2380        |\n",
            "|    total_timesteps      | 847872      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003302057 |\n",
            "|    clip_fraction        | 0.00845     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.41       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.65        |\n",
            "|    n_updates            | 4130        |\n",
            "|    policy_gradient_loss | -0.00119    |\n",
            "|    reward               | 0.45744362  |\n",
            "|    std                  | 1.36        |\n",
            "|    value_loss           | 3.08        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 415          |\n",
            "|    time_elapsed         | 2386         |\n",
            "|    total_timesteps      | 849920       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.002557252  |\n",
            "|    clip_fraction        | 0.0146       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.44        |\n",
            "|    explained_variance   | 7.59e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.207        |\n",
            "|    n_updates            | 4140         |\n",
            "|    policy_gradient_loss | -0.00137     |\n",
            "|    reward               | -0.045834105 |\n",
            "|    std                  | 1.37         |\n",
            "|    value_loss           | 0.396        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 416          |\n",
            "|    time_elapsed         | 2391         |\n",
            "|    total_timesteps      | 851968       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036581105 |\n",
            "|    clip_fraction        | 0.00933      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.44        |\n",
            "|    explained_variance   | 2.57e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.78         |\n",
            "|    n_updates            | 4150         |\n",
            "|    policy_gradient_loss | -0.000797    |\n",
            "|    reward               | -0.006531284 |\n",
            "|    std                  | 1.37         |\n",
            "|    value_loss           | 3.33         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 417          |\n",
            "|    time_elapsed         | 2397         |\n",
            "|    total_timesteps      | 854016       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049518635 |\n",
            "|    clip_fraction        | 0.0143       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.45        |\n",
            "|    explained_variance   | 4.82e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.13         |\n",
            "|    n_updates            | 4160         |\n",
            "|    policy_gradient_loss | -0.00103     |\n",
            "|    reward               | 2.341846     |\n",
            "|    std                  | 1.38         |\n",
            "|    value_loss           | 3            |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 295\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -708063.40\n",
            "total_reward: -718063.40\n",
            "total_cost: 863.43\n",
            "total_trades: 4140\n",
            "Sharpe: 0.630\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 418          |\n",
            "|    time_elapsed         | 2402         |\n",
            "|    total_timesteps      | 856064       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025993697 |\n",
            "|    clip_fraction        | 0.0136       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.46        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.392        |\n",
            "|    n_updates            | 4170         |\n",
            "|    policy_gradient_loss | -0.000664    |\n",
            "|    reward               | 0.20531099   |\n",
            "|    std                  | 1.38         |\n",
            "|    value_loss           | 0.793        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 356         |\n",
            "|    iterations           | 419         |\n",
            "|    time_elapsed         | 2408        |\n",
            "|    total_timesteps      | 858112      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010234198 |\n",
            "|    clip_fraction        | 0.118       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.46       |\n",
            "|    explained_variance   | 4.37e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.48        |\n",
            "|    n_updates            | 4180        |\n",
            "|    policy_gradient_loss | -0.00757    |\n",
            "|    reward               | 0.021276528 |\n",
            "|    std                  | 1.38        |\n",
            "|    value_loss           | 3.08        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 420          |\n",
            "|    time_elapsed         | 2413         |\n",
            "|    total_timesteps      | 860160       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010145076 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.46        |\n",
            "|    explained_variance   | 5.07e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.885        |\n",
            "|    n_updates            | 4190         |\n",
            "|    policy_gradient_loss | 0.00023      |\n",
            "|    reward               | -0.43673065  |\n",
            "|    std                  | 1.38         |\n",
            "|    value_loss           | 2.85         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 421          |\n",
            "|    time_elapsed         | 2418         |\n",
            "|    total_timesteps      | 862208       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029343744 |\n",
            "|    clip_fraction        | 0.0188       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.46        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.81         |\n",
            "|    n_updates            | 4200         |\n",
            "|    policy_gradient_loss | -0.00103     |\n",
            "|    reward               | -0.34421235  |\n",
            "|    std                  | 1.38         |\n",
            "|    value_loss           | 1.79         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 356         |\n",
            "|    iterations           | 422         |\n",
            "|    time_elapsed         | 2423        |\n",
            "|    total_timesteps      | 864256      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004442828 |\n",
            "|    clip_fraction        | 0.0246      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.47       |\n",
            "|    explained_variance   | 2.73e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.487       |\n",
            "|    n_updates            | 4210        |\n",
            "|    policy_gradient_loss | -0.00169    |\n",
            "|    reward               | 0.026393238 |\n",
            "|    std                  | 1.39        |\n",
            "|    value_loss           | 0.985       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 423          |\n",
            "|    time_elapsed         | 2429         |\n",
            "|    total_timesteps      | 866304       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.00426769   |\n",
            "|    clip_fraction        | 0.0155       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.48        |\n",
            "|    explained_variance   | 4.08e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.32         |\n",
            "|    n_updates            | 4220         |\n",
            "|    policy_gradient_loss | -0.00122     |\n",
            "|    reward               | 0.0012200809 |\n",
            "|    std                  | 1.39         |\n",
            "|    value_loss           | 3.13         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 424          |\n",
            "|    time_elapsed         | 2434         |\n",
            "|    total_timesteps      | 868352       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033861008 |\n",
            "|    clip_fraction        | 0.0107       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.48        |\n",
            "|    explained_variance   | 4.11e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.35         |\n",
            "|    n_updates            | 4230         |\n",
            "|    policy_gradient_loss | -0.000802    |\n",
            "|    reward               | -0.5808056   |\n",
            "|    std                  | 1.39         |\n",
            "|    value_loss           | 3.13         |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 300\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -667645.92\n",
            "total_reward: -677645.92\n",
            "total_cost: 739.29\n",
            "total_trades: 4006\n",
            "Sharpe: 0.629\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 425          |\n",
            "|    time_elapsed         | 2439         |\n",
            "|    total_timesteps      | 870400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041150916 |\n",
            "|    clip_fraction        | 0.02         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.48        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.178        |\n",
            "|    n_updates            | 4240         |\n",
            "|    policy_gradient_loss | -0.00179     |\n",
            "|    reward               | 0.15196764   |\n",
            "|    std                  | 1.39         |\n",
            "|    value_loss           | 0.427        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 426          |\n",
            "|    time_elapsed         | 2445         |\n",
            "|    total_timesteps      | 872448       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027383096 |\n",
            "|    clip_fraction        | 0.0177       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.49        |\n",
            "|    explained_variance   | 4.73e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.987        |\n",
            "|    n_updates            | 4250         |\n",
            "|    policy_gradient_loss | -0.00167     |\n",
            "|    reward               | 0.006885877  |\n",
            "|    std                  | 1.4          |\n",
            "|    value_loss           | 2.75         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 356         |\n",
            "|    iterations           | 427         |\n",
            "|    time_elapsed         | 2451        |\n",
            "|    total_timesteps      | 874496      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004826663 |\n",
            "|    clip_fraction        | 0.0213      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.5        |\n",
            "|    explained_variance   | 3.96e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.23        |\n",
            "|    n_updates            | 4260        |\n",
            "|    policy_gradient_loss | -0.00239    |\n",
            "|    reward               | 0.5462874   |\n",
            "|    std                  | 1.41        |\n",
            "|    value_loss           | 3.21        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 428          |\n",
            "|    time_elapsed         | 2456         |\n",
            "|    total_timesteps      | 876544       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036107567 |\n",
            "|    clip_fraction        | 0.0152       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.51        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.166        |\n",
            "|    n_updates            | 4270         |\n",
            "|    policy_gradient_loss | -0.00068     |\n",
            "|    reward               | 0.018371688  |\n",
            "|    std                  | 1.41         |\n",
            "|    value_loss           | 0.641        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 429          |\n",
            "|    time_elapsed         | 2461         |\n",
            "|    total_timesteps      | 878592       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061955443 |\n",
            "|    clip_fraction        | 0.0229       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.51        |\n",
            "|    explained_variance   | 8.36e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.58         |\n",
            "|    n_updates            | 4280         |\n",
            "|    policy_gradient_loss | -0.00207     |\n",
            "|    reward               | -0.019417442 |\n",
            "|    std                  | 1.41         |\n",
            "|    value_loss           | 1.37         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 356          |\n",
            "|    iterations           | 430          |\n",
            "|    time_elapsed         | 2467         |\n",
            "|    total_timesteps      | 880640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024584718 |\n",
            "|    clip_fraction        | 0.00679      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.52        |\n",
            "|    explained_variance   | 4.88e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.958        |\n",
            "|    n_updates            | 4290         |\n",
            "|    policy_gradient_loss | -0.000905    |\n",
            "|    reward               | 1.0423034    |\n",
            "|    std                  | 1.43         |\n",
            "|    value_loss           | 2.82         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 431          |\n",
            "|    time_elapsed         | 2472         |\n",
            "|    total_timesteps      | 882688       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040637567 |\n",
            "|    clip_fraction        | 0.0256       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.53        |\n",
            "|    explained_variance   | -2.38e-07    |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.54         |\n",
            "|    n_updates            | 4300         |\n",
            "|    policy_gradient_loss | -0.00182     |\n",
            "|    reward               | 0.1479872    |\n",
            "|    std                  | 1.42         |\n",
            "|    value_loss           | 2.6          |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 305\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -547130.27\n",
            "total_reward: -557130.27\n",
            "total_cost: 816.30\n",
            "total_trades: 3696\n",
            "Sharpe: 0.456\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 432          |\n",
            "|    time_elapsed         | 2477         |\n",
            "|    total_timesteps      | 884736       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056057097 |\n",
            "|    clip_fraction        | 0.04         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.52        |\n",
            "|    explained_variance   | 1.53e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0473       |\n",
            "|    n_updates            | 4310         |\n",
            "|    policy_gradient_loss | -0.00242     |\n",
            "|    reward               | 0.014315252  |\n",
            "|    std                  | 1.42         |\n",
            "|    value_loss           | 0.357        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 433          |\n",
            "|    time_elapsed         | 2483         |\n",
            "|    total_timesteps      | 886784       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043302476 |\n",
            "|    clip_fraction        | 0.0267       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.53        |\n",
            "|    explained_variance   | 4.42e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.11         |\n",
            "|    n_updates            | 4320         |\n",
            "|    policy_gradient_loss | -0.00177     |\n",
            "|    reward               | 0.007955064  |\n",
            "|    std                  | 1.42         |\n",
            "|    value_loss           | 2.13         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 434          |\n",
            "|    time_elapsed         | 2488         |\n",
            "|    total_timesteps      | 888832       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045764092 |\n",
            "|    clip_fraction        | 0.0406       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.53        |\n",
            "|    explained_variance   | 5e-05        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.1          |\n",
            "|    n_updates            | 4330         |\n",
            "|    policy_gradient_loss | -0.00339     |\n",
            "|    reward               | 0.9121773    |\n",
            "|    std                  | 1.42         |\n",
            "|    value_loss           | 2.55         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 435          |\n",
            "|    time_elapsed         | 2493         |\n",
            "|    total_timesteps      | 890880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035463031 |\n",
            "|    clip_fraction        | 0.0177       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.53        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.441        |\n",
            "|    n_updates            | 4340         |\n",
            "|    policy_gradient_loss | -0.00122     |\n",
            "|    reward               | -0.07478537  |\n",
            "|    std                  | 1.42         |\n",
            "|    value_loss           | 0.644        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 436          |\n",
            "|    time_elapsed         | 2499         |\n",
            "|    total_timesteps      | 892928       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056314673 |\n",
            "|    clip_fraction        | 0.0624       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.53        |\n",
            "|    explained_variance   | 4.58e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.15         |\n",
            "|    n_updates            | 4350         |\n",
            "|    policy_gradient_loss | -0.00326     |\n",
            "|    reward               | -0.05345028  |\n",
            "|    std                  | 1.42         |\n",
            "|    value_loss           | 2.23         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 357         |\n",
            "|    iterations           | 437         |\n",
            "|    time_elapsed         | 2504        |\n",
            "|    total_timesteps      | 894976      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004914639 |\n",
            "|    clip_fraction        | 0.018       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.53       |\n",
            "|    explained_variance   | 3.84e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.49        |\n",
            "|    n_updates            | 4360        |\n",
            "|    policy_gradient_loss | -0.00156    |\n",
            "|    reward               | 1.126784    |\n",
            "|    std                  | 1.42        |\n",
            "|    value_loss           | 3.44        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 438          |\n",
            "|    time_elapsed         | 2509         |\n",
            "|    total_timesteps      | 897024       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050222464 |\n",
            "|    clip_fraction        | 0.0255       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.53        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.21         |\n",
            "|    n_updates            | 4370         |\n",
            "|    policy_gradient_loss | -0.00124     |\n",
            "|    reward               | 0.111546345  |\n",
            "|    std                  | 1.42         |\n",
            "|    value_loss           | 2.96         |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 310\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -750920.47\n",
            "total_reward: -760920.47\n",
            "total_cost: 897.00\n",
            "total_trades: 4110\n",
            "Sharpe: 0.749\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 439          |\n",
            "|    time_elapsed         | 2515         |\n",
            "|    total_timesteps      | 899072       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054168487 |\n",
            "|    clip_fraction        | 0.0348       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.53        |\n",
            "|    explained_variance   | 2.66e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.513        |\n",
            "|    n_updates            | 4380         |\n",
            "|    policy_gradient_loss | -0.00124     |\n",
            "|    reward               | 0.06156441   |\n",
            "|    std                  | 1.43         |\n",
            "|    value_loss           | 0.933        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 440          |\n",
            "|    time_elapsed         | 2520         |\n",
            "|    total_timesteps      | 901120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029179011 |\n",
            "|    clip_fraction        | 0.01         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.54        |\n",
            "|    explained_variance   | 3.45e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.82         |\n",
            "|    n_updates            | 4390         |\n",
            "|    policy_gradient_loss | -0.000682    |\n",
            "|    reward               | 0.002895115  |\n",
            "|    std                  | 1.43         |\n",
            "|    value_loss           | 4.08         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 441          |\n",
            "|    time_elapsed         | 2526         |\n",
            "|    total_timesteps      | 903168       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011972206 |\n",
            "|    clip_fraction        | 0.00801      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.54        |\n",
            "|    explained_variance   | 4.82e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.16         |\n",
            "|    n_updates            | 4400         |\n",
            "|    policy_gradient_loss | -0.000318    |\n",
            "|    reward               | -0.34192508  |\n",
            "|    std                  | 1.43         |\n",
            "|    value_loss           | 3.36         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 442          |\n",
            "|    time_elapsed         | 2531         |\n",
            "|    total_timesteps      | 905216       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031626527 |\n",
            "|    clip_fraction        | 0.00854      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.55        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.13         |\n",
            "|    n_updates            | 4410         |\n",
            "|    policy_gradient_loss | -0.000637    |\n",
            "|    reward               | 0.15143321   |\n",
            "|    std                  | 1.43         |\n",
            "|    value_loss           | 0.453        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 443          |\n",
            "|    time_elapsed         | 2536         |\n",
            "|    total_timesteps      | 907264       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.005280751  |\n",
            "|    clip_fraction        | 0.0261       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.55        |\n",
            "|    explained_variance   | 4.14e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.88         |\n",
            "|    n_updates            | 4420         |\n",
            "|    policy_gradient_loss | -0.00203     |\n",
            "|    reward               | -0.008490536 |\n",
            "|    std                  | 1.44         |\n",
            "|    value_loss           | 3.16         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 444          |\n",
            "|    time_elapsed         | 2541         |\n",
            "|    total_timesteps      | 909312       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051699276 |\n",
            "|    clip_fraction        | 0.0192       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.55        |\n",
            "|    explained_variance   | 4.69e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 2.53         |\n",
            "|    n_updates            | 4430         |\n",
            "|    policy_gradient_loss | -0.00149     |\n",
            "|    reward               | -0.9689697   |\n",
            "|    std                  | 1.44         |\n",
            "|    value_loss           | 3.85         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 445          |\n",
            "|    time_elapsed         | 2547         |\n",
            "|    total_timesteps      | 911360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059914486 |\n",
            "|    clip_fraction        | 0.0539       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.55        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.405        |\n",
            "|    n_updates            | 4440         |\n",
            "|    policy_gradient_loss | -0.0047      |\n",
            "|    reward               | 0.10125222   |\n",
            "|    std                  | 1.44         |\n",
            "|    value_loss           | 1.5          |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 315\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -616264.78\n",
            "total_reward: -626264.78\n",
            "total_cost: 922.70\n",
            "total_trades: 3818\n",
            "Sharpe: -0.118\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 446          |\n",
            "|    time_elapsed         | 2552         |\n",
            "|    total_timesteps      | 913408       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0062823296 |\n",
            "|    clip_fraction        | 0.0714       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.54        |\n",
            "|    explained_variance   | 3.96e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.728        |\n",
            "|    n_updates            | 4450         |\n",
            "|    policy_gradient_loss | -0.00456     |\n",
            "|    reward               | 0.007761229  |\n",
            "|    std                  | 1.43         |\n",
            "|    value_loss           | 1.31         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 447          |\n",
            "|    time_elapsed         | 2557         |\n",
            "|    total_timesteps      | 915456       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.003627876  |\n",
            "|    clip_fraction        | 0.0283       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.54        |\n",
            "|    explained_variance   | 3.29e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.42         |\n",
            "|    n_updates            | 4460         |\n",
            "|    policy_gradient_loss | -0.0019      |\n",
            "|    reward               | 4.501667e-05 |\n",
            "|    std                  | 1.43         |\n",
            "|    value_loss           | 2.68         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 357          |\n",
            "|    iterations           | 448          |\n",
            "|    time_elapsed         | 2563         |\n",
            "|    total_timesteps      | 917504       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046246424 |\n",
            "|    clip_fraction        | 0.0375       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.54        |\n",
            "|    explained_variance   | 7.87e-06     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.13         |\n",
            "|    n_updates            | 4470         |\n",
            "|    policy_gradient_loss | -0.00249     |\n",
            "|    reward               | -0.6281023   |\n",
            "|    std                  | 1.43         |\n",
            "|    value_loss           | 2.7          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 449          |\n",
            "|    time_elapsed         | 2568         |\n",
            "|    total_timesteps      | 919552       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037930682 |\n",
            "|    clip_fraction        | 0.0149       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.53        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0795       |\n",
            "|    n_updates            | 4480         |\n",
            "|    policy_gradient_loss | -0.00151     |\n",
            "|    reward               | 0.10355089   |\n",
            "|    std                  | 1.42         |\n",
            "|    value_loss           | 0.179        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 450          |\n",
            "|    time_elapsed         | 2573         |\n",
            "|    total_timesteps      | 921600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069308667 |\n",
            "|    clip_fraction        | 0.0601       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.52        |\n",
            "|    explained_variance   | 4.18e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.47         |\n",
            "|    n_updates            | 4490         |\n",
            "|    policy_gradient_loss | -0.00468     |\n",
            "|    reward               | 0.02015158   |\n",
            "|    std                  | 1.42         |\n",
            "|    value_loss           | 2.28         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 451          |\n",
            "|    time_elapsed         | 2579         |\n",
            "|    total_timesteps      | 923648       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049274624 |\n",
            "|    clip_fraction        | 0.0452       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.51        |\n",
            "|    explained_variance   | 4.68e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.11         |\n",
            "|    n_updates            | 4500         |\n",
            "|    policy_gradient_loss | -0.00291     |\n",
            "|    reward               | 0.29375738   |\n",
            "|    std                  | 1.41         |\n",
            "|    value_loss           | 2.43         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 452          |\n",
            "|    time_elapsed         | 2584         |\n",
            "|    total_timesteps      | 925696       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036267722 |\n",
            "|    clip_fraction        | 0.0308       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.5         |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.27         |\n",
            "|    n_updates            | 4510         |\n",
            "|    policy_gradient_loss | -0.00195     |\n",
            "|    reward               | -0.008596859 |\n",
            "|    std                  | 1.41         |\n",
            "|    value_loss           | 0.535        |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 320\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -471750.01\n",
            "total_reward: -481750.01\n",
            "total_cost: 718.88\n",
            "total_trades: 3588\n",
            "Sharpe: 0.429\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 453          |\n",
            "|    time_elapsed         | 2590         |\n",
            "|    total_timesteps      | 927744       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.004580338  |\n",
            "|    clip_fraction        | 0.0266       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.5         |\n",
            "|    explained_variance   | 4.3e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.893        |\n",
            "|    n_updates            | 4520         |\n",
            "|    policy_gradient_loss | -0.00269     |\n",
            "|    reward               | -0.013212446 |\n",
            "|    std                  | 1.4          |\n",
            "|    value_loss           | 2.42         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 454          |\n",
            "|    time_elapsed         | 2595         |\n",
            "|    total_timesteps      | 929792       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042033494 |\n",
            "|    clip_fraction        | 0.0245       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.49        |\n",
            "|    explained_variance   | 4.57e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.782        |\n",
            "|    n_updates            | 4530         |\n",
            "|    policy_gradient_loss | -0.00206     |\n",
            "|    reward               | -3.297593    |\n",
            "|    std                  | 1.4          |\n",
            "|    value_loss           | 1.71         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 455          |\n",
            "|    time_elapsed         | 2600         |\n",
            "|    total_timesteps      | 931840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025834609 |\n",
            "|    clip_fraction        | 0.00947      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.49        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.533        |\n",
            "|    n_updates            | 4540         |\n",
            "|    policy_gradient_loss | -0.000534    |\n",
            "|    reward               | 0.002124899  |\n",
            "|    std                  | 1.41         |\n",
            "|    value_loss           | 1.71         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 358           |\n",
            "|    iterations           | 456           |\n",
            "|    time_elapsed         | 2606          |\n",
            "|    total_timesteps      | 933888        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0028725208  |\n",
            "|    clip_fraction        | 0.00313       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.5          |\n",
            "|    explained_variance   | 2.6e-05       |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 0.237         |\n",
            "|    n_updates            | 4550          |\n",
            "|    policy_gradient_loss | -6.47e-05     |\n",
            "|    reward               | -0.0012207493 |\n",
            "|    std                  | 1.41          |\n",
            "|    value_loss           | 0.41          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 457          |\n",
            "|    time_elapsed         | 2611         |\n",
            "|    total_timesteps      | 935936       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051805484 |\n",
            "|    clip_fraction        | 0.0332       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.5         |\n",
            "|    explained_variance   | 4.21e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.02         |\n",
            "|    n_updates            | 4560         |\n",
            "|    policy_gradient_loss | -0.00266     |\n",
            "|    reward               | -0.016808165 |\n",
            "|    std                  | 1.41         |\n",
            "|    value_loss           | 2.1          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 458          |\n",
            "|    time_elapsed         | 2616         |\n",
            "|    total_timesteps      | 937984       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0057231225 |\n",
            "|    clip_fraction        | 0.0428       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.49        |\n",
            "|    explained_variance   | 5.5e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.64         |\n",
            "|    n_updates            | 4570         |\n",
            "|    policy_gradient_loss | -0.00283     |\n",
            "|    reward               | -2.0556734   |\n",
            "|    std                  | 1.4          |\n",
            "|    value_loss           | 1.91         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 459          |\n",
            "|    time_elapsed         | 2621         |\n",
            "|    total_timesteps      | 940032       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018560345 |\n",
            "|    clip_fraction        | 0.00415      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.48        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0816       |\n",
            "|    n_updates            | 4580         |\n",
            "|    policy_gradient_loss | -0.000376    |\n",
            "|    reward               | -0.31795654  |\n",
            "|    std                  | 1.4          |\n",
            "|    value_loss           | 0.273        |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 325\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -573995.64\n",
            "total_reward: -583995.64\n",
            "total_cost: 810.28\n",
            "total_trades: 3610\n",
            "Sharpe: 0.539\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 460          |\n",
            "|    time_elapsed         | 2627         |\n",
            "|    total_timesteps      | 942080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046872175 |\n",
            "|    clip_fraction        | 0.0384       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.47        |\n",
            "|    explained_variance   | 4.14e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.706        |\n",
            "|    n_updates            | 4590         |\n",
            "|    policy_gradient_loss | -0.00268     |\n",
            "|    reward               | 0.0009797728 |\n",
            "|    std                  | 1.4          |\n",
            "|    value_loss           | 1.52         |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 358        |\n",
            "|    iterations           | 461        |\n",
            "|    time_elapsed         | 2632       |\n",
            "|    total_timesteps      | 944128     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00419386 |\n",
            "|    clip_fraction        | 0.0191     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.47      |\n",
            "|    explained_variance   | 5.63e-05   |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 0.936      |\n",
            "|    n_updates            | 4600       |\n",
            "|    policy_gradient_loss | -0.00199   |\n",
            "|    reward               | -0.9385321 |\n",
            "|    std                  | 1.39       |\n",
            "|    value_loss           | 2.19       |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 462          |\n",
            "|    time_elapsed         | 2637         |\n",
            "|    total_timesteps      | 946176       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033530334 |\n",
            "|    clip_fraction        | 0.0125       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.46        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.847        |\n",
            "|    n_updates            | 4610         |\n",
            "|    policy_gradient_loss | -0.000864    |\n",
            "|    reward               | 0.40890992   |\n",
            "|    std                  | 1.39         |\n",
            "|    value_loss           | 1.24         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 463          |\n",
            "|    time_elapsed         | 2643         |\n",
            "|    total_timesteps      | 948224       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.00383128   |\n",
            "|    clip_fraction        | 0.0229       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.47        |\n",
            "|    explained_variance   | 6.34e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.464        |\n",
            "|    n_updates            | 4620         |\n",
            "|    policy_gradient_loss | -0.000939    |\n",
            "|    reward               | -0.011780518 |\n",
            "|    std                  | 1.4          |\n",
            "|    value_loss           | 1.09         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 464          |\n",
            "|    time_elapsed         | 2648         |\n",
            "|    total_timesteps      | 950272       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043093376 |\n",
            "|    clip_fraction        | 0.0228       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.48        |\n",
            "|    explained_variance   | 4.55e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.666        |\n",
            "|    n_updates            | 4630         |\n",
            "|    policy_gradient_loss | -0.00181     |\n",
            "|    reward               | 0.0057914346 |\n",
            "|    std                  | 1.41         |\n",
            "|    value_loss           | 2.33         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 358         |\n",
            "|    iterations           | 465         |\n",
            "|    time_elapsed         | 2654        |\n",
            "|    total_timesteps      | 952320      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005305034 |\n",
            "|    clip_fraction        | 0.0329      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.48       |\n",
            "|    explained_variance   | 4.85e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.797       |\n",
            "|    n_updates            | 4640        |\n",
            "|    policy_gradient_loss | -0.0024     |\n",
            "|    reward               | 0.2766043   |\n",
            "|    std                  | 1.4         |\n",
            "|    value_loss           | 2.09        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 358         |\n",
            "|    iterations           | 466         |\n",
            "|    time_elapsed         | 2659        |\n",
            "|    total_timesteps      | 954368      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003958353 |\n",
            "|    clip_fraction        | 0.0141      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.47       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0505      |\n",
            "|    n_updates            | 4650        |\n",
            "|    policy_gradient_loss | -0.000944   |\n",
            "|    reward               | -0.18211344 |\n",
            "|    std                  | 1.39        |\n",
            "|    value_loss           | 0.218       |\n",
            "-----------------------------------------\n",
            "day: 2896, episode: 330\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -600749.38\n",
            "total_reward: -610749.38\n",
            "total_cost: 804.59\n",
            "total_trades: 3614\n",
            "Sharpe: 0.345\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 467          |\n",
            "|    time_elapsed         | 2664         |\n",
            "|    total_timesteps      | 956416       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037901541 |\n",
            "|    clip_fraction        | 0.0154       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.47        |\n",
            "|    explained_variance   | 3.83e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.04         |\n",
            "|    n_updates            | 4660         |\n",
            "|    policy_gradient_loss | -0.00131     |\n",
            "|    reward               | -0.023406172 |\n",
            "|    std                  | 1.4          |\n",
            "|    value_loss           | 1.94         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 468          |\n",
            "|    time_elapsed         | 2670         |\n",
            "|    total_timesteps      | 958464       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029193922 |\n",
            "|    clip_fraction        | 0.00845      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.47        |\n",
            "|    explained_variance   | 4.83e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.77         |\n",
            "|    n_updates            | 4670         |\n",
            "|    policy_gradient_loss | -0.000599    |\n",
            "|    reward               | -0.27999535  |\n",
            "|    std                  | 1.4          |\n",
            "|    value_loss           | 2.7          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 469          |\n",
            "|    time_elapsed         | 2675         |\n",
            "|    total_timesteps      | 960512       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030076664 |\n",
            "|    clip_fraction        | 0.0187       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.48        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.117        |\n",
            "|    n_updates            | 4680         |\n",
            "|    policy_gradient_loss | -0.00183     |\n",
            "|    reward               | 0.19034506   |\n",
            "|    std                  | 1.41         |\n",
            "|    value_loss           | 0.468        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 470          |\n",
            "|    time_elapsed         | 2681         |\n",
            "|    total_timesteps      | 962560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052219396 |\n",
            "|    clip_fraction        | 0.0212       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.48        |\n",
            "|    explained_variance   | 3.02e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.631        |\n",
            "|    n_updates            | 4690         |\n",
            "|    policy_gradient_loss | -0.00118     |\n",
            "|    reward               | -0.016262421 |\n",
            "|    std                  | 1.41         |\n",
            "|    value_loss           | 1.26         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 358         |\n",
            "|    iterations           | 471         |\n",
            "|    time_elapsed         | 2687        |\n",
            "|    total_timesteps      | 964608      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005006884 |\n",
            "|    clip_fraction        | 0.0258      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.49       |\n",
            "|    explained_variance   | 5.15e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.06        |\n",
            "|    n_updates            | 4700        |\n",
            "|    policy_gradient_loss | -0.00167    |\n",
            "|    reward               | 0.50979114  |\n",
            "|    std                  | 1.41        |\n",
            "|    value_loss           | 1.78        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 358         |\n",
            "|    iterations           | 472         |\n",
            "|    time_elapsed         | 2692        |\n",
            "|    total_timesteps      | 966656      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007200052 |\n",
            "|    clip_fraction        | 0.0446      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.5        |\n",
            "|    explained_variance   | 5.96e-08    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.896       |\n",
            "|    n_updates            | 4710        |\n",
            "|    policy_gradient_loss | -0.0028     |\n",
            "|    reward               | -0.12466692 |\n",
            "|    std                  | 1.42        |\n",
            "|    value_loss           | 1.73        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 358          |\n",
            "|    iterations           | 473          |\n",
            "|    time_elapsed         | 2698         |\n",
            "|    total_timesteps      | 968704       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.006037263  |\n",
            "|    clip_fraction        | 0.0553       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.5         |\n",
            "|    explained_variance   | 5.82e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.0801       |\n",
            "|    n_updates            | 4720         |\n",
            "|    policy_gradient_loss | -0.00388     |\n",
            "|    reward               | 0.0049110926 |\n",
            "|    std                  | 1.42         |\n",
            "|    value_loss           | 0.263        |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 335\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -555813.03\n",
            "total_reward: -565813.03\n",
            "total_cost: 797.53\n",
            "total_trades: 3692\n",
            "Sharpe: -0.451\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 359          |\n",
            "|    iterations           | 474          |\n",
            "|    time_elapsed         | 2703         |\n",
            "|    total_timesteps      | 970752       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043474063 |\n",
            "|    clip_fraction        | 0.0167       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.51        |\n",
            "|    explained_variance   | 3.23e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.754        |\n",
            "|    n_updates            | 4730         |\n",
            "|    policy_gradient_loss | -0.00105     |\n",
            "|    reward               | 0.0063575134 |\n",
            "|    std                  | 1.42         |\n",
            "|    value_loss           | 1.59         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 359          |\n",
            "|    iterations           | 475          |\n",
            "|    time_elapsed         | 2709         |\n",
            "|    total_timesteps      | 972800       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023982774 |\n",
            "|    clip_fraction        | 0.00977      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.51        |\n",
            "|    explained_variance   | 3.89e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.888        |\n",
            "|    n_updates            | 4740         |\n",
            "|    policy_gradient_loss | -0.00104     |\n",
            "|    reward               | -0.197533    |\n",
            "|    std                  | 1.42         |\n",
            "|    value_loss           | 2.31         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 359          |\n",
            "|    iterations           | 476          |\n",
            "|    time_elapsed         | 2715         |\n",
            "|    total_timesteps      | 974848       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071265963 |\n",
            "|    clip_fraction        | 0.0754       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.51        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.197        |\n",
            "|    n_updates            | 4750         |\n",
            "|    policy_gradient_loss | -0.00527     |\n",
            "|    reward               | 0.47427917   |\n",
            "|    std                  | 1.43         |\n",
            "|    value_loss           | 0.594        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 359         |\n",
            "|    iterations           | 477         |\n",
            "|    time_elapsed         | 2720        |\n",
            "|    total_timesteps      | 976896      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004156233 |\n",
            "|    clip_fraction        | 0.0189      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.51       |\n",
            "|    explained_variance   | 4.42e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.584       |\n",
            "|    n_updates            | 4760        |\n",
            "|    policy_gradient_loss | -0.00111    |\n",
            "|    reward               | 0.010386407 |\n",
            "|    std                  | 1.42        |\n",
            "|    value_loss           | 2.3         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 359         |\n",
            "|    iterations           | 478         |\n",
            "|    time_elapsed         | 2726        |\n",
            "|    total_timesteps      | 978944      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004042605 |\n",
            "|    clip_fraction        | 0.0268      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.51       |\n",
            "|    explained_variance   | 4.49e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.83        |\n",
            "|    n_updates            | 4770        |\n",
            "|    policy_gradient_loss | -0.00133    |\n",
            "|    reward               | 0.1722786   |\n",
            "|    std                  | 1.42        |\n",
            "|    value_loss           | 3.26        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 359         |\n",
            "|    iterations           | 479         |\n",
            "|    time_elapsed         | 2731        |\n",
            "|    total_timesteps      | 980992      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005503176 |\n",
            "|    clip_fraction        | 0.0256      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.51       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.406       |\n",
            "|    n_updates            | 4780        |\n",
            "|    policy_gradient_loss | -0.00245    |\n",
            "|    reward               | 0.16788943  |\n",
            "|    std                  | 1.41        |\n",
            "|    value_loss           | 1.4         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 359          |\n",
            "|    iterations           | 480          |\n",
            "|    time_elapsed         | 2736         |\n",
            "|    total_timesteps      | 983040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0057235225 |\n",
            "|    clip_fraction        | 0.021        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.5         |\n",
            "|    explained_variance   | 6.52e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.284        |\n",
            "|    n_updates            | 4790         |\n",
            "|    policy_gradient_loss | -0.000911    |\n",
            "|    reward               | 0.0002629434 |\n",
            "|    std                  | 1.41         |\n",
            "|    value_loss           | 0.754        |\n",
            "------------------------------------------\n",
            "day: 2896, episode: 340\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -484334.76\n",
            "total_reward: -494334.76\n",
            "total_cost: 872.83\n",
            "total_trades: 3654\n",
            "Sharpe: 0.687\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 359          |\n",
            "|    iterations           | 481          |\n",
            "|    time_elapsed         | 2742         |\n",
            "|    total_timesteps      | 985088       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058554597 |\n",
            "|    clip_fraction        | 0.0292       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.49        |\n",
            "|    explained_variance   | 2.55e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.521        |\n",
            "|    n_updates            | 4800         |\n",
            "|    policy_gradient_loss | -0.00217     |\n",
            "|    reward               | -0.007791533 |\n",
            "|    std                  | 1.41         |\n",
            "|    value_loss           | 1.75         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 359          |\n",
            "|    iterations           | 482          |\n",
            "|    time_elapsed         | 2747         |\n",
            "|    total_timesteps      | 987136       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020116833 |\n",
            "|    clip_fraction        | 0.00186      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.49        |\n",
            "|    explained_variance   | 4.8e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.841        |\n",
            "|    n_updates            | 4810         |\n",
            "|    policy_gradient_loss | -0.000422    |\n",
            "|    reward               | -0.040827192 |\n",
            "|    std                  | 1.41         |\n",
            "|    value_loss           | 2.01         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 359         |\n",
            "|    iterations           | 483         |\n",
            "|    time_elapsed         | 2753        |\n",
            "|    total_timesteps      | 989184      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005242831 |\n",
            "|    clip_fraction        | 0.0303      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.5        |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0494      |\n",
            "|    n_updates            | 4820        |\n",
            "|    policy_gradient_loss | -0.00183    |\n",
            "|    reward               | 0.04813735  |\n",
            "|    std                  | 1.42        |\n",
            "|    value_loss           | 0.26        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 359          |\n",
            "|    iterations           | 484          |\n",
            "|    time_elapsed         | 2758         |\n",
            "|    total_timesteps      | 991232       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041327197 |\n",
            "|    clip_fraction        | 0.0132       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.51        |\n",
            "|    explained_variance   | 5.3e-05      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.9          |\n",
            "|    n_updates            | 4830         |\n",
            "|    policy_gradient_loss | -0.00102     |\n",
            "|    reward               | -0.02276609  |\n",
            "|    std                  | 1.42         |\n",
            "|    value_loss           | 2.07         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 359         |\n",
            "|    iterations           | 485         |\n",
            "|    time_elapsed         | 2764        |\n",
            "|    total_timesteps      | 993280      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007853522 |\n",
            "|    clip_fraction        | 0.0492      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.51       |\n",
            "|    explained_variance   | 3.97e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.89        |\n",
            "|    n_updates            | 4840        |\n",
            "|    policy_gradient_loss | -0.00315    |\n",
            "|    reward               | -1.6826979  |\n",
            "|    std                  | 1.42        |\n",
            "|    value_loss           | 2.61        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 359         |\n",
            "|    iterations           | 486         |\n",
            "|    time_elapsed         | 2769        |\n",
            "|    total_timesteps      | 995328      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004807608 |\n",
            "|    clip_fraction        | 0.043       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.51       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.28        |\n",
            "|    n_updates            | 4850        |\n",
            "|    policy_gradient_loss | -0.00286    |\n",
            "|    reward               | 0.24863872  |\n",
            "|    std                  | 1.42        |\n",
            "|    value_loss           | 1.53        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 359         |\n",
            "|    iterations           | 487         |\n",
            "|    time_elapsed         | 2775        |\n",
            "|    total_timesteps      | 997376      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006098197 |\n",
            "|    clip_fraction        | 0.0584      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.51       |\n",
            "|    explained_variance   | 7.69e-05    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.516       |\n",
            "|    n_updates            | 4860        |\n",
            "|    policy_gradient_loss | -0.0042     |\n",
            "|    reward               | -0.02872915 |\n",
            "|    std                  | 1.43        |\n",
            "|    value_loss           | 1.69        |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 359           |\n",
            "|    iterations           | 488           |\n",
            "|    time_elapsed         | 2781          |\n",
            "|    total_timesteps      | 999424        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.004098502   |\n",
            "|    clip_fraction        | 0.0211        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -3.52         |\n",
            "|    explained_variance   | 4.36e-05      |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 1.96          |\n",
            "|    n_updates            | 4870          |\n",
            "|    policy_gradient_loss | -0.00182      |\n",
            "|    reward               | -0.0051941588 |\n",
            "|    std                  | 1.43          |\n",
            "|    value_loss           | 3.12          |\n",
            "-------------------------------------------\n",
            "day: 2896, episode: 345\n",
            "begin_total_asset: 10000.00\n",
            "end_total_asset: -659381.22\n",
            "total_reward: -669381.22\n",
            "total_cost: 735.67\n",
            "total_trades: 3946\n",
            "Sharpe: 0.649\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 359          |\n",
            "|    iterations           | 489          |\n",
            "|    time_elapsed         | 2787         |\n",
            "|    total_timesteps      | 1001472      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044767633 |\n",
            "|    clip_fraction        | 0.0117       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.51        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 1.4          |\n",
            "|    n_updates            | 4880         |\n",
            "|    policy_gradient_loss | -0.000837    |\n",
            "|    reward               | 0.34210974   |\n",
            "|    std                  | 1.43         |\n",
            "|    value_loss           | 2.91         |\n",
            "------------------------------------------\n",
            "======PPO Validation from:  2021-10-04 to  2022-01-03\n",
            "PPO Sharpe Ratio:  -0.46149065799229233\n",
            "======Best Model Retraining from:  2010-04-01 to  2022-01-03\n",
            "======Trading from:  2022-01-03 to  2022-04-04\n",
            "[[ 593.2583     155.68903    642.6515    -103.          51.\n",
            "     0.9646785   27.117754   161.18152    680.7989     148.02783\n",
            "   546.65094     49.942413    67.751976    30.670969    91.113716\n",
            "     4.2563453   53.900658   154.06818    587.7529     154.93849\n",
            "   549.4282   ]]\n",
            "Ensemble Strategy took:  171.71917641162872  minutes\n"
          ]
        }
      ],
      "source": [
        "# df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n",
        "#                                                  PPO_model_kwargs,\n",
        "#                                                  DDPG_model_kwargs,\n",
        "#                                                  timesteps_dict)\n",
        "df_summary = ensemble_agent.run_ensemble_strategy(None,\n",
        "                                                 PPO_model_kwargs,\n",
        "                                                 None,\n",
        "                                                 timesteps_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "-0qd8acMtj1f",
        "outputId": "b5d9cb94-51a9-4569-a9a8-7e18f1139f4e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iter</th>\n",
              "      <th>Val Start</th>\n",
              "      <th>Val End</th>\n",
              "      <th>Model Used</th>\n",
              "      <th>A2C Sharpe</th>\n",
              "      <th>PPO Sharpe</th>\n",
              "      <th>DDPG Sharpe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>126</td>\n",
              "      <td>2021-01-04</td>\n",
              "      <td>2021-04-06</td>\n",
              "      <td>PPO</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.064783</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>189</td>\n",
              "      <td>2021-04-06</td>\n",
              "      <td>2021-07-06</td>\n",
              "      <td>PPO</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.112206</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>252</td>\n",
              "      <td>2021-07-06</td>\n",
              "      <td>2021-10-04</td>\n",
              "      <td>PPO</td>\n",
              "      <td>0</td>\n",
              "      <td>0.084356</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>315</td>\n",
              "      <td>2021-10-04</td>\n",
              "      <td>2022-01-03</td>\n",
              "      <td>PPO</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.461491</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Iter   Val Start     Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n",
              "0  126  2021-01-04  2021-04-06        PPO          0  -0.064783           0\n",
              "1  189  2021-04-06  2021-07-06        PPO          0  -0.112206           0\n",
              "2  252  2021-07-06  2021-10-04        PPO          0   0.084356           0\n",
              "3  315  2021-10-04  2022-01-03        PPO          0  -0.461491           0"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6vvNSC6h1jZ"
      },
      "source": [
        "<a id='6'></a>\n",
        "# Part 7: Backtest Our Strategy\n",
        "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "X4JKB--8tj1g"
      },
      "outputs": [],
      "source": [
        "unique_trade_date = processed[(processed.date > TEST_START_DATE)&(processed.date <= TEST_END_DATE)].date.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9mKF7GGtj1g",
        "outputId": "8b89807b-ff71-4902-dd45-1f9111788cbb",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sharpe Ratio:  1.2283504861902412\n"
          ]
        }
      ],
      "source": [
        "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\n",
        "\n",
        "df_account_value=pd.DataFrame()\n",
        "for i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n",
        "    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n",
        "    df_account_value = df_account_value.append(temp,ignore_index=True)\n",
        "sharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\n",
        "print('Sharpe Ratio: ',sharpe)\n",
        "df_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oyosyW7_tj1g",
        "outputId": "d2dc62c2-e2a0-48fc-8183-0399d1b27f53"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>account_value</th>\n",
              "      <th>date</th>\n",
              "      <th>daily_return</th>\n",
              "      <th>datadate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000.000000</td>\n",
              "      <td>2021-04-06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2021-04-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9999.024008</td>\n",
              "      <td>2021-04-07</td>\n",
              "      <td>-0.000098</td>\n",
              "      <td>2021-04-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9994.634467</td>\n",
              "      <td>2021-04-08</td>\n",
              "      <td>-0.000439</td>\n",
              "      <td>2021-04-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9996.583334</td>\n",
              "      <td>2021-04-09</td>\n",
              "      <td>0.000195</td>\n",
              "      <td>2021-04-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004.388871</td>\n",
              "      <td>2021-04-12</td>\n",
              "      <td>0.000781</td>\n",
              "      <td>2021-04-12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   account_value        date  daily_return    datadate\n",
              "0   10000.000000  2021-04-06           NaN  2021-04-06\n",
              "1    9999.024008  2021-04-07     -0.000098  2021-04-07\n",
              "2    9994.634467  2021-04-08     -0.000439  2021-04-08\n",
              "3    9996.583334  2021-04-09      0.000195  2021-04-09\n",
              "4   10004.388871  2021-04-12      0.000781  2021-04-12"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_account_value.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "wLsRdw2Ctj1h",
        "outputId": "9a874df9-2c5f-423c-8fd2-8966aab63fc0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot: >"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "df_account_value.account_value.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr2zX7ZxNyFQ"
      },
      "source": [
        "<a id='6.1'></a>\n",
        "## 7.1 BackTestStats\n",
        "pass in df_account_value, this information is stored in env class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nzkr9yv-AdV_",
        "outputId": "b419a565-8c15-47d8-f66c-00f81c3c526d",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============Get Backtest Results===========\n"
          ]
        }
      ],
      "source": [
        "print(\"==============Get Backtest Results===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiHhM1YkoCel",
        "outputId": "903ef035-f9f4-4678-d18a-1516254eaf3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============Get Baseline Stats===========\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (251, 8)\n"
          ]
        }
      ],
      "source": [
        "#baseline stats\n",
        "print(\"==============Get Baseline Stats===========\")\n",
        "baseline_df = get_baseline(\n",
        "        ticker=\"^GSPC\", \n",
        "        start = df_account_value.loc[0,'date'],\n",
        "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
        "\n",
        "stats = backtest_stats(baseline_df, value_col_name = 'close')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U6Suru3h1jc"
      },
      "source": [
        "<a id='6.2'></a>\n",
        "## 7.2 BackTestPlot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HggausPRoCem",
        "outputId": "e61a64e0-58ed-4490-b19a-78bd4f76e666"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============Compare to DJIA===========\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (251, 8)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Worst drawdown periods</th>\n",
              "      <th>Net drawdown in %</th>\n",
              "      <th>Peak date</th>\n",
              "      <th>Valley date</th>\n",
              "      <th>Recovery date</th>\n",
              "      <th>Duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31.74</td>\n",
              "      <td>2021-05-12</td>\n",
              "      <td>2021-09-08</td>\n",
              "      <td>2021-11-04</td>\n",
              "      <td>127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>29.67</td>\n",
              "      <td>2022-01-04</td>\n",
              "      <td>2022-01-21</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9.83</td>\n",
              "      <td>2021-11-18</td>\n",
              "      <td>2021-11-22</td>\n",
              "      <td>2021-11-24</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.45</td>\n",
              "      <td>2021-11-05</td>\n",
              "      <td>2021-11-10</td>\n",
              "      <td>2021-11-15</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.32</td>\n",
              "      <td>2021-11-24</td>\n",
              "      <td>2021-11-26</td>\n",
              "      <td>2021-11-29</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Stress Events</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>New Normal</th>\n",
              "      <td>0.21%</td>\n",
              "      <td>-6.10%</td>\n",
              "      <td>17.31%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2AAAA36CAYAAACmUEXcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOzdd3xkWXkn/N+pqArKObVi5zzdMx1megJDNAzGBmxsggeDYezFNsavbQxeM2DAuwuL2eV9AcMsHtgh2ATDDgtD8szQ0NNhejq3Wt3KOZWqpEqqeN4/SnV1q1SSStKtIOn3/Xz06Vu3bt17SlKX6qnnOc8RUkoQERERERFR5ulyPQAiIiIiIqKtggEYERERERFRljAAIyIiIiIiyhIGYERERERERFnCAIyIiIiIiChLGIARERERERFlCQMwIiLaNIQQTwohnlznOT4khPixRkMiIiJKwACMiIhWTQhxQAjxb0KIMSGERwjRI4T4mhBiX67HthpCiOeEEI+r90kpPymlfE2OhrQkIUSfEOLRXI+DiIjWhwEYERGtihDiQQDnAAwDOAagEMBRAL8G8Js5G9gGJYQwZfFaOiGEPlvXIyKixRiAERHRav0zgH+TUv6FlLJfxkxLKf9ZSvkJIHUpYHK2SQghhRB/JoQ4L4TwCiHOCiG2ze8bEEJMCyH+i+r4B4UQMumcjwoh+pYaqBDiH4QQXfNZuv7527r5+74I4BSAD83fPza//3EhxHPz238ihLiVdM7C+eNfNn+7RAjxhfnzO4QQPxJCtC4zpkfns1nvF0IMABiY379LCPFDIcS4EGJYCPF5IYRt/r4fA9gG4Ivz1z6f6ns6v0/JlAkhmue/z+8SQlwH4AOwe/6YDwshfiyEcAsh7gghflN1joNCiOeFEC4hhFMIcVEIsXOp50REROljAEZERGkTQmwHsAPA/9bolG8D8EYAlYgFBz8HUAWgHcDDAD4ghHhgHefvBPAgYlm6NwH4YwDvAgAp5WMATgP4pJTSLqWsSfH4bwBoEkLcq9r3uwDGATwrhBAA/h2AHcBhAHUArgL4oRDCuMy4GhD7Pu4G0CqEqJgfy08RC7QOAtgO4LPzY30NYoHaY/NjvWd13wb8AYBXz4/z9vy+PwLwIQDFAL4E4GtCCPv8fZ8H8AsAFYj9bN4FwLXKaxIRUQoMwIiIaDWq5v8d1uh8/ySlHJRS+gB8B0A9gI9IKYNSyksAriNW3rgmUsqnpJRD81m6CwC+DuDlq3i8C8B3MR+0zXsXgK9IKSViQdcJAO+dzwIGAHwYsSDq2DKnjgL4gJTSO//c3wHglpTyf0opA1LKKQB/B+AdGpUMfnT++xCWUgbn931JSnlJShkF8AUARQDiWa7g/HNomn/MZSnluAbjICLa8hiAERHRakzM/1uv0flGVds+AJNSykjSvsK1nlwI8cdCiMvzZXQuAO/FQhCZricA/I4Qwi6E2APgbgD/Mn/fdgAmACPz5XouAA4AegCNy5xzTEo5p7q9HcCx+Dnmz/NTABJAqszcavWm2DcS35BSeuY349/rR+ev/R9CiEEhxD/FyyGJiGh9DLkeABERbRxSyjtCiNsA3opYueBS3FgcONSt8/JuABBC2KSU3pXOKYQ4iVgJ3ysAnJFShoUQ/wOx8r64aBrXfR6xQPF3ESsZfEZKGQ9exgD4AVRIKcOreC7J1x0D8JyU8pWreAwQ+54ogZEQwoDUAWY6z1MhpexHrEQRQoh2AD8AMAvgI6s5DxERLcYMGBERrdZ7AfyuEOJT800zxHwjincJIT40f8yLAB4WQuwQQhiFEO8H0LLO695GLOB473w3v0MA3rPM8cUAIgAmAUSEEKcQCxzVxhCbi7Wk+VLDryD2vN+OWEYs7lcAOgB8XghRBQBCiFIhxBuFENZ0nxhiGbWjQojHhBDW+e9poxDiDUljTW6E8SKANwghaoUQFgD/BcByc8/SMt8opGF+jtssgDBi30siIlonBmBERLQqUsrnEJv31IRYAOAGcAmxjoLfnz/s6wC+DeAsgEEAJYi1qV/Pdd2INZP4T4gFBf+IWPOIpfwEwP+av+40gD+bH5fafwewb77sb2iZc30VwF2IleX9UDWmCGIZtjkA54QQbgBXAPzW/LHpPrcBACcBvApAN2INL34CYL/qsI8BeNN8OeWZ+X3/BOAyYs1GOgF0QZv5eQ8BOA/Ag9jzeQHApzQ4LxHRlidiH+wRERERERFRpjEDRkRERERElCUMwIiIiIiIiLKEARgREREREVGWMAAjIiIiIiLKEq4DloIQwozYQpujYNtdIiIiIiJKTQ+gFsAFKWUgnQcwAEvtbgCncz0IIiIiIiLaEE4htjbkihiApTYKAKdPn0ZDQ0Oux0JERERERHloaGgIp06dAubjh3QwAEstAgANDQ1obm7O8VCIiIiIiCjPpT1tiU04iIiIiIiIsoQBGBERERERUZYwACMiIiIiIsoSzgEjIiIiIsoAKSWmp6cRCKTVnZzylF6vR1FRESwWiybnYwBGRERERJQBbrcbQgjU1tZCCJHr4dAaSCkRCoUwPT0NAJoEYSxBJCIiIiLKAJ/Ph6KiIgZfG5gQAiaTCWVlZZidndXknAzAiIiIiIgyIBqNQq/X53oYpAGj0YhIJO1O88tiAEZERERElCHMfm0OWv4cGYAREREREREef/xxvOUtb1nxuMceewwf+chHAADPPfccampqMj20TYVNOIiIiIiIKG1f/OIXc3r9xx9/HLdu3cK3vvWtnI5jrZgBIyIiIiKivBEOhzf0+VfCAIyIiIiIaAu6evUq7rnnHhQWFuLVr341pqamlPve8pa3oKamBsXFxXjwwQfR0dGh3Pfoo4/igx/84KLzffrTn8brX//6hH0f+tCH8Ad/8AfLjuPRRx/Fe97zHjzyyCOw2Wz44Q9/iJGREbzpTW9CVVUVmpub8d//+38HADzzzDP45Cc/ie9+97uw2+3YuXMnAKC5uRnPPPOMcs4nn3wSx48fV24LIfC5z30OO3bsQG1trVI6+bnPfQ61tbWorKzEJz/5yVV899aOARgRERER0RYTCoXwm7/5m3jDG94Ah8OBv/7rv8aTTz6p3P/qV78ad+7cwfj4OPbt24e3v/3tK57zbW97G37+858rgZyUEl//+tfxjne8Y8XHfvOb38Rf/dVfwe124xWveAUeeeQR7NmzB4ODg3juuefwhS98AT/4wQ/w6le/Gh/60Ifwxje+ER6PB52dnWk/53//93/HmTNnMDAwAACYmprC4OAg+vr68Mwzz+Dxxx/HjRs30j7fWnEOGBERERFRFjz99NNZuc4jjzyy4jEvvPACvF4vPvjBD0Kn0+FlL3sZHnnkEUgpAcSyUnGPP/44Kisr4fV6YbPZljxnTU0NHnroIXzrW9/C+973Pjz//POQUuKhhx5Ka8z3338/AOD69esYHR3FRz/6UQgh0NzcjPe+97341re+hd/8zd9c8VxL+eAHP4iKigrltk6nw8c//nGYTCYcOXIEBw8exKVLl7B37941XyMdzIAREREREW0xIyMjqK+vh063EA40NTUBACKRCP76r/8ara2tKCoqQnt7OwAklCgu5dFHH8XXvvY1AMBTTz2Ft771rQnXWEpjY6Oy3d/fj4mJCZSWlqKkpAQlJSX42Mc+hvHx8VU9x+WuAQBlZWUwmUzKbZvNBo/Hs65rpIMZMCIiIiKiLEgnM5UtdXV1GB4eRjQaVQKkeGne17/+dfzgBz/AL37xCzQ3N8PhcKCyslLJji3n9a9/PR577DFcuXIF3/nOd3DmzJm0xqNeZ6uxsRGNjY3o7e1d8dg4u90On8+n3B4dHU3rcbnADBgRERER0RZz4sQJWCwW/Lf/9t8QCoXw3HPPKSWSHo8HZrMZ5eXl8Pl8+PCHP5z2ec1mM97ylrfgHe94B9rb27Fnz55Vj+2ee+5BaWkpPvnJT8Lv9yMSieDmzZs4d+4cAKC6uhp9fX2IRqPKYw4fPoxvfOMbCAaDuHXrFp544olVXzdbGIAREREREW0xRqMRP/jBD/Cd73wHpaWl+Md//EelW+E73vEONDc3o76+Hnv37sXJkydXde5HH30UV69eTav5Rip6vR4//OEPce3aNbS0tKCiogLvfOc74XQ6AQBvfvObYTAYUF5erszX+od/+AeMjo6irKwM73nPe1bsvJhLIp1U4lYjhGgG0Nvb24vm5uYcj4aIiIgoc/whP7ocXWgra4PVZM31cDaVkZER1NXV5XoYWTc+Po5t27ZhaGgIlZWVuR6OZlL9PPv6+tDS0gIALVLKvnTOwzlgRERERFvY/770v9Hv6kdDcQMeu+exvJknQxuTlBKf+cxn8IY3vGFTBV9aYgBGREREtEVFZRT9rn4AwNDMEMLRMIx6Y45HRRuV1+tFdXU1Ghoa8KMf/SjhPrvdnvIx3/rWt/C6170uG8PLGwzAiIiIiLaoQDiQcDsUCTEAozVbro17Ntq7bxRswkFERES0RQUjwYTboWgoRyMh2joYgBERERFtUckZsOSAjIi0xwCMiIiIaItKVYJIRJnFAIyIiIhoiwpEAsveJiLtMQAjIiIi2qKYASPKvrwKwIQQ7xNCXBRCBIUQT65w7J8IIbqFELNCiKtCiNcm3f9xIcSUEMIlhPiCEIItfYiIiIhUFjXhYABG6/Tkk0/i+PHjuR5GXsurAAzACIB/APC/ljtICHEPgE8B+D0AxQAeB/BtIUT5/P3vBvAWAEcBtAM4BODvMjVoIiIioo2ITTi2tgcffBAFBQWw2+0oKirC3XffjV/96lcZu95zzz2HmpoaTc714IMP4otf/KIm58q2vArApJTfk1J+H4BjhUNbANyQUp6XMd8DEADQOn//OwF8RkrZJ6WcAvAxAH+YqXETERERbUTMgNFnP/tZeDweuFwu/OEf/iF++7d/G1LKXA9rU8urAGwVfgxAL4Q4KYTQCyF+F4AbwPX5+/cBuKI6/jKABiFEcfKJhBAlQohm9ReAhswOn4iIiCj3kptucB2wrUun0+Gtb30rJicnMTk5iRdffBEnTpxASUkJamtr8Wd/9mcIhRZ+Pzo6OvCqV70K5eXlqKqqwt/+7d+mPO9HPvIRHDlyBP39/XjNa16DiYkJ2O122O129PT0IBqN4r/+1/+K9vZ2lJeX441vfCMmJycBAHNzc3j729+O8vJylJSU4OjRoxgdHcWHP/xhnD59Gu9///tht9vx7ne/OyvfI61s1ADMA+C7AJ5DLPP1BIB3Sin98/fbAcyojnfN/1uY4lzvB9Cb9HVa6wETERER5ZtFJYhhliBuVeFwGF/96lfR3t6OiooK6PV6fOYzn8HU1BR+/etf45lnnsE///M/AwDcbjde/vKX42UvexmGhobQ19eH17/+9Qnnk1LiT//0T/Hcc8/h2WefRVNTE3784x+jqqoKHo8HHo8Hra2t+NznPofvfOc7+I//+A+MjIyguroa73nPewAAX/3qV+FyuTA4OAiHw4Evf/nLsFqt+MQnPoFTp04p2bsnnngi69+v9TDkegBr9O75r/0A7gB4OYB/FUIclVL2IRagFamOj2e+3CnO9VkATybtawCDMCIiItrkFgVgUQZgmfThn344a9f6xCs/kdZxH/jAB/DBD34Qfr8fOp0O3/jGN6DT6XD48GHlmNbWVrznPe/B888/j/e97334v//3/6KsrAx/8zd/oxxz4sQJZTscDuNtb3sbXC4XnnnmGVgsliWv/8UvfhGf/exnsW3bNgDARz/6UVRXV2Nubg5GoxEOhwN37tzBwYMHE8a0kW3UAOwAgP8rpeycv/1TIUQfgPsA9CFWingQwJn5+w8BGJJSziCJlNKFhQwZAEAIkYEhExEREeWX5BJENuHYej7zmc/gscceQzQaxZkzZ/C6170OLS0tsFgs+MAHPoCLFy/C5/MhHA7j2LFjAICBgQG0tbUtec6enh5cv34dp0+fXjb4AoD+/n68+c1vhk63UJhnMpkwPDyMt7/97RgaGsLv//7vY3p6Gr//+7+PT37ykzCbzdo8+RzJqxJEIYRBCFEAQI/YHK+CJdrHnwPwGiFEm4h5GYA9AK7N3/8kgL8QQjQJISoA/GcAX8nCUyAiIiLaMNiEg+J0Oh3uu+8+bN++HT//+c/xx3/8x9i5cyfu3LmD2dlZfOxjH1OaczQ2NqKnp2fJc+3YsQNPPfUUHnnkEVy7dk3ZnyrJ0djYiKeffhoul0v5mpubQ1tbG4xGI/7+7/8eN27cwLlz5/DTn/5UKTfcyAmTfMuA/R2Aj6huvw3AVwE8KoTwAHiNlPI0gKcAtAH4DwBlAIYBvE9KGW+88QSAZgAXARgBfBPAx7PxBIiIiIg2Ci7EnF3plgXmytmzZ3Hz5k3s3bsX//Zv/4aioiLY7XZ0dHTgn//5n1FfXw8AeN3rXocPfOAD+NSnPoU//dM/RTQaxZUrVxLKEN/0pjchFArhla98JX7+859j7969qK6uhtPphNPpRGlpKQDgsccew9/93d/ha1/7GlpaWjA1NYXTp0/jt37rt/Dss8+ioqICe/bsgd1uh8FgUDJl1dXVywaB+SyvMmBSysellCLp69H5++zzwRfmW88/LqVsklIWSil3SSm/ojqPlFJ+WEpZIaUsllI+JqXkKwoRERGRSnLTDZYgbj3xToJ2ux1ve9vb8PGPfxyvec1r8OlPfxrf/OY3UVhYiPe+97343d/9XeUxhYWF+NnPfoaf/OQnqK2tRUtLC374wx8uOvfv/d7v4VOf+hRe8YpXoKOjA7t27cJb3/pWtLe3o6SkBL29vfjzP/9z/NZv/RZe/epXo6ioCPfccw/OnInNIhobG8Ob3vQmFBcXY/fu3Th+/LjS8fDP//zP8f3vfx+lpaV473vfm51vlkYE+/wvNt+Kvre3txfNzc05Hg0RERFRZnz69Kfh9DuV221lbfjDo1w6VSsjIyOoq6vL9TBII6l+nn19fWhpaQGAlvlmgCvKqwwYEREREWVPcgaMJYhEmccAjIiIiGiLWtQFkW3oiTKOARgRERHRFhSJRhCOhhP2cQ4YUeYxACMiIiLagpI7IAIsQSTKBgZgRERERBtcIBxAVEZX95jI4gCMGTCizMu3dcCIiIiIaBUuDF3A929+H7WFtXjs2GMw6NJ7e5cq2ApFQpBSbuhFbvMNv5+bg5ad45kBIyIiItqg5kJz+PHtHwMARt2j6Hf2p/3YVCWIURlFREY0G99WZzQa4fF4NH3zTtklpUQ4HIbT6YTZbNbknMyAEREREW1QZwfPJgRSU74ptJW3pfXYpcoNQ5FQ2lk0Wl5ZWRmmp6fhdrtzPRRaB51OB6vVisLCQk3Ox/9dRERERBtQMBLEmYEzCfscPkfaj0+VAQNiAZjFaFnX2ChGr9ejsrIy18OgPMMSRCIiIqIN6OLwRXiD3oR9U96ptB+fqgkHwEYcRJnGAIyIiIhogwlHwzjdd3rRfi0yYAzAiDKLARgRERHRBnNl9Apm5mYAAFajVdk/7Z9Oux39kiWIUa4FRpRJDMCIiIiINpCojOKXvb9Ubt/bdC+KzEXKfdO+6bTOs1SmKxhmBowokxiAEREREW0gNyduYsoXm+tlNphxvPE4yq3lyv3pliEuNQeMGTCizGIARkRERLRBSCnxfO/zyu3jjcdRYCxAha1C2efwpxmAcQ4YUU4wACMiIiLaIO447mBkdgQAYNQZcbLpJACsKQOmLjUsMBQo26EIM2BEmcQAjIiIiGiDUM/9OtJwBHaTHUBiAJZuK3p1CWL8PAAzYESZxgCMiIiIaAPod/Wj19kLANAJHU41nVLuUwdgXY4u/MvFf0nZpl5NnQGzmxmAEWULAzAiIiKiDeD5noW5X4dqD6HEUqLcLrOUJRzb5ejCM7efWbYj4lIZMJYgEmUWAzAiIiKiPDfqHkXnVCcAQAiBB1oeSLjfqDeipKBk0ePi3RJTUWe61BkwBmBEmcUAjIiIiCjPqed+7a3am9D1MG5HxY5F++KLNSeTUmIuPKfc5hwwouwx5HoARERERLS0Ke8Uro1fU24nZ7/iXrvrtWgvb8fVsau4Pn4dAOCac6U89tzgOfhDfgCx7Fl8IWeA64ARZRozYERERER57NzgOUgpAQDbK7ajrqgu5XEGnQF7q/eivbxd2ZcqAzblncIzt59Rbp9oPJHQhl7dnIOItMcAjIiIiCiPjXvGle17Gu5Z8fjigmJle3ZuNuG+qIzi29e/rWS5auw1eLj9YRj1RuUYZsCIMosBGBEREVEeU5cRqtvNL0UdgCWXID7X8xyGZoYAAHqhx5v2vwkGnQEmvUk5hnPAiDKLARgRERFRnpJSJpQRpup0mEx9zOzcrFK+ODwzjGd7nlXue3n7y1FbWAsADMCIsogBGBEREVGe8oa8CEfDAACL0QKzwbziY8wGs3JcKBqCN+RFKBLCt69/G1EZBQA0lTThvub7lMeoAzC2oSfKLAZgRERERHlqxr+Q/VKXFq4kOQv2kzs/waR3EkAs2HrTvjdBJxbeBibMAWMARpRRDMCIiIiI8pR6Dlc65Ydx6mDt4shFvDDwgnL7tTtfizJrWcLxCRkwNuEgyigGYERERER5Sh2ArSYDpj727MBZZXtX5S4cqT+y6Hh1BiwQDijzxohIewzAiIiIiPLUahtwxKUK1ox6I96w5w0QQiy6z6AzwGq0Aoi1qncH3KsfLBGlhQEYERERUZ5aawliqmN3VuxEoblwyceUWkqV7Wn/dNrXIqLVYQBGRERElKfUGbBiy9pKEOP2Vu9d9jHqeWFOvzPtaxHR6jAAIyIiIspTLr9L2V5PCaJRZ8TOip3LPkadAWMARpQ5DMCIiIiI8lAoEoIn6AEA6IRu2fLBZMkBWFt524priJVZFjJg0z6WIBJlCgMwIiIiojykLj8sNBcmrNu1EoPOkHC7tax1xcckBGCcA0aUMQzAiIiIiPJQwvyvVbSgjztUewgAUGQuwtH6oysezxJEouwwrHwIEREREWXbWjsgxr1hzxuwp2oP6ovqVyw/BIASSwl0QoeojGI2MItQJJSwPhgRaYMZMCIiIqI8tNY1wOKMeiP2Vu9FiSW9x+qELiHTxiwYUWYwACMiIiLKQ+p5WGspQVyLcmu5ss0AjCgzGIARERER5aE+Z5+yXV1YnZVrcjHm3BqZHUHHRAeiMprroVAGcQ4YERERUZ5wB9ww6ozwhXxKBsqoN6KxuDEr108IwNiKPqumvFP4/LnPQ0qJ39j5G7i36d5cD4kyhAEYERERUR7ocnThqy99FUa9EUfqjij7m0ubF7WVzxR2QsydnukeSCkBADfGbzAA28RYgkhERESUB14YeAFRGUUgHMCZgTPK/raytqyNodyyMAeMJYjZNRNYaLoy5hlTgjHafBiAEREREeWBW5O3Uu7PZgDGDFjuzM7NKtuBcAAOnyOHo1kQlVGMzI4gFAnleiibBgMwIiIiohxTv/lWsxqtqC2szdo4LEYLjLrY2l/BSBCBcCBr197qZgOJvwNjnrEcjSTR0x1P4/87+//hC+e+wOYgGmEARkRERJRjAzMDKfe3lLVACJG1cQghYDfbldvugDtr197qkr/XI7MjORrJAqffiQvDFwAA455xTHmncjyizYEBGBEREVGODc0Mpdy/vXx7lkcCFJoKlW1P0JP1629V6oW3AWDUPZqjkSw4P3g+YS4afx+0wS6IRERERDnW7+pXtl+363W4NXkLNpMNh+sOZ30s6gwY33BnRyAcwFx4LmFfrgOwUCSEF4dfTNjnCfD3QQsMwIiIiIhyKBwNY3R24c32vup9OLHtRM7GYzexBDHbUn2f3QE33AE3Cs2FKR6RedfGr8EX8iWOKcjfBy2wBJGIiIgoh8bcYwhFYx3mSi2lOXvDHae+PjNg2ZHcgCMul1mwc4PnFu3j74M2GIARERER5dDgzKCy3VjcmMORxDADln1LBWBj7tx0QhyaGUo5L5EliNpgAEZERESUQ+oAbFvJthyOJEadAWMAlh3qZQjMBrOyPeGZyMVwcHbgrLJdZC5StpkB0wYDMCIiIqIcGnAttKDPtwwY33Bnx0xgoQNiQ1GDsu0JZf/77w16cW38mnL7gZYHlG0G5NpgAEZERESUI+6AG06/EwBg1BlRU1iT4xEldUFkyVlWuOcWApu6ojplW+vvv5QSZwfO4jO/+gy+fvnrKRdWvjh8EeFoGADQUNyAXZW7lPu8Qa+m49mq2AWRiIiIKEfU82xqi2ph0OX+rVlyBkxKmdXFoLci9RywukJVAKZhBtIX9OHrV76OPmcfAMDhc6Bnugft5e3KMVEZxfmh88rt443HYTPZEsbD34f1YwaMiIiIKEcGZhbKD7cV537+FwAY9UZYjBYAsTfk3hCzHpmmDsBqi2qVbW/Qm7AQ8nr85M5PlOArzjXnSrjdOdmpZGRtRhv2Ve9b9PuQ3JqeVo8BGBEREVGODLpUHRBLcj//Ky4hC8YyxIyKymjC3KpSSykKDAXKfVoEPFJKdEx2LNrvCyae++zgQvONI/VHYNQbAcSCsTjOC1w/BmBEREREORCVUQzNLpQg5ksGDGAjDq2MzI7g3OA5+EP+JY/xBr3KXCyb0QaDzpDw/ddi3tWoezTledQ/2ynvFLocXQAAIQTuabxHuS9hbTgG5OvGAIyIiIgoB8bcYwhFYgswFxcUo6igaIVHZM9Kregj0Ug2h7Mh+UN+fPnCl/F/Ov4PftDxgyWPm5lb6IBYWBD7vic0QtEgAI4HVsnUQZl64eVdFbtQailVbqvH4w6yE+J6MQAjIiIiyoF8W4BZLSHjkZQl+dL5L+Gjv/gozgycycXQNozBmUEEI0EAwLWxawiEA4uOmfBM4LvXv6vcjq+5ldD4IkXGKRAOpDzfUtQB2L7qfQvnVv1se5w9yvbdDXcnPF7rjNxWl/tWO0RERERbkHr+Vz4swKymfsPtDrghpcSFoQv40e0fKVm7n935GQ7XHlYaNFCiudBcwu2e6R7srtqt3L4+fh3fvf5dJUgDgL3VewEkff+TMk7DM8P48otfhpQSL2t7GU41n4JOLJ1TCUaC6Hf1K7cP1R7C9fHrABKDKfVi0OpW+IvGw7XA1o0ZMCIiIqIcUHdAzOcM2IR3Ak9dfgo/6PiBEnwBsTf2L428lIvhbQjJgdPtqdsAYuWbP+r8Eb555ZtK8GXUGfGmfW/C0fqjAJbPOP3kzk8QioQQjobx0zs/xf968X8l/FyS9Tn7lHW9qmxVqC1M7LIIAKFISGn2oRO6hOsDXBtOawzAiIiIiLLMF/TB4XMAAPRCn/CmOB+o34DfmbqDW5O3lNvqjNcLAy+kXMyXFmeKOqc64Q648ZWLX8Gv+3+t7C+zluG9x96Lw3WHlX1LNUEZcA2ge7o74bx9zr6E7oXJ1OWH7eXtKdf1Us9DKy4oXrTOV6FJNSeQc8DWjQEYERERUZap53/VFdUp7b7zhTrjoXZy20l84N4PKEGY0+9UMjuUKDkAm5mbwf888z8T1uLaXbkbf3LsTxYF4OrvvzoD9lzPc8q2OpBKDsrUkgMwo94Is8EMINaJcy48lzBWdfZTGQ+7YmqKARgRERFRluVz+SGw0Awizm6y4w/u+gO8dtdrYTVZlVI5ADg/eD7bw9sQUs2Vipf5CSHwivZX4K2H3ppyDl1ylgqItbTvnOpUHv/GvW9UjhlwDaTMRM7OzWLcMw4glmltLm1edH5v0IuZQGIGLBlLELXFAIyIiIgoy4ZmFtb/yqcFmONsJhuO1B+BTuiwv2Y//uzkn2FHxQ7lfnUApl7LjBYs1azCZrTh0bsexYOtDy4q9YtLtRD2c73PKfv2VO3BjoodSqAcCAcw5h5bdB51ZqyptEnJfNmNiRktdQlicvANJAVsIS/LTteJXRCJiIiIsigqo3ndgj7ut/f+Nl6/+/Uw6Ba/XSy3lsOoMyIUDcEb9MIX9MFqsuZglPkr1VyphuIG/P7B30+ZZVJLLvmb8Ezg5sRNZd+DLbHgram0CdfGrgEA+l39i7oXqssP28ralO3kDNhsYKEDYqqxGXQGWI1W+EI+SCnhDXpTlipSepgBIyIiIsqiSe+ksoZTobkQJQUluR3QMlIFX0CsBK7cVq7cnvRNZmtIG0IoEoI/5AcQ6yr4N/f/Dd519F14z93vWTH4AgCzwazMC4x3O5RSAgB2VuxUAq2mkiblMepW8wAgpUwIwLaXb1e2k+eYqVvQp8qAAYuDNlo7BmBEREREWZSw/lfxtiXL0PJdla1K2Z70MgBTUzeqsJvsKCooQmtZK/Q6fdrnUGfBOiY7lO0HWx9UtuNzuoBYN8R4kAYAY54xZRxWozUhO2Y1LmQrk0sQlwoQGYBphwEYERERUQaFIiH8+41/x79e/Vd4g144/A7lvprCmhyObH0qbZXK9pR3KocjyT8rdRVMh7r1e1xbWVvCot3V9mplXpc74IbT71TuSyg/LG9LCPSTm3wwAMsuzgEjIiIiyqDr49fx4vCLAIAqe5VSmgYkvqndaCpsFco2M2CJtAjAUv1uqLNfQKy8samkSVkKoN/VjzJrGYDF7efV1MHd7NwsvKFYQCWEWLQIc1zC4tAhBmDrwQwYERERUQa55lzKtsPnSAjAUrUg3yjUGTAGYIm0CMCS12LbVrwNLaUti45TN3EZdY8CiGVd1euNqed/AYnB3ZhnTCldtJvsS5ZJpmqNT2vDAIyIiIgog0KRkLLtD/kTAzDDxg3Ayq3lSlnbtH8a4Wg4xyPKH+oOiFplwJZqW19lXzwXr8/Zp/w8Km2Vi8oK1edWly0u1yDEZlx4jC/oS+cp0BLyKgATQrxPCHFRCBEUQjy5wrFlQoivCiGcQogZIcQvku7/uBBiSgjhEkJ8QQiRX0vMExER0ZYQiASUbV/QpyzGCyQ2Q9hoTHqT0sFRSgmHz7H8A7aQhAxYirlc6VB3I6wtrE1Yh00tVSZSvf5XcvkhsHTpa7F5mQCMc8A0k1cBGIARAP8A4H+lcez3AMwAaAFQBuBv4ncIId4N4C0AjgJoB3AIwN9pPFYiIiKiFakzYL6QD3PhOeX2Ri5BBFiGuBQtShD3VO1BqaUUJr0Jj+x+ZMlumeXWcuhE7C29a86FYCSIO447yv1LBWCpzldYsPRY1XPAUq1xRunLqyYcUsrvAYAQ4iiAhqWOE0K8HLHA62EpZWR+94uqQ94J4DNSyr754z8G4EsAPpKBYRMREREtKRgJKtv+kB9huVCqtxkCsHgDCAZgCzTpgmguxF/c+xcQQigBVioGnQFlljJM+aYgpUSfsw9j7jEAgF7oU84b0wkdrAbromYa6WbAWIK4PvmWAUvXCQC3APyLEMIhhLgshHhEdf8+AFdUty8DaBBCLPqtEkKUCCGa1V9YJvgjIiIiWo1geCEA84V9yiLMQggUGApyNSxNsBV9aloEYACg1+mXDb7i1D+HFwZeULa3lWxT2tQnS1WGuNwcMKtpoVyWXRDXZ6MGYI0AXgngDIAaxMoPvyWEiLd4sSNWnhjnmv831f+A9wPoTfo6rfmIiYiIaEtSZ8DUC+VaDJYNuwhzXIV1oRX9lI8B2JmBM/jyhS8rXQKXa+uupUr7QgAWz0gCsfW/lpIqMCy1lC55vNVoVX5f/SE/m66sw0YNwHwAhqSUX5RShqSUPwHwS8SCMgDwAChSHR8P51MVrH4WsXJG9depTAyaiIiIth51AKa20csPgcQsirq741bkCXrwo84fJbR/txqtS7Z111KVrSrl/t2Vu5d8zIltJ5TsmE7ocKj2UEJL+2Q6oUtoGsMyxLXLqzlgq3AVwG8vc/91AAcRy5ABsSYcQ1LKmeQDpZQuLGTIAGDDfxpFRERE+UPdhENtMwRg6hJKdXORrWjGP5OQ4QSWDoy0pi5BVF+72l695GN2V+3Ghx78ECLRCEx6U1rvf+0mu9IB0RvyoqigaIVHUCp5lQETQhiEEAUA9AD0QoiCJdrH/zsAmxDi3UIIvRDiYQD3AfjJ/P1PAvgLIUSTEKICwH8G8JUsPAUiIiKiBJs5A6aeXxSf27ZVqZcXAIAj9Ufw+t2vz8q1UwVg+2v2rxhUGXQGmA3mtJMPbEWvjbwKwBBrFe8H8EEAb5vf/jIACCE8QohTACCldAJ4BMB/AjCLWBnhW6SUXfPneQLAtwFcBNAN4BqAj2ftWRARERHNWyoA28hrgMWZ9CalSUQ4Gt7S84LUJZj7qvfht/f+dsIiyZlkNpgXNds4UHNA8+swANNGXpUgSikfB/D4EvfZk26fAXB4iWMlgA/PfxERERHlzFIB2EbvgAgsdHKMZ3/mwnNZaTqRj3K9wHZyBrLCVrHEkWunDsDijUZo9fItA0ZERES0aURldMms0GbIgAGJZYhzoa07D0wdgOWivPT+5vuV7YfbHs7INWzG9WXAojKq5XA2rLzKgBERERFtJuo1wJJthjlgwOZuxDHlncK18WvYW7V3xXJCdQliqjW2Mu1k00lMeCdgMVhwqjkzDb3V2c3VBmDfvf5dXBu/hldvfzWObzuu9dA2FAZgRERERBmyVPkhsHkyYJs1AIvKKL526Wtw+By4OHwRf3nfXy7brEKdActFeWmhuRBvP/z2jF4jYTHmVQRgM3MzeGnkJQDA6b7TWz4AYwkiERERUYYsF4AxA5bfeqd74fA5AABOvxPe0PIBhzoAy0UGLBvW2oTDHXAnbCe3699qGIARERERZQgDsI3rytiVhNsrBRzqEsTN8rNNpi5B9ITSb8KhbtgRkZFN9XuyFgzAiIiIiDJk2QDMsDnepJuNm28tsFAkhBvjNxL2rRSA5boLYjastQlH8rFbvYU9AzAiIiKiDGEGbGO6PXV70XNZqe16rrsgZoPFaFHWfQuEA2kH3MkBV/Ki1VsNAzAiIiKiDNkKAZg6k7dZ2tAnlx8Cy2dtojKaELBt1gyYEAJlljLl9rnBc2k9LjngYgaMiIiIiDIiFAml3G/Sm2DQbY5m1JsxA9bt6F60b7mgYS40pzSWKDAUKFmizejepnuV7ed7n4cvuHI2yxNIzB6u1NBks9u8vx1EREREObZUidZmyX4BiQsxb4Y5YMFIMGUguVwAthXKD+OO1B9BhbUCQCzgfr73+RUfkxxwMQNGRERERBkRiqbOgG2mN+mbLQOWnK2JSzcA26wt6OP0Oj1esf0Vyu1zg+eWzPTGsQlHIgZgRERERBmy1BywzTRHaNMFYEs021iuCcdWaEGvtrdqL0otpQBiHzJMeieXPX5RE440yhY3MwZgRERERBkSDKcOwDbTm/QC48YIwPwhP6IyuuJx6kArHmQA6WfANlNwvRQhBGrsNcrtCe/Esscnf+9Ws4bYZsQAjIiIiGiNhmaGcHn0MsLRcMr71Rkwo86obG+mN+kbIQN2YegCPvHcJ/D5s59fMQhTlyCqg4zlGkdspTlgcVX2KmV7wrN0ABYIBxaV4jIDRkRERESr5vQ78cXzX8S3r30bv+j+Rcpj1HNjym3lynahuTDj48uWjdCE4/s3vw8pJUbdo+iZ7ln2WHUGrNJeCSEEgFgGLRKNpHzMVsuAAekHYKnW/FrLOmBDM0O4NnZN6Ta5kW2O/qdEREREWTYyO6K8Gbw6ehWvbH+l8mY9Tp0BO9ZwDC8Ov4iIjOCuuruyOtZMMuqM0AkdojKKcDSMUCQEo9648gOzxOV3JdxeqWGEOgArMhfBarQqJXS+kC9l8KyeA7ZlAjCbKgBLKkGMyiieuf0Mro9fx/by7Yseu9Ki1skmPBP40vkvISIjOFx3GG/a96a1DTpPMAAjIiIiWoOIXMiGuOZccPgcqLBVJBwTiCxkhEosJfiT43+StfFlixACBYYCJasxF57LqwCs19mbcHvFAExVgmgz2WA32ZUAzBP0pAzAtmIGrNIWyw5KKTHtn1YCbyklvnf9e7g0egkA8OLwi4seG4qEEIwEYdKb0rpW51Sn8v/t0sglbC/fjoO1B7V7MlnGEkQiIiKiNUieS9Tl6Fp0TMIcsDwKSrSmbsSRb2WIyQGYOihOxR10K9uFpsKEgGqpRhxbrQsiEPt9LrOUAQCklJj0TkJKie/f/L4SfC1nNa3ox9xjCbd/0PEDTPumVzfgPMIAjIiIiGgNkucDrRSAmfXmRfdvFvnciCM5AFtpfOryuEJzIexmu3J7qaBBvX+rZMCAxWWIT996OmXGK5XVNOJIDsAC4QC+ff3baXW1zEcMwIiIiIjWIPnNX4+zZ9E+dblbuuVWG1G+BmAzczOLMiUrBmBJJYjqgGqpuUvqc26pAEzViOMnt3+Cc4PnlNt2kz3VQxTpzgMLR8Mp29wXFxSvWE6arzgHjIiIiGgNkjNggXAAgzODaCppStgXxwAs+5KzX8DyJZKBcEDJWhp0BhQYChICiXQyYFulBBEAqu3VyvZsYFbZPlBzAIdqD+Frl7625GPT7YQ44ZlQPtgotZTixLYTsBqtOFR7aFHTm42CARgRERHRGqibcMR1O7oTAjD1+kebeQ6YuhV9PgVgfc6+RfuWG586kLKb7BBCrBiAhaNhJWjTCV1CMLrZVdoqF+3bW70Xb97/5oR5cXGlllI4/U4A6c8BG3WPKtt1hXW4t+neNY42f7AEkYiIiGgNUq0JdcdxR9mWUibMAdsqGbB8acIhpcTtqduL9gfDwRRHx6gbcMTnfllNyzfhULe5txgtGzYrsxaVtkroxEI4satyF35n/+9AJ3SwmWwotZQuOj5uuYWt1dTzv2oKa5Y5cuNgAEZERES0BqkyYEMzQ0oAEo6GlXXCDDoD9Dp9VseXTflYgjjmGcPM3Myi/cuNTz3/K575splsyr5UAdi18WvKdn1R/ZrGulEZ9Ubc13wfdEKHAzUH8HsHfw8G3UKBXfL3Q12yuJYMWG1h7TpHnB9YgkhERES0Bqk6sEVlFL3OXuyq3LVlWtADSQFYKD8CsFsTt5TtMmuZ0oxj2QAsuDgASyhBTMraSClxZfSKcvtw7eH1DXoDetX2V+FlrS9L+TveUNyA6+PXldvqDNj18etoK2vDtpJtizJlcVJKjHk2XwaMARgRERHRGqhLEPVCr2TE7jjuLArANnP5IZCfGbBbUwsB2KHaQ/iP7v8AsHyJZEIANl+CaDPaUt4PACOzI5j0TgKI/Yx3Ve1a/8A3oKU+YFC3qQdigXBcIBzAv137NwBAY3Ej9tfsx77qfSguKFaOmZmbUeaSWYwWlBSUaDzy3GAARkRERLQG6gxYS1mLsg5Yt6MbALZWAKZaiPmlkZfg8DnwyO5HclYyNjs3i6GZIQCxxhj7qvcpAVg8QJydm0WBsSDhZ5OqBNFitMCgMyAcDSMQDiAQDihNRy6PXlaO31u1d9P/nFerubQZZoMZgXAADcUNKDQVpjxucGYQgzOD+FHnj7CteBsO1B7A3Q13Y9wzrhxTba/eNPPrGIARERERrYE6A9ZS2oI+Zx/C0TAmvZOYmZvZMmuAAVjU+a/f1Y/v3fge/tPx/5ST8XROdSrbzaXNCZmTQDiAZ3uexc+7fg6jzoi28jbsqtyFXZW7UpYgCiFQZilT1qKa9E6iobgBURnFlbGF8sNDdYcy+6Q2ILPBjLcfejtuTtzE3Q13o9xajrayNnRPd6PMWobSglL0OnsTPswYmBnAwMwApnxTqLQulCxWWCty8RQyggEYERER0Rqom3CYDWY0lTShezqW/epydCW86d/sAViVrQpCCKXpCBArzxt1j+YkC6buRrmrchdMepMyvlA0hIvDFwHElgm4NXkLtyZj5YrqBhLxEkQgNncpHoBN+abQUNyAO1N3lEYSReYitJa1Zvx5bUQtZS1oKWtRbr/zyDsRjASVLKIv6MPNyZu4Pn4d3Y5uJRjrc/bBpFv4f6MuTdzo2AWRiIiIaA3Un9rrhR7t5e3K7S5H15ZZAwwAigqK8K4j78Ir2l+REIi8NPxSTsYz6ZlUtptLmiGESMjSueZcKR8XjoaVbXW5XIVtIfsSn/Olzn4drD2Y0I6dliaESFg3zmqy4mj9UTx616P4i3v/Qtnv9DsTfk4MwIiIiIi2OHUJok6nSwjAuqe7E5o9bPYMGBDLdDzY+iBONZ9S9l0ZvZIQ1GSDlBLT/mnldrm1HABg1psTjgFiGa/f2PkbaC1rTQigzAZzwhv+5AAsEA7g5vhNZd/B2oPaP5EtqNRSqnxYEQgHEtYA2ywNOACWIBIRERGtSXIGrLawFjajDd6QF96gF/2ufuX+rRCAxbWXt6O4oBgzczPwhrzonOzE3uq9Wbv+bGBWCfpsRpvSICR5nhoQm+d1b9O9uLfpXvhDftyeuo2R2RHsrtqdkLVUz0Wa8k7h5sRNJcNZY6/ZNOtT5Vp8vl28+Ua87BNgBoyIiIhoy1PPAdMLPYQQaC1PXX5XaE7d/W0z0gkdDtUeUm6/NJLdMsT4el9AYttzk2FxEKye52UxWnCw9iBes/M1aC5tTjhOnQFz+By4NHJJuc3sl7aWynQxACMiIiLa4qLRhQyYThd7S6UuQ1TPAdtqb9LvqrtL2b49dRvugDtr13b4Hcp2vPwQWDoDlg6L0aIcG46GlWYrQogt97PNtFLr4kWZ7Sb7pppHyQCMiIiIaA3Uc5v0Qg8AaC9rX3RcU0kTqu3VWRtXPqiwVaCppAlArFRTvV5Wpjl8CwGYOgOmbvwQt5rMpDoLFtda2rqpMjP5oLRgcQBWYinJ/kAyiAEYERER0RqoSxDjDRxKLCUJWRcAONZ4LKvjyhd31S9kwV4afimhRX0mJQRgloUAbD0ZMCDWij4Zs1/aK7UsDsCKzZsryGUARkRERLQGCU04dHplW12GaDPZstqAIp/sr96vNB+Z8E5geHY4K9dVzwHTqgQRWByAGXVG7Kvet4YR0nJSBmCbLMvIAIyIiIhoDdRt6NUB2P7q/cr28cbjCYv7biVmgzkhQIkvfpxJyS3oE0oQ9YtLENVNOFZSYU0sQdxVtStlWSOtT6oAjCWIRERERLSoDX1cS1kL3nH4Hfitvb+FB1sfzMHI8oe6DPHq2FWEIqFljl4/b8irrL9mNphhM9qU+8xGbeeAHa49vMZR0nIKDAWLAltmwIiIiIhoURt6tZ2VO3G0/mjC4r5bUXNJs5KFmgvP4ebEzRUesT4JLegtZRBCKLdTZsBWUYJYailFkbkIQCwgUJeaknaEEIuyYJtpEWaAARgRERHRmqhLEONt6CmRECKhJX2m1wRbqgMisP45YDqhw9sOvQ33N9+Ptx9+e0LZKWkruRMiM2BERERElDgHTPDN+FLuqrtLyUR1T3fD5Xdl7Frq+V/llsRulMkBmElvWvUcrvrierxqx6tQW1i79kHSitQZMIPOsKpAeSNgAEZERES0Bqna0NNixQXFaCtrAxBrknFp5FLGrrVUB0Rg8Tpgq2nAQdmlbrpRVFCUUEq6GfDVgoiIiGgNlmpDT4sdqTuibF8cuZixNcGWC8CSM2CbLauymah/dqkWZt7oGIARERERrQFLENO3u2q3EgA5/U70Ofsycp3l5oAlZ8AKTel3QKTsai9vR0NxA0x6E042ncz1cDS3NRemICIiIlondQaMTTiWZ9QbcaDmAM4PnQcQy4K1lLVoeo250By8IS+A2LyheMfCOJYgbhwGnQGP3fMYIjKyKdfR46sFERER0Ros14aeFjtSv1CGeH38urJel1YSFmBOakEPAEadMWGuHksQ85sQYlMGXwADMCIiIqI1iUZVGTA24VhRfVE9qmxVAIBQJIRr49c0Pf+Ub0rZTi4/BGJv6NVZsNUswkykJb5aEBEREa1BQgaMTThWJITA4brDyu2+6T5Nz5+8CHMq6kYczIBRrjAAIyIiIlolKWViF0SWIKal0lapbMfna2klYQ2wpA6IcRajRdlmBoxyhQEYERER0SolrwG22dYpypQC40IGai40p+m5EzJgKUoQAeCehnugEzpsK9mG+qJ6Ta9PlK7NObONiIiIKIPYgn5trEarsu0P+zU9d0IL+iVKEO9uuBv7q/fDbDAzaKacYQBGREREtEpsQb82FsNCCaA/pF0AFoqEMBuYBRDLSJZall68V52FI8oFvmIQERERrRJb0K9NQglieA5SSk3Oq57/VVxQzKYolNcYgBERERGtElvQr41RZ1TWdgpHwwhFQ5qcVz3/a6kGHET5gq8YRERERKukzoBt1sViM0EIkdAKXqtGHOl0QCTKFwzAiIiIiFZJ3YSDc8BWR90KXqtGHOoGHAzAKN/xFYOIiIholbgG2NqpG3H4Qj5NzplOB0SifMEAjIiIiGiV2IRj7TKxFlhCALbEGmBE+YIBGBEREdEqsQRx7dRrgWmRAYtEI5iZm1FuMwNG+Y6zRomIiIhWiRmwtUtuRb8aLr8L/37z32ExWvDGvW+EUW+E0+9USkKLzEUw6o2ajpdIawzAiIiIiFZJ3Yaea06tjjoDttrFmH9464focnQBACptlXi47eGEDogsP6SNgDlzIiIiolViBmzt1G3oV9sFsWOyQ9m+NHIJANcAo42HARgRERHRKnEO2Nqp29CvpwlHMBIEwA6ItPFoWoIohNgOwCWlnBRCWAH8FYAIgE9JKQNaXouIiIgoV9iGfu20akMfioQAgCWItOFo/ZHNNwDUzm9/HMCbAbwJwGc0vg4RERFRzrAEce20akMfis4HYKoSxAprxdoHRpQlWgdgbQCuz2+/EcDrAbwSwBs0vg4RERFRzqibcLAEcXUSmnCscg6YTix8r6WUkFImZsBYgkgbgNZdEAUAKYRoBSCllD0AIIQo0vg6RERERDnDDNjaqUsQV9sF0aQ3JbSunw3MIhwNAwBsRltCdo0oX2kdgF0B8GEA2wD8FACEEPUAZjW+DhEREVHOqAMwdVaGVpa8DpiUEkKItB5r1BsTArCEBhyc/0UbhNYB2J8B+DyAIIA/mN/3cgA/0/g6RERERDnDdcDWzqgzwqAzIBwNIxwNIxQNwaQ3pfXY5GB31D2qbLMFPW0UmgZgUsqrAO5L2vdVAF/V8jpEREREucQM2NoJIVBgKIAn6AEQa8SRbgAW73wYNzQzpGwzA0YbhdYZMMy3n98JoFC9X0r5S62vRURERJQLbEO/PhajRQnA/GE/ipBeu4B458O4wZlBZZsNOGij0HodsNcD+Bqw6H+RBMBXJyIiItoU4o0fAJYgrsVa1gKTUi7KgDn9TmW71FKqzeCIMkzrnPmnEFv/q1BKqVN98ZWJiIiINo2ENvQsQVy1tawFpg56U2EGjDYKrUsQa6WUn9b4nERERER5RT0HzKDTfEbHpqdeCyzdDFhy9kvNoDOg0Fy45P1E+UTrj2x+JYQ4oPE5iYiIiPIKm3CsT3Ir+nQslwErKShJu5U9Ua5pHoAB+L4Q4m+EEO9Qf6XzYCHE+4QQF4UQQSHEk2k+5nEhhBRCvDpp/8eFEFNCCJcQ4gtCCOPqnw4RERHRYmxDvz7qDFi6izEHI8El7yu1cv4XbRxa58z/aP7fx5L2S8Sac6xkBMA/AHgVAMsKx0IIsQPAmwCMJu1/N4C3ADgKwAPgaQB/B+AjaYyBiIiIaFnMgK1PgWEhA+YPpxeAJXdAVOP8L9pINHvFEELoALwOwA4pZUvSV2s655BSfk9K+X0AjpWOnfdFAH+J2MLPau8E8BkpZZ+UcgrAxwD8YZrnJCIiIlpWJLoQgLEN/epZjAufs6fbhGO5OWDsgEgbiZYZMAngAgC7hudc0nxZo0NK+ZMUNb/7AFxR3b4MoEEIUSylnEk6TwmAkqTHN2g6WCIiItpU1BkwliCu3lra0C83B4wBGG0kmgVgUkophOgGUI2kkkCtCSHKADwO4NQSh9gBqAMt1/y/hUn7AeD9YGkiERERrQLb0K/PWtrQL5sBK2AARhuH1nPA/gnAN4UQjwPoA6C8OkkpBzS8zn8D8Hkp5fAS93uQuBh08fy/7hTHfhbAk0n7GgCcXsf4iIiIaBNjBmx9EppwaDAHjBkw2ki0DsCemP/3PxArSQQAMb+t5avTywG8Xgjx/8zfrgTwDSHEf5dSfgLAdQAHAZyZv/8QgKHk8kMAkFK6sJAhiw2YbUyJiIhoGWzCsT7qEsR0uyAulQEzG8wJc8qI8p3WAVjLeh4shDAgNiY9AL0QogBAREqZ/D/ubiQGdBcA/DVi3Q6BWEbrr4QQPwLgBfCfAXxlPWMjIiIiiktoQ88mHKuWvA6YlHLFD8CXCsDKLGX88Jw2FE0DMCll/zpPkdwq/m0AvgrgUSGEB8BrpJSnpZST6gcJISIAnFJKz/yuJwA0A7gIwAjgmwA+vs6xEREREQFgCeJ6GXVGGHQGhKNhhKNhhKIhmPSmZR+zVAkiW9DTRqNpALbcgstSyhXXAZNSPo5Yc41U9y3ZXVFK2Zx0WwL48PwXERERkaaikk041kMIgQJDATzB2Gfnc6G5lQOwJTJgJZYSrYdHlFFalyB+NOl21fw1hpHeQsxEREREeU+9DphBp/Xbqa3BYrQoAZg/7EdRQv+0xZgBo81C6xLEhDlg83O6/hHAHS2vQ0RERJRLbMKxfqtdC0ydAdtRsQO9070wGUzYV7MvI+MjypSMfmQjpQwLIf4eQAeAL2XyWkRERETZoi5BZBOOtVF3LkxnLTB1ALazYid+Z//vwKg3MgNJG042fmOLAXBxBiIiIto01CWIbMKxNuoALK0MmKoE0ag3svU8bVhaN+H4+6RdNgBvAPCMltchIiIiyiU24Vi/5Fb0K1FnwIw6Y0bGRJQNWmfAHkq67QbwdQD/pPF1iIiIiHImHA0r28yArY3VaFW201mMWf09N+oZgNHGpXUTjuQAjIiIiGjDk1IiGAnCbDAD4BwwLRQYFjJg/vDKAVhCBowBGG1gmubMhRBnl9j/Ky2vQ0RERJQtURnFF89/ER9/9uO4OHwRAOeAaWE9TTjYeIM2Mq2LlvcusX+3xtchIiIiyorOyU4MzQwhKqP43o3vAWAbei2stg19MBpUtldatJkon2ny8YEQ4h3zm3ohxNsBCNXdOwE4tLgOERERUbYll8dJKVmCqIGEJhxpZMDCkYU5YMyA0Uam1W/vR+f/NQP4mGp/FMAYgD/V6DpEREREWZXccc8f8rMEUQMJTTjSmQMW5Rww2hw0CcCklC0AIIT4kZTyN7Q4JxEREVE+UL/xBwCn38k29BpQlyCm0wWRTThos9D0FSMefImYWi3PTURERJQLwXAw4fa0fzphDhgzYGuTvA6YlHLZ4xMyYFwHjDYwrbsgWoQQXwLgB9A1v+83hRAf1vI6RERERNkSjCQGYA6fQwkWhBDMgK2RUWdU5nKFo+FFmUY1KSUzYLRpaP2K8WkATQAeABD/X/ISgN/T+DpEREREWZEcgE35ppRtNuBYOyFEwlpgyzXiUC/CbNAZGPTShqZ1C5nXAzgopZwWQkQBQEo5KISo1/g6RERERFmxKAPmXWjuzEBgfSxGCzxBD4BYI44iFKU8jmuA0Wai9auGEcCseocQwoJYSSIRERHRhrNsBozzv9Yl3bXA1Bkwlh/SRqd1AHYBwHuT9r0DwFmNr0NERESUFckBmDpQYAZsfSzGhQBsuRJE9c+AGTDa6LT+Df4rAL8UQvwOAJsQ4hkARwGc1Pg6RERERFmR3AVRjXPA1kcdgC2XAVM36DDpTRkdE1GmaRqASSlvCSF2I5b1uoHYIsx/JKUc1PI6RERERNmSnAFTYwni+iS3ol8KOyDSZqJZACaEMALoB9Aqpfwnrc5LRERElEvLBWAsQVwfq9GqbC+3GHPCHDCuAUYbnGavGlLKEGKt54VW5yQiIiLKtWUzYCxBXBd1G/plSxDVXRD1nANGG5vWH9t8BsCn5rNhRERERBveshkwHTNg62Ez2ZRtb9C75HEJc8B0nANGG5vWHyG8H0ADgHcLIcYARON3SClbNb4WERERUcYFwoEl72MGbH3sJruyHV8PLBXOAaPNROsA7HGNz0dERESUU+o3/8UFxZiZm1FuMwBbn4QALMAAjLYGrbsgflXL8xERERHlUlRGlfI3IQQe2fUInrr8lHK/w+/I1dA2Bbt5IQDzhtIrQeQ6YLTRsXCZiIiIaAnqNcCMOiN2Ve5K6MJnMVhSPYzSZDVaIUSsf5s/5E/odqjGDBhtJgzAiIiIiJagbsBh0psghMBjxx5TgoD9NftzNbRNQSd0sBmXbsThC/rwvy/9b/ys62fKPrahp42OOVwiIiKiJSQEYIZY972awhr8ybE/wbR/GjsrduZqaJuG3WxXGnB4Ah4UFxQr9/2s62e4NXkr4XhmwGijYwBGREREtITkDFhclb0KVfaqXAxp01mqE2IgHMCVsSsJx+qFHq2lbKxNG5vmAZgQQg/gGIBGKeW/CiEKAEgp5dI9XImIiIjyUCCy8PZFHYCRdpYKwK6NX1OWAKiwVuCR3Y+gpKAEFbaKrI+RSEuazgETQrQAuArgJwC+Mr/7NwB8WcvrEBEREWWDugmH2WDO4Ug2r6UCsItDF5XtuxvuRnt5O4Mv2hS0bsLxOQA/AFACIP6K9SyA+zW+DhEREVHGJZQg6pgBywR1K/r4WmDjnnEMzAwAiJUdHqo7lIuhEWWE1iWIxwD8lpQyIoSQACCldAohSjW+DhEREVHGLTUHjLSTKgN2YeiCsm9P9Z6EY4g2Oq0zYF4AVvUOIUQlAK5SSERERBtOqi6IpC2bKbENfSgSwuXRy8q+o/VHczAqoszROgD7MYD/Md94A0IIHYCPA3ha4+sQERERZRwzYJmXnAG7MXED/pAfAFBqKUVbWVuuhkaUEVqXIH4QwPcBTAMwA5gB0AHgFRpfh4iIiCjjGIBlXqG5UNn2BDwJ5YdH649CCJGLYRFljKYBmJRyBsBDQoi7ALQDGAPwKyllVMvrEBEREWUDuyBmns1kgxACUkp4Q154nV4AgE7ocKT+SI5HR6Q9TQMwIcSDUsrnpJQvAXhJy3MTERERZZs6A2bUGXM4ks1LJ3SwGqzwhrwJ+3dV7krIjhFtFlrPAXtaCHFHCPFBIUSNxucmIiIiyio24cgOdSv6ODbfoM1K6wCsFsB/BfB6AANCiP8jhHj9fDMOIiIiog1FHYCZ9SxBzJTkNvPFBcXYXrE9R6MhyixNAyMppUdK+YSU8iSAQwA6AXwJwKCW1yEiIiLKBjbhyA51K3oglv3S8fN72qQy+Zvdh1gHxH4AVRm8DhEREVFGJMwB03MOWKaoM2BCCDbfoE1N8wBMCHFCCPEEYh0Q/wbAvwPYpvV1iIiIiDKNXRCzQ91sY3v5dhQXFOdwNESZpWkAJoToAPBzxNYAe0RKuVNK+V+klKNaXoeIiIgoG1iCmB37a/ajyFwEs8GMV7Rz+Vja3LReiPl/AvjG/HpgRERERBsaSxCzo9RSir889ZfQCR3nftGmp/VCzF/Q8nxEREREucQuiNlj0GmdFyDKT+v+TRdC/F8p5Wvnt58FIFMdJ6V82XqvRURERJQtkWgE4WgYQKwxBAMEItKCFq8kv1JtP48lAjAiIiKijSR5/pcQIoejIaLNYt0BmJTyH1Xbj6/3fERERET5gA04iCgTtO6COLLE/gEtr0NERESUaf6QX9lmAEZEWtG6zUzhKvcTERER5Z1p3zS+eeWbym2L0ZLD0RDRZqLJbFIhxN/PbxpV23E7APRrcR0iIiKiTBuaGcLXLn0N3qAXQKwBx/HG4zkeFRFtFlq183lIdb6HVPujAMYA/KFG1yEiIiLKmFuTt/Ctq99CKBICEGuN/ub9b8a+6n05HhkRbRaaBGBSyocAQAjxBSnlH2txTiIiIqJsOjd4Dk/fehpSxho6W41WvO3w29BU0pTjkRHRZqL1QswMvoiIiGjDea7nOfys62fK7VJLKR6961FU2CpyOCoi2ow0X1FQCPEuAC8HUAVAWTCDCzETERFRPvIFfXi251nldn1RPd5++O0oNLOHGBFpT+s29B8D8F8AjAM4AeAqgP0Armh5HSIiIqL1cPlduDh8EZ6gB06/E+FoGEAs8/Wuo+9i8EVEGaN1BuztAF4tpbwohHiHlPL9QojvAnifxtchIiIiWpOojOIrF78Ch8+B1rJWnNx2Urmv0lYJs8Gcw9ER0Wan9TpgFVLKi/EbQgghpTyNWEkiERERUc4EwgEAsTW+HD4HAKDX2YuZuRnlGGa+iCjTtM6AjQkhaqWUo4it/XVSCDGl8TWIiIiIVuX/dPwfnBs8h+PbjmNnxU5lv5QSw7PDym0GYESUaVpnwL6JhXXAvgTgFwAuAnhK4+sQERERpWUuNIdzg+cAxFrNj7nHEu4fmhlStgtNDMCIKLO0bkP/96rtLwghrgAoAvATLa9DRERElK4xz0LAJaVE51Rnwv2Tvkllu6igKGvjIqKtSfM29GpSyjOZPD8RERHRSpIzXgOugYTb8YWXAWbAiCjz1h2ACSG+ks5xUso/XO+1iIiIiFZLnQEDYl0Ql8IMGBFlmhYZMLHyIURERES5Me4eT/tYm8mWwZEQEWkQgEkp36nFQIiIiIi0JqVclAFbis1kg0GX0dkZRESad0EkIiIiyhsOnwPBSDCtY9mCnoiyQdOPeYQQvQBkqvuklK1aXouIiIhoJeOe9MsPGYARUTZonWd/POl2PYA/AvDPGl+HiIiIaEXplh8C7IBIRNmh9TpgX03eJ4T4EYBPAPgvWl6LiIiIqGOiAz/r+hn2Vu/Fw20PL7pf3YK+uKAYM3MzS56LHRCJKBuyMQfsCoBTWbgOERERbTHP3H4G455x/Ef3f2DaN73o/lH3qLK9v3p/wn3JJYfMgBFRNmQ0ABNCWAD8OYCJTF6HiIiItp6ojGLavxB0qYMtAAiEA3D6nQAAndBhT/WehPtbSlsSbnMOGBFlg6YBmBAiKoSIxL8AeBCbF/aXWl6HiIiIaHZuNmFR5eSGG+r5X1W2KtTYa5Q28xajBQ3FDQnHF5lZgkhEmad1E46Hkm67AdyWUno0vg4RERFtcc45Z8Lt5IYb6gWYawprYDaY8ciuR3B+6Dzua7oPOl3i59DMgBFRNmiaAZNSPp/09dJqgi8hxPuEEBeFEEEhxJPLHPdaIcSvhBAuIcSYEOIrQoiSpGM+LoSYmj/mC0II49qfGREREWWDlBITngn4Q/4Vj01uqKEOuIDEgKzaXg0AONpwFH9y/E9woPYASgpKEo63m+1rHDURUfo0X+5dCHEKwFEACR8jSSk/lsbDRwD8A4BXAbAsc1wxgI8D+CUAE4CnAHwWwKPzY3g3gLfMj8MD4GkAfwfgI2k/ESIiIsqYUfcovn756yg0F+LRux6F2WAGAJwbPIenbz0Ni9GCv7zvL2ExLv12ID6/K87hdyAUCcGoNyrXiKsprFn0+BJLCYQQkFKiyFyklCcSEWWS1nPA/hHAzwG8DcArVF8vT+fxUsrvSSm/D8CxwnHfkFI+I6X0SSldAL4E4F7VIe8E8BkpZZ+UcgrAxwD84SqfDhEREWXIz7t+DqffiQHXAK6MXlH2P33raQCAP+RP2J+Ky+9KuC2lxKR3UtlWzwmrLaxd9Hi7yY6HWh9CqaUUr9z+yrU+FSKiVdH6o54/AnBMSnlZ4/Ou5H4AN1S39yHW/j7uMoAGIUSxlDKhXmG+dLEk6XwNICIioowIhAPocnQpt4dmh3AP7kEgHEg4LhgJLnse15xr0b4xzxjqiurg9DuV89mMNthNqcsLH257OOX6YUREmaJ1AOYFcF3jcy5LCPEyAO9GYgbMDkAdaLnm/y1M2g8A7wdLE4mIiLLmjuMOwtGwcnt4ZhgAMDgzmHCc+phUkjNgwMI8MPX8r5rCGggh1jpcIiJNab0O2KcB/L3I0qucEOIYgH8F8DtSSnUGzANA3Uu2eP5fd4rTfBZAS9IXF44mIiLKkI6JjoTb495xBMIBDLgGEvZ7gkv38ZJSLmrCET8XAIy5EwMwIqJ8oXUG7PuIzQH7CyHEpPoOKWWrlhcSQhxGrLnGH0kpf5p093UABwGcmb99CMBQcvnh/LhcWMiQxc+t5VCJiIhoXiQaQedUZ8I+KSVG3aPod/Un7PcGvUuexxP0IBQNLdqfKgMW74BIRJQPtA7A/hXAEGJZJd9qHyyEMMyPSQ9AL4QoABCRUoaSjtsH4BkAfzbftCPZkwD+SgjxI8TKIv8zgK+sdjxERESkrT5nX8oW80MzQ4tKEJcLwNTlhzX2Gkz5phCOhjEbmIUv6EvIgKVqwEFElCtaB2AHAFRIKefW+PjkVvFvA/BVAI8KITwAXiOlPA3gLwFUAnhCCPFE/GApZXyG7RMAmgFcBGAE8E3E2tYTERFRDt2cvKlsW4wWJRi7NHJpUROO5QIw9SLMpZZSCCGUtvODM4OY9k8DAHRCh0pbpWbjJyJaL63ngN0AULbWB0spH5dSiqSvR+fvs88HX5BSvlNKqZvfp3ypziOllB+WUlZIKYullI8lZ9GIiIgou6SUCfO/7mu6T9lWlwzGLReAqed/lVhKUGNfmOd1dewqpJQAgAprhbIuGBFRPtA6A/YUgO8JIT4DIOGVVEr5S42vRURERFkSioTw1OWn4PK78JaDb1lTWd/I7IgSOFmMFpzYdgK/6P4FojKa8nhf2IeojEInFn9erF6EudRSimhBFJhfd/nmxEKWjQ04iCjfaB2A/Y/5f7+VtF8iNq+LiIiINqDOqU5l7a6f3vkp/uCuP1j1OdTlh7sqdsFsMKOmsAYjsyPKfp3QKQGZlBLeoBeF5sJF51LPASsuKIZJb1Juq9cPYwMOIso3mpYgzpcFpvpi8EVERLSBzQZmle2e6Z5F87XSoS4/3F21GwCwvXy7sq+msAZ/dPcfocpWpezzhVL39FKXIJYWlCaUIKqxAQcR5RutM2BERES0CfmCC4FQOBrGHccd7Kvel/bjp7xTGPfEWsQbdUa0l7cDAB5oeQBWoxU2kw0Haw9CJ3SwmqyxHsYAPAFPyiyWP7zQSdFqsqLQXAir0booYNsKJYhSSoyOjsJkMqGkpAQulwvj4+OoqalBeXl5yscEAgF0dXVhaGgIJpMJhYWF2L17N2w2W5ZHT7T1aBqACSH+fqn7pJQf0/JaRERElD3JgU3HRMeqArCOyYXsV3t5O8wGMwDAbDDjvub7Eo61mRaCgKUacajLDM16M4QQqLZXo9fZq+y3GC0oMhelPcaNKBKJ4NKlSxgdHV10X29vL3bu3In29nZljdNwOIze3l50dXUhHA4DAILBIDweDywWC/bu3ZvV8RNtRVpnwB5Kul0HoAXArwAwACMiItqgkgOwzqlORKIR6HXpzTJQN8aIlx8uxW5SGhvDE/Isul9KmVACaTLE5n9VFyYGYDX2GiXw2IwCgQAuXLgAp9MJg8EAm82GmZkZWK1WlJaWYmRkBLdu3cLk5CQOHDgAh8OBzs5OBAKx711VVRV27twJt9uNy5cvw+Vy5fYJEW0RmgZgUsrkAAxCiPcD2NwfPxEREW1y6hJEAPCH/BhwDaClrGXFx7oDbmWRZSEEdlXuWvZ4dQCWKgMWjoaVRh16oYdBF3s7kzwPbDOXH3o8Hpw/fx5erxcWiwXHjh1DYWEhIpEIdDodhBBoaGjA5cuX4XA48OyzzyqPLSkpwe7du1FRUQEAsFqtAICZmRlIKTd10EqUD7ReByyV/xfAY1m4DhEREWWIN7Q4EFJntZZza/KWsi5Xc0lzQolhKiuVIKrLD+PZL2Bxx8PNGoBNT0/j17/+NbxeL4qLi3HfffehsDDWKVKv1ysBVFVVFR544AHU1dUBAGw2G44ePYr77rtPCb4AwGQywWq1IhKJwONZnHEkIm1lowlHCwBzFq5DREREGZKcAQNi87p+Y+dvrJgxWU35IbByAKYuPzTrF95iLArAluiMuJGNjIzg0qVLiEajqK6uxl133QWDYem3c2azGUeOHMHu3btRUFAAnS71Z+8lJSXw+XxwuVxKMEdEmaF1E46vJO2yAXgYwL9peR0iIiLKHillwhwwk96EYCQIp9+Jcc/4spmmQDiAnuke5faeqj0rXk8dgHmCizMyCQ04DOaE7YbiBgzNDMFusm+qNcCklOju7kZHR6yZSXNzM/bt25d2uWC8zHApxcXFGBkZgcvlQmNj47rHS0RL0zoDlvwqMA7gAwC+rvF1iIiIKEuCkSDC0VjHPKPOiJ2VO3Ft7BqAWBZsuQCsc6pTeWxtYS1KLaUrXm+lOWCBiKoBh2oBZgD43f2/iytjV7CzYieMeuOK19oIpJS4fv06+vr6AAB79uxBa2urpnO1SkpKAMTmga3W5OQkHA4HduzYsWSGjYgWaN2E451ano+IiIhyT539spqs2FO5ZyEAm+jAQ62LenApbk/eVrbTKT8EAJtxhQxYOHUGDADKrGXLjkdr8bltmWxcMTg4iL6+Puh0Ohw+fFiZ06Wl4uJiAMDs7Cyi0WhagVQkEkFHRwd6e2OdJ+12OxoaGjQfG9Fmo8nHFEKIvUKIv13ivg8KIZZvd0RERER5Sz3/y2q0YnvFduhE7C3E8OwwZvwzSiCiJqXEbcdCALazYmda15vzzCESjgCIlTDGM2hxy2XAsu3y5ct45plnMDg4uOxxN27cwEsvvZTy+7Scubk53LwZm0N38ODBjARfAGA0GmGz2VbViOPatWtK8AUAExMTGRkb0WajVZ74rwBMLXHfBIC/1ug6RERElGXxDoh+vx+uSReuXboGzMQaQgwNDeFfnv4XPP/883C73QmPG3WPKiWENqMN9UX1i8/t9eL06dO4cOECfD4fbt68iV//+teYGp3C2NgYZmZmMDI5khC4xJtwyKjE9OQ0fvazn2FgYCBTT18RDodx6dIlPPfcc/D5fPB4PBgaGkI4HMbly5dx5coVRCKRRY8LBoPo6enB8PBwygWTl3P9+nWEQiFUVVWhvn7x909L8TLEa9euoaenR1moORW/34+hoSEIIXD48GEAsVLE1QaYRFuRViWI9wF4/xL3fRfAhzW6DhEREWWZL+SD2+3G9PQ0CgoKMC7GURopRW8olv0YmhtCm7sNv/71r3H06FGlxfntqYXsV0tpy6LgxOfz4dy5c5ibmwMAjI+PK+tQWQ1WTAemEQgE8Nyvn0OVtQoVFRWoqKiA0+/EzMwMPG4PTGYT5ormcOfOHTQ2NmasFNDj8eDChQtKdqijowNmc6z8saSkBG63GwMDA3C5XDh69ChstoUySofDoWx3d3ejtrY2rXG6XC6Mjo7CYDDgwIEDGV+fq7q6GsPDw5iensb09DTGxsZwzz33pOyy2NfXBykl6urqUF9fj87OTvh8PszMzCiBHBGlplUAViWldKW6Q0o5I4So1Og6RERElGW3e29jenoaALCtbhvu3ns39kb3YuzSGHQ6HQx6A8qLy+GYcOD8+fN4+OGHYTabccdxBzIqMTo2ihpXDX48+OOU5y8vL4fJZMLo6CiMRiOOHj2Kid4JXBu+hrm5OURMEYRCIYyOjmJ0dBQ3PTfh8rgAAMX2YpjNZqWFemnpyk0+1uLGjRvweDwoLCyEz+fDyMgI9Ho9gFhpIAC8+OKLmJ2dxS9/+UscOnQItbW1ABIDMJfLhenpaZSXl694zf7+fgDAtm3bYLFYtH5Ki9TX16O0tBTT09Po6OiAwxH7eba0tMBiscBiscBkMiEajSpjizcDqaysRH9/PyYnJxmAEa1AqwDMK4RolFIuKoAWQjQC8Gt0HSIiIsqirq4udPV1QQiBsrIy7GjegZqaWNfDbf3bMOoehYSEfZsdgXAAU5NT6O7uRtuONgy4BjA7O4tQKIRac23KTEpVVRUOHToEvV4Pp9MJi8WCgoIC1E/Xo9vZDavVitrmWtzfcD+mpqYwOTmJzr5OWK1WFBYW4tDeQ6iaq1JK/DIRgEkp4XQ6AQDHjh1Df38/7ty5g0gkgvLychQVFQEATp06hStXrmB0dBQvvvgi2trasHv3biUAq6iowNRU7PuzUgAWDocxMjICAGhqatL8OS3FarXCarWitLQUZ86cgcPhSAgg9Xo9jEYjQqEQSktLle93PACbmJjA9u3bszZeoo1IqwDslwD+HMD/k+K+9wF4TqPrEBERUZb09fWho6MDQRlEeXk5bDYbLMaFTMyeqj0YdcfmNH2/4/vwz/kxODkIv/AjVBxCKBzC7OwsSo2leOi+h1YMOtTBU0PxQje9wZlBWHdYsW3bNmzbtg0jthE4B2IBkclgQn19PXp6ejAyMoK9e/cuWaoXCoVgNK6+Nb3f70coFILZbEZBQQHa29sxMDCAQCCA5uZm5Tij0YgjR46gt7cXN2/eRHd3N4qKiuB2u6HT6XDo0CE8++yzGB8fh9frTShTTDY8PIxwOIzy8nLY7fYlj8sUm82Ge++9F729vfB6vfD7/cr3IV5K2tbWphxfUVEBIQScTieee+45SClx9OhRLupMlIJWAdgnAJwVQpQBeArAMIB6AG8F8LsATmh0HSIiIsoCj8eDGzduAAAq6yoRCoUAJLaI31W5C7/o/gWAWGMMnUEHi8WCbk83vNe9cDgciMoodlXvSqvkTq2xeGEx4OHZYURlVOm8mNyGvri4GHa7HR6PB1NTU6isTJz5IKVER0cHuru7cfjw4VW3So+vjVVcXAwhBAwGA+655x44nU6lzDBOCIHW1lYAsbLFq1evQkqJsrIyWCwW1NbWYmhoCIODg9i1a+km0fGmItu2bVvVWLVktVqxd+/ehH3hcBh+vx/RaFRpXQ/Egs/y8nJMTU0pzVjOnz+P++67T5krR0QxmnRBlFJeBfAbAE4C+DmAm/P/3gvgtVLKa1pch4iIiDJPSolr164hGo2isbERBYUFyn1Wk1XZri2sRXFBccJji4uL4Q67MTAxAL/fH+uSt+PwqsdQVFCknDsUCWHMPabcl9yGXgihdAgcHh5edK6uri50d3cDiDX6WC2XywUACQFHSUkJWlpalsy2NTc3w2q1KtmieAAaD6gGBweX7Bjo9XrhcrlgNBoXBXi5ZjAYUFhYmPC9iDt48CAOHjyIe++9F6WlpUqTleW6KRJtRZotVy6lfE5KuQvADgCnAOyQUu6SUj6v1TWIiIgo8wYHBzE1NQWTyYQ9e/YsWgcsTgixaHFls9kMe6kdOqsORUVFqK6uRm3Z2oIIdRni0MyQsh2MqDJg+lh2Jb4+1ujoaEK3xb6+Pty6dUu5HQ+mVkOdAUuXTqfDzp0L657FA7CysjLY7XbMzc0tuW5WvOFJeXm50uhjI7BaY2WiZWVluPvuu2G1WjEzM4OLFy+yPT2t2uTkJG7dupVyaYeNTrMALE5K2SWlPCOl7NL63ERERJRZQ0NDuHr1KgBg7969MJlMyjpgAGAzJc5bOtF4AmZDYomZzqaDrcyG0tJSmM1mlFnK1jQWdRni4MxCn6/4OmBAbA4YANjtdpSUlCAcDitZruHhYVy/fh0AsH//fhgMBvh8PgQCC49fiZRSCcBW292vvr4eFRUVsNvtyvw2IYSSBYt3EkwWb/hRVra271s+MJvNOHbsGEwmEyYmJnDt2jUGYZQ2KSWuXLmCO3fu4M6dO7kejuY0D8CIiIgo/0kpMTc3B4fDgf7+fty8eRPnz5/HpUuXIKVEe3s76uvrIaVMyICpm3AAQIWtAn9z/9/gbx/8WyUQC0VCStCmF3oUmtfWiGE1GTAACWWIExMTynPZvXs3mpublQzWarJgfr8fwWAQJpMJBQUFKz9ARQiB48eP48EHH0zIZDU0NECn02F8fBy3b99eFJjEM2AbOQADYkHx3XffDb1ej/7+fqUMlGglTqcTfn+siXpXV5fyIchmoVUTDiIiItoA3G43urq6MDY2lnJujhACe/bsURpJBMIBRGSsBMioN8KkNy16jNlghhlmlBaUYswzlnBfsaVYaZ6xWnWFddAJHaIyiknfJOZCcygwFiRmwFTjqaurw82bNzExMYHJyUklkGxvbwcQy2A5HA64XC5UV1enNYbkBhyrleoxZrMZBw4cwJUrV9DZ2YlQKIQ9e/ZACIFgMKh0TVxNyWO+Kisrw+HDh3Hx4kV0dHTAYrEogTLRUkZHY91V40seXLlyBadOncr4YuTZwgCMiIhoixgYGFC68gGAyWSCzWaDzWaD3W6HzWZDcXFxQnt0b1BVfmhcum06AJRYShYFYKUFa1+Xy2wwo9peHVtrTEoMzQ6hvbw9MQOmKn8sKChQOvEBsfWz1J0G42WA8RK/dKy1/HAljY2NMBgMeOmll9DT04NQKISDBw8qYyspKYFOtzkKlWpra7Fnzx7cuHEDly9fhtlsRkVFRdbH4ff7YTKZNtS8uq1ISqmsgXf06FFcvnwZMzMzcDgcOfm9yQQGYERERFtANBrFrVu3IKXEtm3b0N7evuw6VHG+0NLlh8lKLCVp7VuNxuJGZa2xwZnBWACmakOfnJFramrC1NQU6urqsH///oRPzONBlMvlgpRyxU/TXS6XMk8rE9mo2tpa3HPPPbhw4QIGBwcRDodhscS+xxu9/DBZa2sr/H4/enp68OKLL+Lee+/N6hph09PTOHPmDLZt24YDBw6k/TiHw4GLFy/i0KFDqKqqyuAIKc7pdGJubg5WqxXl5eWora1FT08PpqamNk0Atjk+WiEiIqIEoVAIfX19uHTpEnw+H8bGxhAIBFBYWIgDBw6kFXwBSRkw0/KPSZXtKrWsPQMGLJ4HFpVRhKKxNcmEEIsCsLq6Ojz88MO46667FgVYBQUFMJvNCIVC8Hpjz2t0dBTPPvvsonlhDocDL7zwAoLBIKqrq1FTU7Ou57GUyspKHD9+HEajEaOjo+jp6QGw+QIwANizZw9qa2sRCoWy3p6+q6sLUkolO5quvr4+BAIBZV02yqxwOKz8H6itrYUQQlnXb7U/u3zGDBgREdEmIaWE0+nEwMAARkZGlPbNMzMzStlVc3PzquZRzAZmlW27yb7ssamyXesNwJI7ISbP/0r1XKxW66J9QCxgKy0txdjYGFwuF+x2O3p6euDxeNDR0YETJ04AACYmJvDiiy8iEomgvr4ehw4dyujck7KyMpw8eRJnz55VOjTGyyU3EyEEDh8+DK/Xi9nZWQwPD6OpqSnj1/V6vUrLf5/Ph0gkklYZopQSk5OTAFZXtkqrJ6XE8PAwOjo6MDc3ByGEsmB6WVkZhBBwuVwIhUIwGo05Hu36MQAjIiLagNQldKFQCENDQ+jv74fb7VaOqaiowNzcnLLPYDAob2rSNe2bVrbLrMtnZVJlwEoKSlZ1vWSVtkqYDWYEwgF4g16MexYWUlZ3QExXWVkZxsbGMD4+jqqqKuWN9dTUFKanpzE3N4eXXnoJUko0NTUtKmPMlKKiItx77724cOECCgsLYTItbnayGej1erS3t+Oll15Cb28vtm3blvHvb29vrzLvUUoJj8eTVkmp0+lEKBTLts7NzcHv9ysloqQdl8uF69evJ8x/3Lt3L4qKigDEXrdKS0sxPT2N6enptBvo5DMGYERERBtINBpFR0cH+vr6UFBQALvdDofDoWS7zGYzGhsbsW3bNthsNni9Xpw+fRqhUEhp/LAaDr9D2V5pPa9MZMCEEGgoakD3dKyFefxfYPH8r3TEOyWOj4+joqJCCWSllLh8+TJ8Ph+klGhra8Pu3buz2nXNZrPhgQce2DSd3pZSW1uLgoICuN3ujDdWCIVCGByMrSFXWFgIt9sNt9udVgCWvFC20+lkAKahQCCAmzdvYmgotsSE2WzG7t270dDQsOj/QEVFBaanpzE1NcUAjIiItp5AIIDbt29jbm5O6aJXXFyMkpKSTVEaks98Ph9efPFFpTOfz+eDzxdrklFZWYmmpiZUV1cndM+z2Wy455570N/fj+3bt6/6mqvJgFmNVhj1RoQisazBetYAU2ssaVQCry5Hl7I/eQHodFgsFpSVlWF6ehq3bt0CALS3t6O3t1eZF7Zr1y60t7fnJBDa7MEXAOh0OjQ1NaGzsxN9fX0ZDcA6OzsRDodRWVmJ0tJSJQBLRzwAi/++OJ1O1NXVZWysW0k4HMbZs2cxOzsLnU6H1tZWbN++fckPiCoqKnD79m1MTk4qcwf1ev2G/f/CAIyIiBaZm5vD6OioshZLTU0N7HY7fD4fbt++rcxTSWaz2VBSUoKSkhIUFxejuLh41RkXSs3lcuH8+fMIBAKwWq246667oNPpMDs7i/Ly8iXnPQGxN5BraeogpcS0XxWArZABE0KgtKAUE97YG9f1rAGmpp4Hpl6QeS0ZMCC2YPP09DSCwVg3xYaGBhiNRnR2dmLXrl3KGmiUOU1NTbhz5w7GxsYyVto3MzODvr4+ZW07j8cDAGkFYIFAQJk72d7ejvPnzysLZNP6xLPNs7OzsNvtOHbs2LKvX0BsTqRer4fb7caPf/xjAMDLXvaytJsJ5Rv+VSQiIgBAMBjE6OgoRkZG4HA4lDkTQKwjnFpFRQWam5uVRWNdLhdmZmbg9Xrh9XoxPDwMIPaGvKSkBLW1tWhsbNy081oybWZmBi+88ALC4TAqKipw9OhRJduYycV6fSGf0vTCpDet2IQDiJUhxgOw9awBpqbuhBiVUWV7LRkwIFYCd/36dUgplXXQ2tra0NLSsmnW3sp3ZrMZ1dXVGB0dxfDwsLJYtlaklLh27RqklGhtbUVRUZGSLUknABsbi61nV15ejvLycgghMDs7m3YDD1pab28vRkdHYTQacffdd68YfAGxrGlzc7OyLMRGxwCMNqxQJIRf9f8KeqHHfc33afIpK9FWdfPmTfT09ChBl06nQ3V1Nerq6iCEwOjoKEKhEEwmE8rLy1NOnI9GownBmMvlwuzsLJxOp9KZ7+TJkzCb1/ameauKv5EMh8Ooq6vD4cOHsxYkJJcfplPuo57ztd41wOLsJjtKLaVw+hM70a01A2Y2m1FZWYmJiQlUVVUpz4vBV3Y1NjZidHQUg4ODaGtr07ScrK+vD06nEwUFBdi5cyeAWIZep9PB5/MhHA4vmZ2XUqK7O1byWl9fD4PBALvdDrfbjZmZmU25REAm9ff34/r16zh+/DjKy8uVlv4HDhyA3b7yhzpxe/bswZ49ezI1zKxiAEYb1qWRS/h5188BxNamOVJ/JMcjIto44k0b4l3guru7IYRAVVUV6urqUFNTkzCfK515DzqdTik7jAuHw5icnERnZyfcbjfOnz+PEydOsCxxFUZGRuB0OmE2m3Hw4MGsBgnq8sNyS3laj6kvqle21aWD69VQ3LAoAFtrBgyIzfPS6/UsN8yhqqoqmM1meDweuFwuzVrve71edHR0AAD27dunvN7odDrYbDa43W6MjIygp6cHFosF1dXVqKqqUjIxw8PD8Hq9sNlsqK+P/T6XlZXB7XbD6XQyAFsFKSW6uroQjUbR19cHi8UCt9sNg8GQsbX1NgL+BaQN68e3f6xsf+/G9xiAEa1ASonp6Wncvn1bWdDy6NGjSgeqeNc3LRkMBtTW1qK0tBS//vWv4XK5cO3aNRw+fFjT62xG8XbZ8TeSO3fuzHrgupoGHHGHag/BE/QgKqM4XKfdz7mxuBHXxq4l7FtrBgyIlW4ePXp0vcOidYiv9dTd3Y3BwUFNArD4/KL4Gm61tbUJ98c7IV69ehVSSrjdbqXZRmFhoVIWCQDbt29XsnKlpaXo7+/nemCrND09rTQKGh8fR0lJCYBY06CtnHFmAEYbllFvRDASzPUwiDIu/kY8XtYXDAaxd+/etEv5pJTo6elBb28v/H4/gFj3qEgkgsuXLyMcDmc8E1BQUIBjx47h+eefx9DQEFpaWpQ/xEuZnZ3F9evXUVJSgoaGBmVNmM1sbm4OU1NTmJycxNTUFObm5gDE1ojatm1b1sfj8KXfgj5Or9PjgZYHNB+Leh5Y3HoyYJQfGhsb0d3djZGREezbt2/db8p7e3sxPT0Ns9mMffv2Lbq/sDDWlVNKidLSUjQ1NWF8fByTk5MJHRJtNlvCmnnx4NDpdCaswbeUQCCAcDi8YZtEaCW+BAAARCIR3L59G0As+7mVMQCjDavQXAhv0KvcDoQD/GNMm4KUEjMzMxgdHYXL5YLL5VLa7qqPOXJk5ayv2+3G5cuX4XK5AABWqxUNDQ1oaWnBpUuXlE9+t23blvG5WXa7HS0tLeju7kZHRweOHz8OIQTC4TDcbjdmZ2fh8/mU9auuX78Oh8MBh8OB7u5uHD58eNWLCG8UgUAAFy5cWPTpenyu0s6dO3PSbjlhDbA0M2CZUldYB53QJTbhWMNCzJRfCgsLlazUzMzMurJgHo9HWVrg4MGDKZv+xEukCwoKcPToURQUFKCxsRHRaBTT09MYHx+Hy+XCjh07Ev7P2Ww2mEwmZUHmpRpHTExM4Nq1a0rW5957792yJYvhcFjJJjY3N6Ovr0/5W7YZ1vJaDwZgtGHFO3PFjbpH0VzanJvBEGlkenoaV69eXdSly2KxoKSkBEVFRejq6sLIyAiampqWXD8nnvW6desWotEoLBYL9u/fn9Bw4NChQ3j++ecRDofR1taW8ecGxNZbGhgYwNTUFM6dO6esY6XuuDg2Noa9e/fC4XDAaDSiuroaQ0NDuHXrFurq6lb9CXkkEkEgEIDFYsnbNWNu3rwJp9MJg8GAsrIyVFZWorKyEna7PadjTihBTDMDlilGvRG1hbUYnh1W9q2nBJHyR3x9LqfTueYATF162NjYuOQb/KqqKhw4cAAVFRUoKChQ9ut0OlRUVCz5mhrv6DoxMQGn07lkANbV1aUEXwAwOTm56QOwyclJXLx4EdFoFHq9Hnq9XnmdDofDKC0txfbt29Hf3w8pJUpKSrZ8MyYGYLQhSSnhCXgS9g3PDjMAow1tamoK58+fRyQSgdlsRn19PcrLy1FSUpLwRkEIgVu3buH69eu4//77FwUkHo8Hly9fVrIp27Ztw549exYtkmw2m/HAAw8gHA5nZA2eVEwmE9rb29HR0YHJyUkAsTc+hYWFKCoqgsvlgsfjwYULFwBAWZwzvn90dFSZFL+Subk53Lp1C6OjowiHwzAajSgpKUFpaSlKS0tRUlKSF23xXS4XhoaGoNPpcP/99+dNyVIgHIAnGHud1QmdZh0N16OhuCEhAGPVw+ZQWlqKgYGBdc2v6u7uhtPphMViwd69e5c8TgiBpqamNV2jrKxMCcBSvQ6Fw2FMT09DCIH9+/fj6tWryqLpm1lPTw9Codji65FIZNH9zc3NKCgoQFlZGRwOx5YvPwQYgNEGFQgHEIqGEvaNzo7maDRES5NSKp+GmkwmGAyGhIxGJBKB0+nE+Pg4+vv7lU9vDxw4sGSmp7W1FQMDA0onL3VZ3vDwMK5cuYJIJIKCggIcPHhw2T92ZrM5659EtrW1wWg0Qq/Xo6ioCHa7XXmubrcbp0+fRiQSgdFoREtLC4QQaGtrw5UrV9DV1aW0xl/J5cuXlSDPZDIhGAxicnJS2QcAJSUlOe3KKKXEjRs3AAAtLS15E3wBSOg4WGIpyYulPhqLG3Fu8JxymxmwzUE9v2ot3G43Ojs7AcRamyd/2KSVlcYZXz+xtLRUyaTFy783q0AggMnJSQgh8PDDD0On0yEajSISiSASiUCn0ymt5vfs2YO+vj60tLTkeNS5xwCMNqT4p7Jq6k9FiXJNSon+/n709fUllBMKIWAymZQAxO12IxpdmNPS1NSE/fv3Lxtg6PV6bN++HVeuXEF/f78SgAWDQVy7dg2RSAQNDQ3Yt29fxt6IrMdyn0AXFhZi//79uHLlCrZv366Mv76+Hrdu3cLs7CwmJiZWnD8Qb2YRzyoVFhbC7/fD5XIp65LF59dNTU3lrB3y9PS00jBg+/btORnDUuKLKQO5Lz+MS25rzwzY5mC322E0GuH3++H3+1eVkY+XHkajUTQ1NWU0u1JSUgIhBGZmZlIuyBz/cKeyshJWqxVGoxGBQABzc3MJVQybycjICKSUqK6uXvHnVlJSgkOHDmVnYHku9x9nEa2BO7B4FftJ3+SieWFEK4l/etfd3Y1Lly4lLEYc53K5lG50SwkGg7hw4YLS0v327du4du0a3G43TCYTrFYrDAYDpJQIBAJKV0MpJYqKitDe3o577713xeArrq6uDgaDAdPT0/B4Yh9IdHd3IxQKoaKiAocPH87L4CsdjY2NePWrX53QlVGv1yvz1K5evYpAYPn/6+o3BfGuZxaLBbW1tdizZw/uvfde5Xy5/IQ6vhxAfX193v28Bl0L3cvUa3vlUrm1HBbjwps8ZsA2h/j8KmD1WbDZ2Vm4XC6YzeaML9JrMBhQWFgIKWXKcaoDMCGE0vBjM5chxv/mbdYGSZnCDBhtSO7g4gBMSokxzxiaStZW201bx+DgIEZGRjA7O7sosBoaGoKUUnlz3t3djZs3b8JsNuPUqVNLfsJ3+/ZtjI2NYXx8HG63W1nY+ODBg6ivr1dK7KLRKILBIEKhEMLhsPLJ72oZDAbU19ejv78fAwMDaGtrQ29vL4DYArMbXaqSwNbWVoyNjWF6ehqXLl3CsWPHlgxWh4djGfHl5ovF3xzlMgBzOGJdBsvL01vkOJsGZgaU7Xx5XRVC4GDtQZwdOAubyYZq+9bupLaZlJaWYnJyEk6nU1n4XUqpZK5tNlvCIu9xs7OzAGL/h7JRSlxaWorZ2VmcPXsWZWVlqK6uRnV1NfR6PTweDwwGgxJMFhcXY2pqCjMzM5uy65/X64XL5YLBYNiUzy+TGIDRhpQqAwYAI7Mjy75RSGftDtrcfD4frly5omS5DAYDioqKUFRUBKPRiDt37uDmzZuYm5tDNBpFX18fgFim7OLFizh58uSiuVk+nw/9/f0AYr9jXV1dAGKLeDY2JpZM6XQ6FBQUaFKOsm3bNiUAm5iYQCQSQU1NjSaLmeYjIQTuuusu/PKXv8Tk5CS6urpSlu15PB7lTcFy5UjxN0kul0uT1waPxwMppZJxW0l8/p8QIu8CsFAklDCvNrn0L5des+M12F25GzWFNTDq8ytrSGsXf92anJzEnTt3lDLheLbbYDDgFa94xaIgKx6AZWudwNbWVvh8PkxNTSnLZNy8eVNp6FNRUaH8jciHD3kyKZ79qq2tXVSOSctjAEYbknoOWIGhAHPhWBZj0ju51EPQ6+zFv179V1TZqvCOu94Bg46//ltRX18fpJSoqanBnj17YLVaE954m0wm3LhxAz09PQBib/p3796N3t5eOJ1O/PKXv0RxcTFsNpvy1dvbi2g0ivr6ehQUFKC7uxslJSXYsWNHRp9LcXExioqKMDs7i1AoBJPJhN27d2f0mrlmsVhw+PBhnDt3Dp2dnSgrK1sUvMSzXyu9KYgHwnNzc/D5fOtqgOHz+fDLX/4SkUgEFRUVaG9vR2Vl5bKPcTqdiEajKC4uzrvyw+HZYURkrJtZhbUCVlPqltu5YNAZ0F7enuthkMbiAZjb7VbW8gKgBDbBYBDj4+OLstrxObbZCsDsdjuOHz+OUCiEyclJjI+PY2JiAsFgEEDiAsObuQRRSplWpQGlxnegtCGpW9C3lLagY7IDwPIB2LPdz8IdcMMdcOPm+E0cqD2Q8XHS2oTDYTgcDkxOTiIcDmP79u2adIeLRCIYGIiVVS11ztbWVlitVrhcLkQiEVRVVaGyshLl5eV44YUX4Ha7F63RBcQCtZ07d8JqtaKmpgZFRUWrXq9qtYQQOHToEEZGRpRAJFfd/LKpqqoK7e3t6OrqwksvvYT7779f6eQYiUSUbORKcxLi807GxsaUEqe1un37ttJ+eWpqClNTU6isrMTu3btTlk3FjwPytPzQtVB+uK1kWw5HQluF0WhEe3s7HA5HwnIRFosFfX19uH79OoaHhxe92Y9nwNLNPGs53rq6OtTV1UFKienpafh8voTXHZvNBoPBgLm5OQQCgTV1nO3v78fk5CQKCwuVD92S1zSUUuLChQsQQuDIkSMZ/9sDxLJ6Xq8XBQUFS66dRkvb/H+paVNSzwFrKVsIwCY8EymPD0fDCW8ohmaHGIDlESklXC6X0iLc6XSmXJjX7/cjEomgtbV1TX/IhoeHEQqFUFJSopSfpVJTU7OoK15JSQle/vKXY3Z2Fl6vN+HL5/MltBDP5qKbxcXFS77B38x27dqldBC8fPky7rnnHgghMDw8jEAggOLi4rQCG3UAttZPcd1uN4aGhiCEwH333ac0dYn/PtfX12PXrl2LFm6Nz//Kxzcv6tfLfJn/RZvfUhn8uro63LhxQ8k0xbNigUAAgUAABoMha2sZphIvI05+zYk34nA4HJiYmFhUkr6S+DIVkUgEo6MLJcFGoxHFxcWoq6tDU1MT3G43xsfHAQDXrl3DgQMHMj7dIp79SndZEErEAIw2JHUGrLG4EQadAeFoGJ6gB/6QP6FLFgAMzgwmrBs2MjuStbHSyrq7u9HR0aHcFkKgtLQUlZWVmJmZwfj4OC5fvqzcPzQ0hCNHjqQd6EgpMTo6itu3bwPAmtcgMRqNKf/IUvap54NNTEygq6sL7e3tSuloa2trWm8K1HM04kH/at9MdHZ2QkqJpqYmJbhvampCV1cXent7MTw8jNHRUTQ1NWH79u0wm80IhUJwuVwQQmQ1YE+HlDKhAQczYJRrZrMZFRUVmJycVP4vAYnzv/I1CGhsbITD4cCtW7dQW1u7qioFj8eDSCQCs9mMxsZGzMzMYGZmBsFgUMm019TUYHp6WnnMwMAAioqKMrrWVjQaxchI7H0Uux+uDQMw2pDUc8CKC4pRYa3AmGcMQKwMMfkNQ+90b8Lt4dlhNuTIACklJiYmoNfrYbFYUFBQsGgOjpQSd+7cwdDQEA4dOoSSkhJ0d3cDgLKGS3l5uTInJt7UYnx8HMXFxZidncX09DTOnDmD++67b9lMVvzxZ8+eVcq9CgsLlQ5btLElzwcbGxuD2+1GQUFB2j9jdSOOn/3sZwCABx54AGazGbdu3YLb7cbBgweVT9zVpJTo7OzE6OgodDpdQkMQk8mEPXv2oLm5GZ2dnRgeHkZvby8GBwfR3NyMsbExRKNRlJaW5t38r2n/NLxBLwDAYrSg0rb8XDaibKivr8fk5CR6enpgNptRVVWllINnu/xwNRoaGtDf3w+n04nOzk7s3bs37cfG546VlZUp2cH4UiYvvfSSUqofD8CqqqowMTGBmzdvoqamJmNZwampKQQCAdjt9qzNvdtsGIDRhhOVUeXNAQDYTDZU2JYPwHqmexJuByNBTPmm+MZCY11dXQmTp4HYJ5cWi0X5crvdylop169fx/bt2xEMBpUFeJODYiEEtm/frry5jUajuHr1KgYHB3Hjxg2cPHly2UB6dHQUU1NTMJlM2LlzJxobG7NSH0/ZUVVVhZ07d6Kzs1PpNNba2pr2z9hkMsFms8Hr9Srd1oaHh1FbW4uuri6lDfaJEycWBUodHR3KcgOHDh1K+WbHarXi8OHDaGtrQ0dHh5KtA2JvGvNxUdIx95iyXV9Uzw+qKC/U1tbi1q1b8Hg8uHDhAoqLi5Wy3nwOAoQQ2L9/P06fPo3e3l5YLBY0Nzen9RoVD8DUZeZCCBQUFKCmpmZRALZ7924YjUYMDw/j1q1bOHz4cEaeU7x8ura2lq8Pa8QAjDYMl9+FL1/4MmYCM0qpkNVohUFnQJW9CoiVP2PKO5XwuFAkhMGZweTTYXh2mAGYhvx+P+7cuQMg9mnd3Nwc/H6/UqOvbsMbzybMzMzg+vXrAGIt1dN5IdfpdNi7dy8mJiYwPT2N0dHRJbMd0WhUCQh37dqllK3Q5rJjxw40NjZidnYWwWBw1SUxBw8exNTUFHQ6HW7duoWhoSFEIhHldWZmZgZnz57F8ePHlSAsvtabTqfDkSNHFs0ZTFZUVIRjx45hamoK3d3dKCoqwo4dO/KydbPD51C2+RpJ+cJgMODUqVMYGhpCX1+fUo4H5HcABsQCqLa2NnR1deHGjRsYGBjA3r17V+yUmioAi4s/dmxsDOFwGEajEYWFhdi1axdGR0cxPDyMtra2jHxv4uNaqQKFlsYAjDaM0/2n4ZpzJeyzm+wAgErrwotYcifEoZkhhKPhRecbnhnGodpDmo9zq+ro6EAkEkFdXR2OHDkCYKFUwu/3K1+RSASNjY0YHR3FjRs3MDc3B51Ot6o3zUajETt37sTVq1fR0dGBqqqqlHX1g4OD8Hq9sNls2LaN81g2s3iGdS3i8/oikQi6u7sxMzMDv98PIBacdXV1weVyJQRh8U6LjY2NKwZfahUVFXnZdENtyrfwIVa5lfMdKX8UFBSgvb0dNTU1+NWvfoVQKDa3O59LEON2796NsrIy3LhxA263G2fPnkVtba2yHEoyKeWyAZjdbofFYlFeq0pLSyGEgNVqRVNTE3p7e9HR0YFjx45p+jxWGhelh3U4tCFIKXFz/Oai/YXm2ItuhW3hDc2Ed6ET4vDMMH7e/XPldklBycJ9s8MZGOnWNDk5ieHhYej1+oQuVvFSidLSUtTV1aGtrQ07duyAxWJBU1OTshhxdXV1yjk2y9m2bRuKiorg8/lw+fLlhK6JQOKCyLt27WKZBK1Ir9cr2dRgMIiCggI0NjbixIkTytIEZ8+ehd/vx+BgLKve3NycwxFnhjoDxgCM8pHdbsfhw4chhEBhYWHezaNcSnV1NR588EHs3r0bBoMBo6OjePbZZ9HZ2aksYxHn9XoRDodRUFCQsuuvECIhg6Zu5rNjxw4YDAZMTEwojUq04vf7lU6U8b/htHoMwGhDGJoZwmxg8YtIgSH2n7/CVqG8wZ72T6N3uhdPvvQkPn/u8+hz9inHn2w6qWyPuEcQldHMDnwL8Hg8uHjxIgCgvb095Sd5qej1euzbtw82mw3t7atfVDW+3kn8j1i8/DHO7XbD5/PBbDajtrZ21eenrUndir6xsRFCCFgsFpw8eVIJwp5//nmEw2GUlZXlfelTssujl/Gtq9/C8MzSH0BN+xY6qjEAo3xVXV2NU6dOaZ7hyTSdTof29nY89NBDaGhoQDQaxe3bt/Hss89ibGxh/mU6WSb1os/qAMxkMikt73t7exc9bj3U4+IHm2vHAIw2hJsTi7NfAGA2xD4VMulNSnZLSoknXnwCd6YS35Afrj2MY43HlKxZKBJaduFmWl4kEsHY2BjOnz+PUCiEmpqahC5w6aitrcXLXvayNdeR2+12HDlyBEIIpRtd3MRELBNaVVXFPxKUtrKyMtjtduh0uoQ1e9RBWLzsaaNlv9wBN757/bu4NnYNX7v0NcyF5hYdEwgHlA+7dEKHUktptodJlLbi4uKcrv+1HgUFBTh8+DDuvfdeFBcXw+/348UXX4THE+vynE4AVlFRAZ1OB4PBsOjvaEtLC4QQGBoaUhoMaYHzv7TBOWCU96SUuD5xXbm9t3ovbozfAADsqtyl7K+0VcLpdyY8VgiB/dX78WDrg6i2VwMAagtr4Q7EWtdOeCaU/bSYlBJerxezs7OYnZ2F2+2G2+1GMBhEOBxWyv6KioqUcpBsq6qqwu7du3Hz5k1cunQJNpsNRUVFSgBWXc2fL6VPCIETJ04gGAwqC2vHxYOws2fPAsCGyKxGZRRT3ljH135Xv5L19wQ9+EX3L/DaXa9NOH7av5D9KrWUQif4OS1RJpWVleHUqVO4cOECxsfH4XA4YLfb0wp0jEYjTpw4ASHEooY+NpsNVVVVGB8fR39/P3bs2KHJeDn/SxsMwCinwtEw/CG/kpVKZcwzppTEmA1m/M7+30FPfQ+klNhRsfCC0lDcgNtTsYV2dUKHg7UH8WDLgwnzwwCgzLqQpk9u6kExbrcb165dg9PpRDSaukxTCIGSkhJUV1ejubl5VYtLaq21tRWzs7MYGhrC+fPncfz4cUxPT0MIkfcNDyj/FBQULDm3wWKx4MEHHwSw+gWbs01KiScuPIF+Vz/uqrtLaVoUd3bwLI7UH0FN4UITEc7/Iso+IYQSLDkcDjQ2Niqdg1cKdJZbyL21tRXj4+Po6+tDW1tbynU5+/v7lQXkV8IGHNphAEY54wv68LkXPgdP0INXbX8V7mu+L+Vx6vLDnRU7YdAZEgKvuJPbTsIX8kEv9DjeeDwh0FIrsyzsT86YETA0NISrV68qE4KtVisKCwtRVFSEwsJCFBYWoqCgAEajMW/egAohcODAAXi9XjidTpw5cwZSSlRUVGyYydm0ceTL7/1KZgOz6HfFujW+NPISagsTM3ZRGcXXr3wd7zj8DqXdvDoAq7DywwuibIkHUtPT03A4HAiHwygqKlpXo4vy8nIUFRVhdnYWIyMjCWXV8Wtdu3YNer0eR48eTZhTlkp8WRmj0bhhSz/zBQMwypnr49eVuQY/vv1jlFhKsK9636Lj1N0P91YvvYK8xWjBI7seWfG66k6IGz0Ak1IiGAxCp9NpEmiMjIzg0qVLAGINCPbu3bthApj4H5DTp09jbi42t2WlPyZEm5kn4Em4PeoeXXTMtG8aXzz3Rfzewd9De3l7QgC21IdYRKS9eDdHv9+Pvr4+AOsvoRdCoLW1FZcvX0ZPTw8aGhoSPkCKd0iMRCK4cOEC7r777mX/bqqzchvlg6h8xQCMcqbH2ZNw+zvXv4MySxnqihYW1Z3yTmHME+sKZNQZsb18dU0eUlFPKnf5Xes+X7Z4PB44HA54vV74fD7l33A4rKyj1dbWBrvdvvLJVHw+H4QQiEQiuHLlCgBgz549aGtry8TTyKiCggLcfffdOHPmDCKRCOd/0ZbmDrpT7reb7HjDnjfgX6/9K0KREObCc/jqS1/Fa3e+liWIRDkihEBZWRnGx8eVboha/A2rr69HR0cHZmdn4XA4Esry4wGYzWaD1+vFzZs3UVlZuWRwxfJD7TAAo5yQUqJ3OrE1aigSwg86foDH7nlM+c+vLj9sL29Xuh6uhzoAc845IaXM609yXC4XOjs7laYSyYxGI8LhMAYGBjA8PKx0VErH5OQkzp8/j2g0Cp1Oh2g0ivr6erS2tmr5FLKqpKQEJ0+exNzc3KqDUaLNJDkDFtdY3IjdVbvxnrvfg6cuP4WZuRlEZRRP33o64bWQJYhE2RUPwADAbDZr0mlQp9OhubkZnZ2d6OnpSQjA3O7YhzT79+/HSy+9pDTaWmp5jXgGrLSU3VHXiwEY5YTD54AnuPDmQC/0iMgIhmaGcGXsCgp9hfB4PLjiuaIcs1z54WoUGApgNpgRCAcQioTgDXkXTU7PJJ/PpyxabDAYYDQaYTQaYTAYoNfrEYlEYDAYYLfbMT09jbNnzyISiUCv16OmpgaFhYWwWq2w2WywWq0wmUzweDzo6OjA2NgYLly4gFOnTqVcuFHN7XbjxRdfRDQaVa5rt9tx4MCBvA5I08H2uERLZ8Dqi2NrndUV1eGPj/0xnrr8FIZmhgBA6WyqEzqUWEqyMk4iilE31NByCZWmpibcuXMH4+Pj8Hg8sNvtkFIqAVhxcTFqa2vR39+PkZGRlAGYlFIJwPg3dv0YgFFO9DoXsl+7Kneh2l6N53ufB4D/n73/jpPsqu/8/9epzjnnMN0Te3JOGmVAQhhEENmAJQshYFls7/68Afu3Btu7+/3uesH+LWssooQAGS0giSgRBBpJoxlNznk651Sduyud3x9Vfaeq03TPVKeZ9/Px6MfUvffce8+tW91zP3XO+RxeOPECG0c2MhIY4XD3YXJzc0lKTGJV7qqonNsYQ1ZSFi19wSZ+95B7zgIway1Hjhyhu/vaY88yMzPp7+/H7/dTUlLCunXriI+Pn7BsamoqW7Zs4Y033qC7u5tXX32VtLQ08vPzqaysHFd+cHCQAwcO4PP5KCoqYsuWLQwMDJCUlDSv2QxFJHpGp9sYqzS91HmdlpDGo9se5Senf8LJlpPO+uykbKWgF5ljmZmZzhei0exCn5CQQGlpKXV1dVRXV7N+/XqGhobw+XwkJiYSHx9PcXGxE4CtWrVqXPA3ODiIx+MhISHhhhKDSJD+usqs6Ovr4+LFi04mvbGudF0d/1WZVcldlXeREp8STInaXMvFwYu0Bdrw+Xy0traSSSZJcdHLuJOVeLX5PHzem9ng9/vp7+/HWkt7ezvd3d3Ex8dTWVlJaWkphYWF5OTkkJGRQWpqKhkZGcTFxeF2u/H5fBQXF7N58+ZJg69Ro0kokpOTGRoaoq2tjVOnTjE0NBRRbnh4mP379zM0NER2djabN2/G5XKRlpam4EvkJjJZF8SS9JKI5fiYeD60/kPcu+xeZ92ynMU3BlRksXO5XFRWVpKTk0NeXl5Ujz06tKC+vh6Px+OM/0pLC04DlJOTQ0JCAgMDA85Yr3DhrV+LvZfMQqCnLYk6n8/Hm2++6XxbsnZtZNdBa21EC1hlViUJsQm8ddlbefrA03i8HhpiG1hbuZZ0Tzq9fb3EdMVw/Phx1q9fP24ei+sx3UQcY8eHjTbBd3Z20tfXx8DAABD8oxn+ExMTg8vlwuv10t7ejs/no6yszGnuX758+ZRJLvx+P83NzYyMjDiz2U9HYmIid999t9Mlsb29nebmZucP78jICG+88QYDAwNkZGSwY8eOqLyfIrLwTNQFsSS9hOT45HHrjTG8ZdlbWJ6znNa+VjYWbZyLKorIGKtXr56V46alpZGXl0d7ezt1dXVOd+PRAMwYQ1FRETU1NVy6dImNGzdGZEHW+K/oUgAmN8Rai9/vdwIPgLNnzzI4OAhAdXU1paWlTlIIr9fLybqTNLY3Yq0lLzuPovTg3DSrc1Yz0BsMaGLSYqjtqSUrO4uEhATKYsuor6+nt7fXaeW5EeFjGyaajNlay+XLl7lw4QIZGRlUVFTQ3d1NQ0MDXq93xuczxlBfXw8EuwJUVFRMWT4mJobS0tIpy0y1b0ZGBuXl5bS3t9PU1MTSpUvxeDzs37+f/v5+0tPT2bVr16JJMS8iMxfeBfHB1Q/SOdjJ9tLtU+6zJHMJSzKXzHbVRGQeLF26lPb2di5fvuw8l4WP9yovL6e2tpbm5mY6OztZuXIlS5YsweVyafxXlCkAu8W43W7OnDlDamoq5eXl057LYbT73NgU6IODg043w5iYGNLS0nC73RhjKCgooKWlhaNHj5KWlkZPTw9NPU283PUynoAHgGUZy5xxBjWXayiKK6Itvi1igr+qkireVvU2Dh06RE9PD6+99hr33HPPDQUP4S1gB+oPcKrlFCUZJXxk40ewPsvRo0dpb28HghMVdnVd7aaYkpJCbm6u02XQGEMgEBj34/f7McaQm5uL1+vl4MGDDA0NsWLFijlpdSooKCA2Npbu7m56eno4fvw4vb29pKamsmvXrmt2aRSRxctaG5HoaGPhRhLjNG5D5FaWl5dHTk4OnZ2dzjPOaAsYBJNx3H777Zw5c4bOzk5OnTpFdXU1q1evVgr6KFMAdgupr6/nxIkTBAIBOjs7qa2tJT09nSVLllBSUhIR0Hi9XqqrqykvLycxMZFLly5x7ty5CY8bExPjBByj35CsXLmSpUuX8vvf/95Ja9rv62evey8mzpAal4pn0EPBYAE9PT3ExMRQW1tLeVI53qTIFqZ1BetIT0/njjvuYP/+/bjdbqqrq1m5cuW4utTW1jI4OEh6ejoZGRmkpKRMGGCGT8YMMOAd4ELHBZ478hxZ3VmMjIwQHx/Phg0bGBwcpLm5mfT0dCoqKiZNz3otd911Fz09PeTkzM3cOjExMRQUFNDY2Mi+ffvw+XykpKSwe/fua2ZIFJHFzeP34PUH/5bGueKiMoWHiCxuxhg2bNjAK6+8QiAQwBgTEYBBsIVr9+7dtLa2cvbsWfr7+zl06BAQ/AJaX95GhwKwW0RHRwfHjh0DgulIY2JiaGhooLe3l5MnT3LmzBmKioqoqqoiKSmJs2fPUltbi9vtZtu2bVRXB8dslZaWkpaW5qRAT05OJi4uDmstXq+X3t5evF4vhYWFGGPYvn07jY2NmATD8zXPk5ucizGG+Jh49qTtYah1iAMHDgDBb2y3L9tOu7udIe/VxBFr8tcAwfmu1qxZw759+7h8+TIVFRURfwj6+vo4ceJExHWPtsqNdiMcDZ5GW8BGx3iNju36ee3PuTf7XqqKq9i8ebOT6ScakxLHxcVFzL8xF4qKimhsbMTn85GcnMzu3buVvUjkFhDe/TA1IVWD5kUECGZNXrZsGRcvXiQlJWXCHjnGGAoLC8nPz6euro7z58/j8Xjm7AvkW4ECsFvEaAC1fPlyZ4Dn6tWraWlpoba2lo6ODhoaGujv72fr1q3OeKXW1lbOnz/PyMgIaWlpbNq0acL/yI0xxMfHjwswMjMziU+O55uHvslAYABjDLGuWD6x+ROUpZexd+9eJ5FFSkoKa1avoe5KHQcbDgLBeWrCuwuOZgYa7cMcPlh1dPLCjIwMkpKS6OnpYWhoCLfbjdvtprm5mXvvvZe4uDiS4pLw+Xw0NzeDDSbR8Pl9GGOojq/mj7f/MfGxi/9bnvz8fKc7565duyK6dorIzSs8AUdafNoUJUXkVrNixQr8fv81vxQencS5pKSE9vb2Of8S+WamAOwmNjg4SEJCAh6Ph9bWVowxTjY8CP5iFRcXU1xczMDAAG+88QZut5t9+/ZFTM576dIlINhyNtNvUUd8Izx19Cla+4PBkcu4+MjGj1CZHZyb6rbbbqOnp4eUlBSnu+CO0h0caTyC3/rZWbZz3DGrqqpob2+npqaGVatWOck/WlqC83qtWLGCoqJgYo/RVKtnz57F7XZz5coVVq0Kzic2MjBCIBAAINbGkhiXSGZOJv4EP3+o/gP3rbhvRte6EMXExHDPPfc4r0Xk1hCegj41Ye4mmheRhS8mJmZchuqpxMXFUVxcPIs1uvUoALsJBQIBzp49y5UrV0hNTSU7OxtrLcXFxZOO/UlJSWHjxo3O/FAAO3bs4MCBAwQCAWJjYykrK5tRPay1/OD4D2joaQCCrWQfWPcBqvKqnDKJiYnjusQVpxfz+ds+z6B3kLKM8efMzMwkNTWV/v5+ent7yczMZGRkBLfbjcvlipg7Y7RVbu3atbz++utcuXKFioqKYDl/Hh10UFpcyp9u+lM6vB384sIvAHi15lXW5q+lJKNk3PkXGwVeIree8AQcczXRvIiITI8CsEXK5/Nx8OBBBgaC3frCf7xeL8PDwwD09/fT3x/8j/haqc/z8vJYsmQJtbW1FBUVkZuby5IlS5xU8jOdpLext5FLnZec5QerHmRD0YZp7ZubMnUzd2ZmJv39/bjdbjIzM2ltbQ2mtc/Lm7Ce2dnZFBQU0NrayqlTp0hPT2dd8joqcyp5y+63UJBawAq7gjPtZ6juriZgA/zk9E/4zK7PEOvSr4mILC7hY8DSEtQFUURkIXHNdwXk+ly6dImOjg6GhoactPD9/f309fUxPDxMcnIyu3btcgZMpqWlkZ2dfc3jrl27lk2bNrFhQzBQWr16NZs2bbquiQEbexuvHjd/LTvKdsz4GJMZnQhwNOviaPfDwsLCSfdZvXo1LpeLpqYmzp07h8u4eMuGYPAFwRa69659L3ExwWyQLf0tvFL9StTqLCIyVxSAiYgsXPpqfxEaGBjg8uXLAOzcuZPU1FSstc54JmstqampuFwucnJyqKmpITc3d1rjt2JiYiK6Go5dnonmvmbndVnm9R1jMqMTAbrdbnw+Hx0dHUBw7qvJpKWlsWfPHo4dO0ZfXx8pKSnk5+dHlMlJzuFty9/GL8//EoA/XPkDa/LXUJRWFNX6i4jMJnVBFBFZuBZcAGaM+RzwCLAe+IG19uEpyn4A+H+BAuB14BFrbWNoWzzwv4EPAV7ga9ba/zK7tZ991lpOnTpFIBCgrKxsXAAxlsvliki8MdvOtp3lQscFdpfvpqm3yVlfnBbdwZvp6em4XC76+/upq6vD7/eTnZ19zRTrmZmZ3HnnnTQ3N5OZmTlhUHpb+W2caj1FnbuOgA3wLwf+hbSENFblreLOijvJSNQkhCKysKkFTERk4VqIXRCbgL8DvjVVIWPMauDbwKeAXOA88IOwIv8F2AAsB7YDHzXGPDIbFZ4rgUCAY8eO0dbWRlxc3HV1C5xNfSN9/OuJf+XNhjf54YkfOpkPgai3ILlcLtLT07HWcuHCBQDKy8unvW9JSQkpKSkTbjfG8NDah4hzBbsi+gI+uoe62V+3ny+/9mX2Vu+NzkWIiMwStYCJiCxcC64FzFr7EwBjzDagdIqiHwN+Za39baj8XwNtxphl1trLBFvRHrPWdgAdxpj/Bfwp8J1ZvYAoO9F8gtMtp+nv66e7q5uRwRFS4lKoWlLF6w2vM+IbYcQ/wohvhGHfMB6/B4/fQ1FaEXdV3kXvcC8nWk5QkFrA9tLtxLhmLyPepc5L+AI+IDh+alRmYibJ8clRP19WVhZutxuv10tsbKyTej4aclNyec/a9/DL879kwDPgrPcFfPz60q/ZUrJFDzUisiD5Ar6Iv1tKQy8issBYaxfkD/D3wJNTbH8B+Ksx684D7wayAAuUhG3bDXRPcJxMoGLMz+2h/Sf8eeKJJ+yoJ554YtJywbf3qi1btkxa7rHHHnPKHTp0aMpjfuwrH7NfeOkL9gsvfcFuemDTpOUKlxc65b7w0hemPOboNQ15huyX/uFLUbmmTQ9ssl946Qv26SNPX/OaDh065Bzzsccem7Tcli1bnHL19fXTuqZo3qfRa7rceXlWrskGP5QL9rOna9I16ZoW/jW9fPll+4WXvmAf+LMHbppruhnvk65J16Rrujmu6ac//eno6wo7zThnwbWAzUAq0DNmnRtIC21jzPbRbWP9OfA30a3a7IqLi4v6MbuHutlbvZdXa15lf/3+qB67OL04+O5H2WgijvnQ1t9GHNG/DyIiN2LAM8ArV5S9VURkITPBoHLhMcb8PVBqJ0nCYYx5AThgrf1vYevOAf8R2At0EWwBawpt20Wwy2LWmONkEmwFC1cKvFpdXX3NubNmW1NvEy19LVgs/oCfId8Q/SP9WCwJsQkkxCSQGJtIfGw8ibGJJMQk4PF7eKX6FWrdtcS6YlmVu4oLHRfwBrzOcQtTC+n39DPgHWCyz4AxhjuW3MG9y+51UrNPpnuom3949R8m3PbxzR+PmHw5Wqy1HDhwAGMMO3bsmFaWxxuxt3ovL118CYCdZTt5cPWDs3o+EZGZevro05xrPwcEv/z6zM7P4DILcbi3iMjNoaamhsrKSoBKa23NdPZZzC1gp4CNowvGmHSgEjhlre02xjSFto+m4tsU2ieCtdbNmPaZ2X6Qn4ni9OJgC9IMrcxdSftAO6nxqSTHJ9Mx0MH3j32ftoE2IHKM1ljGGKeJdG/NXk61neJ9a99HZVblpPtc6boy6bbZSuFujGHXrl2zcuyJ5KXkOa87Bjrm7LwiItNxtu2sE3wZY3iw6kEFXyIiC9CC+8tsjIk1xiQCMUCMMSbRGDNR88v3gAeMMfcaY5IIZk7cb4MJOACeBP7aGJNrjFkC/DuCWRNvCcYY8lPzneQXuSm5fGrHp1ies3xcudT4VIrSiqjKq+Ldq9/Nf7jjP0SU6xrs4tuHvs3RpqOTnq+6q9p5HR5wpcSlkJ6QHq3LmlfhAdhoICsishB4/B5+cf4XzvK2km1Rn39RRESiYyG2gP01kWOyPgY8BTxsjOkHHrDWvmqtPWuMeRT4JlAIvAZ8NGy/LxFMT3+Zq/OAfWcuLmChSopL4uEtD1PXU0eMiSEtIY3U+NQJMyM+vOVhDjUe4qWLLzHkHSJgA/zo1I94vfZ1EmMTnZ+EuAQAzrafdfZ9x6p38JPTP6F7qJuNRRsXVIvijchOzibWFYsv4KNvpI8h7xBJcUkzOoY/4J/VTJQicmv6w5U/0D3UDQS/+Lpv+X3zXCMREZnMggvArLVfBL44ybbUMcv/F/i/k5T1AI+HfiTEGMOSzCXTKre9dDsrc1fy3SPfdbosNvc1T7lfQmwCFVkVfG7X5+gY7KAkvSQq9V4IXMZFbnKu8160D7RTnjm9ucestTx78lnOtJ3h/pX3c1v5bePKnGk7Q31PPWvy1uibaxGZUt9IH2fbzrIidwW+gI/Xal5ztt238r5ZmfpDRESiY8EFYLKwZCRm8Nj2x/jhyR9yoePClGWNMdxVeRcu4yIxLpHSjKmmcVuc8lLznACsbaBt2gFYa38rJ1pOAPDKlVfGBWDV3dV8/9j3gWCyj5W5K3lw9YNkJWWNO5aI3HpGfCNc6rxEWUYZ6Ynp/OD4D6hz1xEfE09Ocg5+6wegPKOcrcVb57m2IiIyFQVgck2JcYn8yZY/wT3kZsAzwLBvmCHfEMO+YUZ8I/gDfvJT8ylJLyEtYaJM/zeP/JR853V7f/u092voaXBe93v6GfAMkBKfAgRbx3576bcR5S90XODrb36dR7c9Sm5K7g3WWkQWux+f+jGn206TlZTF4zsep85dBwTHfo32TDDG8OCaB2+abt8iIjcrBWAybZlJmWQmZc53NeZVeDA0k0Qc9T31EcttA21UxgezSl7pukJNdw1wNQOntZbekV6+eeibPLb9MXKSc26w5iKykFlr6R7qJi0hbdy0H8PeYc60nwGCU34cbDg44TF2l+2etayzIiISPQsuC6LIQlaQWuC8bh+YugWsd7iXU62nGPIO0dDbELFtNI29tZbfXf6ds35byTYe2fIIca7gA1jfSB+/ufSbaFVfRBaoV6pf4X+99r/48mtfpqm3KWJbjbsmYr7GQ42Hxu2fkZjBW5e/ddbrKSIiN04tYCIzkJOc48yT1j3UzaBncNxg94AN8EbdG/zm0m/w+r2UZZTR2t8aUaatP9h6drnrMrXuWgBiTAx3Vd5FVlIWH930UZ468lSwTOdlrLXqViRyk/IFfLxWG0yi0TvSy7cOfYtPbPmEkzBp7DyLPcM9zut7l91LZmImy3OWkxCbMHeVFhGR66YWMJEZiHXFRmR2PNUaObd3W38b33jzG/zy/C/x+r1AsPth+LfXEOyCaK3ld5fCWr9KtzlJN1bkrCAlLjhGbNA7eM3WNhFZvC53XmbIO+QsD/uG+c7h73Cp8xIw9UT3y3OWs7VkKxmJGbNeTxERiQ4FYCIztKlok/P6aHNwcmp/wM/vL/+e/7P//1DXU3fNY7QPtHOh44JTNtYVy12VdznbjTEsybo6XcDoGDERufmcbDk5bp3X7+Xpo09zuPGwk3l1LGMMhamFs109ERGJMgVgIjO0vnA9LhP81alz13Gi5QT/fOCf+e3l3+IL+IBgd8KdZTsnPUbPcA8vXXzJWd5Wum3cN9gVWRXO6xp3zXXV1VrL6dbTnGs/N64VTkTmTp27jn96/Z946shTDHoGnfVev9dJsAHwgfUfcP4W+AI+fnL6J5P+7uYk5ajboYjIIqQxYCIzlBqfysrclZxrPwfAD0/8MGJ7aUYp71v7PgpSC+gY6OBy12VnW5wrDm8g2DVxdFxYrCuWuyruYqzwCbOn2wLW7+nn+8e+jz/g52ObPsaV7iv835PBucrvrLiT+1feP/0LFZGo6Bvp4/vHvk+/p5+2gTaePvo0D299mITYBC51XmLENwJAVlIWGws3siRzCd85/B06BzsjjhNjYpz5vgCK0pXxUERkMVILmMh12Fy8edy6OFcc71j1Dh7f8biTLfG2JVcnXI6LiWNl7spx++0o3UF6Yvq49cXpxcTHxAPBFrPuoe5r1uv1mtepc9fR2NvIG3VvcLbtrLNtb81eXq99/doXJyJRY63lR6d+RL+n31lX11PHMyeewVobMY50feF6jDFkJWXx2PbHxnUv3Fi0MWK5OK14disvIiKzQgGYyHVYlbuK5Lir2Q8rsyr53O7PsWfJHqd74mi55TnLAbit/DYK0goijhPniuPOyjsnPIfLuCjPLHeWR7MlTuVM29WuTHU9wUAs3C/P/5ITzSeueRwRiY5Xa151kmmEu9hxkYudFyNat9fmr3VepyWk8ei2RynPCP4NyE7O5o6KOyKOoTm/REQWJ3VBFLkOcTFxfHTjRznQcIAVOSvYUrxlwjTxxhge3vIwQ94hkuOTOdESGfzsKt9FWkLapOepyKxwHt5OtpxkY+HGSdPRdwx00DHY4Sw39jQ63R3D/ejUj0iJT2FZzrJpXauIXJ86d13EPH53Vt5J/0g/R5qOAMEsqu5hNxD8MmZsQJUcn8xjOx6jtruWgtQCkuKSSE9Ip3ekF5dxUZyuFjARkcVILWAi16kyu5IPb/gwW0u2TjlHlzHGmSssvEtRfEw8t1fcPuU5VuSucF6faz834QSso8Jbv4CI4Cs3OZf8lHwA/NbP949/f9xkr+Ha+tt46shT/Prir5W8Q+Q6DHmHePbkswRsAIDyjHLeuuytrMpb5ZQ53nzceV2UXkSMK2bccVzGRWV2JcnxyRhjeM+a91CRVcG7qt5FSnzK7F+IiIhEnQIwkTmUl5LHluItJMcl886qd5Ianzpl+dKMUraXbneWf3HuFzT3NU9Y9mz72QnXQzBY/JMtf0J6QnCs2YhvhKeOPEXXYNeE5X914Vdc6LjAK9WvTJgiW0QmZ63luTPPOeM2k+KS+OCGDxLjinG6FAJO1lSAsoyyaR17Vd4qHtv+GDvKdkS30iIiMmcUgInMIWMMD617iL+656/YWrJ1Wvu8Y9U7nKQe3oCX7x757rjAqW+kj/qe+kmPUZxWTGZSJn+y5U9IjE0EghkTv7r/q3z5tS/z41M/diaO9gf8EeNS9tbsVSuYyAwcbDjI6dbTzvJ71rzHmWQ9PTHdeR2uNL10zuonIiLzSwGYyAIXHxPPhzd82Jnvp3ekl+8c+Q59I31OmfB5viaaF6gkvQSAwrRCPrbpY8S6gsM/R3wjdA52cqTpCL+99FsAGnsb8fg9zr7Nfc0RqfRFZHKt/a384vwvnOWdZTtZV7AuosxErV2lGQrARERuFQrARBaB/NR8Pr7p407g1DXYxZOHn2TIOwTAkcYjTtnbl0SOK3MZF/mp+c5yZXYlH1z/QeJccRHlXq8LprCv7q4ed/5Xa16N2rWI3MzeqHvD6VpYmFbIAysfGFcmPLspQHJc8oStYiIicnNSACaySFRmV/KRjR9x0ty39Lfw3SPfpaGngbqeOiA4UeuOsh3kpeQ5+xWkFhAXExlsrS1Yy1/d81f8hzv/g5Mm31rLc6efmzBl9qXOS1Mm7RCRoNruq9NFvGPlO8b97kHkJOsQbP2aKpGPiIjcXBSAiSwiVXlVPLTuIWe5rqeObx361tXt+VWkxqdGjCeZLFV1XEwcGYkZvGfNe5wJn9sG2rjSdcUpE54wQK1gIlMb9AzSNtAGBFueyzInTqxRmFYYEZip+6GIyK1FAZjIIrOpaBPvrHqnsxw+XmtrcTCxx9qCqxO6hk/uOpGspCzuX3H/uPUZiRkR5znVemrSrIkiQkQinOL0YueLjbFcxhXx5cZ0MyCKiMjNQQGYyCK0u3w3b1n2loh1GYkZzrxhVXlVPLrtUT657ZMR8w5NZmfZTiqyKiLWVWZVUpJRwrLs4ITNARvg9brXo3MBs6y1v5Xqrmplb5Q5Veu+2v0wPMCayH0r7qMkvYRtJdtYkbNiyrIiInJziZ3vCojI9bln6T0MeYfYV7cPgB2lO5zxYcYYlmYvnfaxjDG8d817+eobX3UmcK7MqgTgjoo7nCyIhxsOc+/Se8dNANs12MVrta/R0NNA11AXVblVvGv1uybMyDibBj2D/OrCrzjSFExK8s6qd7K7fPec1kFuXXXuOuf12EQbY5VmlPLZXZ+d7SqJiMgCpABMZJEyxvCOVe+gLKOMYd8w20q33dDxclNyeXDNg7xw5gUyEjNYX7gegOU5yylMK6SlrwVvwMuB+gPcu+zeiH2fPflsRPero81Hqeup4yMbP0JRWtEN1Ws6rLUcbznOL8/9kgHvgLN+b/VedpTuIMYVM+t1kFubP+CnobfBWR6baENERGSUAjCRRcwYw4aiDVE73pbiLazOW01ibKKTlc0Yw50Vd/LsyWcB2F+3n9srbnfGt/R7+iecBLpzsJMnDjzBO1e/k20lkcFhx0AHZ9vPkhqfSmFa4Q0FaZ2Dnfz07E8nzN7YO9LL2faz4+ZhEom2lr4WZzLzrKQs0hPT57lGIiKyUCkAE5EISXFJ49atK1jHby79hu6hbga8AxxpPMKu8l0A1HTXOOVK0kvYVb6Ln539GR6/B2/Ay3Onn6O2u5Z3rX4X8THxDHoG+fqbX49oqdpVvot3Vb1rxnXdX7efFy+86HSbhOBYuOK0Ys62n3XKKACT2TLoGeSliy9xtu2ss05JNUREZCpKwiEi1xTjiuG2Jbc5y6/VvkbABgAiJm5enrOcLcVb+MzOz5CfcnXy5yNNR3jiwBN0DHTwh+o/RARfEBxbNnq86WroaeBn537mBF/GGG4rv40/u+3PeHD1g854uOruapr7mmd2wSLTMOAZ4FuHv8WhxkMRn+mZjL8UEZFbjwIwEZmWrcVbSY5LBqB7qJvLncHEHNVdVwOw0QfP/NR8Pr3z02wu2uxsa+lv4f/s/z/sr9s/7tjegHfGKe5HW7ggONn0Z3Z8hj+q+iMSYhNIT0yPSMV/uPHwjI4tci0jvhG+ffjbtPS1OOtS4lPYWbaTTUWb5q9iIiKy4CkAE5FpSYhNiHiwPNl6kgHPAK39rUBo4tmwrlcJsQk8tO4h3rPmPcS6gr2dPX4PfusHglnilucsd8q39F99kJ2OK51XJ4y+d9m9lGSURGwPH3d2rv2cUtJLVB2oP+AEX8YY3rv2vfznu/4zD65+MGKSZRERkbEUgInItG0ovJrw40zbGSc9PUBpeum4tPPGGLaXbufxHY+TnZwdse0dK99BYWqhszwayE3HiG8kIuPc0qzxXb4qsiqcRCHdQ910DHZM+/gi1xLe9fa+5fexrWSbk7hGRERkKgrARGTaSjNKyUrKAmDIO8RvLv3G2VaRXTHpfsXpxfybnf+GjUUbiXPFcVflXZRlllGQVuCUae2bfgBW3V3tjBkrSisiOT55XJlYV2zEBLcXOi5M+/giU7HWRmT+XJO/Zh5rIyIii42yIIrItBljWF+wnr01ewEixm2NTtw8mcS4RD64/oPYddZpKQhvAZtJF8QrXVe7Hy7LXjZpuZW5KznddhqA8+3n2bNkz7TPITKZzsFOhrxDACTHJZOTnDPPNRIRkcVELWAiMiOjEzSHy0rKoiKrYlr7h3fTykvJc5a7hrrw+D3TOkZ418epMs6tzF3pvK7urmbENzKt49d01yhzokyqrqfOeV2WUaauhyIiMiMKwERkRorSiiJSzBenF/Pwloed8VYzERcTR05SsPXAWkt7f/s19+n39DvJD1zGNWXgl56Y7kzyHLAB/vcb/5tnjj/DoGdw0n3erH+Tbxz8Bl/b/7WIljaRUfXuq90PyzI155eIiMyMAjARmRFjDA+te4iqvCretvxtPL7jcXJTcq/7eOHjwKbTDfH3V37vvC7NGJ/4Y6xVeauc191D3ZxqPcVrta9NWNYX8PHylZcB8Fs/vzz/S2VPvIUNeYdo7W8dN0ddeAtYeUb5XFdLREQWOY0BE5EZK80o5eObPx6VYxWmFnK6NThO61qZEBt7GjlQf8BZ3l2++5rH31W2i5MtJ+kc7HTWXey8yH0r7htX9kTLCfpG+pzl5r5mTrWemrDbpdzcuga7+Or+rzLiGyE+Jp4lWUuozKqkLKPM+ZwaYyjNKJ3nmoqIyGKjAExE5lV+6tXujE29TVhrJxxTE7ABnj/7vNMitTxnOesLrh0YpSWk8Rd7/gL3sJsvv/ZlAjZAc18zg57BiOyJ1lper3l93P6/vfRb1hasxWXUYeBWcqTpiDNm0OP3cLHjIhc7LkaUyU/Jv2YLrIiIyFh6ohCReRWeCbG6u5rnzjyHL+AbV+61mtdo6m0CIM4Vx4OrH5x28gNjDFlJWZSmB1srrLVc6b46vstay/76/U4XyLiYOBJjEwHoGOzgVOup67s4WbTC5/maTHmmuh+KiMjMKQATkXmVk5xDVV6Vs3y48TDfPvRt+j39zrq2/jZ+d/l3zvLdS+++rtTfldlXU+WPJtjoGOjgO4e/w8/P/dzZtrVkK7ctuc1ZPtZ0bMbnksXL6/fS0HN1ou9P7/g071v7PrYUb3HmwYt1xbK5ePN8VVFERBYxdUEUkXlljOHDGz7MC2de4GjzUQBq3bV8bf/X+Njmj5GTnMOPT//YaRUrSS/hzso7r+tcy7KX8Ur1KwBc6rzEH678gT9c+QPegNcpk5Ocw92Vd+P1e3n5cjAhx8XOi/R7+kmNT72BK5XFoqGnwfm85SbnUpZZRllmGVtLtgLQO9yLy+XS50FERK6LAjARmXdxMXE8tO4h8lPz+fWlX2OtxT3s5ok3nyA/JZ/G3kYg2Orw0LqHrns8VnlmOXGuOLwBL52Dnfzm0m+cbcYYbl9yO/csvccZ11OeWU6du46ADXCy5eS0kn7I4hfe/TC81XRUemL6XFZHRERuMuqCKCILgjGGOyvv5OObPu4EQF6/1wm+AO5bcR8FqQWTHeKa4mLiJhy3U5xezGd3fpa3r3x7RFKFzUVXu5gdaz523eeVxSV8/rfKrPEBmIiIyI1QACYiC8qqvFV8esenyU7Ojlh//4r72bNkzw0ff2XuSud1XEwcD6x8gM/s/AzF6cXjyq4rWEeMiQGC3dLOtZ8bV8br99I73Is/4L/husn88wV8EeO/FICJiEi0qQuiiCw4+an5fGbHZ/jZuZ9R31PP3ZV3s610W1SOvbNsJ11DXVhruaPijnGBXrjk+GSq8qo43Racp+x7x77Hmrw1DPuG6Rvpo8/Tx5B3CIC8lDwe3fYoaQlpUamnzB1rLX7rJ9YVS213rTMmMCc5R90NRUQk6hSAiciClByfzIc2fCjqx42LCaawn677V95PQ28DPcM9WGudYGys9oF2nj76NJ/c/kniY+KjVV2ZZSO+Eb5+8Ot0DXbxwMoHONR4yNm2NHvpPNZMRERuVuqCKCIyhZzkHD6z8zOTzvnkMi5nPrLG3kaeOf4MfSN9c1lFuQHHm4/T0teCx+/hhbMvRCR8uX3J7fNcOxERuRmpBUxE5BrSEtJ4dNujXO68TL+nn7SENNIS0kiNTyUlPoWDDQf56dmfAnCh4wJfef0rvG3529hVtmvak0XL/LjQcWHC9XcvvZvclNw5ro2IiNwKFICJiExDrCuWVXmrJty2s2wn7iE3e2v2AsFubT8/93POd5znobUPaVzYAuUL+LjcdXnc+tzkXO6ouGMeaiQiIrcCBWAiIlFw/8r7qcyu5BfnfkHHYAcAFzsu8j/2/g+WZi9lVd4qlmYtpSC1QK1iC0RNdw0evweApLgklmYtxT3s5r1r30usS/89iojI7ND/MCIiUbIydyVLb1vK7y79zmkNC9gAlzovcanzEgApcSlUZFdQmVVJSXoJLX0ttPS3kBKfQnZSNlV5VSTFJc3nZdwywrsfbizayLuq3jWPtRERkVuFAjARkSiKdcVy/8r7WZazjN9d+h11PXUR2we8A5xuPc3p1omzKRamFfLZnZ8lxhUzF9W9pV3suOi8XpmzcoqSIiIi0aMATERkFizPWc7ynOX0DPdwtu0sV7qvUNNVw4B3YMr9WvpaeLPhTXaX756jmt6auoe6aRtoA4JBc2W2JlwWEZG5oQBMRGQWZSRmsKt8F7vKd2GtpW2gjStdV6juqqa1v5XclFzKMspo6W/hZMtJAF6+/DKbijapK+IsOt9+3nldmV2pudtERGTOKAATEZkjxhgKUgsoSC0Y18Ll9Xtp6Gmge6ibQe8gv7/ye96x6h3zVNOb39n2s87rqtyqeayJiIjcajQRs4jIAhAXE8d9K+5zlvfV7Zt0jiq5McPeYaq7qp3l1fmr57E2IiJyq1EAJiKyQKwvWM+y7GUAWGt59uSzdA52znOtbj4XOi/gt34AitKKyEjMmOcaiYjIrUQBmIjIAmGM4QPrP+AEBEPeIZ4++jT9nv55rtnN5Vz7Oef1mvw181gTERG5FSkAExFZQNIS0vjoxo86EwG3D7Tz5OEnGfYOz3PNbg7+gD+ia2dVnsZ/iYjI3FIAJiKywJRmlPL+de/HGANAc18zTx19ihHfyDzXbPGr6a5hyDsEBDNUFqUVzXONRETkVqMATERkAVpfuJ73rHmPs1znruMHx3+AL+ADgmnUX7zwIu4h9/xUcJEK735YlVflBLkiIiJzRWnoRUQWqG0l2xjxjfDL878E4FLnJX544odsKtrED47/AIDa7loe3/n4fFZz0bDWRqSfX52n7IciIjL3FICJiCxge5bsweP38NtLvwXgTNsZzrSdcbbX9dTR3NesrnTT0NrfSvdQNwAJsQlUZlfOc41ERORWpC6IIiIL3N2Vd3NHxR2Tbj/SeGTuKrOIhbd+rcxd6SQ6ERERmUsKwEREFjhjDPevuJ/tpdsj1o061nzMGRsmkwsf/6XuhyIiMl8UgImILALGGB5c/SB3VtxJYVohH9nwETITMwEY9A5GBBcyXu9wLw09DQC4jIuVuSvnuUYiInKrUv8LEZFFwmVc3L/yfu7nfiCYnv73V34PwLGmY6wrWDef1VvQwgPUyqxKkuKS5rE2IiJyK1MLmIjIIrWxaKPzutZdi7V2HmuzsIWP/1qVt2oeayIiIrc6BWAiIotUbnIuCbEJQLAbYu9I7zzXaGEa8Y1wpeuKs6zxXyIiMp8UgImILFLGmIj08819zfNYm4XrUuclJ0lJYWoh2cnZ81wjERG5lSkAExFZxIrTip3XTb1N81iThets29Xuh1X5VfNYExEREQVgIiKLWlG6WsCm4vV7Od9x3llW90MREZlvyoIoIrKIqQvi5Ia8Qzx99GkGvYMApCWkUZJeMs+1EhGRW51awEREFrH8lHxiXcHv0rqHuhn0DM5zjRaGYe8w3zz4TWrdtc66OyruiJjAWkREZD4oABMRWcRiXDEUpBY4y2oFg4AN8OzJZ2npb3HWPbDyAfYs2TOPtRIREQlSACYissjdrN0Q/QE/DT0NtPS14PF7pr3fby/9NmLc1/vWvo/bK26fjSqKiIjMmMaAiYgscuEB2OHGw+Sn5rMiZ8Wi7m7X2NPID0/+kM7BTiCYcn932W7+qOqPptyvc7CTvTV7neU7K+5ka8nWWa2riIjITCy4FjBjTKYx5lljTJ8xptEY89kpyn7JGNNgjOkxxuw3xuwK2xZvjHnCGOM2xrQbY/52bq5ARGRulWaUOq/bBtp46shTfP3g16l3189jra5Pz3APvzr/K5548wkn+AKw1rKvbl9ESvmJHG8+jrUWgIqsCt624m2zWl8REZGZWnABGPBVgi1zxcAfAV8yxtwztpAx5oPAp4B7gCzgX4HnzNWvfP8LsAFYDmwHPmqMeWT2qy8iMrdK0kvYVb4Ll7n6J73OXce/vPkv/OuJf6VrsGseazd9R5uO8g+v/gOv1b6G3/oBiI+JJz0h3Snz07M/Zdg7POH+1lqONR9zlneW7Yx4T0RERBaCBdUF0RiTAnwA2Gyt7QOOGWO+Dfwp8PsxxSuBV621F0P7fgf4CpALtAOPAI9ZazuADmPM/wod5ztzcjEiInPEGMO7qt7F7Utu57Xa1zhYf9AJYE62nORs21l2l+/mrsq7SIpLmufaTmzYO8wLZ18gYAPOurKMMj6w/gMkxSbxj/v+kQHPAL0jvXz94NdZlr2M0oxSStJLyEnOwRhDY2+j02qWEJtAVZ4mXRYRkYVnQQVgwErAWGvPhK07Btw3Qdl/BT5kjKkCLgGPAYeste3GmCyCLWjHxxznv409iDEmE8gcs7p0bDkRkYUuKymLd1W9i91lu/n1pV9zuvU0AL6Aj1drXuVw42Het/Z9rM5feJMRn2g5gdfvBYLX8c6qd7Iqd5Uzju2dVe/khyd+CEBrfyut/a3OvklxSZSkl3Cp85Kzbk3+GuJj4ufwCkRERKZnofXNSAV6x6xzA2kTlG0BXgXOAMPAXxJs4Ro9DkDPNI7z50D1mJ9XZ1pxEZGFIjcll49u/Cif2vEpyjPKnfWD3kG+d+x7/P7K751xUgvFocZDzus9S/ZQlVcVkURkfcF6tpdun3DfIe9QRPAFsKlo06zUU0RE5EYttBawfiB9zLoMoG+Csn8D7AKWAM3AR4AXjTGrQ8chdKzR15Md5x+BJ8esK0VBmIgscksyl/CpHZ/iVOspXrzwIu5hNxBM054Um8Su8l1TH2CONPU20djbCECsK5aNhRvHlTHG8J417+Ety95CY28jDT0NNPQ20NjTyKA3cvLp9IR0lmYvnZO6i4iIzNRCC8AuANYYs9paO5rqahNwaoKyG4BnrbWjab6eNsZ8BdhgrX3NGNMEbASapjqOtdZNsHXMsZhTN4uIhDPGsL5wPcuyl/GD4z+gursagIONBxdMABbe+rW2YC3J8cmTlk1LSKMqr8oZ32WtpXuomxp3DZc6LzHoHeSuyruUfENERBasBfU/lLV2APgR8HfGmDRjzAaC3Qq/PUHxA8D7jTGFxhiXMeajQArBIA6CrVp/bYzJNcYsAf7dJMcREbnpJccn8/HNHyfWFfzeraWvZUFkR/T4PRxvvjpcd3vJxN0MJ2OMITs5my3FW/jg+g/y8JaHqcyqjHY1RUREomZBBWAh/wawBLsVvgh80Vr7e2NMuTGm3xgzOqDhfwCHgCMEW7D+A/BBa21baPuXCLZ4XQYOAz+01ioDoojcshJiE1ies9xZPtt+dU6t3uFeuoe657xOp1tPM+wLppXPSc6hIqtizusgIiIylxZaF8TRLoEfmGB9HVeTa2CtHQH+behnouN4gMdDPyIiAqzOX8259nNAMPjZs2QP59vP88zxZ/BZHw9WPciOsh1zVp/w7odbS7aqC7iIiNz0FmILmIiIzJLw7IJ1PXVc6rzEv574V7wBL9Zafnrup5xsOTkndekY6KCmuwYAl3GxpXjLnJxXRERkPikAExG5haTGp7IkcwkQTGDxncPfweP3ONuttfzo1I+43Hl51usS3vpVlVdFWsJEM4WIiIjcXBSAiYjcYtbkrxm3LiE2gZzkHCA4cfP3jn2Ppt4mZ3tzXzMdAx1Rq4Mv4ONI0xFneVvJtqgdW0REZCFTACYicovZVrKNFbkrnIyICbEJfGTDR3hk6yOkJwSnYvT4PTx55Ek6BjrYV7ePr77xVb7y+lf46dmf4vV7b7gO59rPMeAZAILzdq3IXXHDxxQREVkMFlwSDhERmV0JsQk8vOVhIBhoxbpinXmzHt76MN84+A2GvEMMeAb49uFv0zdydQ77A/UHqHPX8dj2x0iITbjuOoxNvqF5u0RE5Fah//FERG5h8THxEcFPQWoBH9/8ceJccQD0DPcQsIGIfZr7mjnYcPC6z+kecnOp8xIQnMdra8nW6z6WiIjIYqMATEREIizJXMKHN344IjBLiktiZ9lOZ/li58XrPv7hpsNYawFYlr2MrKSs66+siIjIIqMATERExqnKq+K9a9+Ly7iIdcXygXUf4M6KO53ttd211zUWrK2/jVdrXnWWlXxDRERuNRoDJiIiE9pSvIVl2cswGNITg8k5cpNz6RjswBvwUuuuZXnO8kn37xvp41LnJQpSCyhOL8bj9wTnHAsFbrnJuazOXz0n1yIiIrJQKAATEZFJZSRmRCwvy1lGx2AwHf3lzssTBmCdg528VvMaR5qO4Av4iHPF8fjOxznYcJDW/lYA4lxxfHjjh51MjCIiIrcK/c8nIiLTtiJnBQfqDwDBcWD3c7+zram3ib01eznVesoZ4wXgDXh5/szzNPY2OuveWfVOitKK5q7iIiIiC4QCMBERmbbKrEpcxkXABmjua6ZrsIvuoW721ux1MhtOpKGnwXm9PGe5Mh+KiMgtSwGYiIhMW2JcIqUZpdS56wD48utfjmjtGrU8Zzl3VtzJwcaDnGw5GbHt/hX3Y4yZk/qKiIgsNArARERkRjYUbnACsPDgyxjDuoJ13FlxJ8XpxQCkJaRFdEncWLTR2SYiInIrUgAmIiIzsqtsFynxKRyoP0BNdw2xrli2FG/h9orbyUnOiSibn5rPjtIdHKg/QHJcMm9d9tZ5qrWIiMjCoABMRERmxBjDhsINbCjcQM9wD/Ex8STFJU1a/l1V72JN/hpyknM06bKIiNzyFICJiMh1G5umfiLGmCnnCxMREbmVuOa7AiIiIiIiIrcKBWAiIiIiIiJzRAGYiIiIiIjIHFEAJiIiIiIiMkcUgImIiIiIiMwRBWAiIiIiIiJzRAGYiIiIiIjIHFEAJiIiIiIiMkcUgImIiIiIiMwRBWAiIiIiIiJzRAGYiIiIiIjIHFEAJiIiIiIiMkcUgImIiIiIiMwRBWAiIiIiIiJzRAGYiIiIiIjIHFEAJiIiIiIiMkcUgImIiIiIiMwRBWAiIiIiIiJzRAGYiIiIiIjIHImd7wosUDEADQ0N810PERERERFZoMLihZjp7mOstbNTm0XMGHM78Op810NERERERBaFO6y1r02noAKwCRhjEoDtQDPgn+fq3CxKCQa1dwCjXxVUA5XzViMJF417MdE9lplZDL8Tt8p9Xgz3YjYsxPt7q96L2XK991j3YeEIvxcL8Xf2VlINLAeKgIPW2pHp7KQuiBMIvXnTimBleowxoy8brLU1o+tGX8v8isa9mOgey8wsht+JW+U+L4Z7MRsW4v29Ve/FbLnee6z7sHCE34uF+Dt7Kwndi8vA5ZnspyQcIiIiIiIic0QBmMynL813BcShe7Ew6D4sHLoXC4fuxcKg+7Bw6F4sHNd1LzQGTOaEMaaCUJ9lNZHfnHSPbw26zzc33d+bn+7xzUX3c3FSC5jMFTfBbwnc81sNmUVudI9vBW50n29mbnR/b3ZudI9vJm50PxcdtYCJiIiIiIjMEbWAiYiIiIiIzBEFYCIiIiIiInNEAZiIiIiIiMgcUQAmIiIiIiIyRxSAiYiIiIiIzBEFYCIiIiIiInNEAZiIiIiIiMgcUQAmIiIiIiIyRxSAiYiIiIiIzBEFYCIiIiIiInNEAZiIiIiIiMgcUQAmIiIiIiIyRxSAiYiIiIiIzBEFYCIiIiIiInNEAZiIiIiIiMgcUQAmIiIiIiIyRxSAiYiIiIiIzBEFYCIiIiIiInNEAZiIiIiIiMgcUQAmIiIiIiIyRxSAiYiIiIiIzBEFYCIiIiIiInNEAZiIiIiIiMgcUQAmIiIiIiIyRxSAiYiIiIiIzBEFYCIiIiIiInNEAZiIiIiIiMgcUQAmIiIiIiIyRxSAiYiIiIiIzBEFYCIiIiIiInNEAZiIiIiIiMgcUQAmIiIiIiIyRxSAiYiIiIiIzBEFYCIiIiIiInNEAZiIiIiIiMgcUQAmIiIiIiIyRxSAiYiIiIiIzBEFYCIiIiIiInNEAZiIiIiIiMgcUQAmIiIiIiIyRxSAiYiIiIiIzBEFYCIiIiIiInNEAZiIiIiIiMgcUQAmIiIiIiIyRxSAiYiIiIiIzBEFYCIiIiIiInNEAZiIiIiIiMgcUQAmIiIiIiIyRxSAiYiIiIiIzBEFYCIiIiIiInNEAZiIiIiIiMgcUQAmIiIiIiIyRxSAiYiIiIiIzBEFYCIiIiIiInNEAZiIiIiIiMgcUQAmIiIiIiIyRxSAiYiIiIiIzBEFYCIiIiIiInNEAZiIiIiIiMgcUQAmIiIiIiIyRxSAiYiIiIiIzBEFYCIiIiIiInNEAZiIiIiIiMgcUQAmIiIiIiIyRxSAiYiIiIiIzBEFYCIiIiIiInNEAZiIiIiIiMgcUQAmIiIiIiIyRxSAiYiIiIiIzBEFYCIiIiIiInNEAZiIiIiIiMgcUQAmIiIiIiIyRxSAiYiIiIiIzBEFYCIiIiIiInNEAZiIiIiIiMgcUQAmIiIiIiIyRxSAiYiIiIiIzBEFYCIiYxhjnjTGPHmDx/iCMeZXUaqSXIMx5m5jjL3BY5QbY/qNMeWh5YeNMTVh2//FGPMvN1jVBckYU2OMeTjKx4x4/2aLMeYPxpgvzvZ5pjh/hTHGGmMq5qsOC7EuIjI5BWAiMm+MMRuMMc8aY1pCD75XjDHfNcasm++6zcRED4DW2v9mrX1gnqo0qdl40F6MJgoOrLV11tpUa23dRPtYaz9trf102DEW5HtpjPmiMeYP812Pa5mrAE1EZKFRACYi88IYczdwAGgEdgJpwDbgdeDd81axRcoYEz+H53IZY2Lm6nwicm1z+TdARG6MAjARmS9PAM9aa//CWltrg7qstU9Ya/8rTNwVcGxrU6i7zeeNMW8aYwaMMftDXck+b4ypM8Z0GWP+n7Dy47qqXeubeGPM3xljLoVa6WpDy67Qtn8B7gC+ENreElrvtEIYYz5rjDk35phpofL3hpYzjTFfCx2/0xjzS2PM0inq9HCoBebPjTF1QF1ofZUx5ufGmFZjTKMx5p+NMSmhbb8CyoF/CZ37zYne09A6p3UnrFvTo8aYU8AgsDpU5q+MMb8yxvQZYy4aY94ddoyNxphXjDFuY0y3MeawMWbVBNcSY4xpMsZ8ZMz6Lxlj9oYtP2aMOWuM6TXGHDXGvGuK9+duY8wbofvfaYz5mTGmMrTtDuBfgNEuh/3GmPdcq/tW+OdxovfSGPP20LUmh+3jmqqlLPQ5ecUY89+MMW2h+v5l6DP829D7esQYszZsnw+E1vWE7vP3jTG5oW1/DHwBuCPs2jaHtu0xxvw+9H50GWN+PaY6JZPdy9D+7zDGHAjdy4vGmM+P2X6/MeZk6JwvA0umuD8T3oPQttuNMftC7+UlY8x/MtcO+LONMc+H1f2Px5xvZ+hz3mmu/g7Hhm23Jvh7ui9UlxPGmNvGHOMRY8zx0PvebIz5+zF1uD20X1/oOFVh+z5pjPmBMeYboetqNsZ8zAR7ARwI7fOKMaYkbJ9/Y4w5HdrWaIz5P2M+W08aY54JHbMD+P4E73OxMeaQMeaJ8OsVkXlmrdWPfvSjnzn9AVYAFnjrNco9CTw5Zt0fgC+GLVvgTaAMSAZeBi4Afw/EA5sBD3BXqPzdwT99Ecd8GKiZ7LzAx4BSwADbgQ7gscnqFFr3ReAPodeZwBCwJ2z7J4HLoWMa4PfA00A2kAD8P8AZIG6S9+ZhwAf8M5ASuvZcoB34fOgYucBvgG+E7VcDPDzVezq2HFARep/3ht6H2NB7WxP62UzwC72/BHqA1NB+rwP/JVQ+FtgEFExyPf8d+E3YsguoBT4RWv4g0E0w2I0F3guMANsmuq/AHmAXEBd6T58HXp/sno+5zoppfi4i3svQfbw8Zt0DoXonTXLdXwS8wKdD1/UAEAB+B6wJ1f8Z4Pdh+7wdWA/EhO7HG8D3J/rsha1bBwwDjwNJofv3tjHXMtW9vCd0HfeGtq8D6oE/Dm2vDN2PR0PXsQtoG/seT/V7F1q3hGCA/+nQtW8g+OXCv5viOH8I7fNHoXP/UaguO0PbVwF9wAdC25cAx4C/GvN35AiwLFTmfwOXw7Y/DrSGrj8GyABuH/O5eQkoABKBnwC/G/PZGQYeDO3/aWAA+BlX/3a9AnwnbJ/3AcsJfq6qgIvAfx1zTC/wiVCdk8PqUhG6l3XA/2emf6P1ox/9zO6PWsBEZD7kh/5tjNLxvmKtrbfWDgI/AkqAv7HWeqy1R4FTBLs3Xhdr7festQ026CDBb5rfOoP93cCPCT6cjnoU+La11hJ8UNoNPG6DrYAjwF8RbGHZOcWhAwQfTAdC1/4J4Jy19v9nrR2x1nYAfw18YhotCNPxpdD74LPWekLrvm6tPWqtDQBfA9IJPvBCMPAtB5aE9jlmrW2d5NjfBu4Na316G8GH3B+Flh8lGEi+GjrWcwQfXj850cGsta9ba/dba73W2i7gS8Du8BaEaAvdyyeAT4Wt/hTwXWvt0BS7XrHW/kvoun5FMMD/rbX2jLXWSzAAcz6/1toXrbUnrbV+a20D8D+49ufxM8CLNtjCPBT63fjNmDJT3cu/AL5qrX3ZWhuw1p4Cvgo8Etr+UeCYtfZboevYD3znGnWayEeBU6H3w2utPRG6vk9dY7+fWWt/ETr3LwgG3H8a2vZvgOettf83tL2WYMD/yJhj/IO19rK11kfwPi41xuSEtn0e+O+h6/dba3usta+N2f9L1tpWa+0wwc/zjjHbX7HW/tRa6we+SzBg+kHY364fE3mff2KtvRT6u3OO4JctY+/zfmvtd0PXNRi2/t3Ai8DnrbX/cI33TkTmmAIwEZkPbaF/S6YsNX3NYa8HgfbQQ074urTrPbgx5jPGmGOhrldugt+G519jt7G+CXzQGJNqjFlDsCVt9AF1BcEWiaZQ9yQ30Enwm/KyKY7ZEnrYG7UC2Dl6jNBxfk3wG/HCGdZ3ItUTrGsafWGt7Q+9HH2vHw6d+2VjTL0x5ism1B1yLGvtReBVrj4UPwo8E/ZQWQZcGbPbJYIB3jjGmE0m2I2zyRjTS7B1wQB5U1xfNHwb2GKMWWuMKQTeSfBhfirNY5YHGf+ZTh1dMMbcE+pO1xq6tqe59uexAjh/jTJT3csVwL8f89n6a6AotL2U8Z+PiT4v1zKj+zzFuaq5+ruzAvjAmLp/g/G/E01hr8defwUzeP9C+6eO2e7c07DP9dj77PydMsa83wS7VHcYY3qA/8r4+zzZe/yfCP4+vXCNOovIPFAAJiJzLvSwfQH442sU7SPYvS5c8Q2evg9gTCAw6TFD40D+keA34HnW2kyCD9QmrFhgGud9heDD1ocIfjP/orV29IGthWAXxVxrbWbYT5K19pkpjjn2vC0Eu56FHyPDWptorW2cZB8Y8z6HxopM9EA/net02ODYvsestUsIdmG7D/gPU+zyLeBhY0wewW/wvxW2rZ5gN7dwywiNfZvAswS7cK6x1qYDd4XWj963GV3LJMYdI9Tq+COCLTZ/SrCF4kwUzgU4iRZ+RrCFZ2no2j5+rXoR7F648gZO3QL8/ZjPVpq1dnRsWgPBICXc2OWxJqrnTO/zZOeqCNUJgnX/7pi6p1trxwZIU6nhxt6/GTHGlAI/BP4BKLHWZhBsFTdjik72OX6Q4Pv4PWNM3KxVVESuiwIwEZkvjwMfMsb8TxNMOGBMMBHFo8aYL4TKHALeYoxZaYyJM8b8OeMfzmbqAsGA43ETTJCwiam7N2UAfoJjq/yh5AFjA8cWrvFwFuqe9m2C1/1xgi1io14DzgL/bIzJBzDGZBljHpphl7nvANuMMZ82xiSH3tMyE0puEFbXsYkwDgHvMcYUGWOSCI4/u+GHNhNMFFJqjDFAL8Exa/4pdvkRwff7O8BZa+2hsG3fBh4zwUQSMSaYIOLB0PqJZITO2WuMKQD+dsz2FiDPGJM14wuLPMa4pCIEu+99HHiMa7d+zVQ8wTFGbmvtgAkmavlPE9RriTEmYUydHjDBRCaJxph4Y8y0u9EC/wT8mTHmXmNMbOhnnTHmztD2Z4DNJpioItYYs4NgC+hUJroHzwDrjTGfCv3OryMYtH9zwiNc9S5jzAOhz8YDBMcIjrYw/zPB1ueHQtcdY4xZbox5+/Qvn38C/rMx5q7Q/hnGmNtnsP9MpRF8Ruuw1o4YYzYQ7Eo5Xe0Ev/QoAZ4P/V6LyAKhAExE5oW19g8Exz0tIRgA9AFHCSZZeD5U7PvA/wX2E/xmPJNgYocbOW8f8CcEH2Z6CY4F+foUu7xEsCXmdaCLYEvY2Gxj/wtYF+re1MDkngK2EOyW9/OwOvkJjnkaBg4YY/qA4wQfIqc9ubANzl91G3A/wWQQ7lD914cV+1vg/aHulPtC675CMCnB+dDPJaIzPu8egglS+glezxvA/5yi/kPADwgmUfjWmG0/JJjd71sEk0F8CfiQtfbNSQ73KMHkKX3AbwkmRQj3MvAL4FLovj04oysLmui9xFr7OsHWl3SujmGLilDXwMeBvzXG9BP8LI79PP6Q4D1sDl3bptCYrbcRDAybQz9/OYPzPk/w9+bvCHYhbiMYFOWGtl8h+Hn99wQ/d/8PwaBvKuPugbW2hmCSkUcIjoV7geDv51eucaxvEXxf3AQTaDxmrX0jVLeDBH8nHif4ue4keF8mzdI4lrX26wS7XH41dI5zoWPOCmvt2dD5fhjqZvoPBMeNzeQYvQTfSz/wkjEmI+oVFZHrYoJfyoqIiEi0GGNeIJhF79/Nd11ERGRh0ZwQIiIiUWSM2U6w5WH1fNdFREQWHgVgIiIiUWKMeYPg/F3/MdQtT0REJIK6IIqIiIiIiMwRtYBNIJQ5ajvBQcpTZewSEREREZFbVwzBOREPWmtHprODArCJbSc4gaGIiIiIiMi13EFwWplrUgA2sWaAV199ldLS0vmui4iIiIiILEANDQ3ccccdEIofpkMB2MT8AKWlpVRUVMxzVUREREREZIGb9rAlTcQsIiIiIiIyRxSAiYiIiIiIzBEFYCIiIiIiInNkQQVgxpjPGWMOG2M8xpgnpyj3R8aY14wxbmNMizHm28aYzLDtXzTGeI0x/WE/K+fiGkRERERERCazoAIwoAn4O+Bb1yiXAfw9UAxUAfnAP44p82NrbWrYz4VoV1ZERERERGQmFlQWRGvtTwCMMduASfO/W2t/ELY4aIz5OvC/Zrl6IiIiIjedEy0neKPuDXaW7WRT0ab5ro7ITW9BBWA34E7g9Jh1Dxhjugjm5P+atfarE+0Y6rqYOWa1Jv8SERGRm17ABnj+zPOM+EZo6WthXcE6Yl03y+OhyMK06H/DjDH3Ap8E9oStfhb4OtAK7AR+bIzpsdY+PcEh/hz4m9mup4iIiMhC0zXYxYhvBACP34N7yE1uSu4810rk5rbQxoDNiDFmJ/BD4IPWWqcFzFp7xlrbZK31W2v3Af8EvH+Sw/wjUDnm545ZrbiIiIjIAtA20Bax3DnYOU81Ebl1LNoWMGPMZuBnwGPW2l9fo7iddIO1bsA95tg3Wj0RERGRBa+tPzIA6xrqmqeaiNw6FlQLmDEm1hiTCMQAMcaYRGNM3ATl1gEvAp+31j4/wfZ3G2OyTNAO4PPAc7NcfREREZFFpX2gPWK5a1ABmMhsW1ABGPDXwBDwn4CPhV5/AyA0l9do18B/D+QB3wyf6yvsOB8GLgF9wHeB/9da++TcXIKIiIjI4jAuAFMLmMisW1BdEK21XwS+OMm21LDXjwCPTHGcj0S7biIiIiILkbWW7qFu0hLSiIsZ13Foyv3GjgFTC5jI7FtQAZiIiIiITF/PcA/Pn3meCx0XyErK4rM7P0tyfPK09nUPu/H6vRHruoa6sNZqPLzILFpoXRBFRERE5BqstbxZ/yb/tO+fuNBxAYDuoW721++f9jHGJuAA8AV89I70Rq2eIjKeAjARERGRRaRjoINvHfoWL5x9wZnDa9S+un3j1k1m7PivUeqGKDK71AVRREREZBEI2AD7avfx20u/xRu42nUwNzkXb8BLz3APQ94hfn3p1xSlFbEkcwl5KXmTHi98/JcxBmuDs/Z0DnZSmV05excicotTACYiIiKywLX2t/KT0z+hoafBWecyLm6vuJ17l97L0aajvHD2BQD21wW7ISbHJfNne/6M1PjUccfzBXw09TY5y2XpZdT11AHQOaTJmEVmkwIwERERkQXscudlnjryFH7rd9YVphXy0NqHKE4vBmBLyRZevvIyfSN9TplB7yDHm4+zZ8meq+s8g7zZ8CZv1L1Bv+fqDD6r8lY5AZi6IIrMLgVgIiIiIgvYry/92gm+Yl2x3L30bu6suJMYV4xTJtYVywfWfYCfn/s53oCX7qFuAI40HWHPkj10Dnayr24fhxsPj8t8WJpRGtHlsHNQLWAis0kBmIiIiMgC1dbf5nQ7jHXF8tldn6UgtWDCsstylvFne/6MEd8I//0P/x1vwEtLXwtPH32a8x3nnTFeo9IT0tldvpudZTvx+D3O+s7BTnwBH7EuPSbOtXPt5+ge6mZH6Y6IAFtuLvrNEhEREVmgjjYddV6vyls1afAVLiE2gTUFazjefBwIPtSHK0wr5PYlt7O+cL0TZMXHxJOZmIl72I3H7+FU6yk2FW2K3oXINVV3V/P00acBaOxp5P3r3z/PNQpq6WvhaNNRVuSuYHnO8vmuzk1BaehFREREFqCADXCs+ZizvKV4y7T33Vy0edy68sxyHtn6CJ/b9Tk2F2+OaOEyxrC9dLuz/EbdG9dXabluRxqPOK+PNh+lurt6HmsTnGvuUMMhvnbga7xW+xrfO/q9iDGGcv0UgImIiIgsQJc6LzmTIqfEp7AiZ8W0912Ws4z0hHRneV3BOj657ZMsz1mOMWbCfbaVbnOCsoaehoiMizK7/AE/Z9vPRqz7+dmfE7CBeamPx+/hJ6d/wnNnnsMX8AHgDXidSb/lxigAExEREVkAvH4vv7/ye16vfZ3e4V5+df5XzrZNRZtmNCbIZVw8tO4hyjLKuKvyLj604UPX3D81PpX1Beud5dF09jL7rnRdYcg7FLGupb+FQw2HonqeEd8Ilzsvs79uP/Xu+gnLdAx08MSbT3Ck6ci4bQrAokNjwEREREQWgB+f/jEnW04C8OKFF53Wj1hXLDtKd8z4eMtzls94zM7u8t0cbQ6OOzvVeooH1zxIfEz8jM8tM3O67bTzOjU+1Zki4ETLCXaUzfzeT+Rky0meO/McI74RIPi5+tzuz0VM1n269TQ/Pv1jpwzAitwVXOy4CARbZQM2gMuoDedG6N0TERERmWcnWk44wRcQ0fXsvWvfS25K7pzUoySjhPyUfCDY5exK15U5Oe/N6mDDQZ45/gyNPY0TbrfW0tLXwpnWM866d61+l/O61l0bEQyNGvAM0DPcMy6z5WTq3HX86NSPIo7lC/g43Xo18DvceJgfHP9BRID2njXv4U82/wkZiRkADPuGqXXXTuucMjm1gImIiIjMo76RPn529mfOsjHGebC+s+LOOc9GWJVXRdtAGwDn289TlVc1p+e/WbT2t/L8mecBuNh5kce2P0ZhaiFtA21Ud1VzpfsKNV01DHgHnH3SEtJYm7+WorQimvuaCdgAV7qusDp/NRAMzF+pfoU/XPkDvoAvWL5gLfctv4+E2IQJ6+EecvO9Y99zxnKFu9x1mbuX3o21lt9e+q2zPispi49s+AglGSUArMxdycGGg0CwG2JlVuW4Y8n0KQATERERmSfWWp4/8zyD3kEAMhMzeWTrI5xqPUVKfApbS7bOeZ1W5q1kb81eIJjC/kH74KSJO2RyZ9qutmqN+Eb49qFvY4xhwDMw6T5birdgjGFFzgqa+5qBYPC2On81bf1t/Pj0jyOSo/SN9LG/bj8DngE+tP5D4+7TiG+E7x37nnPO5LhkPrb5Y3z9za8DwZYxj99Dc1+zk/AlOS6Zz+78LMnxyc5xVuWuigjA7l9x/428Nbc8BWAiIiIi8+Rw0+GIeboeWvcQuSm53L307nmr05LMJSTFJTHkHaJ3pJfmvmaK04vx+D009jRS666l39PP9tLt05qX7FZ1vv18xPJokD1WSlwKFdkVrMxd6bR2rshd4QTBFzou8Hrt6/z64q8jWrFcxuV0VT3ZcpLl2cvZVrrN2W6t5cenf+wEci7j4qObPsqSzCUUpBbQ2t+KL+CjprvGGeMFsCZ/TUTwBbA0eykxJga/9dPS10LvcC/pienI9VlQAZgx5nPAI8B64AfW2ocnKfdHwH8G1gHDwC+Bf2etdYeV+Xvg0wSv8Rng89Za72zWX0RERGS6uoe6+eX5XzrLu8t3szR76TzWKMhlXKzIWcGJlhMA/Ozcz/AH/E6XuFGHGg7xztXvZGvxVrWQjdE30kdD78Rp/JPjkqnMqqQyu5Kl2UvJT8kf9/6VZ5YTHxOPx+8Z9zmJdcXylmVv4bYlt/Hzcz93WqZ+fu7nVGRVOOMFX77ycsQYr3evfrfTdXBZ9jJa+1uBYGKN8CQg6wrWjatzQmwC5ZnlztxkV7qvaKLuG7CgAjCgCfg74H4gaYpyGcDfA3uBeOB7wD8CDwMYYz4JfBjYBvQDPwP+Gvib2am2iIiIyPRZa3nu9NWMdDnJOdy34r55rtVVVXlVTgBW566bsIw34OW508/RN9LHPUvvmcvqLXgXOi444/gqsip4cPWDNPQ0UJxeTGFq4TUD1lhXLEuzl0a0jgIUpRXx/nXvpzCtEIB3rHoHde46Wvtb8Qa8/O7y7/jQhg9xouUEL19+2dnvtvLbIlrHluUsY1/dPgBer33dWZ8clzzplwDLcpZdDcC6FIDdiAWVBdFa+xNr7fNA5zXK/cBa+6K1djDU6vV1YE9YkUeAL1tra6y1HcDfAn86S9UWERERmZH99fu53HUZCCbdeP+69y+odO8rclYQFxM3bn1+Sj7bSrZFdD185cor9I30zWX1FqwR3wjVXdVO8ArBYLYgtYCtJVspSiuadmvhqtxVzmuXcXHvsnv59M5PO8EXQHxMPO9b+z5n+WTrSQ43HuYnp37irFuRu4IHVj0QcezKrMoJU8mvzl896Xxx4YHZla4r087AKOMttBaw63UncDpseR1wPGz5GFBqjMmw1vaE72iMyQQyxxyvNPpVFBERkVvVkHcIv/WTGp9K12AXL114ydl2Z8WdlGeWz2PtxkuOT+ajGz/KieYTZCRlUJ5RTnlmOUlxwQ5KHr+Hbxz8Bk29TXgDXl6reW3cQ/6txhfw8cSbTzhd+0aFB1IzsaVkCw29DQx6Brln6T1ORsKxSjNKWZm70ml1+8npq8FXbnIuH1r/oXHB1miXwprumoj14RNxjztPemlEt8juoW6yk7Ov69pudYs+ADPG3At8ksgWsFQgPNByh/5NG7Me4M9R10QRERGZJR0DHXx1/1fxBXw8uvVRLnZexBsIDksvTCvk3mX3znMNJ7YydyUrc1dOuC0+Jp57l97L9459D4ADDQe4s/JOUuJT5rKKC0pDT8O44CsnOSdiouOZiHXFRrRuTeWepfdwoeNCxLqU+BQ+vvnjTtA81ttXvJ3nzz5P/0g/cTFxrM5bPeXE3TGuGCqyKpzzXOm6MqMA7LWa1zjZepJ7l97LqrzrC0pvFlENwIwxKwC3tbbdGJMM/CXgB/6ntXb8LHI3fr6dwA+BD1prw1vA+oHw1CwZoX8nah//R+DJMetKgVejU0sRERG5lZ1sPYnXHwy43mx4MyIN+V2VdxHrWpzfh1flVVGYVkhLXwtev5d9dft42/K3zXe1oqqpt4mTLSdZV7Bu0haoUeHp4QHKMsq4b8V9c5KgpDyznOU5y7nUeQkIzif2p1v/dMoJvMsyy/i3u//tjM6zLHuZE4Bd7rocMa5sKt1D3bx48UWstbxw9gX+Mvcvb+nELdEeA/YDoCj0+u+BDwDvB74c5fNgjNlMMLnGY9baX4/ZfArYGLa8CWgY2/0QwFrrDo0Vc36AidPWiIiIiMxQ12CX87rOXUdjb6OzXJZRNh9VigpjDHdV3uUsn2k9M0Xpxed8+3m+/ubX2Vuzl+8e/e6EExmHq+u5mqzk3avfzad3fnpOs1q+q+pdFKYWUp5Rzie3fZL81PyonyP8ei52XqS6q3pa+4WPGesZ7qFzcMp0Dze9aAdgywgGPwAPAQ8C9wHvmc7OxphYY0wiEAPEGGMSjTHjRoAaY9YBLxJMLf/8BId6EvgLY8wSY0wu8P8Fvj2zSxERERG5cd1D3c5r97CbYd8wEOwilpmYOU+1io5Vuaucloz2wXanpW+xO9N2hu8d+57TVbTf0099T/2U+4S3gJVmzH06gdyUXP7tbf+Wx3c+PmXL140oSisiNT4VCI5r/Oahb/Lri2PbQcYbO9ZsNJvirSraAZgBrDFmKWCttVestW1Edgecyl8DQ8B/Aj4Wev0NAGNMvzHmjlC5fw/kAd8Mre83xvSHHeebwP8FDgOXgZMEW+RERERE5lR4ABauJL1k0XfDSohNIDspOA7IWkv7QPs81+jGBWyAF868EDHnGTBla0/vcC89w8GOVnGuuIhMhTcTYwwPrXuIhNgEZ90r1a+M63451tiAa2xANh0XOi7wRt0bzvu8mEW70/Fx4K+AcuDXAMaYEqB3Ojtba78IfHGSbalhrx8hmGp+suPYUD3+anrVFhEREYk+X8BHz8jED4yLufthuMLUQqdLWXNfM8XpxfNco/H8AT+n205TlFZ0zaQYzb3N9Hv6x62/0nVl0oQp4a1jJRklE6Z4v1mszF3Jn9/25zx78lknsHr58st8YssngGDSmZMtJznRcoKOwQ42FW0a9yVEdXc11tppfwFxvv083z36XQB+df5XbCrexJ0Vd85aS99si3YA9nngnwEP8CehdW8FfhPl84iIiIgseO4h96TzJZWkT53UYbEoTCvkdFswF1pLX8s812a8gA3w3aPf5VLnJZLikviLPX8xZbbGi50XndfLspc587XV99Tj9XsnnB8tvAXoZgmsp5KemM6Dqx/k//fG/w9rLec7zvPShZe43HU5YowjwJGmI+P27xnumXYa+4AN8OKFF51lv/VzuPEwZ9vO8h/v+o+LMolNVMNza+0Ja+3t1tp7rbX1oXVPWWsfjuZ5RERERBaDybofAtfMqrdYhHe3G5uGfSF4pfoVJzvgkHfomt3fRgMugM3Fm50WM1/AR527bsJ9wlvA5mP813zIT82PmDdsb83eccHXVK50X5nWmMEjjUdoG2gDiGgx21W+a1EGXzAL84CF0s+vIjjnlsNauzfa5xIRERFZyCYLwLKSspxkBotdYerVAKy5r3lGXctmW3V3NS9ffjliXVt/G2sL1k5Y3uP3RARZy7KXUd9T74xtu9J9hWU5yyL26Rvpu2kyW87UPUvv4WTryYhW3hgTw8rclVTlVfGL87/A4/c420YnjAZ47vRzPHf6OZLikshIzCAjISP4b2IG+an5rMpdhd/6+e3l3zr7v2XZW6jMqmRf7T52le2auwuNsmjPA/Yg8F3GJ92wBDMbioiIiNwUAjbAz8/9nM7BTt6+8u0UpRWNKzNZAHYztZJkJWURHxOPx+9h0DtIv6eftIS0a+84yzoGOnjm2DPjkmmMtqaMBg3hwWJNd42Tbj4/JZ/0xHSWZi/lQP0BIDgOLFz3UDffPvxtJ8jISsoiIzGDW0V+aj4PrHyA12tfJzc5lw1FG1ibv9aZ/HnIN+R0H4x1xXJnxZ3jJowe8g4x5B0a1311z5I9FKYV0jcSnMY3PSGdPUv2EB8TT0VWxexf3CyKdgvY/ySYbfBr1tqBaxUWERERWaxqu2udB/OnjjzFZ3d+lvTEyO+gu4auzgG2oXADJ1pOALA6b/XcVXSWGWMoTCt0Wo6a+5rnPQDrG+njySNPMuAd/zja1t/G0aaj/OzczwgEAqQmpJKekE56YjruIbdTbnnOcgAqsyqddfU99XQPdZOVlEXHQAffPvxtJyufy7h4x6p3zO6FLUB7luxhz5I9E267rfw2qruqOd9xntsrbqciq4IVuSu42BEcZ+cyrnEB8qiDDQcjxknuLt9NfEx89C9gHkQ7ACuy1v5DlI8pIiIisuD0jlxN8tw30sczx5/h0e2PRoxLCW8B21m2k83Fm/EH/FTlVUW1LkNDQ8TFxREbG4vH46G1tZXc3FySkpImLG+tpaamhtraWhISEsjMzGTZsmXEx1/fA25h6tUA7I26N0iITaA8o3zeuiL+8vwvnfc+zhXHH2/6Y5488iQAHYMdvHjhRUZ8I0DwHk3UUjkagKXEpzjJOKy17Kvdx9aSrXzn8HecbImxrlg+vOHDrM6/eQLraIhxxfDxzR/H4/c4qesf3vIw/Z5+EmISiHXF0u/pp2e4h57hHtzDbt6oe4PuoW48fk9E+vr1hesnO82iE+0A7DVjzAZr7YkoH1dERERkQRl9gB9V11PHT8/+lPeuea8TeIQ/2GcnZY9rIYuGhoYGjh07hjGG7Oxsuru78fv9JCQksHv3btLSIlujBgcHOX78OB0dHQD09fXR0dGBMYaqqusLDMMTcVzouMCFjguszV/LB9Z/YMKsgbOp39PP6dbTzvKHNnyIFbkrSE9Ip3ekF1/AN2Ga+XAp8SkR3dxur7jdSc5xqPEQR5uPMuQdAiAuJo6PbfqYE7BJJGNMxLxhQMT4x7SENNIS0pxuuf6An5cuvhRRvjSjlKykrNmv7ByJegAGPG+MeQJoDt9grf1ulM8lIiIiMm+GfcPj1h1uPExRWhG7y3cz7B1m0DsIBFthZqNbXmtrK8eOHcNai7XWCaqSkpIYGhpi37597Ny5k8zMTKy11NXVcebMGXw+HwkJCaxdu5aBgQHOnz9PX1/fddejNH38mLbTbafpO9zHxzd9nOT45Os+9kwdazqG3/oBKM8od1ql8lPzI1otAaryqnhg5QP0jvTSO9JL30gfHr+H1XmrI4KGFTkrKEgtoLW/NTjeK3h4EmIT+MTmTyz6MUkLyaaiTfz60q8jEntsKNwwjzWKvmgHYI+F/v30mPWWYHIOERERkZtCeACWEJvgtIj98vwvKUwtjHiAz0zKjHp3vM7OTg4fPoy1lhUrVlBRUUFnZyfp6ekkJydz+PBhWltb2bdvH2vXrqW5uZn29mA2v6KiItavX09CQgK9vb03HICVZJTwlmVv4UzbGVzG5WQFrHPX8Y2D3+ATWz4xJy0Y1loONR5ylreVbnNeF6QWOOnoR63KXUVuSu41J/Q1xnB7xe38+NSPnXXJcck8vOXhm2Y6gYUiPTGd5TnLnXFiAOsK1s1jjaIvavOAGWNcwDuBldbayjE/S6N1HhEREZGFYMR/tQvi3ZV3O12oAjbAM8ef4VTrKWd7tIOP3t5eDh48iN/vZ8mSJaxatYrExERKSkpIS0sjJiaGbdu2UV5ejt/v58SJE7S3txMfH8/WrVvZunUrCQnBADE1NRVjDIODgwQCEydEmI57l93L53Z/js/u+mxEMoq2gTaeePMJmvuap9g7OmrdtU7K+ITYhIgH9/yU/HHll2ZP/xF1Q+EGcpODgVpqfCqf3P5JBV+zZEvRFud1eWb5TZdZMpoTMVvgIE6jrIiIiMjNa8R7NQBLiU/hoxs/6oxtGfAO8Er1K8728LmybtTAwAD79+/H6/U6LVkTta65XC42bNjA2rVrcblcFBYWcvfdd1NcXBxR3uVykZycjLWW/v6px0ZN154le/jQ+g85CUn6Rvr4xsFvcLnz8jX2vDHhrV8bCzdGtELmp0YGYFlJWeQk50z72LGuWB7d9igfWP8BPn/b5ylILbjxCsuE1hWuY1vJNkrSS3jnqnfOd3WiLmpdEK211hhzGShgzPgvERERkZtNeAtYYmwiGYkZfHTTR/nWwW85Y5Ag+KB/25LbonLO4eFh9u/fz8jICLm5uWzZsmXKro3GGJYuXUpFRQUu1+Tfu6elpTEwMEB/fz/p6dFJFLKhaAOpCal879j3GPGNMOIb4akjT/HQuofYWLQxKucIN+Qd4lTL1VbHbSXbIraPbQFblr1sxt1C0xPT2VS06brrKNPjMi7eu/a9812NWRPNFjCArwDPGGPuNsZUGGPKR3+ifB4RERGReRWeBXG0pWVJ5hIeXP2gs74yq5LP7PxMVBJweL1eDhw4wODgIJmZmWzfvn3KoCrctcqlpgZb7m5kHNhElmYv5VPbP0V6QjCo81s/z558lldrXo1IshANx5uP4w14AShKK6I4vThie2JcYkRXtmU5y6J6fpHpinYSjm+G/n2ZYJdEABN6HRPlc4mIiIjMm/AkHImxic7rbaXbyEzKpN/Tz7qCdRHzgl0vv9/Pm2++SW9vL6mpqezYsYPY2Og9xo2mqo9WF8RwhWmFfHrnp3nqyFO09rcC8OKFF0lPSI9qS1hE8o2SbRO2bq3NX8u+un2kJ6SzMmdl1M4tMhPRDsAqr11EREREZPGbqAVsVDTnhLLWcvjwYbq6ukhKSmLXrl1OAo1ouZEWsJaWFtra2li7di0xMRN/356RmMFj2x/je8e+R013DQDHmo9FLQBr7Gl0knzEueImPe4Dqx5gTcEa8lLySIxLnLCMyGyLagBmra2N5vFEREREFqqINPQx0Q2IwjU1NdHa2kp8fDw7d+4kKSkp6ucYDcAGBgaw1k5rbJS1litXrnDmzBkAsrOzKS0dPx/YqKS4JN675r185fWvANDY2zjtc11LeOvXuoJ1JMVN/B65jIvKLLUXyPyKagBmjPnEZNs0EbOIiIjcTEb8I/T39zM0NHTNHNCdnZ34fD4KCmaWOc9ay4ULFwBYvXq101Uw2mJjY53JmwcHB0lJSbnmPtXV1U7wBdDd3T1lAAaQk5zjzJk24Bmgb6SP9MTpJ/3o9/Tz0oWXSIpL4u0r347LuBjxjXC85bhTZmvp1mkfT2Q+RDsJx5fG/HwN+AbwxensbIz5nDHmsDHGY4x5copyRcaYnxpjmo0x1hhTMWb7F40xXmNMf9iPOvqKiIhEgc/nY2BggK6uLpqbm6mpqaGzs/O6j9fT0xMMYghm+Ttw4ADHjx+nt7f3mvv6/X4aGxsZGRm5ZtloGBoaoq2tjYAN4PF56O7uZmhwiIP7DzI4ODjhPtZaDh48yMGDBxkYGJjR+RoaGujv7yclJeWawc2NGm0Fm877bq3l8uVgSvklS5YAwQDsWowxFKUVOcujEzZP1/66/RxpOsLrta/zZv2bAJxqPeV0B81NzqUis2JGxxSZa9HughjRpmuMiQX+O3Bx4j3GaQL+DrgfmKp9PQC8GDr2vknK/Nha++FpnldERESmYK3l1KlTNDQ04PP5JiyzceNGystnlvi4qamJw4cPExsby7p167h8+bIzDqmuro6srCyKioooKioiOTk5Yt++vj6OHDlCb28vpaWlbN68+foubpp6e3udFPAbtmxgeGiYQCBAnCuOwcFB9u3bx+7du8e1HvX39+P1BrPzNTQ0sGrVqmmdLxAIOK1fK1eunHbGw+uVlpZGe3s7hw8fJicnh/Xr1ztB2VhdXV0MDw+TnJzMmjVrqKuro7e3F5/Pd83kIMVpxc44sKa+Jlbnr552HX9/5ffO6xcvvMiu8l2RyTdKJ06+IbKQzOpvsrXWB/wX4AvTLP8Ta+3zwJRfo1lrW621/0xw4mcRERGZZefOnaOmpgafz+dM3JuVlUVhYSHFxcF03ydOnKClpWXax3S73Rw7dgwItqodO3aMvr4+0tLSqKysJDY2lu7ubs6cOcPvfvc7Xn31VS5fvkxPTw9nzpxh7969TmtNW1tb1NOah+vp6eGNN95wWtrOXz7PwGCwNSs/O5/s7GyGhoZ4/fXXxyWy6OnpcV43NDRMu54dHR1Od8CSkpIoXcnkKioqyMvLc8795ptvOoHjWI2NwZarkpISYmNjycjIwFqL2+2+5nlKMq5eS1Nv03XX1xvw0tbfRp27DgiO79pcPLtBuEg0RDsL4kQygKw5OM9YDxhjughOCv01a+1XJypkjMkEMsesnt02fhERkUWkrq6OS5cuYYxhx44d5OXljWtlSE1N5cKFCxw5coS3vvWtxMfHA8FWnH379k34YD4aiJSXl5OSksK5c+dITk5m165dJCYmUlVVRXt7u5OEwu12jztOeXm5E6j09PSQmZk5G28B586dw+PxkJ+fT1dXF60drU6Xw/zsfHbu3MnBgwfp6Ohg37597Nq1i4yM4JxT4XUeHByku7ub7Ozsa55zNJgtKSmZk1adlJQUdu3ahdfrZd++ffT29nL06FE2bdrk3E8I3tOmpianbgBZWVm43W66u7vJzc2d8jzFaVfn55ppAJYan0q/52qq/L01e53Xq/NXkxo/cYudyEIS7SQc/2XMqhTgPQS7C86lZ4GvA63ATuDHxpgea+3TE5T9c+Bv5rBuIiIii4bb7ebkyZMArF+/nvz8/AnLrVy5kq6uLjo6OmhsbKSyMjgqoampacqxQYWFhaxfvx6Xy0VxcTHx8fFOF7bY2Fin+6Hf76etrY2mpiY6OzvJzMxk1apVZGRkcPLkSWpqamhra5u1AGy0pW39+vVUV1fTcq4Fay0JCQmkJqYSGxvLjh07OHz4MK2trezbt4+dO3eSnZ3ttIBlZGTQ09NDQ0PDNQMwa60TgBUWFs7KNU0mLi6O7du3s3fvXlpbW3nppZeIj48nJSWFlJQUXC4XXq+X9PR0JylIVlYW1dXV0xoHlpuSS1xMHF6/l96RXvpG+qY1UbW1NiLzJMDRpqPO620l22Z4pSLzI9otYPeMWe4Dvg98JcrnmZK19kzY4j5jzD8B7wcmCsD+EXhyzLpS4NVZqZyIiMgi4fF4OHToEIFAgIqKCifZwkSMMSxZsoSOjg7q6uqoqKgA4MqVKwBs2LBh3Pgwa23EuKaxY7zCxcTEOMHYWHl5eU4AtnJl9HNueb1ehoeHiYmJISkpicrKSl4/97pT54S4BKeO27Zt48iRIzQ3N3PgwAHuueceJwBbu3Yt+/bto6mpiXXr1k05pqu7u5uRkRGSk5NJT59+lsBoSU5OZvv27Zw9e5a+vj48Hg8ejyciwArvFpmVleXU2+124/f7ycnJmfDYLuOiKK3I6TrY1NvEqrxrj4sb8g7hC0w8/jA1PjWqc6+JzKZoJ+EYG4AtFJN2trbWugF3+DoN3hQREQmO6RoaGiIrK4u1a9des3xhYSHx8fH09vbS09ODz+ejp6eHhIQESktLx/3/Gq3/b3Nzc3G5XLjdbjweT0R3uVGBQIDOzk5ycnJmnMyivz/Y5S0lJQVjDMnJyeQV5hHbG0tKSkrEHGAul4utW7dy4MAB2tvbOXPmDH6/n6SkJHJyckhLS6Ovr4/Ozk5nvNVEwlu/5uu5JCcnh9tvvx1rLSMjIwwMDNDf38/AwAB+v98JsgGSkpJISEhgZGSEV18Nfoe9efPmSTM3FqcXzzgA6/NMPkn0hsINuMzsJikRiZaoflKNMfsnWf/aNPePNcYkAjFAjDEm0RgTN0nZRGD0L15CqKwJbXu3MSbLBO0APg88N9PrERERuVW53W6am5uJiYlh69at0wpaXC6X88B9/vx5zp07BwSTO8TExMxaXWNjY8nOzsZaS0dHx7jt1lqOHj3K/v37qampmfHxRwOw8IyApUtKKSkpISYmhoTYyEmYjTEsXx5sjRlNVjE6Hmy0BW+qZCXWWpqbm4G57344EWMMiYmJ5OTksGTJEtasWcP69esjsh0aY5xrG50o+uTJk5Om5g8fB9bc1zytevQOT54ef1PRpmkdQ2QhiPZXBZN9PTbd/KJ/DQwB/wn4WOj1NwBCc3ndEVZ2CBgdhXkutDzaN+LDwCWCXSC/C/y/1tonp1kHERGRW95o+vOKigrngXo6RrsZtrW10d3dTUxMzJRdF6NltDWpra1t3La6ujonacR0xiiNNRqAhU+CPDrvFEBibOK4fUZbu0aNjk0bDahaWlomzYY4OhlyfHz8tJJ1LBTr1q3j7W9/O295y1soKipyMltOdJ3hc4E19U0vEcdkLWB5KXkUpxdPuE1kIYpKF0RjzCdCL2OMMR8HwtvKV3GNtPKjrLVfZJJJm621qWOWJ22Pt9Z+ZDrnExERkfHcbjetra3ExsaybNmyGe2blpbGqlWr6OnpIS0tjYKCAhISEq694w3Kz8/n7NmztLe3Y611uu319vZy+vRpp9zYFPHTMVEL2Ij/agA2tgUMgi1ClZWVnDhxArjaApaenk5SUhJDQ0O43W5n7FS40TFjmZmZi2pYhDGGuLhgx6UNGzbQ1dVFZ2cnly9fdloER+Wn5uMyLgI2QPdQNyO+kQnfx3CTtYBtLNq4qN4nmR6fz4fH45lybOhiFa0xYF8K/ZsA/G3Y+gDQAvzbKJ1HREREZpHf73cCloqKiusKnmYjEca1pKWlkZiYyPDwMH19faSnp+Pz+Th8+DB+v5+SkhKampro7+8nEAjMaBzYRAHYsPdqNr6JWsAASktLOXfuHD6fzwnAjDEUFhYGMym2tEwYgI1mXJyP5BvREh8fz6ZNmzhw4ADnz58nLy/PeQ8AYl2x5KXk0drfCkBLfwtLMqduKQ1vAdtctJkadw1p8WnsKts1Oxch8+ro0aO0trayZ8+eCX9PFrOodEG01lZaayuBl0Zfh36WWWv3WGtfisZ5REREZPZYazl27BhdXV0kJibOuPVrPhljxnVDPHnyJP39/aSlpbFx40aSkpKw1jIwMDDt4wYCAQYGBjDGkJKS4qyPaAGLmThIjYmJYc+ePezZsycikB3thtjc3EwgEBi3380QgEGwVbKyspJAIMDRo0fx+/0R28O7ITb3XnscWN/I1QBsZe5K/v3t/57Hdz5OUtz0u8jK4uDz+ZzJ1UfHkt5MojoGzFr7DoBQ8ovxeWJFRERkwfD5fHR1dVFTU8Px48fZu3cvTU1NxMbGsnPnzgmzCS5ko3OUtbe3U19fT0NDg5NEJCYmxhmTNZNuiAMDA1hrSUpKikgkEj4f1VRd51JTU8fNTZadnU1iYiIDAwOcOnVq3Bip8HnDFrvVq1c7mR/Pnj0bsa0w7WqCkZb+yZOSjOobvnrf0hLT1O3wJtbV1eV8OdHR0TFhcp3FLNoTMScB/wR8AvADKcaYdwPrrLX/NZrnEhERkZnz+/1cuXKFurq6CTPUxcbGsn379kXZ+pKbm4sxhs7OTifZxvr1653AKz09ndbW1hkFYBN1P4TIJBzXGrs0lsvlYtu2bbzxxhvU1taSkpLitDZ6vV6GhoaIiYmJaHFbrGJiYti8eTOvvvoq1dXV5OfnO4FyYWpYANY3jQAsrAtiWvy1J26Wxau9vR3Amdrg/Pnz5OTk3DRBd7SzIP4DwUyEdwHe0LojgJJiiIiIzLPe3l5eeeUVzp07x+DgIC6Xi4yMDMrKyli7di233XYbb33rW8nNzZ3vql6X+Ph4MjMzsdbi9/spLS2NmIfqelrAJgvAPD6P83qyMWBTycrKYvPmzQCcPXvWSTs/2v0wLe3maeHJyMigqqoKgGPHjuHxBN+7sS1gATu+O+Yoa21EF8S0BAVgN7PRAGzjxo3Ex8fT1dXl/G7cDKIdgD0IfMRae4BgAg6stfVAyZR7iYiIyKw7ffo0AwMDpKWlsWvXLh544AHuvPNONm3axNKlS8nJyXGy2C1Wo60rqamprF+/PiKImWkAZq2lq6sLgF7Ty+u1rzPkHQKm3wVxKkVFRaxevdqZp8ztdt9U3Q/DLVu2jJycHEZGRjhx4gTWWtIS0kiNDwa2Xr+XrsGuSfcf8g7hC/iA4Ps90/fc7/dz6tSpGXdlCwQCNDc3jxu/JrNnNJFOTEwMeXl5zu/09UwhsVBFOwCLAyLC01C3xKEon0dERERmYGRkhM7OTlwuF3v27CEvL29GmQAXi6VLl7Jy5Up27twZMVEwQEpKCsYYBgYGIh6oJ5uP68qVK7S1teHBw8/qfsYvz/+SF86+AEQm4bieFrBRy5Yto7y8HL/fz5tvvukkEFmMXUCnYoxh06ZNxMbG0tzcTENDAxDZCjbVhMw32v2wvr6e6upqZ3676aqpqeHQoUNcvnx5xueU6zMaJOfk5OByuZwxlG63e/4qFWXR/st7EHh8zLpPAPujfB4RERGZQiAQ4MqVKxw4cID+/n6am5ux1pKXl7foW7mmEhsby6pVqyacO2h0XJW11ulaWFtbyy9+8Quny9OolpYWJ2lEdmU2xhVsSTvZcpK+kb7IFrBJsiBOhzGG9evXk5uby8jIiFOPmy0AA0hOTmb9+vUAnDp1Co/HFvwCKAABAABJREFUE5kJcYoALHwOsPTEmb83jY2NADPKgAlXu8LdTK0vC5nP56O+vh64Orn6zRiARTUJB/CXwF5jzAcJJuB4EdgG3Bbl84iIiMgEAoEATU1NnD9/3kmyMTIy4mTwKy4uns/qzbu0tDT6+/vp6+sjIyODxsZGrLVcvnzZeeDr6enhyJEjWGupqqqiI6EDmq4e40TLCTz+q2PA4mNvLFvkaFKO119/3ekeeTMGYAAlJSXU19fT0dFBc3MzxelXP4917roJ9/EFfBFZEmc6/mtwcNDpSjo8PIzf74/IaDkZa60TeN1M448WqtHfu/7+fmJiYpzpGtLT0zHG0N/fj8/nG9eyvRhF9QqsteeMMasJtnqdJjgJ82OhcWAiIiIyS/x+P/X19Vy+fNkJvNLS0vD5fM64IpfLRUFBwXxWc95lZGTQ3NxMd3c3xcXFzgN2R0eHk5jkzTffdJJ4LF++nMsXI7ufvVn/ptNtMT4mHpe58Q5FcXFx7NixgzfeeIOUlJSb4iFzIsYYSkpKnABs7ea1zraGngZ8AR+xrqvXfr79PD88+cOIrJPpCTMLTpuamiKWBwcHnfGAU+nv78frDeaUGx4exuPxLLqpGRYDay3V1dWcPXuWQCBAWloaW7ZscVqxY2JiSE9Pp6enh56eHnJycua5xjcuar/dxpg4oBZYaq39SrSOKyIiIpE8Hg/19fWkp6eTmZlJXV0dly9fZmQk+JCamprK8uXLKS0tpaOjg/37gyMBbvbuh9MxmuGxra2NkpISZ64hay01NTV0dnYyPDxMdnY2GzduxBhD91Bk97OOwauJHG5k/NdYycnJ3HPPPTdN9sPJFBUVcfLkSTo6OognnpzkHDoHO/EGvDT0NFCRVQEEu3s+e/LZcdkRMxMzZ3S+0e6HsbGx+Hy+aQdgo61mo/r6+m6Kh/+FZGRkhGPHjjljH5csWcLatWvHtVBmZmbS09OD2+2+Ke5B1AIwa63XGOMFbu6/GiIiIvNocHDQGdc1VkZGBitWrKCwsNB5iM/Ly2PJkiXU1tZSXl4+19VdcDIzM4mLi2NwcNBJBDE6UfBoooXk5GS2b9/uJClxD7snPd71ZkCczM2YGGWsuLg48vLyaG1tpbm5mYqsCjoHOwGo7q6mIquCo01H+fHpHzstjXGuuGDrWXoJm4s3T/tcPT099Pb2EhcXR1FREXV1ddMeBzbaOhoTE4Pf76e3t/emePhfKLq6ujh06BAjIyPEx8ezYcMGioqKJiybmZlJbW3tTTMOLNrt218G/qcx5i+std5rlhYRkUVnZGSEU6dOMTg4SGJiImlpaeTm5pKVlTWtcRVy/fr7+3njjTcYHh4mNTUVYwx9fX1kZ2ezYsUK8vLyJmw9Wb9+PcuWLbspJva9UcYY8vLyaGpqoq4uOOZo+fLlzpi5uLg4du7cGdHVzD3knvR40Q7AbhXFxcW0trbS1NREZUUlhxsPA1DTXcOB+gP89OxPnbJ5KXn86dY/va7kG6NBdWlpKUlJSQATTkA+kdEWsKKiIhoaGjQOLIq8Xi+HDx9mZGSEnJwcNm/e7NyfidxsiTiiHYD9OVAKfNIY00JoLjAAa+3SKJ9LRERmibUWt9vtPKCWlZWRmZlJb28vhw8fjniAaWlp4eLFi7hcLrKzs8nNzSUnJ4fMzMxb4tv8uTI8PMz+/fsZHh4mJyeH7du3ExcXh8/nIyYmZspua8YYBV9hRgOw0daV7OxsVq5cyYULF9i4cWPEpMtev5d+T7C10RjD+oL1nGg54WyPZhfEW0lBQQEul4uuri62r9nurL/SdYVLnZec5cK0Qh7Z+ogzX9hM9Pf309TUhMvlYtmyZc7D+3QCsJGREQYGBoiJiaG0tJSGhoYZTeAtUztz5gzDw8NkZWWxe/fua3a7TUtLIyYmhsHBQX7xi18AcPfddy/av2vRDsC+GOXjiYjIHBrNoFddXR3xTeNoIDYqKyuLqqoqPB4P3d3ddHR00NvbS0dHhzOHS2xsLNnZ2RQWFlJSUnLTJhWYC16vl/379zM0NERWVhY7d+50Whv1vs7c6MSuAElJSSQlJVFWVkZZWdm4sj3DPc7rzMRMPrj+g6zOX80vzv2CQe8gW4q3zEmdbzZxcXHk5ubS1tbGSO8IWUlZdA91R4z3Ksso40+2/AlJcZO3jEzl0qVLWGspLy8nKSkJjyeYuXI6Adho98OsrCxnUuze3l6stTf9GL3Z1t7eTl1dHS6Xi02bNk3r/TTGUFpaSm1trTNuczGLdhbEp6J5PBERmRsjIyPU1NRQW1vrJHKIj493xgzV19fj8XhISEigoKAgYpD0aFpzj8dDZ2cnHR0ddHZ20tfXR1tbG21tbZw5c4Y1a9awZMmS+bnARe7y5cv09fWRlpbGjh071NXzBo12nR3tvjnVA2D4+K+MxAyMMWwo3MC6gnUMe4dJjh8/35hMT2FhIW1tbbS2tlKRWRGR7KQiq4JPbP7EdXfxHB3jZ4xh+fLlAE5ryeDg4DUDqdHMiTk5OcTHx5OYmMjw8DCDg4OLttVlvng8HpqbmykrK8PlclFdXQ3AypUrI1qbr2XDhg2sW7fOWV7MgfCC+trMGPM54BFgPfADa+3Dk5QrAp4AtgOFQKW1tmZMmb8HPk3wGp8BPq9xaSIi41lr2bdvn5PUIT09ncrKSkpKSpwH/aqqKmDq//Di4+MpKipyBlEPDw/T3t5OfX09nZ2dnDx5kvT0dLKysmb5im4uPp+PmpoaIPgAojTY0VFcXMz58+cjWsMmEj7+Kyvx6mfXZVwKvm7Q6Hvf3t7Oqs2rONp8FIAVuSv46MaPEh9z/Z/1c+fOYa2lrKzMSWceGxtLfHw8Ho+HkZEREhISJvybNhowjLa6QPDv4vDwML29vQrAZujMmTPU19fj9/uprKx0xtaVlJTM+Fg3S7f2BRWAEZzm8O+A+4Gp2psDwIvAfwf2jd1ojPkk8GGCk0D3Az8D/hr4myjXV0RkUers7MTn81FQUEB7ezv9/f0kJSWxefPmCVsEruebxsTERKdb15kzZ7h8+TJHjhzhzjvvvOVToc9EfX09Xq+XrKwssrOz57s6N40VK1aQn5/vdC+bTPfw1VaZjKSpy8rMJCUlkZGRQU9PD/mufD64/oN4/V42FW+KmAtspnp6emhsbMTlcrFq1aqIbcnJyXg8HhoaGrhw4QIpKSmUlpZSWlpKQkKwta2hoYFAIEB+fr4TvKWlpdHW1kZfX9+kmfpkPGstra2tQHDqh7y8PLxeL0lJSc57eytaUAGYtfYnAMaYbQSTeUxWrhX4Z2PMZPV/BPjyaKuYMeZvga+jAExEbnFer5fTp09TX18PwO7du53xXUuWLJm1FMtVVVV0dnbidrs5e/YsGzZsmJXz3GystVy5cgWAZcuWzXNtbi7GGCez2lR6hiLHgEl0FRQU0NPTQ1tbGxvXb4zKMc+ePQtARUXFuMx6KSkpuN1up4Wst7eXM2fOcPbsWfLy8igrK6O2thYgost0enowA6MyIc5Md3e3M/auq6uL9vZ2gFv+y6QFFYBF0TrgeNjyMaDUGJNhre0JL2iMyQQyx+w/afAnIjJfrLUMDg4yMjJCVlbWjFqlhoeHuXLlCrW1tfh8Pmf9yZMnGRwcxBgzYQKCaHG5XGzevJk//OEP1NfXs2rVKufb5smMJgTJzs6+pb4pHc1A2dTURHNzM0NDQ6SkpFBYWDjfVbslhbeAKQCLvoKCAi5cuEBrayvr1q274XE97e3ttLe3Exsby4oVK8ZtH/1bYq0lLS2NVatW0dDQQGtrqzNmFYIt+OHdUxWAXZ/R1i8Av9/vfKGkACzKjDExwE6gzFr7Q2NMImCttSPRPtcUUoHwQMsd+jdtzHoIps5Xy5iILEjDw8NOZsGOjg6GhoYA2Lx5szM24Vo6Ozs5dOiQ8y1kbm4ua9eu5eDBg864r/z8fBITZzeddmpqKgUFBbS0tFBbW8vKlSunLH/hwgUuXryIMYbi4mLWr19/U3dd7O3tpaGhgaamJuc+Q7Cb1oYNGxb1gPPFLDwLYlaSxi9GW0ZGBgkJCQwNDTE0NHRDX7ZYazl37hwQnNttovGSo8c3xrBp0yYyMzMpKipiZGSEpqYmGhoacLvdLFu2LGK80ei8e4ODg/h8vkmzj1prnWREHo+HNWvW3NKZSkcDsMzMTNxut/O3TQFYFBljKoGfA+WAC/gh8A7gPcAnonmua+gHwmfrG+20PdEEDv8IPDlmXSnwatRrJSIyDT6fj9raWurr68fNOxMbG4vP5+PixYuUlJRc86G8vr6eEydOEAgEyMvLo6qqyul2tWbNGg4dOgTgZDucbZWVlbS0tFBTU+NkJuvp6aG7u5vu7m76+vpYtWoVBQUFEanvGxsbiY2NvWm7LnZ1dbFv3z5nXqrExESKi4spLi4mMzNTwdc8CdhARACWkagxYNFmjCE9PZ329nZ6e3tvKABrbm7G7XaTmJjI0qUTTz+bl5dHSkoK5eXlEV1QExISqKyspLKy0plbL5zL5SI1NZW+vj76+/sn7b567tw5Ll26Oo9ZZmbmnP19nU/Dw8NYa4mNjf3/s3ff8XFdZeL/P2dGo1HvXVazJbn33mKnJ4QQElJJAgE2kF1YYNn97ZelhqXtLmUpSwmwoSYEEjaE9OrELe62XGXJlmT1MpJGZdSmnN8fM3OtUZc9qn7er5denrn3zrlniqx57jnneTCbzZhMJrq6uujo6CAkJIT58+ezf/9+wFuCIDo6eop7PLWCHZL/GHgO+DJg823bAXw/yOcZzUlgORcTdKwAqgdOPwTQWtu5OEIGzOy0lkKIma2xsZGjR48ao1X+WlpJSUkkJSURHR3Njh076OzspK6uzkgBP5D/SrD/i8DcuXNZtGhRwP9vaWlpzJkzh56eHlJTUyf+yeFN6exP/71z5066urpwu90Bxxw/fpxFixbR29tLdHQ0K1asYNeuXdTW1gakvx8rrTVOp3NaZw8sLS1Fa01aWhrz5s0b9xRTEVw9zh7ONJ3hRP0Joy5VZGgkFvPsHYGdSv4ArKOj45Kn2no8HmP0q7CwcNj/J8LDw7nmmmtGbGu4EauYmBg6Ojpob28fNgDzr3GKioqis7PTmGUwm9XU1HDkyJGAbUopYwQxJSWFxMREzGYzbrdb/n8j+AHYeuB2rbVbKaUBtNatSqkxjdn7kmqEAGbA7Ju+6B4qfbxvn/+3y+q736u9lw9/A/x/SqmXAAfegPDxy3tqQggxsTo6Ojh8+DAul4v4+HgKCgpITk4elHZ33rx5nDhxgnPnzpGenj7oD5nL5eLo0aPU19ejlGLp0qVD1t9SSrFy5coJfU5DnXPu3LkUFRUZo3tRUVEkJCQQHx9PVVUVLS0tHD9+HMC4Su3PlNbQ0DBs0DmQ2+2mvLyciooKYx1VcnIyycnJJCUlTZtpQf56aWazmeXLl0/rQHE263P3cbrxNCfqT3Cu+Rwujytgf0rkyOnqxaXzj4ZczvqqyspKHA4HUVFREzbiFBMTQ01NzbD9dLlctLe3o5SioKCAo0ePXjEBGHhHtrTWuN1u419/Kn+z2UxCQgJNTU1X/PRDCH4A5gAi6LfOSimVDDSP8fEDU8U/APwWeEgp1QncrLX2Tw3s7ndcse/fPKAC+BWQCxwGLHjrgH1jHM9DCCEmlcPh4ODBg7hcLjIyMli1atWwVwizsrIoKSmhra2N5uZmkpKSjH3d3d0cPHiQtrY2LBYLa9asCdg/HWRlZWE2m7FYLMTFxQUEHHFxcezcuROPx4PJZDLWuc2ZM4e2tjaqq6vHHICdPHnSmMaolMLhcOBwOKioqEApRUJCAmlpaeTl5U3p1djz588D3tdFgq/Jo7Wms6+TaGs0Hu3hsQOPUd9RP+SxmTGZ3Fx48yT38MpxuQkuXC4XJSUlgDfj6kT9Po/Wz7a2NrTWxMbGGuUNZnsA5na7sdm8k962b99OWFgYWmu01rhcLpRSxtrdBQsWYLVah7wgeKUJdgD2MvBDpdQjAEopE97A5/mxPFhr/Sjw6DD7ogbcH/a3yzcK9kXfjxBCTJnW1laqqqpQSmG1Wo2fsLAwTCYTzc3N1NXV0dzsvU4VGxvLihUrRvwCYTabyc7OprS0lNra2oAA6+jRo7S1tREZGcm6deuIiooatp2popQatgBnTEwMOTk5VFRUkJGRYQQkmZmZnD59msbGRqOA6ki01tTV1QGwZs0aI9W1P0Naa2srzc3NNDc3Ex8fP2XFoXt7e6mpqTFGBsXE8WgPjj4HkaGRKBS/O/o7SmwlrJuzjpUZKwcFXxkxGSxJXcKS1CUkRkxMeQbh5U9w4XA4cLvd455mXFZWZmSHnchsof6Ruo6ODrTWg/6fttvtgPdCUmRkpJG041Ke00zR3NyM2+0mNjbWSOSklEIpNeiCUlxc3KTPupiugh2AfR74K9ACWPGOhJ0Brg/yeYQQYlrr6+vj6NGjRkrj0ZjNZtLT01m4cOGY/lCnp6dTWlpKQ0OD8UXAPyIWEhLCli1bZuxoyqJFi4iJiQkodmq1WklJSaGhoYHKysoh00v3Z7fbcTqdREZGGu34A63CwkKcTidHjx6loaGB9vb2KQvAbDabUfA1MjJySvpwJdBa8+cTf+ZE/QlWpK9gfdZ6SmzeEZODNQcD1nblJ+Zz64JbSYqcXiPHs5nZbCYyMtJYMzVacez+XC6XMYq8cOHCCR3NDgsLw2Kx0NfXR29v76DMsa2t3pIF8fHxmEwm4zk5HA5j9Gy28a9565+yX4wuqAGYL8nF1UqpVUA+UA/s1tq3glUIIaYZt9uN3W6npaWF1tZWYmJimD9/fsAf8ba2NsLCwkYcdenp6eHgwYNkZmYyd+5ciouLaWxsJCQkhNzcXMLCwujt7aW3t5eenh76+vro6+sjLi6O1NRUUlNTx5ViPSYmhvDwcLq7u7Hb7cTHx1NRUQHM/KlsZrN5yCkqc+fOpaGhgXPnzjFnzpxBBVb78we+w30psFgsJCQk0NDQMKVThPxXzKcqALxSVLRWcKL+BADH6o7R0t1i7NNas79qv3F/RfoKCb6mQExMDJ2dnbS3t48rAGtvb8flchEbGzthheT9/Bkbm5ubaW9vHzEAg8BEHLM1APP/X5ucnDzFPZlZgp2GfrvW+m2t9RHgyKgPEEKIKdDa2kptbS0tLS3GnH2/hoYGIiMjjaLE/uxOYWFhbN++fdggqaysDLvdTlubdwlsZWUlSim2bNkyIel2lVKkpaVRXl5OfX09UVFRxkLo3NzcoJ9vOkhKSiI9PZ26ujpOnz7N6tWrhz12tAAMAqcTTRX/52W4jGoiOHZf2B1wv9JeGXC/f8KNuQkyFXQqxMTEUFtbO+T6qt7eXsxm85CJcxwOB8CkTbf2B2CHDx8mPT2drKwsEhIS6OnpoaenB4vFYoxm+/s0W9eBdXV10dnZaVzQEmMX7CmIzyul6oH/BX6jtR56NasQQkwRl8vFvn37cLm8X7iUUsTGxpKQkIDZbObcuXOcPHmS+Ph43G43RUVFgHeEq7i4mKVLlw5q0+12U1VVBXivpp86dQrw1ryayFon6enplJeXU1dXh9vtxu12k5ycPC3XfQXL4sWLaWxspLa2luzs7CGvuvb19dHW1obJZBrxS4H/dZqqAExrbQRg47niL8ansbOR4qbi0Q8EEiMSpdbXFOl/QcTlchnFjP3p6aOioti+ffugKYb+AGyypvDm5ubS1tZGS0sLVVVVVFVVERERYfwO96/bN9sDsP6jX1d6WvnxCnYAlg7cC3wU+Hel1Ct4MxK+INMQhRDTQX19PS6Xi5iYGBYtWkR8fLxxVVVrTXd3NzU1NezYscN4TEpKCk1NTVy4cIG0tDSSkpIC/tjU1tYa0wnNZjPNzc1YLBYKCwsn9LkkJCQQGhqKw+GgvLwc8AZ9s1l4eDgFBQUUFxdz8uRJtm3bNihNf1NTE1rrUVPNR0REYDab6enpwel0jmsK6EBaa06cOIHH46GwsHBMxWQdDgcul4vw8PBRk4qI4Z1tOsub599kYcpCrp579aD9ey7sGXNb8xLmBbNrYhz8U/Sam5t59dVX8XgCvzZ2dnbS1tY2aLR4sgOwqKgoNm/eTGdnJ9XV1VRVVdHV1UVXVxcQOJ14qi/yTLSxzDQQQwv2GrBOvAHXr5RSi4CPAL8A3MDQKa+EEGIS+TPjDTV64q+Z1dPTQ0tLC1prUlJSWLt2LWfPnuXcuXPs27ePkJAQoqOjiYmJISYmhgsXLgDeK6PJycmcOHGCOXPmTPg6LKUUOTk5nDt3jqSkJHJyciatoPJUmjdvHtXV1XR2dlJWVkZ+fn7A/oaGBmD0LwVKKaKiomhra6Ojo+OyptD4A3TwTludO3fuiMVg4eL6Lxn9unRaa/56+q+097ZT017D3IS55MRdXD/Y0dvBsbpjxv0N2RvYV7nPuJ8Vm0VVW5VxPy9hdl/AmM78FyJ6e3tRShEfH09SUhLJycnGSFNTU9OUB2B+UVFRLFiwgPnz52Oz2aiqqqKjo8MoneE/xt/HobImBpN/Kv1kjUT1Tz8v67/GbyKrUFbgzYB4AVg1gecRQswyHo+HpqYmamtr6e7uZunSpUGZyud0OmlsbEQpNWwtKYvFwqZNm9Ba4/F4jC/QhYWF9Pb20tTURE9PD62trcaCa4DQ0FAyMjIwm82sXbv2svs6VvPnz6ewsHDQKNBsZjKZWLJkCfv27aO0tJTMzEwjIYfL5aK+3jv7fSzpqKOjo4MSgPkToERHR9PR0cG5c+doaGhgxYoVw67vkvVfl6+mvYb23otrhvZU7CFnxcUAbF/VPmN9V1ZsFu8pfA9lzWU0OhrJjs1m29xt/P7o743j8+IlAJsqSik2btyIw+EgMTExYES6r6/PCMD6Z0DVWk9ZAOanlDIKvA9ksVgICwujp6eH7u7uMY2MD1RaWkpjYyPx8fEkJCQYMx/601rzzjvvYDKZ2Lx586SkvG9paRmUfl6MXdADMKXURuBjwN1AHfBr4P3BPo8QYnbxB111dXXU19fjdDqNfe+++y4bN26ku7ubnp4esrKyLukqX319PR6Ph6SkpFGnfCmlAv6Imc1mVqxYAXgXhHd0dNDe3k57ezsOh4Ps7OwpqfPir7dypUlOTh4yIUd9fT1ut5uEhIQxfdkJxhqNrq4uGhsbMZlMbNy4ka6uLo4dO0ZHRwe7d++moKCAgoKCQUHylT4C1uPsYWfFTmKsMazPWm98jm0OGy+cfYHUyFRuKrxpxM/36cbTgfebTmNz2EiKTKLX1RuQ3XBL7hbMJjMfW/sxKlormJcwjxBTCDHWGNp728mLzyPaOnFrNsXooqOjh7zY5p/23dLSEjBduK+vD5fLhcViuawpxBMpKiqKnp4e7Hb7uAMwrTWlpaW43W5aWlqMdPvR0dEkJCSQmZlJYmIinZ2dxjTHs2fPsmjRoqA/j4Fk+uHlCXYWxDNANvB/wK1a63eC2b4QYnay2WwcOnQoIOiKiYkhIyMDm82GzWbj7bffNvY1NjayatWqcY36eDweqqurAYYd/RorfzHl/gWQxeQbKiGH/z3uPw1oJMHIhFhZWYnWmszMTOOzcdVVV1FcXExZWRklJSXGaJh/nUv/BBxX4giYR3v4w7E/UN7qXbsYYgphzZw1eLSHPxb9kfrOekptpRQkFZCfmD9sOwOTa2it2Vu5l/ctfB9Hao/Q7ewGID48nkUp3i+lUaFRLEldYjzm79b+HeUt5SxIWRDspymCxGKxEB8fT0tLCzabzajt13/0a7peiEpLS8Nms3H+/HnS09PH1c/u7m7cbjehoaHk5OTQ0tKC3W6no6ODjo4OqqurueGGG4z/S8CbkTcjI2PC/1+R9POXJ9hzVn4EZGitH5TgSwgxHLfbTWNjozFn/ezZszidTqKjo1mwYAFXX30127Zto6CggLVr1xq1XaKjo7FYLNTV1XHw4MFBi7SH09LSws6dO7HZbJhMpjFNTRPTnz8hB8DJkydpa2sz3uOxBtn9A7C6ujojlT94pzP29vaO+Pienp6ANYB+ZrOZxYsXs2nTJiIiImhra2PXrl2Ulpaitaampga3201ERMSMrtl2qV4pecUIvgDePP8mTreTg9UHqe+8mEC5rKVs2Daau5pp6PSu9+v/pfZIzRE6+zoDkm9sydmCSQ39lScxIpE1c9YQFTp7s4fOBv6RFn/hX5i69V/jkZ2djdVqxW63G2umxso/Mh8TE8OCBQvYtGkTN910E5s3byYyMhK3201bW5uRut9qtaK1pqioKKC8SrBJ+vnLF+wkHD8LZntCiJnF6XRSWlpq1EHx//TPROd0Otm3bx92u52FCxeSlZVFa2srJpOJLVu2DMpaFxISwsaNG+np6SE8PJy2tjb2799PY2Mj1dXVZGdnj9gnl8vFgQMHcDqdREZGsnTpUsk4N4vMmzePqqoqOjs72blzJ+C94jzW6Uj9MyEeOnQI8H6Zi42NZe/evXR2drJp06Yhrya73W4OHjxIX18fSUlJQx6TmJjItm3bOH36NBcuXKC4uNhIIAKM+vmdjY7XHx+UmbC9t503z7/J4ZrDAdtr2msYTv/Rr/lJ82nraaOuow6nx8kTR5+gtdu7RjPCEsHKjJVBfAZiKiQnJxu/P2azmblz586IAMxsNpOXl0dxcTGlpaXjGjHy/z/Rv7SIv7xGcnIyDoeD1tZWYwRsyZIlnDp1ivb2dmw224SNTvmD4IEZgcXYXXYAppR6UWt9i+/2DmDIkFtrfc3lnksIMb2dPXvWSIfeX1hYmBGM2e1242rdhQsXCA0NRWtNcnLysCnDlVJGkoXY2FgWLVrE0aNHKSsrG3U9WHV1NU6nk/j4eDZt2nRFJau4EphMJtasWcPp06dpaWnB4/GMqxC1P9uaf+TM4/HQ0NCA2Ww2vtQcOnSIrVu3Dgrci4qKjHUdq1atGvZzGBISwrJly0hPT6eoqMj4UrVo0SLmzp05RX+11rxx/g3s3Xauy7+O+PD40R80QENnA8+eeta4HxsWS1uP93XeVbFr0PFVbVXDZo/rH4AtTFlIiCmEp088DUBl28VCy+uy1mENkYsuM11sbCyZmZnU1NRQVlZGbW2tMYI9nQMw8I6Onz9/nubmZs6ePUthYeGYApehAjC/+Ph4KioqaG1tNf6mxsfHk5ubS3FxMeXl5RMWgPmnbPdPuS/GJxgjYP3Ly7/DMAGYEGJ26+vro7LS+6UnNzeXnp4eHA4HDoeDnp4eenp6aG5uBrx/LD0eD11dXZw9exYYW8Y6v4yMDIqLi+no6KCxsXHY1OtaayM73dy5cyX4mqViYmLYsGEDHo8Hl8s17il9q1atwuFw4HQ6OXDgAI2NjQEJVbq7uzly5AgbNmwwvjQ5HA5qamowm82sW7duTKOqycnJbNu2jbKyMuLi4mZcyYCztrO8XfY2ALXttTyy/pFxBTY9zh6eOPYEfe4+wDv17+PrPs7P9//cGK0aqNfVS5OjiZSowQv9/dMPwVu/K8Yaw2ulrxkBHXjXlm3I2jDmPorpSynFqlWrmDdvHsePH8dut9PT0wNM/wDMYrGwcOFCTpw4QUlJCc3NzaxcudK4sDic0QIw8I5G+deJhYWFkZ2dbaw7dTgcE/LajNQvMTaXHYBprb/d7/ajl9ueEGJmqqiowO12k5KSwtKlS43t/uLG/mDM5XKRlZVFZWUlxcXFxh/Q8XwZNZlMzJ07l1OnTnH+/PlhH9vc3ExHRwdhYWGy7usKYDKZLmk9lT9xhtvtxmQyYbfbcbm8qcuXLFlCaWkpNpuN06dPs3jxYsBbfBsgPT19XCUSLBYL8+fPH3cfp4ML9gvG7UZHI3859RfuW3bfmK7ka6155uQzNHd5L8JYzBbuX3E/UaFR3L7odp4sehKNJjsum6WpSznTeIYzTWcA7yjYwADM6Xbi6PNOPzMpE7FhsZiUiU3Zm3i55GXjuJUZKyWz4SwTGxvLihUr2Llzp7EOeLoHYAA5OTlERkZy9OhRmpub2blzJ8uXLx/xb9NIgY5//Whfn/eCRkxMDEoprFYrc+bMobKykvLycpYsWTLosZdLArDLF9TLwUqp2mG2Vw61XQgxO7hcLmPq4cCiuEopIiIiSE5OJjc3l/z8fKxWK9nZ2cYXt7i4uHHXEcnOzsZisdDc3GxkYxrIP/qVk5Mjo19iVGaz2chs2dnZiclkIisrizVr1qCUoqyszMiy6C/o7c/GdiWo66gLuH+q4dSgtVzDeaf8HSOgArhj8R2kRnkvnMxLnMeXrv4SX776yzy06iFWZ65mTuzFLJb9CyX79R/l8gdfAGvnrA0Ylducs3lM/RMzS3R0tJGAZzqnoB8oKSmJq666ipSUFPr6+jh48CAnT54cMqFUX18fvb29hISEDPn30T992s+fYRUgL89bz66qqgq32x3U5+Byueju7sZkMl1SXTPhFexvJMNdZpLLT0LMYmVlZfT19RmFIsfCarUaV/4uZXQqJCTECPaOHz9ujFj4+dfywJWZ6EBcmv41bZKSkggJCSEhIcG4inz8+HHq6upoa2sjJCTkikrBXNdeN2jbq6WvUt4yeN1nf+ebz/PG+TeM+5tzNrMsbVnAMQPr2WXHXfydHSoAs/fYjduxYRfrqFlDrHxw+QfJT8znjsV3kBx55bw/V5r8/HxycnJYsGDBjEoEYbVaWbduHYsXL8ZkMlFeXs7u3bsH1SL03x8pxX7/AKx/PcGYmBji4uJwuVzDXqC8VGPplxhdULIgKqW+4rtp6XfbrxC4gBBiVmpra6OkpASAhQsXjus/5KVLl5KQkEBOTs4lnXvevHnU1dVht9s5c+ZMwNRHu92Ox+MhOjp63KNr4srVPwDrP7U1JycHu91OVVUVhw97M/WlpaVNSfHtqdDR20Fnn/eLV6g5lLSoNCrbKr11u47/kU9u+GRAIOTX1dfFMyefMVJi58bncmPBjaOeLzMmE6UUWmsaOhvodfUGjGz1D8DiwuICHpufmD9i7TAxO5hMJpYtWzb6gdOQUoq5c+eSkJDA4cOHjTIVS5cuNWoYjmWaX/8Lnv1HwAAyMzOx2+3U1NQEdaReph8GR7BGwK72/YT0u301sA1QwEfH2pBS6lNKqcNKqT6l1G9GOfYupVSZUsqhlHpNKZXZb99vfG109vuRNEhCBFFfXx/Hjh1Da01eXp5Rr2usrFYrc+fOveQvsUopli9fjlKKiooKI8kHeGt/AVKjRIxLZGQkcXFxhISEBIzMKqVYunQpcXFxRjBxJU0/rG2/uMIgLTqN+5bfR2Sod92No8/BU0VP4fK46OzrpL2n3Tj2+eLnae/13o8MjeTeZfdiNo3++24NsRpTFLXWnG48HbB/4BREIWaiuLg4tm3bRmZmJi6Xi2PHjhmp9f2BzkhrTGNjYwkJCcFisQwKiDIyMlBK0dDQgNPpDFqfJQALjqCMgGmtrwZQSv1Ma/33l9lcLfB14EZg2PQwSqmFwOPA7cAe4L+AJ/EGfX7f11p//jL7I4TAW7/Lbrdjt9vp7e2lq6uLpqYmPB4PERERLFiwYEr6FRMTQ0FBASUlJRQVFbFt2zbMZjOtrd6sahKAifHasGEDLpdr0Mip2WxmzZo17N7tTf57RU0/7Lf+Kz06nZiwGO5bdh+PH34cj/ZQ2VbJz/b9jAZHAwrFQ6sewulxcrz+uPG42xfdPq6EGItSFlHf4S3K/Ob5N1matpQQk/dri73bbhw3cARMiJkkJCSElStX4nK5aGhooLW1lcjIyDEFOv46mUqpQeucw8LCSExMxGazUVdXF7Sp+GMJDMXogl2I+XKDL7TW/weglFoDzBnh0AeAl7XWb/iO/xLQqJSap7U+f7n9EOJK19XVhc1mo7W1ldbWVjo7O40r/35KKVJSUli0aNGwNbwmQ0FBAXV1dXR0dFBcXMyiRYtkBExcspEW9YeHh7N9+3aAK2b6IQQGYBnRGQDkJeRxU+FNvHT2JQDqO73Bkkazv2q/d/6Lz6qMVSxMWTiuc27O3sy+yn10Obto7W7lYPVBNmZvBGQETMwuSini4uJoaGgwanr5a22NluFxqALwfpmZmdhsNmpqaoIegMkI2OUJ+jcmpdTHgOuAFPr99zsBhZiXAAf6td+mlKrwbfcHYB9XSn0cqAD+Q2v95yH6GwfEDdg8UuAnxKxXWVnJ8ePHAwIuk8lEXFwccXFxREREYLVaSUxMnBbrq0wmEytWrGD37t2Ul5cTExNDX18fYWFho9ZZEWK8ZkrGtWAaOALmtyl7E1VtVZyoPxFwfElzCapfBLY1d+u4zxlmCWP73O1GgLejbAerMlZhDbEGrgELjxt320JMN/4kGm1tbcYsE7PZfFmBTnp6OidOnKC5uZmenp5Bf6/dbjeHDx8mOTnZyJw4Eq21MUVyJqT+n86CGoAppf4d+HvgCeA24BfA/cAfgnkenyigbcA2OxczLv4I+GffMTcAf1ZK1Wutdw54zGeBr05A/4SYkcrLyzl58iTgTTKQmJhIfHw8MTEx0/qKf1xcHPPmzePcuXMUFRUB3tEvydIkxOXpdfUa9btMyhRQk0sp5Z1aGBpNt7Obo3VHAW+dLr/EiMRLzka4bs469l7Yi73HjqPPwe4Lu7lm7jUBI2AyBVHMBv4kGu3t7cYMjvj4+MsqoWKxWEhNTaWuro7a2lrmzp0bsL+5uZmGhgYaGhqwWq1kZGSM2F5XVxcej4fw8PApnfUyGwQ7Df2DwE1a688CPb5/7wBGfkcvTScQM2BbLNABoLU+orVu1lq7tNYv4Q0CPzBEOz8A8gb8jP9SnRCzQFNTkxF8LV68mLVr1zJ37lzi4+OndfDlV1hYSFRUlDFyJ9MPhbh8/Ue/kiOTsZgDRwCtIVZuWXALdy69c8iRrgXJl54m3GK2cG3+tcb93RW7qe+sx+Xxlp0It4QHZEcUYqYKCwszCivX1NQAjDux1VAyM7356fxt9ucfzQI4duwYbW0DxzUCyfTD4Al2AJaktT7sv6OUUlrrXXinJAbbSWB5v3PF4A2eTg5zvB5yo9Z2rXVF/x+gOtidFSJYent7sdlslJeXc/z4cfbs2cOBAwew2+2X1a7b7ebECe80ovnz5w+6UjYTmM1mIysiBNZIEUJcmhJbiXE7MyZzhCO9wdZAC5PHt/ZroBXpK4yMiH3uPv52+m/GPln/JWYLpZQxDbG+3rueMhgXEVNSUggJCcFutw+qNeYPwKxWK263m1OnTo3Yln9dmgRgly/Y44f1Sql0rXUd3tpfm5RStvE0oJQK8fXLDJiVUmGAW2s9MIfmH4D9SqlrgHfxZk7c50/AoZS6E3gF6MIbAD6Ad1qkEDNOd3c3JSUlNDQ00NvbO+QxjY2N5OTksGTJkjFfbfZ4PJw5cwbwBmAOh4Po6GijwPFMlJCQwLJly+jq6gooTCmEGD+tNScbLl7XXJSyaMTjs+OyiQyNxNHn/WIXbgknJ/7S6vz5mZSJGwpu4PdHfw9AZVulsU+mH4rZJCYmhqamJrTWKKWCchHRbDaTnp5OVVUVNTU1zJ8/39jnD8AWLlxIUVERLS0tuFyuYacX+gMwyYB4+YI9AvZHvPW/wLv+603gMONbA/YloBv4PN6gqRv4JYCvltdWAK31GeBjwK+AZmAh8MF+7XwGqMG7Luw7wMNa67cu5UkJMZUqKirYsWMHlZWV9Pb2EhISQnx8PNnZ2SxevJgNGzYwb948oxZWZWXl6I36lJaWUlZWRllZGRcueOulL1269LLmnE8H2dnZLFhw6dOehBBe9Z31xvova4h11ALHJmViftLFL3jzk+ZjUpf//8n8pPnkxA0O5GQETMwm/S8axsXFBW3qf/9piP2Ta/kDMH+CLa11QD3NgSQAC55gp6H/Sr/bP1NKFeFdp/XqONp4FHh0mH1RA+4/DTw9zLGyjmsGKy4upqOjg2XLlmG1zq75/Q6Hg+rqakJCQggNDcVisRAaGkpoaChmsxm3243ZbCY8PJzGxkZOnjyJ1pqMjAxjjdPAwCI5OZnY2FiOHDnC6dOnSUlJGTX7X2trK6WlpSilyM7Oxm63k5KSEpQ550KI2aH/6NeC5AWD1n8NZVPOJk7Un0Cj2ZS9KSj9UEpxY+GN/OLALwK2ywiYmE38iTgguGuYk5KSsFqtOBwO2trajGCrq6sLgIiICJKTk2ltbaWpqYnU1NRBbWitpQZYEE1oChOt9d6JbF/MTm1tbZSWlgLeBZ8bN24cMtV5a3crvz/6e8wmMw+seGDGXAktKioa8QqTX3p6Os3NzWitmT9/PoWFhSMen5GRQW1tLfX19Rw4cICkpCRSU1NJSkoadKzL5eLo0aNorZk3bx6LFo08rUgIceXRWnOy/mIAtjhl8Zgelx6dzr9t/ze01oRZglemIicuh4XJCznTdMbYJinoxWwSFRVlXIgNZgCmlCIzM5OysjJqamqIi4uju7sbrTXh4eGYzWaSk5MpKSmhqalpyDa6urpwu92EhYVdkaU4gu2yAzCl1ONjOU5r/dHLPZeYObTWeDyeSxo+9wdfJpOJzs5O9u7dy8aNGweN6Lxb+S4NnQ0APH/meR5Y+cDld3yCdXZ20tzcjNlsJicnh76+Pvr6+nA6nfT19eF2uwkJCaGrq4u6Om/msZSUFAoKCkZtWynF0qVLaWlpob29nfb2dioqKrjxxhsD5nNrrSkqKsLhcBATExMwH1wIIfzqOuqwdXmXcYeaQylMGvkiUH8TlZnwhoIbKLYVG9OoZARMzCZKKebMmUNLS8uQF08vR/8AbNGiRcb0w4iICMA7DTEkJITOzk66u7sHfeeS6YfBFYwRMFlkIQY5c+YM5eXlbNy4cVxXcTo6Oqirq8NkMnHVVVdx9OhR2trajCDM/x8FwJHaIxfP13SG5q5mEiMmb/qc1pru7m7Au8jVbDZjMpkC1k+5XC5qa2ux2+3k5+cb66wyMzNZvHj4q8k9PT2cO3eO7u7ugKx+owkLC2P79u3YbDZKS0vp6Oigubk5YDpBeXk5tbW1hISEsHr16hmRXl4IMfneOPeGcXus0w8nWkpUCltytrCrYheJEYlkxExElRshps6yZcsmpN3Y2FgiIyNxOBzYbLZBBZVNJhNJSUnU19fT1NREdnZ2wOMlAAuuyw7AtNYfCUZHxOzR2dlJWVkZWmuKi4vZtGnsawDOnTsHeJMoREdHs3HjRvbt24fdbufdd981gjCXxxVQ6BNgZ/lObl98e1CfS1dXF2FhYUZQ1d3dTV1dHY2NjbS2tuJyuQY9RillBGQulwu32w14a2w5nd4+5+SMnBUsLCyMJUuWXFKfrVYrmZmZdHZ20tHRETCfu6WlhdOnTwOwYsUKSSUrhBhSeWs5Z21nAe//advytk1xjy66seBGVmeuJi4sjhCTFIMVYiz80xBLSkqoqakxphH6AzDwrievr6/n/PnzxMXFBaxJkwAsuGZ2qjMxLZ09e9aYHtLc3Byw3snj8dDc3MzZs2cpLi7G4/EY+7q7u6mpqUEpZaRBt1gsbNiwgfj4eLq6uti7dy8Oh4Pa9lqjEKff0dqj2LvtI/bN5rDR1dc16nPQWnPmzBnefPNN3n77baqrqzly5Ahvvvkmp06doqmpCZfLhdVqJTw8nNDQUEJCQlBKobXG5XLR29trzOOOjY2lq6sLp9NpZBuaaMnJyQDGfO7e3l4OHz5srPtKT0+f8D4IIWYerTWvlbxm3F+RtoK06LQp7FEgpdSQBaGFECPrnw2xpaUFCAzAMjIyiIqKorOzk127dnHu3Dnj+5wEYMEV1EtHSqlyhi94PPOqus5Cvb29FBcXExsbS1ZW1rimn7ndbmNUxf9vR0cH3d3dRka/mJgYamtrMZlMZGVlceHCBc6cOUNqaio2m43W1lZjRAggNDTUKPhbXl6O1prMzMyAucf+IGz//v20tLSwb98+LHmD//C6tZsD1Qe4oeCGIfu/t3IvLxa/SFRoFI+sf4T48KHra2itOX78uJHO3eFwcPToUcA7RJ+WlkZ6ejqJiYmDkoNorY31b/7nabVacTqdxkheXl7eWF/yy9J/PndXVxdFRUX09PSQmJjIggWDi6UKIQRARWuFUWsrxBTCtfnXTnGPhBDBEBUVRXp6OnV1ddjtdoCApR2hoaFs3bqVM2fOUFFRwZkzZ2hoaGDFihWSATHIgj12/+iA+5nAw8BjQT6PuAS9vb3s3bvX+CUqLS1l3rx55OTkDBmI+dOhg7cq++HDhwNGrPrzJ5Pwt52Xl0dBQQG1tbW0trbS2tpqHBsdHU10dDS1tbWUlpYa84z9AY8/IOsvJCSE9evXs3v3bjo6OqiqrDL25Sfmc67ZO3XxcPVhrsq+ijBrYGDU0tViXNHt7OtkR9kO7lh8x5DP+ciRI9TX12M2m1m1ahVdXV2Ul5eTlJREQUFBwH9WAymlUEphMpkCEl9YLBY2bdqE3W4PamajkfSfz33w4EHa29uxWq2sWrVqxtf5EkJcmm5nNw2dDWTFZmE2DX0B7kTDCeP2qoxVw16sEkLMPAUFBUaSLwgcAQPv962lS5eSmppqFGd+++238Xg8hIeHD1ukWYxPsOuA/XbgNqXUS8A3gf8I5rnE+DidTiP4io6ORilFe3s7p06d4ty5c0Yg5v/F8n9pX7ZsGTk5OVRUVODxeIiIiCA2Npbo6GiioqKIjo4mIiICt9tNT08PLS0t9Pb2kp+fT0hICEuWLKG8vJy4uDgSExNJTEzEarWitTaOLykpwWw243Q6SUhIGHZ6ntlspi+uj/LGcs62nyUu2Xvc9fnXU9dRR2dPJ8Xlxfyu+XcUJBaQkJBAQkICiYmJvHj2RZyei2vGjtYe5Zq51wSkMHY6nRw8eJDm5mYsFgvr1683qtAPFRSOl9lsnvQaW/4ArL29HaUUq1evHjKlvxBidtJa097bTmxYLL2uXn6y7ye0dreSFpXGXUvvGjS10KM9AbW/lqVPTEIAIcTUiI2NJS0tjfr6eqxW67ABVUpKCtu2bePEiRPU1tYCMvoVTJMRxhYBUhR5itXU1BjB18aNGwkNDaWhoYHS0lLsdjunT5/m/PnzrFq1iqSkJM6fPw/A+fPnSUtLw2azoZRi69athIaGDmo/JCQEq9UaUMUdYM6cOcyZM2fQ8UopFi5cyJ49e4xzwciBzhvn3+Dt+rep7qj2BoN9EUSFR5ERk8HK9JW8Xvw6breb8u5y4triOGs7S4uzhWZnMza3jbi4OCPphEd72Fmxk+tyrjNGrfbv3097ezthYWFs2LBhVvxH418HBrBw4UIpsizEFURrzW+P/pZSWymrMlaREpVCa7d3NkJ9Zz0/2/8zVmasZHn6cnLjclFKUd5SjqPPmx0tKjSKnLiREwYJIWaewsJCGhsbR52RExoayqpVq0hLS6O0tJSsrKxJ6uHsN6EBmFIqHPgE0DiR5xGj81+9yM/Px2r11mdJS0sjNTWVpqYmzp49i91up6ioiDVr1hiLMx0OB6dOnUJrTUpKypDB16VKSEggOzubmpoaoqOjSUpKIi1t6IXe55rP8U75OyiTIioyivaOdjo7O5mfOh+TMrEqcxUvFL0AQFtoGwfMB+h19dKre+l1e5NhtLS0MDdlLo1d3o/j3vK99JX0YTVZMZlMeDweoqKi2LBhw6D6FzNVZGQk8+bNQykVlFE8IcTM0eRootTmrat4pPbIoIyBLo+Lg9UHOVh9kLiwOJalL6PZcTFp0pK0JZiUTFcWYraJjY3l2muvHVNBZX/2RH8CDxEcwU7C4WFwEo4O4MPBPI8Yn97eXlpaWjCZTAH1oMD7i5WSkkJycjLvvPMOHR0dHDp0CPCOarlcLmpqagAmJGteTFYMvQm9LExZSLR16BGnjt4Onj7xtJGJJyraG4A5HA6yY73rx1KjUokmmjbaCAsLw2q1GoEmQGNjI6HOUK5OvJo9lj1Ut1XT3tFONdXkR+bj8XiIi4tj/fr1QQ0yp5pSikWLFk11N4QQU6CqrSrgvj9zbIw1hmhrNDXtNcY+e4+dneU7A45fknpppTCEENOfLEeYWsEeAbt6wP0OoERr3Rnk84hR+EezkpOTiYyMNEawhrvaoZRi/vz5HDp0iK4ub5r2FStWGGnLlVLDjk5dqvPN5/n1kV+jtealsy+xIXsDV8+9GmvIxcDJoz08feJpOvu8H6Go0CjuWHkHj7/+OH3OPpYletcnuN1u5pnnUaNqsFqtWMwWMqIzmBM7hzkxcwjtC6WkqITGmkaWFyynuq2aLkcXtSG1fPiGD2O1WgPqfQkhxExX3VY95PZtedtYn7WeC/YLFNUVcbLhJF3OwPIcMv1QCCEmTrCTcLwTzPbEyBwOB93d3UbWPf9apq6uLo4dO4bL5aK9vd1YYDnaCFZaWhpxcXHY7XZiYmJIS0sjOTmZxsZGkpOTgzoy5NEeXih+wRjVcnqc7KrYxZnGM9y3/D5jYfg75e9wvsW7RkwpxV1L7yI/MZ8P5H+AhoYGdJ/38a2traSFpvHBuR9k1bpVJEcmB0yd0VpTV1ZHZ2cnmZ5Ment6cbldNJuaiYiOCAj6hBBiNhg4Agbe0a/VmatRSpEbn0tufC63LLiFUlspRfVFFDcW4/Q4uSrvKpl+KIQQEyToa8CUUluBNUDAfDKt9b8H+1xXMofDYaQFHU5SUhLNzc24XC6UUoOmHw6klGLp0qUcO3aM+fPno5SisLCQ7u5uozBysOyv2k+jY/DSQFuXjZ/v/zkfXPFBLCYLb55/09i3LW8b+YnefkRHR9PQ0EBHRwfp6elGsefs1GxSowY/T6UUubm5nDx5kvqKesy93vTLYRFhlLeWU5hUKF82hBCzRp+7j4bOBuP+B5Z8gLKWMjbnbB5UwDjEFMLClIUsTFlIr6uXHlcPsWGxA5sUQggRJMFeA/Zt4HPASaD/fAYNSAAWROfPnzfSwoeFhQUUANZak5GRQUFBAZWVlRw/fpzU1NQxjWDFxcWxfft24358fHzA/cvV1dfF/ur9AWsNbii4gWhrNM+feZ4+dx9Oj5Onjj9FqDnUGCHLjc/l2nkXi4H6MxT6K7P7A7CRMvr4C0N3dHQQ7fQ+PjIikt8f/T0Ws4XkyGTet+B9ZMVJlh8hxMxW216LR3sv0CVHJrMqYxWrMlaN+jhriFVmBAghxAQL9gjYw8B6rfWxILcr+unp6aGqqgqlFOvXrzdSqw8lJyeHxMTEKV9s2dbTxp4LezhYfZA+d5+xPSEigc05mwkxhTAnZg6/PfJb7D12bwZDVy8AEZYI7ll6T8AIlf85d3R04Ha7jYruI6VZDwkJYfPmzRw9epSMvgzKnGVYQr1Xgp1uJ7XttTx28DE2ZW/iuvzrCDXPnmQcQogrS//1X3NiB5cCEUIIMXWCHYA58I5+iQlUVlaGx+MhPT19xODLbyzHTJTmrmZ2nN9BUX2RcTXWLy4sjvuW3WekRk6JSuH+FffziwO/CCiafOeSO4kJiwl4rL+YdGdnJ01NTbjdbmJjY0cd5bNYLKxdu5aMzAwunLqAC1fAfq01ey7s4UzTGe5YdAd5CXmX8/SFEGJK9F//lRUro/pCCDGdBHvRy3eBryil1KU2oJT6lFLqsFKqTyn1m1GOvUspVaaUciilXlNKZfbbF6qUekwpZVdKNSmlZsUUyI6ODi5cuAAQ9HVZwdbR28EvDvyCo3VHA4Kv1KhU7lxyJ5/b8jkyYjICHpMRk8EdS+7A/xHalreN+cnzB7VtNpuJiIhAa20Uch5tjZufUoo5mXNYn7PeuN9/fRlAS1cLvzr0K/56+q/Ud9Rj77YPCiCFEGI66urr4oL9gnFfAjAhhJhegj0C9lfgDeCflFJN/XdorcdaBbYW+DpwIzBsNVyl1ELgceB2YA/wX8CTwDbfIV8BlgH5QBTwhlKqXGv967E+memmt7eXAwcO4HK5yMjIIC4ubqq7NEhjZyMX7BdYlraMA9UHjPTxAHnxeWzN3UphUiEjxejL0paRFJFEl7OLeQnzhj0uOjoah8NhFI0eb5r8GwpuIDsum+TIZFKjUtFac7j2MC+ffZkeVw+AUaQUINQcSlZsFptyNrEgecG4ziWEEJOhvLWcp088TUevd31sqDl0yMREQgghpk6wA7A/AdXADwhMwjFmWuv/A1BKrQFGmrj+APCy1voN3/FfAhqVUvO01ueBjwAPa61tgE0p9T3go8CMCsDONJ6hxFZCm72NhvoGent6iYqKwhJl4Y1zb+DRHjzag8vjwu1x4/K48GgPsWGxZMdl0+3sptHRSIw1hoLEAhIjEkcMfi6HvdvOzw/8nF5XL/uq9hlfAABuX3w7azLXjLmtgSNjQ4mOjqa+vh7wFhSMiYkZ5RGBQkwhAYVGlVKsyVxDYWIhzxc/z+nG0wHH97n7ON9yngv2C/zL1n8ZtnC0EEJMNo/28E7ZO7xZ9qaRvAjg+oLrMZvMU9gzIYQQg/iz5wXjB+gEwoLU1jeA34yw/zngiwO2nQVuA+LxZl7M7LdvI9A6RDtxQO6Any2+xw/589hjj2m/xx57bNjjvC/vRatWrRr2uIcfftg47tChQyO2+eEfflh/4dUv6C+8+gW94uYVwx6Xlp9mHPeFV78wYpuf/cZn9XOnn9P/8+7/6Pd+9r1BeU4rbl6hv/DqF/R/vvOf+sDBAyO2eejQIaPNhx9+eNjjVq1aZRxXVVU1YpsT8T75n9Puit2jvk+X8py090M5bT978pzkOclzmt7P6ebP3Ky/8OoX9Dfe+oZ+9DuPzornNBvfJ3lO8pzkOc2e5/S3v/3NfztXjzHOCfYI2CkgAe80wokWBbQN2GbHW3/Mn3WibYh9A30W+GpwuzaxTObg16s623SWiKoIANzaHdS2N2RtwNQS/D6Pd8QrmI7UHmFT6Kagtunoc2DrsgW1TSHE7HCo5hCvl77OkrQlox6bG5/L3Uvv5k+lf5qEngkhhBgvpftNVbjsxpT6R+B+4PtAff99WuudQz5o+La+AczRWj80zP7ngP1a62/121YM/D9gJ9CCdwSs1rdvA94pi/ED2onDOwrW3xxgV3l5Obm5uePpdtBVtFZwofkCIZYQPNpb48ujPWi8EbRSihBTCCZlwmKyYDKZUCjqO+qpaa8h3BJOalQqjZ2NnGs5h9PtHP2kozApE2ZlJsTsPa9C0eXsMpJUhJpDjVTzFrOFf936r0SERlz2eQdyu928/vrrKKW47rrrMJsndppNr6uXb7/9bSND4yc3fHJMUyX9j/3xuz+mtbuV5enLuXvp3QH7y1vKeaLoCbqd3d6i2VGprMpYxZrMNVKTR4grwMmGk7xY/CIxYTGsm7OOZWnLjILJNoeNH+39kXFxbH3WevZX7R/UhlKKq+dezdVzr5bC8kIIMUkqKirIy8sDyNNaV4zlMcEeAfuh79+nBmzXQLC/HZ8ElvvvKKVigDzgpNa6VSlV69vvH41bwRAp8rXWdryjY4aJWiN1KXLjc8mNzw1KW72uXk41nuJs01m01oSaQ7GYLVhDrFjMFmOxdnJkMudbznOy4STnm88Pyv7nX3fWP1W8n8Vk4ZH1j/C3M3+jorWC6/Ovn5DgC7yZELds2YJSasKDL/AWKF2UuoiiuiIAjtYeHTEA6+rrorW7lfSYdPZX7ae1uxWAoroirs+/nvhw77WA4/XH+cvJv+DyeFPia62p76jnpbMvsaNsB/cvv1/S4QsxC/gvmg1U217L0yeexuVx0d7bTnVbNa+UvMLqzNWsm7OO10pfC5iZMFTwFWON4e6ld8v/FUIIMQMEdQQsGJRSIXgDw6/iHYl6GHBrrZ0DjlsI7AfeD7wL/AewQmu9zbf/m8B2vGvCIoHXgW/rMWRBVErlAuXTYQRsqnX1dXG66TQnG05S0Vox4ghaZGgkNxTcwJrMNWitcXlcxhXc2aLEVsJvj/wW8BaI/vSmTxvJOLTWNHQ2cNZ2lrNNZ6lsq0RrTV58Ho2ORhx9DqOd6/Kv4+q5V7Pnwh5eOvuSsT3UHGokUvGLC4vjs5s/O+teSyGuFG6Pm3cr32VnxU6irdFsydnC8vTlmJSJHmcPP9n/E1q6WoZ8rFKK4f5OK6X45IZP0u3sJjMmU0bLhRBiCkyHEbBg+BKBa7IeAH4LPKSU6gRu1lrv0lqfUUp9DPgVkAbsBj7Y73FfA5KA84AT+NlYgi8RKCI0gjWZa4wMhv4pkP6si27tRmtNuCU8IEBQSs3KgCE/MZ/YsFjaetrocnbx5LEn2TZ3G2ebznLWdpa2noHLEr1poQc6WnuUbmc3ey7sMbalRKbwoVUfIsISQVFdEa+de41uZzf2HjsHqg+wOWfzmPpYYitBa8385Pl0O7t5vvh5FIpN2ZvIjM0cvQEhRNBU2it57sxz1Hd4Z+U7+hw8c/IZ9lXt46OrP8rLJS8bwZc1xMqWnC0cqT1ijJj3D75CTCHGSDnAgqQFpEenT+KzEUIIEQzBXgP2leH2aa1nTCFkGQETIymxlfC7o78b9qq030hXrgfKicvhgRUPBEzX3Fu5lxeLXwS8o23/vOWfCbOEjdjOu5Xv8kLxCwC8f9H7qeuoC5iutCB5AdfMvUYCMSEmWLezm1dLXzXqCA5ldeZqjtZeLFR/z7J7WJa2DI/2UGIrYV/VPkptpYA3OLt/+f38+sivjf9XPrr6o8xLHL5WohBCiIl3KSNgwQ7AdgzYlIF3XdZurfU1QTvRBJMATIxm4NRBv7CQMAqSCpifNJ+CpAIO1xzmtdLXAO8UzXkJ8zhefzzgMYtTF3PXkrsGjRi6PC5+sOcHxpXw7Nhs3rfofcNe8W5yNPGTd39irM2LscbQ4+oxEqL0N1og1tbTxhvn3iAlKoUtOVum1bpIIaa7Y3XHeOnsSwHTji0mC1fPuxpHnyNg5NsvNz6Xh9c+PGi7zWGjwl5BblwuSZFJ7Di/gzfOv8HStKXcs/Qe+d0UQogpNuVTELXWVw/cppT6LDB1+cKFmACbsjfR0dvBngt7SIpIYn7yfOYnzSc7Ljug6Om2vG1EhUZxpvEMW3K3oNEBAdiG7A3cMv+WITOWhZhCuD7/ev584s8AVLZV8tN9P2V52nK2zd1GcmSycaxHe3jm5DMBiVHae9uN29YQK33uPuPKeXFTMcVNxaREpmA2mcmOy+aaedcQFRqF1pqnip6isq0SgIaOBu5YcodkVRNiDA5VH+LZ088GbFuQvID3Lngv8eHxxuhWk6Mp4JituVuHbC8pMomkyCTj/tXzrmbb3G3y+yiEEDPYhCfh8CXVqNRajy1f9zQgI2Biomiteb74eYqbitmSu4WNWRtHvIKttWZH2Q52lO0ISMyhlGJJ6hK25W0jPTqdl86+NORVdb/bF99OVmwWO8p2cLLh5JBTIyNDI7lj8R24PW6eLHoyYN/y9OXcueRO+dInxAicbiff3fVdOvs6AYgNi+W9C97LwuSFAb/nx+uO86cTF2t0pUSm8OlNn5bRLCGEmIGmfArikCdQqgDYp7VOnNATBZEEYGK6aexs5MWzL3Ku+dygfdmx2cZoFcBVuVexv3o/va5ewLt+7F+v+ldjimNDZ8OIgZg1xGo8tr8lqUu4e+ndASN805W/VEKIaTrmGRKzVf91mzHWGD67+bNDZib0aA8/3vtjGh2NANyx+A5WZ66e1L4KIYQIjimfgqiUenzApkjgWuDPwTyPEFealKgUPrL6I1ywX+DtsrcpsZUY+/oHX4tTFnNDwQ0A7Kzw1j5fl7UuYH1ZalQq9y67l86+Tjp6O2juauaF4hfo6O0AMIIva4iVJalLOFxzGMAI2O5edvegwMbmsLHnwh7sPXZ6XD1kxGSwPG05WbFZk3ZVv62njRJbCSW2EiNQ/cCSD7AkdcmknF9cuXpdvdgcNnaV7zK2XZV31bBp4U3KxD3L7uH54ufJiM5gZcbKyeqqEEKIaSDYSTgGpnnvAA4BT2jdr4rkNCcjYGK6q2mr4Z3ydzjVeMrYlhGTwd+t+TusIVZcHhdvnHsDheLa/GtHHQnq6uviuTPPcbLhYq3y6/OvZ1veNl46+xJ7K/ca2xckL+C+5fcZbbo8Ln6494dD1jGKD49nWdoylqUtIy06zdh+tuksJ+pPoJQiNiyW1ZmrjcLU42Fz2Dhce5gSW4mR5rs/szLzwMoHKEwqHHfbQozGf+HhSO2RgPTw0dZo/nnLP8/KUhxCCCECTcspiDORBGBipmjobGBf5T7c2s31+dcbRaEvhdaaovoi3il7h5SoFO5ccicWswWtNa+WvsquiotX9wuTCnlw5YOYlIl9lft4vvj5UdtPjUpladpSel29AW0BpEWn8akNnxrXaFlDZwOPHXhsyOmS/VnMFh5e87Ck3hdBVWmv5PFDjwckvvG7ZcEtbMreNAW9EkIIMdmmbAqiUmox8D6t9beH2Pd54K9a6+JgnEsIcVFqVCq3LbotKG0ppViRvoIV6SsGbb+x4EZMysQ75e8A3lpoO8p2sCVnCzvKLlaf2JyzmXkJ8zjdeJpTjafodnYb+xo6G2g41zDkues76qlsqyQnLmfM/X3p7EsBwVeIKYTc+FwKkwrJjMnk6RNPY++x43Q7+cupv/DJDZ+cEevXxMzwSskrAcFXYkQiSRFJ5MTnsCFrwxT2TAghxHQXrDVg/x8wXAq2RuBfgY8G6VxCiEmmlOL6/OvRaHaWe9eW7SjbQXlLeUDGt+vzr8ditjA/eT63LryVUlspRfVFFDcWDxopKEgqwISJs7azAByuOTzmAKz/Oi+lFHcvuZv5yfMD1tx8ZPVH+J99/4PT7aShs4FdFbvYPnf7mNp3e9yYlEmy0okhVbRWcMF+AfBOc/3wqg8zN2GufF6EEEKMSbACsC3AZ4fZ9xfgi0E6jxBiiviDsJq2Gs63nEdrTXlrubH/mnnXBKx5CTGFsDBlIQtTFtLr6qW4qZiiuiLqOupYmbGS6/Kvo7qt2gjATtSf4Jb5twybuMCv29nNKyWvGPfXZK5hWfqyQcclRSZxff71RsHsHWU7ON14muTIZN674L2EW8KHbP9M4xn+evqvhIWEceeSO8mKyxr7iyRmDa01uyp20dDZQIw1htiwWOPHPxIM3hIN8xLnTWFPhRBCzDTBCsBStNb2oXZorduUUslD7RNCzCwmZeKupXfx43d/jKPPYWxfnLKYVRmrhn2cNcTK8vTlLE9fHrA9KzaLpIgkbF02+tx9nGo8NWI7lfZK/nziz7R2twIQag7l2nnXDnv8xuyNHKs7Rm17LS6Pi5r2Gmraa1Ao7lx656DjS2wl/LHoj7i1m86+Tv730P9y7/J7WZC8YNhziNlpX9U+Xi19dcRjlFLDFlAWQgghhhOsqqoOpdSQl4l927uH2ieEmHmirdF8ZPVHWJa2jK25W/n79X/Pfcvvu6QizUqpgPpHfzv9N54+8TTlLeUBNcq01rxT/g6/PPhLI/gCuKHghhETj5iUiTsW30FYSFjA9qN1R6ltrwW8GSCP1R3jqeNP8cSxJ3D3S9jq9Dj5w7E/DFl/Tcxeva5e3i57e9TjFiUvIiUqZeI7JIQQYlYJShZEpdSfgCqt9b8Mse8/gVyt9T2XfaJJIlkQhZg8Hb0dfHfXdwPSeAMkRCSwOmM1yZHJ7L6wm0r7xXpnYSFh3L749jHX+Op19dLS3cJrpa8ZNdTSotIIs4RxwX5hUEFqf0p8f7AXaYnkkxs/SWxY7CU/TzFz7CzfaYx+xVhjWDdnHW29bdh77LR1e/+NC4vjgZUPkBiROMW9FUIIMZWmshDzN4F9SqkE4A9ADZAJ3A/cA2wM0nmEELNMtDWae5fdy5vn36Suo87Y3tLVwuvnXh90fHZsNncvu3tcdcOsIVbSo9O5Zf4tnGs+h0d7qO8cXDcMvCnxP7j8g4SaQ/nJvp/Q0duBw+ngiWNPcPP8m8mMyaTP3Uefq8/7r7sPl8dFWlQaEaER438BxJRr72mno7eD9Jh0Ono7jCLm4F3buHbO2insnRBCiNkmaHXAlFLbgZ8DhYAGFFACfEJr/c7wj5x+ZARMiKlR217LoZpDFNUV0ePqCdhnUia25m7l2nnXXlY6+eeLn2df5T7jvlKKrJgs5ifPZ0HyAlKjUo1sduWt5Tx+6HE82jNquxaThc25m9mas5UwS9iox4vpoaGzgV8e/CXdzm6SIpLodnbjcHrXNyZEJPDZTZ+V8gVCCCGGNS0KMSul8oEUoFFrPSMXTkgAJsTUcrqdnGo8xZGaIzQ5mliSuoRNOZvGNeo1nD53H6+VvkaXs4t5CfOYnzyfqNCoYY9/t/JdXih+Ycztm5WZnPgcFiQvYGnqUmLCYi67z2JiaK35xcFfBExv9TMpEw+seID5yfOnoGdCCCFmimkRgM0GEoAJIfqrba/lYPVBTjacpM/dR6g5FGuIFYvJQmhIKD3OHmxdtkGPU0qRHJFMcmQy8eHxxIXHERcWZ/wbbgmn19VLR28HFrOFcEs4oebQKXiGV6bDNYf5v1P/N2h7VGgU9y6/l7z4vCnolRBCiJlkKteABY1SKg74BXAz0A58U2v90yGOswDfwLvOLBr4G/D3WutO3/7fAB8E+vo9LFFr3TuR/RdCzD4ZMRnctug2blt025D7tdYcqzvG7gu7qe+oD9je6Gik0dE45ONCTCEByUdMysTKjJXcuuDWgJpqIvi6+rp4teRimvmN2RuJD4+ns6+TTdmbRsyuKYQQQlyOaReAAf+Dt18ZwDzgdaXUGa31jgHH/SuwDVgF9AB/An4EfLTfMd/XWn9+4rsshLiSKaVYmbGSlRkrae9p56ztLCfqT1DWWjYow2J/AzM/erSHwzWHaeps4v6V9484NVJcntfPvW6s9YoLi+P6/OtHLQIuhBBCBMO0CsCUUpHAXcBKrXUHcEwp9TjeoGpgAPZ+4L+11o2+x/4H8IpS6pNaa6k7JoSYEjFhMayds5a1c9bS6+rF5rDR1NVEa3crbT1txr/2bjtOj5MQUwjR1micbiedfZ0AVLZV8sM9P+TGwhtZnbHaSAoigqPKXsXBmoPG/fcueK8EX0IIISbNtArA8GZQVFrr0/22HQNuGOJY5fvpfz/M10aRb9vHlVIfByqA/9Ba/3lQI94pj3EDNs8Zf9eFECKQNcRKZmwmmbGZg/ZprY31ZEoptNbsrdzLyyUvo7Wmy9nFs6eeZV/lPq7Pv57CpEIJxILAoz08d+Y5Y2RyQfICFiQvmOJeCSGEuJKYproDA0ThXffVnx3vGq+BXgQ+o5RKV0rFA/6phv5CPD8CCvBmZPwS8LhS6qoh2vksUD7gZ9elPwUhhBidUgpriNUIqpRSbM7ZzIdWfoi4sDjjuLqOOn539Hc8duAxzjWfMwKH9p52zjefH3GKoxhsf9V+o96cxWThlvm3SGArhBBiUk23EbBOYGDO5ligY4hjv+3bt993/7vAjUA1gNb6SL9jX1JK/QH4ALCTQD8AfjNg2xwkCBNCTIHCpEI+venTvFP+Dnsv7MXpcQJQ1VbFrw//mtz4XLJjs9lbuReXx0VhUiEPrnwQk5pu19Omn47ejoDi3tvmbiMhImEKeySEEOJKNN3+YpcAWim1sN+2FcDJgQdqrXu01p/VWmdrrbN9j60GaoZpe8jLxFpru9a6ov+Prx0hhJgS1hArNxTcwD9v/Wc2ZG8gxHTxWllFawU7K3YaCTxKbCW8ef7NqerqjPJKySv0uryJcBMjEtmau3WKeySEEOJKNK0CMK21A3gG+LpSKloptQxvAo7HBx6rlMpQSs1RXsuA7wNf1Vp7fPvvVEpFKaVMSqkbgAeA5ybv2QghxOWJtkZz64Jb+dyWz7F2ztphR7neLnub4qbiSe7dzFLeUs6xumPG/fctfF9AYCuEEEJMlmkVgPl8Eu9oVR3wCvCo1nqHUipbKdWplMr2HZeHd5qgA/gr8FOtdf9A7TN4R8PswHeAh7XWb03OUxBCiOCJDYvl/Yvezz9t/idWZ64mPTqdWxbcQn5ivnHMy2dflvVgw3B5XPztzN+M+0vTlga8dkIIIcRkmnaX/7TWdryp6Adur8SbpMN/fw/eIGy4dmRuiRBiVkmISOCOxXcY95enLed7u7/nTXffZeOC/QK58blT18Fpas+FPUYxbGuIlfcUvmeKeySEEOJKNh1HwIQQQoxBZGgky9KWGfcP1Ryawt5MPxfsF/jtkd/yWulrxrZr511LTNjAXE9CCCHE5JEATAghZrA1mWuM2ycbThpJJmYLj/aMe2qlo8/BX07+hV8c+AUlthJje1p0GhuzNwa7i0IIIcS4TLspiEIIIcYuMyaT1KhUGjobcLqdPF/8PCvSV5ATl4PFbJnq7o2b1hp7j51zzec4WnuUyrZKFIpoazSrM1dz9dyrR0y539XXxc/2/4zW7lZjm1KKBUkLeN/C90m6fiGEEFNOAjAhhJjBlFKszlzNS2dfAuBo7VGO1h7FYrKQm5BLQWIBhUmFJEUkTfuCw6caTvHi2Rdp62kL2K7RtPW08db5t7jQeoHtc7cTGxZLbFhsQCZDrTV/PfPXgOBrcepibsi/gaTIpEl7HkIIIcRIJAATQogZblXGKnZX7Ka9t93Y5vQ4KbWVUmor5aWzLxEXFkdhUiFrMteQGZs5hb0dWpW9iqeOP4XHW0lkWOdbznO+5bxxPzI0kriwOGLDYjGbzJxqOGXsu2vpXaxIXzFRXRZCCCEuiZK0xYMppXKB8vLycnJzc6e4N0IIMbpuZzeltlIq7BWUtZTR5Gga9tjsuGzuXno38eHxk9jD4XX1dfGTfT/B3mMHINQcSnZcNoVJhSxPX47VbGVXxS7eKntrzOvB1s1Zx22LbpvAXgshhBBQUVFBXl4eQJ7WumIsj5ERMCGEmAXCLeEsS1/GsnRvVsTW7lZKbaWcaz7HuZZzAck5Ku2V/On4n/jEuk9M+bRErTV/OfUXI/gKt4TzD+v/gYSIhIDjrpl3DXnxeRysOUhrdyttPW2097YPGZAlRSRxU+FNk9F9IYQQYtwkABNCiFkoPjyedVnrWJe1DrfHTaW9ksM1hymqL8KjPVS1VXGw+iDrstbR1tPGO+Xv0OfuY2vuVlKjUietn3su7KG4qdi4f8fiOwYFX355CXnkJVws/+jRHjp6O7D32GnraaOtpw2Xx8XqjNVYQ6wT3nchhBDiUkgAJoQQs5zZZDaCl7jwOHaU7QDg1dJXqe2opaiuiD53HwDH6o6xNnMt18y7hmhr9IT2q9Jeyaulrxr3N+dsZlHKojE/3qRMRjIOIYQQYqaQAEwIIa4g2/K2UVRfREtXCz2uHg5WHwzYr7XmQPUBiuqL2Ja3jU3Zm7wZCMveQqFYlraMgqSCy07n3tXXFZB0Iys2ixsKbrisNoUQQoiZQAIwIYS4gljMFt6/8P38+sivA9ZPpUSmEBMWw7nmcwD0unp5rfQ19lftp8vZhdPtBLwjZKlRqXxk9UcueYRMa83TJ5820s2HW8K5Z9k9ASnlhRBCiNlK/toJIcQVZl7iPP5h/T9Q015Dn7uP2LBYFiYvxGwyU2Ir4eWzL9PoaAQYVJMLoKGzgVdLXuXOpXeO+9wuj4uXS16mxFZibLtzyZ3TJiOjEEIIMdEkABNCiCtQRkwGGTEZg7YXJhWSn5jPgaoDvHX+LRxOBwCpUankJeSxr3IfAMfqj3FV3lWkRKUMasPpdlLdVk15azm17bVkxmSybe42Wrpa+OPxP1LfUW8cuzV3KwuSF0zQsxRCCCGmHwnAhBBCBDApExuyN7A8fTmHaw5jMplYm7kWi9lCc1czpbZStNa8cf4N7lt2H33uPqraqihvLaeitYLqtmpcHpfR3pmmM9R11lHRWoGjz2FsX5C8gOvzr5+KpyiEEEJMGSnEPAQpxCyEEEOraavhp/t/atwPt4TT6+o1kmmMhcVk4cbCG9mQtWHK65AJIYQQl+NSCjFfXhorIYQQV5TM2EwWpy427nc7u4cMvpIiklg7Z23AsQDWECsfXfNRNmZvlOBLCCHEFWnaTUFUSsUBvwBuBtqBb2qtfzrEcRbgG8D9QDTwN+Dvtdadvv2hwI+BewAn8DOt9Vcm4zkIIcRsduuCWwEobymny9kFeNeI5cbnkhufS158npEh0aM9PHvqWY7UHiEyNJIPr/wwmbGZU9Z3IYQQYqpNuwAM+B+8/coA5gGvK6XOaK13DDjuX4FtwCqgB/gT8CPgo779XwGWAflAFPCGUqpca/3riX8KQggxe0Vbo/ng8g+itaatp41QcygRoRFDHmtSJj6w5ANsy9tGbFgsFrNlknsrhBBCTC/TagqiUioSuAv4kta6Q2t9DHici0FVf+8HfqS1btRatwP/AdynlAr37f8I8HWttc03H/N7w7QjhBDiEiiliAuPGzb46i8pMkmCLyGEEILpNwJWiDcxyOl+244BNwxxrPL99L8fBhQqpSrxjqAVDWjnW4Ma8U55jBuwec74ui2EEEIIIYQQo5tuAVgU3nVf/dnxrvEa6EXgM0qpt/BOQfy8b3uErx2A/hVEh2vns8BXL6m3QgghhBBCCDEO02oKItAJxAzYFgt0DHHst4G9wH68I10v+bZX+9phQFvDtfMDIG/Az9bxd10IIYQQQgghRjbdRsBKAK2UWqi1PuPbtgI4OfBArXUP3tGrzwIopW7CG3zVaK09SqlaYDlQO0o7dryjYwZJjSyEEEIIIYSYCNNqBExr7QCeAb6ulIpWSi3Dmzjj8YHHKqUylFJzlNcy4PvAV7U2CtL8BviSUipJKZUDfG6odoQQQgghhBBisky3ETCATwK/BOrwrgd7VGu9QymVDZwGFmmtK/FOFfwDkArUA9/XWvcPsL4GJAHnuVgHbKwp6M0A1dXVQXg6QgghhBBCiNmoX7xgHutjlNZ6YnozgymltgC7profQgghhBBCiBlhq9Z691gOlABsCEopK7AW7yice4q7M1vMwRvUbsW7Vg+gHO9Ipph6wXgvhnqPxfjMhN+JK+V9ngnvxUSYju/vlfpeTJRLfY/lfZg++r8X0/F39kpSDuQD6cBBrXXvWB40HacgTjnfizemCFaMTb/EJtW+wtgopfDfFlMrGO/FUO+xGJ+Z8DtxpbzPM+G9mAjT8f29Ut+LiXKp77G8D9NH//diOv7OXkl878V5vEuexmxaJeEQQgghhBBCiNlMAjAxlb421R0QBnkvpgd5H6YPeS+mD3kvpgd5H6YPeS+mj0t6L2QNmJgUSqlcfHOWZYh8dpL3+Mog7/PsJu/v7Cfv8ewi7+fMJCNgYrLY8V4lsE9tN8QEsiPv8ZXAjrzPs5kdeX9nOzvyHs8mduT9nHFkBEwIIYQQQgghJomMgAkhhBBCCCHEJJEATAghhBBCCCEmiQRgQgghhBBCCDFJJAATQgghhBBCiEkiAZgQQgghhBBCTBIJwIQQQgghhBBikkgAJoQQQgghhBCTRAIwIYQQQgghhJgkEoAJIYQQQgghxCSRAEwIIYQQQgghJokEYEIIIYQQQggxSSQAE0IIIYQQQohJIgGYEEIIIYQQQkwSCcCEEEIIIYQQYpJIACaEEEIIIYQQk0QCMCGEEEIIIYSYJBKACSGEEEIIIcQkkQBMCCGEEEIIISaJBGBCCCGEEEIIMUkkABNCCCGEEEKISSIBmBBCCCGEEEJMEgnAhBBCCCGEEGKSSAAmhBBCCCGEEJNEAjAhhBBCCCGEmCQSgAkhhBBCCCHEJJEATAghhBBCCCEmiQRgQgghhBBCCDFJJAATQgghhBBCiEkiAZgQQgghhBBCTBIJwIQQQgghhBBikkgAJoQQQgghhBCTRAIwIYQQQgghhJgkEoAJIYQQQgghxCSRAEwIIYQQQgghJokEYEIIIYQQQggxSSQAE0IIIYQQQohJIgGYEEIIIYQQQkwSCcCEEEIIIYQQYpJIACaEEEIIIYQQk0QCMCGEEEIIIYSYJBKACSGEEEIIIcQkkQBMCCGEEEIIISaJBGBCCCGEEEIIMUkkABNCCCGEEEKISSIBmBBCCCGEEEJMEgnAhBBCCCGEEGKSSAAmhBBCCCGEEJNEAjAhhBBCCCGEmCQSgAkhhBBCCCHEJJEATAghhBBCCCEmiQRgQgghhBBCCDFJJAATQgghhBBCiEkiAZgQQgghhBBCTBIJwIQQQgghhBBikkgAJoQQQgghhBCTRAIwIYQQQgghhJgkEoAJIYQQQgghxCSRAEwIIYQQQgghJokEYEIIIYQQQggxSSQAE0IIIYQQQohJIgGYEEIIIYQQQkwSCcCEEEIIIYQQYpJIACaEEEIIIYQQk0QCMCGEEEIIIYSYJBKACSGEEEIIIcQkkQBMCCGEEEIIISaJBGBCCCGEEEIIMUkkABNCCCGEEEKISSIBmBBCCCGEEEJMEgnAhBBCCCGEEGKSSAAmhBBCCCGEEJNEAjAhhBBCCCGEmCQSgAkhhBBCCCHEJJEATAghhBBCCCEmiQRgQgghhBBCCDFJJAATQgghhBBCiEkiAZgQQgghhBBCTBIJwIQQYgZSSv1GKfWby2zjC0qpl4PUJXEJlFIPKaUqpkE/7ldKnRrlmAnpq1KqUym1NdjtXg6l1HallJ7qfgghZicJwIQQYgRKqWVKqT8rpep9XxTLlFK/U0otmeq+jYdS6m2l1KP9t2mtv6W1vnmKujQspVSFUuqhqe7HlURr/YTWerH/fjAC/HGcO0prvWsyziWEENOBBGBCCDEMpdR2YD9QA6wHooE1wB7gtinr2AyllAqdxHOZlFLmyTrfTKaUskx1H4QQ4koiAZgQQgzvMeDPWut/0lpf0F4tWuvHtNbfhKFHCgaONimltFLq00qpA0oph1Jqn1Iq27etUinVopT6j37HD5r+NNr0L6XU15VS53yjdBd8902+fT8HtgJf8O2v921/VCn1tu/2Pyilige0Ge07/hrf/Til1M987TcrpV5SSs0doU8P+UazPquUqgQqfdsXKKVeUEo1KKVqlFI/VUpF+va9DGQDP/ed+8BQr6lvmzFSppTK9b3OH1NKnQS6gIW+Y76olHpZKdWhlCpVSt3Wr43lSql3lFJ2pVSrUuqwUmr+CM/pNqXUUaVUm1LqtFLqY/32+fvwgFLquO98e5VSC4Zrb4j2w5VS3+v3Gr+mlFrUb79FKfUd34hsk1Lqv3z9f7TfMb/0fa46fc/3U0O8bl9VSr2ulOoAPtH/86WU+gJwP3C/r41OpVRiv8c/4utfm1LqT0qp6AFtf0Up9abvs35SKbVSKXWPry9tSqlfq35Bn+81297v/mal1A7f829RSr02wut1t1LqlFKqXSllU0q90W9fhFLq28r7e+F/7z/g27dEKfWW7zF23+drxSjvzYeUUkW+53BKKXXvSMcLIcRwJAATQoghKKUKgELg90Fq8gHgA0Ay3uDgDSAFyAeuBT6nlNp2Ge2fBbbjHaW7E/h74GMAWutHgF3At3zTvdKGePyTQI5SanO/bfcADcAOpZQCngWigJVABnAceEGNPIIyB+/ruBCYq5RK8vXlNbyB1nKgAPiBr6834w3UHvH1dd34XgY+DNzk62eJb9vDwBeAWOAXwO+UUlG+fT8F3gSS8L43HwPsQzWslNoA/Bn4GpAAPAJ8Xyl1x4BDHwSu97VXD/xkHP3/HnA1cBWQCRwBXu8X5PwrcAewzbe/A9g0oI19wGogBvhH4HtKqesHHPMJ4Eu+Yx7vv0Nr/S3gCeAJ33sQpbVu9u3OxPuZXYD3PV0DfHZA2x/2nTcOOAb8Be/rsQJYBtwKfHCoJ6+8U3vfBJ7C+9lJA74zzLERwB+Af9Rax/iO/1a/Q/4X72v5Hq11NHANUNpv/zd9j8kEioFnh/ss+wL9fwc+CsTjff0eU0ptGep4IYQYiQRgQggxtBTfvzVBau+/tdZVWusu4Bm8X/q+qrXu01ofBU7i/TJ7SbTWf9BaV/tG6Q7i/QJ93Tgeb8f7Rflj/TZ/DHhca63xBl0bgU/4RgF7gS/iDaLWj9C0B/ic1trhe+4fAoq11j/SWvdqrW14A4EPqeBMGfya73Vwaa37fNt+obU+qrX2AD/DG3T4R7n6fM8hx/eYY1rrhmHa/gjwnNb6r1prt9Z6J/BL4OND9KFBa92DN7gZUxCpvCOWHwG+5Btx7cH7GpuBW3yHPQT8l9b6rO/5fRNo7N+O1vp/tdZNWmuP1voV4BUGfxb+V2u93/d56RpL/3ycwOe11t1a61q8QfnA5/crrfVprbUTb2CfB3zZ9xm4AOxk+M/63wOv+EaZu32/H6+P0p+FSqkkrXWP1votAKVUMnAv3kC+BMD3+3fcd/uk1vpN32McwL8BuXiDy6F8Dvi61vqw73Xd7XtuD43QNyGEGJIEYEIIMTT/l9rMILVX1+92F9CktXYP2BbNJVJK/b1S6phvGp0d7xX6lFEeNtCvgLuVUlG+aW9rgV/79hUAoUCtb8qWHWjGGxxkjdBmvS+Q8CsA1vvb8LXzGqDxjnZcrvIhttX6b2itO303/a/1Q75zv6WUqlJK/bfyTYccQhZQNmDbObwB3JDnAzrxjsaNRRIQ1v8cvs9IRb9zzPHd9+/3AFX++8rry0qpM76pcnbgZgZ/FoZ6ncaiUWvt6ne/k8Gf24GfdbTWA7cN91nPxTuaOypf4HgT3uDyrPJO+/RPt8z1/TtkW8o7XfRp33vezsXXY7jfmQLghwM+tw/iHQkWQohxCZnqDgghxHSktS5VSpXgXQvzxgiHdjA4cLjcL2UdAEqpSN/V+RHbVEptwjuF73pgr9bapZT6Id7pfX6eMZz3Hbxfnu/BO73sFd8oB3in0nUDSQO+gI9m4Hnrgbe11jeM4zHgfU2MwEgpFcLQX5bH8jwNvhGZh31t5gPPAe3AV4c4vArvaE5/8/CtbQsCG9DjO0exr09mIKffOaq5GFz4R836B8D3AZ8CbgBOaK09SqnnADXgXKO9Th6m5iJtBd4pq2Piy564yzdFdhvwivKm0z/pO6QQKBriob/A+3qv0lo3KaXigRYGv05+9cAXtdZPjrVvQggxHBkBE0KI4X0CuEd5kx5k+0YX4pQ30cMXfMccAq5VShUqb4KEzzL4S/p4leANOD6hvNn8VjB4mlt/sYAbaALcyltT6f4Bx9Qzyhdb31TDx/E+7wfxjoj57QbOAD9VSqUAKKXilVIf8K3FGatfA2uUN5FDhO81zVJKvX9AXwcmwjgEvF8pla6UCgf+A7js7H3Km3xiju8LfDvgwvtaDuU3vj7cqpQy+9b/PEzg63TJfKNZvwG+7vu8heFdd6SBF32H/Rb4F9/nLRTv1Ln+gWis7znYvE9P3Y43MB+veiA/SNNCx+NnwM1KqYeVUmFKqVCl1JBTaZVSaUqpu5RScb7Prh3va+XWWjcBf8T7eS3wHT9HKbXM9/BYwAHYlVKxwH+N0q8fAF9VSq3x/U5alVJrlVKrL/cJCyGuPBKACSHEMLTWb+Nd95SDNwDoAI7izSj4V99hTwBP4018UIU38cCeyzxvB95EBp/EGxR8G+8V++G8ijfhwB68V/E/7etXf98DlvimT1WP0NZvgVV4v8i+0K9Pbrxf5HuA/cqbPa8IuN137FifWyXepBE3Aufxfml+FVja77B/B+70Tafc69v233gTOpz1/ZwjOOvzrgYO4J1KVwS8yzBJH7TW7+IdYfo60Io38PpXrfUzQeiH3z/jTVKyG+9UxvXADb7PBMB/An/zHVODN5A4iPd9AW8AtxM4jTeIuhnvqN54/QLv9FJ/lsCES3ky46W1Pon3c/Yg3tHYOuD/G+ZwhTcRSplSqhPv2sov+NbmgTc43gO86tu/g4trvD6Dd4qtHe/v9kij3Gitf4j3c/kY3t+xGryfk+GmqwohxLCU96KREEIIIWYa3whVDfBPWus/TnV/hBBCjE5GwIQQQogZQikVq5S6xTfdNYqLUzFfnuKuCSGEGCMJwIQQQoiZwwQ8ijcDZTXeKYo3+8oICCGEmAFkCqIQQgghhBBCTBIZARNCCCGEEEKISSJ1wIaglLLizY5Ux/DpiIUQQgghhBBXNjOQDhzUWveO5QESgA1tLd4Uv0IIIYQQQggxmq14S4iMSgKwodUB7Nq1izlz5kx1X4QQQgghhBDTUHV1NVu3bgVf/DAWEoANzQ0wZ84ccnNzp7grQgghhBBCiGluzMuWJAmHEEIIIYQQQkwSCcCEEEIIIYQQYpJIACaEEEIIIYQQk0TWgF0Ct9tNS0sLTqdzqrsiLoPFYiEhIQGz2TzVXRFCCCGEEFcICcAuQUtLC2FhYSQlJaGUmuruiEugtaazs5OWlhaSk5OnujtCCCHElKloreBI7RFWpq8kLyFvqrsjxKwnUxAvgdPpJCoqSoKvGUwpRVRUlIxiCiGEuKJprXnq+FMcrjnMH4//EY/2THWXhJj1JAC7RBJ8zXzyHgohhLjSNXc109HbAYCjz0Frd+sU90iI2U8CMCGEEEKIK1R9Z33AfZvDNkU9EeLKIQHYFeDRRx/l3nvvHfW4Rx55hK9+9asAvP3226SlpU1014QQQggxheo66gLu27okABNiokkSDmH4+c9/PqXnf/TRRykuLuapp56a0n4IIYQQV4r6DhkBE2KyyQiYmDQul2tGty+EEEJMV119XZeUQENGwISYfBKAzULHjx9n3bp1REdHc9NNN2GzXfzP9N577yUtLY3Y2Fi2b9/OmTNnjH0PPfQQn//85we1993vfpf3ve99Adu+8IUv8OEPf3jEfjz00EN8/OMf59ZbbyUyMpIXXniB2tpa7rzzTlJSUsjNzeV73/seAK+88grf+ta3+Mtf/kJUVBTz588HIDc3l1deecVo8ze/+Q0bNmww7iul+PGPf0xhYSHp6enG1Mkf//jHpKenk5yczLe+9a1xvHpCCCHEzNHa3cqTRU/yzbe/yY/3/pheV++YH9vV10VbT1vANhkBE2LiyRTEy/T8889P2rluvfXWUY9xOp3cdtttPPzww+zevZvdu3fzvve9j/e+970A3HTTTfzyl7/EYrHwL//yLzz44IMcOnRoxDYfeOABvvKVr2Cz2UhKSkJrzRNPPMHjjz8+an/++Mc/8uKLL/Lcc8/R3d3NVVddxS233MITTzxBXV0d1113Hfn5+dx222184QtfuKQpiM8++yx79+4lMjKS/fv3Y7PZqKqqoqKigpMnT7Jx40Zuu+02Fi9ePK52hRBCiOmqz93HzvKd7K7YjdPjLanS6Ghk94XdXDvv2jG10dDZMGhbe287va5erCHWoPZXCHGRjIDNMu+++y4Oh4PPf/7zhIaGcs011wQEbg899BDR0dGEhYXx6KOPcvjwYRwOx4htpqWlcfXVVxuB0TvvvIPWmquvvnrU/tx6661cddVVmEwmTp48SV1dHV/72tewWq3k5ubyiU984rLXfH3+858nKSmJ8PBwAEwmE9/4xjewWq2sXr2a5cuXc/To0cs6hxBCCDEdaK05XnecH+z5ATvKdhjBl9/uit109nWOqa3ajtohtzd3NV92P4UQw5MRsMs0llGpyVRbW0tmZiYm08XYOicnh4qKCtxuN//2b//GM888g81mM46x2WxERkaO2O5DDz3Ed77zHT71qU/xhz/8gfvvvz/gHMPJysoybl+4cIHGxkbi4+ONbW63m7Vr1473aQ57DoCEhARCQ0ON+5GRkXR2ju2PkRBCCDFd1bbX8uLZF6lorQjYnhmTSY+rh+auZvrcfTxx7AmiQqNYkLyA1Zmrh21vYAIOP5vDRkZMRjC7LoToRwKwWSYjI4Oamho8Ho8RIFVWVgLwxBNP8Nxzz/Hmm2+Sm5tLc3MzycnJaK1Hbfd973sfjzzyCEVFRTzzzDPs3bt3TP3pX+w4KyuLrKwsysvLRz3WLyoqiq6uLuN+XV3doGOkoLIQQojZzOVx8WLxixysORjwNzsyNJIbCm5gdcZqzjSd4YljTwBQaff+3T/deJr06PRBwZRHeyixlXCu+ZyxbU7sHKrbqgFJxCHERJMpiLPMxo0bCQ8P57/+679wOp28/fbbxjq1zs5OrFYriYmJdHV18cUvfnHM7VqtVu69914+9KEPkZ+fz6JFi8bdt3Xr1hEfH8+3vvUturu7cbvdnD59mv379wOQmppKRUUFHs/FLE4rV67kySefpK+vj+LiYn71q1+N+7xCCCHETPZKySscqD5gBF8mZWJzzmY+t/lzrMlcg1KKhckLyY7LHvTYA9UHjNvtPe3sOL+D7+76Lr8/+nvae9sB74XMJalLjOOaHE0T/IyEuLJJADbLWCwWnnvuOZ555hni4+P59re/bWQr/NCHPkRubi6ZmZksXryYTZs2javthx56iOPHj/OhD33okvpmNpt54YUXOHHiBHl5eSQlJfGRj3yE1tZWAO666y5CQkJITEw0EmZ8/etfp66ujoSEBD7+8Y+PmnlRCCGEmE16nD0cqrmYLKsgqYBPb/o075n/HsIsYcZ2pRT3r7if7XO3syH7YrbgoroiqtuqefLYk3xn13d44/wbAZkPlVJszdnKnNg5xjZZAybExFJjmX52pVFK5QLl5eXl5ObmDtpfW1tLRsaVNze6oaGB7OxsqqurSU5OnuruBMWV+l4KIYSYGd6tfJcXil8AIDUqlX/c+I+jTr3XWvPjd39sZDlUSg1abhAZGsnqjNWsnbOWhIgEOvs6+fbb3wbAYrbwb9v+TTIhCjEGFRUV5OXlAeRprSvG8hhZAybGRGvN97//fd7//vfPmuBLCCGEmM601hyoujiFcH3W+jGte1ZKsXbOWiNw6x985cXnsW7OOhalLiLEdPFrYKQlksSIRJq7mnG6nRyqOcTmnM1BfDZCCD+ZgihG5XA4iI6O5rnnnuPb3/52wL6oqKghf1544YUp6q0QQggxO1S0VtDoaAQg1BzKivQVY37syvSVWMwW435sWCz/sP4f+Lu1f8ey9GUBwRd4g7YtOVuM+3su7MHtcV/eExDjprXG6XaOfqCY0WQETIxqpDTukt5dCCGECI7Ovk5eL32dEHMIK9NX8pdTfzH2rcxYOa4pgWGWMK6ddy2vlr5KVkwW9y2/j5iwmBEfszJjJW+cfwNHn4O2njaO1x9nZcbKS34+Ynw6+zr5xYFf0NHbwd1L72ZhysKp7pKYIBKACSGEEEJMMbfHzRPHnjBSyO+r3Gfss5gsbMoeX+IsgK25W1mftR6LyTKmqYsWs4WN2Rt549wbAOy+sFsCsEl0oOqAkQDlL6f+wmdiP0O0NXpK++TRHvZc2MPhmsMsSlnEDQU3TGl/ZguZgiiEEEIIMcXeOPeGEXz1Z1Im7l1+L0mRSZfUbqg5dFz1MjdkbcBi8k5drO+op7Gz8ZLOK8ZHa83RuqPG/W5nN8+feX4KewSt3a3876H/5ZWSV2hyNPFO+TvDFu8W4yMBmBBCCCHEFDrbdJadFTuN+/1HPW5bdBsLkhdMWl/CLeEUJhca9081npq0c1/JqtqqaOlqCdh2qvEUpxtPB/1cbo8bm8OGy+Macr/WmsM1h/nxuz+morUiYN+ZxjNB78+VSKYgCiGEEEJMkbaeNp45+YxxvyCpgAdXPEh5azkRlggyYia/VMrilMWcavAGXqcbT3P13KsnvQ9XmmN1x4zbFpMFp8ebiONA9QEWpSwKyjnqO+p5ofgFqtqqcHlcxIbF8qkNnyIiNMI4xtHn4LnTzw0beJ9uOs3V8+TzcLlkBEwIIYQQYgq4PW6eOv4UXc4uAGKsMdy55E7MJjP5iflTEnwBzE+aj1mZAahtr6W1uxXwjoy0drdyov4E+yr30dknibhGorXm1dJX+cm+nww7ctTW08bxuuOcqD9hbLtt0W3G7fKWcnpdvYMe1+vqpbW7dVB9t+HYHDYeP/w45a3lxsiXP9GKX217LT/a+6OA4CsxIpGPrP5IwOfB3m0f0znF8GQETIzqN7/5DT//+c/Zt2/f6AcLIYQQYkz6r/syKRP3LLuHqNCoKe6VN4PivMR5lNhKAPjbmb8BUNNeg6PPYRz3VtlbvH/R+4M2QjPbVLZVsrPcO7X0yaInuXvp3SRGJFJpr+SC/QKV9krsPfaAx8SFxbEifQW7L+ymvqMel8fFueZzLE5dDHgDrx1lO9hzYQ8e7SHcEs6C5AW8p/A9ASNZ/bX3tPObI78JeO/8SmwlbMjeAMD/nfq/gKB63Zx13FR4E9YQK3MT51JqKwXgTNMZNmZvvOzX50omI2CzzPbt2wkLCyMqKoqYmBjWrl3L7t27J+x8b7/9NmlpaUFpa/v27fz85z8PSltCCCHEdDZw3df1+deTG587dR0aYHHKYuN2ia2EElvJoC/wjj4HTxx7gl0Vuya7ezPCyfqTxm2P9vDU8af4yb6f8Hzx8xyvPz4o+ALYmL0RpVTAur/ipmLj3x/t/RG7Knbh0R7Am6zjaO1R/nTiT8a2/rqd3fz2yG+NUUyLycJdS+8y9pe1lOF0O6nvqKeuow6AEFMIH1r5IW5bdJtR+mBR8sUgW9aBXT4JwGahH/zgB3R2dmK32/noRz/KHXfcMeYhaiGEEEIEX6W9knPN59Ba097THrDuqzCpkK25W6ewd4MtSFkwqFgzQFhIGPMS5hFjvVhT7I1zb9DW0zaZ3Zv2tNZjSmBiMVuYmzCX7XO383dr/o7NOZsBWJh8sQbY2aazPHnsSX5/9PcBQVv/Qtvnms/xeunrAW073U5+f/T31Hd6MxealIn7lt/HivQVJEV4s2o6PU7KW8sD1qAtTFnI/OT5AW31r0lW3lpOt7N71OcmhicB2CxmMpm4//77aWpqoqmpiUOHDrFx40bi4uJIT0/n05/+NE7nxWrrZ86c4cYbbyQxMZGUlBT+7d/+bch2v/rVr7J69WouXLjAzTffTGNjI1FRUURFRVFWVobH4+E///M/yc/PJzExkQ984AM0NTUB0NPTw4MPPkhiYiJxcXGsWbOGuro6vvjFL7Jr1y4++9nPEhUVxd/93d9NymskhBBCTLSK1goeO/AYvz78a4rqizhYc3DQuq/xpIqfDFGhUdy99G4WpyxmQ/YG7lp6F/+0+Z/40tVf4qNrPsqnN32a9Oh0AFweF2+XvT21HZ5matprAoJSf8ATY41hSeoS3jP/PfzD+n/gy1d/mY+t+RjX519PXkKe8TnIjMk0pqM6nI6AYC7CEsEdi+/gq9d8NSBBys6Knca0Uf+I2wX7BWP/HYvvMAKrwqSLmS7P2s5SVFdk3F+ZPrj2W7Q1mjmxc4y2zzWfu8RXRoCsAbtsX3zti5N6vm/e8M0xH+tyufjtb39Lfn4+SUlJ1NTU8P3vf5+1a9dSWVnJTTfdRGFhIZ/61Kfo6Ojguuuu49Of/jR//etf0VpTVFQU0J7Wmk9/+tMcP36cHTt2EBMTw8svv8y9995Lff3FuhA//OEPeeaZZ3jrrbdITU3ln/7pn/j4xz/Os88+y29/+1vsdjtVVVVYrVaOHz9OREQE3/zmN9mzZw/33nsvjzzySNBeLyGEEGKq+b8UAxyvOx6Q/vvGwhuJDI2cim6NanHqYmPt0UDhlnBuKryJXx/+NQCHag6xOWfzJdcrm21ONlycfrgqYxW3L76dbmc3EZaIMQXbSinmJ8/ncM3hgO2rM1dzY8HFz8y1866ltr2Ws7azALxa+ir5ifk8e+pZY+oiwHvmvyegqPb85PnsrdwLBBb9jgyNJD8xf8g+5SfmU91WDUBpcylL05aO+jzE0CQAm4U+97nP8fnPf57u7m5MJhNPPvkkJpOJlSsv/uLNnTuXj3/847zzzjt86lOf4sUXXyQhIYH/9//+n3HMxo0XF1i6XC4eeOAB7HY7r7zyCuHh4cOe/+c//zk/+MEPyM7OBuBrX/saqamp9PT0YLFYaG5uprS0lOXLlwf0SQghhJiNmruajdsX7BcC1urkxedNRZeCYl7CPPLi8yhvLcejPbxT/g4fWPKBqe7WlPrbmb9xpPZIQJC9JHUJJmUad6C9MmOlEYClRKbwvkXvG/R5UUpx++Lb+d7u7xlruX554JdUtl0s6n1V7lXG1Ea/3PhcLGYLTrczYPuytGWYTeYh+1OQWGCMdPqn0063kduZQgKwWej73/8+jzzyCB6Ph7179/Le976XvLw8wsPD+dznPsfhw4fp6urC5XKxfv16ACorK5k3b96wbZaVlXHy5El27do1YvAFcOHCBe666y5MposzXENDQ6mpqeHBBx+kurqaD37wg7S0tPDBD36Qb33rW1it1uA8eSGEEGKa6R+A9bh6jNuxYbHEhsVORZeCQinFtfnX8quDvwLgfMv5Ke7R1KrvqGd/1f6AbdYQK/MSh/9+NZK8+Dw+tuZjOPocLExZOOSaPPBOD9ycs9kIjvoHX6syVnFDwQ2DHhNiCmFB8oKA9PdKKVZlrBq2P1mxWVhDrPS6emnraaPJ0URKVMolPbcrnQRgl2k8UwInm8lkYsuWLRQUFPDGG2/w0ksvsWLFCp566imio6P57ne/ywsvvABAVlYWZWVlw7ZVWFjIv/zLv3Drrbfy+uuvs3Spd9h5qCsfWVlZ/OIXv2Dbtm1DtvWVr3yFr3zlK1RWVnLLLbcwd+5cPvnJT8pVFCGEELOO1jogAOsvOy57knsTfDlxOYSYQnB5XLT1tOHoc0zbKZWX4nj9cY7WHmV15mqWpC4Z8diK1opB27bnbR82cBqLuQlzx3Tclpwt7K/aH5AcY0X6Cm5ffPuw369umX8L0aHRdPZ1YjaZWZC8YMTac2aTmfyEfGM9Wmlz6bgCsNdKX+NEwwmun3c9y9KXjflxs1FQk3AopQqUUsm+2xFKqa8qpb6klJLhjSmyb98+Tp8+zeLFi+ns7CQmJoaoqCjOnDnDY489Zhz33ve+l6amJr7zne/Q09NDV1cX7777bkBbd955J//93//NDTfcwKlT3l++1NRUWltbaW1tNY575JFH+NKXvkR5eTkANpuNZ599FoAdO3Zw4sQJ3G43UVFRhISEGCNlqampIwaBQgghxEzT2ddJn7tvyH2zIQAzKROpUanGfX8q85lOa83r517nT8f/RImthGdOPDNkQeT++ie8uG7edXxx+xe5Ku+qie4q4F2Td+28a437V+VdxZ1L7sSkhv+qH22N5pYFt3DPsnu4c8mdowaYQMD6sNLm0jH3z+aw8U75O7R0tfDC2Reu+Ozcwc6C+CSQ7rv9DeAu4E7g+0E+jxiBP5NgVFQUDzzwAN/4xje4+eab+e53v8sf//hHoqOj+cQnPsE999xjPCY6OprXX3+dV199lfT0dPLy8ozRsf7uu+8+vvOd73D99ddz5swZFixYwP33309+fj5xcXGUl5fzmc98httvv52bbrqJmJgY1q1bx9693oWe9fX13HnnncTGxrJw4UI2bNhgZDz8zGc+w1//+lfi4+P5xCc+MTkvlhBCCDGBhhv9AsiJzZnEnkyc/qMmsyUAe630tYDMjv507SPpH4AVJhUOWxh5omzI2sBHVn+Ej6/7ODcW3DghM4sKkgqM26W2Up45+QwdvR2jPq5/1kRHn8NIjX+lUsGMQJVSLUCS1tqjlLoAXA10Ake11plBO9EEU0rlAuXl5eXk5uYO2l9bW0tGxvBDtGLmkPdSCCHERDpcc5j/O/V/g7ZbTBa+fM2Xh014MJPsr9rP3878DYDl6cu5e+ndU9yjodkcNmLDYgPqZw2l19XLN3d8E7d2B2zfkL2BWxfcOuRjWrtb+e6u7wIQag7ly9d8ecTRp5nslwd/GTDdMikiiU9t/NSIr+sfjv6BM00XCzi/Z/57BiUGmakqKirIy8sDyNNaV4zlMcH+ZChAK6XmAlprXaa1bgRiRnmcEEIIIcSM0ufu46f7fsq/v/XvAWnH+xtuBGxO7JxZEXwBRj0wgLr26TkC9mLxi/z3nv/mh3t/OOyUUL9zzecGBV8A55uHTzLSf/QrOy571gZfAPcsvSegULSty8aB6gMBx/Q4ezhWd4w3z7+JzWGjrDVwiclIr+VQtNbsLN/JX07+hbNNZ2f8FMZgJ+EoAr4IZAOvASilMoH2IJ9HCCGEEGJKlbeUU9NeA8DTJ54mKjSK3PjcgGNauluM2+nR6cYUvbEmV5gJUqNSUUqhtaapq4k+dx+h5tCp7pbhYPVBo+ZVa3cr5S3lRkHiofhragFsztnM/qr9uDwumhxNtPW0DZm58kLrxQAsJ252TC0dTkxYDA+sfIBdFbt4peQVAN4ue5uFyQspay3jVMMpzjefN4LYt86/NaiN8tZy3B73mC9C7K/az6ulrwJwpPYISRFJbMzeyLqsdTMy2A12jz8N3ATkA1/3bbsOeD3I5xFCCCGEmFIOp8O47fK4ePLYk7R0tQQcY3PYjNs3F97M2jlrWZmxctZMvwJvqvXE8ETAO1LR0NEwxT26qNJeyfNnng/Y1tA5fP+01gGFsxenLg4IqodLPNF/BGy2B2B+G7M3Eh8eD0CXs4vv7f4ez556lhJbyZAjiP31ufuobq8e03kcfQ7eOP9GwDZbl439VftRzMwM2kENwLTWx7XWW7TW12itq3zbfqu1fiiY5xFCCCGEmGr9U36DNyD73dHfGdsHpqBPjU7l/Yvez51L7sQaMrsSRPdPxFHZVonbM/IX8MnQ0NnA74/+flAwMFIAVtdRZySViLBEkBWbxbyEi3W8Bk6d01qzq2KX0aZJmZgTOydYT2FaCzGFcF3+dcPuT4kcnKI+0nKxRMFb59/i5bMvs6tiF8frjlPeWk5LV8ug4tBvnHvD+J2KDI00fnc25WyasSWMgl4HTCkVAcwHovtv11rvDPa5ppJU/575Zvr8YSGEEFNrqLTkTY4mnjr+FB9a+SG6nF3GeiNriDXgy+dskx6dzvH64wC8dPYldpTt4Krcq9iau3VKvi81dzXz+KHH6XJ2DdpX31lPeWs5r5W+hkd7iA6NJtrq/ekfnOUn5mNSJvIT843pb+eaz+F0O7GYLXi0hxfPvsi+yn3GYxYmL5x1wfVIlqct52D1QSMpR3ZcNktSl7AoZRHx4fE8eexJo24YwLa523jp7EuA97Xsnx2xv/jweO5YfAdRoVEcrDlobL9j8R3kxedxtPYoK9JXTNjzmmhBDcCUUu8DfsfgpBsamB0rTQGLxUJnZydRUVEShM1QWms6OzuxWEbOhCSEEEIMp8fVY9zOjsum0l4JeL9YvlD8AsvTlxv7kyKSZvV3hoEFfLud3bxa+ipNjiZuW3TbZRUjvhTPFz9PZ18n4A1+719+P48ffhzwTgt99tSzI5YIAIx1YunR6cRYY2jvbafL2cXR2qOszFjJ0yeeDggucuNzuX3x7RP0jKYnpRQfXvVhatpqSIxIJCYsMAS4deGtVNgrcPQ5KEgqYHn6ct4498aoiVBau1t5/szzzE+eb1wwL0gqYH7SfJRSbMjeMGHPaTIE+7fhO3jrf/1Ma+0Y7eCZKiEhgZaWFjo6Rq97IKYvi8VCQkLCVHdDCCHEDNU/AFuVsYqCxALePP8mAAeqDwSsF0qImN1/b+YmzKUwqZASW4mRkAO8CRNau1v54PIPTlpdLJvDRqnN+9orpXhw5YPkxecRGxZLW08bLo9r1ODLYrJQkFhgtLEld4sxcrOzYidH644aATfAktQl3LnkzlFT3M9GoeZQ8hLyhtwXbY3mHzf+I2UtZRQkFhARGsGHVn2I0w2nCQ0JxWKy0NnXSXtvO+097d5/e9vRWtPoaKS1u9Voa2PWxllzESPYAVi61vq7QW5z2jGbzSQnJ091N4QQQggxhfoHYNYQK2sy12DrslFUVwQQ8OVxUcqiSe/fZDIpEx9e9WFcHhcAfz39V47WHgW8Ge8eO/AYD658kKTIpAnvy76qi1MCFyQtIC/eGxykRqXS1tMWcGxufC4bsjbQ0ddBR6/3p8/dx6qMVUSGXpwyuiZzDW+XvU2Xs4vW7taA93ZT9ibeM/89syY4CLZoa3TAaHBefJ7xngzl2VPPcqjmEOAtgA3etV/5ifkT29FJFOwAbLdSapnW+niQ2xVCCCGEmFb6rwELCwlDKcXti26ntauVyjbv6IhSihvyb2Bp6tKp6uak8k81/MDiD5AUkcTr57yJsG1dNh478Bj3r7h/UKr+YOp19XKk9ohxf33WeuN2WlRaQIZDgKWpS1maNvp7Yw2xsil706BsfLOpoPB0sXbOWiMA81uWtmzW1M2D4Keh3w38VSn1/5RSH+r/E+TzCCGEEEJMqf4jYOEh4QBYzBbuX3k/C5MXkh2bzUOrHuKqvKuuuNERpRTb527nnmX3YDF5p+V1Obv49eFfc6zu2ISdt6iuyAiMkyKSAkZNUqIGZ+UrTCocc9sbsjcQbvG+zyGmEO5Zdo8EXxMgMyaTtOi0gG0zOeHGUII9Avaw799HBmzXeJNzCCGEEELMCj3OiwFYmCXMuB0VGsUDKx+Yii5NO8vSlhEXFscfjv0BR58Dl8fF0yeeprmrmWvmXhPUwFRrHTD9cH32+oD2U6NSA45Pikga19q8cEs4H1n1EU40nGBp6lIyYzMvv9NiEKUUazLX8ELxC4D3fcqMmV2vddBGwJRSJuC9QKHWOm/Az+wp9y6EEEIIAXS7LtYBCwsJG+HIK1t2XDZ/v/7vA+pCvXX+LQ7XHg7qeSpaK4w08qHmUFalrwrYnxyZjEld/Oo7ntEvv8zYTG4qvEmCrwm2KmMVc2LnYDFbuKHghlk3ghzMKYgaOAhMfeU9IYQQQogJ1n8N2JVU++lSxIfH84l1nwiYEnii/kRQz/Fu1bvG7ZUZKwNGJcE7PTQp4mISkEsJwMTksIZYeWTdI3z56i+zOHXxVHcn6IIWgGlvvtHzQOpoxwohhBBCzGQuj8vI+GdWZmOdkxhemCWM2xbeZtyvaa8x0tVfrraeNs40njHu90++0d+2udsINYeyIHkB8xLnBeXcYmIopWZV4o3+gr0G7L+BPyqlHgUqAI9/h9a6cpjHCCGEEELMKP0TcPgzIIrRxYfHE2GJoMvZRbezm9bu1qDUSDtQfQCP9n7tzIvPG7Tey29F+gqWpS0LmIooxGQLdgD2K9+/b+GdkgigfLdnZwgrhBBCiCtO/wQcVotMPxwrpRQZMRmcaz4HQHV79bgCMJvDxlPHnyLCEsH9K+7HGmLF5XFxsPqgccyG7A0jtiHBl5hqwf4E5vX7mev78d8WQgghhJgVBo6AibHrn9Gurr1uXI/dUbaDuo46zrec563zbwFwsuEkjj4HALFhsbO+6LWY+YI6Aqa1vhDM9oQQQgghpqOhaoCJscmIyTBu17TXjOux/WuI7ancw83zb2Z/5X5j29o5a2WES0x7QQ3ARiq4rLWWOmBCCCGEmBVkBOzS9R8B8yfiGOsaOpMyGWu9tNbUtNVQ2eZNM2BWZtZkrgl+h4UIsmCvAfvagPspvnPUIIWYhRBCCDFL9A/A/n/27js8ruu69/53T0HvHSQIEmxgATslipRkSZYt9xa32JYT24mvnXqT3Dj9TXNuyk2vvvaNHfdYLpJl2XJTr+wdJAgSRCF678Bgyn7/GMwhBoUEwMGg8Pd5nnmIOXPmnD0clFlnrb22WtDPTVZSFqneVIb8Q4wGRuka7iIvNe/mTyScbRzyDzn3f3z5x87XO4p2kJ6YHvPxisRarEsQyybeN8Z4gL8CLsfyPCIiIiKLaeIaYMqAzY0xhlWZq7jcGf542NzfPKsALBAKRAVfADXdNc7Xd665M7YDFVkgC1oka60NAH8M/MFCnkdEREQknqJKEL0KwOZqchnibAz4BmZ8LC8lj9LM0lsel0g8xGOWYiaQHYfziIiIiMTFxDb0yoDN3ar06404WgZm1wmx39c/42N7Vu3RWmyybMS6CccfT9qUCrwT+FEszyMiIiKymEYCI87XmgM2d0XpRc7XrQOts2rE0T86fQBmjGHPqj0xHZ/IQop1E44HJt0fAL4G/GOMzyMiIiKyaCbOAVMb+rnLSc4h0ZOIL+BjyD/EgG+AjKSMGz5npgzYhpwNZCZlLsQwRRZErJtwTA7ARERERFYctaG/NcYYCtMKaegNt5BvGWi5aQA20xwwtZ6X5Samc8CMMYdn2P5SLM8jIiIiEk/n287z5KUnnTK4Ef/1EkQFYPNTnF7sfD2beWB9o33O12/d8lYeWP8Ab9/6dioKKxZkfCILJdYliNtn2L41xucRERERiYuekR6+cfYbWGtpG2zjo/s+qnXAYmBiANY62HrT/SeWIOan5nOw9OCCjEtkocUkADPG/Nz4l25jzIeBibMoy4GuWJxHREREJN6u9V7DWgvAla4r9Iz0RK8Dpjb08xIVgA3MLQDLSLxxuaLIUharDNifjf+bCPz5hO0hoBX4tRidR0RERCSuBsai5x6daTmjOWAxUJBWgDEGay2dw52MBcdIcCdMu6+1loHR6++Dmm7IchaTAMxaWwZgjHnSWvvmWBxTREREZCnoGemJun+s8RghGwLA6/LiccV6RsftIcGdQG5yLp3DnVhraR9spySzZNp9R/wj+EN+53kq+5TlLKZNOCLBlwkrvtn+IiIiIktd70hv9P3R6/cVCNya4ozZNeJQ+aGsJLHugphsjPkcMAJcGd/2DmPMH8byPCIiIiLx0jPaM+NjKj+8NUVp1xdkbu5vnnG/iQGYyg9luYtpAAb8HbAWuA/wj287CXwgxucRERERiYvJGbCJ1IDj1pRmlTpf1/XUTbtP93A3R64dce4rAybLXayLlt8O7LLWdhtjQgDW2mvGmNUxPo+IiIjIghvxjzgNN7wuL3evu5vnrj7nPJ7qTV2kka0MJZkluI2boA3SPtTO4NggaQlpQLjxxjNXn+GZmmeinpOelL4YQxWJmVhnwLxA/8QNxphkwiWJIiIiIsvKxPleWclZvH7j6/nEnZ+gJLOEFG8Kd5XetXiDWwES3Amszrx+nb6+px4IB19PXnpySvAFUJymNgOyvMU6A3YM+ATw7xO2/RxwOMbnEREREVlwE8sPs5KzgHDZ3C8d+CWstRhjpn+izNq67HU09DYA4TLErQVbeazyMU42n3T2KUovIi0hjZLMEiqKKhZrqCIxEesA7FPAC8aY9wGpxpgfAfuBQzE+j4iIiMiC6x7pdr7OTsqOekzBV2ysy1rHC7wAwNWeqzxy9hHOt513Hq8orOC9O96rdv+yYsT0O9laW2WM2Uo461VJeBHmj1trr8XyPCIiIiLx0Dfa53ydnZx9gz1lvtZmrXUWZG4daKV1oNV5bO+qvbxr+7twmVjPmhFZPDELwIwxXqAeWG+t/cdYHVdERERksUSVICZlLdo4VrIkbxLF6cVT2tAfKj3Em8vfrEyjrDgxu5xgrfUTbj2vnxIRERFZESaWIEbmgEnslWWXRd1/7YbXKviSFSvW+dx/AP52PBsmIiIisqxN7IKoEsSFs2/1PtzGjcu4eNPmN/HghgcVfMmKFevZjL8BlAC/aIxpBUKRB6y162N8LhEREZEFYa2lrreOEX94JR2vy+usTyWxV5hWyO/e97sEQgEykzIXezgiCyrWAdifxvh4IiIiInFhraWpv4lzrec413YuqgFHZlKmMjILLDVBi1rL7SHWXRC/FMvjiYiIiMTDyeaTPFPzDD0jPdM+rrWnRCRWtKCCiIiI3HaONx7nZPNJ7l13LyWZJTxW+RghG4raJ9mbzLaCbews2smGnA2LNFIRWWkUgImIiMiKd6zxGIcbDnOw9CCb8zbz3YvfxVpLe2U7byl/ixN8JbgTqCisoKKwgo25G3G73Is8chFZaRSAiYiIyIrWPdzN4xcfx1rL4xcf52DpQay1AIz4R3ih9gVn33vX3ctrN7x2sYYqIrcBLSsuIiIiK9orDa84AVfIhni5/uWox9uH2p2vy3Ki16MSEYm1mAdgxhi3MeaQMeb94/eTjDGJsT6PiIiIyM2M+Ec40XRiVvt6XV7WZK5Z4BGJyO0upgGYMaYMOAv8GPjC+OY3A/8vlucRERERAbjQfoF/eeVf+OmVnzpZromONh5lLDg2q2OtzV6Lx6XZGSKysGKdAftX4HEgC4j8tnsWeE2MzyMiIiK3OWst37v4PdoG23ju6nNc67sW9XggFOBww2HnflFaUdTjCe6EqPvrstct2FhFRCJiHYAdAP7EWhsELIC1tgfIjvF5REREZBkLhoIcazzGpY5LUduHx4b54aUfzqpssKm/iQHfgHP/1YZXox4/13qOfl8/AGkJaTy852FcJvzRJ9GTyGvWRV8fXp+zfl6vRURkLmKdZx8CUgBn6XhjTD7QFePziIiIyDJlreVb57/FudZzADy8+2G2FmzFWssj5x7hStcVIJyxWp25esbjXOy4GHX/fNt53jT6JjKSMrDW8lL9S85jB0sPkp2czbsr3s2JphMcLD1IXkoeT9U8BYSzYSUZJbF+qSIiU8Q6A/ZD4J+NMUkAxhgX8BfAEzE+j4iIiCxTh68ddoIvwJm/Vd1Z7QRfAJe7Lt/wOFUdVVH3QzbEkcYjANR019A60AqA1+3lzpI7AdhdvJtf2P8LbCvYRn5qPneU3IHX7eV1G1+nNb9EJC5inQH7PeC7QDeQSDgTdhF4fYzPIyIiIstQY18jP7z0w6htbYNtnGk9w3NXn4va3jzQPONxekZ6nABromPXjnF/2f1R2a+9q/aSkpAyZV9jDO/c9k7esfUdGGPm9kJEROYppgGYtbYPeMAYsxfYCLQCL1k7vry8iIiILEuRhhc9oz28pfwt5Kfmz/kYw2PD/PeZ/yZogwB4XB4CoQAA3zn/HUKTPi40988cgE2cO7YxdyNdw130jPQw5B/iqStPcbkznD0zxnCo9NANx6XgS0TiKdZt6O8HsNaetNZ+01r7goIvERGR5a+yvZKjjUe53HmZL5/6Mr6Ab07Pj8z76h3tBSDJk8T/uON/kOgJLxU6OfiCcJZrcGxw2uNVdV4vP9yav5UDaw449ydmv7blbyMvNW9OY12O/H4/gUA4mA0EAgwODhIMBmfc31rL0NAQLS0ttLe309vbO20bfxGJvViXID5hjGkFPg980Vo7tTZARERElp3Gvkbn6+7hbh678Bjv3/H+WWePnq99nurOauf+eyrew+rM1bx2/Wv5YXW4JNHj8rC9cDvtg+20DLQA0NTXRHl++ZTjTSw/3Ji7kRRvCk9feRp/yB+1393r7p79i1xmAoEALS0tNDY20tXVhbUWj8fjBGJut5u8vDwKCwvJy8tjZGSEnp4e5zY2Fr0+2tatW9m4ceNivBSR20qsA7Bi4GeBjwF/boz5EfCfwPeVCRMREVm+IgFRxLnWc2zI2cAdJXfc9LlXu6863QYB7l13L1sLtgJwz7p7KM0qJWRDlGSW4HF5eKLqiesBWP/UACwQCjiZMWMM2cnZuF1u9qzaw9HGo85+azLXUJpZOr8XvESFQiE6OjpobGykra3NyXK5XC6MMQQCAVwuF4mJiYyMjNDW1kZbW9u0x0pMTCQzM5NQKERnZyc1NTWsW7cOj0eLUYsspFjPARskHHD9pzFmG/BR4HNAEJi5j6yIiIgsadM1vPhB1Q8ozSqlMK1wxucN+AZ45OwjTnnbuux1vH5jdG+u0qzoIGliO/iJmbeJx4wcLz0h3eleeFfpXVEB2N1r714x87v6+vq4du0azc3N+HzXyz9zc3NZvXo1q1atwuPx4Pf78Xq9GGMYHR2lvb2d9vZ2urq6SElJITs727klJydjjMFayyuvvEJ3dzf19fVs2LBhTmMbHR3F5/ORmZkZ65ctsiIt5CWOOsIdEOuBvQt4HhEREVlAg2ODTsbJ4/KQlZhF22AbgUCALx/7Mh/d9VHSUtJISkqKep61lscqH3Oem5qQyvt3vH9Ku/exsTFcLhcej4dQKERKIAXfqA+P10NjXyPW2qhAKjKPDCAjMYOhoSFSUlIoTCtk3+p9nGg6QVl2GdsLt8f8/yIYDOL3+53X2tzcTFdXFwUFBeTn5+NyTT+9vqOjA5/Px+rVq+cUFAYCAS5cuEB9fb2zLS0tjZKSElavXk1KSnR3x4SEBOfrpKQkSktLKS29cRbQGMOmTZs4cuQINTU1rFmzxgnibqStrY1Lly7R1xde/nXv3r2sXq3r7SI3E/MAzBhzEPgF4H1AC/BfwDtjfR4RERGJj8aeRgYGBhgcGCSddDZlbuJ012mCNkgTTfxz0z9zZ+ad5ObmUlZWRnFxMQCnWk5xqfMSY2Nj+Mf8vKn8TfR19NFH+AN7KBSitbWVjo4OALKzsxkcHMTn89HV3oXf+nEZF0/4nyA/PZ+kpCSSk5O5OnSV3t7e8BymDnim4xlWrVrF3r17eee2d3Jf2X1kJGbgMrHrNTY4OEhVVRXt7e2EQiE2b95MYmIiZ8+eBaCurg6Px0NhYSHFxcXk5+c7pXwDAwMcOXIEay3d3d3s2LFjVkHY8PAwr776KsPDw7hcLtauXUtJSQmZmZkxz+zl5+eTlZVFb28vP/7xj/F4PKxevZrS0lJSU1PxeDxR52xsbOT06dNYa3G5XIRCIc6dO0deXh6JiYkxHZvIShPTAMwYcxEoBR4F3matfT6WxxcREZH4GRoaoqamhqcuPUV3bzcA2anZ5CXncVfuXRzpPYIxhqZgE+eHztPe3Y6ttnxwzwcp31zOD6p+QG9vL319fWxK2UTP1R566JlyHpfL5QQnAOnp6az2raahv4FQKMSFrgts913PZl0YvEDfYDiIS0pNwhhDc3MzaWlplJeXk5uSO+Uc1loCgQBer3fO/w/WWo4dO8bg4PWOjJcuXW+DX1JSwsDAAH19fTQ1NdHU1ITb7aaoqIiKigoqKyudksn6+nr8fj979+69YRA1OjrK4cOHGR4eJjMzk927d5ORkTHnsc+WMYbt27dz9uxZRkZGCAQC1NfXR2Xe3G43Ho8Ht9vNyMgI1lo2bdrEpk2bOH78OO3t7Zw6dYrCwkJcLherV6/WfDKRacT6p+JfgK+PrwcmIiIiy5C1ltraWqqqqggGg3T5ukhKSiI9PZ037HkDB9cexFpLzrkczraGM0D9oX6Cg0F6env44fkf8mLNi9T01hAIBkjzpPGGzW9wWs5PlJGRwZo1azDG0NPTQ2JiIhkZGWS3ZvOtc9/ChixDDLF7126s3zI6Okp9bT1Zniy8Xi/3bLuH7VnbOXr0KNXV1aSnp7Nq1aqo19LS0kJNTQ29vb3s2rXrpiV5k7W1tTE4OEhycjJ33303g4ODnDp1Cp/Px7Zt25w5U0NDQ7S2ttLS0kJPTw9NTU10dHQwNjaG1+tl165dnD59mubmZjweDzt37pw2CAsGgxw5coShoSGysrI4ePBgXAKZnJwc7r//fiCc8aurq6O1tRW/308wGHRuEA7YJnZN3LlzJ8899xwdHR1ORvPixYusX7+esrKyeQW+cnuz1joZ1pUm1k04PhPL44mIiMjCsdYSDAYZGxsjEAjg9/vp7e2loaHByfaUlJSQnZ4N4x3LV2WGgxtjDO/c9k6a+pvoGu7C5XKRnpGON8FLa3crrjEXgWAAj9vDhw99mLvK77rpeAoKCpyvdxbt5JmaZ+ga7iJEiMvDl3nthtcCcHjwMJkm3PChILOAgoICtm3bRmVlJadPnyYlJYX09HSuXbtGTU0Nw8PDznGrqqpYvXo1bnf0PLQb/R9duXIFgA0bNpCcnExycjL3338/o6OjUVmp1NRUNmzYwIYNGxgaGuLkyZP09vYCsGXLFoqLi0lMTOTw4cM0NDRgjGHz5s1T5s7V1dXR399PamoqBw4cWJQsUlpaGhUVFVRUVADXv1eCwSCBQAC32x017uTkZPbt20djYyNer5eBgQG6urq4dOkSNTU1lJWVsX79+qg5aiIzsdZy/PhxOjo6KC8vZ/369SumoQ7EIAAzxvzAWvuW8a+fBaZdxc9a+9pbPZeIiIjM3/DwMLW1tfT29jI4OIjf759x8d2kpCR27txJbn4ujz79qLO9KK3I+TrRk8jP7vxZvnLqK/T7+p3nJRQlEAgESDWpJCUksX/D/jmP1WVcPLD+Ab59/tsAvNLwCodKD5HkTaLPd73QJjMpHIiVlZUxMDBAQ0MDR48exVrrrHMVCYzq6+vp6+ujoaGBsrKyWY2ju7ubnp4eEhISWLNmjbM9ISHhhsFEamoqhw4dorq6mkAgwNq1a4Fwlmn//v0cPXqU+vp6GhoaKCoqorS0lPz8fAKBAJcvXwagoqJiyQQsxhg8Hg8ej2fGOV4FBQVRQXRXVxeXL1+mo6ODy5cvc/XqVdatW8eGDRsWZZ7Y6OgoCQkJc86ohEKhFZmFWcouXbpEa2u48+qFCxdobW1dtIsRCyEWr+KlCV8/zwwBmIiIiMRHIBBgYGCAgYEBxsbGWLVqldNqfHR0NGpfj8eD1+t1/k1OTmbVqlUUFBTgcrlo7m8mNL6UZ3Zy9pQywlUZq/ite34Ll3Hx32f+m4sdF3G5XE7gUJZTNm3p4WzsKt7Fs1efpWu4ixH/CK9ee5UH1j9A3+jUAMwYw44dOxgaGqKrqwuArKwsNm7cSFFREcYYEhMTOXbsGFeuXKG0tBS3283g4CDXrl1j3bp1JCcnA+Gr7z09PdTV1dHSEl6PbD7rY7ndbrZu3Tple0FBAYcOHeLq1atOyWJLSwspKSmkpKTg9/vJzc0lPz9/Xv9vS0Vubi65ubn09PRw+fJl2traqKmpoa6ujnXr1rFly5a4BTb19fWcO3eO1atXs2fPnlk/L9JsZOfOnXMuXZW5sdYyODhIW1sbly9fxhhDeXk5dXV1dHd3c/ny5Wl/npajWw7ArLV/NeHrP73V44mIiMiNDQ8P093djdfrJSEhgaGhISfgGhgYiCq5g/DVZI/Hw9jYGLm5uWzcuJHMzEwSEhJuWtZT11vnfL0qfdW0+3jd4fk95fnlXOy4GPXY5rzN83iFYS7j4v719/Od898B4OX6l9m/ej8j/hEg3BI/LSHt+v4uF/v376euro7c3FxycnKiXl9hYSGZmZn09fVx5coVNm7cyNGjRxkaGqKxsZF9+/bR399PXV0dAwMDQDiwKy4unvPaWDeTk5NDTk4Oo6OjXLt2jYaGBoaHh533btu2bSum5Co7O5s777yTvr4+Ll++7MzJGx0dZc+ePQv+Ouvq6jh37hwATU1NbNu2bVYZuJGREc6dO4e1lqqqKmetNYmNSMDV1dXl3CaucbdlyxY2btxIfn4+L730EjU1NZSUlJCenr6Io46NWHdBbLbWTvntbIxpsNbqsoGIyDJgrcXv9zM4OMjQ0BCA04Y6GAzS09NDe3s7fr8ft9uN1+slKSmJxMREkpKSor6ezQd8mZ2xsTEaGxtpbGx01l2aicvlIi0tjYyMDILBIK2trYyNjZGTk8Odd945pw+RF9uvB1Sb8jbdcN/pgq3yvPJZn2s6u4t38+zVZ+ke7mbEP8KPqn/kPJaemD7l+yshIYHNm6cP+owxbNu2jcOHD1NdXU1XVxdDQ0POosUvv/yys29iYqKzhtbktbZiKSkpiU2bNrFx40Y6OjpobGwkIyODrKysBTvnYsnMzGT//v10d3dz5MgRmpqaMMawe/fuBfk94ff7qays5Nq1a0B4ntrIyAhNTU2sX7/+hs+11nLmzBkCgQAAPp+Puro6p+mI3JrOzk6qqqro6YnuipqUlERubi6FhYVOM52srCxKS0upr6/n1KlTTpnrcp5TGOswfqaQdPmHqrLk+AI+flT9I9wuN2/c/EY8Ll2VEpmvSBnU0NCQMzcoFiJlX0lJSRQUFFBWVrZs/2AuFmstdXV1XLhwgVAoXAro8XjIzc3FWovP53OaTmRkZJCenk5qamrUB9r+/n66urpYs2bNnIKv4bFh6nrqgPB7uSV/yw33z0zKpDCtkLbBNgByU3LJS82b4yuO5jIu7i+7n0crw/PQTrecdh7LSsqa8/Hy8vIoLy+nqqqKrq4ujDHcfffdXL16lebmZnJzc1m3bh1FRUVxnfdjjJkyh2qlysnJ4cCBAxw5coTGxkaSkpJiXlrW3t7utNR3uVxUVFQ4JaiROYB+v99ZAHwiay2XLl2io6ODhIQEtm/fzqlTp6ipqZlXKertbmBggMbGRtavX09iYiKXLl2iuroaCF8wyc/Pd8pVJ//uitiyZQstLS309fU5F6DWrFmzbP+exOQ7yBjzx+Nfeid8HbEZqEckxg5fO8zRxqMAJHuTeXDDg4s8IpGFFQqF8Pl8GGOmdE27mUAgQF9fH4ODg/T19dHd3Y3b7WbLli309vZSVVUVtb/H4yEtLY3U1FQg3F47MhE9NTWVwsJCUlNTnQ56o6Oj+Hw+RkdHo76OPDY6Okpvby9Xr16lvLycsrKym17xttYyPDx8w0n/K1EoFGJ0dJSRkRFGRkac4BjCc4dKS0spKCiYdRc/CLd6n88aUpc6Lznzv9ZkrCE98ebXU8vzyp0A7FazXxGRLFjPSPTV8vkEYAAbN26kv7+f5uZmNm/eTHZ2Nvv27WPnzp1qlx4nkWYkR44c4cqVK6SmpsZkjlUgEKCyspKGhgYgXP64e/du0tLSCIVCJCYmOgtjR9rlJyYmkpycTEpKCqmpqQwNDdHc3Iwxhp07d1JUVER9fT3d3d3U1tayadONM8FyXWQxcZ/PR1dXF1u3bo2a31VWVjargDYhIYEDBw7Q0dHhNA5azj+rsQrhH5hwvAcmbA8BrcDHYnQeEceRa0ecr5+peYZ7191Lgnt5XgkRiQgEAnR0dDAwMMDg4CA+n8+5RTq6QbghwLZt2274IXx4eJi2tjba2tro6upysicTHT58GAhffd+0aRN5eXmkpaXFrHQwEkwMDg5SW1tLe3s7lZWV9PX1UVJSwtjYmHPz+XwEg0FWrVpFfn4+Z86cobGxEQh/QNq+fTurV6+e8xistYRCoTkFLPE2MDDAhQsX6O/vx+fzTelM6PF42LVrV9T6VvFwof2C8/XWgtllKO5edzd1PXWECPGastfEZBxul5v719/PY5WPRW3PTM6c1/GMMezdu5fy8nLS0q7PIVvOH+iWo/z8fHbs2MHZs2c5d+4ceXl5t1Tu2dHRwZkzZ5ysV3l5ORs2bHB+l7lcLkpKSqipqaGjo8PJcEZ+x0aWDIBwA5X9+/c7Gcny8nJeffVVJws20/dKV1cXFy9eZGRkBGMMBw4cWBFzlm4kFArR0tJCIBDAGIPL5cIYgzGG6upqZ15XT08Phw8fxlrLxo0b5xzIZmVlrZjS3JgEYNbaBwCMMZ+x1v5SLI4pciPWWnwBX9S2082nuXPNnYs0IpHphUIhRkZGsNbidrtxuVy43W4nGPD5fE6mo6enh2vXrs1Y/meMISEhAb/fT11dHT09Pdx5551R2bDh4WHq6+tpa2tzmghEnpuZmemUqWVnZ9Pd3U11dTXWWvbs2bMgH+5dLpfT2a2goICWlhZOnz7tzGWaTqQkaXR0FLfbjTEGn8/HqVOnCAaDs75K3tbWRnV1NYODgwQCATweT9T8tMiCvyUlJYs6T625uTlqrokxxllrKnJVvqSkJCpQiIex4BiXOy8797cVbJvV89IS0vjEgU/EfDx7ivfw3NXnorJgmYnzC8Ag/P8c7/9TmWrt2rV0dXXR1NTElStX2Llz55yPEQgEuHDhAvX14YKrrKwsdu/ePW3gU1ZWRldXF+np6WzevJnk5GR8Ph9DQ0OMjIwwPDyM3++npKSEzMzr31+RErmuri5qa2unnWfo9/s5ceJEVCOJK1euzKnr4nJjreXEiRNOy/jppKWlsX37do4dO0YoFHL+729nsV6IWcGXxEXPSA+jgehWyi/Xv8wdJXdowr/clLWWQCDgZF0m/puWlua0rI7s29vbS2Ji4g2vzAaDQerq6sjIyCAvL4+Ojg4uXbpEf3//tJknCH8AnG4NpuzsbHJzc0lLS3MChcTERCcr1dvby4kTJ+jr6+Po0aMcOnQIj8dDZ2cnx48fdwI4j8dDQUEBhYWF5OfnTynjy8nJYc2aNQSDwQVtMjBRcXExqampXLx4kVAo5KylFHl9fr+fK1euMDo6SmJiIgcOHCAjI4MrV65QVVXFmTNn6O/vp7y8/IbZir6+Pk6cOEEwGATC/9eBQIDBwUFngeEIr9dLUVHRdIdZcJ2dnZw4cQKA1atXs2XLFpKSkpbEmkPnWs/hD4W/lwpSC255Ltetcrvc3F92P49duJ4Fi7Sgl+Vt8+bNNDc309DQwMaNG+f0+ygQCPDiiy8yODiIy+Vi8+bNbNy4ccbPAsnJydx7771R2yLNg24kUjL3yiuvUFNTQ35+PqmpqXi9XudcVVVV+Hw+cnJy2LZtGy+//DJNTU1s3bp1zmXjy8WVK1dobW3F6/VSXFyMtTbq5vF42LRpEykpKezatYu6ujp27NixpCsS4iHmswiNMb8AvA4oAJzvfi3ELLHU2D/1ynnncCeXOi/NOEncH/RztPEouSm5N51ILivX2NgYR48endJ5aaL09HTnA3lzc7PTJW3dunWUlJSQkJDgrJsUyc4cPXrUKV9JSUmJagOenJyMy+UiGAwSCoWcf621ztyDyG316tU3LbHIysrinnvu4eWXX6avr4/Dhw+TkpJCc3Mz1loKCwtZv349OTk5N/0gvxhzqzIyMjhw4MCMj69Zs4bm5maKi4uddZk2bdqE2+3mwoUL1NbW0tzczLZt21i9evWUD1pjY2McP36cYDDImjVr2LZtG16vl0AgEDU/rbOzk2vXrlFTUxOTAKyrq4vR0VEyMzNnnEg+kbWWyspKIDwnacuWLUvmAlIwFOTZq88693cV71rE0Vy3e9Vunqu9ngXLT13e62RJWFpaGqtXr6axsZFz586RlZUV9bPq8/nIyspi3759U36nNTU1MTg4SGpqKvv375/XXMfZiqzN1tHRwUsvhZfB9Xq9Tpa/tbXVmTeWnp5OcXExzc3N1NbWrpj1qyZqa2vj0qVLTknvzRrIlJSUUFJSEqfRLW2xbkP/58AvAV8D3gF8DvgQ8NVYnkekqa9p2u2nW07PGFx9p/I7nGs9hzGGX9j3C5TllC3kEGWOAoGAU4oXKQMZGRkhFApRVFREQUGBMzcmPX1q6+nZnuPIkSP09vbidrudrEvkX6/XS2trq7OWUkRSUhI+n4/a2lpqa2ud7cYYPB6Pk1FLTk4mFAoxPDyM2+2mvLyctWvXTjvBOJL5mu8H7kh26KWXXqKnp8cJKDds2MDWrVuXzAf5+UhKSpq2RfT69evJy8vj3LlzdHd3c+rUKerr69mxY4fzoSsQCHDs2DGGh4fJysqKutLq9Xrxer1OWVJRURGtra10d3fT3d1NTk7OvMYb6Zh2+fL1cj2v10tOTo5TtpSZmTnlPbl27Rr9/f0kJyezefPmJfWenW457QQ5Kd4UDpYeXOQRhXlcHj6w8wP8tOanbMzZSE7K/N4zWXo2bdpEU1MT7e3ttLe3T3m8tbWVCxcuUFFREbU90mxj8+bNCxp8RVRUVHDp0iUGBwedcsWJnfk2bNjg/I5Zv349zc3N1NfXs3HjxnnNMayrq6O9vT3qb1Xk3+zsbLxeL9Zazp07RzAYZPPmzU7zpIU0NDTEqVOnsNayZcuW26J7ZyzFOgP2YeCN1toTxpifs9b+hjHmO8Cvxvg8cpubmAF73cbX8dSVpwCoaq/CF/CR6Im+ql/fW8+51vAijNZaXqh7QQHYAhkeHiYUCuHxePB4PM4cnghrLX19ffT29rJ69Wq8Xq9TXjZdOR7gdICLSElJYfXq1U5W5GY6Ojpoamqiq6uL4eFhUlJSuPvuu6ctCdm6dSstLS3O68jIyKCoqIiBgQGqq6sZGhpyyhcDgYBT7hfp6OV2u2lrayM7O/uGZTSx+LCdmprKoUOHaGlpITk5mYyMjKg5CytRRkYGhw4doqmpiQsXLtDd3c0LL7xAaWkpOTk5zty45ORk5/2YicfjYd26dVy+fJmqqioKCwvxeDyUlpZijKG/v5+RkREKCgpmfL/6+vqorq52rnzn5+fT39/P6Oio0wAlcq5IQJadnc3Q0JDTeXLr1q1Lqhxncvbr7rV3T/mduphWZ67mI3s/stjDkBhLS0tj165d9PT0RM3TTEpKYmxsjGPHjlFbW0tycjIFBQWkpaXR399Pb2+vU/4Wr3Hu27cPCP89GxsbcxbQDgQCrFmzxtk3OzubnJwcuru7eemll9i/f/+cGnKMjIxw/vz5Gf82JiYmct9999HV1eXMf2tubmb9+vULmlGPXOjy+/0UFxdrbbR5iHUAlmetPRG5Y4wx1toXjTHfjfF55DY04BvgO5XfwRfw0dDb4Gzft2of51vP0zrYij/k52LHRXYX73Yet9byw0s/jDpWdWc17YPtFKTpik2sBINBzp075yx4GWGMwe124/F48Hq9BINBpzyvvr6eNWvWcPHiRYwxpKamRjUeSE5OJhgM0tjYSH9/P0lJSc7zL1++THt7O/v3758x0LHWOsFdREpKCgcPHpyxHt/lck3baS8jI4P9+/dPOX4gECAQCJCUlOT8sZtPp775Sk9PX/EdtiYzxlBSUkJhYSGXLl2irq6O+vp65wNIcnIyhw4dcsoXb6SsrIyamhq6urro6uoCwhPp8/PzeeWVVwgEAqSkpLB+/fqoNbSCwSAnTpyICrD27dvnXAUeHh6mu7vbOe7Q0NC0V/ZzcnLi3tnwZi53XV6S2S9Z+dasWRMVwEy0fft2zp07x4ULF7hw4YLzNwLCpW2LcREjss5hYmIi2dnZ0+6ze/dujh07xsDAAC+88ALZ2dnk5+eTn58/bWZ8orq6Oqy15Ofns2rVqqg5y729vQwNDXHhwgWn/D07O5ve3l6uXLlCf38/e/fuXZDOnjU1NQwMDJCenr5gi2ivdLEOwFqNMcXW2hbCa38dMsZ0xvgcchuy1vLt89/mSteVqO0ZiRlkJGWwo2gHrVfCHXjOtJxhQ84GrvVdo6G3gfqeeq71XZtyzFcaXuGd294Zj+GveH19fZw5c4a+vj7cbjdJSUlOYBIMBp2vR0fDjVMSExNxu9309/c7c2AqKipYt27dtMefuN1aS1dXF2fPnqWvr48XXnjBKfWbPDegsrKS2tpajDFs3LiRwsJCMjMzY9bgwBjjlLVJ/Hm9XioqKigtLaWxsRGfz4fL5XImfM9GYmIiFRUVtLS0kJiYSGNjI1VVVVy9etXpnDg8PMz58+eprq5m7dq1rFu3jrNnz9LW1uZkzMrKyqLOGZkTEpnvMDo66gRjkaYuxcXFrFq1Kq4fXgZ8A7QMtFCWXYbXPf337cTW8/tW71tS2S+5fa1duxYIL7Dc19fnZJ2AmKwftlBSU1O55557qKys5Nq1a87vgaqqKrxeL3l5eeTn5zst+CO/D4LBoFNeWV5ePiXAGxoa4rnnnnO6yaakpHDo0CF6eno4fvw47e3tvPLKKxw8eDCmixUHg0HnYteOHTu0KPU8mZnSmvM6WHgOWJW19uvGmF8C/hEIAJ+31v7PmJ1ogRlj1gG1tbW1M34glPg63HCYJ6qemLJ9a/5WHt7zMN3D3fz9S39/0+OUZZdR2xOew+NxefjUaz5FWoLaEN+MtRa/3x/VLTByiyxmCuE/AHfccUdUHf7ELFEgEHDK+vx+v9MMo6ysbEpd/834/X5OnjzpZBTS0tLYtm2bUy7W3t7OkSNHcLlc7N27N27lKbK8Xbp0ierqaiB8NfngwYO0t7dTU1PjzLOLdK9MSEjg0KFDSzoDGbIhuoe7yUnJwR/088+v/DN9o33kp+bzgV0foDCtcMr+f/38XzM0NgTAJ+78BKVZS/fDrdyerLU0NDRw5coVpznHcjA2NkZXVxcdHR10dnYyNDQU9XhWVhZ33XUXXq+XhoYGzpw54zRdmu5CTXV1NZcuXQLCmbZI9nB4eJgjR44wODhIVlYWBw8ejFmgdO3aNU6fPk1mZib33nuvsl+EM5VlZWUAZdbautk8J9Zt6P94wtefMcacATKAH8fyPLIyWGt5rvY52gfbuav0LtZmrZ12v86hTn5U/SPnvtfldVojR+Zx5aTkUJpZSkNfw7THACjNKuXh3Q/zhRNfoKm/iUAowKWOS+xbvTx+cceL3++ntbXVmQcVCbRudLHG5XKxbt06Nm/ePCUbNFOWKPLhtb+/f17zlrxeL3feeSdtbW1cuHCBwcFBjh49Sl5eHuXl5Zw7F57zt2XLFgVfMmubN2/G5/MxMDDgzCErLi6muLiY7u5uampqaG1txe12c+eddy7p4Mtay+ePf566njp2F++mOL2YvtFwo4COoQ4+c+Qz3L32bvav3k92cvjqekNvgxN8pSWksSZz+nIwkcVkjGHt2rVOVmy5SEhIcH6fQDhQigRjHR0d9Pb2UlNTw+bNm7l69SoQLpOeKcjZsGEDHR0dTll2REpKCnfddRevvPIKvb29HD16lAMHDkwp04yU6ScmJrJ69eqblnFaa51xrV+/XsHXLVjQvKG19pWFPL4sb6dbTjvNM862nmV74XbetuVtpCde/0ATsiG+ff7bTsBVmFbIR/Z+hJfrX8ZiubPk+sLLryl7DV89HW646XF5WJ2xmtKsUtZkrqE0q9Q5bkVhBU394S6KNd01yyYAi3QJ9Pv9UbdAIIDL5XJWiJ9rHXykHboxhtraWqqrq50FYSfyer1T1myKfF1UVDSvdaQi454vY4zTIbGuro7q6mo6Ozvp7AxXPmdmZk7bTU9kJpEW0tPJyckhJyfHKXuK19pp89U13EVdTx0Q/n07sbQQwktzPHf1OZ6vfZ4NORvYt3of9b31zuNbC5Z3N02RpS4lJcUJJHt6enjppZeora0lGAwyMDBAamrqDeeIut1u7r777mkfS05O5uDBg7z88st0dXVx/Phx7rjjjqgS/ObmZmeOdFVVFRUVFTc8X1dXF/39/SQmJi65uavLzS0HYMaYL8xmP2vtx271XLJyBEIBnq55OmpbZVsljX2NPLz7YVJtKiMjI1QOVjrzt9zGzXsq3kNGUgZvKn/TlGNuLdjKb979m/gCPgrTC/G4pv/23pi7kR9fDidlr3RdcYKPeAkGg/T09DjndblcGGOcm8vlwuPxkJSUhN/v5+rVq7S2tjI4OHjDLBSEr65t3rx52vlQk/l8Pq5evUpdXR2BQAC32+0sWpubm8vq1avJzs52Aq2lsDDsTFwuF+vXr6ekpITLly87E5d37typD5ASc0s98IqIXGiKGAuOAZCakEqKN4WOoQ5g/Cp415Upc2y35q+8dYtElqrs7GwKCgpob293skw7d+68pb+9kaZTr7zyCu3t7Zw8eZJ9+/Y5fxcjTbMSExPx+XycOnWKtLS0Gdv5R8a1bt26Jf2ZYDmIRQZMn25kCp/PR19fH/n5+dN+AD5y7YjTZcvj8hAIhTMufaN9/N1Tf8d2ux2v8fJ0z9MkpySTlprGWyveyqqMG19xyUvNu+nYitOLSfWmMuQfYmhsiNbBVorT51eidrO1nCItasfGxkhLS2NsbIwjR44464XciNfrdRbtjZwjLS3NKeebeBsbG6Onp4f+/n7Onz/PhQsX8Hg8FBQUsGvXrqhflJHAK3KVLXLsYDBISkoKO3bsWLbreSQkJLB9+3bWr19PMBgkLU3z++T2NTkAizi45iCvKXsNVR1VHG86zuWuy1Mu7iS4E9iQuyEewxSRceXl5c685tLSUvLybv6Z5mbS0tI4cOAAr776Ki0tLZw+fZrdu3c7i9G7XC7uv/9+qqqqqK+v5+TJk9xzzz1T5owNDQ3R1taGy+VadqWfS9EtB2DW2o/GYiASP5Fsx61kBkKhkFMCFwwGncxNYmIiXV1dnDlzhrGxMfLy8ti7dy8JCQn4fD5GRkc43XSaH9X8iLHQGCkpKTy06SHyU/P5xplv0NTWxNDQEP2uftKS0giGggwODpLoS8R/1c8l/yXWrFlzS1egjTGsz13vrAt2sf0iHYMdFKQVUJReBISzVG1tbXR0dJCUlERmZiYjIyPO+j6R29jYmHPMyL+RYCcyUT9SzhcZ8/DwMMnJyaSmpmKtdW6RUkBrrdPoAqCgoIANGzaQnZ19w/JCay1tbW1cvHiRwcFBxsbGaGxsJCUlhfLy8mkDr8LCQjZv3kxmZiZjY2MkJCSsiIzRbNqPi6x0zf3NU7Z5XV7uXHMnbpeb7YXb2V64nd6RXk42n+RE0wl6R3sB2Fm0c8YqAhFZGFlZWaxfv57e3l62bo1dBjozM5MDBw5w+PDhqK6J1lqKi4udi5fd3d0MDAzw/PPPO50Zc3NzSUxMdLJfJSUlJCaqM+qtimkXxJViJXZBtNbS2tpKfX29c8UjIyPDWbg1IyOD9PR054qH3++nubmZoqIiEhMT6ezs5MKFC4yOjjqtxW/G5XIRCoWcf6+NXuP84Hn6A/3OPrmpufzJm/8Ej8vDi8df5LHaxxhjjNzcXFJSUsKd90bGeE3qa/AGwk0c3G43+/fvnzZL09zczNDQkLMux8RV4ycGL8ebjvNY5WNTnr8rexfr3evpaOuYdh7UfHi9XlwuFz6fD7j+i/BGv8AiQVgoFJpzsGmtJRgM0t3dzdGjR4Hw2ipNTU1TAq9bmX8lIkuXtZZPP/tpfIHw753tBdtp7G/kwQ0PzjjvNWRDXO2+Sr+vn4rCChLcsWtdLSKLr6uriyNHjkR9hjtw4IDzeWpgYIDDhw87S8ZEZGRkMDQ0RDAY5P7771/SzYcWw3y6IMa6DX0tMO0BrbXLZib8SgzALl++7Ey0jGRmJot0Fdq4cSPHjh2jr6+PlJQUtm/fzqlTp6ICkomd7Twej/Oh3+fzYYxh8+bNrFq1ipMnT3Km6QyVQ5UMhAZwu93OLegLclf6XRQkXA+k+kwf58w5PN7rV17fsfUd3FFyB11dXVy9epW2tjaMMezZsydqwdtI2/GZFBUVsWfPHjweD70jvfz1c39NT08PoVAIYww+n49gMEiuN5e7Mu+iJK+E4uJip9V6JBOWkpJCUlISSUlJTsZoYiZr4s0Y4wS1nZ2d9PX1sXbt2ritG1VVVcXly5ed+wq8RG4PnUOd/OPL/wiE53z9/n2/vyKy2yJya/r7+zl+/Lhzsfr1r3991O8Gay19fX1Od8aenh4nYMvPz+euu+5arKEvWYvehh7400n3VwMfBz4b4/MI4Xrc4eHhqPI3CP/wdHR00N7eTmpqKhkZGVy6dAljDFu3bnXWiejv76e/v5++vj76+/sZGBigrq6O+vp6J3gYHh7m2LFjAKxatYrt27fj8XhuWMIYeW7IhriafJWG9AYyMzPJJNxqPMGdwKG1h7iz+E6uVl+lo6MDr9dLeno6D+14iMJrhTx39TkANudt5o6SOzDGOKnwixcvUlNTw+nTp8nNzXUW/T179iwAxcXFeDwefD5f1K21tZVXXnmFO++8kzRvGr4e35Q1OBISEgimBLmYcpHtG7ezsXjjrN6LSAONG8nPD698H0+bN29mZGSEYDDIxo0bFXiJ3CYmlh+uyojvYs8isnRlZGRw7733UldXR25u7pTfDcYYp6vypk2bnMZhfX196nwYQ7FeB+xLk7cZY54E/jfw17M5hjHmV4GPAjuAr1trP3KDfd8L/A1QCLwMfNRa2zT+WALwr8D7AT/wmYnrlC1n1lpqa2u5cOHCTbvi9ff309LSAsC2bduiWnLn5eVFTfDs6+vj5MmTDA4Okp6ezv79+zl9+jQ9PT3k5uayZ8+eWXW9ifwwX2i/wMWOi85zEtwJHCw9yD1r7yElIVxWt2fPninPf3DDgyR5khgaG+L+svujfjkYY9i2bRtDQ0NOSWV5eTlVVVWMjIyQmZkZ1eEnYmhoyGl+8dRTT5GYmMha91p6vb2sKVzDW8veSk+oh5eaXiJkQwQJ8si5R6juquaB9Q+Q7Ekm2Zu87D7EuFyuaf+PRWRlm9iAY3XG6hvsKSK3G6/Xy6ZNm2a1r9vtnvJ5UW5dPGbYngHuncP+zcCngTcAM86kN8ZsBb4AvItw8PV/gK8D943v8sfATmAjkAY8ZYyptdb+11xfwGKa3GVvcHCQS5cu0dwcvroZuXoRCoUIESIQChCyIfKy8lhVvIqenh4aGxtZtWpVJD06o8iq5u3t7eTn5+P1ernrrrvo7OwkLy/vpsGXtZbvXfweVR1VPLTpIU63nHYe21G0g7dueStpCTfvSucyLu5dd+NvmfXr19Pa2kpdXR0ZGRnU1tZijGHXrl3TBkmpqancfffdnD17lra2NkZHR9mWvY0PveFD5GTk4HaF54dtX72dR849QvdwNwCnmk9xqvkUAOmJ6azLXsfB0oMzLhotIrIUTAzAVqXrqrWIyFKyoAGYMSYZ+ATQPtvnWGsfHX/ufqDkBrs+DPzQWvvU+P5/BLQbYzZYa2sIZ9E+bq3tBDqNMX8PfAxYVgHYk1VP8uPKH+MP+An4A4z5xjAY3C43BQUFJI8mEwwFnTbuEYmdiawNrGXUP0qrbSWjM4M6Vx07i3bO2MrdWkuvr5c+Tx+J/kRyvbl4PB6KiopmNdbK9kqONoabPjxa+SghGwLCweMbNr1hVsHXbOXk5JCZmUlfXx8nTpwAwu1bMzMzZ3xOYmIid9xxB36/n66uLjIyMqY0uCjJLOFX7/pVnrj4BKdaTkU9NuAb4FzrOao7q/nUvZ8i2atOeyKy9DT2NdLY3+jcVwZMRGSJmal5wHxuQAgITrr1Au+Yx7H+AvjiDR5/HPjDSdsuAe8Asgk3A1k94bGDQM80x8kC1k263TP+/Glvn/3sZ23EZz/72Rn3C//3Xrd3794Z9/v4xz/u7Hf8+PEbHvPd//vd9nd+8Dv2D378B3b3m3bPuF/RxiL7Bz/+A+d2o2O+/3feb//y2b+0f/DjP7Bv+p9vislr2v2m3fYPfvwH9osnvnjT13T8+HHnmB//+Mdn3G/v3r3OfteuXbvhMRfifYq8ppNNJxfkNdnwN+WS/d7Ta9Jr0mta2q/pD//mD+0f//SPY/q7fLFf00p8n/Sa9Jr0mlbOa/re974X+XqdnWWcE+sM2AOT7g8A1dbawRifB8JlhZNXs+0F0scfY9Ljkccm+w3gT2I7tIWVkZkxZYG8W9Xv62dwbHZvU89IDx6XB4/Lg8XedP87Su5g5NrIrQ5xisWcDHq+7Tzb2LZo5xcRmc7J5pPs2R2e9+l1x6fbqoiIzM2SXQfMGPMXQImdoQmHMeZx4Ii19i8nbKsCfhd4AegmnAFrHn/sLsIli9mTjpNFOAs2UQnw4lJqQ2+tJWRDzi1y32VcuF1uPC5PVBfEruEurvVdI9mbzKr0VbQMtHC29Szn285PKVecKNGTSGFqIY39jU4J4VwVpxfTMhBu/JGWkMbvvOZ3nDlWsRb5/o1Hc4yu4S7+4aV/AMDj8vD79/0+Sd6kWT//6LWjXOi4wH1l91GWPXU+3sX2i1zru8aqjFWsy14X05JNEVlZ+kb7ON92nrVZa8lOzuaRs49Q013jPF6YVsgHd32QvFRNnBcRWUhLoQ09xph7gf1MyjZZa/88xqc6D+yacN4MoAw4b63tMcY0jz8e6cW7e/w5Uay1vYSzY46l2OnOGIPbuHFz80DGGENeal7UH96MpAzK88t5U/mbqO6sJmRDJLgTSHQnkuhJJMGdQJIniazkLFzGxYBvgMq2Si52XORq99VZB2Mp3hR+cf8v8uzVZ7nSfYU3bnrjggVfEN/3Kjcl1wkuA6EAVZ1V7C7ePavntg228fjFx4Hw+jz/657/FTX2F+te5EfVP3LuG2PYUbiD+9ffT2FaYUxfh4gsP2dbzvKTKz9hR+EOHtr0EF8++WVaB1uB8IWzyILLEF50+d0V7ybRM/Ni7yIisnhiGoAZY/4K+C3Cgc7whIcsMKsAzBjjGR+XG3AbY5KAoLXWP2nXrwJHjDGvBV4l3DnxsA034AD4IvBHxphjQOr4uP5qPq9rJUlLSGPvqr033S89MZ27Su/irtK76Bvt4/C1w1zuvMxYcIxAKEAgFHCaf4RsiLSENLKSs8It5L1JvKn8TXF4NfFXUVjhZPcq2ypnDMBCNkRtdy0dQx1UFFXwasOrzmM9Iz009jWyJiu8Htvztc/zk8s/iXq+tZazrWc513aO9+14HzuLdi7MCxKRJaG2p5YfVf+IrKQs7l57N6VZpc5jA74BHq18FH/Izwt1L5DoSXSCLyAq+Hrdhtdx//r7l+SFRBERCYt1BuzjwAFr7elbOMYfET0n62HgS8BHjDGDwJustS9aay8aY34B+E+gCHgJ+OCE5/0ZkAfUcH0dsP+6hXHdtjKTMnnDpjfwhk1vWOyhLLqKwgp+euWnAFR3VtM22OZkqIKhIDXdNeHMYftFhvzhRZ5fqn+JQV/0/LrK9krWZK3h2avP8tSVp5ztqzJW4TEeGvoagHAg9oOqH7A1f6vmc4isUAO+Ab52+muM+Edo7GvkfNt5yrLLuK/sPjbmbuS52ufwh65fg3yq5qkpx0j0JPLeiveytWBrPIcuIiLzENM5YMaYemCDtXbmSUbLgDFmHVC7lOaAydLx2SOfdQKkgtQCHtr0EJXtlVR1VDHin12zkezkbPas2sMzNc8429bnrOfh3Q+T6Emkqa+Jr57+Kv2+fgDetuVt3FV616yOPeAbAMJZTGstJ5pP4DIudhbtxOOKx9J/IjJZy0ALL9S+QEZiBvesu4f0xHCVvrWWr5z6Cpc6L037vFUZq2gfbJ9x7u77d7yfsdAYG3M2kpWctVDDFxGRGcxnDlisA7BfA/KBP7FLtbvHLCgAkxtpH2znPw7/R9QV6emkJ6YzODbIbH4UNuZu5EO7P0SCO8HZ9nL9yzx56UkgHLD95t2/edP5dLXdtXzp1Jew1vKRvR+hdbCV71d93znGGze/ke0F21WeJBInIRvixboXefrK0wRtEIAEdwKv2/g67l57NyeaTvBo5aPO/lvzt3Kp89Ks5t0WphXyawd/TT/PIiKLaD4BmCvGY/gu8H6g3xhzdeItxucRWTQFaQW8dctbp30sMn/jf9z5P/jd1/wub9vyNuexVG8q2wu3T3nOprxNPLz74ajgC2D/6v2kelOB8Lyx52ufv2Ew5w/6efTCo/iDfgKhAE/VPMXhhsPO4z0jPfz3mf/mP4//J019TTd9nb6A74YdM0XkxrqGu/h/x/4fP7n8Eyf4AhgLjvHkpSep6qji2avPOtsPlh7k4T0P81v3/BZ3ld6F1xVddnxHyR1R9/et3qfgS0RkGYp1PdIjQCPwT0Q34RBZUfat3kfLYAuHGw6Tk5JDRUEFFYUVrMpYFfWB6MCaA7iMi8r2Su5bdx+jgVEq2yqdxzfnbeaDuz447fyuRE8iB9cedOaIPV3zNPW99bxty9umbS39Yt2LdA93O/freuqmHXtdTx3/ceQ/2FO8h4OlB/G6veSm5EZl1042n+Q7579DbkouH9n7EXJScub8fyRyu7LWcqzxGD+s/iFjwTFne0lmCf6gn7bBNgAeq3zMWX8x2ZvM6ze+Hghnq9+25W08sP4BXql/havdVynPL+e+svu40nWFnpEevC4vu4p3TT25iIgsebEuQRwE8qy1ozE76CJQCaLMViAUwG3cs74KHQgF+MyRz9A60Mr2gu28b+f7bjgvyxfw8fnjn6ep/3rGymVcHFhzgAfWP0BqQjhD1jnUyb+++q8zZqx2Fe8i1ZvK4WuHpy1tSktI490V72Zz3mZ8AR9/9+LfMewPX0PJTcnlE3d+wjmXiMzMF/DxjbPfoLqz2tnmMi5eu+G13Fd2HwO+Af7uxb+b8nN4z9p7ZtU9tnWglaONR9lesJ0NuRtiPn4REZmbpTAH7Ajwrsjix8uVAjBZSIFQgN6R3lkvkOoP+nm65mleqn8pqgQx0ZPI/WX3c0fJHXz++Oed9vjpielOI46IXz7wy6zOXE3nUCc/qv4RFzsuTjmPMYYH1z+Ix+2JWpMMYE3mGj6676NaV0jkJp6oeiKq9LcgtYD37ngvqzJWOdseOfsIZ1vPRj3vN+/+TS2aLCKyDC2FAOzXgA8B/wC0TnzMWvtCzE60wBSAyVLU2NfID6t/OKW00OvyOg1BPC4Pn7jzEzxy9hE6hzsBKEov4lfv+tWoLN3V7qu8WPcifaN99Pv6o7o3GmOmnWu2JX8LH9r9IVwm1lNHRVaG4bFh/s+L/wd/MPzzeKj0EA9temhKiXFjXyOfOfIZ5/6mvE18ZO9H4jlUERGJkfkEYLGeA/bP4/9+Y9J2S3hhZRGZp5LMEn5x/y9S1VHFj6p/5ARYE7sxvmnzm1iVsYq7197N4xcfB8IT+yeXSK7PWc/6nPUADI4N8o0z36C2pxbACb4i7bIjnRirOqp4/MLjvHPbO6ccb9Q/yvn28/SM9DDiH2FN5hoqCivivnbZiH+Eqo4qLrZfJGRDvLn8zZq/JnFzvOm4E3wVpRfx5vI3T1ueXJJZwtqstdT31gNw15rZLTEhIiIrQ0wDMGutLo2LLCBjDFsLtrI5bzPHGo/xzNVnGBoLL/hcUVjBgTUHgHC3tARPuKvirqIbT9RPS0jjY/s/xk8u/4QX6150tt+z7h7uXns3Q2NDPF/7PBD+gJmZlMlrN7zW2c9ay9fPfJ2a7hpn25FrR/jBpR+wq3gXd5bc6SxWHTHiH6G+t54EdwKZSZnkpuTO+/9keGyYCx0XqGyrpKarJqrbXMdQB5888EmSvcnzPr7IbPiDfg5fu156ePfau284N/Rnd/4sP778Y4rTiynPK4/HEEVEZImIaQniSqESRFkufAEfJ5pPEAwFuWvNXbeccTrfdp6nrzxNflo+7614L163F2st3zn/HU61nHL2e+e2dzotsWt7avnPY/95w+OWZpayv2Q/O4p20D/azxdOfIG+0T7n8btK74pq2T8bwVCQ71R+h3Ot5264ZtLmvM18eM+HVTopMWet5WzrWV6oe4G2wTYne5yWkManXvMpLXwuInIbWPQSRGPMH8/0mLX2z2N5LhEJN+I4VHooZserKAy305/IGMO7tr+LQf8glzsvA/C9i99jdcZqVmWscrJjABtyNrA2ey2nW05HtcRv6Gugoa+BJy89icu4nA6LEUevHeXB9Q+SkpAy67GeaDrBmZYzU7avzlhNSWYJR64dAaC6s5qX6l7iNWWvmfWxRW5meGyYL578YlSH0ogDaw4o+BIRkRnF+i/EA5PurwLKgJcABWAiy5Tb5eYDOz/gtMQP2RCPVj7KO7e90wnKjDG8fevbyUvN47XrX8vV7qscazrGhbYLTlngaOD6ChVet5dEdyKDY4OEbIgLHRfYv3r/rMYTCAWiAr9VGavYXbybbQXbyE7OBsLB6Qu14d4/z9U+x97Ve0lLSIvJ/4fIUzVPRQVfxhgyEzMpyy7jnnX3LOLIRERkqYv1HLDJARjGmN8AMmJ5HhGJv0RPIu/b8T7+7dV/wx/y0zLQwuePf955vKKwwmmjbYxhQ+4GNuRuYHBskFPNpzjWeIyu4S4AkjxJ/Nzen6Oxr9Fp8nG+7fysA7DTzafpHe0FIDUhlV/c/4tTWuS/fuPrudh+kY6hDnwBH89efXbOZY4i0/EFfJxqvl6Se++6e7mv7D7NNRQRkVmJR43EvwENKAMmsuzlpebx4MYHnXXCxoJjzmOvWTd9iV9aQhr3rruXe9bew9XuqzT1N7G9cDu5KblkJGY4AVhNVw0j/pGbfoj1BXw8V/ucc/+etfdMuz6Zy7h4w6Y38NXTXwXCZY6tA63kp+bzps1vmnFNs6vdV/nG2W+Q7EnmQ7s/REFawQ3HI7ef0y2nne/9gtQC3rDpDbNejF1ERCQeAVgZoNVbRVaIu9fezfm28zT2NQLhDFSk/f2NTMyKRWQnZ1OSWUJjXyMhG+Jix0X2rto74zF6Rnr4yqmv0DPSA0CKN8Xp/DidLflbWJe9jrqeOkI2RF1PHXU9dbhd7mmzYR1DHXzt9NcYDYwyNDbE549/no/f8XEtkHsb8gV8fOf8d2gdbCUrKYuclBxyknPITs6OWmj5zjV3KvgSEZE5iXUTji9M2pQKPAh8M5bnEZHF4zIuPrbvY5xsPkl2cjabcjfhds1/mb/tBdudYO6Zmmew1rKreNeUJgb1vfV87fTXnLb7AA9temjGTBaEg763bnkrnzv6uahs3fHG49xfdj/pielAuKPila4rfP/S96PmqQ2ODfL545/nlw78EhlJqqS+nbxU/xKV7ZUAdA13RS2zEOF1e9lTvCfeQxMRkWUupm3ojTH/NWnTAHAc+Jq1ExbnWYKMMX8K/MnEbWpDL7Lwuoe7+fuX/j5qW1pCGneV3sWBkgMke5M53nSc71d9n0AoAIDH5eGd297JnlWz+/A74h+hc6iTJ6qecBon3L32brbmb+Vs61nOt52P6swYaecfWVS3PK+cD+/5sDIdt4mx4Bh/+8LfTunWOdkdJXfwzm3vjM+gRERkSZpPG3qtAzYNrQMmEl8v1r3IMzXPRGWpALwuL5lJmXQOdzrbUr2pfHD3B1mXvW7O57nYftGZEzYTl3Hxszt/lgR3Al88+UVn+3sq3jPrgE+Wt8MNh3mi6gkgXCb71i1vpWekh+7h7vC/I91kJGXwnor3qLOmiMhtbtHWATPGbAfebq39q2ke+z3gu9baqlicS0RWnnvX3cv+1fs51niMVxtepd/XD4A/5I8KvgrTCnl498PkpOTM6zxb8rdQlFZE62DrlMcykzLZUbiDvav3UphWCIQXiI7M93mi6gn6RvsoyynDF/AxFhxjNDCKL+AjEAqwNmvtvIJCWVpCNsTLDS879w+tPcSW/C2LOCIREVlpYjUH7FPAyzM81g78DvCxGJ1LRFagZG8yryl7DYfWHuJ823leqnuJloEWIFwSeKj0EPeV3XfDOV83Y4zhoU0P8dXTXyVkQ6QmpFJRWMHOop2szVo7pcTwoY0PcanjEj0jPfgCPn565ac3PP7Oop28ufzNztwyWfr8QT/fOvctOoY6uKv0Lq71XXMWEU/2JrNv1b5FHqGIiKw0MSlBNMZcAfZba3uneSwTOGmt3TDliUuUShBFFp+1lrreOjoGO9hasDWmQU3bYBu+gI+SzBJcxnXDfZv7m/nq6a/SN9o3q2O7jIv1OevZUbSDHYU7bilglIX33NXnZgysH9zwIK/d8No4j0hERJaTRZsDZozpt9bO2CLsZo8vNQrARGSiQCjA2daznG4+jS/oI8mTRKI7kQRPAomeRAZ8A1S2VU55XqInkY25GylOKyYvNY/clFxyU3IVlC0Rw2PD/P1Lfx/V+TJi/+r9vGPbO24aoIuIyO1t0eaAAUPGmDXW2muTHzDGrAFGYnQeEZG487g87F2194ZrlFV3VvNszbM09DU423wBH5VtlVOCs9SEVHJTcslMymTAN0DfaB8J7gTSE9M5VHqI8vzyBXstct2LdS86wVdaQhpjwTECoQAPrH+AB9Y/oK6XIiKyIGIVgL0A/E/gt6d57FeB52J0HhGRJWlz3mY2522mb7SPs61nOd54PKqByERDY0NR65lFtA22UdNdw7u2vYt9qzX3aCH1j/bzasOrzv23bHkLW/O34gv61NlQREQWVKwCsP8NHDbG5ABfBZqA1cCHgPcDB2N0HhGRJS0zKZN7193LPWvvoWWghZaBFtoG2+ga7qJ7uJvukW5nPbPpWGt57MJj+IN+Dqw5oCzMAnn26rP4Q+F13orTi9lRuANjjLMGnIiIyEKJSQBmrT1rjHkz8H+BjwAWMEA18BZr7blYnEdEZLkwxrAqYxWrMlZFbQ/ZEP2j/XQNd9Hv6yctIY3s5Gx8AR+PXXiMloEWrLU8UfUEV7uv8o5t7yA1IXWRXsXK1DXcxfGm4879hzY9pEBXRETiJlYZMKy1zwFbjDEbgQKg3Vp7JVbHFxFZCVzGRVZyFlnJWVMe+9i+j/FfJ/+L5v5mACrbK6ntqeUNm97AvtX7FCTEyNM1TxOyIQDKssvYlLtpkUckIiK3k5i3d7LWXrHWvqLgS0RkblISUvj4HR/nwJoDzrZh/zCPXXiMzx39nBOYAYwFx5xsmcxey0ALZ1rOOPeV/RIRkXiLWQZMRERuXYI7gbdvfTvleeU8UfUEPSM9ADT0NfAfR/6DA2sOsD57PY9ffJyhsSHuLLmTd2x7xyKPevn46eXra35tyd9CaVbpIo5GRERuRwrARESWoPL8cspyyni+9nlerH2RoA1ireVww2EONxx29jvaeJQt+VvUun4W6nvrudR5CQjP0Xv9xtcv8ohEROR2pBUmRUSWqAR3Aq/f+Hp+/dCvszF344z7fffCdxnxa7nFG7HW8pPLP3Hu7yraRVF60SKOSEREblcKwERElri81Dw+svcj/OzOnyUjMQOATXmbnO6I/b5+fnrlpzc6xG2vurOaup46INwI5cENDy7ugERE5LalEkQRkWXAGMOOoh1sK9hGv6+f7ORszred57/P/DcAp1tO8+byN+Nx6df6ZNZafnLlevbrjpI7yEnJWcQRiYjI7UwZMBGRZcTtcpOdnA3A9oLtzte+gI+arprFHNqSda71HK0DrQB4XV4eWP/AIo9IRERuZwrARESWKWMMFYUVzv3K9spFHM3SVNtTy48v/9i5f2jtIdIT0xdxRCIicrtTrYqIyDK2rWAbL9a9CMDF9ouEtoVwGV1bGxob4vELj0cFpcneZO5dd+8ijkpEREQBmIjIsrYmcw0ZiRn0+/oZ9g9T213LhtwNiz2smPAH/bQOtOJxe0hPTCctIW1Wz6vtqeWbZ79Jv6/f2eY2bt6+9e0ke5MXargiIiKzogBMRGQZM8awrXCbszbYI+ceoTyvnO2F29mYu3HZNeWw1tI22Ma5tnMcu3aMIf+Q89jOop38zPafwev2zvj87uFuvnTiS/hDfmfbnuI9PLjxQWe+nIiIyGJaXn+ZRURkiorCCicAGxob4mTzSU42nyTJk8TWgq3sKNzBhtwNSz4Yq+qo4vELj0dlriY623qWfl8/797+brKSs6YttXzy0pNO8JXqTeXdFe/WItUiIrKkGGvtYo9hyTHGrANqa2trWbdu3SKPRkTkxiJt1o81HptxQeZkbzJb87dyz7p7KEwrjPMIb65zqJN/ffVfCYQCUdszEjNI8iTRPtQetd1twt0gs1OyyUnOITcll5AN8aPqHzn7fPLOT7Ima01cxi8iIrenuro6ysrKAMqstXWzec7SvhwqIiI3ZYzhDZvewOs3vp7GvkYutl/kXNs5ekZ6nH1G/COcbD7JqZZT7CjcwTu3vZNET+Iijvo6ay3fu/g9J/hK8iSxMXejs+6Zy7h4se7FqOAqaIN0DnfSOdw57TH3rd6n4EtERJYkBWDjjDF/CvzJYo9DRGS+XMZFaVYppVmlPLTpIZr7mznXdo7zbeedYMxay9nWswC8f+f7F3O4jpPNJ6npDq9hZozhY/s+xurM1VH73LvuXrKTs3m14VU6hzoZHBuc8XhJniQe2vTQgo5ZRERkvlSCOA2VIIrISmKtpaGvgRdqX6CqowoIBzq/dvDXnHJEf9BPyIbinhUbHBvkn17+J6d08p619/Cm8jfd9Hm+gI/ukW66h7uj/vUH/Tyw/gE25W1a6KGLiIioBFFERKYyxrA2ay0f3vNhvnLqK1R1VGGt5ekrT/OBXR/gRPMJnrz0JMFQkPvK7uO+svtwu9xxGdsPqn7gBF/Zydm8dsNrZ/W8RE8ixenFFKcXL+TwREREYk4BmIjIbeTBDQ86WbDK9kr+/fC/0zLQ4jz+dM3TVHVU8Z6K91CQVrCgY7nUcckphwR4x9Z3LJl5aSIiIgtlag9fERFZsVZlrGJ7wXbn/sTgK6Kpv4l/P/zvvFz/MtZa+kf7eazyMR6/8DjN/c0xGYcv4OOJqiec+7uLd6tsUEREbgvKgImI3GYe2vQQV3uuRrWs3796P7kpuTxd8zSBUIBAKMCTl57kQvsFuoa7GPANAHC08SjbC7bz3h3vveGCyDfzdM3TTmOQFG/KrOZ9iYiIrAQKwEREbjN5qXl86t5P0T7YzlhwjKzkLHJTcgEozy/nW+e+5WTG6nrqpjy/sr2S4rpiHtjwwLzO39TXxCsNrzj331z+ZtIS0uZ1LBERkeVGJYgiIrehRE8ia7LWsCF3gxN8ARSmFfLJA5/k/vX34zLX/0Qke5PZnLfZuX+08SjBUHDO563vredLp75EpAPvxtyN7C7ePf8XIiIisswoAyYiIlE8Lg+v3/h6tuZv5adXforLuHhL+VvISs7ib1/4WwbHBun39VPZXsnOop1Tnt851Mmlzktc6rhEfW89qzJW8XN7fo7anloeOfuIs+BygjuBd2x9B8aYeL9EERGRRaMATEREplWSWcJH9300atuda+7kmZpnAHi14VV2Fu0kGArS0NtAVUcVVR1VdA53Rj2nobeBL5/8Mi0DLU7wlepN5UN7PkROSk58XoyIiMgSoQBMRERm7c6SO3nu6nOEbIiG3gb+4aV/YNg/HNXQYzoNfQ3O17kpuXxk70cUfImIyG1Jc8BERGTW0hPT2VG0w7nfNdw1Jfjyur1szd/Ku7a/i0Olh6IeS/Gm8PN7f17Bl4iI3LaUARMRkTl546Y34gv4qOmqwR/yA5CVlEV5fjlb8rdQll3mtKgP2RCdw51Ud1bjcXn40O4PRTX9EBERud0oABMRkTnJSMrgw3s+jD/op2WghURPIgWpBdM203AZFw/vfpiLHRcpSisiLzVvEUYsIiKydCgAExGRefG6vZRmld50P7fLTUVhRRxGJCIisvRpDpiIiIiIiEicKAATERERERGJEwVgIiIiIiIicaIATEREREREJE4UgImIiIiIiMSJuiBOzw3Q2Ni42OMQEREREZElakK84J7tc4y1dmFGs4wZY+4BXlzscYiIiIiIyLJwr7X2pdnsqABsGsaYROAOoAUILvJwVooSwkHtvUDkUkEtULZoI5KJYvFeTPcey9wsh5+J2+V9Xg7vxUJYiu/v7fpeLJT5vsd6H5aOie/FUvyZvZ3UAhuBYuCYtdY3myepBHEa4/95s4pgZXaMMZEvG621dZFtka9lccXivZjuPZa5WQ4/E7fL+7wc3ouFsBTf39v1vVgo832P9T4sHRPfi6X4M3s7GX8vaoCauTxPTThERERERETiRAGYLKY/W+wBiEPvxdKg92Hp0HuxdOi9WBr0Piwdei+Wjnm9F5oDJnFhjFnHeM2yUuQrk97j24Pe55VN7+/Kp/d4ZdH7uTwpAybx0kv4KkHv4g5DFlAveo9vB73ofV7JetH7u9L1ovd4JelF7+eyowyYiIiIiIhInCgDJiIiIiIiEicKwEREREREROJEAZiIiIiIiEicKAATERERERGJEwVgIiIiIiIicaIATEREREREJE4UgImIiIiIiMSJAjAREREREZE4UQAmIiIiIiISJwrARERERERE4kQBmIiIiIiISJwoABMREREREYkTBWAiIiIiIiJxogBMREREREQkThSAiYiIiIiIxIkCMBERERERkThRACYiIiIiIhInCsBERERERETiRAGYiIiIiIhInCgAExERERERiRMFYCIiIiIiInGiAExERERERCROFICJiIiIiIjEiQIwERERERGROFEAJiIiIiIiEicKwEREREREROJEAZiIiIiIiEicKAATERERERGJEwVgIiIiIiIicaIATEREREREJE4UgImIiIiIiMSJAjAREREREZE4UQAmIiIiIiISJwrARERERERE4kQBmIiIiIiISJwoABMREREREYkTBWAiIiIiIiJxogBMREREREQkThSAiYiIiIiIxIkCMBERERERkThRACYiIiIiIhInCsBERERERETiRAGYiIiIiIhInCgAExERERERiRMFYCIiIiIiInGiAExERERERCROFICJiIiIiIjEiQIwERERERGROFEAJiIiIiIiEicKwEREREREROJEAZiIiIiIiEicKAATERERERGJEwVgIiIiIiIicaIATEREREREJE4UgImIiIiIiMSJAjAREREREZE4UQAmIiIiIiISJwrARERERERE4kQBmIiIiIiISJwoABMREREREYkTBWAiIiIiIiJxogBMREREREQkThSAiYiIiIiIxIkCMBERERERkThRACYiIiIiIhInCsBERERERETiRAGYiIiIiIhInCgAExERERERiRMFYCIiIiIiInGiAExERERERCROFICJiIiIiIjEiQIwERERERGROFEAJiIiIiIiEicKwEREREREROJEAZiIiIiIiEicKAATERERERGJEwVgIiIiIiIicaIATEREREREJE4UgImIyIphjHnOGDNmjBk0xvQbYyqNMR+fw/OtMeb+hRuhiIjc7hSAiYjISvOX1to0IAv4M+CzxpjXxOvkxhiPMcbE63wiIrK8KAATEZEVyVobstZ+E+gG7gQwxhwYz5J1GWPqjTGfNsZ4xh+rHH/qD8czaN8a315njPnIxGNPzJQZY+4fv/+zxpgrwDCQOr7tl40xr4wf76wx5tCEYzxgjDlujOkbH8/Lxpjshf1fERGRxaYATEREVqTxTNQHgVzgkjGmHHgK+HegEHgN8DbgdwGstdvHn/oma22atfa9czzlewgHehnA0Pi2XwQ+TDgb9zzwlQn7f3V8LFlAMfDbwNgczykiIsuMAjAREVlpfs8Y0wuMEg54/sBa+wTwK8B3rbXfstYGrLX1wF8BH43ReX/XWtttrR211trxbX9nra2x1gaAzwLrjTG544+NARuAVdbaMWvtq9baoekOLCIiK4cCMBERWWn+2lqbBWQD/wW8brzMcBPwXmNMb+QG/D+gKEbnrZ1mW/OErwfH/00f//ftwHrghDHmsjHmT4wx7hiNRURElijPYg9ARERkIVhrB4wxvwJcJJz9agW+bK39Hzd62jTbBoDUyB1jzKoZzhea4/jOAR8cP+Zu4MdAA+GgUUREVihlwEREZMWy1vqAPwf+CPgi8D5jzLuNMQnGGLcxZqMx5o0TntIKlE86zHHgg8aYTGNMJvDXtzqu8fN/1BiTP76pDwiO30REZAVTACYiIivdVwh3Qnwd8AbgE0AT0AV8G1g7Yd/fB/7QGNNjjPnG+LY/ItxUo5FwMPZYjMb1HqDSGDNEuEHHFwk35hARkRXMXJ8nLCIiIiIiIgtJGTAREREREZE4UQAmIiIiIiISJwrARERERERE4kQBmIiIiIiISJxoHbBpGGMSgTuAFtQSWEREREREpucGioFj40uf3JQCsOndAby42IMQEREREZFl4V7gpdnsqABsei0AL774IiUlJYs9FhERERERWYIaGxu59957YTx+mA0FYNMLApSUlLBu3bpFHoqIiIiIiCxxs562pCYcIiIiIiIicaIATEREREREJE4UgImIiIiIiMSJAjAREREREZE4UQAmIiIiIiISJwrARERERObppzU/5bd/8tuLPQwRWUYUgImIiIjM0/erv8+/H/v3xR6GiCwjCsBERERE5ilog4wGRgnZ0GIPRUSWCQVgIiIiIvMUCAUAGA2MLvJIRGS5UAAmIiIiMk+RAGzEP7LIIxGR5UIBmIiIiMg8BW0QgGH/8CKPRESWCwVgIiIiIvPkZMACyoCJyOwoABMRERGZp2BIGTARmRsFYCIiIiLzpDlgIjJXCsBERERE5kkliCIyVwrAREREROZJTThEZK4UgImIiIjMk0oQRWSuFICJiIiIzJOacIjIXCkAExEREZknzQETkblSACYiIiIyTypBFJG5WnIBmDEmyxjzTWPMgDGmyRjzyzPsV2GM+bExpssYY6d5/IvGmDFjzOCEW+LCvwIRERG5XagJh4jM1ZILwIB/AzzAKuAtwJ8ZYx6YZj8/8E3gYzc41j9Ya9Mm3HyxH66IiIjcrlSCKCJz5VnsAUxkjEkF3gvssdYOAKeNMV8gHGQ9O3Ffa+0l4JIxZmP8RyoiIiJyvQmHShBFZLaWWgZsM2CstRcmbDsNVMzzeP/DGNNtjDlpjHnfdDuMlzyum3gDSuZ5PhEREbmNRDJgKkEUkdlaUhkwIA3on7StF0ifx7H+BfhfQB/wEPBNY0yrtfaFSfv9BvAn8zi+iIiI3OZUgigic7XUMmCDQMakbZnAwFwPZK09aa3tstYGrLVPAl8F3j3Nrv8ElE263TvX84mIiMjtR004RGSulloGrBqwxpit1tqL49t2A+djcOwpnRIBrLW9hLNsDmNMDE4nIiIiK50yYCIyV0sqA2atHQK+DXzaGJNujNlJuAHHFybva8KSgITx+0nj9yOPv8cYk2aMcRljHgIeBh6PywsRERGR24KacIjIXC2pAGzcrxDOVrUAPwL+1Fr7rDGmdHwtr9Lx/dYCI0Dl+P2R8VvE/wSaCGe3/hb4uLX2mTiMX0RERG4TasIhInO11EoQIyWB751mewPhJh2R+3XAjLWC1lrN4xIREZEFpRJEEZmrpZgBExEREVkW1IRDROZKAZiIiIjIPDkZMM0BE5FZUgAmIiIiMk9OEw6VIIrILCkAExEREZknNeEQkblSACYiIiIyTxNLEK2ddslREZEoCsBERERE5inShMNi8QV9izwaEVkOFICJiIiIzFMgFCAtIbxKjhpxiMhsKAATERERmQdrLSEbIj0hHVAjDhGZHQVgIiIiIvMQKT+MZMDUiENEZkMBmIiIiMg8RBpwZCRmACpBFJHZUQAmIiIiMg+RNcDSE1WCKCKzpwBMREREZB4iGTCVIIrIXCgAExEREZmHyBwwlSCKyFwoABMRERGZh0gGLNIFURkwEZkNBWAiIiIi8zA5ANMcMBGZDQVgIiIiIvMwpQmHShBFZBYUgImIiIjMg5pwiMh8KAATERERmYcpTThUgigis6AATERERGQeIhmwVG8qBqMMmIjMigIwERERkXmIBGAel4dkb7LmgInIrCgAExEREZmHSBMOt8tNsidZJYgiMisKwERERETmYXIGTCWIIjIbCsBERERE5iHShMPj8pDiTVEGTERmRQGYiIiIyDxEMmBuEy5BVAZMRGZDAZiIiIjIPKgJh4jMhwIwERERkXmY2IRDJYgiMlsKwERERETmISoDphJEEZklBWAiIiIi8zAxAEvxpqgEUURmRQGYiIiIyDxEuiC6jTs8B0wliCIyC0suADPGZBljvmmMGTDGNBljfnmG/SqMMT82xnQZY+w0jycYYz5rjOk1xnQYY/584UcvIiIitwuVIIrIfCy5AAz4N8ADrALeAvyZMeaBafbzA98EPjbDcf4Y2AlsBO4APmiM+WjshysiIiK3oylNOFSCKCKz4FnsAUxkjEkF3gvssdYOAKeNMV8gHGQ9O3Ffa+0l4JIxZuMMh/so8HFrbSfQaYz5+/Hj/NeCvQARERG5bSgDJiLzsaQCMGAzYKy1FyZsOw08NJeDGGOyCWfQzkw6zl9Os28WkDVpc8lcziciIiK3n8lNOII2iD/ox+v2LvLIRGQpW2oBWBrQP2lbL5A+j+MA9M3iOL8B/Mkcjy8iIiK3uclNOABGAiMKwETkhpbaHLBBIGPStkxgYB7HYdKxZjrOPwFlk273zvF8IiIicpuZXIIIqAxRRG5qqWXAqgFrjNlqrb04vm03cH4uB7HW9hhjmoFdQPONjmOt7SWcHXMYY+ZyOhEREbkNTW7CAagRh4jc1JLKgFlrh4BvA582xqQbY3YSbpzxhcn7mrAkIGH8ftL4/YgvAn9kjMkzxqwFfmu644iIiIjMR1QGzKsMWLx0DXcxODZ48x1FlqglFYCN+xXAAi3Aj4A/tdY+a4wpNcYMGmNKx/dbC4wAleP3R8ZvEX9GOONVA5wAHrHWqgOiiIiIxMTkJhyAFmOOg7d/4+389k9+e7GHITJvS60EMVIS+N5ptjdwvbkG1to6YMZaQWvtGPCJ8ZuIiIhITEU14RifA6YSxIXXMtBCQWrBYg9DZN6WYgZMREREZMlTCeLi8AV9zv+9yHKkAExERERkHiJNOFSCGF9jwTH8Qf9iD0Nk3hSAiYiIiMxDJAvjdrnVhj6OfAEf/pACMFm+FICJiIiIzMN0JYiaA7bwfEGfMmCyrCkAExERkWVnNDDKvs/t48X6FxdtDJEmHC7jUglinFhrwyWIyoDJMqYATERERJadruEuTrac5Hjz8UUbQyAUwOMKN5RWCWJ8jAXHANSEQ5a1WQdgxphMY0zy+NfGGPPzxpiHF25oIiIiItOLZEAWc0HeYCh4PQBTCWJc+II+AJUgyrI2lwzY94Gd41//f8DfAH9tjPl0zEclIiIicgORDMhiBmCBUAC3cQPhMsREd6IyYAsskgFTCaIsZ3MJwLYCJ8a//hDwEHAv8OFYD0pERETkRiIZkMUOwCIZMAhnwTQHbGH5AsqAyfI3lwDMba0NGGNWARnW2rPW2logd4HGJiIiIjItJwPmj08AdrTpKJ/8/iex1jrbgjaI2+V27qd4U1SCuMAiJYiaAybL2VwCsCvGmJ8HPgk8A2CMyQOGFmJgIiIiIjOJ9xywH17+IZ898dmoDNeUDJgnmeGAShAXkpMBUwmiLGOem+/i+B3gK4APePv4trcCi9d+SERERG5L8Z4DFgm8xoJjTsv5iU04QBmweFATDlkJZh2AWWufBUombf7a+E1EREQkbuI9ByzSXCPSBAIgYK834QDNAYsHNeGQlWAuGTAAjDHZQPqkzQ2xGY6IiIjIzUUyYENj8ZkJEclsRQVg05UgqgviglITDlkJZh2AGWMOEi5BLJu4GbCAe9oniYiIiCyAeM8Bm1iCGBEMTW3C0TncGZfx3K7UhENWgrlkwD4DPAl8Fli8nq8iIiJy24t3CWIkAItkYGD6NvTKgC0sNeGQlWAuAdgGYK+1NrRQgxERERGZjbg34ZimBDFog1NKEDUHbGFNzIBZazHGzLhvTXcNhWmFpCWkxWt4IrMylzb0Z4HShRqIiIiIyGxFMiBD/iFCcbg2PG0TjlB0E44bdUHsHO6keaB5YQd5G5j8/z8Tf9DPns/u4Z8O/1McRiUyN3PJgH0V+LYx5m+BlokPWGtfiOmoRERERG5g4ofvYf/wgmc5ppsDNpcmHL/+w1+nsb+RFz6qj0y3YnIJqNftnXa/y92XGRgboH2oPV5DE5m1uQRg/z7+739P2q4mHCIiIhJXE7vgDY4NLnwANl0J4jRNOGYqQWwbaqNrpGtBx3g7iJQgQjgLmkzytPudbz8PxK9LpshczKUEMd1a65rmpuBLRERE4mpiBmw2H7J7R3v56OMfpW+0b17nm1UGzJvMWHCMYCg45flDY0NRz5X5mZgBu1Er+sr2SiBcoiqy1MwqADPGuIEuY0zCAo9HRERE5KYmdsGbTSOOlxte5ounv8jx5uPzOt9sm3AA02bBhv3DCsBiYHIGbCbnO8YzYArAZAmaVQBmrQ0C14CUhR2OiIiIyM1NzIDNJgDrHukGoj/Az8Vsm3AA0zbiGPIrAxYLs82ARUoQtSyALEVzKUH8I+Bzxph1CzQWERERkVmZPAfsZpwALDC/AGy2JYgw/Yd+ZcBiYzZdEEcDo1zpvgJoDpgsTXNpwhFpvvHuyWsuaB6YiIiIxNN8M2CjgdE5n8ta6zxvYgZtuiYcMH0J4tDYEBY753NLtNmUIFZ1VhGyITwuj0oQZUmaSwD2wIKNQkRERGQO5joH7FZKECcGbTdrQw9TM2DWWob9w1HBmszPbEoQIw04dhbupGekJy7jEpmLWQdg1trnF3IgIiIiIrM11xLEntHwB/H5lCBODKhu2IRjvARx8hywseAYQRskGAxirWVyJZHM3mwyYOfbz+N1edlVuIsnLz8Zr6GJzNqsAzBjzGtmekwLMYuIiEg8xbMJx8SSwlk14ZhUgjgxgLvR4sFyc5MXYp7O+Y7zbMnbQlZSlkoQZUmaSwnic9NsixQzK6cuIiLLSlN/Exc6LvD6Da9f7KHIPPhDfgzhTNJsPmTfyhywiRmt+ZQgThzfWHBMAdgtGAtd//+/UQnigZIDpHhTwnPvlHWUJWbWXRAnL8AMlABfBX4mlgMyxmQZY75pjBkwxjQZY375Bvv+6vg+A8aYR4wxGRMee84YM2qMGRy/1cRynCIisrz99Ut/zdu/8XasVWOE5SiSSUpLSFvwLogzZcCCoegSxJna0M9UwihzFzUHbJoSxMGxQWp7a6nIryDVm4rFzivoFllIc2lDH8Va2wz8OvB/YjccAP6NcGZuFfAW4M+MMVMagBhjXg/8yfg+qwEv8K+TdvsNa23a+G1DjMcpIiLLWFVXFaOBUZUozcGnn/80B/7zwGIPAwhnP7yueQRg8ylBvEEGbGJjDWcO2KQSxImt0JdiANY13MVbvv4W2ofaF3soNxU1B2yaDNiFjgsAbC/YTmpCKqC1wGTpmXcANs4CxbEYCIAxJhV4L/BH1toBa+1p4AvAx6bZ/SPAf1lrT1tr+4E/BN5vjNFi0SIiclOXOi8B1z+Yy80dbT7K6dbTSyJrGCn/m00AFrIhpwnHfLIhN2zCYW5egrjUM2DHm4/z5OUnOd16erGHclM3y4BFOiBWFIQzYDC7ElWReJp1AGaM+blJt18CfgC8EsPxbAaMtfbChG2ngYpp9q0AzkTuWGsvjn+5acI+f2GM6TLGvGKMee10JxwveVw38Ua4vFJERFaoobEhrvVfAxSAzcW1vmuMBccYGBtY7KHgD/lnXYI44BsgZENAbEsQJ2fAZipBnDwHbKnp8/UBS3Nsk/mCPifQna4Jx/n28yR7kinLKnPeDy3GLEvNXJpw/Nmk+wPAceCPYjcc0oD+Sdt6gfQZ9u2btK1vwr6/C1wAxoCfBZ4wxuy21l6e9JzfIFzKKCIit4nL3df/FKzkAKxtsI0/f/7P+cc3/iMJ7oRbPl4kaO0Y6iAjMeMmey+suWTAJr7Ht1qCOLkL33Rt6JdbBqx3tBeYuanFUjIWHCMtIY2RwMi04z3fcZ6t+Vtxu9xOCaIyYLLUzKUJR9mk205r7cfG54LFyiAw+Td6JuFgbzb7ZkT2tdYeGS9j9FlrvwS8CLx1muP8E1A26XbvfF+AiIgsfdVd1c7XK3mh1icvP8l/HP8PpyzrVgz7h51AZinMFfKHZj8HbGIANq8uiLNswuFxefC4PMtuDljf6DLKgAV8pCWkATOXIFYUhAunIiWImgMmS81cShAfmWH712M3HKoBa4zZOmHbbuD8NPueB3ZNGMcWwACTM1wR0xasW2t7rbV1E29A4zzGLovgV37wK/zOT39nsYchIjFypPHIjGv7xFJk/hes7AxY80D4GmksPoBe67vmfN0x3HHLx7tVkS6IqQmpccuAJbgTotqgT14HDMJliMutC2IkA7YUxzaZL+hzMluTM2A9Iz00DTRRkT8egEUyYCpBlCVmLk043jTD9jfEYiAA1toh4NvAp40x6caYnYQbcHxhmt2/CHzUGLPTGJMO/AXwiLV2eC8ZYhEAAQAASURBVHxe1xuMMUnGGI8x5kPAa4AfxmqssjS8fO1ljjQdWexhiEgMnG8/z12fv4snLj2x4Oe61HWJvJQ8YGUHYC2DLUCMArD+CQHY0OIHYP6g3ylBvFmJWaQBh9flndccsMj/X1ZS1tQmHK7o2RzJnuSbrgO21DgliNNklJYaX8DnZLYmX6yp7AhnercXbAeuz8lTCaIsNTedA2aMec34l25jzL3AxJXsygmXAsbSrwD/D2ghPB/sT621zxpjSgnP6dpmrW2w1v7UGPNp4EeESw+fBH5t/BhewgHZFiAIVAHvtNZWxXisssgGxwa1oKXICnG48TAArYOtC36uS12X2F20mxfrX1QANktLLQPmlCB6Z1+CWJRWNL8M2HhJYWZi5g2bcMB4Bmy5lSAusyYcM5UgTuyACNdLEJUBk6VmNk04nhv/1wLPT9huCQdJvx/LAVlrewm3op+8vYFw442J2/6VqWt/Ya3tAO6I5bhkaTjffp6x4Bh7i/cC4ataSZ6kRR6ViMTC8ebjwPUPgwvFWkt1VzUf3vlhzrefd7IjK1HLQOwzYInuxCWRAZtPE47i9OL5zQEbLynMSMyYEoBNyYB5p2bApitB/Jcj/8Lx5uP8/j2/z9b8rSymZVWCOHEO2KQSxPPt50lPSGdNxhoArQMmS9ZNSxCttS5rrQu4GPl6/Oa21pZYa78Sh3GKAPBrP/w1fuXJX3HuD44N6heryApxouUEcL0hwEJpG2qj39dPeW45Ock5yoDN0rW+axSmFlKUVkT78BJowhG83oZ+LDh2w+Che6SbZE8yGYkZ825Dn+RJItGT6JzHWkvIhqYtQZySAZumBPGbld/kK2e/QsVnKvj57/48V3uuznlcsbIcuyDCNBmwjkq2F2zHmHCx1mKsA9bY38jvPfV7BEPBuJ1Tlp+5dEGcbi0ukbiq7qp2OpaFbIihsaEpf+hEZPkZC45xtu0ssPAZsEgDjvK8lR2AWWtjmgFrHGhkTeYaClILllwGDG5cZtY90k1Ocg5JnqR5N+FI8aaEm3CMB1BBG/6APd8mHKOBUQ6tOcRv3fVbfLPym5T/Wzmf/P4naeyPfx+w5VaCGAmspsuARRpwAIuyDtjXz32dv3n5bxY1oJalby5dEF3GmN83xlw2xvSNb3uDMebjCzc8keuG/cM0DzQ7C4CO+EewWGXARFaAyvZK58PfggdgXeMB2ArPgPWO9jrBRqwyYGsy1pCfmh+zOWC9o73zKgmE6Db0wA3LEHtGe8hJziHRnTjj+UYDozx99elpHxv2D5PsSY4KwCINIGZTgjhdBmw0MEpRWhF/+9DfUvPrNXxi3yf4wqkvsPFfNvLf5/77Ri895pZbCWKktHBiE472oXY6hjuc+V8AbpebRHdiXDNgFzouAAv/e0yWt7l0QfxTwnOz/pDrLd2vAL8U4zGJTCtyNWnAFw7AIn9sJ19pFJHlJ1J+mJmYSb+vf0HPVd1VTZIniTWZa8hOyl6xc8Ai5YcQuzlgazLWkJ+SH5MMWMiGuOP/3cEfPP0H83p+JAMW+TB+owAskgFL9CTOWIL43arv8rqvvI4TzSemPDYSGCHZGw7AIs+PlJjNpgnHsH/YCRQnBmCROcyr0lfxb2/+N6p/rZqitCK+du5rN339sbRcuiAGQ0GCNjhtCWKkAUekA2JEakJqXC/UXuy8CFz/PxWZzlwCsA8D77DWfhMIjW+rBdbFelAi06nprgHCf2Sttc4fW3/IH5d1g0Rk4RxvPk5GYga7i3Yv+BywS12X2JSzCZdxregMWGQNMLj1AKzf10+/r5+SjBLyU/JpH2rH2mmX15y1Y03HuNJ9Jaq9/VxMnAMGN57n0z3STXZyNknumUsQI+XtP7360ymPjQRGZp8Bm64N/dgQWUlZwKQAzB3dRGpd1jrKsssW/CLERIFQwPl7utQzYJH3broSxPPt4SVjJ2bAIvvGKwNmreViRzgAW+jfY8vRhY4LPPSVh1S5xNwCsHSmLlDsBvTJV+KipiccgFksQ/6hqF+oyoKJLG8nWk6wr3gfWUlZcZkDVp5XDkBOcg6DY4NL/oPnfETmf8GtB2CRFvRrMsMliL6g76adB2/m0YuPAvOfnzN5DthNM2BJ4QzYTCWIkazV07VTyxAjc8AS3YlT5oBN24Rjmjlg2UnZwPQZsIkyEzPjWr42Mdhb6j8HkfElehLxuDxRGbDz7efJSc6hMLUw6jkp3pS4zQFrGmhypkkoAzbVSw0v8dOrP6W+t36xh7Lo5hKAnQPeNWnb24BTsRuOyMwiGTAIlyFO/GOrqykiy1ekAce+4n1kJmUu6JXjseAYV3uuUp4bDsAiH4oj2Y+VJFKCmJ2UzXDgFgOw8SzVmoxwEw6Y3VpgFzouUNU5dQlOay2PVoUDsPkGcnOZA+aUILpnLkGMBE0v1r84bQAVKUGcnAGbtgnHNF0Qp82ATROAZSRmxDUDNjFQWOpdECPvXaI7Ea/LG1X9UtlRSUVBhdMBMSI1YfoMmC/gY+9n9/JM7TPTnstayzcrvzmn/5NI9gs0B2w6kSkkap42twDs94AvGmO+BCQZY/4v8J/AHy3IyEQmiWTAAAbGogMw/TCLLF+RBhz7Vu1b8Kv/tT21BG3QCcByknMAVuQ8sJaBFlK9qRSmFcY2A5aSDzCreWC/8uSv8Invf2LK9sqOSq50X8Fg5l0eNtsM2Ih/hNHA6E27IEb+jviCPl659sqUx26lCcewf5js5DlkwOJYvjbxXEs9AxZ575wM2HhwZK2d0gExItU7/RywzuFOTrWecjKxk51uPc37v/1+nqh+YtbjizTggKVbgnil+8qijW1iE7Xb3Vza0B8B9gO9hBdn9gLvBN66AOMSmeJK9xWnpezg2KAyYCIrRKQBx77ifU4TjludXzSTSAfEzbmbgesB2EqcB9Yy2MKq9FWkeFPm/DvyZMtJ/vcL/9u5f63/Gi7jYlX6KvJTwwFY+9DN1wLrHe3lctflKdsfvfgoBsN96+6bfwZsfA5YekI6wIxZo0hwHWnCMRYcI2RDU/Yb8Y/gdXnxuDxTyhBH/CNTMmAzNeFI9iQzGhiN+h6ePAcsEAoQtMEbZsAW6mdgsokZsLHQEg/AxjNgCe4EvG6vU4LYNNBEn69vSgMOGM+ATVOCGClFPdZ8bNpzRb6/IxcfZuNi50Wyk7LJSMxYkiWII/4R9n9uP59+4dOLcn6neZoums8uADPG3GOM+S1go7X2fxIuPTwDfBt43wKOTwQIX2ms76tnZ+FOQCWIIivJieYTZCRmsCFnA5lJmYRs6JbnF81k4hpgsPIDsOL04nkFYF8/93X+6Nk/om2wDQh/sFyXtQ6Py3M9AzaLEsRh/zAtgy1Tzv/oxUe5u/RuNmRvmPf8nEgJYiSzNFMZaeS9zU7OJtGdCEyf6RkJjJCZlMmB1Qd46upTUx6bbQYscqFw4lyzYf8wGQkZuIyLseCYE0hMmwFLyiRog3H7u7asShCD0SWIkfFGOiBObsAB43PApitBHD/W6dbT034/RL5vJjazuZmLnRfZlr8tai5ry0ALnz3+2VkfYyH9uObH9Pn6aOhrWJTzOyWIyoDdPAAzxvwi8Dzw+8ATxpjfBX4E/DrwKWDq5QaRGGvoayAQCrC7cDcQTmNP/KO9En6YT7Wc4vee+r24XfUUWSqOtxxnb/FeXMZFZmImsHDzJy51XaIgtcDJRkQ+vK/IAGygheK0+QVgkQ/lR5uOAnCk8Qh3rr4T4PocsFmUIEbOW9tT62y72nOVM21neNeWd91Sh7pICWIkMJqpjDTy3kZKEIFp54FFgqzXrX8dx5uPRwV0N1qIeboSxImvHcJzwCY+PxKczVSCCDNn9GIt8rOW4k1Z+iWIgesliBMzYJEOiNvzp8mAeafPgEWONRYc41zbuSmPOwHY4OwDsAsdF9iatzWqlPrLZ77MJ3/wySWxePl3Ln4HmN3Fk4XglCAqAzarDNj/BH7WWptPuBX9XxBuP7/NWvsla6fJ44vEWKQBx+6i3cDKzIB95exX+JuX/yauk69FFlukAcf+4v1AuPwKFm7+RHVXtTP/CybMAVuhTTjmG4BFPjwebTpKy0AL1/qvcWD1ASBc0pXsSZ51Bgyur+MI8NjFxwB415Z3kZaQdmsliC4vxpjwem43yYBFShAhnP043XqanL/JcbpFRsoMHyx7EIvlubrnol7HxAyYtfaGTTjg+ofMQCjAWHCM1ITUWQVgzs9AnJo4RILtgtSCJRuA/d/j/5evnPnK9S6I7vAcsMh7cL7jPEVpReSm5E557kxzwCZmKI83H5/y+FwzYB1DHXQOd7I1fytZSVnO/2uklHG280xHA6MLckFoLDjGE5eeiBrTdHpHexfsQnDkZ32ui68PjQ0tWtZuocwmAFtjrf3W+NePjP/7m9bapflTKitSpAGHE4CtwCYckQ8oi3VlSmQxTGzAAeHyK1jYDFhk/heEsw0GsywzYDcKXCIXqeZbghgJgI80HeFI0xEAJwMGkJ+aP6s5YNMFYI9WPcqeoj2UZZeRmpDqBChzFcmAQTiTOdMH3EhgFumCCOEPgJXtlfSM9lDbG87ORTJgB0oOkOpNjSpDnLgQsyUcfN1oHbCJrz3y76wzYEnxzYBFAoW8lLwluxDzPx7+Rz574rNRTTi8rusZsMr2ymnLD+EGXRAnNGOZbh7YXAOwyALM2/K3RXVzbR8eD8BmeZHnD5/+Q+79r3tnte9cPH31afp8fazNXDtjNs4X8LHmH9fwlq+/ZUG+/+bbhOOvX/prdv/f3Uu+RHYuZhOAOftYa4PAgLU2PgsqyLI3ODbI4cbDt3ycmu4aEt2JzryNlZgBcwKwGJcpfPH0F/nG+W/E9JgisTKxAQdcL79aiAxY72gv7UPtURkwt8tNZlLmsgvA6nvryf6bbF699uq0j0da0BenFZPimX8J4rHmYxxuPIzH5WFP0R7n8fyU/JteLArZkBNoRC6itQy08Mq1V/iZrT8DXF9Qdz5ZMH8o3IQDwq32Z3oPZypBjHwYnBgoRYKs+9bdx1O14QAsGAoyFhwj2ZMcNYdsxiYc4yWIkQ+ZkeOneqdmwCIZuYkWOgs8Wd9oH+kJ6SR5kpZkBsxaS0NfA62DrVObcIx/IG/oa6Asq2za50cuQExuvBJ5D7KSsqYPwEbD3zcT19O7kUgHxK150RmwyN/02TblONFygrreulntOxffufgdMhIzeP/299M53Ol8/07UPNDM4NggP7zyQ+7+wt0xH8d829C3DLbQM9rj/L1YCWYTgCUaY/44ciPcgv6PJ20TmdYXTn2Bg58/yCPnH7n5zjdwpecK67PXO3+YpmTAlvkcMGutcxU21hmwfzr8T/zVS38V02OKxMrEBhywsBmwyQ04InKSc5wPW3PxeNXjPF71+C2P6zPHPkN1V/WcnlPXW0cgFIhqez1R5EPjfLsg9vn6cBs3vaO9fOP8N9hVuMsJLCBcrnazi0UTy4wiF5i+W/VdACcAi7SQn08jjtlmwLpHunEbN+kJ6VEliJG/IZFzj/hHnOzVg2UPUt1VzbW+a87riARncL2TIczchCPyITNyfCcDFprfHLB/ePUf+Pj3Ps4fPv2H/PPhf+Yb57/BM7XPUNleScdQx7SdHWej19dLVlJW1Py2paRrpIvRwChtQ21Tm3CMZ8CG/cPO99JkkSB/8ueESDB395q7qWyvnPIzEgnc+3x9s/r+rGyvJC0hjdLM0qg5YJG/6bMNwK50X2HYPxzT9yIQCvDdqu/y1s1vZU3mGix22gsWrYOtAPz2wd/mWt81DvzngRkv8syH0wVxjp/ZIhdLnq97PmZjWWyzCcBeBR6YcDsy6f79CzU4Wf4iP8y/8L1fcLoUzUdNdw0bcjbgMi5SvakM+AYY8g85f6iWQwbsaNNRdnxmx7RXejuHO53tsc6ADYwNcKHjwoyLj4osphMtJ5wGHLCwDQgiQc7EDBiEA7D5zAH79Auf5k+f/9Mp25+pfYYvnf7SrNpX+wI+fvnJX+YvX/zLOZ078oFkpgs2p1tPA7AxZ+O8SxAPlITnfNX31TvzvyLyU2+eAZt4zkgA9mjVo5TnlrM1bysQLg+DeWbAxueAwY3fw+6RbrKTszHGRJUgRq7GR8rTImWGAK9b/zoAnq592gmkIgEUjGfAZmrCMUMJ4q3MARsNjPK7T/0uXz//df7m5b/hN378G3zgOx/gwS8/SMVnKij4uwKS/iKJb1/49mz+66L0jfaRmZRJgjthSZZ4RX6OBscGnaAh0oQjEgRH5uhNJ/I9NvlnIBLM3VN6D0Eb5FTLqajHJwYokYzyjVzovMC2/G0YY5y13Ky1c5oDNuwfpmmgCYhtBvT5uufpGuni3Vvf7XQxna6EOPI6P7TzQxz+xcOkJ6TzwJceiFkVzXybcER+Vl9oeCEm41gKbhqAWWvvt9Y+cIPba+MxUFmeekZ6SE9IJy0hjXc98q55/UKx1nK15yobssNXyNMS0pwMWGQ9muUwB+zVa69yvv38tB/KJs6PiHUGrN/Xf8Mr5bHyQv0LS/KPtyxdY8ExzrSdccoPYUIGbAHKry51XcJt3KzPXh+1PSc5Z9qrwX//yt/z8KMPz3i81sFWarprpkxY/4Xv/QIfefwjlP5TKZv+dROf/P4n+Vblt+gc7pxyjEig+ZOan8xp4nvkeTPNw/rp1Z+yKWcTa7PWOt3tAqEAL9a/yPp/Xn/TALd3tJeDJQedrMLE+V8wXoI41HHDMUc+8GYnZVPbW0vXcBfP1j7Lz2z9GYwxwIQM2Dw6IUZlwJJukAEb7XaarUxXgjhdBqyioIL8lHyern3aeR2RJhwQnQGbsQnH+FX+yGub6xywiT8D59rOEQgF+PI7v8zY/zdG56c6ufDLF3j255/lkfc8wr+88V+wWE40z71Eq3c0nAHzurxLMgM2sflC5O9npAmHP+jHH/QTtEHn/32ySAZs8vdY5D24p/QeYGojju6RbrKTwl1SZzMPrLK90unCmJWURdAGGfIPzakEMdJwbLb7z9Z3Ln6HFG8Kb9z4RqeL6XS/OyIXzYvSitiSt4XDv3iYO1ffyQe+8wH+7Lk/u+XmHPNtQx/5WX2p4aVpSyeXo1kvxCwyHz2jPRSnF/PN936Tqz1X+fnv/vycyyTahtoY8g85AVh6YroTgOWl5AHLIwPWNdIFXP9FMlFUABbrDNj4L7wzbWdm/RxrLbv+7y4+d+Jzs9q/uqua+754X9znmj1f9zyf+smnVswv5NtNpAHH/lX7nW2p3lTcxr0wJYhdl1ifvd6ZNxQx0/yhr5//Ol8797VpP3yFbIi2oTYGxgaiAqtAKMC1vmv8/K6f5x/f8I9sydvC1859jfd9+33k/20+/37036OO46wVNNjitNKeyeDYoPMBKPJzPd2HqLHgGM/VPcfr178eiA4ITrScoLa3NuqD3mS+gA9f0EdOco7z3kSyYRH5KfmMBEZuGDhFfi9XFFQwGhjlcyc+R9AGnfJDmPDheI4liMFQEIuNmgPWN9o37d+XnpEeJwCbWIIY+T+MjHNiBsxlXDy4/kGeuvrU9QBsliWIk9vQ32gO2HQB2HQLS59sOQnAvlX7cBkXuSm5bM3fyv3r7ud929/Hrx34NbKTsuf1of3/Z+++w+OoroePf++uula9WZKL5N7ANmC66QZMJ0AIJaEFUiAJaaRAAoRUIAlvwi8hCS0QQiAQQq8x3WCqAfdu2bLVe5d27/vH7B3NrrZKsiTb5/M8fiztzo5m+z1zzj3XBGBjtQRxe0v/SUsTjDmbcDibnIRiLg9+jZmqkPLsckoySgbMA2vobLAbe0QLwOo76qlur7YDMBNE72jZYWfaYnluNjZstH8ergDMp308sfYJlkxdQlpimn3iOtTJ3l2tu3Apl50ly0/L5+Uvvswl8y7hptdv4ql1Tw36OLTWg16IubW7Fbdy09LdEtdYZiyTAEwMq0+rP+XMf51pf7A1djWSnZLNUZOO4vYTb+fJdU/y67d+bW+/pnYNj656NOI+zUBhau5UwPpyautpo62njczkTFISUvaIOWD1Hf4ArDt8ABbLxPZ4mIEU9JckxaKtp41Pqz/l1a2vxrS9KS9dV78u7mMcij++90duf+d2meO2hwpuwAGglCIzOXP3ZMDq1g2Y/wVWBsycIDG6+7rttYGeWf/MgNs0djbaA3DTYAKsAZdXezly4pFce+i1PH3B0zRc18Cyy5dR7CnmzYo3A/bjHGS/uOnFsMde015DwW0FvLz55YDbhfq8eGf7O7T3trN4SmAA1tHbYQeakToYmqAwKzmLk6acRFl2WUDnSIhtLTBnAAbwh/f+wITMCQHP92BLEIODn5zUHDQ65OumobM/AxZQgtgTVILoyIABnFB+AlVtVXbwE5wBC9uEw7+P4DlgsZYgul1uPEmegJMQH+76kJyUHCZlTQr7mGSnZNPU3RT2+nCau5vJSvaXII7BLojODNi25m1AYBMOZ4AcinmNhcuAJScks7BkYUAAprWmsbMx5gBsVa31HTinsD8DBrChfoO9TSxlzs4ALNpJqM2NmwO2D2fZ9mVUtVVxzqxzACJmwHa17aIwvTDgNZ2ckMztJ94O9D/+g9HR24HGOoEU75itraeNIyYeAew988AkABPD6ql1T/HUuqfszjmNnY12Cv9bh3yLL8z9AjcsvYGXNr1EU1cTSx5awhef+GLErJj5gDGT9DOSM+wuiJ4kT8zzG7TWnPyPk7l/xf1Du5ODVNdpnSUPNdDY3LiZovQiJmVPGtYAzJlti+esUXV7NRD45RGJCbxMI5GRoLXmnR3vkOBK4MbXbtxrPpT3JcENOIyslKwhZ8CCS2V82seGhg0D5n+BVW7T0NkQME/ys5rP7MHo0+ufHnAbU6oDgYOmbU3WAMU5UE50J3LYhMOYljdtwFwSEzAoFC9teins/dnatJWuvi57HlukEsSXN7+MW7k5tuxYIDAAM4NA8x4PxZx5z07J5rojrmPdNevsOXpGpLPoRnAAVtVWxdkzz7bLDyF8CeI3n/8mL296Oey+zXNj5oCZ75lQmcyAAMxkwEKVIPZ1BmRRjp98PND//MfdhCOoC6KzBNGcGAsVgIE1D8wZnH+460MOLDkw4LEL5uy8Fw+7BNE9NksQt7dst18ndgbMHXsGzGRZw80BS0lIYWHJQtbXr7cfv/bednp9vZRnl5OakBo9APOfhLQzYP65rAEZrRiC4w0N/d+50Z7Ly5+8nEv/e2nUfT6++nGS3EmcOv1UAPJS81CokCdPqtqqKPYUD7jcZGVDnUCOlXM8EncGrKeVWfmzmJwzea+ZByYBmBhW5sPDlOQ0djWSk2p9MSqluPv0u5lTOIcLHr+ACx6/gG3N2+jx9oScG2FsatyES7koyy4DrA8CU4LoSfKQmpAaUwBW0VzBi5te5M1tb0bddnewM2AhShC3NG1hcs5kCtIKIj4Wsbh92e38cfkfrb/l/7BMT0xnRdWKmOu3zeByff36mG5jBoVbGkcuANvesp2drTv52TE/Y2ruVC78z4XDXr4pdq/gBhxGZnLmkAKwZ9Y/Q+6tuQGvB9PNLlQAVppRCgROtDdzac6YcQavbH5lQPmSMwBzlvOZM8Tm88qpJKNkwEDODLKPmnQUb2x7I+xnmflcMAGb+RwJFYC9tOklDhl/iF0GZZdg9bbb3R4jZsD8fyMrJQuXctlBh5MpUYr0njMByKz8WfZz7Cw/hNBt6Bs7G/nje38MmXk0zHxTuwTR/z0Tah6Ycy6PPQcsVAliUAasLLuMKTlTeH7D80AcTTiCShBNcBlrCSIQ0EWvx9vDZ9WfccC4A8I+HjC4AExrK2uYnZJNkmtsliBWNFfYa4AGlCD6m3A4m6SEYmfAwpQgJruTWVi6EOh/3zuXLgj1vg22qnYVGUkZjM8cD/SXIJoxUZI7KeYMmPk8ivZcrqxZGbV7qtaa/6z9DydOOdFu7uJ2uclLywubARvnGTfgclPyGWr8Eitn8DaYEkRPkodFExexbPuyQR/DWCIBmBhWJmNiB2CODBhYH4T/+fx/8Pq8vLDxBRZNtBYb3NGyI+w+NzVuYkLmBPuLz2TA2nvb8SRaGbBY3szmTTuYEo3hYB6TcCWIk3Mmk5+WP6Qg4p6P7uH7L3+f+1bcB/QP7g6fcDhNXU0xryRvBpetPa0Rz5QbdgA2ghkw0xr3xCkn8ui5j1LfUR81myrGjh5vD59WfxpQjmaYDmKD9XbF2zR1NQVklEyWNriUDqA00xrwVLZU2peZkq9vHvxNuvq6Ahblhf73iEu5AkoQTfZ/QtaEAX+n2FPMztadASc1zCD7vNnn0e3tDnuCyHx+mEGZXYIY1AijobOBD3Z+wImTT7QvC1WCWN0W/n3tLEEMx2TAIgVyJgDJTslmQuYECtIK7IYHRqg29KacK9KJteDsk8lwBQ9yvT4vzd3NA0oQu/scbeh72/H6vPT6egeUsZ0w+QT78XCWIHZ7u6M34QjXhj6GAMyZAVtZs5JeX6+9WHk4gwnA2nvb8WpvfwniGGyktL15u/39aB5TZxOOmOeAhShBVCgSXAn255BpxDGYAMx0QARHCaI/AJuSMyXmOWAmGIy0fV1HHfWd9dR21EacP/nBzg+oaK7g3FnnBlwebrpDuAwY9I+9BmuwSweZIDsjKYMZeTOoaa8Z1LIVY40EYGJYOTNgWmuaupoCAjCAaXnTePILT3LDohu4bfFtQJQAzN+C3nBmwNKT0klNjC0D9vb2t4HYV6MfDs6z5GaOSXAJYo+3h+0t2+0M2GBLEF/f+jpfffarQP9ZYHO2ygS6sZYhOgdnsZQhmsFtVVvViDVEWbZ9GakJqexftD/zxs3j/538/3hx04vc+vatI/L3xdCsqllFt7c7dAA2xBLEjY1W2c9Lmx0BWJg1wKA/A2baP0N/yddRk44iKzlrwORz896eVzQvIADb1rSNYk9xyIF1SUYJHb0dAaVl5ufTZ5xOsjs57DywcAFYr6834LFaumUpGm3P/4KhlSCGY88Bi6EEMTUxla8c+BV+ctRPBsyXCjUHzDQjidTgI1wJYnAGzNyX4BLE4DlgZmAf3Mr8+PLj7Z9TE1Pt20cqQUx0JeJSrkG3oQf/e8B/EsJkZUK9V5wGE4A5n+uxWILY5+ujsrWSCZkTKEovAqyA1+1yDyhBDNuGPkyjl25vNykJKSilyEvLY3LOZHseWNwBmKMDIgwsQZyWNy3qc9PZ28n2lu3ML5qPS7kinoQyn2dAxMWSH1/zOAmuBM6YcUbA5YXphQNOnnh9XqrbqinOCBOA+cdegzXYEkTzvGUkZzAp2yrtHspctLFCAjAxbJq6muxBQl1HHa09rXi11y4NcTq67GhuOe4WJmZNBALPPAfb1LiJqTlT7d8zkjJo6mqiq6/LngMWTwYslrU4hsO/V/2bkt+W2A02wpUgVjRX4NM+KwBLL6Cjt2NQQcyty25lnGccX5r3JXuQ5cyAKVTMjTicgWO0EoeGzgbqOuo4oNgqj4n0ZTCc3tnxDgtLF9olSFcdeBXnzzmfG5bewFsVbw1p359Wf2ovZCuG5qNdHwUMJLY3b8fr89oNOJwdEI2hZsDMoMfZ2n19/XoykzPtQZxTcAbMNOA4sPhAEt2JnDLtFJ5e/3RAt82qtipSElI4oPiAgBLErc1b7UFCsJKMEiCw1NHcz6L0IhZNWhR2HpgdgPkz+M7PEWfW/KVNL5GZnBnQNj7uJhyOEsRw0hPTSUlIiakJR1piGj9a9CO+ccg3BmyT7E7GpVwBwZaZTxNPBswuQQw6weYcSEP4EsRwjRyOLT8WhZXVCNeEIzgAU0qRmpA6oA19SkJKXCWI5vP7o10fkZWcNWD5hGCDCcDMYz1WuyDuat2FT/uYmDXRLo0zz4FpwmEe52gliO9Vvsdh9xzGCxtfAKwg3ATUQEAjjlABWLhy/Nr2Wmo7au0GHNB/8mJb0zbSEtMo8ZREHXuYscL0vOlkJWdFfC7X1q21fw5XeaK15vE1j3Nc+XEDxmGh1vGr76zHq70hSxDBylYPZr0+w7zfclNz48qAmc+6jKQMu7R7pMYZu5MEYGLYODMldR119hdhcAbMqTC9kARXQtgMWHNXM3UddQEZME+Sx/7yinUOWFtPm539GakM2J3v34lGs65uHR29HXaQGPwBZj50TQYMBteKfmfrTuaPm09ZVhnN3c14fV77C7wko4RpedNiDsCq26vJT8snyZ0UNQAz15885WRgZOaBdfZ28nHVxxw+/nD7MqUUfz39r5TnlHPB4xfYAW88qtuq+dITX2LeXfP47kvfHc5D3ie9tvU1DvrrQfz+3d8D1pnM6XdO55L/XhK2AQcEzn+Jl9aaDfUbKEgroKqtis9qrE6G6+rXMSNvRsgmBjkpOaQkpNgZMNOAw2QcTp9+OrUdtbxX+Z59m6r2KsZ5xjE1d6rVjt4/uNjWtC3k/C/oD8CcZ9NbultIdieTnJDMSVNOYlXtqpCfh8FzwFq6W+zSNxNMaa15adNLHFd+XEBQELIEMUIGLJYSRKVU1Ix9tNIwsx9PkicgO7GydmXA7UMZMAcsTAYsOABzliA6m3CYAWFwFiU/LZ8FxQus68I04QjO6pn7bD7zO3o7SEtMs+fTmQBMoewMXjDnPEgzVzJSAw6wBv1dfV3292M4Wmte2PgCJz54Iic/dDJpiWnMLpg9JrsgmrL5CZkTKPJYJ09M0JTosuaAxdqE464P7+LdHe+yfMdywHoNOAPghSULqWiuoKa9JuB1U+wppr23PWz2x6yx6cyApSSkkOhKRKMpSCsgJ9VaIiDSnGpz4mhq7tSoHS3X1a+zTwyEC0Y+q/mMjQ0b7e6HToVpAzNg5qRjxBLEIWTAzNjHLGERK/PZmpGcYTc3Ms2O9mQSgIlhY8oPFYq6zjr7izBUBsxwu9wUe4rZ0Ro6ADOlPWYNMLDehIadAYtyNmX5juX4tI8ZeTOGdXHDcNbWreWNbVannh0tOwKCgeAa6oAALIbOYuFUt1VTmFZoP94t3S0BH1zziubFXIJY1VZFaUYpU3KmBHRlCsUOwKaeHHB/Iunu6+a+j+8b9PpdH+76kD5fH4dNOCzg8szkTB4991Fq2mvscsx4nPmvM/nXyn9RkFYQ9X6LyOo66rjoPxeh0fYZ2ormCrr6unjos4e4/5P7QzbggP7yq8Es+mnWDbxiwRUAdkZpXX3oFvRgBQGlGaV2AGZKvkx27uSpJ5PgSgjohljdVk1RepH92bS5cTM+7aOiuSJsq/BQAVhzd7OdaTpxijVvK1T3v1AliCbTZgZSGxs2sq15m73+l2EGpm09bfbncqQ5YE1dTShUwGdtKAXpBTHNAYsUgIE1QDaDM6213f4/UglicAYsNTGVZHfygC6I5ncToJnBuzPrFVCCGKKV+QnlJ9jHGUsTDrMfe/897fZjYBpddPV12eVvoZgMmE/7WFW7inlF88I+FobJuoTLHnf2dvK3D//GnD/NYclDS1hZs5JfHvdLKq6tYE7hHDugGUvzaM0aYBOzJjIu3crMmCA6wZUQWIIYpg19amIqGUkZHFx6MImuRHv7bm+3vS/Annv1fuX7AzJgEL4VfXALerA+U8z7ujC9kOyUbPp8fRFf0+Y7xw7AomTAZhfMJiUhJexJz8dXP45LuThr5lkDritIL6Chs8F+H0F/Zj5cBiwjKf45YDXtNXzr+W8FlPwWpBcMKgPmSfJQnFFMoitRShCFcNpQvwGFYmb+zJgzYADjM8eHLUE0pT3Bc8AMT5Inpjlgy7YvQ6FYMnWJnR1yuuPdO6JmeuJx90d3k+BKQKGobK0MWGMo+AzS5sbNJLmTKMkoGXQGzKd91HbUUuQpsr+EG7sa7QxYZnIm88fNZ3Pj5phKu6rarLP70/KmRX1c1tWtI8GVwCHjDyEtMS2mRhxPr3+ay5+6PGLb7VC2NW3juy9+l689+zUADh1/6IBtFhQv4LL5l8W975r2GpZXLuemY27irJlnxdywZF/x5NonWbplaUzbaq254qkrqG2vpTSj1M7omP+n5U6jq68r7JyWrOQsvNo7qFJck4k/uuxo5hTM4cVNL9LR20FFcwXTcwc24DBKM0vtz6GPdn1ETkqOncnKSc3hqElHBcwDM+8R89m0qXETu1p30evrDZsBM2eWgzNgpjvZfoX7Mc4zLuQ8sOAArLW71Q7+zAkbs0aYCeQMM/ivbqvGp32kJqRS21EbdqDd3NVMZnJmyODYqTC9MOLJIhPUhCuzM9KT0u2BaU17jf15GTEDFjQHDKznKVoJYoIrAbdyB3wmd/R2hM2AAVx3xHX8+7x/k5WSFToDpgZmwFITUvszYH0ddhbGmQFzlr8Fy0zOpK2njW1N2+jo7WBm/syw2xrmsz/UwL2tp405f5rDVc9cRWpiKg+e/SBbr93Kjxb9iLy0PPvYgDHViGN7sxWATcgKnQGLpQmHS7lY/431vHXZW2QkZ9jbBz8HC8YtQKF4f6cVgKUkpJCamBo9AKtZRWZypj2X1DDPR0F6gT0OihRUvbTpJYo9xeSk5gTMAQxlXf06ZhXMoiy7LOx37tPrn+bIiUfa8zWdzGXOrstm6kHYOWCDyIDdv+J+/vDeH3iv8j07eCtMLxxcBiwpA5dyMTFropQgCuG0oWEDE7ImMD5zvBWAxZABA2vgE64EMeYMWJQ387Idy5hTOMceGDnLm9p72vn2i9/mtrdvi7iPWHX3dXP/ivs5c8aZjPOMY0fLjoAPueASxC1NWyjLLrNWnx9kBswsCluUXtRfitPZGHDmyLTx/bT606j7q26vpshTxPTc6Wxs2BjxjOj6hvVMzplMkjsp4peBk3m+Yx3QgzU/5+j7j+bO9+/Ek+ThF8f9IuQXC1hnEFu6W+KaR/Ta1tcAa9L9xKyJ1LTXjOkFvt/c9iZH3HtE1HKjWP3qzV9x7QvXhr3+h//7IT985Ycx7etP7/+Jp9Y9xa2Lb+XwCYcPCMAePe9RLtzvQi7c78KQtzdnjp3NKmJlT3rPncaJU07kzW1v8o9P/wGEbsBhlGSU2BmwFdUrmD9ufkB24ozpZ7CqdpV9UsgOwPyfTZsaNtmDgnABWEZyBp4kT8D8QrMILlhnzU+cciIvb355wEmiUBkwMyfIZKFe3vyy3TrdyQxMzeM/I38Gfb6+sOXYzqxcJAVpBVHngKUmpEYN5JxzS0w2oSCtIGKns1ANMHJTcweUIJrfTQAG1gDe+Rnb3hM5A5aXlse5s60ucrGsAwYErE9pGkaZ2zszYOGYx9/MSRpqALaxYSNbmrZwx0l38MGVH3Dx/hcPWF7ADsBiKEPUWo/IfLGK5gqykrPITM60MzMma5XotppwRGtDD1ZWJ9GdGDBlwTThMDKSM5hVMIsPdn4QsHacCVDDvV9W1VoNOIKzmeZ9XZBWEPG5AXhl8yu8vPllvnf494DI8/l6vD1satjEjLwZlGeXhw1GtjRtYb/C/UJeF+pkr/lcGs4MmJlvV9lSGViCGMd3q7mdGfuVZZdJBkwIpw0NG5iWO438tPz4MmAZ49nRsiNkudGmhk0UphcGBF0DMmBR5oD5tI93tr/D4eMP788OOT5ITTD28uaXB1XyFOyJtU9Q31nPlQdcaZ1Vb620SxDz0/JDZsDMQGqwGTAzn6PIUxSwHk5LdwueJA8u5bJLWKKVIWqtrcFl+jim502n29ttn4UMZV3dOru19+ScyTHNATOZhle3vhr9zmE9Xyf94yTqO+tZdvky3rniHX686Mdht7frxOP4kH51y6tkJGVwYMmB9u3HchZs6ZalLNu+LKABxGD1eHu4ddmt/On9P4X9gq1qq+KT6k+iDro+rf6U7770XU6ZdgrfOuRbjM/sf3+bAGBW/iwe+txDduOWYGbgMph5YBsbNpLgSmBS9iSuXng1xRnFfOWZrwCEXAPMKM2wMmBen5eVNSsHlHydPuN0wDqr3Ovtpa6jjnGecWSlZJGXmmeX/wFhSxDBvxZYW+gMGMBJU06iobOBj3Z9FHA7EzA0d1ulma09rRSkFZCVnEVNew19vj6WblnKiZNPHDAQNANTE2CawXy4eWBmYd5oQs0BW1+/3i4h7OjtCFsW5pSe2J8BMx0QDy49OK45YGB914SbA+Y8EZjsTrYD2rTENKsEMUIGzCmWJhxgBXJmn81d/UF2rAGYeU2YeYdDDcDM/V1QvCBs2aN5LGMJrJ5Y+wT5t+YPaq5tPLa3bLeXdDANdOLNgDmlJabR0efIgLkDs5CmEUd9Z709djHPXbiAyLSgD2aCaDMHDEIHcT7t47qXr2NSlvWZBZEDsM2Nm/FqLzPzZ1KeXR7ypGdXXxdNXU1hgylz8tJZQlzVVkVmcmbYxzHeLoit3a12Q6zK1kpae1pJdieTkZQRXwbM0YQDrM9XyYDtBkqpbKXUo0qpVqVUpVLq6xG2vca/TatS6hGlVOZg9iOGx4b6oADM/0UY7Yt8fOZ42nvbQ57t3tS4acDZXGcwlp6YHnUO2Ora1TR3N3PExCNCLtZpPuS2NW8LaCc9WH/76G9MyprE4imL7cGnKXcpyy4LOQdscrYVgGUmZ5LoSow7A2bmcxSmFwaUOjgHdyUZJeSn5UdtxNHc3UyPt8cuQYTwnRB92seGhg12aVd5djmbGzdHDWTNQPCjXR/F1BTlLx/+hVW1q3jyC09GXQsH6G9VG8dE3aVbl3J02dH24B3GdgBmHsPhOMaXNr1EU1cTvb7ekFnJ7r5umrqa7AVhw+no7eCCxy8gJzWH+868D6UU4zPH09HbQXN3MztadlCQVhCx9Ar6B5/vbH+H77743bhOSGxo2EBZdhkJrgSm5E7hw6s+5LTpp1GQVhByDTCjNKOUbm837+98n47eDvYv2j/g+sk5k5lbOJen1j1FbUctGm0PbuYUzuGFTS/Yj024LogwcDHm5q7AbJOZv+UsofX6vDR0NtiD9/rOenzaR0Zyht3N7L3K92jpbgloP28kuhMDmh3NzLMG8+HmbzmzcpGYrq3OTNV3X/ouX376y0B/84lonE04VtasJC/VagkeTxdECF+CmJmcGbBdSkKKHTiM84wLaJIU7XgH04TDGdCa5zA4+xLMPP7vVb5Hdkp22Gy/U6QAzLyHzEm+UJz3LZrnNzxPa09rQGOa3aGiucLulhyqC6JpwuFSrrANTZycmcngJhxgBWA17TV8UvWJnQEz789QJ4Rq2muo66gLaMBhmOfDzAGD0M/Nv1b+i4+rPubnx/3c/myM1AXRdECckTeDsuwymrqaBmxrlxOGaagRqtom3CLMhlkHLNYT1a9ufdXOpla2VNLa3UpGcgapial09XXFvB8zZjJrBpZll1HVVjVs1R+jZcwFYMCdQAJQApwK3KyUOjZ4I6XUYuBG/zalQCLwx3j3sy/o9fbG/ELv7O3kf5v/F3dzhPqOehq7GpmWZwVgTV1N1LbX4lKuqBO5TQvoUGWIGxs2DuiSFm8G7O0Ka/2vwyccHrIO21mmFrzYarw2Nmxk6ZalXHnAlbiUy57/Ys4+lmWXBZQgNnY20tTVZGfAlFKDWozZDKSK0osCsnytPa3246WUYv64+VEzYOaDu8hTZA9YwwVgO1p20NXXZW9Xnl1Oa0/rgInwwSpbK0lLTEOj7WYlkaypW0NpRinHlR8XdVvA/sKONTjZ0bKD9fXrOa7suIDbj+UyBzOIH44A7JFVj5Cdkk1GUgbPbXhuwPXOTIkpiQrlOy9+hzW1a3jw7AftAeP4zPGA9RjvaN1h/x6JGfBc/tTl/O7d33HjazfGfF82NmxkWu40+/fc1FyevuBpKr9TGTEbYz6HzP2fN25g04PTp5/OG9veYE3tGqB/QPir43/FjpYd3P7O7RSkFUQcxJvFmI3gDFhBegEHFB8QMA+sqasJn/bZJ6PMc56ZnGmv5/PyppdRqLDvkbTEtP4MZMEsIHwjjqaupphKEEOtBVbbXmt/HsUagKUnpQeUIM4tnBuQFQsl5BywMBmw4CoMZwliUXpRYBfEKBk7ZxfFiE04HN9LwQGYCRpiyYB9uOtDZubPjNoBEWLLgOWn5Ye9fTxzwJZXWp0EzcLFu8v2lu1MyPRnwMwcsBBNONIS02J6jAICMG/3gJNBphHHlqYtdgBmvkNDlbSbNv7OBhyGXYKYXhAwN9upu6+b65dez7yieQEl2dkp2dZSPiHGYs41DctzyoGBnRDN93i8GbBwARtYj4NXe2MOfF7c+CLpiemUZZdR2VpJW28bGUkZdpY51v3YGTD/WHJPOEEaizEVgCml0oHzgBu01q1a6xXAvcDlITa/FLhPa71Ca90CXA+cr5RKi3M/ex3nfJ2a9hpKf1cadXHalu4Wvv/S9yn9XSknPHgC//f+/8X1N53zLswH/KbGTWSnZEet/3cO0Jy6+7rZ0bIjYgbMzAHzam/YL41lO5ZRmF7IlJwpIcsAnGe1zCT2wbr7o7txKzeXLbgMsO5bU1cT25u3k5mcSU5KTkAK39kB0Qi1Pkc0kUoQnYO7eUXz+Kz6s4DORwP25R+UjfOMo9hTTHpietiOgM5FJp33I9o8sJ2tOzlpykmkJqTGNA9sQ/0G+2/EojC9kGR3cswB1KtbrFJIM3gtzSjFpVwxZdA6ejv4zVu/iWnB6lB6vb088MkDcXfnHK4MWFdfF0+ufZLPzfwci6cs5vmNzw84YeNcF+79ytAB2OOrH+cvH/6F6464jhMmn2Bfbiam72jZwY6W2AKwqblTyU3N5bL5l3HRfhdx90d3x/RcaK3Z0LCBqblTB1znLFULxRzncxuew63cIUuKzphxBl7t5f5P7gf6BzeHTzicHx35I/p8fWHnfxklGSXsat1lP8ahsk0nTTmJd3a8Y1cFmMGzORllSoKdAdhLm19iYenCgLlOTmmJafbzGK0EsbmrOeYSRAgsmW7ubrY/Xzv7OmMLwBzB1ura1cwumE1aYlpAlilYuBLEUF0Qgx8TZwlikaeIXl+v/VjHU4IYsQmHswSxuzkgAAPrrH4sc8A6ejsils46OQMwr8/LN577hn2yoLajFoUK+/qA/mA2WgasrafNnqtn1vPbHTp6O6jrqLMDsPy0fBQqoATRp30BXSajcQZgoUoQ9y/a3w6ozWPldrnJSMoImQGzOyBGyIAVpIVvwnHXB3extWkrvznhNwFjJXPbUJVBa+vXUuwpJjM5k/JsKwALLv23W8qHaaiRm5qLS7kCArBYMmAwcB57KFprnt/4PMdPPp7y7HKrBLG71W6cBrEvxtzW04ZC2Y1szGfsnt6KfkwFYMB0QGmtVzsuWwHMDbHtXMA+la+1XuP/cVo8+/GXKpY5/wHRRwij4Jn1z/DCxhdYX7+epVuWcuOrN3LJfy/h1H+eyiF3H8LUP0wl+9fZJN6SyHUvXwfALa/fQm1HLb9++9dhGxK8s/0d5t81n9+9+zsWT1nMfoX78X/v/1/MrWir2qrsM9SzCmbZAdiGhg1R539B+ABsS9MWNHpAAGbS0OZn82YOlwVbtn2ZtRCxUiHPQpnH5ZDSQ1i6ZemgW6P3eHu4b8V9nDb9NLtrkhnUfVL9Cflp+XiSPAEliCEDsChr64RS3VaNW7nJTc0lPTGdBFeClQHzp/yN+ePm0+3tts+ggfUh5nxt2Bmw9CKUUhE7IdpdKv3PkQmSIgVVWmsqWyopzy7niIlHxDQPLDirEY3plBQcnPR4e+ju6x6w/dKtS8lLzWO/ImvCcqI7kdKMUipaIgc36+vXc+jdh/LD//0wriyN018+/AuX/PcSDv7bwfbZ1FiYeXRDzdKZUqLz557PkqlL2N6y3R5UGCYoL0grCJkBq2iu4MtPf5mDSw/mlmNvCbjO+f6ubKmMKQAb5xlH/XX13Hvmvfz6hF/jUi5ueeOWqLeraa+hractZAAWjcmAfbjrQ2bkzwg5OD649GAK0wv596p/28dp/PTon3LkxCM5cuKREf9OSUYJnX2d9lyu4JMkYHUx7PP12ScGTLBgFqQ3rbkzkjIoSCugormC5TuWD2g/72QyzmAFuG7lHpYSRAjMgDV3NdudZuMpQWzraaO5q5mmribKs8vtphXhPtfDlSC2dLcEfIY3djUOCDpSElLss++mtbkpE4+WAXPOk4rWhKOzrxOt9YAMGFgD61gyYBDb/C+wgsdEVyJNXU1sbtzMne/fyRNrnwCs11Buam7Ickkj1hLED3Z+gE/7KEwvDJsB++/a/7L4wcWD/j6F/jGBqUhIcCVQkF4Q0IQDrNdrtMDZcE5ZCFWCmJKQYpcfO183WSmh1yZcXbuarOQs+zvfyZkBMwF1cPXNLW/cwvHlxw/oXBopm7mubp39mgi3MHG0DJhLuchNzQ2Yw7erdVfEDJgZe8UyD8w0fTlpykl2h9nWHn8Jov+56uzt5Kl1T5H882Suee6asF0mTeBmMpxmju2ePg9srAVgHiA43G8CQtWweYDgd0Ozf9t49nMtsCXo35uxH/LI+f7L32fJQ0uYcecMjn/geH7+5s95fevrVLdVk5OSw6HjD+XS+ZdyxowzuG3Zbdzy+i3c9eFdHFt2LE1dTfxh+R8C9tfn6+Pm125m0X2L0GjevOxNHjn3EX5wxA9YX7+e/23+X8Tjaepq4rfLfst+f96P17e9zp1L7mRq7lQ7ANvYsDFqB0ToXxvHnNE3zOA+eDAVXILoXGQ0WHVbNRsbNtoL9jo7BBrmQ/Xc2efS1NU0YPJ7Q2cDE34/gaufvTriXLOn1z1NTXsNVx5wpX2ZGWyaeQ0ZSRm097bbwa3JFJkyArA+rJ1dE2NR3V5NQXoBLuVCKWWX4gQP7kwnRGcZ4lH3H2W3dYeBH9zT86aHDcA2NmwkyZ1k389Z+bNYMnUJP3v9Z2EzM01dTXT2dVKaWcqxZcfyWc1nEUsum7uaqe2ojXtQPTFr4oDg5IqnruCsR84KuExrzdItSzm2/NiAM5ATsyZGPMP271X/5qC/HsTO1p0cMeEInl7/dNjXR7gS4F5vL7cvu53ZBbNp6W7hkLsPiampRndftz3oHWoG7L/r/kteah7HlR/HkqlLACsoczKviVOnn8qq2lUB77U+Xx8X/ecivD4v//zcPwdkmoozilEoNtRvoL6zPqYAzGl85ni+cuBXuH/F/VEbvDgz8fFyDqDCrbnkUi5On3463V4riDdNAcAavL5x6Rv87qTfxfR3drbutD8LgoOdwyccTnpiul2GaAdg/vdAcAliS3cLXu0dMIhzMp+TqQmppCWmUZBeELIEUWsd0DQiknAZMPN/zCWIiem097T3NzHJnhTxcx3ClyBC4KA1ZAbMUXZmPufMYxxtIO9SLhJcCdGbcPhLEDt6O+jz9cUdgDkf/1gDMHOSsamryf5uMYPa2o5aO2AOJ9YuiGYh4y8v+DKVrZUBGXLjrYq3eGXzK7yz452Yjj0UexFmfxMOsE5WmjGGee5bulsGnwELMR91YYlVhhgQgCWHbgu/qnYVcwoHdkCEwAxYgiuBjKSMgLHHrW/fSn1nPb854TdhOygGB2Baa9bWrbWzormpuWQkZQyoOtnVtguFijh3MC81L2DJh/be9ojbm7FXLJ0QTffDk6eeTGlGKTtbd9LS3WKVICb2lyB+Vv0ZPd4e/vLhX5jyhyl898XvDjgx1NrTGnDivTSzFLdyj+kpArEYawFYG5AZdFkWEOrZDrVtpn/bePZzB1Ae9G9RPAc9UpZ+aSlvXvYmfz/r7zxzwTM0/qCRrddu5YOrPuCFi1/gH5/7B3ecfAePnvsoiyYu4qev/ZRkdzL/POefnDHjDH7/7u/tD5DNjZs56r6juOn1m7hwvwv55KufcPgEK0g5d/a5FKQVcOf7d6K1HjA4Xl+/nmueu4bxvxvP917+HnML5/LhVR9y9cFW9x7z4djR2xFTBizJnURheuGADJjdgj5oDpg5M5rgSiDJndR/NiVEOtt8+B8x8QjA+vA1ZwgN85iY1eKD54Gtrl3NjpYd/OmDP3Hw3QeHDRb++tFfGZ853l6QGPoDsM6+TvLS8uxslJlwvrlxM3mpeYFzQNKsgVGkMsFgNe01AYNB8yUcHIDNyJtBkjvJbsTR0NlARXMFT6x9wv5QrW6vJtGVaAfP03Ons7Vpa8izopsaN1GeXW6fVVVK8adT/4RGc81z14QMPEygXZpRyoJxC4D+gXMogx1UT8qaNCCAenfHu/Yiu8bmxs1UNFfY87/s22dPCvkB3+Pt4ZvPf5PPP/Z55hbO5eOvfMxPj/4pbT1tIddveujTh8j+TTZz/jSHH7z8A97c9qb93P5r5b/Y1ryN35zwG966/C3ae9t5bPVjUe+bGfC4lXtAANbQ2RDTvDpjTe0aDig+gARXAqWZpexftD/PbQycB2b+3mnTTsOnfXy862P7ul+88QveqniLu067a8B7Faz3d5GnyJ4zEm8ABvC9w7+HV3t5ZNUjYbdp7mrml2/9Eoh9wBp8nCagCG7A4XTGjDMAK/gJzpbEMgfFuRaYc52+4GM5tvxYuxFHcABmZ8CSM+wBU3piesh18QwzQDXv68L0Qmo6BmbA2nvb8WpvTCWIwfNInB3pGjsb7Tb00XiSPHT2ddoB9qSs6AFYuDb0EFjhEK4E0TDziuwALIaujaaRRtQmHL2d9nfNSGTAzN9p6m6yH0sTgNV11EWc/wWxd0FcXrmcKTlTOGnqSQADPlOhf5D+5NonYz72YKbU1mTAAB7//OPccfIdAcc72ACs29tNinvgcxAyAAuRAdNas6pmVcjyQ4BzZp/Dz4/9uZ2lMs8NWBUMv3/391ww94KQjaXsRbWD/qZpcGZeE0opyrLL7Goao6qtioL0gpAnB4y8tP4AzLz+IwXpZvwSSwbshU0vMC13GpNzJlOaUUqvr5ctjVvseftgjYsaOhtIT0xn3TXrOH/O+dyx/A4m/7/JXP+/6+1yYpM5MxJcCYzPHC8ZsGG2HtBKqVmOy+YDK0NsuxKwT1MqpWYCCtgQz3601k1a663Of0DoRalGWXFGMUdOPJIvzfsSp04/dcCXtpHoTuSRcx9hZv5MfnHcLxjnGceNR99IY1cjB/3tIL7z4neYf9d8Vteu5p+f+ycPnP1AwL6SE5K56sCreHrd0xTdXkTh7YUcdd9R3PPRPZz2z9OYcecM/vbR3zhvznl8/JWPefWSVwPmSzg/5GPJgAF2t0CnTQ2b8CR5BnRtcikXniQP6YnpKKUiflG/XfE2Se4ku921UsrqlNUVmAFzKzdl2WXMK5o3YB6Y+SL79fG/ZmXNyoDFWJ3bvLzpZa5YcEXAl7EpawLsEkTor6F2tqA3Dp9wOK09rZzz6DkxL0Rr1u0yzH10NuEA67Uxt3CuHYCZ+QFdfV08uc76oqxqq6IwvdDOBk3Lm4ZXe0NmHzY2bByQmSrLLuPmY27m6fVP8581/xlwG1M6V5JRYh9zuLkogD3/bDAZsF1tu+ySwx5vD1sat1DbURtwBs+USwY3L5iUNYkdLTsCSmi2NW1j0X2L+ON7f+TaQ67ltUtfY0LWBI4tO5bc1Fz+vfrfrKpZRcFtBez/5/0579/ncfETFzOnYA4lGSX8/t3fc9T9R1F4WyEX/ecifvbGz5hbOJdTp53K1NypzCuax/MbA7NPoZggdt64eQOO8Q/L/8DR9x/NTa/dFFPzneDn8JSpp/BWxVsBcw+q260suzlJ4yxDvPP9Ozlzxplh1/QC6/1tSpUGE4BNyJrAQSUH8d+1/w15/SdVn3Dw3Qfz0qaX+OOSPwZklONh3q/hMmAAJ0w+gZSElIhzJSIxGbBdrbvskz+hGl6cNOUkNjVuYlPDpogZMPP5eGz5sQPWdXIy8yfMoLIovShkBizSMQXzJHlIdicHtMg3Gjob4mrCAf3d3SZlT7KPN9xaYCHngAXN8dVaR8yAKZT9+NV11Fnzi9wDMyLBTAAWSxOO4G7AsQZgaYlpuJXb6uaZM/DERjhhM2DttRE7IDqPLZYA7JDxh9gLF4eaB2YG6U+ue3LQy7uYEw3OBY5NN1/of9ybu5sHF4D1DWzCAXDkxCNxKVfAfM5QGTCzaHi4AGx85niuP+p6+8RMTmqOHZDf9NpN9Pn6+MVxvwh523AliHYHRMeahguKF7C8cnnAtJFdbZHLCcHKgJkgJ5YmLbFmwLr6unh1y6v2yWjzuVrfWW93QQSrBLGxq5Gc1Bwm50zm/rPuZ9XXV3H6jNP55Vu/ZOHfFuLTPmsqRVJgAdvesBbYmArAtNbtwGPALUqpDKXU/liNM+4Nsfn9wGVKqf2VUhnAz4FHtNYdce5nr1ScUczqr6/mW4d+C4ADig/gifOfoNhTzO/f/b3VDe+rn3DBfheEvP3VC6/miIlHcPLUk7nx6BvZ0rSFLz/9Zd7f+T43HX0TFddWcN+Z99klbU55qXn2z7FkwMC/Bk9QCeLGxo1MyZkS8qxyRlKGHcw438zBlu1YxkElBwV80QV3ymruaiYzOROlFCdMPoG3t78dEPiYsyxfOchaSyhUucU9H9+DUorLFwT2eUlLTLMfA1OCCP1fTqECsC/M/QJ3LrmTp9c9zVn/OmvA3wqluq06IAOWk2K1Yw41v2Re0TxWVK1Aa82aOisAy0jK4OGVD1v7aq8OGFyG64SotQ65TADAtYdey/xx8/nG898Y8KVlBgSlmaX2MYd6TA3T3CJUdiUS0ynJBPZm7RQIbBKydOtSSjJKBrQon5g1kT5fH7varMnMWmuOe+A41tat5bHzHuP3J/8+oB3y2TPP5ul1T3PGv87ArdzkpeXxzPpn+PpBX+f1S1/n5S++TN11dTx23mOcOfNMXt70MhsbNnLDohvs1/iSqUt4q+KtqAtImyD2sPGH4dVe+xih/6zxza/fzNXPXT1gDsbT657mV2/+CrAGyY1djQEB2JJpS+jz9QVkgs2iw8UZxZRmlNrBVGt3K3UddRw2/rCIx1uaUWo3WRhMAAZw1oyzWF65PGCegNfn5ba3b+Pguw+mpbuFpV9ayjUHXzOo/ZvjhMgZsLTENC7a76Ko9zkcMyk+UgYMrAAMrHb0dR11pCak2rcNbsIBRJz/ZY4b+j+TizxFIU98mAFfLCWISqmApkHO121jV2NcJYhglXMlu5MpTC8cVAbMLjH3f7639bTR5+sb8D1kvg88SR77e6S+s56UhJSYspjBGbBQjaZSE1PRaDs76FwHDAYuAhxMKUVmciaTcyZHbSDjFC4AiyUDFksXxB0tO9jZupNDSg8hIzmDGfkzIgZgGxo22EFDvCqaKxjnGRd22QpTgtjc1RxT5hICu1OGW4ttRv4MNn9zs/0ehNAZMDNXNlTDnlCyU7Jp7Gxkde1q7l1xL19f+PWwJ4tCzRkDWFdvzd92ZkWPmXQMdR11AXOIq9qqwjbgMJxzwMz/zvFbsHAZsOApE29VvEVnX2d/AOYIoJ1dEE0GzHmCZGb+TB4+52F+e+Jv2dy4maq2Ktp62gZ0056UveevBTamAjC/qwEN7AJeAG7SWr+qlJqolGpTSk0E0Fq/DNzi32YX4AO+EW0/I3c3Rl/wF8lZM8/ijcveoP66el679LWIa9UUZxTz5mVv8sDZD3DTMTex6ZubWHb5MiqureDGY24MyLYES05ItgONWAOw6XnTWV272q4bBisDFm7QnZHcH4CF+6Lu7uvmg50f2PO/DPMhaDR197dcXjx5MT3eHnvxQLAG68WeYrJTsslOyQ4Y7II1ELj343tZMnVJQKmEYc7+5KX2lyC2drfS5+tjW/O2AQEYwNUHX831i67n5c0v28da217LJ1UDW8hrralurw6o3c5JzWFX2y76fH0DzhzNHzef2o5aqtqqWFO7hpSEFK468Cpe2vQS9R31VLVVBTy/JjAJ7oRoGh6Eeo4SXAn89bS/Ut1ezfVLrw+4zgTaJRkl9jGHa4cNViBemlEa8xlOI3gxZmcAabJ5Zv7XceXHDXi/2Lf3lzGurl3N5sbN/O7E33HO7HMG/L3zZp9Ha08rlS2VPPmFJ3n1klfp+HEH/3fq/9kDqMzkTM6ZfQ73nXkfVd+rYvM3N3P+3PPtfZwy7RS82msHP+HONJpBlSk5c5Za7mrbxQHFB/CDI37Anz/4M194/At2FrCtp40rnrqCm16/iV5vr13e6QzADht/GFnJWQHt6E0ABtZgwzyWoeYwhuIMupxfxvE4a+ZZAHYGelvTNo5/4Hiue+U6Tpt+Gp997TMWTRpa9fjM/JlMyJwQckK9091n3M39Z90/qL/hSfKQlZxFRXOFPaALFexMzZ1KWXYZL256kbpOa/BsmiyY5z8jKYNDxx/KVw/8asQMJPR/TprBTmFaYcgmHOaYYilBBH/ToPaBGbDGzkY6e2Prgmg+y1fXrmZi1kRcymVnxcK1og85B8yfATNn9U0gFq4E0ZPksf9OXUddzIN4ZwAWrsTL3G/TjS44AwaELH9zyk3NZVb+rIjbBDMBmBmc7mrbhdfnpa6jLmoGLJYuiGb+1yGlhwBwYPGBIRtxtHa32p8r4TLX0Thb0Ic83kGWIHb2deLTPqsNfZiM56TsSQHfCaEyYJFa0IeSk2JlwH70vx/hSfJww1E3hN02UgYsJSElYKxxbLm1wpKzodWu1sgdDSFwDthgM2AbGzZSdHuR3TAIrPlfye5kjp50NBBYCRTQBbF3YABmmDlu25q2DZgDBlaS4C+n/SXi/RvrxlwA5i8JPE9r7dFal2it/+S/vMJ/WYVj2z/6t/ForT/vb0cfcT+iv/1oPJLcSRw24bCoC6ga5k0cawnijxf9mLmFczn7kbPtdci2NG2xu34FC8iAhZkD9uGuD+nx9thlU8aAEkTHhPMjJx5JkjuJlzf1lyFubdpqDzCLPcUDArBn1z/LrrZdAc03nMzgM7gEcUfLDvp8fSEDMOgfXK+utZp5/uh/P2Lh3xby5rbAHjFtPW109XUFzgFLzrYHacFn103WckXVCtbUrWF63nQu3v9i+nx9fOHxL7C+fr3dGQys10tuau6ADJiZoxeuNHBh6UKuWXgNf3r/T7y741378sqWSvJS80hJSCHRnUheal7kEsQ4W9AbwWuBOTs/mnr51bWrqWmvGTD/CwauNWK+3MKts3Rc+XF8Ye4XePichzlkvDU4iXQ23aVcAwKXwyb0Bz8/e/1n5Pwmh6fXPT3gtpWtlSS7k+05dM55YFVtVZRklPDrE37Nb0/8LY+tfoxT/nkKLd0t3PHuHdR21NLj7WFd/bqQAViiO5ETp5wY0I7eWeI6LXcaGxo2oLW2B3mmFXI45j2Qk5JjD3jjNbtgNlNzp/LE2if4x6f/YP+79uejXR9x35n38dh5j0U9ux+Lm4+5mfeufC+mLMhQzMifwbr6dREzYEopTppyEku3LGVX6y6rBbe/yYJXe0lwJZCSkEJ6Ujp/Pu3PUe9/cABW5Cmio7cjYOAE8ZUgAnYbfOdtIc4MmP81saZujf2+HVIGzH/SygRi4UoQM5Iz7L9jsoyxSHYn0+ProamracAJLsPsy3xfhAzAImTAAO454x5+dfyvYjomw86ANW4hwZVAn6+PjQ0b8WpvzBmwiAFY5XKS3En298hBJVYjouAOdq09rczIm8FBJQfZ5e3xqmiuCGjAEWywTTjAel31eHtiHtNkJYfOgGWnZEct9TOyU7JZU7eGp9Y9xQ+O+EHE58N8JgQHfevq1zE9b3rAGK4su4yy7DJe2/oaYC1FVN1eHb0EMS2Pjt4Ouvq6YgvAQmTA1tevx6d9AcHfCxtf4KhJR9nv63GecfbxBmfAGrsaQ56oN9+/25q3hSxBPLj0YE6ZdkrE+zfWjbkATOwd7AAsxgxYbmouL3/xZabmTuW8f5/H6trV9Hh7wmbAJudMtgev4b6ol21fBjAwAEvJCWzC0d1sDzbSk9I5fMLhvLKlv/xqa9NWuxa8OKN4QLncXz/6K8WeYk6dfmrIYzVn/PPSAksQTRYmXABmzqqZMof3d75Pr6+Xzz36uYDUu3MNMPs+pubY9eDBgztTXvVJ9SesrVvLrPxZzCuax+nTT2dt3VoK0grsydVGqE6IZvAeaX7Cz4/7OaWZpVz19FV2WUtla2XAGbEiT1HEEsR4W9AbE7ImoFB2dmh9/XoK0grITM60A7BIQVXwYsyvbn2VSVmTwmZ7Et2JPHzOw5w96+y4j9VIcCVw4pQTeeizh7jxtRtJcidx2ZOX2SWHRmVrJSUZJSEXpNzVtssOoL9z2Hd44KwHeGPbGxxz/zHctuw25hZaq3GsqFrBxoaNKNSA1+CSqUvY2bqTT6s/BfwZMP8+p+ZOpamriYbOBvs1HGsGbLDlh2AFJGfNOIuXNr3EF5/4IvsV7scnX/2ES+dfOmwBU3pS+qDndsVjVv4s1tStiRrsnDjlRFp7Wnl92+v2Z6oZyJuy6VgFlyCeMeMMxnnGcdwDx3H8A8fbWf94ShAhcN3C4DlgnX2dMTfhAOsz3GSeo3ZBjDQHrCtyAGYyTxlJGXb5Y2NnY9wZsC1NW8K+9mPJgEUb/B9ddrS9aHasslOyqW2vpbaj1j5BY7reDkcXxOWVy5k/br597OZEocmMGS3dLWQkZ3DmjDNZXrncfhxipbVme/N2JmYOrCoxTPCt0XG1oYf+13m0INjISsmix9sTsHjwqlqrAUes78PslGx6vD2UZJRw7aHXRtzWdE0MlQELtS7csWXH8vq21/FpH/Ud9fT5+mLKgIH1PjGZsEgnzc34xbkOmDn5YuYFb2+2ljFxlm8muBLsYwmeAxYuA+asQAmey763kABM7BbBg4VYb/PAWQ/Q2NXIN1/4JhB+cP/3s/7OA2c9AISfA/b29reZkjNlQLmkmR9lBC86unjyYlZUraC2vZY+Xx8VzRWUZZUB1pkc5xdJRXMFL2x8gcsXXB62FMUMOoNLEEOtAeY0MWsiaYlprKpZRXdfN6trV3Pe7PPo8/VxxsNn9Hct9JfvBc8BM4Jrp7NTsinLLuOdHe+wtWkrs/JnoZTiqQueYvu3t7P5W5v5/JzPB9xmet70ASWImxo2DZioHCwjOYM7l9zJZzWf8bt3rPbcO1t3BpR4jfOMi7gg7GBa0IM1mCjOKO7PgNWvY0b+DCbnTGZzk/XYL92ylMk5k0OW43qSPOSm5rKufh0+7eP1ra/bpR670ynTTqHb283ZM8/m/Svfp7Ovk4ufuDhgLtfO1p2UZpbax2juo9fnpaa9JqD2/4vzvsiTX3iStXVrae1u5cGzHyTZncwnVZ+wsWEj4zPHDxiEmNr95zc+T3tPO209bfYXqHkuzDovniRPxHkD0H8SYigBmLkvRelF/PK4X/L6pa8PutnGaJuZP5OdrTvtJgPhGiodV34cbuWmq6/L/kw1wVq8A5LgDNjM/Jls/qZVUruqZhWL7lvE4gcX22fRB1WC6DhbbzIi8cwBg/4z39GacITKgKUkpJCakBpXBsycpdfomLMoSe4kuvu62dK4JWz213wv7WyzHgfzvMWTARsMkyGF/pOP5kTKULsg9vn6+GDnB3b5IcCCcQtIcicNaDdvshZnzjgTgKfXD8zkR9LY1Uh7b3vkDJgj+I43A2ZeI7E0XYH+ExLmNR6tA2Io5nv55mNujul4s1Ky7K6JgP2aC9UV85iyY2jobODT6k/tE5rRMmDmfVHfUU9dRx05KTkRuyYmuhNJdicHlCCa8ccHOz9Aa213AnZ2g4b+74DgLoiNnaEzYBnJGeSk5LCteVvIOWB7AwnAxG4RbwmisaB4AWfPPNseBITLgKUmptpfcKHOlGqtWbZ9md1+3sl0IjLlVcGLjp4w+QQA/rflf1S2VOLV3gEliOa29358L1prrlhwRdj7ZAdgaXkBJYibGzfjVu6wg1KXcjG7YDar61azqnYVfb4+zpt9Ho+e+yira1dz8RMX26UGMDADZoQa3M0fN58XN76IRsd0hnVa7jR2tOwIGAxtbNzIhMwJUc/injnzTM6eeTY3v34zmxs3WxkwxzygcN3YYGjrOkHgWmDr69czI88KwLY0bsHr8/La1tc4tix8UHXa9NN4+LOHeW7Dc9R31nPMpGMGdRzxuHj/i3n03Ef55zn/ZE7hHO5ccievbX2NX7/1a3ubypZKO4h13sfajlp82jfgzOcp005h2RXLePzzjzN/3HzmFM7hk+pPQnaxBCvTu2DcAp7b8Jz9+jL7NOWgGxo2sKVpC2XZZVHPAA9HBgys7G3V96r40aIfRVxQdqwzA6j3Kt8DwgdT2SnZdjmrmb/jzIDFIzgAA+tz9NuHfZvN39rMb0/8LZ9Wf8pfP/orEHsJYkFaAe297XT2dtoZsGR3sj3XM54SRCD2DFiIOWAQWGJuArDg7yEz6M5Iygg4vlizKEnuJLr6uqzy9HABmClBbN1FSkKKHWyNRABmHDHB+v6zM2BD7IK4qsZaA9AZgCUnWKXQzjJzsKo8MpMzmVs4l8k5k+MuQwzVgj6Y87mPOwDzv0biyYBBf5a3ur2axq7GmOd/gTWP9VuHfItL518a0/amnNTY1LgJr/aGzYABvLb1NbvsNWoGLM06cVbfWR9TkxawAiNnCaL5fqjrqGNb8zZe2PgC4zPHD2hMYqpenOuANXY20tnXGTIDBtbJmC1NW+jo7ZAMmBCxircE0enmY25GoUh0JUacgGuEmgO2uXEzNe01AxpwQP8ZQvMhErzo6IHFB5KVnMUrm1+xS/3sEkRPMV19XdbCpz4v93x8D4unLI54Jv7smWfz06N+yn6F+wWUIG5u2syk7EkRzzjNKZjDqppV9rpL88fNZ/GUxdxx8h08te4prv/f9XYJgLMJh/NLONQH17yiefZisrFM8jaNOJzrdW1q2BRzZuqPS/5IgiuBq56+iuq26gEBWLgSxMG2oDem5k5lRdUKqtqqqG6vZnredMqzy9nStIWPqz6msasx7JwugFuOvQWALz3xJYARyYAluBI4b8559sDg0vmXcsHcC7jxtRtZtn0ZWuuAIHZi1kQ7AxbpzOf8cfPt8sh5RfMiBmDgD9q2L7M7mJkAvzy7HIWyMmARMgBO4zPHk+xOHvTzuLcx77n3Kt/Dk+SJGEyaUp5QJYjxCF4HLPi67xz2HTZ/czO3Lb6N7x/+/ZiDEfO5U9tRa2cHJmZNjCsD5pxgb2fAojXh8JcgBn9+OrvcmizHgBJERxdEZ/YtnhLEiuYKur3d0UsQ23YFfB6PZAB22ASrU2esGbBoXRDNWn7mpID9d8Yfxgc7P7Bv5/V57UGzUoozZ5zJK5tfiWkBX8NehDmGJhwwhAxYHHPAoD8DZjfgiCMDNm/cPO44+Y6I3/lO2SnZAVllM485VAZsQtYEpuRM4fmNz/d/D0TpgmgqF+o76qnvrLcDskg8SZ4BAZjCOgH3zvZ3eGXzK5w85eQBJ+XM91VGcv8cMPMZETYAy5pkP87BTTj2BhKAid1isBkwgP2K9uNL877EAcUHxHSWO9SZ0re3vw0MnP8F/UGhyYK1dLcEnO11u9wcV34cL29+2e7yZgIwc0ZpV9su3qt8jx0tO7hs/mURjy8vLY+bj70Zt8ttDypMCWK48kNjdsFsdrXtYunWpWQkZdgZwasXXs1XDvwKv3771/zto78BgWc3nYFvuAwYWFm2WBpcmAyUswxxY8PGmNenKc0s5ZfH/5L/bfkfGh0wB2ycZxztve0hS42eWvcUniTPoAfuVyy4gvrOeq7/n9WJ0WTAuvq6+Odn/wSImAGbmDWRbx/6bRq7GpmcMzni2djdRSnFn0/9MxOzJnLh4xeyrXkbHb0d/QFYZn8AZspjo535nFc0j5r2mojlnUumLsGrvTz46YMB+0xOSGZi1kQ7AxZLAJaamMoHV33A1Quvju1O7+Um50wmwZVAfWd91LlWJgAz83eyk7OBgaXF0YTKgAVLT0rne4d/j1sX3xrzvBZzXDXtNTR3N5OakEpheqE9bzHuEkR/BswEJ9GacAS3aM9JzbEzXw2dDSS7kwcEk3YJYlIGSe4k3Mr6noknA2ZORkUtQWzdOSoBWFpiGqUZpRSkFdifD9HmgEXrgrh8x3LyUvMGfO4fOv5QOvs6+azmM6B/jpB5jZ4540x6vD0hF6oPx5TnxpoBi3cOmHmNxFyCGJQBM3Oz48mAxSsrOSsgA2ZOhgUvmWJcvP/FvLTpJbtRV7TvAfNZ0NDZEHsGLCljQAniAcUHkOhK5M7376S5u3lA+SEEliCa173JkocbJ07KmhSw6PzeRgIwsVscMeEIDio5KGo753DuOeMe3rr8regb0v8l5pwDtmz7MjKTM0N+ODoX62zvbcervQMGQYsnL6aiuYJXNr+CQtlfAuaM0q7WXayssdb1dpZjRJPgSiA1IdUuQZycHTkAM2fX/rv2v8wbN8/uJKSU4o9L/sgxZcfw0a6PyEvNCzkZHUJ/cJkArDy7PKZBgAnSTCOO5q5m6jvr41qb62sHfc1+rAIyYGEWY97YsJFHVj3C1w76WsxnpoMdPeloFpYs5N4V1hKA0/Om20HvA588wKz8WVHPEv7wyB9SlF7EKVNHr+NSVkoWD5/zMJWtlZz37/OA/pKOSdmTaO5uprGzMeYzn/PG9S80HC4AO2T8IeSk5PDEmieAwC/zaXnTeHfHu7T1tMU8D2tu4dxBd0Dc2yS6E+2TGtEyWQeXHsw9Z9xjz8sczhLE4WBO/NS2WxmwrJQsexkM59+NxJzddimXXabqUq6ANZuChS1BdMzxNRP8g4NJuwQx2crQmNdlPBkw8/fDzYE1AUFbT1vA98tIBWDl2eUopezv4NSE1KjPRbQSxOWVyzm49OABj6dpxPHOdmsemMmQmOqLIyYeQW5qblxliBXNFSS6EiMueePMJMWaAbPL3+ItQQyRActJyQmYez3cclJz7OYYYM1jLs0oDRuMfOXAr5DoSuS+FfcFrHEXznCUINa01zAhawLzxs1j2fZluJWb4ycfP+B2JrOdk5JDojsRt3JHz4A55mZLCaIQMTq67Gjev/L9QX/BuF3umNP0SqkBX9TLti/jsPGHhWy371ys0+74FTTfwcwDe2z1Y5RmltpfTKa0q6qtijV1a0hNSI24nlooGckZ7GzbSV1HXdQMmAkgO3o7mF80P+C6RHcij533WMgmEtEyYJOyJpGVnBVzhy1PkoeSjBI7ADP/hzsTF4rb5ebuM+7m6ElHc1DJQfbl4RZjvvXtW0l0JfLtQ78d898IppTiB0f8wPr7ys2U3Cn2Gev6zvqI5YdGVkoWq69eze0n3j7o4xgOh4w/hJ8f+3N7zR0zsDK19qtqV8Vc+z+vKHoAluBK4KSpJ9Ht7calXAEZ1qk5U+0mMrFkwMRApowo2lwrs8C7GaQMtgnHjLwZeJI8EZvmDIbJqtR21NrzaXNS+ruwxhLUmMFzSUZJwImk9KT0qE04gj/jA+aAdYXusGa+l8xjaP5+PBkwI9zj6QwIRiMDZk6MmM+JaNkv57GF6oLY0t3C6trVIU84TsyaSLGnmHcrrXlgJkNiAoUEVwKnTT+NZ9c/G3GRZ6ftLdspzSyNuGTOiJYghsiAzSmMvQPiYJRnl7OjZYe9juPaurXMyB84/8sozijmvDnn4dXemLq5piWmkZKQYpUgdtSTnzqIDFh7NYVphSwsWQhYwXioBj7nzDqHf5/3b/tzLzUx1c6ARSpBtP+uZMCEGJtSE/sDsKauJlbWrLQnIAczHw6NnY39baCDMmBTc6cyMWsi3d7ugC9YOwPWtovVtauZmT8z7jXVPEkePqu2SjWiBWCmEyJYDUqC5aXlsfzLy/nP5/8TcLnJgClUQHmPoZTi/rPu58ajb4z5uM36T9AfgIWaDBzJ3MK5vHbpawFnNc0XhbMRx46WHdy/4n4uX3B51GxONGfNPItpudOYnDOZJHeStcCmv2Y9lgAMrC+IWL+od6fvH/F9++SAmRth2sqvrFlJVVsV2SnZUQd2Oak5dlY30mtwydQlgFVS7CwHdgZte2onwtFmBiLxZrIGmwFbNGkRrT9qHZb10pzsOWDttfaSHs4TQLEMjN0u94DFZc1tO/rCt6FPdCUOGADnpuQGZMBClTc5uyBCfwlkvAHYOM+4sAGm83LngNQZNOzuDBj0B2CxPO+RuiB+sPMDNHrA/C+wvk8OHX+o3YgjOAMGcNaMs2jsarSXO4hme/P2qCXfASWIMWYvg0sQB5MB01rbLeh3pxl5M/BpH5saN6G1Zm3dWmbmDZz/5fTNg60O0rGuTZaXmseO1h109nXGNAfMmQEzC3wXeYrsACxU+SFY77lzZ59rv19TE1LtDFi4XgHOE8syB0yIMcqsbg9WnbpGh5z/Bf3BSVNXk302K/gstFKKxZMXA4Fn+LOSs0h2J7Or1QrAgjv9xCIjKYM1dWuA6AGY6YQI2Gu6BMtPyx+QActMzkSh7BKbUM6aeVZAJioa51pg6+vX41KuqMcfi1AliL9d9lt82sd1R1w35P27XW7+c/5/eOBsa9mClIQUSjNLUSiOnnT0kPc/klzKxSPnPsJDn3vIDnwmZE4gIymDlTUrrTXAYlzHav64+RR7iiN+sZkv0+B9OucNSgZscEwjjljX2zIGG4DtLmYeVU17jd3QyBn0xJqZ8CR5As54gxUYRcqAhaqSyEnNobWnlT5fH42djSHPrju7IAJxlyCaAC7Sa3+0MmB5qXkUpBXYZYF2BixKB0SIPAfMrPN1cOnBIW97UMlBbGzYSGt364AMGFhr2qUkpPDftf+N6X5UNFdEbcI1pAxYV3xt6O2Fkbub2dW2i6aupt0egJkKk3V16+w5lqEacDgdMv4QTpl2StgT0MFyU3Pt7/V454DVddTh0z6K0os4ccqJLCxZyBfmfiGmv5uamGqvqRZTBmwvLEGMrcZLiDHOWYL49va3cSlX2C8KZwmiyYCFSpmfMPkE7vn4noAMmFKK4oxiNjRsYHvL9sEFYMkZdvlMLNmDOQVz+KTqk7j+lku5yErJGtazRtPzplPXUUdjZyPrG9ZTll02LFkhMzAwJYi17bX89aO/ctH+Fw1buZTJEhmz8mcxzjMupjN+Y01uai4X7neh/btSirmFc1lZsxKv9sZ85vO2xbeFbf9vFKYXsmjiogHzMEwGzLm2nYjPUDNgY2VAopSy1gLzlyBOyJoQMKCKdWD8h5P/MKC8Ki0xLeIcsOAGHBDYZKmhsyFk5YCzC6LzGOPNgEX6/HbuayQDsOSEZKq+V2Vn+ePJgLldbtzKTa+3l66+Lu77+D6uPPBKElwJLK9czrTcaWEHy+bv1LTXhMyApSelc8LkE3hy3ZPccfIdEUv3vD4vla2VcWXA4g3A7CYcMX6HuV1uPEkemrua+zsg7sYGHID9flhfv95+3COVIBrPXvhszH8jLy3PLmuPNQAzTVacS+CUZpby3pXvxfx3zfvDrdxhPwPz0/JJTUils69zr/yekQBM7BXSk9LtyarLti9jXtG8sG/YjOQMXMpFQ2dDfwYsxFnoEyafEHAm0Sj2FPP6tteB2Fq4BzNf+mauRDQ/XvRjzpxxZtzBTk5KzrB+wTs7Ia6vXx/X/K9IEt2J5Kfl28HAH5b/gc7eTn54xA+HZf+h3HfmffYclb3B3MK5PL7mcXJScsKeeAg2PW96TM/hMxc+M6DMdnLOZBRq2OcT7UvMQGpPz4CBNb/ItKEP/lyLdWB8wX4XDLgsLTEtbBv6SBkwsAbYDZ0N5KaEyICFK0GMtQmHyx+ARciAOT97RzIAg8B5cfFkwMD6PO7x9vDSppf4+nNfZ5xnHGfNPIvllcvt8udQ7GYsHbUhM2BgdUN8Zv0zfFr9aUAjoGBVbVX0+fqiZsCcz3+8XRDjbcIB1nu1ubu5vwPibs6AZSZnMs4zjnX16+zXdbQMWLzyUvPsgMq0pY/ElCBqre0lcAbTiMS817JTssMG40opJmVPYm3d2jFzwmk4SQmi2CucUH4Cr255lW1N21heuTxs+SFYX05l2WWsr1/fPwcsxET4/LR8ar5fwynTArvfjfOMs5t3DLYEEfyD2Bgm8E7Pm26v3xSPnNScYR2kOcshzKLGw6UovYjq9mqau5r543t/5HOzPhdzg5DBKM0sZUJW9DXm9hT7Fe5HQ2cDW5q2xJwBi1VmcuaATGpKQgpTcqfEdDZWhJaZnMkdJ93BJfMviet2phw0Une4kVaQVtA/B2yQJYihpCelh8+A+eeABTPBX3VbNe297fGVIMaZAYt0AsI0h4KRD8Cc4mnCAdbx9Xh77AzRCxtfYHvLdqraqiJ2/DX7r+uoC5kBAzh9+ukoVNRuiLG0oIfBlSCax9xuwhFjCSJY44Tm7mZW164mLzUvYO3N3WV63nTW1a9jbd1aUhNSh7yYfTBn0BVrBsynfXT2ddonTQfzOJj3RrSurKYMUeaACTFGfX3h1/FpH1c/dzVtPW1R65/nj5vPJ9WfRMyAhWMGuImuxLjasBvOAGx3OmvGWZw+/fRh29/knMm4lIvXt71OW0/bsGXAwBpMVrVV8ecP/kxzdzM/OvJHw7bvfYEpsfRpX8xzwIbqmQue4bcn/nZE/tbe6luHfov9i/aP6zZTc6fy3pff49Rpp+6mo4pfYXohO1t30tHbMaAJR6xBTSiRShCjZcBMl85QTTgOm3AYF+53IQcUHwD0Z8BiHcTbJYhR5j86z/IbzqBxJAIws9SIqWCIxrTYNycnn9/4vD3/K2IA5liOIFwGrMhTxGETDosagNmLMEc5STaYEkSzvMGgM2BdzSPSAdGYkTeD9fXrWVe/jhn5M+Ju+hWNMwCKJQAzgVBrd2tACWK8zHsj2lqxJgDbG5cwkRJEsVcozynntOmn8fT6p4HQCzA7zSuaxxNrnqCypRK3csd1ltZ05ZuRPyPmVvlO5gNsdwdgPzn6J8O6v+SEZCZlTeK5Dc8B8bWgj2acZxyvb32d37/7e06achIHlhw4bPveFzjnuA21a2SsJPs1ehaWLhztQwhQkFbAjpYdAAMyYINdww8iN+EINwfMDCg3NW4K+N0pPy2fhz73kP27PQcsjnXAIPoc3rTENBo6GwJO8Jl5Vl7tHZEALC8tj23Xbou5+2WiyypBNFUe21u2c9+K+0h2J0csG3QuR9Da02oHOsHOnHEmP3jlB1Q0V4TNcG1v3n0ZMLNtvG3owcqA1XXUsaF+Q8A83N1pRt4M6jrqWL4jcgnoYDnnQUcLhqA/qG7taaW6rZokd1LcZdQQewbs4v0vJjc1d9gDz7Fg77tHYp91zcHXAFbJRbQP7vnj5qPRvLX9LbJSsuI6k2UyDIOZ/wX9H2C7OwDbHabnTbfXmhrWDFh6EZWtldS013D9ouuHbb/7ioL0ArsMZKQyYEIYBekFaDRAQAYsJSFlSAOnaE04QmbA/H87UgAWLN429EWeIjKTM6POUQpVggj9AVw85W9DUZheGPPzYEoQm7qacCtr6YnnNz7PguIFAeWTwdIT00lJSLEzYBlJoTvwnjnjTACeWvdU2H1VNFfgSfJEHdgHzAGLI9BPTUzFq71AnCWIyVmsq1tHc3fzoKYfDIb5nq3vrB/2+V/QX4KYk5IT0wllU8FjMmBF6UWDygSa5yva+3PRpEX86oRfxb3/PYEEYGKvccLkE5hXNI+TppwU9QPBLES7ompF3GdvTAniYD+ARyoDtjuYL4PhrkU3k3iPnHgkiyYtGrb97ktMFmy454AJEY2zwYMzAzaU+V/m9pGacIScA+b/25sa4gjA4mxD/7WDvsbqr68OmYFzClWCCP0B2EhkwOJlShCbupsozSy1v+cilR9CYDfM1p7WsE2wZuTPYGb+zIhliNtbtjMhc0LU7/HBlCAGbxtvCaKZ37a7G3AYzkqD4Zx3bZgMWKwZUmcGrKa9ZtBzUc3JiVgake2tJAATew2XcvHOFe/wl9P+EnXbiVkTyU7Jxqd9IVvQR2ICp/nj5g/iKPvnm+2JAZiZRzAtb9qwlgSYWv8fH/njYdvnvmZugRWASQZMjDTnJPyslCxSElJITUgdcgCWnmg14dBaD7iu1xu6BDHJnURaYhobGzYCsQVg8bahT05IpjSzNOb97kkBmOmC2NTVRHZKtr0Ye7QADPq7Ybb2tEbsWnfmjDN5betrdpljsO0t0RdhNsdqxPNYOl+X8ZYgGru7Bb1Rnl1uZ6Z2RwbMvD9iXZIlOAM22EYksZYg7s0kABN7ldTE1KhnJcE6W2eyYKE6IEYyq2AWH171oV1KEa/z557PvWfcy5Sc+Bt4jDaTARvO8kOAc2adw6uXvGov/Cvid/mCy/nhET/cp7/QxOhwdtgzJ5hyUnOG1IADrIGyT/tCLgwcrgkHWGfVzbIkcZUgDmG+WihRSxCHYR3F4eYsQcxKzuLi/S9mTsEcjis/LuptTTfM1u7wGTCwArA+Xx/Pb3g+5PWxLMIM/RmweEtdTQCW6EqM63bmtZ2flj8iHRDBCjLNydrh/t6F/hLEWDNgprNyRXMF1W3Vg2pBD7GXIO7NJAAT+yyTwRrMBNIDig8YdAek3NRcLltw2Yh0UBpudgCWO7xfBMkJyRxTdswe+ZiMFfPGzeNXJ/xKHkMx4gJKEP0ntHJScoaeAfOXBoYqQ+z1hW5DD/1liAoV01Ic8bahj1VqYipJ7qQB2ZkkdxJJ7qQx2VggyZ1Er7fXzoDNHzeflV9fGVOpWX5afkwZsEPGH0JRehH/XfffAdd19XVR014TVwYs3teZ2T7eANi8tkeq/NCYXTCbSVmTdksnwHhLEKfnTWfBuAXc+NqN9hywwZASRAnAxD5ssBmwfdmk7En8+Mgf88V5XxztQxFCjBGhMmB5aXlDHjCagXKoRhzRMmBgBWKxBDm7KwOWlpgWcqHZUEHZWOHsghhveX6sGTCXcnHKtFP43+b/DSgvNd00Y1mn0aVcKNTgA7A4m6CY1/ZIB2C3Lb6NR859ZLfs22Sg8lNjC8DcLjf3n3U/TV1N9Pn6Bj8HTDJg0oZe7LuGkgHbV7mUi18c/4vRPgwhxBiSlZxFoiuRXl+vfULrl8f90u40N1hmoByqFX24OWDQP6iLdXC3ZNoSblh0w7APrBeWLAw5f20sB2DOEsS4A7D0Atp726lpr4k6R/qA4gO4b8V97GrbZS8WDbG3oDcS3YmDDsDifQ7sDNgIzf8ypuZOZWru1N2y7wRXAveecS9HTjwy5tvsX7Q/Nx59Ize8esOg5xzbGbAYWt/vrSQAE/us2QWzY2olLIQQIjylFAXpBTR0Ntjzm46YeMSQ92syU+EyYOFKyMygLtYALDc1l1uOu2WQRxnedUdcF/LysR6Atfe209zVPKgMGEB1e3XEEkTAXoD80+pPAwIwexHmGL+XE12JcZeOpiUMrgRxau5U3ModdZ3RPc1lCy6L+zY/OPIHTMyayOnTTx/U35QMmARgYh+WnJDMyq+tDCifEUIIEb+CtAK8vqFlvIJFKkGMOAcsJb4AbKSN5QAs0Z1IQ2cDGj2oDJgRqQQRYL/C/QArAHM2X9reYmXAYl3mZCQzYLMLZtPyo5Yhz23cGyS4EoY0FWFW/iyK0ouGdTmbPY0EYGKfFkuduRBCiMgK0gvo7Osc1n1GasIR0xywMTrBfywHYEnuJGraa4D4y/OdzViiZcByUnMYnzmez2o+C7i8ormCgrSCmOfjJbriD8DMvgezELYEX8Pj+MnHU/W9qtE+jFElAZgQQgghhuSrB37VHrgPl4gZsAhzwOItQRxpniQPfb6+0T6MkJLcSbR0twAD2+dHE08GDKwyxE+rPw24bFPjJsqyy2L+mwmuhLibpww2AybEcJIATAghhBBDcs7sc4Z9nxGbcPh6o2bAxmoAdtvi2+j19Y72YYTkLOsc7BwwiJ4BA9i/cH9e3vQyPd4ektxJ+LSPD3Z+wEX7XRT78Q6hBHEsrsMm9h0SgAkhhBBizInWhCPcHLB4uyCOtFkFs0b7EMIyTVQg/gAsOyWbBFcCfb6+mDNgvb5e1tWtY7+i/Vhbt5aW7hYOKT0k5r95/pzzmVs4N67jHGwbeiGGkwRgQgghhBhzopUghs2AjfESxLFsKAGYUor8tHyq2qpiy4D5OyF+VvMZ+xXtx7s73gWshZpjdeviW+M6RpASRDE2yELMQgghhBhzojXhCJcBm10wmxMmn8ARE4beCn9fM5QSROgvQ4wlAzY9bzqJrkR7HtjyHcvJSs5iet70uP9uPKQEUYwFYyYAU0olKaX+opRqUkrVKqV+FmX785RSm5VS7Uqpl5RSpY7r7ldK9Sil2hz/5J0mhBBC7CESXYmkJ6azbPuyAQsa9/rCN+HITM7k5S++zJTcKSNxmHsVZwbMLDwcD9OII5YMWKI7kdkFs/sDsMrlHDL+EFxq9w5NJQMmxoIxE4ABPwX2B6YCC4ELlVIhV4dTSs0C7gWuAvKBdcA/gzb7ndba4/jXvfsOXQghhBDDSSnFjUffyLMbnuXvn/w94LpIbejF4JkALD0xfVCPb35aPmAFwbE4uPRgXt/2Omtq1/BZzWdxzf8aLJkDJsaCsRSAXQbcorWu01pvBX4LXB5m24uB57XWr2itO4EbgEOVUnK6SwghhNhLfOew73D0pKP55vPfZEvjFvvyXm/4hZjF4Jms4mDKDyG+EkSA6xddD8AZ/zoDn/ZJACb2GWMiAFNK5QAlwCeOi1cA4VrbzHVuq7VuBrYGbX+VUqpBKfWRUurzEf52tlKqzPkP2HeX5hZCCCHGCLfLzd/P+jtKKb703y/h9XkByYDtLiYDNtgArCy7jNSE1JhKEAEmZU/ip0f9lI0NGwErI7a7pSZY64ZJCaIYTWMiAAM8/v+bHZc1AeHewZ6gbYO3/wMwDSjEyo7dq5Q6Ksy+rgW2BP17M+YjF0IIIcRuMyl7EncuuZO3Kt7i9mW3A5HngInBG2oA9vWFX+fDqz6M67n59mHfZlb+LKbnTQ9YzHl3kSYcYiwYkdNHSqkXgJPCXL0NWOD/ORNo8/+cBbSGuU2bf1sne3ut9UeOy59TSv0DOAd4I8S+7gDuD7psPBKECSGEEGPCxftfzFPrn+Inr/6EE6eciE/7JAO2G5iyzsEGYGmJaXGvc5bkTuKVL70ScsHt3UGacIixYEQ+vbTWJ0fbRim1E5gH7PRfNB9YGWbzlf5tzW0zgfII2+swl6O1bsLKnjmPJdrhCiGEEGKEKKW469S7eLvibS78z4UAMgdsNxhqBmywSjJKRuxvyRwwMRaMlRJEsLJQNyil8pVSk4DvYHU6DOUfwBKl1HFKqVTgFuBdrfUmAKXUuUopj1LKpZQ6Eatpx5O7/y4IIYQQYnfIS8vjvjPvY23dWgDJgO0GJgDLSo6/Bf2eIjc1l18c9wvOmX3OaB+K2IeNpQDsZqwM1ibgQ+ARrfV95kr/Wl6LALTWa4ArgLuBemAWcKFjX98CKrEyW7cBV2qtl47AfRBCCCHEbnLS1JO4euHVADIHbDcYahfEPYFSih8v+jGTcyaP9qGIfdiYOX2kte4BvuL/F+p6T9Dv/wb+HWbbRcN+gEIIIYQYdbcuvpWuvi5OmHzCaB/KXme0ShCF2NeMmQBMCCGEECKatMQ07j7j7tE+jL2SBGBCjIyxVIIohBBCCCFGyVC7IAohYiMBmBBCCCGEkAyYECNEAjAhhBBCCMEBxQdw2vTTOLDkwNE+FCH2ajIHTAghhBBCUJBewNMXPD3ahyHEXk8yYEIIIYQQQggxQiQAE0IIIYQQQogRIgGYEEIIIYQQQowQCcCEEEIIIYQQYoRIACaEEEIIIYQQI0QCMCGEEEIIIYQYIdKGPjQ3wI4dO0b7OIQQQgghhBBjlCNecMd6G6W13j1HswdTSh0JvDnaxyGEEEIIIYTYIyzSWr8Vy4YSgIWglEoGFgK7AO8oH87eYjxWULsIMKcKtgDlo3ZEwmk4notQz7GIz57wnthXnuc94bnYHcbi87uvPhe7y2CfY3kexg7nczEW37P7ki3AVKAYeF9r3R3LjaQEMQT/gxdTBCtio5QyP+7QWm81l5mfxegajuci1HMs4rMnvCf2led5T3gudoex+Pzuq8/F7jLY51ieh7HD+VyMxffsvsT/XGwCNsVzO2nCIYQQQgghhBAjRAIwMZpuHu0DEDZ5LsYGeR7GDnkuxg55LsYGeR7GDnkuxo5BPRcyB0yMCKVUGf6aZUmR753kOd43yPO8d5Pnd+8nz/HeRZ7PPZNkwMRIacI6S9A0uochdqMm5DneFzQhz/PerAl5fvd2TchzvDdpQp7PPY5kwIQQQgghhBBihEgGTAghhBBCCCFGiARgQgghhBBCCDFCJAATQgghhBBCiBEiAZgQQgghhBBCjBAJwIQQQgghhBBihEgAJoQQQgghhBAjRAIwIYQQQgghhBghEoAJIYQQQgghxAiRAEwIIYQQQgghRogEYEIIIYQQQggxQiQAE0IIIYQQQogRIgGYEEIIIYQQQowQCcCEEEIIIYQQYoRIACaEEEIIIYQQI0QCMCGEEEIIIYQYIRKACSGEEEIIIcQIkQBMCCGEEEIIIUaIBGBCCCGEEEIIMUIkABNCCCGEEEKIESIBmBBCCCGEEEKMEAnAhBBCCCGEEGKESAAmhBBCCCGEECNEAjAhhBBCCCGEGCESgAkhhBBCCCHECJEATAghhBBCCCFGiARgQgghhBBCCDFCJAATQgghhBBCiBEiAZgQQgghhBBCjBAJwIQQQgghhBBihEgAJoQQQgghhBAjRAIwIYQQQgghhBghEoAJIYQQQgghxAiRAEwIIYQQQgghRogEYEIIIYQQQggxQiQAE0IIIYQQQogRIgGYEEIIIYQQQowQCcCEEEIIIYQQYoRIACaEEEIIIYQQI0QCMCGEEEIIIYQYIRKACSGEEEIIIcQIkQBMCCGEEEIIIUaIBGBCCCGEEEIIMUIkABNCCCGEEEKIESIBmBBCCCGEEEKMEAnAhBBCCCGEEGKESAAmhBBCCCGEECNEAjAhhBBCCCGEGCESgAkhhBBCCCHECJEATAghhBBCCCFGiARgQgghhBBCCDFCJAATQgghhBBCiBEiAZgQQgghhBBCjBAJwIQQQgghhBBihEgAJoQQQgghhBAjRAIwIYQQQgghhBghEoAJIYQQQgghxAiRAEwIIYQQQgghRogEYEIIIYQQQggxQiQAE0IIIYQQQogRIgGYEEIIIYQQQowQCcCEEEIIIYQQYoRIACaEEEIIIYQQI0QCMCGEEEIIIYQYIRKACSGEEEIIIcQIkQBMCCGEEEIIIUaIBGBCCCGEEEIIMUIkABNCCCGEEEKIESIBmBBCCCGEEEKMEAnAhBBCCCGEEGKESAAmhBBCCCGEECNEAjAhhBBCCCGEGCESgAkhhBBCCCHECJEATAghhBBCCCFGiARgQgghhBBCCDFCJAATQgghhBBCiBEiAZgQQgghhBBCjBAJwIQQQgghhBBihEgAJoQQY4xSqkwppZVSZf7fL1VKbXVcf5dS6q7ROr7dQSl1klJqvVKqVSl1cwzbD+tjopS6SSn12mBvvydQSr2mlLopju1XKaUu8v8c8JoUQggxeBKACSHEMPMPdHuUUm1KqRb/QPbK4dq/1vqrWuuvDtf+RlKEQOePwJ+11hla6xvj3e9YeEziDXDC7GPMBDpa6zla64dG+zhgYMAthBB7MgnAhBBi9/il1toDZAM3A39RSh01uoc0upRSiRGungx8PFLHIsaOKK+L4f5bSSP1t4QQIhwJwIQQYjfSWvu01o8CDcDB5nKl1JlKqY+VUs1KqdVKqSti3adS6n6l1P2O37cqpa5XSj3vL+HboJQ6M+g21ymlKpRSTUqp+5RSDzv3EeZvPKyUutd/m21Kqe8GbXOkUmqZ//qNSqkfKqXcjuu1UupbSqnlSqkO4ELgx8Aif3awTSl1oFKqDXADz/svW6iUciulfuzfb5P/7xwex2MyQSn1uFKqRim1Uyl1j1IqJ/pDq25VStUqpaqUUr9RSiU4rixVSv1TKVXp3+/DSqkC/3V3AYuAH/vvQ5X/8mOUUu8opRqUUvVKqaeVUuURjmGV+d+/n98O5v4opRL896XKf39+Daigbf7mf020+V8z1wRdv1UpdWmIfecopTqCnw+l1IORXlNB+71RKfWyUqoV+Ir/+f6uUmqN/z3xoVLqeP/2i4C7gImO181Z/sdWB+07uDTVvI7/ppSqAx4y2yilvup/XTcrpR5RSmVEO3YhhBgOEoAJIcRu5B8IXwjkAev8lx0KPIqVGcsFvgr8Tin1uSH8qSuxgpss4K/AA0opj//vXQT8ADgPyAdeB86NYZ/nAm/7b3M+cL1S6nz/PicBLwEPAAXA54CvA98K2sdXgEuAdKz7/EvgTa21x//vQ3+mEGCJ/7L3ge8CVwFn+/f/EPCSUmpCtIP2B4HPAq3AFGAeMBH4e5SbHg50AOOBY7Eer+/695kM/A/YDkzHytj1Af8EqwQSeBN/5lNrPc6/z17g20ARMA3wAv+IcAxzzP/+/Xx3kPfnOqzn71j//eny3z+nd4EDgUzgG8BvlVKLI+wT/31tBB7Ben4AKyjz/71Y5+F9BbjB/7fvBX4CXAScCeQAPweeVEpN0Vq/ifUeqXC8bv4b49/Bf1xvAuOwXosApcBUYCYwCzgIuDaOfQohxKBJACaEELvHD5VSTVgD3weBH2utn/ZfdxnwpNb6v1prr9b6DeBvOAa0g/BXrfXHWmsf8Gesge0M/3WX+q9frrXu01rfD3wYwz4/0lrf47/Nu/5jvNx/3YXASq31XVrrXq31p8CtIe7Db7XWa7WlM477cwVwq9b6M//+/w9YizVIj+ZgYDbwTa11q9a6FisIOl0pNS7C7WqBn2mtu7XWa4Db6L+/pwJpwA+11u1a6zbge8AJSqnx4XaotX5ba/2u/z40YAXdhyml0mK4H0O5P5cBt2mt12itu4GfAXVBx3aP1rrWn6V9AXgBOCHGY/oz8HmlVJb/9y8B6/2vk1jc4389aq11h//+fF9rvd5/PE9gBU0XxLi/SN7VWj/gfx13+C/rxXouO7XWO4EncGSohRBid5IATAghdo9fa62zsc7m34c1UDflbBOAzUHbb8TKagzWTvODPzgAMCVV44GtQdsH/x7KlhC/mwxUrPcheB+xGspjNAGo01q3BN2WKLev8AewhvP+TgNKgEZ/SWQTVkazO9I+lVLzlVLP+csGW7Cyjworqxerwdyf8Tgee//92uY4LqWU+omj5K8JWAIUxnJAWuv3gDXAxf6LrgT+Estt/exjU0oVYZ0weMI8tv7jOQorUzVUoV6DNVrrPsfvbfS/X4QQYreSAEwIIXYjrXUrcDVQ7v8frDK24HlAU4CK3XQYO4CyoMsmxXC74NuU+fcFsd8HX5TfwxnKY7QdyA+a0zPF/3+k209USjm/F8vov79VwGatdXbQvxSt9TL/NqHu26PAamC21joTONp/uQqxbbh9DOb+BDzn/vvlDNYuAK4BvgDk+E8WPB/huEL5M3Clfy5YGZFLK4M572cTVqb45KDHNl1r/bUQ2xutAEqpdMdlJVH+lhBCjDoJwIQQYjdzlIDdoJTKBO4HzlJKne5vPnAkVgbh7t10CH8Hvqys5hYJSqkvYc39ieZApdRl/tsc7D/G+/zXPQzsp5S6SimVqJSaizXvKNp9qAIm+edURXIvcJ1Sao5//1/DKsP7ZwzH/T5Wdub/KaU8Sql84HfAs1rrqgi3K8Ca55aklJoBfJ/++/sfIEVZbfSzAJRShWZOnOO+TQ/aZxbQArT4Mz0/i3LstVgBwwzHZYO5P38Hvq+UmqGszn83EJh1y8Kaw1Zn3RV1NhB1/leQh7ECrz8C/wrK0MXM//64C7hNKTXLn51LVUodpZQyj2cVUKACG4+sxwrCvqKUciml5jO0Ml4hhBgREoAJIcTIeBCrE+L3tdbvYGUgbgEasYKW67TWj+2mv/0Q1oD9P1gD7mOBp7CyDpE8hlUGVgc8DvxGa/0wgNZ6K3Ay1lyjOuBJrOYfv4+yz0ewyud2+UvN5ofZ7rfAPf7jrMOaY3Sy1jpqBsxfWnYaVvnnFuAzrBLNL0W56TKsMrRK4A2sx+t2/z5bgcOwsnKf+csJl2E9Ps5jnuu/XyZzdgVWmV4r8Ip/n5GOvROrmcrf/fu5dZD35zfAf/33oxKrCcoyx/X3+69bjRXcLMF6DmOmtW7Hel0fQHzlh6F8Dytb+G+sjNhW4EeAaVG/FKsRiemKeYb/ObkEK7PcAvwK6zUohBBjmtJaR99KCCHEXkUp9QHwuNb6V2Guvx9Aa33pCB6W2MMopb4NfElrvWC0j0UIIfYUkgETQoh9gFLqC/6yrhSl1LeA/bGyDUIMir8U8hrgjlE+FCGE2KOMuQBMKXWNshZg7FFRFnRUSp2nlNqslGpXSr2klCp1XJeklPqLv1ShVikVre5eCCH2Zl/BKjWrAb4InKm13hj5JkKEppS6Faur4rsENd9QSplFpAf8G5WDFUKIMWbMlSAqayFSH3ASkBqu/EUpNQt4D2uRzrex1p/ZX2t9tP/6nwPHA6cDHqza+19ore8LtT8hhBBCCCGE2N3GXABm+AOo8RECsF8A07TWn/f/noV1Zne21nqTUqoSuFJr/Zz/+q8BF2qtF43IHRBCCCGEEEKIIAnRNxmz5mJlwADQWjcrpbZidaBqwFoL5BPH9iuAXwbvRCmVDWQHXZwETAY2AN5hPGYhhBBCCCHE3sMNFAPv+5fViGpPDsA8QHPQZU1YLYQ9/t+bQ1wX7FrgxuE9NCGEEEIIIcQ+ZBHwViwb7skBWBuQGXRZFtZaK2aib6bjZ3NdsDuw1kNxmgS89uabbzJ+/PjhOFYhhBBCiD1GR3cv/3p7U9Tt0pIS6Ojps38/bHoRs8bnRLiFGAt8WvPg6+vx+qypSBPzPYzP8zCjJAul1Cgf3Z5lx44dLFq0CGBXrLfZkwOwlcA884tSKhNrgcyVWutGpdRO//U7/ZvM998mgNa6CSs7ZjMvvPHjx1NWVjbsBy6EEEIIMZatrWwkr6h/rfa05AQ8KYlkpCaSlpTA6h2N9uA91XG7wxZMJzs9eYSPVgzGtB191LZYz3E7sK4JSsZnsv+kvFE9rj1YzNOWxlwAppRKwDouN+BWSqUAXq11b9Cm/wCWK6WOA94BbgHe1Vqb0zX3Azcopd4H0oHvACEXHBVCCCGEEP2217XbPx86vZBDphUFXD+9JIun3t9Gr9dnX5aRmkhWWtKIHaMYmpmlOdS2BCZtXlu1k7SkBMblpJGalIDbJdmw3WHMBWDADQTOyboY+DtwqX8NkSVa6ze11muUUlcAdwPjsGouL3Tc7mYgH9gE9AJ/lhb0QgghhBCRaa2pqOtftm1i/sAp9OPzPFy4aCqfVTSwfmczHd29HDKtUMrX9iAHTM5nYr6H1s4e3t1QQ01zJ1rDsx9V2NukJLpJTUrAk5LAnIm5zCjJHr0D3ouM2Tb0o0kpVQZs2bJli5QgCiGEEGKf0tDWxYOvbwAgKcHFV06cjStKYOXTOuo2Yuxq7ezlX29vpKO7L+w2SsHlx83Ek5I4gkc29m3dupXy8nKAcq311lhuMxYzYGOe1+uloaGB3t7gqkgRq8TERHJzc3G73aN9KEIIIYRwcGa/xud5YgqsJPjas2WkJnLWwWW8s66als5eOrp76ewJnNKkNVQ2tEsWbBhIADYIDQ0NpKSkkJ+fL6n2QdBa09bWRkNDAwUFBaN9OEIIIYTw01qzraa/afTEfE+ErcXepCAzlTMWltm/+7Smq8fLextr+GRrPQA7JQAbFq7RPoA9UW9vLx6PR4KvQVJK4fF4JIMohBBCjCGbqpr5+2vr2VrrnP8lAdi+yqUUackJlBf2zwHc1dgxike095AM2CBJ8DU08vgJIYQQY4fXp3npkx309PV3Ncz1JJOdLl0N93XFOWn2z7UtXXT3eklOlCkkQyEZMCGEEEKIfVxTe7cdfLldirkTcjhzYZmcMBUkJbgpyEyxf5cs2NBJACaEEEIIsY9rbOu2fy7NTef4/ceTKWt6Cb+SnHT7552N7RG2FLGQAGwv9fjjjzN37lzS09OZNGkS//nPf0b7kIQQQggxRjU4ArBcT/IoHokYi0py+8sQdzZIBmyoZA7YXmjp0qVce+21PPzwwxx++OHU19fT2toa/YZCCCGE2Cc1tHXZP0sAJoKV5PZnwKqaOvD6fLhdkscZLHnk9kI//elP+elPf8qRRx6Jy+WioKCAyZMnh9z20ksv5atf/SqnnnoqHo+Hww47jJ07d/L973+f3Nxcpk2bxrvvvmtvv379ek444QRycnKYMWMG999//wjdKyGEEELsLoEZsJQIW4p9kSclkcxUawFmr09T29wV5RYiEgnA9jJer5f33nuPhoYGpk+fTklJCZdddhnNzc1hb/Poo49y0003UV9fT0ZGBkcccQTTp0+npqaGiy66iG984xuA1X7/tNNO46ijjqK6upoHH3yQ73znO7z++usjdfeEEEIIMcy01oEBWIZkwMRAzixYpcwDGxIpQRyi//fsZyP697516n4Rr6+urqa3t5d//etfLF26FI/Hwxe/+EWuvfZa7rvvvpC3OfPMM1m4cCEAZ599NrfeeitXXnklAOeffz6//OUv8fl8LF++nMbGRq6//nrcbjcHH3wwl19+OQ8++CBHH3308N5RIYQQYi/T0d3Hcx9V0Of1sXBqIZOLMsZEl8HWzl68Pg1ASpKb1CQZHoqBSnLTWVvZBEgnxKGSDNheJi3NmiR5zTXXMH78eLKzs7nhhht45pln+OpXv4rH48Hj8fDVr37Vvk1RUZH9c2pq6oDfe3t76enpobKykvHjx+N296/9UFZWRmVl5QjcMyGEEGLP9s66Kiob2qlu7uSZD7fx2Lub+WhzHbUtnWitR+24pAGHiEVJjrMRR/uovmb3dHKKYy+TnZ3NhAkTQp5Ru+uuu7jrrrsGve/S0lJ27NiB1+u1g7CtW7dSWlo66H0KIYQQ+4K2rl7W+LMHxs6GDrujXGqSmwn5HibmeygrzCA9OXFEjsunNfWOBhx5Mv9LhJHrSSY50U13r5fOHi9N7T3kSMA+KBKADVG0ksDR8OUvf5k777yTU045hfT0dH75y19yxhlnDHm/hxxyCNnZ2fzqV7/iuuuu49NPP+W+++7j8ccfH4ajFkIIIfZeH26qtcv80pIT6OjuC7i+s8fL+p3NrN/ZjNul+MIRU8nPHHww1Ov18e76alZvbyQvI4UF5fkkJrhobOumoa3L/3837UHHIQNqEY5SipKcNLbUWJ21dza2y+tlkCQA2wv9+Mc/pq6ujtmzZ5OQkMCpp57K73//+yHvNzExkaeffpqvf/3r3H777RQWFnLrrbdyzDHHDP2ghRBCiL1UR3cfn1U02L+fsF8peZkpbKttY3ud9a+r12tf7/VpPtxcy0nzJ8T8N7w+zSdb61m1vQGfT9Pr9dnBVWVDO5UNsTVNkBJEEUlJbnp/ANbQwZwJuaN8RHsmNdbqN5VS2cBfgSVAC/ALrfWfQmx3F3Cx46JEoEdrneG//jXgUMCc2qnWWk+J8RjKgC1btmyhrKxswPU7d+6kpKQktjskwpLHUQghxL7gk631vLZqJwAFmSlccOTUgKkCWmtqW7rYXN3C8g01ALhdii8fP5MUR0MMr0/T0d1He3cv7V39/7d19VLV1BEwl2uwLj9uJhmpI1P+KPY8Oxva+fc7mwHISE3kwkXTSEl0R7nV3m3r1q2Ul5cDlGutt8Zym7GYAbsT67hKgCnAy0qpNVrrV50baa2/CtidJJRS9wO+oH1dq7Ue/KQnIYQQQoghqm/tn2M1oyR7wDxtpRSFWakUZKawubqF2pYuvD7NmsomFpTnU1nfzmurdlLXGt/aS8mJbg6fUURzRw9ba1pJdLvIy0ghx5NMrv9fbUsXL3+yg16vj1xPMp6UsTg0FGNFUXYqbpfC69O0dvby99fWcdzcUqYVZ432oe1RxtS7TCmVDpwHLNBatwIrlFL3ApcDr0a53TnAaSNyoEIIIYQQMWpsj63LoFKK/SblsfQzq7vwZ9sayPUk88yH2+jzRq9YSnArDplWRHlhBj19PvIykklKsLITi2YVh7xNdnoyRdmpbKtto6xgbLTFF2OX2+Vi7sRcPtlaD0BXj5fnPqrgrIPLmFSQMcpHt+cYUwEYMB2rLHK147IVwIlRbncOUAu8EXT5z5VSvwDWATdorZcG39Bf8pgddPH42A9ZCCGEECK8RkdpYLSmBTNKsnhrzS56+nw0tnfz3/e2BlyfmuTGk5JIenICacmJpKck2L8X56STlhz/0C4zNYn9JspcHhGbo2cXU5qbzhurd9HW1QvAcx9VcOK88WSkJtlrySW6ZbWrcMZaAObBmvfl1AREC6kvAR7QgRPafgCsBnqALwBPK6Xma603BN32WuDGwR6wEEIIIUQ4PX1euxmG26XITEuKuH1SgptZpTl8sq0+4PK05ATOPXSydJ0To04pxbTiLEpy0nj4rY20d/fR0+fjmQ8rArZzuxQZKYnMK89j3qQ8ya46jLXQtA3IDLosC2gNdwOl1ETgGOAB5+Va6+Va61atdbfW+u/Am4QuUbwDKA/6t2iQxy+EEEIIYXM2xshOS8IVwyD0sBlFzC/LIy/DakOfmZrI5w4pl+BLjCnpKYmcsbCMBHfo17TXp2nq6OH1Vbt46ZMd9HmDWzXsu8ZaBmw9oJVSs7TWa/yXzQdWRrjNF4G3tdabo+w7ZPG01roJK8tmkwhdCCGEEMMhnvJDIznRzdFzrC7BXp8PpVRMgZsQI60wK5WzFpbzaUU9nd19dPZ46ezpo6vXa697B7C2somunj7OWFgm42zGWACmtW5XSj0G3KKUugwrG3U5cH6Em30J+I3zAv+8rkOA17Ha0J8PHAV8ezccthBCCCFESIMJwJzcrrFWrCREoNK8dErz0gMu09pai+7N1btYub0RgK21baytbGLW+JzROMwxZSy+q6/GylbtAl4AbtJav6qUmqiUavOXHAKglDoMq2HGv4P2kQj8HKsxRx3wDeAsrfXakbgDQgghhBAADTF2QBRib6KUIinBzXH7lTJvUp59+Rurd9HZ0xfhlvuGMZUBA7sk8LwQl1dgNelwXvYOkB5i21pg4W46RCGEEEKImDgzYNnpEoCJfYtSisNnFrG5uoXWrl66er28taaKxfP27YbjYzEDJobozjvv5MADDyQpKYlLL73Uvnz9+vWceeaZFBQUkJOTw+LFi1m9enX4HQkhhBBi0Hxa0yQZMLGPM5kwY01lo92+fl8lAdheqKSkhJ/85CdcccUVAZc3NTVxxhlnsHbtWmpraznyyCM59dRTCezeL4QQQoih6Onz8vqqnfzrrY2YPgTpyQn2oshC7GvKCjMoyU0DQGtYWdEwykc0uiQA2wt97nOf46yzziIvLy/g8oMPPpgrrriCvLw8EhIS+Pa3v83WrVvZuXNn2H2VlZXxm9/8hnnz5uHxeLjkkkuora3l9NNPJzMzk6OPPpqamhp7++eee47999+frKwsDj30UN57773ddj+FEEKIsaa+tYuH39rIiq311LZ02ZdL9kvs6+aX5ds/f1bRgNe377alH3NzwMTIeeONN8jNzaW4uDjido899hgvvvgiWmsWLFjAihUruPvuu9l///05/fTTue2227jtttvYsGED5513Ho899hiLFy/mgQceYMmSJWzcuJGcHOl4I4QQYu+2fmcTr3xaSW+I9Y7Mml5C7KsmF2WSnpxAe3cfHd19PPn+NhJcitSkBNKSHf+SEshOTyYjNZE+r4+lKytpbOvhqNnFFOdYWbQ+r48E956bR5IAbIg+/PDDEf17Bx544LDsZ+fOnXzta1/j9ttvxxWlxe0111zDuHHjADj66KNJS0tj4UKrx8nZZ5/N448/DsAjjzzCSSedxJIlSwC4/PLL+dOf/sSzzz7LxRdfPCzHLYQQQow1Xp/mrTW7WLG13r7M7VLMK8ujtrkTlGJBeX6EPQix93O7FPtPyuOd9dUAbK9ri7j9vEl5dPb2sX5nMwD/fW8LJ82fQGVDOysrGjjn0MkUZqXu9uPeHSQA2wfV1dWxePFirrjiCi677DL78jlz5rBt2zYA/vKXv3DRRRcBUFRUZG+Tmpo64Pe2NusNVFlZyaRJkwL+VllZGZWVlbvtvgghhBCjqa2rl+c+qmBXY4d9WXZaEqceOIn8TMl6CeE0Z2IOH26upacvevnhJ9vqA37v6fPx9Afb7N8/3lLHSfMnDPsxjgQJwPYxjY2NLF68mFNOOYWbbrop4LpVq1YNad+lpaV89NFHAZdt3bqVs846a0j7FUIIIcairp4+/vXWRtq7+9c1mlyUyYnzxpOcKA03hAiWnpzIeYdNYVttKylJbpIT3HT2euno7qXDX5rY1N5DXWtX1H3VNnfi9WncLjUCRz68JAAbouEqCRxOfX199PX14fV68Xq9dHV14Xa76ezs5KSTTuLwww/ntttuG/a/+/nPf55f/epXvPjiixx//PE89NBDbN68mVNPPXXY/5YQQggx2rbXtwcEX0fMHMeBk/NRas8bEAoxUvIzUyJmh7XWvLO+mvc31gJQmpvOETPH8fQHW+ns8VKam84Bk/MpL8zYY99rEoDthX7+859z880327//4x//4JJLLuHYY4/l/fffZ9WqVfz973+3r3/++edZtGjRkP/u9OnT+de//sX3vvc9KioqmDFjBs8++6w04BBCCLFXau/uX8to9vgcDppSMIpHI8TeQSnF4TPGMT7PQ0NbF3Mm5JLodnHpsTPo7fORnpI42oc4ZErWgBpIKVUGbNmyZQtlZWUDrt+5cyclJSUjfVh7HXkchRBC7MmWra3i/U3WWfpDphVy6PSiKLcQQuxttm7dSnl5OUC51nprLLfZc/s3CiGEEEKMImf5YXqyFBUJIWIjAZgQQgghxCB0OEoQ05L3/LIoIcTIkABMCCGEEGIQAjJgKZIBE0LERgIwIYQQQohB6HAEYGlSgiiEiJEEYIMkzUuGRh4/IYQQezKf1jIHTAgxKGMuAFNKZSulHlVKtSqlKpVSXw+z3aVKKa9Sqs3x74R49zMYLpcLr9c7XLvbJ3m9XlyuMffyE0IIIWLS2dMffKUkunHLd5oQIkZj8XTNnVjHVQJMAV5WSq3RWr8aYtv3tdaHDsN+4pKWlkZLSws5OTl77AJwo0lrTUtLC2lpaaN9KEIIIcSgtHdJ9ksIMThj6hNDKZUOnAcs0Fq3AiuUUvcClwMxB07DtZ9wMjIyaGhoYNeuXUPd1T4rOTmZjIyM0T4MIYQQYlBk/pcQYrDG2ifGdKzFoVc7LlsBnBhm+/2VUnVAA/AQ8AutdV88+1FKZQPZQRePj3SQSiny8vIibSKEEEKIvVi7owV9eoq0oBdCxG6sBWAeoCXosiYgVKrkDWAOsM3//yOAD7glzv1cC9wY6mC+9IelpOZEX9V+yYIJXHva/gGX3fHMpzz/8faotwW4+KhpfPHo6QGX/fRf77N8Q01Mt//WqftxygETAy67+m9vsrEq+CEI7ebzD+LQ6YH384Lfv0JDW3dMt7/zy0cyrTgr4LKTbnk2ptsC/PPa48nLSLF/r2/t4sI7/hfz7V/8yakBv2/Y1cw1d78V021zPck8/O0TAi57d301Nz7yQUy3nzouk/+7clHAZc99VMH/e/azmG5/yLRCfvaFhQGXPfj6ev7xxoaYbi+vPXntOclrT157sZDX3vC89pwZsH++uYHfPf1pTLeX15689pzkc2/Pf+11NlbHtA+nsTZjtA3IDLosC2gN3lBrvVlrvUVr7dNafwb8DDg33v0AdwDlQf8WhdhOCCGEEAIInAPmcsl8cCFE7MZaBmw9oJVSs7TWa/yXzQdWxnBbZ1/zmPejtW7Cyo7ZpLGGEEIIISLpcHRBdMm4QQgRBzXW1mNSSj0EJAOXYWWjXgHOD+5eqJRaAnykta5WSs0EHgMe01rfFM9+whxDGbBly5YtlJWVDdM9E0IIIcTe4t/LNrGzsQOAzx1SzoR8zygfkRBiNGzdupXy8nKAcq311lhuM9ZKEAGuxspm7QJeAG7SWr+qlJroX+vLFL8eD3yqlGoHngP+A/wi2n5G6k4IIYQQYu8lXRCFEIM15j4x/CWB54W4vAKruYb5/XvA9+LdjxBCCCHEULU7AjDpgiiEiMdYzIAJIYQQQoxZPX1eer0+ANwuRXKCDKeEELGTTwwhhBBCiDgElx9K8y4hRDzGXAmiEEIIIcRYs2p7AzsbOpgzIYeqpk778vRkKT8UQsRHAjAhhBBCiAiaO3p45dNKAFbvaAy4riQnbTQOSQixB5MSRCGEEEKICOpbu0JeXpiVysJphSN8NEKIPZ0EYEIIIYQQETjnfBmFWamcfUg5KYnuUTgiIcSeTEoQhRBCCCEicAZgJblpzJmQy7TiLBLdch5bCBE/CcCEEEIIISJo7+61f546LovZ43NG8WiEEHs6OXUjhBBCCBGBMwOWniznroUQQyMBmBBCCCFEBO1B634JIcRQSAAmhBBCCBFBe1d/CaKs+yWEGCoJwIQQQgixz1izo5HH3tnMxl3NMW2vtaajx1GCmCIZMCHE0MiniBBCCCH2CV29Xv73WSVen6amuZOJBR6SEiK3ke/1+ujzagDcLiWdD4UQQyafIkIIIYTYJ2yrbcXrs4KpXq+PLTWtUW8T3IBDKbXbjk8IsW+QAEwIIYQQ+4TN1S0Bv6/f2RT1Nu1dzgYcMv9LCDF0EoAJIYQQYq/n05pttW0Bl22taaWr1xvxdjL/Swgx3MZcAKaUylZKPaqUalVKVSqlvh5mu0uUUh8qpVr82/1OKZXkuP5+pVSPUqrN8S955O6JEEIIIcaKnQ3tdAcFWz4Nm6oiN+NwLsKcliQBmBBi6MZcAAbcidUcpAQ4FbhZKXVsiO3SgGuBAuAgYBHw46Btfqe19jj+de++wxZCCCHEWOWc75WU0D/8WbczcgDW0SVrgAkhhteY+iRRSqUD5wELtNatwAql1L3A5cCrzm211n92/LpLKfUgcPog/mY2kB108fh49yOEEEKIsUlrHTD/68hZxSz9rBKAHfVtdPV6SUkM3Q3RuQhzeorMARNCDN1Yy4BNB5TWerXjshXA3BhuexSwKuiyq5RSDUqpj5RSnw9zu2uBLUH/3oznoIUQQggxdlU2tNPU3gNAglsxqzSboqxUALS2uiOG0yEliEKIYTbWAjAP0BJ0WROQEelGSqkvAUcCv3Zc/AdgGlAI3ADcq5Q6KsTN7wDKg/4tiv/QhRBCCDEWfbyl3v55VmkOCW4XZYX9Q4utEdrRB2bAJAATQgzdWAvA2oDMoMuygLCfjEqpM4DbgZO11lXmcq31R1rreq11n9b6OeAfwDnBt9daN2mttzr/ATuG4b4IIYQQYpQ1d/QElB/OK8sDYHJR/3Bja00rPq1D3t65DpjMARNCDIexFoCtB7RSapbjsvnAylAbK6VOBu4FztBar4iy79CfrEIIIYTYa63YUmf/PKnAQ15GCgAFmSmk+wOqrl4vuxo7BtzWp3VgG3oJwIQQw2BMBWBa63bgMeAWpVSGUmp/rAYc9wZvq5Q6DngIOEdr/W6I689VSnmUUi6l1InAxcCTu/ceCCGEEGKs6OnzsnpHo/37/LJ8+2elFOWOMsQtQYs0d3T3sa6yCZMYS0l043aNqWGTEGIPNRZP5VwN/A3YhTUf7Cat9atKqYnAamC21roC+AlWeeKzSilz221a6zn+n78F3AMorMYaV2qtl47c3RBCCCHEaFq1vZGePh8AuZ5kJhV4Aq4vK8xk5XYrQFuxtZ4Et4uuHi876tuobwtcuUbKD4UQw2XMfZporZuwWtEHX16B1aTD/B5qbTDn9tJIQwghhNhH+bQOKD+cX5aH44QtABMLPKQnJ9De3YfXp1m+oSbs/qaOy9ptxyqE2LeMuQBMCCGEEGKotlS30NJptZBPSXQzc3zOgG0S3S7OPLiMF1fsoL61K+A6pWBcdhrj89KZmO+hNDd9RI5bCLH3kwBMCCGEEHsdZ+v5/SbmkugOPX+rIDOVC46cyoqtdeyoa6MgM5XxeemMy0kjKSH04sxCCDEUEoAJIYQQYq9S09xJZUM7YGWy9puUF3F7t0tx4OQCDpxcMBKHJ4TYx0k7HyGEEELsVVZs7Z/7Na04i4zUxFE8GiGECCQBmBBCCCH2Gu3dvazf2Wz/vqA8P8LWQggx8iQAE0IIIcRe47NtDXh91uJdxTlpjMtOG+UjEkKIQBKACSGEEGKvsWp7/8LLkv0SQoxFw9KEQyk1AzgGKMRa+BgArfXPhmP/QgghhBDRtHf10tZltZ5PdLuYMi5zlI9ICCEGGnIAppQ6D3gIWA3M9v8/B3gLkABMCCGEECOiurnT/rkgMwVX0MLLQggxFgxHCeJPgCu01vOBdv//38QKwIQQQgghRkSNMwDLSh3FIxFCiPCGIwArw8qAQX/54d3A5cOwbyGEEEKImNS29AdgRRKACSHGqOEIwFoB02KoVilV7v9dCq+FEEIIMWKqm/oDsEIJwIQQY9RwBGDLgLP9Pz8DPA0sRUoQhRBCCDFC2rt7ae/uA8DtUuR4kkf5iIQQIrTh6IJ4Mf2lhz8AarGyX7cPw76FEEIIIaKqbe6yfy7ITJUGHEKIMWs4MmAnaa27ALTWPVrrX2qtfwgcOgz7FkIIIYSIytmAozArZRSPRAghIhuOAOwfYS5/YDA7U0plK6UeVUq1KqUqlVJfj7DtNf5tWpVSjyilMgezHyGEEELs2WpaZP6XEGLPMBwB2IAcv1IqG/ANcn93YpVGlgCnAjcrpY4N8TcWAzf6tykFEoE/xrsfIYQQQuz5AjNgEoAJIcauQc8BU0ptATSQqpTaHHR1AfDsIPaZDpwHLNBatwIrlFL3YrW0fzVo80uB+7TWK/y3vR74WCn1NaygMNb9CCGEEGIP1tXTR2tnL2A14Mj1SAmiEGLsGkoTjpuwAp0/Azc7LvcBVVidEOM1HVBa69WOy1YAJ4bYdi7wnPlFa71GWRNup2Fl9mLajz9blx108XiA8vLyOA9fCCGEEKPtG6N9AEIIEcGgAzCt9d8BlFIbtdbD1XLeA7QEXdYEZITZtjnosmb/tiqO/VyLVcoohBBCCCGEELvVkNvQa63f8i++fAFQorW+Rik1DUjQWq+Jc3dtDFzAOQtrsedYts30b+uKYz93APcHXTYeeHPLli2UlZVFO2YhhBBCjKJnP9zGxirrvOvx+5Uyd2LuKB+REGJfsXXr1rir5obchEMpdRzwKXAkcIn/4nEMbh2w9YBWSs1yXDYfWBli25XAPMdxzMTKfG2IZz9a6yat9VbnP2DHII5dCCGEEKNAGnAIIfYkw9EF8TfAxVrrU4A+/2UfAAfEuyOtdTvwGHCLUipDKbU/VuOMe0Nsfj9wmVJqf6VUBvBz4BGtdUec+xFCCCHEHqqr10uLowFHXkbyKB+REEJENhwB2DSt9ZP+nzWA1roTGGwLoqv9+9kFvADcpLV+VSk1USnVppSa6P8bLwO3+LfZhdX84xvR9jPIYxJCCCHEGOTMfuVlpOB2DcfQRgghdp8hzwEDdiqlpmitN5kL/OWAgyrj01o3YbWQD768AqvxhvOyPxK49lfU/QghhBBi71HrLD/MlPbzQoixbzhOE90DPOJf5NillDoU+Bvw12HYtxBCCCFESH1eH9vr2+zfZf6XEGJPMBwZsN9jtXd/Aqvz4FLgLuDOYdi3EEIIIUQAn9asqmjg3Q01dHT32ZcXSAAmhNgDDEcbeh/Wosw3KaUKrYt07VD3K4QQQggRrKGtixc+3k5tS1fA5bmeZMmACSH2CEMKwJRSXwHmAm8ATwGPAouUUhXAKYNYB0wIIYQQIqTuXi//fW8rrf6uhwDpyQksKM9nv0m5uJQaxaMTQojYDDoAU0r9HLgCeBP4A3AhUAOcAXwJ+DVw5jAcoxBCCCEEr66stIMvt0tx0JQCDppSQIJbOh8KIfYcQ8mAXQQcq7Veq5TaD1gBFGqt65VSy4C1w3GAQgghhBBrKxtZt7PZ/v3EeeOZXpI9egckhBCDNJRTRnla67UAWuvPgA6tdb3/90ZACrGFEEIIMWTNHT28unKn/fvs8TkSfAkh9ljDmbPvjb6JEEIIIUTsvD7NCx9X0NPnAyA7LYmj5xSP8lEJIcTgDaUEMVkp9VPH76lBvycNYd9CCCGEECzfUE1Vk7XYslJw8oIJJCW4R/mohBBi8IYSgL0DHOv4/d2g398Zwr6FEEIIsY+rrG/n/Y39K9scPmMcRdlpo3hEQggxdIMOwLTWxwzjcQghhBBC2Lp6vbywYrv9+4S8dA6cnD+KRySEEMND+rYKIYQQYkzRWvPyJ9tp67Kml6ckujlx/gSUrPMlhNgLSAAmhBBCiDHlnfXVbK5utX8/fr9SPCmJo3hEQggxfCQAE0IIIcSYsamqJWDe1wHl+UwtzhrFIxJCiOElAZgQQgghxowPN/cHX5MKPBwxa9woHo0QQgy/MRWAKaXOU0ptVkq1K6VeUkqVhtmuUCn1sFJqp1KqWSm1TCl1hOP6MqWUVkq1Of7dPHL3RAghhBDx6ur1squxw/598bzxuGTelxBiLzNmAjCl1CzgXuAqIB9YB/wzzOYe4H3gQCAHuBt4RimVHbRdvtba4/934245cCGEEEIMi+11bfbPRVmppCfLvC8hxN5nzARgwMXA81rrV7TWncANwKFKqSnBG2qtN2utf6e13qW19mmt7wU08P/Zu+/wuIp7jePfn7pkSZZc5S53XHAJEOwE0y8QOhcIYAM23UkgQAoQegkm4RIgjQ6xMTa9hIQAoWMgFIMh2NgYbEvuRdjqXZr7x1mtVs1ayavdlfR+nmefPWXOnNk9MujVzJkzIcxtFhERkRDJ2V4/8cawvmkRbImISMfZkwcxh9pE4OO6FedcgZnl+Lav2d2BZjYRr1dsdaNda8zMAW8Av3bObW/m2Awgo9HmwW1su4iIiLTD9oIyPvl2O6lJ8azZVujfPqxvagRbJSLScaIpgKUCBY225QO7/ROYmaUBjwHznHN1d+7mAfsBnwO9gb8CjwOHNVPFZYCGJ4qIiHSA6ppaPly9jYLSShLjY71XnPdeVlnN0jU7qKl1DY5JjI8lKzMlQi0WEelYEQtgZjYLuN+3mgt8C6Q3KtYTKKIFZpYM/ANYBvgn2XDOFQNLfavbzOxiYIuZZTrndjWq5m5gfqNtg4ElwX4WERERad6ydXl8ujavTccM7ZOqyTdEpMuKWABzzi0CFtWtm9mtwOSA9XRgOLC8uePNLBF4AdgKnOecc82Vqztd3WHNtCMfr6ctsO4gPoGIiIi0JvC+rpb0TEmgoLTSv67hhyLSlUXTEMTHgI/M7FDgP8AtwIfOuSb3f5lZPPAMUA6c6ZyrbbR/f7xQ9Q3eLIl/At5xzu3s0E8gIiIiflU1tWzNr59W/qAJA6iucVRW1VBeVUNldQ39eqYwaVgv1m4r5N2vtpCZmsjYgRmRa7SISAeLmgDmnFtpZufhTSmfBbwHzKzbb2b3+crNBX4AHAuUAfkBPVYX+XrWRgDzgH5AIfAacHp4PomIiIgAbNlVSt3tXb1SE5mS3afFsmMGZjB6QE+NQhGRLi9qAhiAc+5p4OkW9s0NWH6HZoYTBux/HG/SDREREYmQTd+V+JcH9+7RanmFLxHpDqLpOWAiIiLShWzcWf9g5UG9Wg9gIiLdgQKYiIiIhFx1TS3b8sv864OC6AETEekOFMBEREQk5LbsKvU/36tXaiI9EuMj3CIRkeigACYiIiIh99XG+sduavihiEg9BTAREREJqY3fFbNqU75/ffSAnpFrjIhIlFEAExERkZCpqa3lreWb/eujB/RkSB89WFlEpI4CmIiIiITM6s0F7CyuACA+NoYDxw+IcItERKKLApiIiIiEzI7Ccv/ylOzepCZp8g0RkUAKYCIiIhIyJRVV/uXM1MQItkREJDopgImIiEjIlJRX+5d7JMZFsCUiItFJAUxERERCJrAHrIeGH4qINKEAJiIiIiGjHjARkd1TABMREZGQqKyuoaqmFoDYGCMxPjbCLRIRiT4KYCIiIhISpRX1vV8piXGYWQRbIyISnRTAREREJCSKywPu/0rU/V8iIs2JqgBmZqea2VozKzGzf5vZoN2UzTGzMjMr9r3ebG9dIiIisudKAnrAeiTp/i8RkeZETQAzs3HAI8CFQB/ga2BxK4ed5JxL9b0O3cO6REREZA8ETsCRqh4wEZFmRdOfp84EXnbOvQ5gZtcC281spHNuTQTrEhERkSA0nII+mn7FEBGJHlHTAwZMBL6oW3HOFQA5vu0tWWBmO8zsNTOb2p66zCzDzLIDX8DgPfkgIiIi3VHjSThERKSpaApgqUBBo235QFoL5WcB2cAw4E3gVTPr1Y66LgPWNXotaUvDRURERJNwiIgEI2IBzMxmBUygsQIoBtIbFesJFDV3vHPufedcmXOu1Dl3G7ATOMi3uy113Q0Mb/Sa0Y6PJCIi0q01eAizhiCKiDQrYv91dM4tAhbVrZvZrcDkgPV0vDC0PNgqA5aXB1uXcy4fr3eMgPJBnlJERETqNLgHTD1gIiLNiqYhiI8BPzKzQ80sGbgF+LC5STPMbKiZ/dDMEswsycx+DfSlfuhg0HWJiIjInquqqaWyuhaAGIPkhNgIt0hEJDpFzfgA59xKMzsPeAjIAt4DZtbtN7P7fOXm4t3LdS8wEigHPgeOcs7lBVOXiIiIhMau4gpe+jSX74or/NtSEuM1mkREpAVRE8AAnHNPA0+3sG9uwPIKYFJ76xIREZE9V1RWxXMfrWsw+QZAD82AKCLSomgagigiIiKdRHllNS983DR8ASRp+KGISIsUwERERKRNKqtreOHjHHb6hh3GNBptmJ6cEIFWiYh0DgpgIiIiErSa2lr++el6thWU+bcdOWUIh08a5F8f0b/xk2BERKSOBmmLiIhIUGqd49XPN7Ihr9i/7ZCJAxkzMAOArIwUap2jT1pShFooIhL9FMBERESkVc453l6+mW+2FPi37T+6H5OG9fav91bwEhFplYYgioiISKu+2VLAl+t3+tcnD+vN/qP7RbBFIiKdkwKYiIiI7FZNbS3vrdrqXx8zsCcHTRigZ32JiLSDApiIiIjs1ufrvqOozJtuPik+lkMmDlL4EhFpJwUwERERaVFRWRUff7vdv77/mH4kxes5XyIi7aUAJiIiIs0qqajiuY/WUlldC0BGSgJ7D+0V4VaJiHRuCmAiIiLSRHllNc9/lEN+SSXgPWz50L0HERujXx1ERPaE/isqIiIiDVRW1/DCxzl8V1Tu3/ajqUMZ0ic1gq0SEekaFMBERETEr6bW8eInuWwrKPNvO2LyYEYN6BnBVomIdB0KYCIiIuK3dM12Nu0s8a8fPGEg4wZnRrBFIiJdS1ykGyAiIiLhtem7EtbnFZOcGEtqYjxpyfGkJsdTVlHDx98EzHg4uh+Ts3tHsKUiIl1PVAUwMzsV+D3QH3gfOMc5t6mZckOBrxpt7gH8yjn3BzM7GHgTKA3Yf6lz7uGOaLeIiEhnsWZrIS99lotzuy+XlZHM90f3C0+jRES6kagZgmhm44BHgAuBPsDXwOLmyjrn1jvnUutewN5ALfBsQLHtgWUUvkREpLvb+F0xLy9b32r4io0xDp80mBg9bFlEJOSiqQfsTOBl59zrAGZ2LbDdzEY659a0cuzZwLvOuZwObqOIiEinVF5Vw0ufrqem1ktf6cnxDOubRlFZJUXl1RSXV1FRVQPAQeMH0DstKZLNFRHpsqIpgE0EPq5bcc4VmFmOb3uLAczMDC+A3dJoV28z2wqUAS8C1zjnips5PgPIaLR5cNubLyIiEr2+3pRPuS9gpSTG8b/TRtAzJaFBmcpqb39CXGzY2yci0l1EzRBEIBUoaLQtH0hr5bgD8O4ZeyZg2ypgMjAQOBSYCvyxheMvA9Y1ei0JvtkiIiLRzTnH8vU7/evfH9WvSfgCL3gpfImIdKyIBTAzm2Vmxb7XCqAYSG9UrCdQ1EpVs4FnA3u3nHNbnXNfOedqnXPrgCuAk1s4/m5geKPXjDZ/IBERkSi1raCMPN9DlWNjjLGDMiLbIBGRbixiQxCdc4uARXXrZnYrXq9V3Xo6Xhha3lIdZpYMnAqc1NrpgGbvJHbO5eP1tAXW20p1IiIinceXufW9X2MHZpAUr14uEZFIiaYhiI8BPzKzQ33B6hbgw1Ym4DgJ2AW8FbjRzA4xs2HmGQL8Dni+oxouIiISrXYUlvH15nz/+sShvSLXGBERiZ4A5pxbCZwHPAR8B4wDZtbtN7P7zOy+RofNBhY612RC3anAB0CJ7/1L4JIOarqIiEiHyy+poLa1+eMbKSmv4sVPcv0zH/ZNTyIrI7kjmiciIkGKplkQcc49DTzdwr65zWw7soWydwJ3hrZ1IiIi4VdTW8vLyzawZmshqUnx/M/kwQztk7rbY0orqlm5cRfL1uVRUlENQEJcDEdMHqJh9iIiERZVAUxERKQ7ytlexHsrt2Bm9OyRQM/kBNJTEuiZksDKTbtYs7UQgOLyKp7/aB17Dcpg76G9GJCZgpnhnGNbQRk524vI2V7EtoKyBvWbwY+mDqVPup7tJSISaQpgIiIiEbTpuxL++Wn9MMG62Qp3Z9WmfFZtyqdHYhz9eiazNb+UssqaZssmJ8Ry8ISBZPdr7akuIiISDgpgIiIiEfJdUTkvLs3xh6/dGT84k9KKKnJ2+J+6QklFNeu2N31aixkMyExh/OBMxg7MIC42am75FhHp9hTAREREIuT9VVuprK4FICUxjv+ZNJiK6hoKSyvJL6mksKySkvJqhvdP44C9sgDYml/Gig07+XZrIRVV9b1eyQmxDOubxvB+aQztm6ap5kVEopQCmIiISATUOsemnSX+9eP2GUZWZkqrxw3ITGFAZgqH7u3YXlDGd0Xl9E5Lon/PZE2wISLSCSiAiYiIRMDOoooGvV/92zg9fIwZWRkpZGW0HtpERCR6aFC4iIhIBGzJL/Uv181mKCIiXZ96wERERPZQQWklKzfuIiEulsnZvYiNaf3vm1t21Q8/HKBeLBGRbkMBTEREpB3ySyrI2VHEhrxi1m6rn4nw260FHLPPUHokxu/2+C27GvaAiYhI96AAJiIi0kYb8op57qN1ze7bsquUR99ezdA+qQzpk8qQ3qlk9EhoMMSwrLKa/JJKAGIM+vVs2/1fIiLSeSmAiYiItNGydXlNtmVlpLDVd19XZXUt324t5NuthQCkJsUzpE8PDCO/tIJdxRX+4/r1TNZzukREuhEFMBERkTYoragmZ0f9kMMZ4waQ3S+VXqlJ5O4o4o0vN1FUVtXgmOLyKlZuzG+2vgGZPTqyuSIiEmUUwERERNrg6835OOctD8hM4Xsj+vj3DeubxjmHjOW7ogo2fFfMhrxiNu0s8U833xzd/yUi0r0ogImIiLTByo27/MvjBmc22W9m9ElPok96ElOH96HWObbll7F5VwmxMUZaUgLfbMnn262F9ElLYni/tHA2X0REIkwBTEREJEjfFZWzo7AcgNgYY/SAnq0eE2PGgMyUBj1dI7PSqXUOAz3/S0Skm4mau37NbICZvWhmW8zMmVl2K+UzzOwpMysys01m9tNG+w8ys+VmVmpmH5rZhA79ACIi0uUF9n6N6J9OUnxsu+uKMVP4EhHphqImgAG1wCvA/wZZ/i94PXgDgWOAm8zsEAAz6w38HbgNyASeB/5uZurxExGRdqupdcTGeKFpr0EZkW2MiIh0SlETSJxz24B7gglJZtYDOBWY6pwrAj43s0eAc4G38ELcaufcIl/5/wMuBQ4C3uigjyAiIl3cQRMGsv+Y/qzZWsCwvrp3S0RE2i5qAlgbjQHMOfdVwLbPgSN8yxOBL+p2OOdqzexL3/YGAczMMoCMRvUPA9i4cWMo2ywiIl1ED2DD+sJIN0NERCIsIC8EPSa9swawVKDx//nygbSA/bt2sz/QZcANzZ1kxowZ7W2fiIiIiIh0HwOANcEUjFgAM7NZwP2+1VznXFsmySgG0htt6wkUBbk/0N3A/EbbEoARwDdATRvaJS0bDCwBZgB1fypYBwyPWIskUCiuRXPXWNqmM/yb6C7XuTNci44Qjde3u16LjtLea6zrED0Cr0U0/pvtTtYBo/DC1yfBHhSxAOa7P2tROw9fDTgzG+ecW+nbNgVY7lteDpxfV9i8aaYmAf/XTDvy8XrHmjuHhEjATF8bnXM5ddvqliWyQnEtmrvG0jad4d9Ed7nOneFadIRovL7d9Vp0lPZeY12H6BF4LaLx32x34rsWawiy56tONM2CiJklAYm+1UQzS7Jm5uh1zpUAzwC3mFmamU3Cm4DjEV+R54CxZnaGmSUCvwJKgXc6/EOIiIiIiIi0IKoCGFCGN3wQYJVvfRiAmV1tZi8HlP0Z4IAteNPX3+icewvAOfcdcCJwLV7v1inACc656o7/CNIGN0W6AeKnaxEddB2ih65F9NC1iA66DtFD1yJ6tOtamHMu1A0RacL3YO11wHB1kXdNusbdg65z16br2/XpGnctup6dU7T1gEnXlY/3V4L8yDZDOlA+usbdQT66zl1ZPrq+XV0+usZdST66np2OesBERERERETCRD1gIiIiIiIiYaIAJiIiIiIiEiYKYCIiIiIiImGiACYiIiIiIhImCmAiIiIiIiJhogAmIiIiIiISJgpgIiIiIiIiYaIAJiIiIiIiEiYKYCIiIiIiImGiACYiIiIiIhImCmAiIiIiIiJhogAmIiIiIiISJgpgIiIiIiIiYaIAJiIiIiIiEiYKYCIiIiIiImGiACYiIiIiIhImCmAiIiIiIiJhogAmIiIiIiISJgpgIiIiIiIiYaIAJiIiIiIiEiYKYCIiIiIiImGiACYiIiIiIhImCmAiIiIiIiJhogAmIiIiIiISJgpgIiIiIiIiYaIAJiIiIiIiEiYKYCIiIiIiImGiACYiIiIiIhImCmAiIiIiIiJhogAmIiIiIiISJgpgIiIiIiIiYaIAJiIiIiIiEiYKYCIiIiIiImGiACYiIiIiIhImCmAiIiIiIiJhogAmIiIiIiISJgpgIiIiIiIiYaIAJiIiIiIiEiYKYCIiIiIiImGiACYiIiIiIhImCmAiIiIiIiJhogAmIiIiIiISJgpgIiIiIiIiYaIAJiIiIiIiEiYKYCIiIiIiImGiACYiIiIiIhImCmAiIiIiIiJhogAmIiIiIiISJgpgIiIiIiIiYaIAJiIiIiIiEiYKYCIiIiIiImGiACYiIiIiIhImCmAiIiIiIiJhogAmIiIiIiISJgpgIiIiIiIiYaIAJiIiIiIiEiYKYCIiIiIiImGiACYiIiIiIhImCmAiIiIiIiJhogAmIiIiIiISJgpgIiIiIiIiYaIAJiIiIiIiEiYKYCIiIiIiImGiACYiIiIiIhImCmAiIiIiIiJhogAmIiIiIiISJgpgIiIiIiIiYaIAJiIiIiIiEiYKYCIiIiIiImGiACYiIiIiIhImCmAiIiIiIiJhogAmIiIiIiISJgpgIiIiIiIiYaIAJiIiIiIiEiYKYCIiIiIiImGiACYiIiIiIhImCmAiIiIiIiJhogAmIiJ+ZpZtZs7Msn3rc8wsJ2D/fWZ2X6TaFwwzm29m8/ewjqvN7OWA9bfN7MaA9WIzm7En52jhvOeY2d9DXW+kmFmOmc3Zzf4TzOytMDZJRCTiFMBERLoQX1Co9AWEQjNbYWYXhKp+59xc59zcUNUXDRqHKwDn3Dzn3I9aOsY5l+qcW+I7/mAzcyFoRzLwO+CaRtsPMrMlvmu6MxoDWuPgHizn3N+BVDM7qWNaJiISfRTARES6nnnOuVQgA7gJuN/MDoxskyQIZwJrnHPL6zb4rtuLwH1AXyALuDUyzeswDwKXR7oRIiLhogAmItJFOedqnXNPATuB79dt9w37WmZmBWb2lZmdF2ydjYf3+YaYXWNmL5tZkZl9Y2YnNDrmCjNbb2b5ZvY3M3u8pSGCZna0me0ys6SAbWZm68zsXN96LzN7xMw2m9l2M3vWzAbvps23mNm3vh6kXN96jG/ffcAM4Grf/q2+7Tea2du7qdP5er6GAi/7thX7Xj83syfM7IFGxxzm+47SWqj2f4FXG237HfCAc26Rc67MOVfpnPu4pXb5zjPfzBab2YO+73yLmZ1pZpPM7CNfG94xs0EBx+z2O/XVucjM/mJm35nZ1ka9hivq3n3fwR8C9g3a3c8H8G/gADPru7vPJSLSVSiAiYh0UWYWZ2Yzgd7A175t04Cn8HrGegFzgTvN7H/34FQXAFcDPYEHgEfNLNV3vlnAlcCpQB/gHeCU3dT1KlACnByw7TDfZ3jSt/4YMAiYBIwESoEXzSy2hTq/Bg4G0nzn/glwHnhDKoEl+HoNnXNZwX5o3/HrgR/5llN9rz8B9wJn1H0PPhcCi5xzRS1U9z0gsPerB7C/b3mpL/j8x8wOC6Jp/wv8A+97uwm4H6/n7BSgv6/MbwPKB/Odnox3/fr5lq+x+vvgJtS9+76DXwYc1+LPB4BzLgfvmu8TxOcSEen0FMBERLqeq8wsHygHFgJXO+f+4dt3DvB359wLzrka59y7eEPALtyD8z3gnFvmnKvFCx7pwFjfvjm+/R8556qdc/OBT1uqyDlXA8zHF5B8zgOedM6VmNkAvMBzuXMuzxdmLgYmA/u1UOdjzrmNzvMJsAg4vP0ft3XOuXeA9cBMAF/vzol4QaglmUBBo/UYvKGJF+ANP3wE+IeZjWilCe845170fZ+PAinAYufcBudcKfAssK+vbcF+p+865572/dy8D3xBQM/qbuzu56NOId4fBEREujwFMBGRrud3zrkMvF/g/wYcbmZxvn1DgLWNyn8LDN2D822uW3DOFfsW64bZDQZyGpVvvN7YI8BBZjbCzDKBk4CHfPuG+N79n8E5VwDsoIXPYGY/MbPPfUMb84GL8HpxOtp9eMEJYDbwhXNu2W7K78TrJapT11P2iC/AVDnnHgTWAUdCg2GPxWZ2dcCxW+oWfIGrwTa8Hq66axTsd7qZhooD6tid3f181EnH+/wiIl2eApiISBfl68n4GTDc9w6wwbceaCReb01H2AhkN9o2bHcHOOfWAm/j9dbNAr5xzn3k273B9+7/DGaWjje8sclnMLMfAHcDPwf6+oLp/YAFFKsN5oPsRkvHPwqMN7OpeEFsd71f4PUM1g3lqwtBa4HGMyy6gDKpAa95bW65p03faQva/R2a2TCgB7vpGRUR6UoUwEREujDnXAVwM3Ct75fq+cCJZnacmcWa2QF44eCh3VSzJxYA55vZfr570s4muHt9HsIbvng+8HDdRufcFuAVvPvW+vjuJfoz3iQQnzRTT0+gBq83p8Z3z9KsRmW2AmPa9KmaHo+ZNRhW5wtQi32fJQt4opV6nsPXsxXgr8C5Zra373qdgxdoX258cHu14zttzg68ENZ4aGEwjgDed87taMexIiKdjgKYiEjXtxBveNevnXP/Ac4AbgF24YWDK5xzz3TQuRcBd+KFizzgELxp1ctbOe55vF6RcXgTRAQ6E9gGfIk3HC8NOM53v1Njr+IFuPfxvoOf+9oU6A/ARN+MgRuD+1j1nHOr8QLLe746Lg7YfR/e5BqPOedKWqlqMTDSzCYGbLvLV8ereNfrQuAY38QVodSW77QJ51wZ3kQbC3zfwe1tOPf5eL2UIiLdgjm3x8+OFBERCZqZLQWedc7dFum2dDQz64PXQ7aPc+6LIMqfA5zonGs8VXuXZGbHA79wzh0c6baIiISLApiIiHQoMzsd+DvevUsXAf8HjHfOfRvRhnUw3xTu/wdMdc4dEun2iIhIdIhrvYiIiMgeuYj6iS9WAyd0g/A1BW/Y4wa8Z3KJiIgA6gETEREREREJG03CISIiIiIiEiYagtgMM0sE9sN7aGVQM0CJiIiIiEi3EwsMAD7xPfqlVQpgzdsPWBLpRoiIiIiISKcwA3gvmIIKYM3bArBkyRIGDx4c6baIiIiIiEgU2rhxIzNmzABffgiGAljzagAGDx5MdnZ2hJsiIiIiIiJRLujbljQJh4iIiIiISJgogImIiIiIiISJApiIiIiIiEiYKICJiIiIiIiEiSbhEBERERGR8KisgG05UF0FcfGQNRziEyLdqrBSABMRERERkY5VVQmfvAzvPAmlRfXb4+Jh8FgYvrf3GjzWC2TlpfDdJijIg5ICqKoA5yAxBZJSILM/DBoduc+zBxTAREREREQkODU1Xg9WeYkXiop2QUm+F45iYgCrf6+tgaKdsD0X1q/0er0aq66CnOXe663HvUCW3ht2bt19O8ZPhzOuDv3nCwMFMBERERGR7qi21gtArtYLSgV5kNQDeg/0epkC1VTDf9+Bt5+EnUE/c7h56b29HqySAsjb1HBfdVXr4Qu8nrBOSgFMRERERCQaFe3ywk5tjReWamu8sFRT4wWluvunCnbArm2Qv90LJtkTITXDCzPlJVBRWv9eUwNV5bDifVj1kTc0sDmpGV4Q6z3QO9eXS7yQtif6DILvHwP7HeX1dAEU7vT1gH0J676sD2QxMdBnsBfUUjMhPtHbXlnmDU8cPGbP2hJBCmAiIiIiIq1xzgtEBTu8ZbOGQ+52bISlr8DmbyElHTL6wYCR0G8oVFd6QScmBmLjICa26XtNtTeUr6rS631a8wWs/I93rt0xa75MbJxXZ3sV53uv3K+a7kvqAQNGeCGqRwakZXqfobYWcN573XeUmgmZ/WDIXl7PV2PpvWDSgd4LvEBWUuCFtS46OYcCmIiIiIhIY2UlXm/Trq3w4T9h1Ydez0swKsq8Hql1X3ZsG6HlgBZs+IpPAAx69ISefaC00BsC2Nzxab1g/2Ng/2ObDlEMlfRe3qsLUwATERERke6jOB/W/hc2rIKaxpNCGFSWw4aVwd2HFA4DRnjDCmNivF4mi/GWC7+D7eu9YYk9+0BGf+jZ1+uh27DKC1CxcV5vVWKK956U4m3DvJ65KYdCVnbTc9bWevV8t9l7Fe30evP2+r7veNkT+gZFREREpHt49xl4Y6FvqFw7JPWAXlleCKkbZud873HxMGY/mHKId+9V3ibYtBryd0BCktfTVFvrBaPaGu9Vt1xT7QWr1AzvXqfKMi80TTkU+g9ruT11vVSNQ1FNtXeu9g7hi4nx7r3K7A+jpravDmmRApiIiIiIdD11YSc2zgsUH/wdXlsQ/PFx8V5wshgYMRmmH+9N/GAW3PF9B8O4/dvX9mC11BsVGwexHXtqaT8FMBERERHpOr7bAu8/B5+/5T2nCppOVJGVDeOme/c0+bfXvZu3f9BoDbeTDqGfKhERERHp/LasgyXPwPIlTSemCFwfOg5m3wIJieFtn4iPApiIiIiIdD7OQWkRbF3rDS9cvbRpmdg437OzfAEseyLMvFbhSyJKAUxEREREOo+aavj4Za+3q6UHA4/+Hsw4FbIn1A8/rK3RkEKJCjGRbkBjZpZhZk+ZWZGZbTKzn7ZQbo6Z1ZhZccDr8LbWIyIiIiKdROFO+Osl8K8HmoYvM5jwQ5h7F5x9EwyfWD9hhpnCl0SNaPxJ/AteuwYCI4HXzGylc+6tZsp+4pybFoJ6RERERCTavfoI7NhYv56Q5E0LP2Qv+MGJ0GdQxJomEqyoCmBm1gM4FZjqnCsCPjezR4BzgaCDU6jqEREREZEoUVEGK/9Tv/4/s+EHJ3jTxYt0IlEVwIAxgDnnvgrY9jlwRAvlJ5lZHrATWATc6pyrbks9ZpYBZDTaPLgdbRcRERGRjvLVB1BV6S1nZcOBp0S0OSLtFW0BLBUobLQtH0hrpuy7wAQg1/f+JFAL3NLGei4Dbmhne0VEREQkHD5/s3558qGRa4fIHoq2AFYMpDfa1hMoalzQObc2YPVLM7sZ+A1eAAu6HuBuYH6jbYOBJcE2WkRERET2UFkJ7NwC5SX1r4pSKCv2Zj5c96VXzgwmHRTZtorsgWgLYKsBZ2bjnHMrfdumAMuDODbwiXtB1+Ocy8frHfOzuhlzRERERKRjbVkL77/gPUC5prr18iOnQHqvjm6VSIeJqmnonXMlwDPALWaWZmaT8CbOeKRxWTP7kZn19y3vBVwHPN/WekREREQkQpa9AfdeBl+8FVz4Avj+0R3aJJGOFm09YAA/Ax4EtuDdx3Wjc+4tMxsKfAWMd86tBw4D5ptZKrANeAy4tbV6wvcxRERERKRFn78Fz//Re0hynb6DoUcGJPVo+IqN8x6kPGAEjGvpCUQinUPUBTDfkMBTm9m+Hm9yjbr1XwG/ams9IiIiIhJBNTXw9hPwzpP14SsrG078OQwaHdGmiYRD1AUwEREREemEnIP8HeBqoboKindBcb7vfRcU7YKinbBrK+zcWn9cVjbMuRV6NJ4/TaRrUgATERERkT2zcys8Pg+2rmvbccP3htOuVPiSbkUBTERERETaxznYvAYW3eL1bgUrLh4O/DEc9GOIiao54UQ6nAKYiIiIiHi9WF/9B1IzICUdvvkUNq32ZiesrfWGFtbWBCzXQnkxlJfW1xEbB2m9vPfUDG85NdNbTs2EtExvW0Z/SO4RoQ8qElkKYCIiIiLdXVkxPHSFd59WeyUkwazrYMSk0LVLpAtSABMRERHp7l5b0P7wlZIGQ/aCQ2bCoFGhbZdIF6QAJiIiItKdrV8Fn7xSvz5iElSUeVPCj/2+N0FGTCxYjHe/VuB7fKI3vNAsYs0X6WwUwERERESiQVmJN0V7ZblvYgrzgk3dK6mHd/9UQlLozrl9AzxzR/362O/DrGsVqEQ6kAKYiIiISDjVVMO3y7zZA7/bDDu3eK+SguCOT0z2gljgKzXTC23VVVBT5U2MsWUNbFnrrWNeb1VCknd8QhIkJHuTbNRNohGfCMdcpPAl0sEUwERERETCoawE3n8ePn3Ve0Bxe1WUQcUmyNvUtuOqKqC0sPl98Ynw4ysgs1/72yUiQVEAExEREelIzsEnL8Mbj0FpUcvl4uIhMwuSU33H1XrHOuctlxZ5z9qqqQ5t+3r28WYvHDAitPWKSLMUwEREREQ60pJnvVkGA6X1gokHQN8h0Hsg9BoA6b1bfyixc96U8UU7G718MxjGJ0BsvBfm+gyCwWMhOQ1wXg9YRZl3j1ml790Mho73jhORsFAAExEREQk157z3nBXwxsL67Zn94fCzYcIPITa27fWaedO+p6RB/2FtOzYhCXr0bPs5RSSkFMBERERE9kRJIWzPhW25sH19/XJ5iReY6sLY0HFwzq1e75SIdFsKYCIiIiLtUVMNj94Ia79ouUxd+EpJ8ya5UPgS6fZaGWgsIiIiIs1a8/nuw1edxGT48ZXeZBci0u2pB0xERESkPQry6pfTesGoqdBvGPQb6t2fldbLm/giLh5i9SuXiHj0XwMRERGR9gh8ptaUQ+CIOU3LJCaHrTki0jloCKKIiIhIe5QU1C+naHZBEQmOesB24+w/vUlyZv9Wy/1o6hAuO3ZSg213//O/vLxsQ1DnOfPA0Zx10JgG265/4hM++mZ7UMdfeszeHP29oQ22/ezBJXy7tYWn3Tdy02n7Mm1Mw895xl2vs7O4Iqjj/3L+AYwe0PB/PEfe8lJQxwIsvuwweqcl+de/Kypn5t1vBH38q9cd02D9my0FXPzQe0Ed2ys1kccvP7zBtg9Xb+OGJ5cGdfyorHT+esGMBtv+9dl6/vjSl0Edv//oftx8+n4Nti18ZzWPvftNUMfrZ08/e4H0s6efvWDoZy+EP3vF+QD8LO5kvn0rAd5q/WdAP3v62Quk/+51/p+9sl3bgqojkHrARERERNqjNLhffEVEAimAiYiIiLRH4BBEEZEgmat7PoX4mVk2sG7dunVkZ2dHuDUiIiISlW6fDUU7veVfPgIZfSPbHhEJu5ycHIYPHw4w3DmXE8wx6gETERERaSvnGg5B7KFJOEQkOFEXwMwsw8yeMrMiM9tkZj8N4pj5ZubMbK+AbQlmdr+Z5ZvZDjO7uWNbLiIiIt1GeSnUVHvLCUkQnxDZ9ohIpxGNsyD+Ba9dA4GRwGtmttI591Zzhc3sYGB4M7uuByYBo4BU4HUzW+ec+1tHNFpERES6kdLAKejTI9cOEel0oqoHzMx6AKcC1zrnipxznwOPAOe2UD4B+DPQXC/ZOcAtzrk833jMP7RUj4iIiEibBE7AoeGHItIG0dYDNgZvYpCvArZ9DhzRQvmrgFeccyvMzL/RzDLxetC+aFTPvMYVmFkGkNFo8+C2NVtERES6lcAAlpoRsWaISOcTbQEsFWj8UI18IK1xQTMbDZwFTG2hHoDA+WGbrQe4DLihbc0UERGRbq1EQxBFpH2iaggiUAw0/q9YT6CombL3Ar9xzhW3UA+N6mqpnrvx7iELfM1oppyIiIiIR0MQRaSdoi2ArQacmY0L2DYFWN5M2cOAv5jZVjPb6tu2xMzOds7tAjYDk1urxzmX75zLCXwBG/f8o4iIiEiXpSnoRaSdomoIonOuxMyeAW4xs3PweqPOBU5rpviARutbgJOAT33r84FrzewToAfwC+C2jmi3iIiIdDPF+fXLCmAi0gZRFcB8fgY8iBeoCoEbnXNvmdlQ4CtgvHNuvXNua+BBvkk48pxzZb5NNwF9gDVAFXCvpqAXERGRkNAQRBFpp6gLYM65fLyp6BtvX0/95BrNHWeN1iuBi3wvERERkdDREEQRaadouwdMREREJPo1mAVRAUxEgqcAJiIiItIWzjUagqhp6EUkeApgIiIiIm1RXgo11d5yfCIkJEW2PSLSqUTdPWAiIiIiUammGnZtg/Ur67fp/i8RaSMFMBEREZHdqa2FZ++E5Uu85UAKYCLSRgpgIiIiIrvz9Sfw33ea39dncHjb0oU559i5cycVFRWRbopIA7GxsaSnp5OcnByS+hTARERERHbny4Dw1aMn9B4IMTGQ3gcOnRm5dnUxRUVFmBkDBgyoe76rSMQ556iqqmLnzp0AIQlhCmAiIiIiLakog1Uf1a+fcyv0Hxa59nRhpaWl9OnTR+FLooqZkZCQQK9evdi1a1dIAphmQRQRERFpyVf/gapKbzkrW+GrA9XW1hIbGxvpZog0Kz4+npqampDUFdIeMDMb5pzLDWWdIiIiIh3KOdixEbaug9oacL6JNmprYekr9eX2Pigy7etG1Psl0SqUP5uhHoL4rZm9BtwH/NM5V9vaASIiIiJhU7gTtq6F/O3elPL522HzGti5pfVjJymASdu8/fbbnH766WzdurVdx8+dO5f+/ftz0003NalrwoQJ/PGPf+Twww8PZZMlDEIdwMYBFwAPANVm9jDwkHNuQ4jPIyIiIhKcmmp4/wX45GUvcLXHyCmQ0TeUrZJO5KijjmLq1KncdtttDba/9957HHXUUWzdupXU1NQ9Osf8+fO57777+PDDD/3b7rvvvhbLr1ixwr984403smrVKp544ok9aoOER0gDmHPuW+BKM7sGOBEvjF1lZq8C9zvnXgrl+URERER2a2sOPHcXbFm7+3IJSTB8b0jy/RId47tN3mKgRzpMO65DmynRbc6cOVxxxRXceuutxMTUT6GwYMECTjnllD0OX9K9dMgsiM65ajN7DqgG+gJHAtPMLB841zn3XkecV0RERATwer3efRreecpbrhOfAANHQe9BkNkfMvpBrywYMNLbJ9KME088kZ/85Ce89dZbHHbYYQCUlZXx1FNPsXDhQs4991xeeukl4uPjOf3005k3bx4JCU1/nm6//Xbuv/9+tm/fzpAhQ/jd737H8ccfz8qVK5k7dy5VVVX+MFdQUMB5551HVlYWv/vd75rUlZ2d7e8hmzdvHs45UlNTGTRoELfeeis333wz//3vf/3lH3jgARYtWsQ777TwTDsJm5AHMDMbhtfzdQ5QiTcc8UfAd8DFwGNAdqjPKyIiIgJ4vV3P3e1NqlEnPgEOPROmHwexegqPtE1SUhKnnXYaCxYs8AewF154gV69evHss8+Sl5fH6tWrKS0t5fjjj+e2227jhhtuaFLPyJEjWbJkCVlZWTzxxBPMnDmTNWvWMG7cOO67774mQxCDcdRRR3H11Vc3GIJYUVHBRRddxBdffMHkyZMBWLhwIXPmzNmzL0JCItSzIL4KHAL8G7gIeMk55wKK3G1mt4TynCIiIiIA7NoO7z/v3etVGzBd9NBxcNKl0GdQ5NombXddGId93vKPVovMmTOHww8/nHvuuYfU1FQWLFjAmWeeye23384nn3xCz5496dmzJzfccAOXXXZZswHs5JNP9i/PnDmTefPmsXTpUo455piQfpzExEROP/10Fi5cyOTJk1m3bh2fffYZL72ku4GiQaifA/YZMMY5d6xz7p+NwledoSE+p4iIiHRH1VVQVgJb1sEzd8LdF8BH/6wPX/EJ8KPz4bzfKXzJHps2bRpDhgzh2WefZfPmzbzxxhsce+yxVFZWMmxY/fPhsrOz2bRpU7N1zJ8/n8mTJ5ORkUFGRgarVq0iLy+vQ9o7Z84cFi9eTE1NDYsWLeL4448nPT29Q84lbRPqPvg451xO441m9jvn3FUAzrldIT6niIiIdDefvgYv3Vf/kOTGho2HE3+u4CUhNXv2bB599FG2bdvG9OnT2XfffUlISCA3N5dJkyYBkJOTw6BBTX/ucnNzufDCC3nzzTeZPn06sbGxTJw4kbr+ij15zlRzx+6333706tWL119/nccee4w777yz3fVLaIU6gF0E/LqZ7RcCV4X4XCIiItIdOQdvLGw+fA3fG2acAqOmgh7q27kFMSww3M466yyuu+46vvnmG2644QZiY2M5/fTTueaaa3jssccoKyvj5ptv5swzz2xybElJCWZG377e4wweeughVq1a5d/fv39/Nm3aREVFBYmJiW1qV//+/Xn55Zepra1tMEvj7NmzueKKK8jPz+fII49s56eWUAvJEEQzG2pmQ4EYMxtSt+57/Q9QEYrziIiIiLBjIxT5BtSYQUoajJ8OF94B586D0d9T+JIOMWjQIA477DC+++47fvzjHwPwpz/9id69ezNmzBi+973vccABB/Cb3/ymybHjx4/nl7/8JdOmTSMrK4tVq1ax//77+/cfeuihTJ48mQEDBpCRkUFNTU2TOlpy6qmnEhcXR+/evZkwYYJ/+1lnncWKFSuYOXMmsbGxe/DJJZSs+du02liJWS3QXEUG1ABXO+f+b49PFCZmlg2sW7duHdnZ2RFujYiIiDTw8b/gH/d6y+OmwcxrItseCYnNmzczcODASDejS6msrKR///689dZbTJkyJdLN6fSa+xnNyclh+PDhAMObuxWrOaEagjgcL2wtByYEbK8FdjjnykN0HhEREenu1tY/24jhkyLXDpEo9+CDDzJmzBiFrygTkgDmnMv1Leox4CIiItJxnIN1X9avD987cm0RiWLZ2dnU1NTwzDPPRLop0sgeBzAzO8M597hv+eyWyjnnHg2yvgzqH95cCNzqnLunmXKHAXcDQ/CGOb4LXOyc2+TbnwD8GTgNqALudc5dH/QHExERkeizLRdKC73llHToP2z35UW6qZycnEg3QVoQih6wa4DHfcs3tVDGAUEFMOAveO0aCIwEXjOzlc65txqVWwEc6ZzbbGaJwC3Ag8DRvv3XA5OAUXg9c6+b2Trn3N+CbIeIiIhEm3WBww/31mQbItLp7HEAc85NDFgevid1mVkP4FRgqnOuCPjczB4BzgUaBDDn3NZGh9fgha065wAXOOfygDwz+4OvHgUwERGRzmj9Svjwn/XrI3T/l4h0PqF+DtieGoM3M+NXAds+B45orrBv6vv/Aul4AWyub3smXg/aF43qmddMHRlARqPNg9vRdhEREekIpUXw7/nw6b/rt8XEwqjvRaxJIiLtFYp7wB4Jppxz7twgiqXi3fcVKB9Ia6HO9UCGmfUCLsAbllhXD0BBEPVcBtwQRNtEREQknJyDz9+EVx6pv+8LID4RjvsJ9MqKXNtERNopFD1goRx8XYzXmxWoJ1C0u4OcczvNbAHwhZkN8tWDr6665ZbquRuY32jbYGBJ0K0WERGRtqsog5pqSOoBMTEN9+3aDs/dBTnLG27fa3845iLI6Bu+doqIhFAo7gE7JxQN8VkNODMb55xb6ds2Be/5Yq2JA/oB6b5AthmYDGzeXT3OuXy83jE/0w29IiIiu1dWDGs+h28+9d5j4+HHv4ZBo5svX1MD23Nhw9ew0ffasbF+f/YEOP5i6DsYvtsCf7saCvLq9/fsA8fMhXH7d+SnEok6Bx98MKeffjpz587tsud/++23Of3009m6tfEUD8GZO3cu/fv356abbmpS14QJE/jjH//I4YcfHsom75GougfMOVdiZs8At5jZOXgPeD4Xbyr5BszsZLz7v74F+gJ3Acucczt9ReYD15rZJ0AP4BfAbR3+IURERLqq7Rtgxfvw7WewYZU3RDDQot/CT+72wtmGVbB1HeRvh5J82JoDVRUt152zAu67HCYfDKs+hiLf/85jYuAHJ8IhZ0BCUod8LJFgHHzwwXz44YfExcURExPD2LFjueuuuzjggAMi3bRuZf78+dx33318+OGH/m333Xdfi+VXrFjhX77xxhtZtWoVTzzxRIe2sTWhuAfsS+fc3r7ldXhTzjfhnBsRZJU/w5tOfgve/WA3Oufe8k248RUw3nfv1xDgDrxer0LgHeCkgHpuAvoAa6h/DphmQBQREWmr8lJ44zH46J9NQ1egop3wp7le+WDExHqhqrzEW68sh09eqd8fnwCzroORU9rddJFQuvvuu5k7dy61tbXcf//9/O///i/btm3rkqOnnHPU1tZGuhldUkzrRVoV2Kt0I17wae4VFOdcvnPuVOdcqnNuYN1DmJ1z633b1vvW73bODXfO9XDODXDOne6cyw2op9I5d5Fzrqdzro9z7ro9/6giIiLdhHPeUMA3FsHdF8KH/2gYvsxg8Bg4+HQ47qf1z+PaXfjq2Qcm/BCOPBcuuB2ufQqueQJ++ifoNaBh2YQkOPMGhS+JSjExMcyaNYsdO3awY8cOAGpra/n973/PqFGj6N27NyeffLJ/X05ODmbGwoULGT58OJmZmVx88cW4gH9TjzzyCBMmTCAtLY2xY8eyZEn9dASbNm3ikEMOIS0tjenTp7NmzRr/PjPjr3/9K2PGjCE1NZXf/OY35ObmMmPGDNLT0znxxBMpLfX+XRYWFnLsscfSr18/MjMzOe6449i0aZO/roMPPpirrrqKGTNmkJKSwpdfftngc+/YsYN9992X665r+mv1k08+yeTJkxtse/DBBznwwAP95z733HPp378/gwcP5le/+hWVlZXNfr+33347I0eOJC0tjfHjx/Piiy8CsHLlSubOncsnn3xCamoqqamp1NTUMGfOHK666qpm68rOzuaVV17hlVdeYd68eTz77LOkpqYyduxYnnnmGSZNavg4iwceeICDDjqo2bpCJRT3gC0OWH3RObercRnfVO8iIiISTuWl3lDAynLAQXIa9OgJqRnecuOJL8C7L+v1hd4ww8rypvtHTIZ9/scLRj16BpyrBF5b4C3HxXtTxA8aDX0GQWqmN2Nheu/m2zlguDd0ccX73myHGf288/RoPC+XSHSorq5mwYIFjBo1ij59+gDw5z//mWeeeYY333yT/v37c/nll3PhhRfy/PPP+4977bXXWL58Odu3b2fffffl6KOP5uijj+bZZ5/l2muv5bnnnmP//fcnNzeX6upq/3GPPvooL730EmPHjuXMM8/kN7/5DU899ZR//8svv8zSpUvZtGkTU6dO5YMPPuCRRx6hf//+/PCHP+Rvf/sbP/vZz6itreWcc87hqaeeorq6mjlz5nDppZfyzDPP+Ot67LHH+Ne//sWECROoqanxb9+wYQNHHnkkF1xwAZdffnmT7+T444/nggsuYMWKFUyYMAGAxYsXM2vWLAB+/vOfs2PHDlavXk1paSnHH388t912Gzfc0HQy8pEjR7JkyRKysrJ44oknmDlzJmvWrGHcuHHcd999TYYgBuOoo47i6quvbjAEsaKigosuuogvvvjCHx4XLlzInDlz2lR3W4X6HrBcms5iCLAW6BXic4mIiEhLyorhgV9B3qaWy8QneFO6B7625UJtTdOyGX3hf+bA3jPqe7sCHXgKZA2HsiIYsy8kpzYtsztJKV6wE/F5/PHHw3auM844I6hyv/jFL7jqqqsoKysjJiaGxYsXE+P7Q8Z9993H3XffzdChQwG46aab6N+/P+Xl9X/IuPnmm+nRowfDhw/n0EMP5bPPPuPoo4/mwQcf5Je//CXTpk0DvF6bQOeccw4TJ04E4Oyzz+bSSy9tsP/Xv/416enppKenM3nyZA499FBGj/YmxDn66KNZtmwZABkZGZx88sn+466++mp+9KMfNajr7LPP9vcKxcbGAvD1119z++23c91113HOOc3Pv5ecnMxJJ53EokWLmDdvHps2beLDDz/k2Wefpaamhscff5xPPvmEnj170rNnT2644QYuu+yyZgNYYBtnzpzJvHnzWLp0Kcccc0yz526vxMRETj/9dBYuXMjkyZNZt24dn332GS+99FJIz9NYKIYgBmryX2QzC/U5REREZHecg2f+sPvwBVBV6T3kuCDPK7tlbcPw1aMnjJoKp10Jlz0Ikw5sPnzVGbOPN4lGW8OXSCdx5513kp+fT1lZGa+99hrnnHMOn3/+OQC5ubmceuqpZGRkkJGRwejRo0lISGgwxC8rq/7ZdT169KC42Hta0vr16xk5cmSL523puDr9+/f3LycnJzdZrytfUlLC+eefz9ChQ0lPT+fQQw8lLy+vQV1Dhgxpcv7FixfTq1cvZs6c2WIbAWbNmsXjjz+Oc44nnniCI444gl69epGXl0dlZSXDhg3zl83Ozm7w3QSaP38+kydP9n+Xq1atatLOUJkzZw6LFy+mpqaGRYsWcfzxx5Oe3rG97yHpAQt4GHNCMw9mHgWsREREREKnvNSbVbC6Coq+80JUQR4U7PCme1/73/qyY/eD2DhveF9Jgfcq3c0jNrMnwo/Oh4Et/0Io0p3FxMRwwAEHMHr0aF5//XWmTJnCkCFDWrx/KCcnZ7f1DRkypMF9XR3lD3/4A6tXr+bjjz8mKyuLpUuXst9++zUo09yEItdddx1vv/02p5xyCs8++ywJCQnN1n/YYYdRVlbGBx98wOLFi7nyyisB6NOnDwkJCeTm5vp713Jychg0aFCTOnJzc7nwwgt58803mT59OrGxsUycONF/v9yeTHjS3LH77bcfvXr14vXXX+exxx7jzjvvbHf9wQrVEEQLeA/8ZLV4DzR+IETnERER6b7KS2Hlf2Dpq7A+yL9tzjgFjpjddLtzXg9YVUXDV0IS9B64+54ukTAIdlhgpHz44Yd89dVX/vud5s6dy7XXXsujjz7K8OHDycvLY8mSJZx00kmt1ATnn38+l112GTNmzGC//fZj/fr1VFVVMWrUqJC2ubi4mOTkZDIyMvjuu++4+eabgzouLi6Oxx9/nFNPPZUf//jHPP3008THxzcpFxsby+mnn85NN93EN998w3HHHddg+zXXXMNjjz1GWVkZN998M2eeeWaTOkpKSjAz+vb1Hrb+0EMPsWrVKv/+/v37s2nTJioqKkhMTGzT5+/fvz8vv/wytbW1/qGjALNnz+aKK64gPz+fI488sk11tkdIhgc6587xPZD5hrpl3+s859w1gbMTioiISDNqa72AVZwPu7Z7z9za9K33kON3n4YF18PvZsFzdwcfvkbvA4c1/QUH8AJWQqI30UVGX+8ByANHepNmKHyJNOuyyy7zz7535pln8tvf/tZ/D9Wll17KSSedxFFHHUV6ejrf//73+eCDD4Kq99RTT+WGG27g7LPPJi0tjSOPPLLdDyVurf3l5eX06dOHH/zgB03u/9qd+Ph4nnrqKWpqajj99NMbTBISaNasWbz22mucdNJJJCcn+7f/6U9/onfv3owZM4bvfe97HHDAAfzmN79pcvz48eP998NlZWWxatUq9t+//gHshx56KJMnT2bAgAFkZGQ0mCikNaeeeipxcXH07t3bH5wBzjrrLFasWMHMmTP99711JHO7e55HN2Vm2cC6devWNbkJUkREJCRKCmHFe7DyQ+/+q4Idu3/GVmMxsZCS5r2nZnpTvPfsW/+e0Q8GjoIw/DIhEgqbN29m4MCBkW6GdEOVlZX079+ft956iylTprRYrrmf0ZycHIYPHw4w3DmXE8z5QjoLopklAdcAh+M9INn/J7Q2PIhZRESkc6up8d1rle/1aJUUeO/VviF/uSu86eHb85DTASNg7wPhe4c3nAZeRETa5cEHH2TMmDG7DV+hFOpp6O8AjgDuAW7FC2M/AxaE+DwiIiKR9d0WX69VrRekqqtg3X+9Hq229mbVSUjyTQfvmx4+zvfedwgM2ct7NlZmv9B/FhGRbio7O5uampoGz0LraKEOYCcAhznnVpvZDc65u83sTeD2EJ9HREQk/CrL4csl8OmrsOHrPa9vyF7etO0jp3jDBuObn1lMREQ6RmszVHaEUAewns651b7lajOLc87918ymhfg8IiIi4bfwJshZ3no5M0hOg9QM79UjwxsumJgMFuPNMjj6expCKCLSDYU6gK03s+HOuXXAt8BxZvYdUN7KcSIiItFv0kH1ASw2DgaPgdh4iInxglVGP5jwA+85WrGh/l+siIh0BaH+v8M9wGRgHfAH4Gm8iTiuDfF5REREwm/vA+HTf3tBbPLB6sESEZE2C2kAc87dE7D8jJkNA9Kcc6t2c5iIiEjnkJQCc++MdCtERKQT69DxEc65TR1Zv4iIiIiISGcSs6cVmNlbZvZma69QNFZERERERCIvOzubV155pV3HLlmyhJEjRzZb17x585gzZ04omhi1QtED9nYI6hARERERiXpHHXUUS5YsYevWraSlpUW6OZ2CmbFy5Ur22msvAGbMmMGaNWuaLXv11Vf7l3Nychg+fDhlZWUkJSWFpa3hsMcBzDl3UygaIiIiIiISzTZt2sTrr79Oz549eeqppzjvvPNCWn9NTQ0xMTGYWUjrleiyx0MQGzOzHmb2YzP7lZmdamY9Qn0OEREREZFwW7hwIVOmTGHu3LksWLAAgIqKCjIzM1m2bJm/XFFRESkpKf5enpdeeompU6eSkZHBtGnT+Oyzz/xls7Ozue2225gyZQopKSkUFBRw++23M3LkSNLS0hg/fjwvvviiv3xtbS1XXXUV/fr1Y/DgwcyfPx8zY9WqVf72XHHFFQwbNox+/fpx/vnnU1JS0uSzBNPu+fPnM3bsWDIzMzn88MNZvXp1k3oAli5dyvTp08nIyGDAgAH8/Oc/p6qqCoADDzwQgH322YfU1FQWLFjA22+/TVZWVrN13XjjjZx++ukNju3Tpw+pqan8+9//pnfv3g2+v4KCAlJSUli7dm2z9UWjkAYwMxsHfA38ETjZ9/61mY0P5XlERERERMJtwYIFzJo1i1mzZvHee++xdu1aEhMTOfnkk1m8eLG/3HPPPcfkyZMZOXIky5YtY/bs2dxzzz3s3LmTSy65hOOOO47S0lJ/+cWLF/PCCy9QWFhIeno6I0eOZMmSJRQUFHDttdcyc+ZMtm3bBsDDDz/Ms88+y0cffcSqVat49dVXG7TxqquuYsWKFXz66aesXbuWvLw8rr226ROhWmv322+/zS9+8QsWLlzItm3bOPDAAznuuOP8wSpQbGwsd955J3l5ebz//vu88sor3H///QC8++67AHz66acUFxcze/bsoL/vumPz8vIoLi7miCOO4PTTT2fhwoX+Ms888wz77LMPI0aMCLreSAv1LIh3AQuBa5xztWYWA9wC3A0cEeJziYiIiEgXtvCd1Tz27jdBlf3R1CFcduykBtvu/ud/eXnZhhaPOfPA0Zx10Jig6v/www/55ptvOOOMM8jKymLKlCksWLCAm266iVmzZnH22Wfz+9//npiYGBYvXsysWbMAeOCBB7jggguYPn06ALNmzWLevHksWbKEI488EoBLLrmE7Oxs/7lOPvlk//LMmTOZN28eS5cu5ZhjjuHxxx/n0ksvZfjw4QDcfPPNPPHEEwA453jggQf47LPP6NOnDwDXXHMNxx9/PHfddVeTz7S7dj/22GPMmTOH73//+/56/vrXv/LRRx9xwAEHNKhn6tSp/uURI0Zw4YUX8s4773DxxRcH9d22xZw5czjuuOO44447iI2NZeHChZx99tkhP09HCvUQxH2AG5xztQC+91uA74X4PCIiIiIiYTN//nwOPfRQ/9C5WbNm8eijj+Kc46CDDsI5x7vvvsv27dt59913Oe200wDIzc3lj3/8IxkZGf7XunXr2Lx5s7/uIUOGNDnX5MmT/eVXrVpFXl4eAJs3b25QfujQof7lHTt2UFpayv777+8/9vDDDyc/P7/ZnqvdtXvTpk0MGzbMXzY2NpYhQ4awaVPTp0x9/fXXHHPMMWRlZZGens7111/vb2+o7bfffvTp04dXX32V9evX8/HHH/PjH/+4Q87VUULdA1YC9AM2Bmzr69suIiIiItLplJeX8+STT1JVVeUPYJWVlezatYt33nmHgw8+mDPOOINFixYxadIkDjnkEPr27Qt44erKK6/khhtuaLH+wEk3cnNzufDCC3nzzTeZPn06sbGxTJw4EeccAAMHDmTDhvpevfXr1/uX+/TpQ3JyMl988UWD8NSSmJiYFts9aNAgcnNz/WVra2vZsGEDgwYNalLPT37yE6ZMmcITTzxBWload9xxB//85z9bPX9rWpqMZPbs2SxcuJBJkyZx7LHH0rNnzz0+VziFOoA9C7xgZtcA64DheD1gz4T4PCIiIiLSxZ110Jighwg257JjJzUZltgeL7zwAs45VqxYQWJion/7hRdeyPz58zn44IOZNWsWhx56KMuWLePyyy/3l7ngggs44YQTOOKII9h///0pKyvj3XffZdq0aWRmZjY5V0lJCWbmD0IPPfSQf4INgNNOO40777yTY489lr59+3LjjTf698XExHDBBRfwi1/8gnvuuYf+/fuzadMmvvjiC44++uhmP1tL7Z41axannHIKM2fOZNKkSdx+++2kp6ez//77N6mjuLiY9PR0UlNTWblyJffff3+DoNa/f3/Wrl3rn4Y+WH379iUmJoa1a9cyfnz9lBJnnXUWt9xyC0uXLm12aGW0C8kQRDN7w8xOAa4HPgKeB1b53pcC17Shrgwze8rMisxsk5n9tIVys83sUzMr9JW708wSAvYnmNn9ZpZvZjvM7OY9+pAiIiIi0i3Nnz+f2bNnM2zYMLKysvyvSy+9lGeeeYbi4mKmTJnCgAEDWLlyJSeeeKL/2H333ZeHH36YSy+9lF69ejFq1CgeeuihFs81fvx4fvnLXzJt2jSysrJYtWpVg9Bz/vnnc8IJJ7DffvsxduxYDj74YAB/MLz99tvZa6+9mD59Ounp6Rx++OGsXLmyxfO11O5DDjmE22+/nZkzZ9KvXz/efPNN/vGPfxAfH9+kjjvuuIPHH3+ctLQ0LrroIv8wxjo33ngj5513HhkZGQ0m0GhNSkoK11xzDQcddBAZGRm88847AGRlZTFjxgwKCws56qijgq4vWlhdd+YeVWL2EHAaUAQ8AjyEN+wwz7XxBGb2GJACzAZGAq8BP3bOvdWo3E+A5cDHQC/gReAl59yNvv2/BQ4DjgNSgdeBW51zfwuiDdnAunXr1jW4IVJEREREOsbmzZsZOHBgpJvR6axcuZIJEyZQXl5OQkJC6wd0ET/96U9JSEjg7rvvDts5m/sZrXtYNDDcOZcTTD0h6QFzzp0PDARuxQs83wAPA22KpL5nhp0KXOucK3LOfY4X6M5t5pz3OueWOOcqnHNb8GZf/GFAkXOAW5xzeb4v4w/N1SMiIiIi0lmUlZXxz3/+k6qqKvLy8vjVr37Fscce263C18aNG3niiSe48MILI92UdgnZLIi+wPRX59xk4CBgF/Csma0zs98EWc0YvF65rwK2fQ5MDOLYA4EVAGaWiRcIv2itHt+Qx+zAFzA4yPaKiIiIiISNc46bb76ZXr16MXbsWJKSkvzP3OoOrrvuOvbaay8uvvjiBveFdSahnoQDAOfcB8AHZvZ/wAvAb4Hbgjg0FShstC0fSNvdQWZ2NnAAMCWgHoCCIOq5DGh5WhoRERERkSiRkpLCxx9/HOlmRMwtt9zCLbfcEulm7JFQPwcMADM70syeAz4DioFmJ9JoRjGQ3mhbT7x7y1o61/HAHcBRzrmtAfXQqK6W6rkbb7bGwNeMINsrIiIiIiIStJD1gJlZX+A84AK84X9PAwc55/7ThmpWA87Mxjnn6qZrmYI32UZz5zwK7x6xY333iwHgnNtlZpuByUDdU+6arcc5l4/XOxZYbxuaLCIiIiIiEpxQTUP/FLABL4DdCwx2zp3dxvCFc64E75lht5hZmplNwps445FmznkosAg42Tn3YTPVzQeuNbM+ZjYM+EVz9YiIiIhIdAjF7NwiHSGUP5uh6gGLB453zv07BHX9DHgQ2IJ3P9iNzrm3zGwo8BUw3jm3HrgOb1jhSwE9VrnOuQm+5ZuAPsAaoAq4N5gp6EVEREQk/OLj4ykuLiY1NVWjkaKYc46SkhIqKyuprKykpqYG5xyxsbHExcX5X/Hx8cTExFBTU0N1dTXV1dXU1NRQW1vrfznn/MEm8D0mJoYePXqQkpKCc46amhqqqqpwzhEfH+9/xcR0yN1UTT5vTU0NhYWFDR7CvSdC8hywrkbPARMREREJr5qaGnbu3ElVVVWkmyLNqK6uprCwkOLiYmpqaiLdHJKSkhgwYEBYzhUTE0NKSgppaWlN/jjQnueAdcgsiCIiIiIibREbG0vfvn0j3YxuwznHd999R3l5OQAVFRWUlZX5e7QCX6WlpWzatCmqhohmZ2d32gd3K4CJiIiIiHQjRUVFfPTRR+zYsaNdxycnJ9O/f3/S0tJISEggNjaWiooKysvLKSsro7y8nPLycqqqqoiPjycpKcn/qhuiGBsbS2xsLGbW5FVaWsqWLVsoKSkhNjaW+Ph4kpOTiYmJobS0lNLSUlJTU1tvaJRSABMRERER6aKqq6vZtm0bmzdvZtu2bVRUVPjvp2qrvn37MmbMGAYPHtzh91911ocsB0MBTERERESkE3PO+SfEqK6upqqqiry8PDZv3sz27dupra1t9jgzIysrCzMjISGB5ORk4uLi/D1RMTEx/ve+ffuSkZER3g/WRSmAiYiIiIhEobp7sOoCUaDq6mry8vLIzc1lw4YNbZ68pFevXuy777707t07lE2WICiAiYiIiIhEkdraWtasWcPKlSspKSkBvJn46l6xsbGUl5cHPYwwPT2dgQMHMnDgQDIyMvxTxktk6JsXEREREYmwiooKNmzYwJYtW9i+fTuVlZUN9tc9O6sl8fHxDSa3SE1NZeDAgQwYMIAePXp0dPOlDRTARERERERCoO5erISEBEpLS/nqq6/Iy8sDvPutmnvocN17SUnJbgNWc9LT0+nXrx/Dhw+nd+/eeoB1J6EAJiIiIiLSiurqatavX8+2bdsaBKW6EFVZWel/kHRsbCy1tbV79NyspKQk9tprL0aPHu2vr7a2lpqaGmpra4mPjyc+Pn6PP5eEnwKYiIiIiEgznHPs3LmTNWvWkJubS3V1dVDH1dTUtOt8vXv3ZujQoWRlZdGzZ88GPVp1QwsVujo/BTARERER6Raqq6vZvHkzZWVlDXqoAt/rhhGWlJSQl5dHRUVFm84RGxvrD2B9+/Zl/PjxJCcnU1tb22A2w8bvddPAS9enACYiIiIiXZpzjry8PP7zn//4ZxVsj7S0NEaMGEFKSgpAgx6qmJgYMjMz6dGjB1VVVdTW1pKUlLTHbZeuRwFMRERERDqtyspKCgoKKCoqori42P9eXFzsf4ZWdXV1mye4qBMfH8/gwYMZOXIkffr0CWqii4SEhHadS7oHBTARERER6XRqa2tZsWIFX331VZvCVXx8PMOGDSM2NrbFIYEJCQkkJiaSmZnZ5F4skT2lACYiIiIiEVVbW8uOHTtaHB5YWlpKYWEhVVVV/vu1SkpKKCwsDPocsbGxDBgwgH322cc/hFAkEhTARERERMQ/jXpSUhI9evTAzPwTRwANeotqa2spLy/3Pyy4qqrKPwX7gAED6Nu3r/+5VzU1NVRVVVFVVUV1dTXV1dX+5ZKSEgoKCtiyZUubJ7sIlJaWRkZGBmlpaaSlpZGamkpaWpp/+va6BxSrJ0uigQKYiIiISBRzzjUIL41fjfcFCgwcu1suLi4mNze33dOnB/rqq6+Ij4/HORf0tO3tZWZMmjSJcePGKVxJp6EAJiIiItLBampqqK6uJiEhocWgUBe01q9fT05ODiUlJf6eo86mPW1OTk6mb9++xMTE+LcFTtGenp5OUlJSg564zMxMTd0unY4CmIiIiEg71D0vqqKiokEPVF3Yqnvt2LGDLVu2UFtbS3x8PCkpKf4gVhew6l7tnakvVNLS0nDOUVZWBjTsKQt8VpaZkZiYSGJiIuBNwZ6RkQHAhg0b/EMTwbv3Ki4ujvj4+AbvcXFxJCUl0bNnTzIyMoKeYVCks1MAExEREdmNyspKVq5cyY4dOwDv/qeysjLKy8vbHJiqqqooKChocxvqgktdmGkcZAJfdfdeBWr8wOHGy2ZGVlaW/96tPbHvvvtSXl7ub09gj5aIKICJiIhETFVVlX/ygdraWmJiYoiJiSE2NpbY2NgmyykpKf4hWBI6FRUVlJSUUFZWRmVlpb83qrKyksrKSjZu3NigR6e9YmNjW73HKiYmhvT0dEaMGMHAgQNJSEggPj6+U4WYup9VEWmeApiIiEiQdu7cSV5eHoWFhRQVFfl/KXfONehhaO2VmJhIjx492LFjR5snKYiLiyM1NZXU1FT/L+WNezeCfa8LdoHBr6X1hIQEevbsSXp6OvHx8Z02BFZXV7NlyxZ27tzJrl272LVrF+Xl5e2uLy4ujsTExGZ7oupeycnJDB48mNTUVMrLyykvL/fP+BcfH098fLw/aMXGxobqo4pIlFIAExERCdLatWv55ptv9rieioqKNj2/KFB1dTX5+fnk5+fvcTv2ROBQuLi4OHr27MmkSZNIS0uLaLtaUlNTw4YNG1i2bFm7AldKSgqTJk0iJSWFmJgYkpKSSE5OJi6ubb9KJScna9IIkW4u6gKYmWUADwA/AgqBW51z9zRTbiLwB2BfoJdzzhrtTwD+DJwGVAH3Oueu79jWi4hIV5aent4hddbN/FZbW0ttbS01NTX+97rlumcmRcs1noRJAAEAAElEQVSMeHVtq+vJqXuW0z777ENmZqZ/oolwcs6xZcsWNm7cSFlZGRUVFf5nVe3ue4uNjaVHjx7+Ntf1RtW9p6SkkJWVpd4pEQmJqAtgwF/w2jUQGAm8ZmYrnXNvNSpXBTwF3AO80Ew91wOTgFFAKvC6ma1zzv2toxouIiJdW+/evRkxYgRpaWkNpsSGhg+prVs2M2JiYhqsA5SWllJcXExqaiq9evUKejifc46KigqKi4spKSnxz0ZXd862vAP+wNc49DW3vaysjPz8fEpLS1scNllVVcWHH37oX+/Xrx+9evXylw+cNCKY5WC/l9raWnJzc1m5cmVQE1wkJyczbNgwevXqRWZmJmlpaZ12SKWIdD7WeJacSDKzHsBOYKpz7ivftt8DA51zZ7VwzCjgm2Z6wDYBFzjn/uVb/wkw0zk3I4h2ZAPr1q1bR3Z29h58IhERka7HOUdNTY3/AcDFxcV8/PHHlJaWhuwcsbGxpKSk+B/oW3fexu0AGtxT1RIzIykpiWHDhjFx4kTi4+ND1lYR6b5ycnIYPnw4wHDnXE4wx0RbD9gYvFD4VcC2z4Ej2lKJmWXi9aB90aieec2UzQAyGm0e3JbziYiIdCdm5u+lAu/ZUUcddRTLly9n586dVFRUUFRUtEfnqKmpaVcdcXFxjBgxgv79+/ufU5WYmLjbByCLiIRTtAWwVLz7vgLlA229ozfV9x44DqGlei4Dbmhj/SIiIhIgMTGRffbZx79eVlbG5s2bqaio8Ae1uh6z6urqBsuN16uqqlqdrr2xpKQkxowZw6hRo/wPBxYRiUbRFsCKgcZ3OPcE2vonsGLfe3rAckv13A3Mb7RtMLCkjecUERERn+TkZEaOHNnu4ysrKykpKWnwoOPAHqzGy+np6Z3qWVki0n1FWwBbDTgzG+ecW+nbNgVY3pZKnHO7zGwzMBnYvLt6nHP5eL1jfhqiICIiEll1sxGKiHQ1UfWnIudcCfAMcIuZpZnZJOBc4JHGZc2TBCT41pN863XmA9eaWR8zGwb8orl6REREREREwiWqApjPzwAHbAFeAW50zr1lZkPNrNjMhvrKDQPKgBW+9TLfq85NeD1ea4BPgSc1Bb2IiIiIiERStA1BrBsSeGoz29dTP7kGvmkeWxwr6JyrBC7yvURERERERCIuGnvAREREREREuiQFMBERERERkTBRABMREREREQkTBTAREREREZEwUQATEREREREJEwUwERERERGRMFEAExERERERCRMFMBERERERkTBRABMREREREQkTBTAREREREZEwUQATEREREREJEwUwERERERGRMFEAExERERERCRMFMBERERERkTBRABMREREREQkTBTAREREREZEwUQATEREREREJEwUwERERERGRMFEAExERERERCRMFMBERERERkTBRABMREREREQkTBTAREREREZEwUQATEREREREJk6gLYGaWYWZPmVmRmW0ys5/upuzFvjJFZvakmaW3px4REREREZFwiLoABvwFiAMGAscAN5nZIY0Lmdn/ADf4ygwC4oE/t7UeERERERGRcImqAGZmPYBTgWudc0XOuc+BR4Bzmyk+B/ibc+5z51whcA1wmpmltLEeERERERGRsIiLdAMaGQOYc+6rgG2fA0c0U3Yi8K+6FefcSjMDGI0XLIOqx8wygIxGmwcDDB8+vI3NFxERERERaVm0BbBUoLDRtnwgrYWyBY22FfjKWhvquQxvKKOIiIiIiEiHirYAVgykN9rWEygKsmy6r2xMG+q5G5jfaNtgYMm6devIzs5urc0iIiIiItIN5eTktHnUXLQFsNWAM7NxzrmVvm1TgOXNlF0OTAYWA5jZXng9X9/43oOqxzmXj9c75ucbyigiIiIiIhJSUTUJh3OuBHgGuMXM0sxsEt7EGY80U3w+cI6ZTTKzNOC3wJPOudI21iMiIiIiIhIWURXAfH4GOGAL8Apwo3PuLTMbambFZjYUwDn3GnCLr8wWoBa4pLV6wvcxREREREREGoq2IYh1QwJPbWb7eryJNwK3/ZmGz/5qtR4REREREZFIicYeMBERERERkS5JAUxERERERCRMFMBERERERETCJOruAYsSsQAbN26MdDtERERERCRKBeSF2GCPMedcx7SmEzOzA4AlkW6HiIiIiIh0CjOcc+8FU1ABrBlmlgjshzeFfU2Em9NVDMYLtTOAuj8VrAPa9uhw6SihuBbNXWNpm87wb6K7XOfOcC06QjRe3+56LTpKe6+xrkP0CLwW0fhvtjtZB4wCBgCfOOcqgjlIQxCb4fvygkqwEhwzq1vc6JzLqdtWtyyRFYpr0dw1lrbpDP8must17gzXoiNE4/Xtrteio7T3Gus6RI/AaxGN/2a7E9+1WAOsactxmoRDREREREQkTBTAJJJuinQDxE/XIjroOkQPXYvooWsRHXQdooeuRfRo17XQPWASFmaWjW/MsrrIuyZd4+5B17lr0/Xt+nSNuxZdz85JPWASLvl4fyXIj2wzpAPlo2vcHeSj69yV5aPr29Xlo2vcleSj69npqAdMREREREQkTNQDJiIiIiIiEiYKYCIiIiIiImGiACYiIiIiIhImCmAiIiIiIiJhogAmIiIiIiISJgpgIiIiIiIiYaIAJiIiIiIiEiYKYCIiIiIiImGiACYiIiIiIhImCmAiIiIiIiJhogAmIiIiIiISJgpgIiIiIiIiYaIAJiIiIiIiEiYKYCIiIiIiImGiACYiIiIiIhImCmAiIiIiIiJhogAmIiIiIiISJgpgIiIiIiIiYaIAJiIiIiIiEiYKYCIiIiIiImGiACYiIiIiIhImCmAiIiIiIiJhogAmIiIiIiISJgpgIiIiIiIiYaIAJiIiIiIiEiYKYCIiIiIiImGiACYiIiIiIhImCmAiIiIiIiJhogAmIiIiIiISJgpgIiIiIiIiYaIAJiIiIiIiEiYKYCIiIiIiImGiACYiIiIiIhImCmAiIiIiIiJhogAmIiIiIiISJgpgIiIiIiIiYaIAJiIiIiIiEiYKYCIiIiIiImGiACYiIiIiIhImCmAiIiIiIiJhogAmIiIiIiISJgpgIiIiIiIiYaIAJiIiIiIiEiYKYCIiIiIiImGiACYiIiIiIhImCmAiIiIiIiJhogAmIiIiIiISJgpgIiIiIiIiYaIAJiIiIiIiEiYKYCIiIiIiImGiACYiIiIiIhImCmAiIiIiIiJhogAmIiIiIiISJgpgIiIiIiIiYaIAJiIiIiIiEiYKYCIiIiIiImGiACYiIiIiIhImCmAiIiIiIiJhogAmIiIiIiISJgpgIiIiIiIiYaIAJiIiIiIiEiYKYCIiIiIiImGiACYiIiIiIhImCmAiIiIiIiJhogAmIiIiIiISJgpgIiIiIiIiYaIAJiIiIiIiEiYKYCIiIiIiImGiACYiIiIiIhImCmAiIiIiIiJhogAmIiIiIiISJgpgIiIiIiIiYaIAJiIiIiIiEiYKYCIiIiIiImGiACYiIiIiIhImCmAiIiIiIiJhogAmItKFmVm2mTkzy/atzzGznID995nZfZFqn68NB5uZi2QbIsHMZphZcQjqWWBml4eiTZHW+Oe1hTJ3mdmN4WuViEhoKYCJiEQxM3vbzCrNrNjMCs1shZldEKr6nXNznXNzQ1Vfc8ysr5k9bGabfJ9ji5m9bGYDOvK80cTMbjSztwO3OeeWOOdS97DefYHDgL822n6RmX1lZiW+7/uaPTlPR2j8x4A2uBW41MwGhrhJIiJhoQAmIhL95vl+Uc8AbgLuN7MDI9ukNnkMr+37+D7HZOBxoMN6vcwsoaPqbnSeGDOLDce5WnA58KhzrjKgTb8BrgDOB9KBscCLkWle6Dnn8oCXgQ79w4GISEdRABMR6SScc7XOuaeAncD367ab2QlmtszMCny9HucFW6eZzTez+QHrOWZ2ja+HqsjMvjGzExodc4WZrTezfDP7m5k9HlhHM34ALHDObfV9ju3OuUfr1gPqPcnMVvt6+l4N7CEzs5/5ev+KfD1pfzWzlEaf43Eze9DM8oBFAcPZzjezlb56Xzez4QHHxZrZL337C8zsUzM7bDffV12d55nZcqAUGGdmp5rZZ746tpnZIjPr4ztmFnA1MMPXA1hsZlMbD730teVqM/vW991+YGY/2E1b4oDjgFcDtvUErgN+7pz7wDlX45wrdM59uZvrU3fdrzezN3y9Zst9bTzN9zNQ4LvW8QHHTDCzf5vZd2aWa2Z3mFlSozqb/VkysxnAfcDQgO/kxIAmHWBm//Ud94GZ7dWoyf8GTtrdZxIRiVYKYCIinYSZxZnZTKA38LVv2zTgKbyesV54vQJ3mtn/7sGpLsALDD2BB4BHzSzVd75ZwJXAqUAf4B3glFbqexe43czm+n6pj2uh3EnAfsBQvJ6b3wbs2wKc4Nt+GHAE0HhY3SnAEiALmB2w/TzgcGAAkAO8GNBrdR0wy1d3pu+cfzezka18ptnAUUAqsBoo8m3rBewDjAD+COCcWwTMA5Y451J9r2XN1PlL4ELf99AXWAT828yGtNCG0UAasDxg23QgGRhvZmvMbKuZ/d3MRrTyeeo+0yV4vZWfA88C/wNMASbhhb2ZAGaWDrwOfAIMAg7C+45vb1Rnsz9LzrkleD+r6wO+kxcCjjvLd+6+wFYaDbEEvgQmBgY+EZHOQgFMRCT6XWVm+UA5sBC42jn3D9++c4C/O+de8PV2vAs8iPeLfHs94Jxb5pyrBe6lfhgbwBzf/o+cc9XOufnAp63UdxqwAO8X/A+APDO7u5lfnq9yzhU45/Lxwoe/l88595xz7lvnWQXcg/cLf6APfT1r1c650oDtNzvnNjnnSvCG7I0LqPty4NfOudW+Hsbn8ULcGa18ppuccxt956p0zr3inPvSdw024gWRxu1rzXnA7b56qpxzfwVW4QXE5mT63gsCtvXxvR8D/BAYBeQB/7DWh0o+5Jz7yjlXBSwGhgPXOedKnHO5eEF634D6Aa53zpU753KAa4HzzcwC6tzdz9Lu3OSc2+acKwceIeBnwafQ994riLpERKKKApiISPT7nXMuA+8X7r8Bhwf0Ig0B1jYq/y1eL1J7ba5bcM7VzdKX5nsfjNeLFKjxegPOuWLn3G3Ouel4PSFn4wXHqxuV2xywWhxwTszsFDP70MzyzKwAbyKGfo1Ota6FJvi3O+eK8ALJEDPrjxcInvcN+cv3Bd0D8Xp1dqfBuczsEPMmTNlmZoV4Qblx+1rT1mu50/feM2Bbke/9VufcVt/1uwoYD4wx38yLAa8ZAcduCVguBXDONd5Wd02GALnOuZpGbU3G67Wqs7ufpd1p/LPQeLKSdN/7TkREOhkFMBGRTsIXHn6G1zPxM9/mDb71QCOB9R3UjI1AdqNtw4I92Ndb9CLe8LUpwRxjZoOBJ4E7gEHOuZ54ww+tUdHaFqrwt9c3lLIP3ufIx+tVPMo5lxHw6uGc+0krzfKfy7wJP/4BvACMcM6l4w2hC6Ztgdp6Lb/B6wmaELCtbmhj4AQn/uW6mRcDXkuCaFdLbR1mZoG/R4wEyoAdQdYRzHfSkonACl8PmYhIp6IAJiLSiTjnKoCbgWt99+HMB040s+N8kzgcgHffzUMd1IQFeMPM9vPdk3Y23j1PLTKzO33lk8ybNfBg4BC8oX7BSMP7/1Wec67CzCZRH0CDcZ2ZDTRv0o4/4N0/95Hvu7wP+D8zG2eeZDM70MzGtKH+BCAJyHfOlfjut7qqUZmteIElcTf1PAJc4ZvcIt7MfoLXc7W4ucK+3qcXgSMDtq3HC4PXmDf9fwre/Wdf4t2rFiov4QXgm8ws0cyGAbcAjzjngp3dcivQ18wyWy3Z1BHA8+04TkQk4hTAREQ6n4V4Q69+7Zz7D979SrcAu/CC1xXOuWc66NyLgDuB5/CG8h2CFwJ21xMRgzd0cruvjffg9Wb9IZgTOudW4t1f9KRveN8dwKNtaPPfgDfwfuEfDZwQMHTuV3iTmDyN1yOWA/wGiG9SS8vtKwYuAm4278HKi3yvQE/iDdHb4hvqOKWZqv4APIz3febhDdU8yheqWnI3MNsaTrt/Nl4P3zdALt6QwOMaDRfcI865QrxJMqbjDV1cArwN/LoN1byJF+TqZn08PpiDzKw38CO88Cwi0ulY8H+oEhERacrMlgLPOudui3RbAplZNt69WsN9k0R0SWa2APjcOXdXpNsSDmZ2J1DknLsh0m0REWkPBTAREWkTMzsd+DvevUUXAf8HjHfOfRvRhjXSXQKYiIh0LhqCKCIibXUR3nC+7XiTTZwQbeFLREQkWqkHTEREREREJEzUAyYiIiIiIhImca0X6X580wTvhzezU8hmjRIRERERkS4lFhgAfOJ7vEmrFMCatx/BP59GRERERES6txnAe8EUVABr3haAJUuWMHjw4Ei3RUREREREotDGjRuZMWMG+PJDMBTAmlcDMHjwYLKzsyPcFBERERERiXJB37akSThERERERETCRAFMREREREQkTBTAREREREREwkT3gLWDc46dO3dSURHUTJOyB2JjY0lPTyc5OTnSTRERERER2WMKYO1QVFSEmTFgwADMLNLN6bKcc1RVVbFz504AhTARERGRPVFTDTGxoN9fI0pDENuhtLSU9PR0ha8OZmYkJCTQq1cvCgsLI90cERGRrum/78ADv4Jlb0S6JdKRlr4KvzsT/nIxbFkX6dZ0awpg7VBbW0tsbGykm9FtxMfHU1MT9MyeIiIiEqzKCnj6DtjwNfz9L14PiXQ9H/zdu77lJbB9PTx0BXz9SaRb1W0pgLWTer/CR9+1iIhIB1n/Vf1yTTXk74hcW6RjvPs0vPxQw22V5fD4PNiWG5k2dXMKYN3I22+/TVZWVqSbISIiItFi7RcN1/O3RaYdEnrOwRuL4LVH67cN2Qsy+nnLNdVeOJOwUwDrgj744ANmzJhBRkYGGRkZ7LvvvvzrX/+KdLNERESkI+zaDs//CV5/DHZubduxaz5vuN7W4yW0nPOGg754DzxzJxTtan89/54Pbz9Rv23EJJhzC5x+Vf225Uu8n586323xhqVKh9IsiF1MYWEhxxxzDHfffTezZs2ipqaGjz/+GDOjujp047qrq6uJi9OPj4iISERVVcKj10PeJm/9nSdh4CgYNBq+dzgMHtPysSWFsGVtw2271AMWMRVl8OgNsH5l/bbYODjp582XLymEf9wDMTFw3M8guYe33Tn414Pw4T/qy47eB864GuITvJ+NEZNg7X+hthbefx6OvcjrKXv3aUjqAUeeA/scodkSO0jU9YCZ2R/MbIOZFZpZrplds5uyp5rZWjMrMbN/m9mggH0JZna/meWb2Q4zuzk8nyCyVq9eTVVVFbNnzyYuLo7ExERmzJjBAQcc4C/z5z//mQEDBtC3b1/mzZvn37506VKmT59ORkYGAwYM4Oc//zlVVVX+/WbGn//8Z8aMGcOAAQP82/74xz8ycuRIevfuzWWXXdZgwoyXXnqJqVOnkpGRwbRp0/jss8/C8C2IiIh0E68vrA9fdTZ/C5+8DI9c7f2S3pJ1//V+WQ+0Sz1gEfPpvxuGL4CV/2l5YpQX/wor3ocvl8ArD9dv/+TlhuFrr/1h5jVe+Kpz4Kn1y5/9Gz56qX44YnmJN2HH/Gu9HjEJuagLYMCDwF7OuXTgB8BMM/tx40JmNg54BLgQ6AN8DSwOKHI9MAkYBeznq+ecDm57xI0ZM4akpCTOPPNMXnrpJfLy8hrsz8vLY8OGDeTk5PDKK69w4403smLFCsB76PGdd95JXl4e77//Pq+88gr3339/g+Off/55PvjgA9avX+/f9uyzz/Lxxx/zxRdf8Oqrr3LvvfcCsGzZMmbPns0999zDzp07ueSSSzjuuOMoLS3t4G9BRESkG1i/Ev7z9/r1gaMa9lhUVUDuipaPb3z/F6gHLJI+f7PptrJiyFnedPuaz+GrD+rXl70O2zd4y5+8Ur994gHekMO4+IbHj5gMA0d6y1WV8M/7mp5j7X/hrxfDe8+BZqMOqagbQ+acW9VoUy1eiGrsTOBl59zrAGZ2LbDdzEY659YA5wAXOOfygDwz+wNwLvC3kDb4uuNCWl2rbvnHbnenp6fzwQcfcPvtt/PTn/6UjRs3cvDBB/PAAw8AEBMTw29/+1sSEhLYZ599mDx5MsuWLWPChAlMnTrVX8+IESO48MILeeedd7j44ov926+66ir69OnT4JxXXHEFvXv3BuDyyy9nwYIFXHzxxTzwwANccMEFTJ8+HYBZs2Yxb948lixZwpFHHhmSr0NERKRbqqqE5/9Y34M1aiqcfZP3C/srD9c/02vjahg/venx322Br/7TdLt6wCJja079cNC4eNj7wPpruOJ9GDmlvuyu7fDSAw2Pr7vn64g5sHVdfT0nXOINY2zMDI7/GfztGm/oY52kHjD1MK8HzTnv5+zVv3m9bCdfDv2GhubzdnPR2AOGmV1lZsXARiAVeKyZYhMB/59unHMFQA4w0cwygYGB+4HPfcc0PleGmWUHvoDBIfooETFmzBgeeughcnNzWbt2LXFxcZx11lkA9OrVi4SE+i7oHj16UFxcDMDXX3/NMcccQ1ZWFunp6Vx//fVNetCGDBnS5HyB24YNG8bmzZsByM3N5Y9//KN/MpCMjAzWrVvn3y8iIiLt9MZj9UMPE5O9X7TNICUNxu5XX27T6qbH5m2CR34DJQXeekp6fc9ZaRGUa6RK2AX2fo2bBlMPr1//6j+weQ28uRjuuRTuPA92+Hq74hPrr93XH8O/AoLZmP0gKaXlcw4aDbNv8UJXnaMv8F4X3QlZw+u3b/4W5l/XMKxJu0VlAHPO/Q5IA74HPAo0NwVMKlDQaFu+77hU33pBM/sauwxY1+i1pF0Nj0LDhg3jkksu4csvv2y17E9+8hPGjh3LN998Q2FhITfffDOu0djw5p7JtWHDBv/y+vXrGThwIOAFsyuvvJL8/Hz/q7S0lHPO6fIjQUVERDrO+pXwwQv160edDxl969cHjq5f3vxtw/u8tm/wwlfhd956fAL8+NfQe2B9GQ1DDK+yYvjvO/XrUw6FYeMhNcNbLymAey+Dtx5vOmnK/5wNkw6uXw+c1XLvGa2fe8hYOO93Xtkjz/XODTBoFMy906u/bvhi0U5YvbRtn02aFXVDEOs47zf/ZWZ2JHAT8ItGRYqB9EbbegJFvn349hc32tfY3cD8RtsGE2wIa2VIYLitWrWKf/zjH5x22mkMGTKEHTt28NBDD/mHAe5OcXEx6enppKamsnLlSu6//34GDRrU6nF33HEHP/jBDygrK+Ouu+5i7ty5AFxwwQWccMIJHHHEEey///6UlZXx7rvvMm3aNDIzM/f4s4qIiHQ7zQ093Od/GpbJ6As9enq/uJeXej1efQd7w9zmX1vf8xWfCGde782Il5lV36OWvw0GDEc62NYc+Oif8MVb3nUF77qNnOrNbDhuujehRmOxcd49XN873LvHq3AnfPtZ/XUFSEjyesCCkZUNP76i+fMceKp3/9ebi7xtKz8MLtjJbkVlD1gjccDIZrYvBybXrZhZOjAcWO6c2wVsDtwPTPEd04BzLt85lxP4whv62CmlpaWxdOlSfvCDH5CWlsaUKVNITU1lwYIFrR57xx138Pjjj5OWlsZFF13EaaedFtQ5TzrpJPbbbz/23ntvDj/8cH76058CsO+++/Lwww9z6aWX0qtXL0aNGsVDDz3USm0iIiLSopaGHgYyazj9/MbVXs/J366u/yU9Icm7Z2zEJG89s399eT0LLHTWfO49DPk73+0XNdWw/D14+Dfw10tg6av14Qtg36MgNtZb/v7RXkgGb5jgpIPgtCvhqkVw9o1e+AJI7+UFqMCfg732h4TE0HyGcdPql1d/AtVVLZeVoFjjIWaRZGbxwBzgaaAQb/bCF4DbnHN/alR2HPARcCLwH+B3wBTn3EG+/bcCBwMnAD2A13z1tDoJh+8+sHXr1q0jOzu7yf7Nmzf7h9l1d2bGypUr2WuvvTr0PPrORUSk21u/Eh66sr7364SLYd8WJrV664n6XotBo70AUF7irSelwFk3wtBx9eXfex5efcRbzujnDYHb70feu7RP4U6463wvsMQneMP7vv6kfvhnoKxsmHa8NwFGTED/SP4OKMn37sdqbjKNQO8+A68tgJhYOO+2htd3TzgHd19YH8zPvglGfy80dXcBOTk5DB8+HGC4ryOnVdE2BNEBpwC/BxLwerH+BPwZwDcxx4+cc0uccyvN7DzgISALeA+YGVDXTXjT068BqoB7gwlfIiIiIlGn8dDDkVO8B+W2JLAHbNM39ctJPWDOLV4oCxTYA5a/3Xt9/Qn84uH6B/xK22xYWd9bVFXZcHp48ILW+B/A/sd6Qbe5hx5n9G14f9/uHHiK16OZkBTa2QrNYK9p9fcdrvxQAWwPRVUAc85VAy3OT+6cS220/jReb1lzZSuBi3wvERERkc6r8dDDE3/e/C/sdRoHLPBmSJzzWxgwoum+XllNt5WXeL90HzarXU3u9rasa357j55e7+J+R0F679CeMzB4h9K4gAC26iM47ie7//mT3YqqACadTzQNYRUREelytuZ4M+Q1mPXwvNZ7RVLSvIk3dvhua8/KhtOvht4Dmi+f0b/57R+8ANOOgx6+ec+c83p1zJo+3Fca2howY2H/YdB7kPdMtgk/7Hzf3dBx3uMKSgu92RC3rK1/kLO0mQKYiIiISDT677vw7B+gtrZ+W2tDDwMdc5HXczZ0PBx2pncfUkuSe3jBYMX7kD3Rm6xjxwaoLPfu/wGorqwfUhcT6z3094cntuODdRNbA3rAfnxF536IcUyMN+Nm3XT53y5TANsDCmAiIiIi0aay3HuobmD46j2w9aGHgUZO8V7BOu1K7xlgmf3hqw/gid952+sm7whUW+NN2pE9ofnhjt1daREU5HnLcfFe71dnFxjA1izz7jmTdukM09CLiIiIdC//ebF+yviefWDmtfCzPwc/IUN7mHn3gpl5k0OMbeE5UnUB0Dl49q6G06iLJ7D3q392/dTynVlgmM/9CiorItaUzk49YCIiIiLRoqoStqyB956r33bITBi3f3jbYQazrvPu98F3v1d8oveevx3+crHXS7djA7zzJBx+VnjbF+22BN7/lR2xZoRUem/oO8S75jXVkLMcxuwT6VZ1SuoBExEREYkGa/8LfzgXHryifthf74He86Miwcz7pTu9lzepR3yCty2zPxx5bn25j17Sw3kbCwxgzc062VkFTj+/5vO2HVtWAuuWq8cUBTARERGRyPtuCzw+r37YYZ3Dz4rO4Wv7HeU9sBm8sPjNp5FtT7TZFjAEsSsFsMBhiCv/0/JU+5XlsOwNePlh2L7euyfu3kvhkd/AP+4JS1OjmYYgdlFHHXUUS5YsYevWraSlpUW6OSIiItKSynJY/Nv6Xq+UNBi9L4zZFyYeENm2tcQMJh8M7zzlrX/xtvesKPF6eLZvqF/vKkMQwZshMzbOG4K4axvc83PvZ/SkS70hqhtWwaevwfIl3s81wGevedPY79rmrS97A479CSQkRu5zRJgCWBe0adMmXn/9dXr27MlTTz3FeeedF7K6a2pqiImJwfTwPRERkT1XN5HF9vXeelw8nH1T55hZcNLB9QHs64+9IWbJPSLapKjwysPeLJEAvQZAUkpk2xNKCUmw/zHwwd/rty1/z/v5ra2pf1h4oPISWL204bYNq2Dk5I5taxTTEMQuaOHChUyZMoW5c+eyYMECKioqyMzMZNmyZf4yRUVFpKSksGbNGgBeeuklpk6dSkZGBtOmTeOzzz7zl83Ozua2225jypQppKSkUFBQwO23387IkSNJS0tj/PjxvPjii/7ytbW1XHXVVfTr14/Bgwczf/58zIxVq1YBUFFRwRVXXMGwYcPo168f559/PiUlzUxxKyIi0lWUFkHhzqbb333am/K9zvE/6xzhC6DfkPrhddVV3pC07u7zt+Djf9Wv/+CEyLWloxx1Hlxwu/fcuDrb1zcNX30GtfzsuZzlHde+TkABrAtasGABs2bNYtasWbz33nts2rSJk08+mcWLF/vLPPfcc0yePJmRI0eybNkyZs+ezT333MPOnTu55JJLOO644ygtLfWXX7x4MS+88AKFhYWkp6czcuRIlixZQkFBAddeey0zZ85k2zava/nhhx/m2Wef5aOPPmLVqlW8+uqrDdp31VVXsWLFCj799FPWrl1LXl4e1157bXi+HBERkXDL2wT/NxvumONNQlDn60+8ByXXmXYcTD0s7M3bI5MOrl9e/l7EmhEVSosa3t808QD4/tGRa09HMfOGFJ5+FZxwifdQ7jqJybDvkXDhHfDze+HES5uvo5sHMA1BDIGF76zmsXe/Carsj6YO4bJjJzXYdvc//8vLyza0cITnzANHc9ZBY1qt/8MPP+Sbb77hjDPOICsriylTpvgD2dlnn83vf/97YmJiWLx4MbNmzQLggQce4IILLmD69OkAzJo1i3nz5rFkyRKOPPJIAC655BKys7P95zn55JP9yzNnzmTevHksXbqUY445hscff5xLL72U4cOHA3DzzTfzxBNPAOCc44EHHuCzzz6jT58+AFxzzTUcf/zx3HXXXa1+PhERkU5nxfv1swR+/iYMn+iFsmfu8IYgAgzfG446t+U6otXY/bwHMgNsz41sWyJt+Xv19z31GtC2h2Z3VvseAf2HeQ9oHjTae35c4L1dkw70hiYuf8+7Z/Cp273tG7/27pVrqYesi1MA62Lmz5/PoYceSlZWFuCFqb/85S9cf/31OOd49913GT9+PO+++y6PPeb91S03N5cFCxZw7733+uuprKxk8+bN/vUhQ4Y0Oc9dd91Fbq73H9vi4mLy8rwnvm/evLlB+aFDh/qXd+zYQWlpKfvvX/88E+cclZWVVFVVER8fH6qvQkREJDoU7Khf3rUVKsp8k274Rppk9IXTrvQmN+hs6h7c7BwUfudNztAZP0cofPFW/fK047zeoO5gyFjv1ZIph3gvgDcXeX98qK6Cjau9P0Z0Q1H1L8TMEoF7gMOBXsBa4Drn3IvNlD0YeBMoDdh8qXPuYd/+BODPwGlAFXCvc+76jmx/pJWXl/Pkk09SVVXlD2CVlZXs2rWLJUuWcMYZZ7Bo0SImTZrEIYccQt++fQEvXF155ZXccMMNLdYdOOlGbm4uF154IW+++SbTp08nNjaWiRMn4nx/xRs4cCAbNtT36K1fv96/3KdPH5KTk/niiy8YNmxYSD+/iIhIVCrIq1/eucWbFW7HRm89PgFmXgs9ekambXsqNs57VlhBnhfC8rd7zy7rbnZuhfUrveWYGK/nR5oaNqH+XrHcFQpgUSIO2AAcBKwHjgSeNrPvOedWN1N+u3Muq4W6rgcmAaOAVOB1M1vnnPtbqBt91kFjghoe2JLLjp3UZFhie7zwwgs451ixYgWJifXdvxdeeCHz58/nsssu49BDD2XZsmVcfvnl/v0XXHABJ5xwAkcccQT7778/ZWVlvPvuu0ybNo3MzMwm5ykpKcHM/AHuoYce8k+wAXDaaadx553/z959h7dZnX0c/96S97bjxE7iJM5OSCAJEMLeUGihhba0QGnZpYMWSjfwQgqUbgpdFMoIhdJSZkvZe5SyAgQCCdk7TuLEe1s67x+PHMmKt2V5/T7XpUvPOM95jizH0a1zzn1u4KSTTmLkyJEsXLhw9zmfz8eFF17IZZddxp/+9CcKCgrYvHkzS5Ys4ZOfHILjpEVEZGhrbICm+o4DqMqIAKyiFNZ9GN4/+kuDf52o3MJwkLmrZHgGYEteDG9P3W/wBtR9rXg2LH7a237lAS81/fFnD7uf14BKwuGcq3HOLXTOrXPOBZ1zTwArgPk9qO5c4FrnXKlzbh3wG2AQDq7uukWLFnH22WczYcIECgsLdz8uueQSHnjgAaZMmcLo0aNZtmwZp5xyyu7r9t9/f26//XYuueQS8vLymDJlCrfddlu799lrr7347ne/y4EHHkhhYSHLly9vNaTwggsu4DOf+Qzz589n+vTpHHnkkQC7g8Jf/vKXzJgxg4MOOoisrCyOPfZYli1b1ic/ExERkT5TVwO/+xr8/Cx459n2y5XvaL2/KpxpmPEz+6Zt8ZQX8V14WUn/tSPWgkF47m/w26/CKw+2Xy4Q8Ob2tZhzVN+3bbCaNMfrIQRvvtw7z8CiK72hq8OItQwbG4jMbCReT9hBzrn3os4dCTwD7ATqgH8DVzjnqs0sF9gFFDnnNofKHwQ87pzLjaonB8iJunUR8MratWtbJZ5osWXLFsaMGYbf7vTQsmXLmDVrFvX19SQl9WyypX7mIiIy4Hz4GvzjZ952SjpceiukZ7Uu01AH132h/Tou/8fgXzvrxfvC2RwPOXVwJhOJVlcD9/8KVi4OH7vsNsgt2LPs04vCAVpyKvzwnmGbXKJLlrwIL/wddoZzDXD0mXDUGf3WpN5Yt25dS+K5iaFOn04NqB6wSGaWANwD3BcdfIUsB+YAY4CjgXnATaFzGaHniojy5UBmG/VcCqyNerzSq8YPc3V1dfznP/+hqamJ0tJSvve973HSSSf1OPgSEREZkGorw9v1Nd6HymiR87+iZY0Y/MEXRPWAbeu/dsTSfT9vHXxBeOhcpA9fa907dtjnFXx1Zs6RcMmf4fhzwsdevA9K1vVTg+JvQAZgZuYD7g7tfrWtMs65EufcR6GhimuBHwAtudGrQ8+RX0NlA1VtVHUjMDHqcVivXsAw55zjmmuuIS8vj+nTp5OSksItt9zS380SERGJrcgADOCtJ/ZcjLYiavhhpFHj2z83mOQOgiGIaz+AP18GT97RedntG2D1e3sef+dZb7jh7nIb4aGIJXSmz4fDT+t1U4cFM6+3dNwMbz8YgEd+1/rnO4QNuADMvHR7t+P1bJ3qnGvs4qUOMADnXBmwBa+HrMVcYI9V35xz5aE5Z7sfwKaevwJJS0vjzTffpKqqip07d/Lggw8yevTo/m6WiIhIbEUHYMEAPBWV66ujHrBRQyQbcOSwvLKS8NpmA0XZdrjrKti8Ev77sJf+vCOR87lmHggZOd521S5Y8ba33VAH/7i+9bpfn/vu0F/3K5Z8Pm+ttJZlCzavhNce6dcmxcuAC8CAm4GZwEnOudr2CpnZUWY2wTzjgJ8DD0cUWQRcaWb5ZjYBuAzowtceIiIiIl1QU7nnseVveL0tLYZDD1h6NiSGsi/X10Jddcfl4ykQ8Ba8jkzysPHj9ssHg/BexHpe+x0P844N77/9pBdgPnRj66UEzrh8aAwnjbdR47z5Xy1a1gkb4gZUABYKlC7C663aambVocflofPVZtYyPHAe8BpQE3r+APhWRHU/wevxWg0sxptLFvMU9CIiIjJMRfaA5YwMbz95e7gXqLKDHrCCIdIDZjZwMyG+/M/w+lwttq5uv/yaJV5PF3iB5ZR5XhDWYsXbcPdP4KPXwsc+8y0oLI5Zk4edQ04NL8XQ3OQNRRxovagxNqDWAXPOrSc0jLCd8xkR2zcAN3RQthEvmLsolm2MqL/V4sTSdwZypk4RERnGIgOwE86HB2+ApkbYstrrRZl3dCdDEIdIDxh488C2rfe2y7bB2Kn92x6ArWu85A5tHd+8ysvcWF0GTQ3hR0NduNycI73hcSNGe9sta31FJuc48GTvnPScPwFOvcSboxcMwPqP4I3H4MCT+rtlfWZA9YANFomJiVRXVysw6GPOOZqbmykrK2u1sLSIiMiAUBORbLlwEhx8Snj/ubu9RZojhyCmReQGyxkFSSl93sS4iewB2zUAesACzV6CjGAoqUNkD9X2Dd6wxJWLvWCsdLMXKNdWtR6qOPeY8Panv7lnj+X4mUMj5f5AMHqSl0GyxTN3eXP3hqgB1QM2WOTl5bFr1y6qqtpKqiix5PP5SEtLIzOzrRUERERE+lFkD1halvcB8u2nvMCsohT+96/WPWAT94YP/+ttD5Xhhy1yIhJxlA+AVPQv3x9Oa56YBKdfDn+9GnZt9YKyjuYZ+fxwwCdh9MTwsaQUOOMKuOUyb45bRg588UfhBBLSe0d+0RvauWOjl9zk2b/Cad/zzgWa4c0nvCG9h58GqRkd1zXA6bemB/x+PyNHjuy8oIiIiAxNTY3hDHg+H6SkeXOhjjkL/v1H7/izd4fLJ6XAhFnhAGzMlPi2t69F9oB9+F8vccW46f3TlspdrdfmOu4cbxjhmMleABZp+nw4/lwviUhSsveckOS9p9FGjIaLboBlr8PsQyErr09fxrCTkAifuRhu+6G3v3KxlxRl6xp4+MbwENeKUvjC9/utmbGgIYgiIiIi3VUXMQomLSucfnzf42DkuD3LZ4+E/Y7zPrjPWODNHRpKxu8V7pWorYI7L4f/Pdp6SF+8PHePN58LvKFtLXOJRk/es+yco7xMfLmjvKQbSSltB18tRoyGQ09tnXRFYmf8TMjM9bbrqmHZ/+COH4eDL4ClrwyMYa69oABMREREpLtqooYftvD74ZMX7lk+a4T34f6LP4QvXQlpQ2xofWo6nHVV+HU1NcLjt8IfvwUrFnd8bSxtWw/vPhve/8S54eB4TFQAlpgE0/aPX9ukc2YwcZ/w/r//FO5pbuHcoF8vTAGYiIiISHdFz/+KNGUefPbS1sciFyseqsbPhK/+GvLHho/t2AR3L/TmX23f0PdteHpROIX51P1g8tzwuZZU5y2m7AvJqX3fJumeSXPC25H/zhZEZEV855nWSXAGGQVgIiIiIt0VPQQx2rxj4NyfQna+1yu0/yfi17b+NGIMfON3cPw5rYOble94vWGP3tz2AtaxsOZ9b50u8HpSjj+n9fn0bO/9aDHrkL5ph/ROZADWIj0bTjw/HEQ3NXqp6gcpBWAiIiIi3RX5zXx6GwEYwKR94Lt3wPfvGhjrYsVLYhIc9jm49FaYf0J4CGAwCG8+Djd+FV77V2wX23XOWwC7xbxj2l4ced/jvOe80TDzwNjdX2Ind1TrpC4A+xzhZZw89HPhY2881j9zDGNAWRBFREREuqu9OWDRzLzsbsNRRo63ftYBn4InboM1S7zj9TXevvngoBglI3n/JS9bHngB4NFfarvcUWfA3od7SVGStMbogDVpTutEG3OP9p5nHQIv3OsNdz3ks4N2GQD1gImIiIh0V0dzwKS1wmI451o480pviGKLt5+MTf1Njd6aUS0OPqX1UMNIZjCySMHXQBc5d2/U+PDQQ78fLv4DnHqJl71ykFIAJiIiItJdkQkAFIB1zgxmLoBv3BTuEdy+AcpisGjzG/+B8h3edlpW62FqMjjNPNDrBUvLghPODw9jhUHb6xVp8L8CERERkXhTD1jPJKV4H6xbkmUsf7N7wxCbGuHtp7x5d/sc4a059tI/w+ePOsNbFFsGN38CnHudN7cvMvgaIhSAiYiIiHRXV5JwSNumHxAOwD7uZgD25uPhZBsJSbB5pTenDLzhjfNPiG1bpX8NweALNARRREREpPvUA9Zz0+eHt9cthfrarl/76oPh7b9fD+8+F94/9stDYniaDH29DsDMLN3MvmBm3ws9p/eirmQzu93M1ptZlZktMbNPd1D+NDNbY2Y1Zva0mY2NOJdkZreYWbmZ7TCza3raLhEREZFWFID1XHY+jJnsbQeaYdU7Pa+rapf3nJ4NMw/qfdtE4qBXAZiZzQQ+Bm4CPgfcCHxsZnv1sMoEYCNwBJAN/Ai418ymtXPvO4CvAvmhdtwbUeQqYB9gCjAfONPMzu1hu0RERGQ427oGFj8DdTXQ2ODNRQKvxyUppX/bNhhNPyC8verd3tc350gvQ57IINDbHrDfAncDY51zBwFFwF14gVi3OedqnHMLnXPrnHNB59wTwAq8ACraWcATzrlnnXN1wJXAgWYW+kqFc4FrnXOlzrl1wG+A83rSLhERERnGairgLz+AR34Ht37Xm3fUIi1ryM5T6VMTZoW3S9Z27ZqmRqgub/vc3GN63SSReOntQNn9gE8754IAzrmgmV0LbOp1ywAzGwnMBD5s4/Rs4M2WHedchZmtA2ab2S5gDLAkovx7wPVt3CMHyIk6XNSLZouIiMhQsnklNDV426Wb4Y4fh88pAUfPFE4Mb29fD4FA5z1YlTvbqasYRk9s+5zIANTbHrAaYFTUsZGh471iZgnAPcB9zrn32iiSAVREHSsHMkPniDrfci7apcDaqMcrPWu1iIiIDDkVpe2fS8uOXzuGkvQsyMzztpsaYeeWzq8p39728TlHx65dInHQ2x6wB4FHzOwKvMBlInAt8EBvKjUzH97QRvDmeLWlGoj+2ikbqAqdI3S+OupctBuBRVHHilAQJiIiItB+z4vPD/sdH9+2DCWFE8NJNErWwqhxHZev2BHeHjfde87MgwM+2TftE+kjvQ3ArgBuAB4GUoB6vGDmip5WaGYG3I43hPBE51xjO0WXAnMirsvCCwCXOufKzGxL6HzLVypzQ9e04pwrx+sdi2xDT5svIiIiQ01kAHbiBTB2KiQkQs4oL/ue9EzhRFi52NsuWQv7HN5x+cgesElzvLTzIoNQrwIw51w98A0z+yZeJsJS55zrZZtuxpv3dZxzrqOFIe4B3jCzo4H/4fW8ve6cWx06vwi40szeAtKBy4Cf9bJtIiIiMtxURgxBHDEGJvQ02bO0EjkPrCuJOCJ7wLJHxr49InESk4WYnWdHb4MvM5sAXITXW7XVzKpDj8tD56vN7LDQPZcB5wO3ATvxgrYzI6r7CV6P12pgMd5csjt70z4REREZhiLngGWN6L92DDXdDcAie8AUgMkg1u0eMDP7wDm3d2h7LdBm0OWcm9Tdup1z64F2x/855zKi9u8H7m+nbCNeMHdRd9shIiIisltVxBBEBWCxM2IMJCZ5STiqdkFNZcdZJcsjesByonPAiQwePRmCGDmMb2GM2jEgfeV3z5OaW9BpuRPnjePSk/ZpdezG/7zPE+9u7NJ9zjp8Kl8+ovVa01f94y3eWNlOtp8ol3xqbz657/hWx775l1dYVVLZpet/8sX9OXBa69d5xm+fZVd1Q5eu/8MFhzJ1dOsx8J+49rEuXQtw76XHMCIzvIjlzqp6zrzxuS5f/9T/farV/sqtFVx826tdujYvI5m/f+fYVsdeX7GNq+97u0vXTynM4o8XHtbq2OPvbOCmxz7o0vULpo7imtNbL3N390sruOflle1c0Zp+9/S7F0m/e/rd6wr97vXkd+8rkORtXbK8nE/u1/q91+9eD3/3/H5ez96PqytDU/pv6Dj/2RR3CH9syfOW4/WADf3fvTD93RuYf/fqyrZ1qY5I3Q7AnHP3Ruz+2zlXFl0mtLaWiIiIyNCiRF2xlTMKuhY/QMtMl7RMSErpuKzIANbbOWDr2zm+ppf1ioiIiMhQN2J096/R/C8Z5Kw3eTPMrMo5lxl1zIeXDTGvt43rL2ZWDKxdu3YtxcXF/dwaERER6TfvPgcP3eht7304fOH7/dqcIaemAn5zPjSFhsGddZWX5v/F++DtJyHQvOc1MxbAl66MbztF2rFu3TomTpwIMNE5t64r1/QoDb2Z3RHaTIrYbjEFWNaTekVEREQGlMg1wLLz+68dQ1V6Nsw/EV57xNt/9E9QVw2N9e1fox4wGeR6OgTR2nk44BVap4MXERERGZxapaBXANYnDjnVW9gavJ93ZPA1YS84LarXccSY+LVNpA/0qAfMOXcugJmtcM5pcWMREREZmiq1Blify8qDfY+DNx8PHysshuPOhqn7eYlP8grhkd95yTfmHt1vTRWJhR4FYC0UfImIiMiQpiGI8XH0l2DHRmiog0NO8ebbRWacLJoGF/+h35onEku9CsDMLAW4AjgWGEXEIso9WYhZREREZECp1CLMcZGeBedd39+tEImL3qah/zXwReA+oBD4HRAAohNziIiIiAwuTY1elj4Anw8ycvu3PSIyJPQ2APsMcJJz7kagMfT8OeDQXtYrIiIi0n/qquHZv4b3M/O8IExEpJd6NQQRyHbOrQhtN5tZgnPufTM7sLcNExEREYmZQMBLqJE9suNAqqkR3ngMXv6nF4S1yC/q+zaKyLDQ2wBsg5lNdM6tBVYBJ5vZTqCDxRtERERE4sg5uO/nsOx1mHkgnHF56wQPLWWWvAjP3Q3lO1qfGzsVTvpa3JorIkNbb/vS/wTMCW3/BrgfeAG4qacVmtnFZrbYzBrNbFEH5Y40s6CZVUc8zo84n2Rmt5hZuZntMLNretomERERGcRWvesFX+A9f/CKt+2c99zUCIuuhAdvaB185Y2GL/4QLvoN5I+Nb5tFZMjqbQ/YIudcLYBz7gEzmwBkOueW96LOLcC1wCeA1E7KbnfOFbZz7ipgH2AKkAE8a2ZrnXN39qJtIiIiMpCUbYd3noEp87xFe9vy8v2t95++E95/EdYsgZkHQVMDrHk/fD4tC446A+afAP7eflQSEWmtx39VzMwP7DKzLOdcI4BzbnNvG+SceyhU//5AbwZcnwtc6JwrBUrN7DfAeYACMBERkaHikZu84Om/D8Glt+6ZKn79R7BuaetjFaXeA+D9l1qfO/gUL/hKSeuzJovI8NbjIYjOuQCwEejPv1AjzKzEzNaa2U1mlgFgZrnAGGBJRNn3gNnRFZhZjpkVRz7oXeAnIiIi8eAcbArlAmtqhMXP7FnmpX+Gt3NGdVzfQZ+GE89X8CUifaq3c8CuBG4NBS3xthxv/tkY4GhgHuG5Zxmh54qI8uVAZhv1XAqsjXq8EvPWioiISGzV10JjRN6vxU952Q5bbFkNKxd722bw5YVQHPoudtR4+MzF3jwvgDlHwgnnIyLS13o7sPnvoefPWVQ2Ieecv5d1d8g5VwKUhHbXmtkPgCeB84GWvLFZEdvZQFUbVd0ILIo6VoSCMBERkYGtIipbYUWpF3DNOMDbj5z7NesQGDUOzrkWdm71kmr4fLDf8VBVBll58Wu3iAxrvQ3AjopJK2LDAQbgnCszsy14PWRbQufnAkv3uMi5crzesd2ig0kREREZgCpL9zz29pNeALZjE3z0Wvj44V/wnv0JXiDWwkzBl4jEVa8CMOfcS52X6h4zS8Brlx/wm1kKEHDONUWVOwpYA2zA67H6OfBwRJFFwJVm9haQDlwG/CzW7RUREZF+UtFGALbibS8z4isPhNPMT58PoyfGt20iIu3o7RywvnAlUAf8CDgrtP0XgNBaX4eFys0DXgNqQs8fAN+KqOcneD1eq4HFwH1KQS8iIjKERA9BBC/oeu4eWPJC+Njhp8WvTSIinRhwi1s45xYCC9s5lxGxfQNwQwf1NAIXhR4iIiIy1ET2gE3dL5xwIzL4mrg3jJ8Z33aJiHRgIPaAiYiIiHQucg7Ygk9BZhtzuY74QvzaIyLSBQrAREREZHAqjxiCmFvoZTSMNHYqTJoT3zaJiHSi1wGYmWWZ2ZmhNPCYWYGZFfa+aSIiIiLtcA6qdob3s/O9ACwyk/ERX2i9LyIyAPQqADOzucBKvMQZV4UOzwP+0LtmiYiIiHSgthKaGr3tlHRIToWckXDo57xjex0EMxb0X/tERNrR2yQcNwILnXM3m1lZ6Nh/gdt6Wa+IiIgMRxuWw39uhsKJcOol7fdgRSbgyM4Pbx/3FTjyi5CYrN4vERmQehuA7Q0cHdp2AM65KjPL7GW9IiIiMtzUVMDdV0N9LWxdAzMPgpnt9GJFpqDPigjAzCAppW/bKSLSC72dA1YGjIo8YGbjgZJe1isiIiLDiXPw7z95wVeLjcvaLx+ZgCNnZN+1S0QkxnobgP0TuNPMJgKEkm/cBPyttw0TERGRYeTD/8JHr7U+tvHj9stHpqCP7AETERngehuA/QTYBqwGcoDNQBD4RS/rFRERkeHkvef3PLZ5JQQCbZdvbw6YiMgA16sAzDnX4Jw7B8gHDgQmOuc+55xriEXjREREZJjYsXHPY00NsH192+Uj54BlawiiiAwesVqIORGv56sxRvWJiIjIcNHcBGXbvG0zmD4/fG7TiravqdoV3s4a0XdtExGJsd6uA5ZvZo8DW4E3gc1m9riZaSyAiIiIdM2urV4SDvB6s4r3Dp/buLzta2oqwtvpOX3WNBGRWOttD9if8dLP7wWkArOA5tBxERERkc7t2BTeHjkOxk0P729qIxFHYwM01nvb/gRISevb9omIxFBv1wE7Gm/eV8vXUMvN7GxgTS/rFRERkeFi5+bwdv5YGD0ZfH4IBrzgrK4aUjPCZVr1fmVrwWURGVR62wNWTmgB5ggOb32wHjGzi81ssZk1mtmiTsqeZmZrzKzGzJ42s7ER55LM7BYzKzezHWZ2TU/bJCIiIn0osgcsfywkJUPhxPCxdR+2Ll8bFYCJiAwivQ3ArgDuMrNpoYBnGnA7cHkv6twCXBuqp11mNhO4A/gqXhbGj4F7I4pcBewDTAHmA2ea2bm9aJeIiIj0hVY9YEXe8+S54WPL32hdProHTERkEOltAPY34DPAMqAu9Hwq8DczC7Q8ulOhc+4h59wjwM5Oip4FPOGce9Y5VwdcCRxoZpND588FrnXOlTrn1gG/Ac7rTltERESkjzkX1QMWCsBmHhg+9vGbEAyG95WAQ0QGsd7OATsqJq3omdl4mRcBcM5VmNk6YLaZ7QLGAEsiyr8HXB9diZnl4C0iHakotk0VERGRNtVWQn2Nt52UApm53nbRNG+7qswLuDYuhwl7eeeqy8PXqwdMRAaZHgdgZpYAfAq4yjlXH7smdVkGUBF1rBzIDJ0j6nzLuWiXAlfHtmkiIiLSJdG9Xy0JNcxgxgJ460lvf9nr4QBMQxBFZBDr8RBE51wzcEE/BV8A1UBW1LFsoCp0jqjzLeei3QhMjHocFsuGioiISDtKoxJwRJoRMQxx2evhtcIUgInIINbbOWDPmdmxMWlJ9y0F5rTsmFkWXvC01DlXhpfMY05E+bmha1pxzpU759ZFPoBN0eVEREQkxla/B28+Ht7Pj5oBMGkfSE71tndthe0bvO3IACwjpy9bKCISc72dA7YFeMjMHgbWArtnyDrnepT2PTS0MQHwA34zSwECzrmmqKL3AG+Y2dHA//AyJ77unFsdOr8IuNLM3gLSgcuAn/WkTSIiIoI3H6uhds+equ5yDp75K7zyQOvjkannARISYdr+8MEr3v6y16FgAtSUh8uoB0xEBpne9oDtAywGxgNH4CXlOAo4shd1XomXUfFHeJkO64C/AJhZtZkdBuCcWwacD9yGlzFxJnBmRD0/wevxWh1q433OuTt70S4REZHhq2Qd/O7rcNPXwvOyeuqlf7YOvnw+2O94mLbfnmWjhyGChiCKyKDWqx4w51zMsyA65xYCC9s5lxG1fz9wfztlG4GLQg8RERHpqWAQHvldOFvhU3d4aeJ7MvzvtX/Bc/eE96ftDyd9HXJHtV1+6n7gT4BAM2xZBeU7FICJyKDW2x4wERERGereeAw2rwzvN9TB83/rfj1vPwVP3BbenzwXzri8/eALIDXdmwvWYskL0ByalZCY7KWuFxEZRHodgJnZ+Wb2dzN7zsyeb3nEonEiIiLSz2oq4Nm/7nn87ae8YYld9f5L8O8/hvcn7AVnXuHN8+pM5DDEt58Kb6v3S0QGoV4FYGZ2DfBzYBtwEPA+sDetF0AWERGRwWrVu9AYWnFmZJHXawVeIo0nbw+nhu/IstfhwRvCZcdMgS9d1fXeqxkLwtvl28PbCsBEZBDqbQ/Yl4ETnHOXAvWh588CY3pZr4iIiAwEu7aGt2ccCCdeEF4sefV7sOLtjq9fuxTu+4U3jwy8LIZnX+MNLeyqrDwYN33P40pBLyKDUG8DsHzn3OKWHTMz59wrQH+tDSYiIiKxtDMiAMsr9AKo/U8IH3vydi9BRlsqd8F9Pw+fzxsNZ18LaZndb0fkMMQW6gETkUGotwFYiZmNDm2vBw42sza+ohIREZFBKbIHLC/0X/4xX4KUNG+7dDO8+cSe1wWaveCrJWNhejaccx1k5vasHTPbCsByelaXiEg/6m0A9ne8db8AbgWew1tz6552rxAREZHBIzIAyy30ntOz4Ygvho+/cC/UVrW+bsmLsGGZt20GX/hBx9kOOzOyaM8FoNOyel6fiEg/6VUA5py7yjl3b2j7ZuBo4PPApb1vmoiIiPSrhrpwD5Y/AbLzw+cOPNkbkghQVw0v/qP1tVtWhbcPObV1KvmemnlQ633NARORQSim64A5515zzj3pXFdSIomIiMiAtqskvJ1bAL6Ijw0JiXD8ueH9Nx7zhiO2qNoV3h4zJTbtiR6GqDlgIjII9TYNfbqZXWFm/4pcA0zrgImIiAwBbc3/irTXQVA829sOBmDx0+FzkQFYZl5s2lM0rfUcsljVKyISRwm9vP52YH/gYaC6980RERGRAaOzAMwMFnwK1i319retD5/riwDMzOt1e/RP3npkBRNiU6+ISBz1NgD7BDDTOVfSaUkREREZXMoi/ntvme8VLb8ovL0zNATROagqCx/vaebDtsw9CuYcGV6LTERkkOltAFYB7Oq0lIiIiAw+OzvpAQMYMcYLhpyDsm3Q3AQNteG1v1LSISkltu1S8CUig1hvk3D8DLjOzGKWzMPMcszsn2ZWZWabzewb7ZQ7x8wCZlYd8Ti2u/WIiIhIO9pKQR8tMQmyR3rbznmJO/qq90tEZAjodg+Yma0FIrMcFgHfMLPtkeWcc5N62KY/hNo1BpgMPGNmy5xzL7RR9i3nXBsrM3a7HhEREYkUaIaKHd62mZcFsT35Y6E89DGgdBMkJIXPKVGGiEgrPRmCuDDWjWhhZunAacA851wV8J6Z3QGcB3Q5cIpVPSIiIsNW2TavRwsga4TX09We/CJY9a63Xbq5dXr4zBF910YRkUGo2wGYc+6uvmhIyDTAnHMfRRx7Dzi+nfL7mFkp3jy0vwE/dc41d6ceM8sBcqIOF0WXExERGVZ2bglvtzf/q0X+2PB26SZwwfC+hiCKiLTSoyQcZpaAF+A0RRw7B5gLvOyce6iH7ckAKqOOlQOZbZR9GZgFrA893wcEgWu7Wc+lwNU9bK+IiMjAVVcNG5fDyPGQO6p7125aEd4uKO64bKsAbDMkJof3NQRRRKSVnmZBvA94CrgVwMyuBK4C3gcuMrNvOedu60G91UBW1LFsoCq6oHNuTcTuB2Z2DfBjvACsy/UANwKLoo4VAa90tdEiIiIDTjAIf/k+7Njk7eeNhv2O99btSk7t/PqNy8Pb42Z0XDY6FX1GTng/S0MQRUQi9TR74f7AfyL2vwVc4JzbHzgL+HoP610BODObGXFsLrC0C9dGJgbpcj3OuXLn3LrIB7Cpuw0XEREZULZvCAdf4GU0fOYuuOF8WPZGx9c6B5sjesDGTe+4fNaIcK9XbVXrBZkzNARRRCRSTwOwXOfcFgAz2wuvd+mfoXOPAMU9qdQ5VwM8AFxrZplmtg9e4ow7osua2YlmVhDangH8H/Bwd+sREREZkraubvt4bRU8fms4wUZbdmyC+lpvOz0bcjoZvmjWehhiZPp6DUEUEWmlpwFYjZm1zKfaH1jqnKsP7Ru9W+D5m3i9WVuBJ4GFzrkXzGx8aK2v8aFyxwDvm1kN8DjwEPDTzurpRbtEREQGjy0RAdgRX4BTvh3upSrf3jrJRrRNH4e3x83o2sLHkQFYJAVgIiKt9DRQegX4qZndijfc8MmIc9Pxgp4ecc6V46WQjz6+AS+5Rsv+94DvdbceERGRYWHLqvD2uBkwfT4sf8N7AKxZ0n7Q1CoA62T4YYsRbdSVkg5JyXseFxEZxnraA/ZD4Di8pBvpwA0R574EvNrLdomIiEhPBYNQsja8P3qy9zx5bvhYy7pdbYlMwFHUxQBs2v57HlPvl4jIHnrUA+acWwvMNLM859yuqNO/BBp73TIRERHpmZ1boDE0MyAzF7JCgVBkALb2AwgEwO9vfW1DXTiJhhmMndq1e46b7tW/+r3wMQVgIiJ76GkPGABtBF8tWQVre1OviIiI9EJkAo6W3i/whhy2pIWvr2k9TLHFltXhBB0FE7qWsr7F0We23m9q6Pq1IiLDRK8CMBERERmAIhNwjJkS3jZr3QsW2VvVYseG8HbhpO7dd/xMSM0I7xfP7t71IiLDgAIwERGRoSayB2zM5NbnJs0Jby97fc909Ns3hrdHjuv+vc/7mZd8IzUD9jmi+9eLiAxxvUkXLyIiIgNNQ13roYWjowKwqfuCPwECzV65JS/C3KPC5yN7wHoSgBUWw4/u8eaXKQOiiMge1AMmIiIyVDgH//p9eBHlrBGQnd+6THo2HPyZ8P5Td4TLg7cIc4tRPQjAwAvwFHyJiLRJAZiIiMhQ8ebj8MEr4f3jzm57EeUjvhjOUFhdDi/c623X1UBVKL9WQiLkFPRpc0VEhiMFYCIiIkPB5pXwxG3h/fkntB5aGCk5FU44P7z/+qNe6vkdEfO/8sfumaJeRER6TQGYiIjIYFdbBf/4uTevC2D0JDjxwo6v2fswmLSPtx0MwmO3tA7AejL/S0REOqUATEREZDBzDh76LZRv9/ZT0uGLP4LEpI6vM4NPXQS+UC/X2g/g1QfD5xWAiYj0CWVBFBERGWyWvQ6vPgRT5oH54OO3wudOvQRGjO5aPaPGw4Enw2uPePulm8PnFICJiPQJBWAiIiKDiXPwrz9ATQVsWNb63MGnwF4Hda++o86AD16CqrLWxxWAiYj0CQ1BFBERGUzKtnnBV7RxM+D4s7tfX0oaHH9u62NmMGJMz9onIiIdGnABmJnlmNk/zazKzDab2Tc6KHtxqEyVmd1nZlk9qUdERGRACwZh8ypobICta/Y8n5YFX/yht/5WT8w5EopnhffzRntp6EVEJOYG4hDEP+C1awwwGXjGzJY5516ILGRmxwFXA8cBa4BFwO+Bs7tTj4iIyID3rz/AO89AwQSYNj98fPahMHkeTJ8Pmbk9r98MPvU1uOUyaG6CyXN73WQREWnbgArAzCwdOA2Y55yrAt4zszuA84DowOkc4E7n3Huha68A3jWzrwPWjXpEREQGrqZGWBL6r2vb+tZztWYeCPscEZv7FBbDV38D29fDXgfHpk4REdnDgArAgGmAOec+ijj2HnB8G2VnA4+37DjnlpkZwFS8oZVdqsfMcoCcqMNFABMnTuxm80VEROLouv/0dwtERKSbBloAlgFURh0rBzLbKRs9C7kiVNa6Uc+leEMZRURERERE+tRAC8CqgayoY9lAVRfLZoXK+rpRz41488ciFQGvdNpaERERERGRbhhoAdgKwJnZTOdcy+Imc4GlbZRdCswB7gUwsxl4PV8rQ89dqsc5V47XO7ZbaCgja9eupbi4uBcvR0REpBN3XA5rP9jzeGExnHU13HSRNw8s2vwT4dNK8Csi0p/WrVvX7WlLAyoNvXOuBngAuNbMMs1sH7zEGXe0UXwRcK6Z7WNmmcB1wH3Oudpu1iMiItI/StaFgy+fD47+kpeRsOXcny5pO/gCGD0pHi0UEZEYG1ABWMg3AQdsBZ4EFjrnXjCz8WZWbWbjAZxzzwDXhspsBYLAtzqrJ34vQ0REJKS2Cp68A958HJwLH3/zsfD2XgfDUafDZ78TDsJqI6YzT9qndZ0KwEREBqWBNgSxZUjgaW0c34CXeCPy2O/x1v7qcj0iIiJxFQjAvdfB+lBi3qZGOOQUb3vN++Fy80/0nuceBYlJ8M9fQTAQPj/3GGhqgI0fQ2YeFBTHo/UiIhJjAy4AExERGVJevj8cfAE8cxcUz4K8MbBzi3fM54dxM8JlZh0CZybBP37mLYzs83s9YJPnwNJXYcq+XpAmIiKDjgIwERGRvrJhObz499bHAs3wz1/Cpy4KHxs1fs+Aavp8OPd6eP1RmHEAZOd7xw/+TN+2WURE+pQCMBERkb5QXwsP/BqCQW9/7FTYudk7vqsEnr07XHbMlLbrGD/De4iIyJAxEJNwiIiIDH7/+TOUbfO2U9Lh9B/DoZ8Ln9+6Jrw9ZnJ82yYiIv1GAZiIiEisvf8yLIlIvPvpb0LOSJixoO3y7fWAiYjIkKMATEREJJbKtsOjfwzvzzsG9j7M2x41HnJGtS7v80Fh9xbxFBGRwUsBmIiISKwEAt68r/pabz+vsHWyDbM9e8FGjlNGQxGRYUQBmIiISKwsfgo2LPO2fT74/PcgObV1menzW+9r+KGIyLCiAExERCRWPvpfePuIL8K46XuWKZ4NSSnh/dFKwCEiMpwoABMREYmFQHO49wtg3+PaLpeQCHsd7G2beYsri4jIsKF1wERERGJh80poavC2cwu8rIftOfECyBsNBRO8xBwiIjJsKAATERGJhbUfhLeLZ3dcNi0Tjjq9b9sjIiIDkoYgioiIxMK6peHtiXv3XztERGRAG1ABmJmdZmZrzKzGzJ42s7EdlF1nZnVmVh16PN/TukRERHolev5XsQIwERFp24AJwMxsJnAH8FUgH/gYuLeTy051zmWEHkf3si4REZHucw5WLIbGem8/ZxTkjur4GhERGbYG0hyws4AnnHPPApjZlcB2M5vsnFvdj3WJiIi0bePHcP+voGxb+Fhn879ERGRYGzA9YMBsYEnLjnOuAlgXOt6eu8xsh5k9Y2bzelKXmeWYWXHkAyjqzQsREZFhYPNK+OtVrYMvgBkH9E97RERkUBhIPWAZQEXUsXIgs53yXwLeAQy4BHjKzGY453Z1s65Lgat71GIRERmeyrbDXVdBfa23n5wKE/eB6QeE1/gSERFpQ78FYGb2JeCW0O56YBWQFVUsG6hq63rn3H8jdn9mZmcDRwAPA9XdqOtGYFHUsSLglQ5fgIiIDF9vPQ511d52Wiacez0UFvdrk0REZHDotwDMOfc34G8t+2b2U2BOxH4WMBFYuufVbVcZsb20q3U558rxeseIKN/FW4qIyLC0cXl4+6SvK/gSEZEuG0hzwO4BTjSzo80sFbgWeL2tpBlmNt7MDjGzJDNLMbPvAyMJ91p1uS4REZFuCTR7879aTJjVf20REZFBZ8AEYM65ZcD5wG3ATmAmcGbLeTP7s5n9ObSbCdwMlAGbgROAE5xzpV2pS0REpMe2rYemRm87ZxRk5fVve0REZFAZSEk4cM7dD9zfzrmvRWx/COzT07pERER6bNPH4e1x0/uvHSIiMigNmB4wERGRQWFDxPyvIgVgIiLSPQrAREREuqNVD9iM/muHiIgMSgrAREREuqq2CnZu8bb9CTB6Uv+2R0REBh0FYCIiIl0V2fs1ZjIkJPZfW0REZFBSACYiItJVGyMCMM3/EhGRHlAAJiIi0lWBZkhO9bYVgImISA8MqDT0IiIiA9rxZ8OxX4bSTZA5or9bIyIig5ACMBERke7w+WDU+P5uhYiIDFIagigiIiIiIhInCsBERERERETiRAGYiIiIiIhInCgAExERERERiRMFYCIiIiIiInGiLIht8wNs2rSpv9shIiIiIiIDVES84O/qNeac65vWDGJmdijwSn+3Q0REREREBoXDnHOvdqWgArA2mFkyMB/YCgT6uTlDRRFeUHsY0PJVwVpgYr+1SCLF4r1o6z2W7hkM/yaGy/s8GN6LvjAQ39/h+l70lZ6+x3ofBo7I92Ig/psdTtYCU4DRwFvOuYauXKQhiG0I/fC6FMFK15hZy+Ym59y6lmMt29K/YvFetPUeS/cMhn8Tw+V9HgzvRV8YiO/vcH0v+kpP32O9DwNH5HsxEP/NDieh92I1sLo71ykJh4iIiIiISJwoAJP+9JP+boDspvdiYND7MHDovRg49F4MDHofBg69FwNHj94LzQGTuDCzYkJjltVFPjTpPR4e9D4PbXp/hz69x0OL3s/BST1gEi/leN8SlPdvM6QPlaP3eDgoR+/zUFaO3t+hrhy9x0NJOXo/Bx31gImIiIiIiMSJesBERERERETiRAGYiIiIiIhInCgAExERERERiRMFYCIiIiIiInGiAExERERERCROFICJiIiIiIjEiQIwERERERGROFEAJiIiIiIiEicKwEREREREROJEAZiIiIiIiEicKAATERERERGJEwVgIiIiIiIicaIATEREREREJE4UgImIiIiIiMSJAjAREREREZE4UQAmIiIiIiISJwrARERERERE4kQBmIiIiIiISJwoABMREREREYkTBWAiIiIiIiJxogBMREREREQkThSAiYiIiIiIxIkCMBERERERkThRACYiIiIiIhInCsBERERERETiRAGYiIiIiIhInCgAExERERERiRMFYCIiIiIiInGiAExERERERCROFICJiIiIiIjEiQIwERERERGROFEAJiIiIiIiEicKwEREREREROJEAZiIiIiIiEicKAATERERERGJEwVgIiIiIiIicaIATEREREREJE4UgImIiIiIiMSJAjAREREREZE4UQAmIiIiIiISJwrARERERERE4kQBmIiIiIiISJwoABMREREREYkTBWAiIiIiIiJxogBMREREREQkThSAiYiIiIiIxIkCMBERERERkThRACYiIiIiIhInCsBERERERETiRAGYiIiIiIhInCgAExERERERiRMFYCIiIiIiInGiAExERERERCROFICJiIiIiIjEiQIwERERERGROFEAJiIiIiIiEicKwEREREREROJEAZiIiIiIiEicKAATERERERGJEwVgIiIiIiIicaIATEREREREJE4UgImIiIiIiMSJAjAREREREZE4UQAmIiIiIiISJwrARERERERE4kQBmIiIiIiISJwoABMREREREYkTBWAiIiIiIiJxogBMREREREQkThSAiYiIiIiIxIkCMBERERERkThRACYiIiIiIhInCsBERERERETiRAGYiIiIiIhInCgAExERERERiRMFYCIiIiIiInGiAExERAYsM1toZi8O9zbEg5k9YWaX9+L6YjNzZlYcw2aJiAw5Cf3dABERiQ8zq47YTQL8QF3Esb2ccxtieL8XgYOBxojDP3DO/SlW95DYcc6d2N9tEBEZDhSAiYgME865jJZtM1sIHOmcO7KPb3u9c25hX1VuZonOuaa+qn84MLMEIOCcc/3dFhGR4UBDEEVEBDMbZ2YPmtl2M9tiZrebWW7E+RfN7Hdm9oiZVZnZSjP7Uh+048uhuqvM7CEgN+p8SzseMLNy4GdmNtrMHgu1vdLM3jKzoyOuedDMronYf8vMNkTsf9PM/tuNNuSZ2R2hn9P2UP1FoXN7m1m9maWG9j8VGpZ3XmjfzGybmR0X8XpuMLN7Q23faGZf7eRn5MzsUjNbHGrjG2a2b1SZr5jZEjOrMLMPzez0iHNHhuo43cxWAbVAeqgtCyPKzTKzp81sp5mtN7Nfm1lKxPnJZvZcqN3LgKOj2jDHzF4ys3IzKwu1d3pHr01EZDhQACYiMsyZmR94DKgCJgNzgPHAXVFFLwD+gheQXArcYWYLOqn+4tCH7+Vm9nMzy2ivoJkdDNwWqjsXuB24sI2i54XakQdchTeU8jZgIpAP/At42MzyQ+WfAVoCnjxgOuCPCAaOA57uRhvuAcYC++D9vGqBf5uZ3zn3AVAGHB5R98qW++P9bLOAVyLqOxe4FcgBvgv8ycwmtvdzCvkGcFbo9T4BPGFmmaHXcA5wTejnlAtcBNxiZodG1fF54IBQe2oiT5hZFvAs8FbotR4BHAv8MnTeDzwKrAVGh85F/5z+BDwXauNI4HygvJPXJSIy5CkAExGRA4C9gG8756qcczuA7wAnm1lhRLlHnXOPOeeanXOPAY/gfchvz+XANGAE8AW8D+m3d1D+XOCRqHs82ka5h51zTznngs65WufcJufcw865Gudco3PuOsAB80PlnwHmm1lOqA2vAE8Bx4eG3x0VKtNpG8xsNHAi8B3nXKlzrgq4GC+warnfs8Dxoe3jQz+HY83MQvuvOOfqI17P/c65F0Ov5594QUqrHq02/NY5t8w514AXbAWBk0LnLgOudc4tDtX5KnAvcE5UHT90zu1yztW3MfzwU6Hnq0Ln1wFXAheEXseBeO/td0I/982hdkRqxAvkJ4R+lu8557Z18rpERIY8BWAiIjIOKHXOVUYcWxV6Hh9xbG3UdWtD17bJOfda6AN+0Dn3Pl6v0udahue1oaide0RrdSxiSOC60HC4crxenVGhdqwGNuANkTsOL9hq6RVr6cF7s4ttaHm9ayJeZwWwg/DP6hngODMbCxQADwG7gHkR94+0JWq/Gshs43W32SbnXBBYH9G2qcBNoaF/5aGfx5eBMR28rmjjgPXOuUDEsVVAKl5vVhHe70xVB/WdgxcIPx8aWvlbM0vv5HWJiAx5CsBERGQjkN8yhC1kcug5MiticdR1xcCmbtwnGHq2ds5vauce7dXT4ud4ww8PAbLxht1VRt3nGbzep5bhhs/gDRP8FPCCc665i23YGHrePUQwNFwvn/DP6llgNvAV4LlQgPQ08BngUPYMwHpid5vMzIcX/LW8FyXAV51zORGPDOfcJyMrCLWrPRuBCaG6W0zGy5q5I3Sv/KghpcUR2zjn1jvnLnTOTcDrZTwe+EE3XqOIyJCkAExERN4CluH1mmSE5k7dADzmnCuJKHeymZ1oZn4zOxE4FbizrQrNrCBUNj2UeGIv4Ebg38652nbacRdwatQ9Tu5C+7PxAoMyIAW4Doiea/YMcDrgd8595JwrBVbjzaWKDIg6bINzbivwJHCDmbUEIL8HPsT7OeKc2wJ8BPyQ0Nyy0PMlePPslnThNXXmUjObbmZJeEMDE4D/hM7dCFxtZvubmc/Mks1svpnt1436H8MLYH8Sun4CcC1wR2i44ht4PWK/MbM0MxsD/F9kBWZ2jpkVhYYsVgLNQAARkWFOAZiIyDAX6v05Ca/naC3wAd6wuK9EFb0dL6FDOV7QcaFz7n/tVJsC/CRUTxXwb+BF4OwO2vFqqP7fh+7xVbyEGJ35P7wgbAfwMbCNPXvmnsMb1hcZbD0dum73sS624azQPT7A+3llAidHDdd7JlR3SwD2ApAGPBujdO9/xpvXtQvvvftkyxBS59xNePOxbgmd3wz8Cujy8L9QXccBBwFb8ebNvQh8P3S+GS8wnYrX4/YccEdUNUfhDe2sxgs6/xdqh4jIsGZa9kNERDpj3qLKL/blml7SNWbmgKOccy/2d1tERKT71AMmIiIiIiISJwrARERERERE4kRDEEVEREREROJEPWAiIiIiIiJxktDfDRiIzCwZmI+X+Ukpc0VEREREpC1+YDTwlnOuoSsXKABr23y8lLsiIiIiIiKdOQx4tSsFFYC1bSvAK6+8QlFRUX+3RTpx5y1/p6Awv7+bISIypG0rKeXci85gx3vLSMxIjVm9TdV1jJw7c4/jy59+m7Sc6PW02+cL1jFy+vgOywSbGkkdNbrbbRwunvvH8+Tk5/R3M0Q6VV5azjGnH93fzQBg06ZNHHbYYRCKH7pCAVjbAgBFRUUUFxf3c1OkMyPy8hk1sqC/myEiMqQ1N0JxcTGp2ytJzEyLWb1NVbUUtPF/bVXBZtLzsrpcjy9YQ+H4TgKwxgbSRuuL1fYU5BeQV5DX380Q6VQyyQPxM3qXpy0pCYeIiIiIiEicKAATERERERGJEwVgIiIiIiIicaI5YD3gnGPXrl00NHQp06T0UnJyMnl5eZhZfzdFRERERKRXFID1QFVVFWbG6NGjFRT0MeccZWVlVFVVkZXV9cnYIiIiIiIDkYYg9kBtbS1ZWVkKvuLAzMjKyqK2tra/myIiIjJk7app7O8miAwbCsB6IBgM4vf7+7sZw4bf7ycYDPZ3M0RERIakZVsr2e+6Z9hQ398tERkeBlQAZmYXm9liM2s0s0WdlP2Gma02s0oze9/MPhV1/jozKzWzcjO72cwSY9zWWFYnHdDPWkREpO8s21qJc1CiTjCRuBhQARiwBbgWuL2jQmZ2APAr4AwgG1gI3G9mI0LnLwBOB/YHpgBzgSv7qtHDRV1dHZ/+9KfJzs7m5JNP7rS8mbF8+XIAvva1r3H11Vf3dRNFRESkmzaV1QFQ0eVlZEWkNwZUEg7n3EMAZrY/0NFS9ROBD51zb4b2HzKzBmASsBM4F7jBObcuVN81wK3AkI8AjjzySF5//XUSEhJITk5m/vz53HTTTUyfPr1b9SxcuJDly5fzj3/8Y/exBx54gE2bNlFaWkpiYvc6FP/85z93q7yIiIjEx6Yyb551eXM/N0RkmBhoPWBd9QTgN7ODzcxvZl8EqoClofOzgSUR5d8DiswsO7oiM8sxs+LIBx0HfwPejTfeSHV1NevXryc3N5dzzjmnW9c3N7f9F3j9+vVMmzat28GXiIiIDFy7e8AUgInExWANwKqBB4EXgQbgNuBc51xd6HwGUBFRvjz0nNlGXZcCa6Mer8S6wf0hIyODs846iw8++IAVK1Zw7LHHkpuby/Tp01m0aNHucgsXLuTUU0/lK1/5CtnZ2fz617/m+uuv58EHHyQjI4Pp06dzxRVXcM011+w+9qc//QnnHL/4xS+YOHEi+fn5fPazn6WkpKTNtpxzzjn86Ec/2r2/aNEipk+fTm5uLsceeywrVqzo6x+HiIiItKElAFMPmEh8DKghiN1wQeixN7ASOBa4z8z2Dw07rAYiF41q6fmqaqOuG4FFUceKGAJBWGVlJXfffTd77703J510EmeddRaPP/447733HieccAITJ07kiCOOAOA///kPf//731m0aBENDQ3U19fvMQQxMTGx1bFFixZxyy238NRTTzFu3Di+/e1vc+aZZ/L888932K4XX3yRyy67jCeffJK5c+fy85//nJNPPpmlS5eqd01ERCSOAkHHlnLNAROJp8EagO0DPOac+zi0/7SZrQMOBdbhDUWcA7wWOj8X2OScqyCKc66ccA8Z0L2sez959EM+2lLZnbb3yF5jsrj65FldKnvZZZfx4x//mNTUVBYsWMAvf/lLPvvZz3LFFVfg9/s54IADOO+887j77rt3B2Dz58/n85//PACpqaldus8999zDpZdeyrRp0wD49a9/TV5eHps2baKoqP1RnPfccw/nnHMOBxxwAABXXHEFf/zjH3njjTc49NBDu3RvERER6b2Synqag4689CTKaxoJOodP2YdF+tSAGoJoZglmlgL48eZ4pbSTPv4N4EQzm2yeo4G9gA9C5xcB3zGzCWaWD/wfcEccXsKAcMMNN1BWVsaWLVt4+OGH2bJlC0VFRa3WLisuLmbz5s2798eNG9ft+2zevJkJEybs3s/OziY3N7dVvV25zu/3M27cuE6vExERkdjatMtLwLHv+FyCQFWT698GiQwDA60H7EpaZyo8C7gLOMfMqoETnXOvAPcAk4HngTxgM3Cxc64l8cZtQDGwGEgE/g5c1xcN7mqvVH8aO3YsmzZtIhAI7A7C1q1bx9ixY3eXie7160ov4NixY1m/fv3u/crKSsrKylrV25XrgsEgGzdu7PQ6ERER2VMw6HhiaQkHTR5BXnpSt65tmf+1f3Euzy7bRlljkOykAfX9vMiQM6D+hTnnFjrnLOpxTuhcRij4wnkWOucmOOcynXMznHN3RNTjnHNXOOfynXPZzrmvOeea+ull9bsFCxaQk5PDz372MxobG3n77be58847Oeuss9q9pqCggHXr1hEMBtst86UvfYmbbrqJlStXUldXx/e//30OO+ywDocftlx311138fbbb9PY2Mj1119PVlYWCxYs6PFrFBERGY7qGgNc/Pd3+Oa97/CLJ5Z3+/qWAGzeuBwAyhrb/39fRGJjQAVg0jcSExN59NFHef755xk1ahRnnnkmv/zlLznyyCPbvea0004jISGBESNGMGtW2718Z599Nueffz7HHXccRUVFbNu2jXvvvbfT9hx11FH88pe/5Mwzz2TUqFE8//zzPProo0rAISIi0g3bKuv54q3/44mlJUzKT+fxD7ZS39S9TBqbymopyEpm/Ig0AHYpABPpcwNtCKL00osvvtjm8RkzZrSbnXDhwoV7HBsxYgSvvvpqh+V8Ph+XX345l19+eZv1OhceRx6Z9h7g/PPP5/zzz2/zOhEREenY0s0VXHDX21TWN3Hrl/cnLcnPl257g2eXbeOkfcZ0uZ6NZbWMy00jPyMZQz1gIvGgHjARERGRQeSpD0s47c//w2fwwNcO5ri9Cjhw0ggKs1J4+J3uJbTaVFZHUW4qiX4fmX4oa1QSDpG+pgBMREREZBBwznHzi6v52j2LmVaYySMXH8JeY7xlT/0+4zPzxvDSih088cFW/vD8Skoq6jusrzkQZGtFPUW53vDD7AT1gInEg4YgioiIiAxwDc0BLn9oKQ++s4mT9hnNr0+bQ0qiv1WZz84r4paX1vD1v70DQGV9M5d/cma7da7bWUsg6CjK9db/zPYrABOJB/WAiYiIiAxwX7/nHR58ZxOXHDOV358xb4/gC2B6YSZ/Pmtf/nreARwwMY8XP97eZl1NgSB3vLqWz/7pvyT4jHnjcwH1gInEi3rARERERAawzeV1PL98O98+ZirfOW5ah2VPmD0agI9Lqvjp48vYXF7H2JzU3edfWrGDax79kNU7ajhsaj5XnbQXUwsyAchJgMomR1PQkejrfD1QEekZ9YD1UGSGP+lb+lmLiMhw9vxyryfr03O6nt3wyOkjAXb3gq0treH8RW9x9h1v0hx03PaV/fnreQfsDr7AC8AAytULJtKn1APWA4mJiVRXV5ORkYGZviHqS845qqurtUaYiIgMWy8s3864vFQmj0zv8jVTRmUwNieVFz/ewYzCTM74yxsk+X38+MQZnHNIMckJew5hbAnAttUHGZmy53kRiQ0FYD2Ql5fHrl27qKqq6u+mDAuJiYnk5eX1dzNERETirr4pwGurS/ni/uO69aWvmXHk9JE8/O5m3t1QzpjsFO676CAKslLavWZiCiQaLN7VyOwcffEp0lcUgPWA3+9n5MiR/d0MERERGeL+t2Yn9U1BjpoxqtvXHjl9FH97YwM+M/7x1QUdBl8AKT6Yk5vImzsb+fLENHwa5SPSJzQHTERERGSAemH5dlIT/Rw4aUS3rz10Sj6HTsnnD2fOY8qozM4vABbkJ1HW6FhZ1dzt+4lI16gHTERERGQAqm5o5omlJRwyZUSbaec7k5rk554LFnTrmnm5SSRaDW+UNjI9S8MQ460p6GgIODIS1UcylOndFRERERkg7vzvWv72xnqcc/ziieWUVjfw9SOnxO3+aQnGPqFhiEFlIY67e9bW8oN3K2gI6Gc/lKkHTERERGQAWLq5gp88+hEAT3+4jZdW7OC8Qyay34TcuLZjwYgkFu9qYm11gMmZ+qgYL8453i1rorzJ8eK2Bj4xpuM5e/HSFHS8sr2BA/OTSUvQvMBYUA+YiIiISD9zznH948vITUvkG0dO5qUVOxifl8b3PtHxwst9YVYoA+Lyyqa433s421YfpLQhiN/gP5vraQ72fy9YQ8Bxw7Jqbltdy7Ml9f3dnCFDX2uIiIiI9LMXP97Ba6t3cvXJe3HuIRM5asYoRmUmk5YU/49quUk+ClJ8rKhs5lNj4377YWtpuRfwnlmcxt1ra/nvjkaOKEjut/bUNTt+vayK5ZXNpPphRaUSs8SKesBERERE+lFzIMjPnlhG8Yg0vrRgAgDzi/OYMKLrCy/H2vSsBD6uasZpHljcLK1oYkSSjxNGJzMh3c+TW/uvx6m6OcjPPqzk48pmvjktnQNGJLFCvw8xE9MAzMymmtnI0HaamV1tZleaWf+F7yIiIiID2AOLN7FiWzU/OGEGSQkD47vx6ZkJVDY5SuqD/d2UYSHoHB9VNDM7JwEzY8GIJNbXBKhuiu3Pf1NtMw9uqONnH1by7q7GNstUNAb56dIq1tUEuHRGBgePTGZaZgLVzY6tdfp9iIVY92vfC5wP7ACuA44HmoHRwDdjfC8RERGRQa22sZkbnlnBvuNzOHF2YX83Z7dpWS3zwJoZndr9FPgS5pzDOlnUel1NgOpmx6xs7+c+NZT8ZGVVM/PykmLSji21Aa5cUklTEHwGKb6GPere1RDk+g8rKW0I8t2ZGczJ9c63/D6sqGpmTJp+H3or1l+zTAaWhrY/B3waLwg7Jcb3ERERERn0/vLyWrZXNXDFp2Z2+iE9nsak+shMMD6OSsTRHHQsr2hSmvoueqO0kW+9Xc62+kCb5wPOsayiiYc31gEwO5QAZXJmAgbtLojtnCPQjZ9/wDn+vLKaRJ9x437ZHJifxKrq1nU3Bx3XLa1kV0OQH+6VuTv4Ahid6iMjwVihxCwxEeseMAOcmU0CnHNuDYCZZcX4PiIiIiKD2vaqem55eTUnzCpkvwl5/d2cVszMmwdW2czOhgDvlzXxXnkTS8ubqQutUXXIyCQumpJOgm/gBI4DzVs7G9nV6Pjjimqu3jsLvxn1AccH5U0s3tXIO7uaqG52JBqcMDqZnCSvbyTFb4xP97cZgG2rC3DD8mq21wfYKzuRE8ek7A7c2vOfzfWsqg5w8bR0Rqb4mZyRwH93NLKrIUhesnfPVVXNlNQH+ea0dGZmt67PZ8bUzARWtBMQSvfEOgBbAlwBjAeeBjCzsUBljO8jIiIiMqjd+OxKGpuD/PDEGf3dlDZNz0rg7V1NfOvtCgDyknwcmJ/EnNxENtcGuH9DHfUBx3dmZOAbQL13A4VzjmWVTeQn+1hVFeDmFTU0BB3vlzfRFIT0BGNebiL75yWxT24iKf7WP8OpmQm8ur2BoHO7f74fVTRx4/JqHHDIyGTeK2vkt8uruWHfbLKT2h7YtqGmmQc21LFgRBIH5Xu9WlNCQxxXVTdzQLJ37P3yJgyYm9t2MDctK4F3y5qoagqSmTgw5ioOVrEOwL4N/AloBM4OHTsWeCbG9xEREREZtFZtr+K+tzZy1oLxTMzvv2yHHTkoP5m11QEmZviZk5vI2FR/eJjkCEgw+Pv6Oj6saGbvTnpghqPt9UHKGh3nTkpldXUzL29vJD/Zx9EFyeyfl8T0rIQOew+nZibwbEkDm2oDjE9P4LmSehatqaUwxcd3Z2ZSmOpnS20KP3yvgn+sr+WiqRl71NEcdNy8soaMBOPcyWm7378J6X4SDFZXNXPACC8AW1rexJTMBNLbSQQzLRS0rahqZr8YzUsbrmIavjrn3nfOHeqcO9o5tzF07C7n3Dldud7MLjazxWbWaGaLOimbZ2Z3mVmZmVWY2XNR568zs1IzKzezm81MfxlERESkX2yrrGfDztrd+zc9t4q0RD/fPmZqP7aqY3nJPi6ensGnxqZSlJawxxy1T4xJISPBeGFbQz+1cGBbFlo3a2Z2IhdMTufX87K5ab9szp6UzqycxE6HbrYk4lhe2cxda2q4fXUts3MS+ck+WRSGEqOMSfPzyTEpvLS9sc3hig9trGN9TYALJqeTFdFrlegzJqT7WRW6propyOrqAHvntN83MykjAR9e0Ca9E/P+w1D6+Xlmdnjko4uXbwGuBW7vQtmHgApgIpAH/DCiDRcApwP7A1OAucCVXX8VIiIiIrHzf48s5at3v717f/G6XRw9cxQjMgbvSj1JPuPQkUm8vbORyhinSx8KllU0kZlgjE31keAzxqT5u5VopSDFS4Tyt7W1PLW1gU+OSeH7MzNIi+qhOqUolZxE4771ta2Or6pq5t+b6jl8VBL7jdizx2pyZgJrqpsJOseHFc046LAnM9lvjEv3s7paAVhvxXodsE/jBVGLgRcjHi905Xrn3EPOuUeAnZ3c51i8wOs7zrly51zAOfd2RJFzgRucc+ucc6XANcB53XoxIiIiIjGyYVctK7ZVUd8UoKKuiS0V9UwvzOzvZvXaUQXJNDt4dXvba0oNZ8srm5mRvWfPYVeZGTOzEwgCF05J56yJaW3OtUtNME4Yk8JHFc1sqfWyLTYGvKyHuUk+vjIxrc36p2Qk0BCETbUBPihvItVvTM7oeHbSpIwEVlcFtCBzL8W6B+xXeOt/ZTrnfBGPWC8YcBCwHLjTzHaa2XtmdnLE+dl4CUFavAcUmVl2dEVmlmNmxZEPoCjG7RUREZFhbGtFPUEHH5dUsXJbFQAzhkAANi49gSmZfl7YVq8P5XiJN8oag2ytC7CjIciMrN7NgDlvcjq/3jebowo67ik9fFQyfoPnQ8NB/7G+li11Qb46NX2PHrMWk0NDHO9eW8tbOxvZK7vjOWkAUzL81Aa0QHdvxToJx2jn3K9jXGdbxuGtL/Z1vIWfjwYeMrO5zrmVQAbe8MQW5aHnzKjjAJcCV/dlY0VERGT4qm1spqLOWz9p2dZKmoNeoDKtYPAHYOAl67h7bS1ljY685OGdDfHNnU3c9HH17v2ZWb37qJ2V6KMrMVxOko/98hJ5eXsDo1N9PLm1gU+MTu5wSGFhio8ZWQlsrg2Q4jeO7CTIg3DQtrpKC3T3RqwDsFfNbB/n3PsxrjdaLbDJOffn0P5TZvYyXlC2EqgGItcea+n5qmqjrhuBRVHHioBXYtVYERERGb62VtTv3l62tRIHZCQnMDYntf8aFUNFad4H8ZL6wO41pYarjyubSPJ587ISfV62wXg5pjCFN3dWcfvqWvbOSeBLxW0PPWxhZly1d/eW6h2b5ifZB6urmzl01OCdv9jfYh6AAY+Y2S3A1sgTzrm/xvA+7wOf7eD8UmAO8Fpofy5ewBbd+4VzrpxwDxnAgFqJXkRERAa3klAAluT3sWxrFRhMK8gYMp83ClO8oGtrnbcw8FDinDfcrjDF16X3a0NtgHFpfk4ZF//gelZ2AmNTfYBxyfSMPlkg22/GxIyEHiXiaAw4lpQ3Mb+NhCDDTay/prgQMOBrwE8iHgu7crGZJZhZCuAH/GaW0k76+IeBdDO7wMz8ZnYMcCjwVOj8IuA7ZjbBzPKB/wPu6PnLEhEREemZLeV1ABw4eQTLtlayYlsV0wu71/MwkI1I9pFoUFI39OYFPbq5nu++U8HSis4DDuccG2q8Nbv6g8+Mhftkcf3crHbnfcXC5IwE1lcHdg+l7aoXtzfw2+XVrFMWxdgFYGbmA04CpjnnJkY9JnWxmiuBOuBHwFmh7b+E6q82s8MAnHNlwMnAN4FKvGGEpzvnVoXquQ24Hy8b42rgA7zkICIiIiJx1dIDdtT0kVQ1NFNe2zQkEnC08JlRmOqnpD7Q302Jqf/uaOAf673geXlFU6fldzU6qptdXIcdRktP8JHYBz1fkSZn+mlydLsXrGXNsTUKwGI6BNEBb+ElwOhZBc4tpJ3eMudcRtT+a8C8dso64IrQQ0RERKTfbK2sZ0R6EnPG5ew+NlQScLQoTPGxuW7oBGA76gP8eWUNM7MSqAwtUtyZDTVeYDE+bWgnp5iZlUia3/jVR9V8dWo6B3RxSGFL4LWmOsDRfdnAQSBmPWChoGc1UBCrOkVEREQGu63ldRRmpzCjMJOWaURDYQ2wSIWpfrbVBwkOkVT0SyuaCTgvDfy0rERWVzd3mmZ/Q2gNrvH92AMWD9lJPn46N4vCVB83Lq9mSVnna8DVNju2hoaoqgcs9nPAfgv83cyODK2pNb7lEeP7iIiIiPS77ZX1vLl2V4dltlbUMzo7lbSkBIpHpDMyM5m89KGViGB0qp+Agx0NA3MeWMA5/r6udncvVWdWVjaRkWCMSfUxOcNPTbNjWydrX62vCTAy2den868GioIUP1fvnUVukvHkloZOy6+tbsbhZYXcWBugsZvzx4aaWP+G3AYcDjyP1xu2FlgXehYREREZUv7yyhpOv/V/vLOhrN0yJZX1jM5OAeC0/Yv44v7j4tW8uClM9T5SlgzQYYhPb23g0c31vLqj894agI+rmpmWmYCZhde+6qTnZmNN85Dv/YqU6DOOLkhhSXnTHu97WWOQhzbW8YsPqyhvDO7u9Tq2MJmAgw013f89eWhjHZe8Xc7L2xsY7PFbrNO0TIxxfSIiIiIDVnltE0EH37t/CY9/+zBSElt/AK9rDFBe20RhKAD7xpFT+qOZfW50SmgtsLogc3L7uTFRdjYEuX99LQDbuhAgVjYF2VoX5IjQOldFaX6SfN7iw4eMbHvtq8aAY0tdsMvzoYaKowuTeWRTHc+WNPCl4lQ+qmjm2ZIG3t7VSMB5qdH/tamOssYgo1J8zMn1kpuvrW5mSmbXw5Dq5iD/2VSHA/68soZxyXB8U2CPf2+DRUwDMOfc+ljWJyIiIjKQ1TQ2k5roZ82OGn791MdcedJerc5vrfCy6I3JSemP5sVNVqKR6je2DrBMiM45/rq2hgDe8LfOhhECrAxl65sWChDCa1+1/9o21QZCQ+z6JwV9f8lN8jE/L4kXtjXwXlkjW+qCpCcYnxidwjGFyTy6qZ7nShpI9RuzchIZkeQjK9G6PQ/s2a0N1Afh+jlZbKkL8PH2mkEbfEGMAzAz+0p752K8ELOIiIhIv6tuCDCtIIO9i7K5/b9r+cTsQuYX5+0+35KCvjAr/gvzxpOZMTrVx9YBNgTxpe2NvLWzidMnpFLRGOT5bQ045zpcVHlFZTN+g0kZ4Y/JkzMSeGZrPc1Bt8cCx0Hn+NemOgyYmDF4g4KeOmFMMm/sbCTV7+NrU9M5cEQSSX7vZ3TquBRe2dFAVbNjcoYfCwWza7qQVbJFY9Dx5NZ65uQkUpyRQHFGAjOCNX31cuIi1mH6T6L2R4XusRlQACYiIiJDSk1DM+nJCfz4xJm8tGIH379/CY9fchhpSd5HrC2hAKxlDthQVpjiZ3llE2/vbCQr0ZiWldiv7dlQ08yda2qYnZ3ASWNTeLakgYYglDc5cpOMxoDD7/N6uCKtrGpmYrp/dxABMDnDz+POS7QxOWLonHOOO9fU8tauJr48MY2RKcMvAJuWlchtC3JJTdgzqB2Z4ufogmSeKWnYHdBOSvfzflkT33izjNqAIz/Zx6gUPwUp3vOoFB/F6X5GJHs/y1e3N1DZ5Dhp7ND5NxTrIYit5oCZWQLwM2BlLO8jIiIiMhDUNDSTl55GenICv/r8HE6/9XV++eTHLPz0LABKQkMQC4dBADYu3c9rpY3csLwagAsnp3FUYf+87qBz/P7jGtL9xjenZeAzoyDFSxSyrS5Aog8uebuchgDkJfvIj3isrm7m2MLWc71m5STiN3ittKFVAPbwRm+I3cljUzhxzNB/j9vTVvDV4rQJqRSm+pme5f3cDh6ZzMbaABkJPlL9UNoYZHt9kI8rm2jpQE3xwR/ne0Hd/0obGZvqY6/soTO8s09fiXOu2cyuApYBt/blvURERETirbqhmYxk7+PUgZNGcM7BxSx6bR2fmFXIQZNHsLm8jrz0pEE9X6WrThidwuSMBNISjPs31HHb6lqS/cbB7SSu6EsrKpvZXBfgG1PTyU7yAq+ClkQh9UFqAo66ABwxKomAg9KGIMsqmtnVGMQB++S07r3LSvSxX14ir25v5IwJaST4jOdK6nlgYx2HjUzi9AlDe4hpb2Qk+FoFp2PT/Fw2c8918JxzVDU7lpQ1cfPKGpaUNzInJ4nllc2cOCalw2Gjg008QslsYIDlwxERERHpPW8IYji4+sEJ03nx4+18/4ElfPf4aTyweBOHTx3Zjy2Mn2S/MTsUuFw6PYNffFTFzStrSPYb++XFNzvga6WNJPtg/4ishPnJPnzA9voAW+vAb3DupPRWQw2bg47agCMrcc+Vmo4sSObNnU28s6sJM7hjdS1zchO5cEr6kAoO+ouZkZVoHDIyib+tq+WtnU34zQg4mJfbv8NZYy3WSTiuijqUDpwCPBnL+4iIiIgMBDUNAdKTwx+n0pIS+PVpczjtlv/xnfuWMG98Dr89fW7/NbCfJPuN783M5PoPK/nd8mq+v1fm7uCsrzUHHW+UNrJvXhIpEcFVgs8YmeKjpD5IWWNwj3leLWWyfG0HU/vkJJKXZDy4sY6S+gCTMvxcMj1jj6Qc0js+8wL210sb8Buk+Y2p3UhZPxjEeiHmo6IeM4G/ARfE+D4iIiIi/aqxOUhjIEhGUusPh/sX5/GDT8zgE7MK+Ot5B5CVMrS+ve+qtATjR3tlUpjq5zfLqlhR2RSX+35Y0URVs+Og/D173QpS/GyuDbCmqrnbSUJ8Zhw+ypu/lJ/s4/t7ZbYK8CR29s9LpC4A/93RyN45iUMuyI11Eo6jYlmfiIiIyEBV2+itZRTZA9bi60dOjndzBqSMRB8/npXJNR9U8suPqrlydibFGX3bm/HajkbS/LZ70d9IBSk+3i/3AsGWpBDd8YnRKVQ2OT5TlNLmMEWJjdk5iaT6oS4A8/KG3hcYMf3NMbPX2zn+aizvIyIiItLfqhtaArChn2CjN3KSfFw+O5O0BONnH1axubbv1gprDDje3tXIASMSSWyj16QgIk38tB4Ma8tO8nHBlPRhmW4+nhJ9xtxcrwdzTpyGrsZTrEP3We0cnxnj+4iIiIj0q5oGL5BoqwdMWstP9vPjWZn4DH72YSXb6/smCHuvzEtlflA7mRcLUlsyIvp2Z0eUgekLE1L59vT0Ifk+xeQvhpl9JbTpN7MvA5FfOUwHdsbiPiIiIiIDRbgHTAFYV4xO9XP5rEyuXVrF7z6u5ro52TG/x2ulDWQnGrPaWTOqMNRz1ZPhhxJfBSn+Vj2WQ0msfvt+EnpOBq6JOB4ESoBvxeg+IiIiIgNCTSgAy1AA1mXj0hM4fnQyD2+spzHg9shC2Bu1zY53dzVxdGEyvnbSwhek+JiS4W8zQYdIvMTkL4ZzbiKAmT3unPtkLOoUERERGchaArD0JAVg3VGUloADttQFYpqQ4+1djTQ5OgyuEnzGNX3Q8ybSHTEdVNkSfJlndCzrFhERERlIqtUD1iNFad7Hz00xTsbxvx2NjEz2Dbk1o2ToiXUWxFQzuxWoA1aFjn3GzK6I5X1ERERE+luNsiD2SGGKH7/BprrYBWCVTUE+KG/ioPwkrJ3hhyIDRazTivwamAAcAbSstvcOcEaM7yMiIiLSr2oalQWxJxJ8RmFoQeSeeHRTHa/taGh17I3SRoLAwSM1t0sGvlj/xfg0MMc5t8vMggDOuY1mNjbG9xERERHpVzUNzST4jOSEoZcmu6+NTfOxvqZnAdhTW+vJS/ZxcESq+f+VNjI21ce4NPVGysAX678YiUBl5AEzS8UbkigiIiIyZNQ0NJOenKAhbz1QlOZne32QxoDr1nVB56hocmyoCRBw3rU7GwIsr2zmoJHJei9kUIh1APYWcFHUsa8Ar8f4PiIiIiL9qrohQHqSelx6IjITYnfUNDsCDhqDsCU0hPH10kYADlZqeRkkYh2AfR+42sxeAtLN7Engp8CPunKxmV1sZovNrNHMFnXxmoVm5szshKjj15lZqZmVm9nNZpbYzdciIiIi0q6WHjDpvp5mQqxoCu7eXhsawvjajkYmZfgpTFUwLINDrNPQLwdmAo8AtwOvAfOccyu6WMUW4NrQtZ0ys2nA54GtUccvAE4H9gemAHOBK7vYBhEREZFO1TQqAOupnmZCLG8MD1lcW93M9voAa2sCHKjeLxlEYvZXI9TDtB6Y5Jz7bU/qcM49FKprf6CoC5f8GfgucEvU8XOBG5xz60L1XQPcClzdk3aJiIiIRKtuaNYaYD3U00yI5Y1eD1hWorGuJsBbO73hh/NHKACTwSNmfzWcc01m1gTEZfajmX0F2Omce6qNCZezgSUR++8BRWaW7ZyriKonB8iJur4rwZ+IiIgMYzUNzYzKTO68oLSpJ5kQW4YgzslJ5M2djQSCjgnpfgpSNPxQBo9YzwG7AfhVX8+3MrM8YCFwaTtFMoDIQKs89JzZRtlLgbVRj1d630oREREZymoaAhqC2As9yYRY0eRINNgrO5GGIKyqDnCAer9kkIn1X41L8XqPLjCzEmD3TEnn3KQY3ueXwJ+cc5vbOV8NZEXsZ4eeq9ooeyOwKOpYEQrCREREpAM1jRqC2BuRmRCLM7r2cyxvDJKd5GNiRrjHSwGYDDax/quxMMb1tedY4NNm9r3Q/kjgXjP7jXPup8BSYA5eEhDwknBsih5+COCcKyfcQwagNSRERESkU8qC2DuRmRC7GoBVNAXJSTTGpvlJ9MHIZB9jtfiyDDIx/avhnLurN9ebWQJem/yA38xSgIBzrimq6PxQmRZvAT8AHg3tLwK+b2aPAzXA/wF39KZtIiIiIi0amgM0BZx6wHqhJ5kQKxodI1N8+M347LhUCjX3SwahgfZX40paZyo8C7gLOMfMqoETnXOvOOd2RF5kZgGgzDlXHTp0G1AMLAYSgb8D1/Vx20VERGSYqGnwggYtxNxzXiZEX7cyIZY3BZmS6X18/UxRal81TaRPDagAzDm3kHaGMTrnMjq4rjhq3wFXhB4iIiIivbJiWxX/eX8r3zl2KmZGTUMzAGnqAeuVsWn+LmdCDDhHVZMjJ0lTRWRwi3UWRBEREZEh56F3NvO751bywWZvOnl1KADTEMTe6U4mxMomhwOyE/XxVQY3/QaLiIiIdGJrRR0Aj39QArC7B0xJOHqnKM2/OxNiZypCizBnJ+njqwxuMf8NNjO/mR1sZl8M7aeYmVYpFBERkUFra3k9AE8s3YpzLqIHTHPAeqMolMFwUxfmgbUswpyTqCGIMrjFNAAzs4nA+8BThLMOfhL4SyzvIyIiIhJPm8vrSEn0sX5nLR9traS2MZSEQz1gvdKdTIjljd4wRfWAyWAX69/g3wP/AnKAxtCxF4DDY3wfERERkbgIBB3bKus5Ze5YfAZPfFCyuwcsPUkBWG90JxNiSw+Y5oDJYBfr3+AFwNXOuQDgAJxzZUBujO8jIiIiEhel1Q00Bx2zxmZz4KQRPPr+FkoqvCGJSsLRe+PSEtjQhUyIFY1BUnyQ4tcQRBncYh2A1QBpkQfMbCSwM8b3EREREYmLLeVeAo4x2Smcc3Axm8rquOGZFYCGIMbC5Ew/OxqClIeSbLSnvMlp+KEMCbH+LX4CuMnMUgDMzIe3APKjMb6PiIiISFxsCSXgGJ2dyvGzCrn/awcxYUQa+RlJJCUoIOitqaGFlVdWNbd5/q2djfxtbS2rqprJUQAmQ0Csv7b5EfAIsAtIBiqAZcBxMb6PiIiISFy0pKAfk5MCwL7jc3nq0sOprG/qz2YNGRMzEkgwWFHZzPwRSa3OPVdSz+2ra0kwCDhYkJ/UTi0ig0dMAzDnXAVwlJntC0wBSoBXnXMd9ymLiIiIDFBbyutJS/KTnZq4+1hKop+URKWgj4VEnzExI2GPHrDnQ8HXvNxELp2RQYKBmeZ/yeAX6zT0RwI4595xzv3TOfeygi8REREZzLZW1DE6O0Uf/vvQtMwE1lY30xz0Us2/uK2B21bXMicUfCX6TD9/GTJiPZD2UTNbaWY/MrPCGNctIiIiEndbyusYk5Pa380Y0qZmJtDkYF1NgJe3N/CXVTXsk5PId0LBl8hQEusAbDTwC+DTwAYz+7eZfTqUjENERERk0NlSUc/o7JT+bsaQ1pKI4771tdyysobZOQlcNiODJAVfMgTFNDByzlU7525zzh0MzAU+Bm4FNsbyPiIiIiLx0NgcpLS6QT1gfSw32Ud+so8PK5rZKzuBy2ZkkqT1vmSI6svFK9bhZUBcD+zbh/cRERER6RPbKutxDsZkKwDra0cXJLO+JsDXpqaTrOBLhrCYB2BmdhBwPvAFYCtwJ3BKrO8jIiIi0tc2hxZhHp2jIYh97ZRxCnJleIhpAGZmy4DxwEPAyc65l2JZv4iIiEi8OOdYvrUS8BZhFhGJhVj3gP0OuDe0HpiIiIjIoLN+Zw3/fm8L/1qyhVXbq8lMSaAoVwGYiMRGrBdivjmW9YmIiIjEQyDouOf19Tz87mbe21gOwAHFeVx3ymw+ufdoLbosIjHT6wDMzB5zzn0qtP0C4Noq55w7urf3EhEREYmFpkCQl1fs4OgZozAz/vn2Rq7+94fMKMzkRyfO4OQ5YxirzIci0gdi0QP2asT2S7QTgImIiIj0l8ZAkMeW7eLzo8aQ6Pdx31sbufKRpfztggUcMiWfV1eVMjo7hScuOQwzZeATkb7T6wDMOfeziO2Fva1PREREJNb+8d52rn9+I2TkcMYB43l0yRYAXvx4OwdPHsEba3Zy2NSRCr5EpM/FdCFmM9vSzvENsbyPiIiISFc1Bx1/XbwNgHteX09JRT1vrtsFwEsrdrB6RzWl1Y0cOCmvP5spIsNETAMwILObx0VERET61LMry9hU0cDhxZl8uKWSnz6+DOfgjAPGsWJbNQ+9sxmAAyeN6OeWishwEJMAzMyuMrOrgMSW7YjHPcD6LtZzsZktNrNGM1vUQblPmdmrZlZuZiVmdoeZ5USVuc7MSkNlbjazxN68RhERERmY3t5RR0Og7Snozjluf3MrE3KT+dUJE0hP8vPoki3MGpPFuYdMBODO/65jdHYK4/PS4tlsERmmYtUDdlTokRCxfRRwBGDAeV2sZwtwLXB7J+WygeuAMcAMYBRwY8tJM7sAOB3YH5gCzAWu7GIbREREZJBYWdHID97cwT2r69o8v3hzNR+U1HDOfoVkJvs5Zd5YAE6eM4apozIYk51CXVOABRPzNP9LROIiJuuAOeeOAjCzm51zX+9FPQ+F6tkfKOqg3L0Ru7Vmdivwm4hj5wI3OOfWheq7BrgVuLqnbRMREZHYcq7tXqu6xgDBds5F+++2WgD+vaGe7zYFSUls/d3yHW9tJSc1gVNm54Nr5sLDJrFuZw2fnTcWM+OI6SP5+5sbNfxQROImpnPAehN89dLhwIcR+7OBJRH77wFFZpYdfaGZ5ZhZceSDDoI/ERER6b3qxgBnP76BPy4tb3W8rKaRw375AvdvbuhSPa9tqyM7yUdFk+M/y3a2OrdmVx0vrCrnzLmjSA0tpFycn87fLjiQUVkpAJy8zxjSkvwcNm1k71+UiEgXxKQHLJKZnQ8cizcscHdffl8txGxmRwMXAIdEHM4AKiL2y0PPmVHHAS5FPWMiIiJx45xj4X9LWFpaz7Kd9Zy/s4YJI9IBuOm5lZRWN7DE1/lHlO11zayqbOKrM3J4bnMVdy0u4XN75+8eSnjX2yUk+o0vzStot46Dp+Tz4U8+oeGHIhI3sU5Dfw3wc2AbcBDwPrA3rXujYnm/BcB9wBecc5E9YNVAVsR+S89XVRvV3AhMjHocFvPGioiICAB3fbiL5zdUc/bsPBLMuOm5lQCs2l7F3a+vJynBx6rqZgKdDEN8bZs37+vgglQ+X5zCytI6/re+EoCdNU088mEpp8zKZ0R6x3m4FHyJSDzFOg39l4ETnHOXAvWh58/iJcuIKTObBzwKXOicezrq9FJgTsT+XGCTcy669wvnXLlzbl3kA9gU6/aKiIgMdlvK63h/Z9eGBrbnja01/OGdUo4rzuTb++bz+ckZPPLuZu54dS2X/XMJaUl+fvCJ6dQFYUN1U4d1vbatjqL0BMZnJHL06GRGpCVw1+ISAO59bxsNzY5z9i/sVXtFRGIt1gFYvnNuccuOmZlz7hW8IYmdMrMEM0sB/IDfzFLaSh9vZrOBJ4FvO+ceaaOqRcB3zGyCmeUD/wfc0e1XIyIiIrv96qmP+drL23k3lPiiu0pqmvjxS1spzkri6oMLMTO+PC2T1EQ/1/znI9aV1vCTT8/i6BmjAFhW1thuXXXNQd7bWc9Bo1IBSPYbp88dxUtrKli+vZZ7393OUZNzmDQitUdtFRHpK7EOwErMbHRoez1wsJlN78b1VwJ1wI+As0LbfwEws2ozaxka+F1gJHBb6Hi1mVVH1HMbcD+wGFgNfICXtl5ERER66P1N5QQc/PClLeysa+7WtY2BID94cQtNQcevjxpLWihbYW6yn39dfChPXHIY7111PJ/dt4iJ+emk+41l5e33tm2pbabZwczc5N3HzphbQKLf+PpDKyira+a8+er9EpGBJ9YB2N/x1v8CL+37c3hB0D1dudg5t9A5Z1GPc0LnMkK9aTjnznXO+ULHdj8i6nHOuSucc/nOuWzn3Neccx2PYxAREZF2NTljTWkNx4xNpboxyI9f3kJzsGup4gF+9eZ2lpbW85NDCinOTmp1bsqoDGaOzsLn8+ZimRnTMvwsr2i/B6wkFAAWpvp3H8tPT+SkmSPYWtXI3oXp7F+U2Z2XKCISF7FOQ39VyxpdzrmbgaOBz+NlGhQREZFBakdzAs7BCePSufygAt4uqePmd0u7dO2/Vlbw4IoKzp2dx9ETuhYUTcvws7ayibrmYJvnt9UGAChIbZ0t8Zz9C0n0GxcdOEbJNURkQIp5GvpIzrnX+rJ+ERERiY/tAW9K9vScRIoKsnhvex13Lt3F3iNTOHJ8+0HVuopGfvHGNuYXpvH1efldvt+0zASCNLCyspF98lL2OL+trplkn5GT1Pq75Okj03jzW/vuXvdLRGSg6XUAZmZdSm7hnDuvt/cSERGR/rGtOZG89CRGhYb8ff+AUSzbWc9Vr5bwt5OSGZeVtMc1TUHHla9sJTnBuO6w0ST4ut4jNS3Du88HuxraDcAKUv1t9nIp+BKRgSwWQxCtiw8REREZpHY0JzJrTNbugCfZ7+NXR47FZ/D9F7ewpbqJ3y/ewT+Xl+2+5o73d/LRznquOLCQkWnd+843J9HHPnnJPLSuqs1hiCV1AQq7WaeIyEDQ679czrlzY9EQERERGZiag1AaSOTUMVlAOKfVmIxErj1sNJc8t5mTHlwDQFqCccrUbPxm3Le8nCPHZXBscc+SYVw4I4dvvbaNB9ZW8eWp2a3ObatrZnp2Wo9fk4hIf4l1FkQREREZYrY1QBBj9pjsPc4dVpTBDw4YxSlTs/n+AaOobXa8tbWWJTvqKG8IcMKknmcinJWbzKEFqdy3ppLyhsDu43XNQSoagxSkaqihiAw+Me27N7O1QJs5aZ1zk2J5LxEREYmPzXXesMNZY7Jg7Z6ZD0+fmQtAQyDIH97ZwYsbq0lN8JHoMw4Zm7FH+e64YEYO5720lXtWVXLxLO8+2+razoAoIjIYxPov18Ko/bHAhcAtMb6PiIiIxMn6WkiyIMUj0tmxtv1yyX4fB49N56WN1ST7fSwYnUZ6Yu8G24zPSOTEcen8e30Vn5uYyei0hPAaYJoDJiKDUKzXAbsr6nE9cCpwWCzvIyIiIvERcPBBhTExsX73QskdOWJcBqV1ATZXN3Hk+N71frX4yjRvTtmdH5cD3vwvQEMQRWRQisccsCUoAJM+4pwj2OagVxERiYVV1VAbMKYn13ep/GFFGfjNS398xLjYBGAjUxL47MRMnttSy6qKRrbVBUj0QV6yAjARGXz6NAAzs1TgEmB7X95Hhq8L/7qYR6ty+7sZIiJD1rvlRorPUZzYtQAsO9nPQWPTWTA6jRExnKN1xuQsMhJ93PZxOdtqmxmVkoCvjTXAREQGulgn4QiyZxKOKuDsWN5HBKChOcArK3fQ0JzK2poAE9P7u0UiIkNLcxCWVhizsx0J3Yh1fnXkmJi3JSPRx5emZPHnZeVkJBjTsvdc+FlEZDCI9ezVo6L2q4AVzrnqGN9HhKWbK2kILc75zDYfX52050KdIiLScx9XQX3QmJMd9P5H76Jkf98MsDllQiYPra1ie70WYRaRwSvWSTheinq8o+BL+srb63YBsF9KNSuqjXU1/dwgEZEhxDl4qdRHRoJjWs+X8oqpJL9x7nRvLTKloBeRwSrmf73M7DBgf6DVn2vn3DWxvpcMb2+tK2NifjoHB7eyvCmd57b7OH9ix71g62ogPxky9P+2iEiHPqyENTXGZ8cG8Q+gqVbHjk1ne12AY8Zq3LmIDE4x7QEzs58BzwJnAcdFPI6N5X1EnHMsXr+L/SfkkmiOA0c4lldBeWP712yqhT+u9nH3+ngk/xQRGbyag/CfrT5GJTsW5A2sVLN+M748NZsxGoIoIoNUrD+JXggscM7t55w7LOJxeIzvI8NUMOhwzrF6Rw1ltU3ML84D4IA8h8N4s6ztr2kDDu7f7P26r64xVmlgrIhIu97YZZQ2GiePHli9XyIiQ0GsA7AaYGmM6xQBoLE5yJfveINjb3iJe15fD8D+xV4K+hFJMC3D8eYu22NdsPoAPLfd2FxnnD7OkZXgeHqbDzewvtQVERkw3txlFKU6Zmb1d0tERIaeWPff/xq4ysyudk4fbyW2rnvsI/67aid56Uksem0dI9KTmJgfngOwIC/I3Rv8vLTDMIPNdbCpzihtAIexV6Zj3xxHXQAe2eJjVQ1Mjc0aoSIig8L2enhxh3HUKMfI5LbLlNTD5nrjM2OUWVZEpC/EOgB7BG8O2HfMbEfkCefcpBjfS4aAqvomNu6qY68xHX/N+s+3NvLX/63nq4dP4htHTua6x5ZRPCINi1iEc1YWZCQ4HivxOnZzEh1FqbBvjmNsapBpGWAGC/Icz2xzvLHTmJqh7wlEZOgqa4SntxknjXakJ3hfPq2oNt4pd3yiwJvfFT2V6t1yw4djbrb+PoqI9IVYB2D3AZuAG4HaGNctQ4xzjm/e+y4vr9jBAcV5XHrcVA6enL9HuXc3lHHlI0s5dEo+P/jEdBL8Pn592pw9yiX44KJJQaqaYGwqpLfz253og9nZjvfKjeagI0E5OURkiHqv3HirzEddwHFofpAV1cZRI4NsqzceK/HxRImXYn5OtmNWliPFD++UGVMzITOxv1svIjI0xToA2wfId87Vx7heGYIefX8rL6/YwUn7jGbx+jLO/MsbnHNwMT86cQYpiX4AtlfV87V7FlOQnczvz5hHQieLe45O8R6dmZ3leGOXj5XVaI6DiAxZa2u83qyllcaaGh/ZiY7jCxwJ5thcB+9VGEvKjfuqfPjNMT4VypqMEws1/FBEpK/EOgD7EMgDtsS4XhliKuqauObRj9inKJubTp9HUyDIr576mNtfXcvb63fx9wsPJDnBzzfueYeKuiYe+voh5KYnxez+UzIg2ed9KJmZpWE2IjL0BB2sq4X9ch3lTbCy2vh8YZDE0PdYRWlQlOb4VKFjYx28HwrGMhK83jAREekbsQ7A7gEeMrMbgJLIE865l2N8LxmEymsbue+tjdz9+np21TSw6Nz5+H2G3+fn/07aiwMnjeDr9yzmG397h6LcNN5eX8bvz5jX6Ryx7kr0wYxMx4eVxqeaHS+VGsVpyvglIkPH9gaoDRiT0h0zs4IsrTDmt7GmlxmMT4PxoWAs4NDQbBGRPhTrAOym0PM/oo47wB/je8kgsrykkrteW8fD726mvinIgol5XHfKbGaPzW5V7ri9Crj+1L35wYPvA3DREZM4ec6YPmnT7CxYUmH8/GMftQEvmcesLMdnxgTJi11nm4hIv1hb4/1dm5juyEiAA0d03qtlBgla90tEpE/FNABzzvX6OzMzuxg4F9gbuNc5d04HZU8DfgEUAP8FznXObQ6dSwJ+D3wRaAJuds5d1dv2SfesK63hRw+9z+trdpGS6OPUeWP5ykHFzBzdflfTF+aPo7K+idU7qvnBJ2b0WdtmZDmSfI40P5xTHGBdjfHMNuNXH/s4tsBxRL4SdIjI4LW2BjITHCP0hZKIyIAS6x6wWNgCXAt8Akhtr5CZzQTuAE7FC75+CdwLHBEqchVeUpApQAbwrJmtdc7d2XdNl2jX/ucjPtxcyY9PnMEX548jJ61rnwQuOKzvVy1I9cMPpgVJT/CGJE5Kd8zLcfxri48nSny8XeY4dUyQKRng0zfCIjLIrK0xJqZ7vVoiIjJwxDQAM7N2e5icc9d0pQ7n3EOhuvYHijooehbwhHPu2VD5K4HtZjbZObcarxftQudcKVBqZr8BzgMGXQBWWd+EC4L5wG+GzwyfD3xmBJ2jKeBoag7SFAjSFHQ0B4IUZKXsziRY1xggJdHXas2svvLqylJ+9/xKbvjCHCrrmnlu+XYuO24aFx0xuc/v3RM5UfFgbhKcUxxkWaW3Xs6ta72fYaI5ClJgQprjhEJHqgbUisgAVt7oZTM8PF3ZDEVEBppY94AdFbU/BpgIvAp0KQDrhtnAmy07zrkKM1sHzDazXaF7L4ko/x5wfXQlZpYD5EQd7ijwi7uzbnuD9zdVdOuaBJ8xrSCTyvomNpXVkZ+RxIJJIzh+rwKOmVlARrL31jcFgtQ1BahvDFBZ38SHWypZua2a2WOzOWxqPunJXf8Vqapv4vsPLGFrRT0X/nUxY3NSyUhO4OyDirvV9oFgZhZMyQiyuMyoaIL6IGytN17baST74JOjlSFMRAamDbVw30YfhmOKFpsXERlwYj0HLDoAw8wuBfoit1wGEB2VlAOZoXNEnW85F+1S4OrYNi22LjxsEjuqGgg6R9A5AkG87aDD5zOS/D4S/UaC30eS34fPZ6zZUc0HmyuYNDKd0/Ybx/qdNby6qpTH3t9Kkt9HcqKP+qYATYH2/3NOSvBxyOQRHLtXAcfMKKAwu+MFtn7z9ApKKuv53vHTuOGZFSzbWsnXj5xMdtrgXM0z0Rc9ad1x5zofb5aZt46O5oeJyADSFISnthkv7TCyEuG84mCX1kUUEZH4isccsD8AG4h9D1g1ewZ22UBV6Byh89VR56LdCCyKOlYEvBKLRsZCrLIABoOOxRvKeOajbTQ2B0lL8pOa6Cc1yXukJfmZXpDFpJHpvLOhjGc/2s6zy7bxwsNLuYKlzCjMJC89iUS/j0S/j6QEI9Hvw4Cy2iZeXrmDsw8q5uKjp5Kdmsidr63j/EMnxqTtA8WBeUE+rPSztNKYm9O9b5brA7C8ypiT7dqck9EYhJJ6GJUMKRriKCKd2NkIOYngNy/hxn0bfZQ2GgfmBfnUaA2VFhEZqOIRgE0Ekvug3qXAnJYdM8sK3Wupc67MzLaEzrcsCj03dE0rzrlyvN6x3eIxV6o/+HzG/OI85hfndVr24Mn5HDw5n/87aSartlfzzLJtvL5mF3WNzdQ0BsJzzgJBgg5y0hI5Ze5Yvnv8NAC+fFAxXx6EQw87Mz0TchMdr+/qfgD2WInxv50+0iYGmBbVF7u9Hhat97G9wfvdG53i2D/Xe6QPxFQ5IhJXtc3wyBbjqFGO0Smwqhr+vMZPdqJjfBosrfCCsYsmBpja1lgPEREZMGKdhOOOqEPpwDHAP7tRR0KoXX7Ab2YpQMA51xRV9B7gDTM7GvgfXubE10MJOMDr1brSzN4KteMy4Gfde0ViZkwtyGRqQSbfOLK/W9P/fOYNS3yixMeWOhjTTp7OiiZYVW2UN8HBIxw1zfDGTi+4+t9OH9MywxPjl1bA3zf6SDA4bWyQqmZYVmU8utXHizsc3wtlahSRoauyCe5c5yMnCebnBpme6fVstXh0q/FOuY/yJsfXJwV5bruPzAQvGPuo0vs788lCR7J6vUREBrxYf6yL7jrahhf4/K0bdVxJ6zlZZwF3AeeYWTVwonPuFefcMjM7H7gNKMRL9HFmxHU/AfKB1YTXARt0GRBl4Dkgz/HyDm8+2MVTgmQnet9Or6rxgq6V1caOhvA/hSXljuzQMKF52UHeLfcSe2QmePM1ntvuoyjVcfaEILmhrIzHFjjW1sDNq308UWJ8vkgT6UUGu9pmSPBBUtT80cagF3yV1MOuRvigwk9mgmPfHMf8PEdVM7xV5qMg2bGmxnhmu/d35qTRQY4c6XBOqeZFRAaTWCfhODcGdSwEFrZzLiNq/37g/nbKNgIXhR4iMZOZABdODHLzGh9/Wu0jxQ9b6sBhJPkck9JhQV6QqRmOyib463ofW+qNY0YFmZ/rWFzu48UdxvZ64+Nq44DcIKeOdSRGfSibmA6H5jteKTUW5DnGpXWtfc9v9z6JHT3K+2B2xzofOxu9uvbPdXt8+BORvlXVDM9sM17faST7YUGe46iR3vBi5+AfG41NdXDOBK/na3mVF3C9Umq8VOojwRz5SY6LpwT57UofT2/zkep3HJTnfTGj4EtEZHCJSQBmZrOATzvn9hjiZ2Y/Ah5xzi2Pxb1EBoKiNG+9sHs3+MhOhOMKHFMzgoxPaz1saGwqXDQpyJu7jCNHepPip2U4Xin14TfH58cGozIttnZ8gePdcuMfG32cPi7YaRD2TpnxeImXfnqvLEd1aDhjdqLjoc0+nixxHDTCccgIR1YnySkbgpBk+nAn0lMNAXip1MtK2BT0es9rA/DSDmNrvXHhxCAfV8P7FT5OLAwyK9u7bnY2zM72hiO/W2Z8WGmcUBgk1Q8nFDju3WgcOkLDDUVEBqtY9YB9H/hvO+e2Az/AWwRZZMiYmgFX79X5IqfF6VCcHg6yjisI0hj0cfKYIBM6CahS/p+9+w6T7Kruvf9d1TnH6cl5JM0oJ5QjQSBykEAEk4PAGDDgC6+xTTAX44Tle6+NA8Y4YDA2BhNMsk0QOZkkkSTNSBpNDj3TuSus9491Sl3TU52rq6q7f5/nqWemq06d2tXVdc5Ze6+9dg08a2OODz2Q4k/vqeG8Due63hxbmk8PjA6Mwr/sNTY3OwdH4bMHUgxnob3WefNZOfaOwJcPp/jvQ8aXDhsXdTrbW2Je29YWp7tgUeoTafjjX6RY1wQv2JxTNTWROcg6fOuY8YWDxkDGOK/duXlNjr6kJPyXD8Mn96f46cn4nnbXO9f3nt4R01YL161yrls18diFnU5dKstOFdoQEVmyShWAXUOsp1XMR4G3lOh1RJa8rS3w6h0zB255O9vg/9uZ40uHja8eMX58oob1Tc41PZ5cjMHxcfib3ZEO+fzNMeL2uYORa/iUdTnqUvG6W1tyHBmDrx4xvn3c+O7xiOJqzXl0n3PDqljf7JP7jLFclLb+f/ekeMnW3CkBmogUl3P4y/tS3DdkbG12XrA5y5aWU7e5usf5xlHngw+kGM0Zz96Ym/W6gimD8zpK324RESmfUgVgfUk599O4+wkzW1Wi1xFZkRpr4HFrnBv7nO8fj0Dsn/em+NR+54oe54f9xkgWbt8WRUGu7XW+esSjamP3qT3rvQ3w1PXOzWucwWykSf3nIeOzB1N877hzSZfzgxMpHrs6x9YW5wN7Uvzfe1K8eMvMKZAiK933+437hoynrMtxTU/xNf9qU/DEtTk+cH8Nqxuci+a4pIWIiCxtpQrAhsxso7s/OPkBM9sIjJTodURWtIYUXNnjXNHt3DMIXz0aKYV1KXj51hwbkgCpsQZeujWHwWnFPR7eVw0PzyF5/mbn5wNZPvZQis8eTLGqIYoE1KZitO5vdkfBkedtznHO5OXPiV7/7/cbh0ZhNAebm2FnW/nXMDs6DvcOGvcOQUsNPH6Nz3pkQWShxrLwH/uNjU0xz3K6+ZPntEcQdkZrdJSIiMjKUarLo68ArwXeWOSxVwNfKtHriAgx/+uMNjijLcex8QiAeictdz7X0aqz2uANZ0b64rbWicBlTSP82o4c79+T4gN7UjxlnXPNpPkq3z5m/OtDKVJESuTXjxqGs7UFzm53zml3VhW079AofPWoUWOxeOw1vX5K8ZLZGs/BD/sj4Lp30Diejp001zjDWePgqPOCLTlVfpRFtX8U9g4bPx+Akxnj+ZuzMwZVZnDDKo18iYisRKUKwP438E0z6yYWSH4IWA88F3gWcGWJXkdEJinl3Ky6FFxdpBhAex28cntUffz4vhRjuRyP6ovtBjLw6QPGthbn9m0xt+2hEbjrZFRv+9T+FJ/aD30NUZmxtRY+dyCuTlMGYzmjvS435zQs9yjx/7MBo7nG2d4K17fk2NHqrG6Abx83/nWv8bd7Urx0a25eAZ7IdH4xAJ89mOKB4Yk/rqt6cqfN+RIRESlUkgDM3X9kZo8H/gJ4IeDEosy/AJ7g7j8uxeuISOU0pKIi4oceND5zIEVPfY5z251P7DPGc3DL+tzDvf4bm2Fjs/O4Nc6xcbg7Cca+ctjIYZzZ6ty2MUdrLfzhz2O9o7kGYN/vN342YDxhTY7rV52exnV5t2PAR/am+K9Dxk2rNdogpTOUiQ6Allp48tocu9qdzrqpU35FRETySjZDw92/BOw0sx1AH3DI3e8p1f5FpPJSBs/c4Bwfdz70oFFrxljOeHTfRIntybrrI8Xwml5nJAuHx2BDEw8HTNf0Oh/bl+L+Idg8y5GDgQz8+74ouV8s+Mq7rNu5dzDHFw4aaxpjZKynnhnnhe0dhqYa6GmYfjtZuf7zUFQKffWWHGum+NsXEREppuRT5JOgS4GXyDJVl4IXbcnxzw+m6Khzdrbn2DXLNYmaamDTpLlpl3Y5nzng3HnE2Nwy8yjVXSfhYw+lGMvBMzfkZpxr87T1zv3Dxt/fHxVH1jY6r90xddnvbx+L1MUag1s3OBd3aeRspXpgGH4xYLTVQntdLF7eVhuLlH/9qHFZtyv4EhGROStzjTIRWQ5aauHFW2e/ltl0GmoiXfArRwzuh/M7nZ1tnFY4o38c/n1fih+fNFY3OM/blmP1LC5+G2uiiMh9Q3B0POakfeGQcfOaicBqLAu7h+EnJ4xvHktxZquTdvinB1PsH83xhLUKwlaa0Sx8YE+Kk5niEX59ynms0lpFRGQeFICJSMU9erUzloMfnzB+cCJFnTm72p3zO6J4x/f7jW8cNbION6/JcX3v3MrLt9TmF691Dozm+OIho7cejozDPYPGg8OQw6gx54ruHE9bHxfWH3vI+OLhFC21OVWsW2E+d9AYyMCvbs/SWQcn03AyAyfTxskMbGqOETEREZG5UgAmIhXXVAO3bHCett65bwh+1G/8+KTxoxNJtUScczrgiWtyC56X9eS1zs8HYiHrFM7G5igHvqM1x+aWKDaS9/T1znA2x6f2pxhI57i4y+mqi/L3aU/+zUHGY15bY83C2ibV4cFh+OoR48qeWEoBoOvhaqMKxEVEZGEUgIlI1agxOKMVzmh1nubO7iE4PGac3V660YbmWnjlthzH0rClefqgKWXwnI1Oihx3HjG+fGTqYbfGlHNVj3N+h7O2CZW9X0K+cdT4n37j0i5nPAefORDzvgrTVEVEREpFAZiIVKWUwfZW2N5a+ovgvkamrNo4WW0KnrfZGco4d580RnNQb1GMpD4VC0878J1jxhcPG/99OFIoNzTD5mZnc7OzqRnaa2PxXakue4fh4/uMWoP7hiLAPrPVuWVDjiaNaIqIyCJQACYiMgsttfCI7qmDwZ1tzom0s3vIeGAY7h827jxifMnjor7GnPbaWNS6vQ7aa52WWhjJwmAGai1e49pep0Nzi8piLAcffCBFay28/owcB8cirfSsVgXLIiKyeBSAiYiUSEcdXNjpXNgJ4GRysG8UHhw2jqejkMNAxjg4Cr9MG6M5oyHltNbGPLKBdJTBf+aGHOd2VPjNrAAff8g4Mg6v2JajpRa26YwoIiJloNONiMgiqU3FumebmgtHzib+n/VT54odGo0RmQ/cX8MZrc5Nq3MPF4GQ0vr2MeM7x1M8ui/HjtZKt0ZERFYSBWAiIhUyuVBHX2OsWfa1ozGf7M/urWFjk3NNr3NBx9xK78vU9o3Avz1kSZCrQhsiIlJeCsBERKpIbQquX+Vc0eN855jx9aPGhx5M8Yl9cd+V3VER8ocnjPuHolJfg4pFzNpIFv7+/hTNNfCcTTlSmuslIiJlpgBMRKQKNaTgml7n6h7nl4PwtaMp/vuQ8cVDRkcdHE9H5LB/1Hnp1hx1Gh2bkTt85MEUx8bhldtztOkMKCIiFaDTj4hIFTODM9vgzLYcx8bh60eNB4eNx6/NkXX45weNv78/xYu2aDRnJnceiQW+n7RWc+tERKRyFICJiCwR3fXwxLVOYSGP4Qx8Yn+Knw7AOe2Va1u12z0En9pvnNvuXNereV8iIlI5SloREVnCru51uuud/zqUwhVXFHV4DP7xgRTd9fCsjTmt8SUiIhVVdQGYmXWa2UfMbMDMHjKzV02z7dvNbK+ZnTCzb5rZFQWP1ZvZX5pZv5kdNrN3lOcdiIiUT43BjaucB4aNe4Yq3ZrqkXP4n+PG/70nxe//vIbhDDx/c44mFSwREZEKq8YUxP9HtGsdsB34gpn91N2/WLiRmT0TeDlwHXAv8BrgY2a2zt0d+B3gfGAH0Ar8p5ntdve/Ld9bERFZfJd2OV846HzmQApfnWN9E7RU49F9DjI5uG8Idg8ZNQattbHIdeMsAqi9w/DBB1McHjP6GpwnrMlxcZfTUbf47RYREZlJVZ2izawFuBW4yN0HgB+Y2fuBFwNfnLT5VuBOd/9l8ty/Bf4E6AUOAy8CXubuR4AjZvbHyX4UgInIslKXgseucf5lb4q/2h0RSm+9s7nZ2dQMW1qcNY2nrztWbUaz8NkDxv3Dxv5RyLhhOE40/AuHnCetdbY0O621FF0X7cgY/PXuFHUpeP7mLOe2o+IkIiJSVaoqAAPOBMzd7y647wfATUW2/TDwLDPbCdwDvAz4rrsfNrMuYgTth5P2867JOzGzTqBz0t0b5td8EZHKuLzbObc9y74R2DsSQcwvBo3v9Uf0UZ9ytjTDeR3O+R1edSNkY1l43+4UDwzDtla4qsfZ0ZpjeyvUAHtH4N8eSvGPD0xEXU01TlttjI611cb/fzoQ7/cV23KsaqjQmxEREZlGlZ2CaQVOTrqvH2grsu0B4E7gbiAHHAUeXbAfgBOz2M/rgLfOp7EiItWkpRbOaIMz2qJSojscT8P9Q8b9w/CzAeOjD6X4/EHntTtydNZXusVhLAd/syeCr+duynFB5+nbbGmB156R4xcD0J82BjIwmIGBjDGYhodGjMFMjPK9eKuCLxERqV7VFoANApMLKXcAA0W2fStwBbAZ2A88G/isme1K9kOyr/z/p9rPHcAHJt23gQjuRESWLLMoXd9d71zUBe7O/cORovcPD6R45bYctakoWHHXSRjLGRd0eFkXdU7n4G/3pNg9BM/Z6EWDr7wag13tUFiG/9T/x2LLqnIoIiLVrNoCsF8Abma73P2nyX0XAj8psu35wEfc/cHk538wsz8Bznf3r5rZPuACYN90+3H3fmJ07GGms7eILENmMZL0rI05/v7+Gv5yd4pV9c59Q8aR8TjufWKfc2WPc1XP4hetyAdf9w7CbRudi7oWXkdfh28REal2VRWAufuQmf0r8Ltm9iKi0MaLgWcV2fxbwC1m9kHgEHAb0EIEcRCjWr9lZt9J7n898HuL+w5ERKrf+R3whDU5vnHMODpmdNXD49dmaamBO4+k+O9DxpcOx2jYdb3OyQx8/mCKdA52tkWA1rvAFL9MDv7u/hS/GDSeuSHHJSUIvkRERJaCqgrAEr8K/DWRVngSeJu7f9HMNhHzvc529weAPwD6gO8Tc77uA57p7oeS/bydqIh4L5AG3qsS9CIi4cY+58a+04Oe7a05jo7BV48a3z5mfL8/8hF76p3u+rj/RyeMN5yZm1VJ+GIG0vCRvSl+NmDcsj7HZd0KvkREZOWougAsSQm8tcj9DzBRXAN3HwN+LbkV28848IrkJiIis9TTAE9Z59y02vn+caMuBZd0OTUGe4bgz+5N8an9xi0bigdO6RwcGIV9I8ahMTinw9nWEqNe/3XI+PIRI5ODp63LcUWPgi8REVlZqi4AExGR6tBUA1f3nhogbWmB63qdLx9J0duQY2uLM5aNKoT7CoKu/NpdhnPnEeNRfc5PB4y9I8YFHTket8ZVqVBERFYkBWAiIjInj1vj3DPkfGr/qeUSO+ucdY2x1tj6phzrGqG5NtINv3AoRVON84LNWc7rqFDDRUREqoACMBERmZO6FLxmR45j43BoFOprYH0SbBXz/E05fnISNjZRNWuPiYiIVIoCMBERmbMag1UNzCqN0AyNeomIiCTKuNymiIiIiIjIyqYATEREREREpEwUgImIiIiIiJSJAjAREREREZEyUQAmIiIiIiJSJgrAREREREREykRl6IurAdi7d2+l2yGzcPTYEWq1tpCIyKI6euwIe/bs4fC+h6hrbSrZftODI4zsaT/t/ocO7qd5bGDW+0nlRhhrr5t2m1x6nKaxzJzbuFIcPHKQMcYq3QyRGfUf6WfPnj2VbgZwSrxQM9vnmLsvTmuWMDO7Briz0u0QEREREZEl4Vp3/+psNlQAVoSZNQCPAPYD2Qo3Z7nYQAS11wL5roLdwNaKtUgKleKzKPYZy9wshe/ESvmcl8JnsRiq8fNdqZ/FYpnvZ6zPoXoUfhbV+J1dSXYDO4C1wHfcfVZDyEpBLCL55c0qgpXZMbP8f/e6+578ffn/S2WV4rMo9hnL3CyF78RK+ZyXwmexGKrx812pn8Vime9nrM+hehR+FtX4nV1Jks/iXuDeuTxPRThERERERETKRAGYVNLbK90AeZg+i+qgz6F66LOoHvosqoM+h+qhz6J6zOuz0BwwKQsz20KSs6wh8uVJn/HKoM95edPnu/zpM15e9HkuTRoBk3LpJ3oJ+ivbDFlE/egzXgn60ee8nPWjz3e560ef8XLSjz7PJUcjYCIiIiIiImWiETAREREREZEyUQAmIiIiIiJSJgrAREREREREykQBmIiIiIiISJkoABMRERERESkTBWAiIiIiIiJlogBMRERERESkTBSAiYiIiIiIlIkCMBERERERkTJRACYiIiIiIlImCsBERERERETKRAGYiIiIiIhImSgAExERERERKRMFYCIiIiIiImWiAExERERERKRMFICJiIiIiIiUiQIwERERERGRMlEAJiIiIiIiUiYKwERERERERMpEAZiIiIiIiEiZKAATEREREREpEwVgIiIiIiIiZaIATEREREREpEwUgImIiIiIiJSJAjAREREREZEyUQAmIiIiIiJSJgrAREREREREykQBmIiIiIiISJkoABMRERERESkTBWAiIiIiIiJlogBMRERERESkTBSAiYiIiIiIlIkCMBERERERkTJRACYiIiIiIlImCsBERERERETKRAGYiIiIiIhImSgAExERERERKRMFYCIiIiIiImWiAExERERERKRMFICJiIiIiIiUiQIwERERERGRMlEAJiIiIiIiUiYKwERERERERMpEAZiIiIiIiEiZKAATEREREREpEwVgIiIiIiIiZaIATEREREREpEwUgImIiIiIiJSJAjAREREREZEyUQAmIiIiIiJSJgrAREREREREykQBmIiIiIiISJkoABMRERERESkTBWAiIiIiIiJlogBMRERERESkTBSAiYiIiIiIlIkCMBERERERkTJRACYiIiIiIlImCsBERERERETKRAGYiIiIiIhImSgAExERERERKRMFYCIiIiIiImWiAExERERERKRMFICJiIiIiIiUiQIwERERERGRMlEAJiIiIiIiUiYKwERERERERMpEAZiIiIiIiEiZKAATEREREREpEwVgIiIiIiIiZaIATEREREREpEwUgImIiIiIiJSJAjAREREREZEyUQAmIiIiIiJSJgrAREREREREykQBmIiIiIiISJkoABMRERERESkTBWAiIrLkmNkeM3thpdtRLczsA2b2gUq3Q0REZqYATEREFsVUQZKZfcnM3lb+Fi0eM3uhme2pdDtmazl+BiIiS4UCMBERWXHMrK7SbSimWtslIiKlowBMREQqxsy2mJmb2fPM7EdmNmBmXzeznQXbtJrZ35jZUTN7yMxeV2Q/O83sU2Z2MNnmz82speDxPWb2VjP7gpkNALeb2WEze2TyeIeZpc3s7wue8y9m9r+T/99gZt8ws2NJOz5pZluTx64F/gLYZGaDye2p82zXK6b5Hb3UzH5qZifN7D/zrz/F73WjmX3UzA6Z2b7k99eVPPYXwLXAbyZtPTC7T0tEREpBAZiIiFSDXwEeA6wCDgB/VvDYe4Dzk9uZwLnA+vyDZtYL3Al8HtgEXACcAdwx6TVeAfwW0A78DfBfyWsC3AjsBh6d7DMFPDLZJ0Aa+HVgdbLvLPCPAO5+J3A78IC7tya3j8+zXe+f5nf0kqR9a4E9wCfMrGbyRsl9nwYGgO3J624C/i5p7+1Ju96VtHXNNK8pIiIlpgBMRESqwdvd/aC7jxJByGXwcCD0fOB33P0hdx8iAiEreO7zgZ+5+/9x9zF3P0IENM+fFKD8jbt/y8Mw8AXgpuSxm4C/BkbN7DzgUqAB+AaAu3/N3b/p7ml3Pwa8HbjSzJqneU/zbddU3jHpd7Ar/3ua5DLgbOA17j7g7oeT7Z9kZgq2REQqrLbSDRARkWUrDRSb01SXPFZoX8H/B4HW5P+riEBod/5Bdx8wsyMF258BXG5m/QX3GeDAGuCh5L7dnOoLwF8nI1WPAW4FdiT/bwK+7O7jAGZ2IfAu4MKCtlnSvvuLvMeFtGsqxX4HG0mCxAIbgSPufrLgvnuSfzcRI4wiIlIhGgETEZHFspsIQh6WjGhtA+6d5T4OA2PAloJ9tAK9BdscAL7k7p0Ftw53b3T3hwq2yxXu2N0fAH4JvBRoA35IpAvelNy+ULD5R4C7gbPdvR24Pt+cYvteSLumsSX/n4Lfwd4i2z0I9JpZW8F925N/H5jja4qISIkpABMRkcXyt8BLzexGM6tNAoL/TYwAfXY2O3D3HDHX6u1mti5J+fvjIq9zqZndbmbNFjbmC2HM4AvAm4H/dHcn5oVdDVzJqQFYB3ASOGlmq4F3TNrPAWBVvtBFCdpVzG9P+h38HPhWke2+A/wU+NOkgEkvMY/u0+6eH/06QMynExGRMlMAJiIii8LdPwS8AfgT4Agx2nQO8Gh375/Drn6dGH36SbKPn1Iw8pOMZF0FPJYYWesHPgecN4t9f4EIrj6f7Ks/eZ3D7n5XwXYvAZ5HFLb4T+DfJu3nv4nCF/eYWb+ZPXmB7Srmb4kA8QAxsvgUd89O3sjdM8ATgS5iFPLHRIrn8ws2+2Pg3KStxUbRRERkkVh0+ImIiEg1MrMtRCC11d33VLY1IiKyUBoBExERERERKZMlF4CZWaeZfSRZrPMhM3tVcv9GM/ummR03sz+e9Jy/XkDOvYiIiIiISEksxTL0/49o9zqiqtMXzOynRPng/KKa3zezD7n7d83samCVu3+8Ug0WERGZryTt0GbaTkREloYlFYCZWQsRaF3k7gPAD8zs/cCLiXK8H0/WRvkusM3MfgD8EfCsSrVZREREREQkb0kFYETJXHP3uwvu+wGxXst/Ao80s28ClwDvBF4PfDSpRFWUmXUCnZPurifWqfklcFqFKREREREREaAGWAt8x93HZvOEpRaAtRLrsBTqJxbQ/D3gvcCdwJ8Dg8BTgceY2XuJ0sdfcfffmvT81wFvXbQWi4iIiIjIcnct8NXZbLjUArBBoH3SfR3AgLsfoyDV0Mz+nVh/5gVEZHo98Hkze5y7Fy4AegfwgUn73Ax86c4772TDhg0lfQNlM3AcvvD3MHQCrrsFjuyFb38G6pugZy1YkekE7jDUDwP90NwOHT1zf93DD8L4KDQ0Q886OPQA1NTCC98JNTXFn/OTr8Kd/wbtvdA6+eMtMHgcThyBxhbIZuK9DPXHe+lZDw1Nc2+viIhML5eFg/dDWxc89bXw8T+FsdE4l8x7n7k4L6XHwGpg1Qaoq4/HRgbh2H6oa4C+TTPva+gE9B+C+kZYtXHq7Y4dgNFBaGiJtp88GueVxjboXg0nj8XPt7wh2jPZkX3wmffF76Nz1cT9R/dP7Ld3XfHXdo/fYXoM1myJ93ZwT5wrXzBpTe9cDj79l7D3F2Cp+L08603Q2jn97+Gbn4QffCn2X+wcP52Tx2DwGDS1QdfquT1XpBKGB+FJt8/8vSiDvXv3cu211wLsn+1zlloA9gvAzWyXu/80ue9CYtHMh5nZ04D97v4NM3s+8F1392Ru2PnAwwFYsuhm/6TnA7Bhwwa2bNmyKG9k8W2B8y469a4N6+FLH4a6dBxgc1nIpJPbOIwNQ80YdLdCdhzqs9DRO/uXzKZhtB5SzYBDZwuMNsLGs2D79qmft3ED9O+Bfb+Ano2QKlKc0x0y/dDQA5c9Hr7x72AOzd1Q3wAN9dDeNfu2iojI7IwOwVgznHs5nHM+/ORMeOiXsGoBx9zB43G+WHMmnDgMTfUR4AH0Z4C26Lzr7Zw5mKhNQ6oNUjVTb+8O6aPRgdfQFG23IahtgZZW6O2CmlFoyMFZZ0N79+n7WNUN3++J30dvwXvP9sO4Tf/6uSyMNUGuATpboakFRpsjECx2nXHrK+FD74KRAXjkc+DcC6f/HQCcvAD2fh86m6KDci5sGOpaobnt1PcmUq2GamDzJmgr8l2tnFlPW1pSZejdfQj4V+B3zazNzM4nCnC8P7+NmbUCvwm8OblrN3CDmdUDVwP3lbfVVeSyx8P510ev30O/jNuB3TFq1X8Ixkagdz286J2w64q47+TR2e9/bDR67tZtBwyGT4DnYNsF0z+vphaueRrU1sPAFK83NgLp0dj3hY+E1i4YH4Nzr4kexPFZpdyKiMhcjY9GALPjwvh50y5Ij0cmwnzkcpGlUVcXGRoNTXGMz0snr5e/zSQzNrFdenyKbcajs7GxJf51n9g2l4t/s5kInppai++juS1GrvLbQ9I5mI77UzUwPDDF6yevaanorMxl4+epXmvNFrjm6bD1PLj4pmnf/sO6+iLwGhma3faF0mOz+12LSEkstREwgF8F/poY5jsJvM3dv1jw+NuBO5KRLYC/BD4CHAY+DXysfE2tMmbwmBfEyeO+H0VvY/daWL0l0i06V0UaYG0dPPH2OGH88ntxsuhcPXMv5PhInFzOvgqOH4gTbKoGNp89c9s27oTeDREMdqw6/fHhk/H6lz4ueiZ3Xg4/vhMufwLsuydG70REpPTGR+K8sHZb/Lx2e6T7DZ0sPlI0k+ET0Wm28zLYfA7UNUaQBxEEjI/GuSNVE4FKsayIQumxSHGvb4y21jcUeQ9JULduBzxwdzwnk44OwGzSaZ3NxPvMp0JOZha97ccPTNznuTin9q6OIHL4JLQUSaXPZuL1a2ridXNZwKGlc+r39YjHxW22OvtOD2ZnI5eNANVS8X5EZNEtuQAsCaxunebxN0z6+QTw2EVu1tJRWwdPePnstnv6a+Gzfws/+hI40L1m+ueMJSfpHRfB9z4fAVh9YwRWM6mpgfOug89/INI7GlsmHstlIw2jsSV6AwEe9Vy44klxouvojRQWEREpLfc4tjc0Q3syL3j15hgNGhmeewCWy8HAsQhyrrslzhmdq+HkkXg8k4ystXRGMJXNxjZTyWbi1tEHuUy0tdickHxQt+Wc6LQbHYxgo7EtXieXi8BopnSmjlUTwZRZMgro0LUmOiv33F38eZl0bF9bf+oIWNs85lpPpbULGltjDt1cpMejLfVNkNMomEg5LKkURCmzVA3c/BK44MY4YQ6dmHrbXDbSRlq7YmRt9eY4uXX2Fe+NLOasS+MEnz8R5w0PxMnrrMtO7ZnM9zJ2r4NMRukTIiKllh6LIGP1loksiKbWSFfPTpHuN52hEzA+DtsvjEJNAH0bkxS93EQq3NptMSKTmyHNMZ/at3Zrkh44xRSMfAfhuh0x4jYyFM/r7AMsgiLPRQGq6eSD0FzBqJl7zKvedgHk0sVT4vPpmvWNpz6/rXP615sLs8hmyYzP7XyY376pRSNgImWiAEymZwaPeT5s3AVH98GRh+D4oYnqUcMnI0DqPxQ9lZt2xvPW7YCaOthy7uxfq7kdzrwk5pJlC06iwyfjxHnhI4s/r3MVGHESERGR0pk8/ytv09kTRZxmK5eLSnv50a+8rtXR4Tc2GsGLpWDDGUl64Az7zwcPG3dGYJgrEkBksxHYdayK16qvT1IeDVZvivNcfhRophGwlo5oa3psYt8Qgdz6M6KK4OCxIm1Ix/PqGyKjJJuN1y91AYHe9fE7mMv8vHz6YWefAjCRMlEAJjOrrYOn/Grk/Y8OReDVfyhK+h55KOZtDZ2IFMFzr4nn7Lgogq8zHzG319p6fvRijiQTmdNj0XPZsSpG1Ypp7420jvwcAhERKY30aARCG8469f41W6CxefrMiMnyo187LpoY/YLoRKtvjLm8+dfrWZ8EYDONgCXBQ9/miTTAycZHYsRp484IoOqbItBIpaIdNbUTgWZn3/Sv19qZnG+SACyXFO7o6I3Rp/ae4iNg+flmTW3g2WiPEVkjpdS1Oto3NhznztkEVOnxmAbQ1l08gBWRkltyc8CkQtq64AVvj5PI2Ejkzw8ch8H++H/P+qhQmF+Lq6MXnvW/5v46fZuSuQWDcaIbPhknqkseO3URkPbu5OQ9EidXEREpjfR4jNxMXhuqb3MEE8MnZ7efwtGva2859bF88YgTRyIIaumIQGY2I2Dp8diuc1XMU84lwU2qYN3J8dE4f2w7fyJYOrA7eV9ropNxPClcUawIVKGWjhjFengELBMBYGtn7G/reXBgT4xw5de+dI9Asbk9bof3JgFYauoqiPOV/10e3Rc/t3ZGsa3ppMciaGvpBHxifpuILBqNgMnc1NbF3KuedTGZ+dyr4dLHwtZzS7MQcv5kkc/rHz4ZwdXOy6Z+TntPbDPfksgiInK6fEXC5raJuUt5DU3RYTbbFMT86NcZF5++gHNLZ1IefjwCkptfEkU/ampmHsHJB2AtHVHQoqbm9BGo8dFIiV+zJX7uWhPvra4hgrHa+thPPjibTmsn1NRPtCsfgDW1xc8bd8V+C0cGc7kIuNq6Y7uHg8TUqQWnSqFzdQR5ZtGOmT6f/Hqg7T2xvZnSEEXKQAGYVJ9Nu+JEPHwyToobdxYv65vX0Jyc1HTSEBEpmXy59O51xR/ftCtS8NJFUu4mGzoRHXjXPuP0x1IpuO7WmOf7ondGgY6GJrAaIk9vCrlcnCvauyNwaO9JStoXLEviHqNbjc0T6X7tPdGWtq44d+RTHc0mFoOeSmNLBKOFa4elCkay1m2H1o5I18/LJh2KnavjXOb5OVoW569SqquH294Ez39HFK6aKQAbOhnt6dsUARimc6lIGSgAk+qzZmvk6Pcfip7FS2dYB8Us0mNmSlUREZHZy1ckXL+j+ONrtkbZ88EZ5oFlkyCta/XU6XBbz4PHv2yiKEV9U7IO2DTV/HLZCB7yaYP5dPTCEbB8Fcc1WyfS6tq6Y9Sra20ETjW1gJ86kjWVfJCWr86YTRZhrklmdDQ0RRGq/GLS+W3cY45YQ3O8Tn5O2FRrji1EU1tUhexaPTHaVszIIJw4FEHrJTdFWzQCJlIWCsCk+qzeEikv6TFobp2orDidjlVJmscMJ47M+NQnIxERmZBJ0vLWn1H88VUbk2P1DAWQxkfjuLv5nNm/dk1SMZBpjun5AKc+SX9v7YpgqLAE+8NVHC+auK9vUwRhG86MICifBjjbOVmdfRHU5XKxBMrk5+TXqxxNRuIyyeha99p4LSOe3zAprbPU2ntOrdhYaHwUju2P93zzS2PkLj8CltU5UmSxKQCT6tPUEqV0HTjnmukX4cxr7Yg0kOlK0bvDoQcnJieLiMjU0mMRoHSvKf54XT2s2TZRwn0q4yMRgGy/YG6v39gyfYeZ5+J182l8+bTCwvnA4yPxHtafOXFfRy88/21wUbK0SUtH7Ku2bnYjUvlRuszYRNGQQuvOiHlYQ/3xczadlHlfFamQqSTlsaHE878mywekY5MC5Ewajj4UAeTVT4Ozr4j76+rjPKpOSpFFpwBMqtPZV8VJ/4IbZ7d9S2ecZKebi5BJR4BWmJsvIiLF5QOwtp6pt9l4VgQvxUqv5+UXQV69ZW6v39gyfVZDPugrHEnqXjdRxOnh164/PYisb5wItvLzvmZbECNfun7gOOCnF+7oXJUUk0oC09Hh2L61K4Kumtp4X80zpDsuVFtXUrGxIADLZWP5mPQ4nHcdXPnkicfqGmLETAWtRBadAjCpTrsuh5f9wenVsqbS0hEnj+kuAgpz8tXDJyIytVwuLtLzlQWnsmZrpODlR3uK7Wd8FJo7pi+mVExTW6TDTTW65jnATy1k0dkXKX6ZdIw8ZcYj+Jouk6I5WVy5eZbt23JuvO/B/mjb5BL9+ZL36fGk+uMIrN0W77+xOQIwzyVl3xdRWzfUNkzMo/McHN0f7dlyLtz0glPLzdfWJ/PudH4UWWwKwKR6zSb1MK+lI3ozpyvEkR5LJhijRZtFRKaTGU+q422cfruedRFITJX+nU7mf001j2w6jc3TF4XwHGCnlshv746S8+NjkXqXy8Hmc6d/nabWeE4+tXAmNTVwzdOTaojZ4muHbTgrRtSOH4xqjtc8Le5vaI5zm/vsX2++GprivXkSxB4/BCMDMXfvqb92+jm2riHemwIwkUWnAEyWh5aOOIFOOw8hyddvbJ6YHC0iIqfLV0DccOb029XWRQGHfLGLXPbUFLax5P4zLpp6H1NpSAKwqdIQJxfhgBixq09K0Y+PxtyrrbMJwGpnXoS50MadMcqVqoH2ImuHrd4ca4Zl0tDVF+uDQTIHrCZG6doXOQCDGJ3LpGPUa6g/0iBvfWPxdMs6jYCJlIsCMFke8gtET3XiyC8o2tgcJ9vpinWIiKx0mfEIXlZvnXnbDWdFoDQ6DIf3wqEHJoKj8WT+19opStlPp74x9jvVnKRcLh5vmDQCVt8wEXTU1kXVw+l0r41zQ+/62bfNDB7zArj05uLPq62DLedAbS1c9dQobgExByxVG6Ni+XXJFlO+FP1gf/z86F+J6ojF1DVMtFNEFlVtpRsgUjJtPfDQPcUfy6bjJL5ue5yUR1SIQ0RkSvkFhmczSrNmS8zXOrYvnpcfCaupnVjvqnMOo0t5DU3TF4XIB3l1BSNgze0xIjY0EOmPrV0zF7tYtSEWLp7rmlytnfCY5039+FVPg96NcNYjJu6rqUneV6o8AVhbd/wOh0/GZ7T9wqm3ra2PoHuaRBIRKQ11dcjy0dGbLDpZJF1lfCzmC2zcCR19qvIkIjKdTBKAzbQwMUSRi9bOKDqBTQRe7vFvY+upxR5mq74p9jVlAJYc6wtHwMxi1Gd8eG5zz1raT51LVgpNLXDB9acHds1tEYg1LXIZeohKiHUNE1UPpwsy6xoiAFMEJrLoFIDJ8tHaFSePTJFCHPkCHBvPiknj2fTUE7tFRFa6bDoq6M1mVChVA5vPjnS786+PQCadFPHw7NyrH+Y1NCVrZk1RXMk9jut1kwKn7rVR+c997muPlUNzW8xZLqzeuFjakpTM+saJdc+mkl8HbLq51CJSEkpBlOWjpSPy7tNjccIplF/Ppnc9nDwaJ5n0eOl7PEVElrr8yNVcqvRd/XTYfE6ksd33A8iOT5SQn24dsenUN0VQN9X6jvkqiLWTLmXae+JckE3DunnMPVtsZ1wChx6c/bpjC9GxKtZGW7UxSvRPJ1UTn59GwEQWnQIwWT7ypejHRyd6XHPZCLhGB+Nk19oVJ+e6BhgbVgAmIjJZLhPBzVzmKNU3RFXAY/vjIn58bGI+2EwX/lPJzwGbKh5wj2qCtZNG6dp7oj25+vnNPVts2y+cfi5WKdXWwa1viJTS2ahv1AiYSBkoAJPlo7UzCaxG4gQyOgj9h5NFQNvg0c+PdJX23jjJjI3CLKY3iIgsG7lcdD41tkw9LysfOE1eYHg2mtoi24DRCOQgyrDPR31SrGKqCMxzQCrS+Qp1JMf49t4I4Fa6VA3Uz/L3UN84ddl/ESmZJTMHzMxuMLOcmQ0W3F5S8PhvmNkRM7vLzM4ruH+7mX3VzHQUXu6a2+NEnM1EL+yRh+L/Oy+Hl7wbzr4ytsuPgGkOmIisNMMn4fCDE2XJi8kXveheM/f9N7ZMLDSczUSQN5f1tQrVN8YcsKlGZB4eAZsUgHWtgeueObH4scxeQ7POjSJlsNRGwA65+2lnBDNbC/wv4Gzg6cDvAU9MHv6/wOvcXSsLLnd19bHG1+EHJ076j3tJrMVS2NNbVw/NHTDQX7GmiohURH4NxIGjUSGv6DZJ4NQ5jxEwszi+9h9OArDU1K8zk1Qq5qH1Hyz+eD5QmByAmcE5V83vNVe6+sZI3c8XOBGRRbFkRsBmsAn4pbsfAr4IbAMws9uAe939u5VsnJTRtvOjtO8VT4aX/B5sPbf4SaSlYyI9RkRkuXJPysMn0uPJOl25qUfB8iNXUy3YO5O2rthHdg6l7KfStzEpaV9kVCaXiwBPaYalU59fU03zwEQW01IbAesxswPACPAJ4C3uPgjcA2xLRsJuBO4ys3bgjcC0dVfNrBPonHT3hhK3W8rlyifDxY+JydvTae1SL5+ILH9jw3B4L/Ssh+bWqCjY1Brzo44diLmzk+UyEdS0dMzvNVs74/iaSUbAFhKAda+NtoyNQeOk43ouF/PNdAwvnbpkMeZcDmqWSx+9SPVZSt+unwEXAOuIoOoi4E8B3P0o8OvAp4EnE4HXu4DfBy42s/82s8+b2blF9vs6YPek252L+k5kcc0UfAG0tAEWFwkiIstVNhPHuaH+ZFQqHVUJL350/P/k0dOfk0knqYTzDJya22PkKzMWKW01Cxih6lqdFE0aOv0xTwIwKZ26hvjsNQ9MZFFVbQBmZs8tKLZxl7sfcPe73T3n7ruJOV/PyG/v7h9y94vd/fFAH7AF+CjwD8CLgHcA7yvyUncAWyfdrl3EtybVoKktTjKzLc0rIrIU5bJxrMtmIrDK5aBvM5x7TSxSfPwgDJ049TmZdCxuPHlu1Ww1tYLVxH6aWhfW/s6+KAwxPnr6YwrASi+/8LYqIYosqqoNwNz9g+7emtzOKbYJUf/oFEm1wz8BXgOsAmrc/X7gO8D5RV6n3933FN6AvaV8L1KFGlvixJ0dn3lbEZGlKj/Knx6DdBLErNsewdVTXg0bd0bF2OHBeCxfvXC+o18QHVy1dXERP5e1xIpp6Yj9FQsIcrnT1wCThaltmEhBFJFFU7UB2GRmdqOZbbawEXg38LEim74a+LS73wccBZrM7Gxibth95WuxVLX8BUJaAZiILGOFadYjg5Ea2Lcpfq5rgFvfCGu2wpEHYXQ4WQMsF9UH5yt/fPVsrMm1EGawakNUbywsR+8e7ZzvKJ0UV1cffyPZdKVbIrKsLZkAjJjz9XVgKPn3x8CvFW5gZuuA24A/AnD3DPCrwH8BfzF5e1nBmlqi51QnGRFZzvIjGU2tSQBWe+q6XA1N8Mz/FcUuDt0Po0MR3HTOc/FkiNGz2rrIU+max1pik63aEMFW4fHaPfZf17Dw/cuEuoYoeqL50SKLaskEYO7+Hndf7+7N7r7R3V/j7gOTttnn7le6e7rgvn9y97XuvsXdv1j+lktVamqLFESlWYjIcpbNxrGupSOCmLr609MLW9rhWW+OyohH98V93Wvn/5r542sqBZ3zXIS5UOfqCAzGhifu8xzgCsBKra4+CcB0bhRZTEsmABMpqfwcMC11IiLLWS4To/19m2LUqGNV8bLtHT3wrDdNlJDvWsAIWF19rCeVqomgbqG6kkIcoyMT9+XTERWAlVb+c1N2iMiiUgAmK1NtHTQ2xxwFEZHlKpuF+oYovFFTB6s2Tr1tz9oYCTvzEVEpcb7MIpCrrYuS9AvVsSpK0ecKqtbmy6TXNy58/zKhrTs+t6zOjSKLSQGYrFzNHcpzF5Hlyz2OcQ3NsP7MSEPccOb0z+nbCLe+YeHFMzr7IjhaSDXFvNq6WA+scNkQ97jNZt1Hmb2m1vjMtA6YyKLSAhqycrV2JRW/vHhKjojIUua5JEhpgTVb4EX/u3wpe1c9BdZuK90IVd8muPcHMTcplSoYAWsuzf4lmEHPeti/W+dGkUWkETBZuVqS1Bj19InIcpTLAj4xCtXSHumI5dDYAruuKN0FfPeamJuUX5A5PwesUQFYyfWsS6pOZmbeVkTmRQGYrFxNrbHgZCY9MRImIrJc5JIRsNbOSrdk4TpXR7rhaH7B6PwImIpwlFxnXxRuGRuZeVsRmRcFYLJyNbUmPapjcGAPHDtQ6RaJiJROfo5rS2dFm1ESXX0RgKXH4+eHqyCqCEfJdfTG77qw7L+IlJQCMFm5mpLFQgePQWYcBo9HMCYishw8HIB1VLYdpdDUdmrhpFwu0hsblIJYcvkCKkpBFFk0CsBk5WpsSdIshuPflg44vr/SrRIRKY1cNoKU5RCAmUWFxsz4RAVEUBn6xdDQNLEenIgsCgVgsnI1tUFtbax3suNiuOjRkfOuvHcRWQ5yyTyp5RCAQVTnc2Lebn4OmMrQL47eDRPBrpTX6BAMHKt0K2SRKQCTlaupFVK10YN65ZPg4kdH7vvxg5VumYjIwuWyUWhouVQK7FodRTdGhyZKpNfVV7pVy1P32olgV8pr+CQceWii4qcsSwrAZOWqq4edl8FZj4DVm6NE84WPioOeJh+LyFKXT0GsXyajRJ19MedrbDgZATOoqat0q5anjlVxjhzXubDs0uPxvR06UemWyCLSQsyysl3z9FN/vvBG+OEXYxRszdbKtElEpBQeLlSxTAKwh6vzjUQAZhaFlKT02ruT3/UotFS6MSuIe6R+pmogXUVFwdxjZC5fPVoWTCNgIoWaWuGSm+LAl19vRkRkKcplIZWCumWyVlZNbSzInJ+bpABs8bR0RHEqFeIor1w25qXX1MVIWLXMwRsZgGP74fihSrdk2VAAJjLZ+ddH/rsONCKylGUzUNsQgcpysWpTXKBmk8CgVnPAFkVTa/xuqyUAWCmyacBj3TvPVccomOfg5NEYUdfSBCWjAExksoYmuOSxMfl4eKDSrRERmZ9sZvmVae9eE9Vr02NoDtgiStVEKXpdcJdXJh1B76azY6mcoZOVbhEMnoi58fWNGhEtIQVgIsWcezX0roN+jYKJyBLkubg1LrMJPJ2ro5MsPRYjezWaj7JoOnojANMoWPlk0vF3vfW8GIWs9AhYLhsl8WvrY7mebFp/DyWiAEykmPpGeMTNkMvA4YfiAKSeQBFZKnK5uFBabgFYV19S1dFjTpgsnrbuZNHrXKVbsnJk0zH62L02qjNnKhyADRyPIHDXFdC3Ke7TKFhJKAATmcquK6PHZ3QgqiI+dA8M9qv3R0SqX/4iqbm9su0otcYWaOuKNapqFYAtqpaOKOKS1lpgZZNJx9p9bV1RiTnnlev8zaZh8Hgs/XDdLbFUTyqlteFKREcvkanU1cPTXxeLfu7fDf/9T3Do/gjA2roq3ToRkanlsnGsau2sdEtKb9Um2P0Tzf9abC2dUWUyPQoNy2wuYbVKj8di4/WNEQDXJOXoF2O0Nz0W36HUFGMxJ5PMn0c8PkZDWzqgpj6et1yWtqigqhkBM7O1ZvYJM9tvZm5mW4ps804zO2Jm/Wb2XjOrS+6vNbMPJ/d/1szaC57zXDO7o3zvRJadxhbYei48/62RFjA2VOkWiYhMb3w0/m3vrWw7FkPvuggMFIAtrpaOWMKg0vOQVopcLkadWrvj5+ZkKYDxEv/+x0fhyF44sAeO7iu+TXosFoJuaoPLnzDRnrr6CMhlwaomAANywGeBpxd70MxeCtwGXArsAC4Efit5+OnAGqAPOAa8PHlOJ/B64LcXr9myYtQ1RG9yTvnwIlLFcrlIHapvgDMuqnRrSi9fiGO5rG9WrfJrgWn+c3nkC1x09cXPzW3xN17KeWC5XARfI4Mx8pWdIp0wX3b+qqdCUzKPtKU9+XvQHLBSqJoAzN0PuvufA9+ZYpMXAe9x9z3ufgR4B/Di5LGtwNfdfRz4MrAtuf/dwLvcXbXEpTQ6epX/LCLVbfgkjI/D9ouhs6/SrSm9rtVRiKNOa4Atqua2mGenec/lkS9BvyopdtHSESO9pez0HR2K1znzMrjgxuJVLsdGYgme9m648IaJ+5vb9fdQQlUTgM3CucAPC37+AbDBzDqAnwDXmFkjcD1wl5ldDqxz949Ot1Mz6zSzLYU3YMOivANZ+jpWJXMrNAomIlXIPSqX1dXBNU+rdGsWR1s37LocNu2qdEuWt9q6SDtT1buFGRuBIw/N/HvMl6BflVyCNrXFZ1DK642RgRj5uvSm+B7BqQGeO5w8Ev+/4bZTR5lr66CpXX8PJbKUArBW4ETBz/3Jv23AfwBfB74NDAIfAN4DvMbMXmNmXzGzf0pSEid7HbB70u3O0jdfloXWTlWFEpHqNXwy5mhs3AW96yvdmsWRSsXF4fXPrHRLlr/23tNTEN1jftDxg0rJn42x4aigfOJI8cfd4/GBY1EBsWt13F9TE6NOU/2O5zoSlctG6mFTK6zbESOcNqmqYS4Lo8Mxcn7WZafvo71bKaklUrEALCmOMZjc7prFUwaBwnq6Hcm/Ax7e7O7nu/vLgduBTwAtxHywRwF3A28ust87iBTGwtu183lPsgK0dMbEb01KFpFqkx/9StXCtbdUujWyHLR3x0V5fl250SE49EAUbzh5FI7ur3QLq18mHZ0Go0UKeI2PwuEH4dj++P1ecMOpHSftPcUDHvd4zv57o9NlNsHYyGDs66wrJoK72knXM5l0fN4bdxZf5Ly9N/lbUOC9UBUrQ+/uHwQ+OIen/AS4gBjpgijCsdfdC0fFMLONwC3AdURxjh+5e9rMvgO8tkg7+pkYTcvvYw7NkhUlXxVqfDQmpIqIVIvRQRgfgfVnwNqtlW6NLAetnTFKMjoEwyfiIh6DdduhtQt+8b0ona75eFPLz+3KjEc6YkNTBDknjsLQ8Xhs9Ra4+aWwZsupz20rCIALy8WPDETghcHhvTGatWrj9O0YHohy9udfFz83t0VRjcIiH/miHKs3F99HS0ekSabTUeRH5q2q1gFL5nDlQ+6G5Ocxd3cirfA3zOw/gCGisuH7i+zmDuCNSdC1G3iEmbUCNwD3Le47kGWvtTNONGMjlW6JiMiEh0e/auD6W+MiSWSh8oUgDj8YgVj3anjkc2H7hZEyt++eGImZ6oJdIvBqaIoFjU8cic7bE0ci8GlqhxufBedcW3zEqaVjIk0wH/DksnDicHzXn/Vm+MlX4cdfjtepnSIQzqZjCZ3WbuhLinw0J1UNC8vK5+eh9a4rvp+WjgjiMuMKwBaoqgIwoPCq9mfJv1uBPcD7gC3A94A64EPAOwufbGZPBI66+9cA3P3bZvZp4EHg58TImMj8tXRECqIPz/25nqxoX6u1a0SkxMaGY+5G38aY/yVSCqs2JuXH6+C6Z8I5V02cw9p74MJHwVf/LS7i67RY82k8F+f9znVRXOPub8RIdU0dnH8DXP+s6bNpmttPD3hOHIlRx/OuhU07o1P4nu9FB0x+/thkw4NRPv68aydG0vJVDccL0hcz6Uhhbl9VfD8t7QVrgbXN9bchBaoqAHP3KbvsklGwtyS3qbb5FPCpSfe9jii0IbJwtXVxABo4NvfnjgxG3nzfpuKryI+PRopAW9firHovIsuHe6QgNbVGT/jA8ei5vk6jX1JCXavhBb8bf1P1RQKsHRfBD/4LBk9AlwKw02QyEYR1rIILHwl77oq0wptfAmu3zfz85nzAMwa0RfbNYH/cf8OzY5u+TdDWA/2Hpt7PyECMdp1z1cR99Y0xpaJwJk9mPAK01s4p2pMsxjw+PnPbZVq6yhOZq/ZeeOieuT8vPRqpA8MnigdgJ49GZamTR6B77dQHQBFZmdwngqvx0Uj9qmuArjUxR6ezD7aeX9k2yvJT7HyV170mUuuGT5avPUtJfnHlnnWw+Wx4xR/FSGGxdMNi8osfp8djP/kg65HPnRg5q6mFrefBtz4d1xipSftOJ3PPutfEsSLPLObxHd0XP+fnqTW2TD2nr6UdauoBFSJbqKVUhl6kOnT0TkyKnYt00mNUbBX5TDrSElo6YjLu0X1wch6jbCKyPGUzsO/e6KSBuFDK5SaqqOFwzTNmf2EnUgr1jRH4qzR5cfnfS35OVWPL3L6jzckcPBwGj0eq8YYz4OwrT91u8znRGTN44vR9jAzENcuFjzx9dLytZ2Ix5ny6ZFvP1O1paI7gTFUQF0wBmMhctXZGD1NmjkPw+VKvxcrFDp+MwOzSx8Lz3w7bL4D+g3GwFREZH41jTv4CKz9ZfsdFkMtEWtNZl1a2jbIyrdk60SEgp8p/T7vXzLxtMY3NEVhl0pElU9cIj3vpqRURIalK2ZlUqSzgHlMb6hqKr+vV1plsl5uo1tizdur2mMVyPMU6kmVOSpKCaGZXA5cxaUaeu7+jFPsXqSotnTHknx4rnhNfTC6bTG6tmXpRy/rGmCBbUwNPehX8w9ujZ3vdGacfbEVk+RkfjXSjYt/39Ghc/Hhy4ZMZj+PQo54Ha7dHsQQV+JFK6F0fRSXGhmNOokzIJuf91u75PT+fJnhgd/x8xZOKB0gNTbG48k+/cWqqcnosjitrt8WabpM1t09UWcwkaY75KolT0WLMJbHgqzozeyvwReA5wI0FtxsWum+RqtTaObEW2HTy+dSQHNhy0NQyMdyfNzoUB8n1Z0QvNsRJ7NpbohpRscUbRWR5yWZigduDe4qPko+PgZP0UucmOnTae+Hqp8KZl5S5wSKJ7rWRmjZ59EUmvqctHfPfR3tPfOe7VsMVT5x6u3XbJ44RecMDcTy5+FHFn9PUlizGPF5Qgn7D9O1p6QQ8OpZl3koxAvYK4AZ3//qMW4osB+29EYCNTnOyyWXh+EEYOhmTb/GJnqUHfx6P5ysdDp+MHqjLHn/qPnrWRSA2OhgLJorI8jU2EkFYLhsj36s2TvRiu0eHjxHHivGx6LRp69acL6m8rjWRKjekQhynyaSTaoMLWKh6/Q74+bfhcS+Oa4+p9KyDhkYYHYC6njhujAxE+frtFxV/Tn6JgfRYjK6naqBzihL0ec1tcWzKZKBex5/5KkVeUz3wjRLsR2RpaGmPA106XfzxTDpWph86ERdMg8djBMxSkSqUSk2MjGXTcYBsaY8KSYU6+6C+SUP9IivB2HAcG865OtbzOnFk4rFsJo4rHb1xMTecTKrv7Ktce0Xy6pNKnJkpzokrVS4X5/iWzoXt55yr4eV/FIU2ppMfiRxNsnPGRyKwWrd96k7cprZIe86k45rGUpHyOJ3Ctclk3koRgH0IeFoJ9iOydGw9Lw6s6UmlWMdGIo1obAQ2nQ0X3Bg91+mxOGD1boDagvTFoaT4xoU3nr72V31D9ERpsqvI8uYeAVhtPTzm+VHh7MThidLe6bFIQdp0TgRgo4PJiPrmyrZbJG/N1riIVyGOCfnpBh29C9/XdEsB5LV2RrCXSzpthwcAg4tvmvo5ze0xfy+dXKc0NM08t705XxpfpegXohQpiF3AP5rZV4B9hQ+4+4tLsH+R6rN+R6QHDvZPrDw/dCLW6MjlIvB6zK/A3l/EyvfDA9EztWpDpBCkx5LiGyfj5/OuL/46fZtg94/j4stUiENkWcp35vRtiTLVN78kjiX77oE1yYWOGZx5MRy4L9YKBFitAEyqRNfqSGUbG4m5zitZNhPXBp5MPehdX57XNYtAeP+90YbhgUhJ3DLNyFlDUwRuR/bG83u2z/w6zflRM42ALUQpArA08M/J/226DUWWjVUbY/5F/6E4wJ48Eut21dTCo54DlzwmDmbrz4COHjiwJybStnbGSWp0PHq806MxUjZVD1n32sjJHhuDxln0gBWTzQCmuSIilZRfRLW+8fQJ+WMj0XFzZlJGvq4BnvZa+Me3w6H7o/OmpjZGvDr7Yo5YqiaZXypSBRpboK4uuShf4QHYyGCMYEN0ns5U1KKU+pK5oyePxWdx7jXTj56ZwS1viOI/dQ3QNkP6ISQBWJ1GwBZowQGYu7+oFA0RWVJqamHTrkg3PLovUoWaWuHJr4at505sV1cP2y6Agw9E0NbUFge54YFkjpjBZTdP/Tpdq2Me2OjQ7AOwseGohNTYHD8f2x8pj2u2KQgTqZSRARg4HnO3UrWnjhKMDcd3c9v5E/e1dcFTXwMffnccXxrbotOndwP84rtQk4pOHZFq0NAUqWxZzQN7uDrgjc8G7NRrgsXWsy46bAaOxvXH5OJexdTVw4YzZ/8aja3xWRer1iqzVooy9C8xszKG9yJVYtOu6AUa7I8JyM/7neIH2p2Xx8jXxrMi4GrviZ6pkcHIpd4yzcG5a02c2NIzlLwv1H84es3z6Q/5OWhH9s71HYpIKeRyUVSjpga6+uDo3om5ne7RwVLXGCnKhdZug8e+OI4zPWujSEdXX6T/1NapOqpUj/woreYsR9ZJKgVnXAyXP35hJejnKl+II5OG9WdOv6jyfKVSUThMZegXpFRl6P/SzO4BvpDcvujuAyXYt0j12rgzgrBMGp7y6qkvhtZugxe/a2Jia8eqiaH7866ffvHU5rY40A3P8uuUzUbAlcvGuh41qbivpQNGhqIHfjYpBiJSOgPH4nu564pYx+dD74Jj+2JUPJuJcs5rthU/Fpx9xUSpaIjjR31jsoCqsv6lSjQ0RVosGhUhl405240VWJS6uS06efsPwdVPWbzXaeuG7M8Xb/8rQClSEC8zs27g0cntT4H1ZvYtd792ofsXqVqNzZE7DTNfCLV2Tvy/vTtOVKkUXHjD9M8zi4u0/btPXd1+KuMjEylOY0NxoeY5OOuyWJfs/rsj9al2AWuSiMjsZdKxFEVDMzzyOXFxtPV8uOd/kseTRdrXbJ16H4VLVHQno+KryjSxX2Q26pMATGlp0aliqYlpAOV23a3wy+/Bhp2L9xqtXXHcmmuBsHxWzmyqOi5zJSmr5u7HgM8Cn0n+HQKmOZuILBNmc++FbumM3uy122e3js/qLXGQGxueedvxkWhPfQOMjcYoGMC6HXDzS6Mn/fBenSRFyuXEkbggu+zmiTlbqzZGR0l+pBqLtXpmo60bnvY6uOaWxWqxyNzVN0YK4nI8t6THoxN0bGR222fTcQ5OVWjO9fodcMOzopN3sbS0R+A113VKRwbg4P0xBWOFK8UcsLeZ2deAB4GXA78ErnV3zQsTKSafunj1U2e3/c7LYj2wYwdm3nZsJE6CLZ0RtGXScRDu3RD7uPHZccA8cWjmfWXGtaaLyEKMDUcBjbbuUyfDd62O7+nYSHzPalJzq5S2ehP0qgKiVBGzGPHxZXjOGDwWnZsDx2be1h0y2cqkH5ZTc3tcW6TnWHQlk4m/EQVgJRkB+x2gB3gV8Gx3f4+7/6QE+xVZntq74dY3xmLOs9HYAlc9NXrLpzsB5HJxkmjtijSlbCYu7lI1E2Xuz7k6ioKcTE4oU3FPKjw+NOu3JSIF3KMgDsAjn3fq4qadfZGCMzYcvetWU5rFWkUqqbF1+RXhyKZjvc7ZyiVpeS3ti9ematCUrAU2lwJhEItEm6lzl9IEYOcC7wWeA9xvZt80s3eY2TUl2LeIAOy6MsrE9h+e+gQ3nqwltHEn9KyH7HgU+6itnygQYgaP/pXogT+8d+qDYHo8Rs+GTy6/E6pIOQyfjABrzVY469JTH+vsi4AsPR4XMI3NmhMhS19z2/KrjDd4IoKG2b63XAZwaFnmxa7yizHnpznM1sMpiwrAFhyAufvd7v6n7v4EYDXwceDXgC8vdN8ikqipgUc9N/LKjzxYfJvxpCfqzEsiwCIVAVhb96nz1Jrb4KYXRf72vntipGtyOkB6NHrwU7WxyLSIzF4um5Sdr4ObXnj6XIymVmjuiBHqbDb5vooscY2tgC+fNMRcFob6ob45SrrPpjMym41zZ+eqRW9eRXX2xXFsdGBuo1mZdPx+NAJWkjlgW8zsZWb2L8BDwG8CXwV+faH7FpECq7fA1U+PQOvk0dMfHx2KC741WyOdqa4+TgY9ReaKbD0XbrgtDqDjo3D4wVMn06bHIkDrXAWjsyj+ISITBo7Fd2jX5bC2SD0qs6himB6Ni9XVW8reRJGSa2iK88ZyGQXLZ4JsO38irX+mIiO55DzascwXSa9vjGsIq4Gj+2b/vGw6SUFcJn8jC1CKFMRfAi8Cfgo8Feh29ye5+/+Zy07MbK2ZfcLM9puZm9mWSY+/zczSZjZYcDszeazWzD5sZv1m9lkzay943nPN7I4FvkeR6nDpTbD9oljjY3xs4v5sJib0t3bGiFdHb5wMc9niF4D5ff3an8UaZU2tpxb5SI9BbS2cew1kxibWLRORmQ2fjO/f9c+aepueDXHx4h5Vy0SWusZmMKIIxXKQTUZrNp4Vha1mEzhks7Fd2wqY07n1XLjoUVHZcGRo5u09F9cqtfWzC2aXuVIEYL3ufpW7/4673+nuc6xJ+bAcUcL+6dNs81F3by24/SK5/+nAGqAPOEZUY8TMOoHXA789zzaJVJdUDTzuxbEY6+EHJg5go0NxYjjrEXHwb++BuoZIfZqpd713PZz5CBgdnEgPGB+NdYvOuiyqHZ0oMuImIqfLZuJ71LV2+kXPO5MFlfGYsymy1NU3RadCbr6XgVUmmxSM6FoTqfupVHy3p5MvMtHSUZ42VtpVT43rkcFZVIjMB131jYBGwUoxB+yEmbWY2TPN7I3Jvy3z2M9Bd/9z4DvzaMZW4OvuPk7MPduW3P9u4F3uPjCPfYpUp9bOCMIsBUeSKoWjQzFPbOfl8XNdQ4yE1TdC5yzml1z++MjfP3YgTjDZTARmPeugb/P0FRNFZEJ++YapRp7z8pUQa+vjAkZkqWtojuUVZgpSKimXm/3ISyZZULm9Jyk6UTdzNkg2G8/JF75a7ppaoGft3ObHtfdEkJpZJoH6PJViDtgu4OfAnwLPAO4Afm5mZy9030XcbGbHzOwuM3t1wf0/Aa4xs0bgeuAuM7scWOfuH52h/Z3JPLaHb4DWMJPqtvU8uPSxMfQ/2B8BWEMzrN48sc2Oi+NAN10vfF73Wth1RexndChJu9gZB8ldV0RPleaCicwsf4G2/ozpt+tYFSMGLR2RuiWy1DU0RQCWrdIALJeFA7tnX1gqm6yj2dwet9r6mQOwXBK0Nc55HGLpWrs9pirMVFgjP8+8Z10Es5k5VlBcZkqRgvgnwD8A6939SiJ4+TsiECuljwC7gFXAy4C3mNmvJI/9B/B14NvAIPAB4D3Aa8zsNWb2FTP7pyQlcbLXAbsn3e4scdtFSu+ap8OGs2ICbDYDm8+Ok1/eJY+BF74zDnSzcdnNsXbJ8YNxAslfQG49L0bdihX+EJFTpZO19/o2Tb9dXX18hy9+dHnaJbLYHg7AqjS1bHQoAqjZzFeCJACrSaqWtse5NDvDqE0mE9kohev+LXerNkYBsNEiv9dcNjqK3SdSOns3JAHYPOaWjwzCsf3LoopiKQKwS4C3ukfd0eTf3wUunu5JSXGMfDGNu2Z6kaTc/T53z7r714kRt1uSx9zd3+zu57v7y4HbgU8ALcR8sEcBdwNvLrLrO4gUxsLbtbN43yKVVVsHT3h59KBnM3BOkaX35rK2UGcfnH0VkIsTSG8yL6WtKyYh59cZE5GppcfiIrSzb+Ztd14GVz558dskUg4NzXHuqNbiCqNDEQAULssyFfdIpWxqi+2b2k7t4JxKNhO/h9m8xnLRuz5G/E5bzmYMDj0Ya44OHp8IwHrWJqOJ8xgpHeyPzuCDe6r372yWShGADRHFLwqtSu6fkrt/sKCYxjnzeN2iv3kz20gEZu8hFon+kbunibll5xdpR7+77ym8AXvn0R6R8utaDU+8Hc64BDbtWvj+HvE4aO2KwK21IHVx5+XREzi8RKZTpseiKqRIOblHddKmVi2sLCtPQ3OcJ4pfnlVWLjcRIMxmnTLPxehNvphGfUO8v+kKR3guUhCbWhfe3qWksy/mkBemng4PRPCVHo1ga2Qwfjepmrhuqallzn8nnouO4Ibm2NeJw0t6zblZhPMz+ijwcTN7C5G+t5UYAfvXue4omcNVk/zYkPw85u5uZk8BvgL0A48AXgO8pchu7gDe6O5pM9sNPMLMWoEbgPvm2iaRqrft/LiVQnsPPOlV0H/41B68TWfHY0P90FqkupN7PDY6nCz+3HVqAFdOQyeiTH8mDRvOiNQIkXLIpOPCoLvI2nsiy11dA6RKcVm5CMaGYwSmpWNinvN0o1SZpGJf4Uh2a2esmTmVfJGJlVIBMa+2Dvo2wPED8f5PHo1bKhVVEk8eg7u+BiSjj52rIyib6wjW+Fh8htsugM3nwLc/Xb1/b7NQihGwtxBzrz4G/Cz597sUD45mMkLM4SLZ1wiQrypwG3APMAD8PfD77v6Bwieb2ROBo+7+NQB3/zbwaeBB4EaiKqKITGfz2XDB9afe19AUB73x0eI9gOlxOH5oIgf86P7ZT3QuFfcIvI4lJ4G6epXPl/LKjGldL1m5UqkoKFON5cVHB+PiP58pMtPFf34NsMLOlLbu6devyiUBWNsyX4S5mLXb4/0f3hsjUw3N8NTXwLXPgE07Y3248ZEI0uvqY07dXJcrGB+J3++Oi2Md09vfE0HxElWKMvSj7v4qYr7VaqDF3V/l7qPz2JcVue1JHnu2u/ckKYs7iy307O6fSuaAFd73Onfvcvcr3F2phSLzdealMbF44Pjpj6WTwOyap8Nr3hvrkR0/FCNp5ZDNREn+k0cjFeKZvxFFEMbnfBgSmb/0eFzkKQCTlaqxtfoCME/SD+ubomCEpcBnWlC5YL5SXksn065flS/Q0bECFmGerGd9XB8Mn4j//8pb4YykFMSarTGHLjMe/0Jkycy1WMv4aIy2bUgKhKVqpt++ypViBAx4uBDGYfclPitORIpbtz3SMUaKzANLj0Xv5+ZzonfrKb8Gu66MnrD+Q0W2H4/88GMHImVwIYeN8dHY18gA9G2EF7wNtpwbvWTp0eotiSzLSy4b8w5raqPMsshK1NxWfVUQR4YiPXjruUlRDWZuYz4A6yxYo685Kcgx1Tpn+SIfhUHbSrF+R1RM3nUF/MrvnPo76FkbI1XuEyNWrV0RGM92Dpd7pJHWNcYcsmVgXsmTydyqGa+Y3H3bTNuIyBJRWxcjW3f+a5yACsvbjyeV37rXxM81NfDkV0JtLfz4Tsg5dBccNAePT6SEDCYjavPJmx8dhqMPxcXvWZfB4182Ufxg63nwnc/GqFjXmvm9Z5GZuMOJIxNVvlo6VmYKkggk6195XFhbyfr4F2b4RIyWXPJYGDgGVjNz+ls2He0vPC/lS9Gnx04vspNNR2diUxtsLdGc7KWkvhGe8urij6VqYl3RffdOLDrf3D4RzNbWzfy3kh6PbdefueRHvvLmO3vtbQX/3wz8KvC3TBTheAHw5wtqmYhUn+0Xwnc/F0FNPthyj1Go5rZTqz+lauDxL49Jsj/6EuDRc5XLwvDJJFXwjfDx/xvpIfMJwIZPJKmPt8CVT4pRuLy+zTFid/ShBbxhkRkM9cPA0UhvuvCRcatZHhcIInPWmJRgz+WgpgoCsMx4jIC1dcUozX0/ju/nVKNYDz8vqdjX3D5xX3NbUj69yALCg/3RAXPxo1UBtZgNZ8IP/nviuqG5LX6/B++PYL2uMake2xzBXGrS387D878uKn/bF8m8AjB3/7v8/83sP4Enu/u3Cu77N+BdRDVEEVku+jbFaFJhJah85bf8umGFUim4+SVxwvuf/5o40GbScMlNsGpTXLgWO6HNxnhS4vbyx59+wK6piYDxwO44Mc5mDReRuRgbiXmOtfXwrDdFmq7ISlbfBFjMyU0l60lWck2s4YHopLvo0dGehsZTF4seH43Rl9q6U9uZGZ8oGJHX3hM/jw2f+hq5LAyeiODh4scs/ntairZfCJc9IYp5AazeAu290XnV3htzy08cnqhO2dgSwW8+ZTE9Fp9fKZbbqRKluCK5jFhjq9D3kvtFZDkxiyqJ++6JE1hNTcyzco8Ug6mec9MLY9vvfh5sIE5sl9wUJ7OW9kgLmatcNgK3nrWnpkMWWrM1XmtkcElXS5IqdfJI/O0/8rkKvkQAVm2IQGRkIDq+jhekppebe6QF1jfCuVfHffVNSQCWjvYdemCig66xZWIEJps5fTH11i5oaj99PczBExGwnX99nM/kdLV1cO3TJ37uWQsveidgExkDxw/Bz78D9/0g0hWP7ovPor4xfr+pmtktcL9ElGJ8eA/w/En3PQ+4vwT7FpFqs35HEtQkJ6H0WPQgrj9z6ueYwaN+BS5/QoyCbTl3olJUZ9/8CmWMj0UQtu6MqbdZtSHSGvLl8UVK5eHU23a48MZKt0akOmzcCS/9fXj1n8EZlyRp4hVaLDeXiQv33vVRQh4iPTBVG9/fbCbOIX0boXttjGwdPzCRNZF/Tp4ZrN4U+8wXjsrlYOh4BAlXPLG872+pq6k9NV27qw+ueAI85y1w25tjWsJwwXVGfeOySu8sxQjYbwD/bmavIOaAbQEuAp5Wgn2LSLVZszXyt/OjSumkAEfvDJXfzOCG22Dn5afO9+pYFUU6ctm5Ta5NJyXmt5wz9TbtPdHGI5oHJiWWzcQocPfqyqZYiVSbppb49/LHwwN3R2pZJSrXpccjQCrspKtvmjjPZJK1vs69LtqazcL++2IE5sGfwzlXnb7PVRuT5yYpisMnYXwcdl2+MsvPL5aO3gi2xkbi2iCbgZ7lVdxowQGYu3/OzHYBzwY2AJ8Cnuvuuxe6bxGpQi0dUWb7gZ9OjALUN86uiIYZrJ1UHLWtO+Zvpcfn1ruVHoOaOli9eeptzGDdjjip5nPLRUohMx6juWuVeihS1Iaz4rbnJ9HRNnme7mJLjwEGG8+auC9f4CHnE6Xm8xV6a2pijakN02RVdK+NfYwOxtzPweORXnf1Uxfznaw8LZ1JKuvQxIhj74ZKt6qkSjIrPQm23lWKfYnIErD5bLjvR7HGVyYdF6HzDW5aO2Mu2PjI3AKwsdEocz9TTvjqLZEiOTaclEgWKYH8xd06LbosUpRZpJ0/+LOYL1nu+Tvp8QiqCgtE1dbFyBW5iVLz7XMYuepeG4HB2AjUDEQH5OZzJkbGpDRSqRg1PbpvYqRyzZZKt6qkFtwdYWYPmtnfmNltZra8xgdFpLi126Pc8InDEdRcf+v899XaFZURx0dn/5xsBjJjcUKfqbrhqg2REjN54rTIQmSKXNyJyKk27oT1Z0SZ9nLPBctXzsuvPZXX2BxtyWbiQn8uS6C0dcW8z2wuKvelauDaZ5S23RJ61sdnND4WwfwyC3JLMR58O3AS+G3gkJl938x+38weXYJ9i0g1Wr0lDo7tPXDb/xdpJvPV1hUjYPlJzbORHosT6PppUkXyetbF4pjZOZS6HxuZf2l8WRnG8xd3mvchMqVUKkbBUjVRcrxcPBfniXyGRaHG1phXlElGwJraZr9fs1iOZWwozhOrNs7uPCRz19kXfzdjw8uuAiKUZg7Yp4FPA5jZOqIi4puANwJajVJkOapvgGf/ZhwYm+dw8iqmoTluQydm/5yxkfh387kzb1tbFyfJw3vh0IPR3ulK0nsu0h5y2Tixat6YTOaeXNx1JelMIjKlzWfHMg17fwltPeWZC5ZOxzG82LyhpiQAy+Xi/3NdOL1vUwQEuWyMfukcsTg6emK+3fDJmG+3zJaSKUUKYoOZPcbM/hD4DFEV8b+AVy503yJSxWpqFh58QZy8OlZFqsFs5HITa7vMdu2lS26KdUfGR+DY/ulTYUaHI70sm5lbUCgrRya5uOteW+mWiFS/VE0swptKRdpeOWTGoqNkQ5HlURpbJsrQt3TOfd/da2O+cudq2Hr+gpsqU+hYFVUrc9m41phqvc8lqhRFOPqJNb/+EXgF8G13r9CiDyKyA30CQwAAmU9JREFUJHX1xcnQc5ESMp2hEzH6cO410N49/bZ563fAy/4AfvZt+PRfxbpgUwWPIwMRFLZ0xLyFZdbrJnMwMhh/K/kFWvM99/mLOy2+LDI7W8+LJUz23xtp54s9CpYej3PJ5Kq7MFHsyXPQOY8U4g1nwsWPifPKXEfPZPZaO6Oj1X3ZpR9CaeaAfQroBZ4FPBO4ycwaS7BfEVkpHi5FP8OCzLkcDB6LtK+r57HUYM/amIA9MjjF/rPxWGMLXPzoWGssPTb315HlYbAfThyJ1NW9P4cjeyMdZmx0YokDEZlZTQ1c9njAYuHixZZfn7J7zemP5dcCy+XmN4pdWxeph9suWHg7ZWqpmmT9uGTe3TKz4ADM3W8FVgEvBo4AbwYOmtkXFrpvEVkhWrtiTa/RKQKjvOETsejl9guKn1hn0rUmRjJyU6Q7jg5FetmOS+Hsq2MUrP/w3F9Hlr78GnctHfC4F0ehmdGRWNT7xOG4OOhRCqLIrG2/MEqJnzw+t6JL85EejUCptev0xxryizF7FGmS6tWzLoL3ZVaCHkq3Dpib2TAwDIwk+1XXgIjMzsad0dN1YHdSlKPIemC5HAwcg7o6uPaW+b1ObV0c0E8UCapyWRg8Eb2mF94QaZHrz4R7/keLOK9E2XSkxfauh4seGbdMGn75PbjraxGMtc0yBVZE4kL6ETfDJ/88RpfbigRHpZDNxHe1b33x43Z908TyJZ2rF6cNUhrrz4hqyz3Lb7mPUhTh+Dsz2wt8F3gi8GXgOkB/1SIyO43NcMvr42R48P7ia4IN9UdayY6LF7b20potExfXeelxOPxgjMB1r425CgDbzo95AnNZo0yWh/RYfPaFk/hr62DXFXDLG+B5v7XsJoWLLLodF0U62clFLEmfGY8Ou7Vbiz/ekARgqRrN8a122y+AF/zuxDl5GSnFHLDDwEuAbnd/tLu/292/577Y48sisqy0dsFtb4rCGgf3nLoOVy4b1bPqGuD6Zy7sdXrWQ21DVDuESDs8/GDM69l8DjznLRMTq9ftiGIdg/0Le01ZevKLf27cWemWiCwftXUxCua5xTuu5uftFquACBMjYLV10NK+OG2Q0mlpX5YZKKWYA/ZGd/+cu4+UokEisoJ19sGz3gzNHZGOmElH+t+JI3FS3XllMil3AfKFOEYHI6g78lAEeJc+Fm5946nVEXvWxro1GRXiWHHSYzEvcSGjrSJyujMvjbUZF2sULD0enWhTFW5oaIrH65u0jp9UTEnqgJrZWWb2CjP7bTP7nfxtjvt4gpl91cz6zeyAmb3fzDonbfNOMzuSbPNeM6tL7q81sw8n93/WzNoLnvNcM7ujFO9TRMqgZy088zciSDqwO+Z9DR6PEbLrnrHw/Xf2RZXD4QHoPxgX2Te/FB713NNTylI1sOWcGA3JZRf+2rI05Atw1NZrnpdIqdXWwdlXRppgdobKt/ORHoNU7dSly+ubwGoWbw6ayCyUYg7YrcCPiYWXfxt4evLvjXPcVQfwTmAdsBPoA+4oeJ2XArcBlwI7gAuB30oefjqwJnnOMeDlyXM6gdcn7RGRpWL1ZnjGG6N38vgBqKmHp72mNBfDNbXQuyHmgLV2wbP/Pzjv2qlTHDacFe0YPrnw15alIZeNC8Pu1csy9UWk4prbYxQqM0VF2vnKd540tcUaUsU0NsOuy2I+sUiFlKIK4m8DL3H3fzCz4+5+oZm9kgikZs3d/6ngx2Ez+yvgjwvuexHwHnffA2Bm7wD+CngrsBX4uruPm9mXmajA+G7gXe4+MJ83JiIVtGEHPOPX4bPvh8ufMHU+/3xc+4woL37ZzTMHdWu3xcXC8EDxksay/IyPRu/8+hL+zYnIhMbm6AxLjxevejtfmXR0oExXXt4MrilBNoXIApQiANsCfDD5f76r8H3AHhY28nQdcFfBz+cCPyz4+QfABjPrAH4CvClZAPp64Gtmdjmwzt0/Ot2LJKNknZPu3rCAdotIqWzaBS/7g9KPQnStjpTD2Whug8274IdfgqETEbjl5bLRg5vLRG9rqqa07ZTKyBeA2aQCHCKLoqElUhFLnYKYHotRMHWeSJUrRQA2ADQDg8BhM9tKpAHOu7SMmT0SeClwdcHdrcCJgp/7k3/bgP8ArgW+DXwT+ADweeC5ZvYa4BZgL/Aqd+/nVK8jRtFEpBpVQwrYo38Fjh2AB34aI2G5bNLTmomTvXv04q7eUh3tlflzh5GBuDhctbHSrRFZnhpbYv5tqQOwzHgcgzfsKO1+RUqsFEU4vg48Lfn/p4BPAv8NfHW6JyXFMQaT210F918O/DPwTHcvHAEb5NSgLt8NPeDhze5+vru/HLgd+ATQQswHexRwN/DmIk25g0hhLLxdO+O7FpGVo64h1n7afA6MDcf8saZWWL0Vdl4O51wdAdmJI5VuqczHYD8c2BOf6+gQjI1E8DXVJH4RWZh8CmKpVyxKj8V+u9eWdr8iJVaKEbDnMZF6+CZiXbB2Tp2/dRp3/yATqYsAmNlFRAD3Mnf//KSn/ISY2/X15OcLgb3uXjgqhpltJEa8riOKc/zI3dNm9h3gtUXa0c/EaFp+H9M1XURWooamKNgxOpSsI1OQbpjLxYn/l9+LFMW6+sq1U+ZuZDCWJTj0QFy8mcH1z9JopshiaWyJlO1SB2DjyfIRqnAoVW5BI2BJGfi/z//s7uPu/q5kNOrwHPd1LvBZ4DXu/vEim3wA+HUz22xmvcT8svcX2e4O4I3ungZ2A48ws1bgBuC+ubRJROQUZjHyVTNprlcqBY95QRT02H/fxCLPUv3cYXwk5vBlM5Fi2rseNp9d6ZaJLF91DbHMg+dKt89cNlIQO3o1H1eq3oICsCTIeSQwXoK2vAFYBbyvIDVxsODx9wH/AnwPuJcoff/Owh2Y2ROBo+7+taR93wY+DTxIlMV/dwnaKSJyuvZuuPU34uR/cI/SEZeK9FgEXpvOhosfE6OX1z8zgmoRWRz5zqxcCQOw9HgEdFMtwCxSRUpxhvkY8OyF7sTdX+TuKXdvLbwVPO7u/hZ373X3Dne/PQkAC/fxqWQOWOF9r3P3Lne/wt33LrSdIiJT6tsIL303nHEx9B+Kwh2lTrGR0hofjc9o+wXw6OfBS38ftl0w8/NEZGGa2+a/wP3ocHx3C+UrIG48a+FtE1lkpZgD1gq838xeTqT8Pdyd4e4vLsH+RUSWjroGePrr4HMfgB9+MYp2tPfEwqAaVak+46ORUrohuWjrWl3Z9oisFC0dEYC5z32+Zf+hSDcsXB8yMx6ph31bStpMkcVQigBsDChcRFmzlkVkZUvVwONeDD1r4ev/DkceiguM5rZY1Dk/AV0qb3wEaupVNU2k3Bpb4riYy0bxm7nIz/cqDN7Gx6IzpVudKFL9ShGAvQa4EugGjgLfdPeBEuxXRGTpMoPLHg+XPg7u/nos5LzvnijyANDYCk0tMQIzOhyjYw1NUfpcwVl5ZDORtrRqoypXipRbYwtYav4BGAXBmzukR+O42tiyKM0VKaUFBWBm9irg94mFmPMjX0Nm9hvu/hcLbZyIyJKXSsG518Qtk4ZffA9+cmcs6nx8MC5AGlui53bgOGSzsGpDpVu9MoyPRhGATap4KFJ2jS1xfMykI3V7ttwnqidm0hGAZTNx7NRItiwR8w7AzOx64D3Au4APEZUGNxIFOd5jZne7+1dK0koRkeWgtg7OviJu2Qw89MtYs2bN1gjAPve38IP/hlwGUqVIUJBpjY/GSOW28yrdEpGVp7Eljn+ZORbSdgcnvrvp8cgcSI9FULZux6I0VaTUFnKGfxXw2+7+hwX3/RJ4R1I+/lcBBWAiIsXU1MKmXafed8EN8NNvwfHDMX9MFtfYSFwA9m2udEtEVp7GluiUyqRn3raQ5wCP7IFsErylxyMg26AATJaGhZTkuoyCRZgn+SBw+QL2LSKy8qzeAuvPgNGB0q6PI6fL5aIAR0t7VGMTkfJqaI6OqLmWos+nH6YM0knwlhmLubM960vbRpFFspAArNPdDxZ7ILm/awH7FhFZeczgokeC1cDAsUq3ZnlLj8aF3/oz514CW0QWrrElUq3nulRizpPqhykefvL4WARzHb2lbqXIolhIADbTc3VGExGZq63nx9o2J4/EpHJZHGMjcRF3xsWVbonIytTQFHNf57pYfX4ErLYOSApyZMagtWvu1RRFKmQhf6mNZvY70zyumr4iInNVUwOPei588J1w9CHo21TpFi1P4yNxAbf+jEq3RGRlqq2D+ibwo3N7Xn4OWG19zB9LpyOluFfph7J0LCQA+wZw4wyPi4jIXK3aCJc8Br728Vg3rLmt0i1aXtxjBKyhGdp7Kt0akZWruW3u8109BxjUN8b3ODMW32lVQJQlZN4BmLvfUMJ2iIhIocufCPf8AA7dDw07lFpTSumxWAZg3XbN/xKppJaOWHbDffbfxXzA1t4DJ49OVEBcs2XRmilSaguZAyYiIoulvhGeeHuM0hx6YO7zJGRqD8//uqTSLRFZ2Zpa41+fwyhYPlhr7UrWAhuNDiotwixLiAIwEZFqtWoD3HAbZNPQf6jSrVk+xkfigm3DmZVuicjK1tiSrOc1h4JD+WCttSueOzYa1RRbVXxblg4FYCIi1eyCG2DXFXDyGIwOTdzvDpnxijVryXKHseEYYexaXenWiKxsDc2ARUrwbD0cgHXGQuoPV0CsWYwWiiwKBWAiItXMDB7zQli1Hg7vnegpPnkU9u+G8dGKNm/JyYxH5bS+zbFwq4hUTmML1NbGKP9s5ZI1wFo7o5JiLgu96xatiSKLQQGYiEi1a2yGJ9wO9Q1w+MEoIjFwLC48ThypdOuWlvz8rx0XVbolItLYEunAmTkEYJ6LjqmWjihFn3MtJyFLjgIwEZGlYO1WuPaWmHB+6MEIvjp6lYY4V+Mjkaq0aVelWyIiDc2RRjivFMRk4eVUjSogypKjAExEZKm4+DFw5qUxAta7Hi59bLIQqYKwWcmv/1XboEVbRapBfgRsLlVecwUjYHX1cetas3htFFkEWlhGRGSpSKXg8S+Hjj44+wpwoozz4HEVlJiNbDpGDNdsi7kjIlJZjc0xgjWnMvTJtnX1MQ9s4JgqIMqSowBMRGQpaWiCRz47/p/NQlu3StTP1vho9J5vu6DSLRERgPqmZJH5OY6ApZLUw0c+F/b+XBUQZcmpmhREM3uCmX3VzPrN7ICZvd/MOgsef5uZpc1ssOB2ZvJYrZl9OHnuZ82sveB5zzWzO8r/jkREFllNDWw9Lwks5rCOzko1NhKjiFvPq3RLRATi+9jYEkHVbOVySdAGdK+B869fnLaJLKKqCcCADuCdwDpgJ9AH3DFpm4+6e2vB7RfJ/U8H1iTPOQa8HCAJ4F4P/Pait15EpBLW74hUnJGhmbdd6cZGompa38ZKt0RE8prb51iEI6sUYlnyqiYAc/d/cvfPuvuwu/cDfwVcPcunbwW+7u7jwJeBbcn97wbe5e4DJW+wiEg1aO+NSmLjw5VuSXXLZqJ4SWdfLMIsItWhuT1G8GdbiCOXg7qGxW2TyCKrmgCsiOuAuybdd7OZHTOzu8zs1QX3/wS4xswageuBu8zscmCdu390uhcxs04z21J4AzaU8H2IiCyetu64GMkqBXFa4yNxkbfl3Eq3REQKNbdGVcPZpCG6RxGO2vrFb5fIIqrKIhxm9kjgpZw6AvYRYlTsIHA58FEzO+Hu/wD8B3At8G3gm8AHgM8DzzWz1wC3AHuBVyWja4VeB7x1sd6LiMiiamqNSmLDJyvdkuo2NgqWUgEOkWrT0BLfzVx25mIa7lGvo14jYLK0VWwELCmOkS+mcVfB/ZcD/ww8090fvt/d73b3fe6edfevA39KBFZ4eLO7n+/uLwduBz4BtBDzwR4F3A28uUhT7iBSGAtv15b+HYuILAIz6Fwd64HJ1MaGY96IFmwVqS6NLXEcm808MM8BDnVKI5alrWIjYO7+QeCDhfeZ2UXAJ4GXufvnZ9pFsTvNbCMRmF1HFOf4kbunzew7wGuLtKMf6J+0j9m9CRGRatC9JnqPc7moKianymUhPQrtq2LEUESqR2NzVDXMjAHN02+bT1NsaFr0Zokspqo5U5vZucBngde4+8eLPP4UM+uycBnwGuBjRXZ1B/BGd08Du4FHmFkrcANw3yI1X0Skctp7Yk2c9HilW1KdxkdjjtzmXZVuiYhM1tgCNXWQmeUImHsUHhJZwqomAAPeAKwC3le41lfB47cB9wADwN8Dv+/uHyjcgZk9ETjq7l8DcPdvA58GHgRuJKoiiogsL209UYp+TJUQT5PLwonDkeK04+JKt0ZEJmtojvTgWaUgJslPjS2L2yaRRVY1RTjc/UXAi6Z5/Nmz2MengE9Nuu91RKENEZHlqb07SquPj1a6JdXFc3B0f6z/teVcLcAsUo0am2MEv/jMklPl54A1agRMlrZqGgETEZH5aOuG2gZgFmWcV5KTR2FkIBZefuqvafFWkWrU2BLVD2ezDlguB5hSEGXJUwAmIrLU1TdCS7vWAis0PgoDx+Pi7hlvUMqSSLWqrY8OJJ/NOmAKwGR5UAAmIrIcdK+FbHp2vcjLnTv0H4re8utuhY7eSrdIRKZiFtVJZ7UQcw4MVUGUJa9q5oCJiMgCdPbFBUw2s3xS7bIZGOyP+SH1jbO/6BoZgNEhWLcdLrhxUZsoIiXQ0j7HIhwaAZOlTQGYiMhy0LcpAq+De6Bn/dK/QMmk4chDMD4SP7tD1+oouT+T0aFYD+1RvxJzS0SkujV3RAeSe4yITSU/SlavETBZ2pSCKCKyHGw9D256YYwUHdwDx/bPbk5FtXGHkUE4/GAEX1vPh+f+Nmw4M4pqzJSm5B4BWH0TrN5cnjaLyMI0t0dqYW6GeayeA0vFvDGRJUwBmIjIcmAG514Dr7oDzrsuUvf23QfjY5Vu2ex5Do7ugyN7Ix3p7KvgGb8OG8+C658ZI3wnDk+/j/HRGD1bt335pGKKLHfNbZFqnJlhMXnPxbGuTgGYLG0KwERElpO6RnjiK+Bpr4uLlAP3wsljS6M4x+gwDJ+MNMNnvB6e9MqJIGrjzrgNnYgAayr5xajPvmrx2ysipdHSEd/19AwdRvnjmDpXZIlTACYishyddSm87A9g0y44fgAO3j+7Se6VNDoUvduPewlsv+DUuSBmcOWT48Jr7y9g/33QfzieU5iWODoENXXxvkVkaWhuj7TCmQKwXDICVttQnnaJLBIFYCIiy1VLBzz7LfDI50SJ+n33QHqGFJ9Kyc/9qmuE9WcW32bDmXDrG+HsK2Ou28kjcOgB2PvzCDAHjsW8sbauWJxaRJaGlvYYsZ9qLcOxkVjXL5MGTCNgsuSpCqKIyHJmBpc/AbacCx/5QziwG9Zuq74LmPHRmP+x5Vyon6Z3O5+KCBFw/eK78MvvR3B57EBM4t9+0fSV1ESkujS1QU1t8VTpXDbmhqbH4nvd2BJVTkWWMAVgIiIrwerN8Kw3wYd/L6okrttRXUHK6FD8e951s39OWzdcclPc3OG+H8EvvwcXPXJx2igii6O2LtIQTx47/bHB/gi+dl0Rt+a2sjdPpNQUgImIrBR9G+HG58Bn3xcBT1NrpVsU8umHtfUxAjYfZjFvbPsFpW2biJRHWzc8dM+p9+WyMHg8lpW48dnQ0VuZtomUmMZwRURWknXboqd56GSlWzIhk4b0KPSsjbkgIrLytPdGwFW4fuHA8Zi3eu7VCr5kWVEAJiKyknSthpbOKMpRLUYHo7rZOddUuiUiUikt7TG3K7/MRDYT6YcNTXDVUyraNJFSUwAmIrKSpGpg/Y6YU1Eta4ONDsUckB0XVbolIlIpzR2Qqp0IwAb7ozDPederqqksOwrARERWmnU7wFITixZDXOycOFL+tmQz0Y6WrhidE5GVqaVgLbBsJuZ+NTbDlU+qdMtESk5FOEREVprVm6Ps89CJKOk8Pgr9hybWCCvnXIvRoVj756xLq6sqo4iUV3OyFlh6LOZ+ZdNR4bS1s9ItEyk5jYCJiKw0XWugtSN6mT0Hxw/Gv32b4MRhGB8rX1tGh2L9n11XlO81RaT6NLdHKnI2A0P90NAClz+x0q0SWRQKwEREVpqaGli7HUaGYP99MDoMG86C294UlcgOP1ie+WG5XARgDc2wesviv56IVK+mVqhrSEbFM3DxY1QVVZatqgnAzOw8M/uemR1Pbv9pZudM2uadZnbEzPrN7L1mVpfcX2tmH07u/6yZtRc857lmdkeZ346ISHV7xONg6znQ2Arda+DxL4+J7je9MB4/tm/x2zA2HBdaW86JoFBEVi4zaOmI0fjGljhGiSxT1TQHbC/wDOB+IjD8VeBfgLMBzOylwG3ApcAg8Engt4C3Ak8H1gB9wAeAlwN/ZGadwOuBG8r2LkREloLuNXDb/3f6/TsuhAtvhO99PlKCmtri/pNHwYH27tLN1Rodin2dd21p9iciS1t7L2Bw6eOgua3SrRFZNFUzAubux919j7s7YEAW2G728Jn+RcB7km2OAO8AXpw8thX4uruPA18GtiX3vxt4l7sPlO2NiIgsddc/M1ICj+yLAhljw1Eh8fh+OLy3NOmJ7jAyCLUNsP7Mhe9PRJa+86+Hs6+K4hsiy1jVBGB5ZtYPjAL/lwie8mf6c4EfFmz6A2CDmXUAPwGuMbNG4HrgLjO7HFjn7h+d4fU6zWxL4Q3YUMr3JCKypNQ3RkpifWPMB+s/HPfvvALGhuDIQwt/jfRorPGzdmsstCoisnYrPOVXoaml0i0RWVRVF4C5eyfQAbwa+G7BQ63AiYKf+5N/24D/AL4OfJtIT/wA8B7gNWb2GjP7ipn9U5KSONnrgN2TbneW5M2IiCxVqzfB1U+LQGlkENZth6f+WvRQjw0vfBRsZCj+Pf+6hbdVRERkCalYAJYUxxhMbncVPubuQ8BfAH9vZn3J3YNAYTmcjuTfAQ9vdvfz3f3lwO3AJ4AWYj7Yo4C7gTcXacodRApj4U0TEkRELr0JzrgkFkN97IsglYKNO+PfsdGF7Xt0KBZd3XJeadoqIiKyRFSsCIe7fxD44DSbpIBmYD1wiEgzvIAY6QK4ENjr7oWjYpjZRuAW4DqiOMeP3D1tZt8BXlukHf1MjKbl9zHn9yMisuykauBpr40CHPnFmXvWRdn40QFonGfq4NgwjI9A7wYtsioiIitO1aQgmtljzewCM6tJysi/BzgO/DTZ5APAr5vZZjPrBX4beH+RXd0BvNHd00Q64SPMrJWohHjf4r4LEZFlxmwi+ALoXhsBWHp8fvtzT+aUGVz1tJI0UUREZCmppjL0XcD/IUa8Roj5XI9z93yey/uALcD3gDrgQ8A7C3dgZk8Ejrr71wDc/dtm9mngQeDnxMiYiIjMV0MTdK2GweOz2z49DrW1YEl/39CJGAFbfwacdenitVNERKRKVU0A5u4fBj48zeMOvCW5TbXNp4BPTbrvdUShDRERKYW122H3jyCXi/lgxWTTUbp+6GTMIVu1EXLZSGesrZ+YUyYiIrLCVE0AJiIiS8SqDVBTH4U0Ji+W6jkY7IeTxyIIq2uIioeZdGyfHouFl/s2VaTpIiIilabuRxERmZuedTGqNTJ46v2jQ3DwATh+MEa3Ln8CPOvN0NQa874G+2P064onVaTZIiIi1UAjYCIiMjedfdDYAiePRFGNbCbSDYdPggGbdsFjXww9a+PxtdsiZdGJ9cR61lX6HYiIiFSMAjAREZmb2jrYdj5869Pw0D0RdGUz0N4Dj/oVOPOSqJ4I8e9518H9d0Ua4pVPnnhMRERkBVIAJiIic3fDbdC9Dr72b5GKePkTI+WwocjaYNvOh641kB6FrVp4WUREVjYFYCIiMndmcMH1cP51MD5aPPDKa2iCZ/8mjA7G6JmIiMgKpgBMRETmz2z64CuvpT1uIiIiK5yqIIqIiIiIiJSJAjAREREREZEyUQAmIiIiIiJSJgrAREREREREykQBmIiIiIiISJkoABMRERERESkTlaEvrgZg7969lW6HiIiIiIhUqYJ4oWa2zzF3X5zWLGFmdg1wZ6XbISIiIiIiS8K17v7V2WyoAKwIM2sAHgHsB7IVbs5ysYEIaq8F8l0Fu4GtFWuRFCrFZ1HsM5a5WQrfiZXyOS+Fz2IxVOPnu1I/i8Uy389Yn0P1KPwsqvE7u5LsBnYAa4HvuPvYbJ6kFMQikl/erCJYmR0zy/93r7vvyd+X/79UVik+i2KfsczNUvhOrJTPeSl8FouhGj/flfpZLJb5fsb6HKpH4WdRjd/ZlST5LO4F7p3L81SEQ0REREREpEwUgEklvb3SDZCH6bOoDvocqoc+i+qhz6I66HOoHvosqse8PgvNAZOyMLMtJDnLGiJfnvQZrwz6nJc3fb7Lnz7j5UWf59KkETApl36il6C/ss2QRdSPPuOVoB99zstZP/p8l7t+9BkvJ/3o81xyNAImIiIiIiJSJhoBExERERERKRMFYCIiIiIiImWiAExERERERKRMFICJiIiIiIiUiQIwERERERGRMlEAJiIiIiIiUiYKwERERERERMpEAZiIiIiIiEiZKAATEREREREpEwVgIiIiIiIiZaIATEREREREpEwUgImIiIiIiJSJAjAREREREZEyUQAmIiIiIiJSJgrAREREREREykQBmIiIiIiISJkoABMRERERESkTBWAiIiIiIiJlogBMRERERESkTBSAiYiIiIiIlIkCMBERERERkTJRACYiIiIiIlImCsBERERERETKRAGYiIiIiIhImSgAExERERERKRMFYCIiIiIiImWiAExERERERKRMFICJiIiIiIiUiQIwERERERGRMlEAJiIiIiIiUiYKwERERERERMpEAZiIiIiIiEiZKAATEREREREpEwVgIiIiIiIiZaIATEREREREpEwUgImIiIiIiJSJAjAREREREZEyUQAmIiIiIiJSJgrAREREREREykQBmIiIiIiISJkoABMRERERESkTBWAiIiIiIiJlogBMRERERESkTBSAiYiIiIiIlIkCMBERERERkTJRACYiIiIiIlImCsBERERERETKRAGYiIiIiIhImSgAExERERERKRMFYCIiIiIiImWiAExERERERKRMFICJiIiIiIiUiQIwERERERGRMlEAJiIiIiIiUiYKwERERERERMpEAZiIiIiIiEiZKAATEREREREpEwVgIiIiIiIiZaIATEREREREpEwUgImIiIiIiJSJAjAREREREZEyUQAmIiIiIiJSJgrAREREREREykQBmIiIiIiISJkoABMRERERESkTBWAiIiIiIiJlogBMRERERESkTBSAiYiIiIiIlIkCMBERERERkTJRACYiIiIiIlImCsBERERERETKRAGYiIiIiIhImSgAExERERERKRMFYCIiIiIiImWiAExERERERKRMFICJiIiIiIiUiQIwERERERGRMlEAJtMys7eZ2Zdm2MbN7IayNGiJMLO3m9mfLuD5F5rZz8ysvpTtEpHZ07FNZO7M7C/M7C9KvM9rzWyw4OcZr01K8TqVYmZvMrMDZjZoZo+udHumY2ZfMrO3TfP4DWbmZWzSkqAArIolf9RuZi+ddH9H8qV0M9tS4td7W6n2t5jM7ANm9oFKt6MYM1sPvAb43YL73mpmh81sj5k9adL2/25mLy68z91/APwY+NUyNFmk7Mzs9uQY9luVbks5LdaFo8hiS64Rxs1swMxOmNn9ZvaRyZ0U7n67u98+y33OqpPD3e9099b5tHua1z7tu7gYrzNXZrYB+D3gZndvdff/rGR7Ci2lTqnkeuuFlW7HVBSAVb+7gMkHsucDe8rflMVnZikzqynj69Utwm5fBXzG3Y8kr3ER8AJgJ3Ab8Ldmlkoeex5Q7+7vL7KfvwZem99WZJl5JXAUeNly+RtfpONJxV9LpMC73L3N3TuAK4DvAp8zs1cv1guuwL/1LYC5+/9UuiHVqJyZQYt5TbosTnrL3L8D683s0oL7XgH85eQNzexlZvZTMztpZv9TONKSHwI2s6eZ2S+SbT5nZmuTx/8CuBb4zWR07cCkfb/VzPab2TEze2+xP0gzqzGzvWb2nEn3/+5UPb5mtiVp10vM7CfAMLDLzDqT17nfzI6a2X+Y2bbkOb8JPBd4btLWQTPrKdabNXmkLOkReauZfcHMBoBXJNt80Mz+X/JaBwpHApO2fNjMjiS/t1+Y2S3F3k/i6cDnCn4+A/iWux91928CGaDXzNYA7wBePsV+vgysAS6a5rVElhwzuwo4H3gOsAF4/KTHZ/pO5o8bzzOzHyU98l83s50F25w2ol/YI2pmjWb2r2a2L3n+T8zsmXN8H25mrzWzb5nZMPDYZL/vMrN7zey4mX0l6YTBzJ4L/CZwbcGx6yIze6GZ7Zm071OOZ8n7+T9Jm/uB38tvM9Xx2czqzezPk9/fQPL+f20u71FkKu6+393/AHgX8Ptm1gGnnnctvCO5NhhI/n1X8thdya4+k3wX/iW5v9jferE0NjOzP7DILjlgZr9vZrXJA/ljxJaCjR/exzTfxVNex+K65jfN7B4z60+OM1cVPP7C5Ht1u8X1ygkz+2cza5vq92ZmTWb2xzZxffN5Mzs7eewFwBeS/w+a2ZEp9vE2M/tycqw5lHz3f8PMNpnZfya/6++b2Tmzed2CfU53PCn6eSXazeyfLK6RHjSzotc1ZrbTzDJmtnHS/XfaFBlYBb/j15nZA8ADBfv6lJkdNLOHkmNdS/LYZ4BNwF8kbf12cv9M54Wprkn3mNlbzOwzye/2l2b2lIJ9XJB8Hv0Wx/3vmdlZxd5PngKw6pcG3kf0FmNm1wFtwKcLN7K4cPgD4mK+m7iw/1c7NXADeBrwCOIPsx14J0TKAHAn0bvV6u5rCp5zNXAiec6VxCjOKUFWso8sMWrz8Bcv+eK+GJgpH/wFwOOAVuCXwMeS/18ErAN+BHzKzOrc/V3AB4EPJm1tdfejM+y/0CuA30ref37k6RlEwNOX/P8tZnZt8thvEL/zrUAH8Bjg7mI7NrMmYqTrJwV3/xi43MxWJQfuNHAYeC/x+36w2L7cfSz5XTxiDu9NZCl4JfA1d/888Nnk58mm+07m/QrxfVwFHAD+bA5tMOCTwC6gC/hD4INmtmsO+4A4nrwAaAH+izjWXQJcl7Trn4kRgk53/yBxsXpnwbFrLr3cLyaOsd3A7yT3TXd8fkFy37nu3kaMWHxtju9PZCYfApqJv7XJHk383V6V/A2eT3zvcPd8cJBPtbu14HnF/tYnu4q4QN4A3AjcCrxhNg2ew3fxDcQ1zdOI7/MHgc9PCiDWAzuIc/8u4FLgddO8/B8n7b0uee73gS+YWZu7/x1wc9LGVnfvnWY/VxHByDqiU/r3gb8lpkB0Az8H/t9sXrdgmymPJzN8Xi8C/groJH5nf25mWyc32N1/RlxrviR/X3LMvYK41p3KBuBM4ve7zcx6k/18PmnrBURn9x3J69yc/G5uT9p62TT7LqbwmvQXyX0vI4L2juS9/r2Z5dNV/5w4/vcSfycvAfqnewEFYEvDXwG3WvQu3U4clHKTtnkJ8NdJ/nLG3T9GHOReOmm7N7v7CXfvJw4ks/mj3O3ud7h72t1/TvyRTfW8vwauMrMzk5+fCNQB/zbDa7zd3fe6ewY4h/jiv8LdjyWByFuIL9nls2jvTP7G3b/lYTi57yvu/i/unnX3rwE/ZOI9jgM9xMHV3P1+dy8agBEXchAHMADc/afEgf6zRF73M4FnEyesfzaz9yU9J39d8GXOO0kcSEWWheTEeSsTJ9v3AY8zs82TNp3uO5n3dnc/6O6jRGfKrE+y7j7i7n+XHA8zyYXP3cANc3xLf+zuP3N3J77TLwBe5e4PJfv9MyLV8olz3G8xH3P3z7l7ruDYNd3xeZy4gDg76bw64O7fL0E7RArlOxGLnavGgUbgHDNrSs7p35jFPov9rU92GHiHu48l59k/JAK3UnoJ8Afu/uPkO/ZnwM+IgCcvTVxbjbj7PqIDueixyCLd+kXAbyXXEqPE9U0N8IQ5tu0+d/+L5DjzGeAI8J/ufre7p4nA+NI5vu5crvcK/Yu7fyn5vD5CBB8XT7Hte4EX20Qm1cuB/3D3vdPsPwe83t2Hkr+H5wM/c/f/k3z+R4iO9edbaVIGH74mdffx5L6/cvf/cfdc8h7agfwo1zhxjbo5ec4P3P3gdC+gAGwJSEZIvgi8EXgy8DdFNtsI3DfpvnuIP4jCfe0r+HGQGNmZyb5JP0/5vGT/nyR6Ckj+/UDBH/BUdhf8/wygHtiXDOf2ExcwNcT7XKjdRe6b7j3+IdHL8j7giMWk421T7Pt48m9H4Z3u/j53v8Tdryc+p3cSwfGbgYPJ/ceAN03aX3tyv8hy8SJgDPhI8vMngUPESFKh2Rx3Jh/PZj153swazOxPLFKLTibHmXOIEbe5KDye7Ej+/V7+2JXsdzPRg7tQcz12/SORrv6HxLHrPyxJhxQpofx5+bRMFHf/MvC/iHPdgSQF7FGz2Gexv/XJHkguhgufU4prhEKzubY6lHQe5013bdVLBKQP79Mje2jPpH3Oxv5JPw9Pum+YiWPibF931td7k8zleR8jrvEeZ2YNRCbDadNqJjmQBI15ZxCZRYXH2c8DTkzdWKhpj7Xunq+UmX+PL0xe+7+TFMw/yadDTkUB2NLxXqK34jPuPvlLB9EDNXm4dztJruwsTR5Vm6/3Ai8ws+3AY4kRvLm89gFgBOh1986CW5O7f2iatg4QaUCF1s3wWjNy92F3/x13v4C4wMoSw/zFth0hetHPKfZ44r3A7yWB9UXAV5L7v0hBj1FyYDqDmOQssuSZmRGBVhNwn8Vc073EyPGLrbST7U85HljMDSkMrt5AHJ8eB3S4eydR9Mjm+DqTj10AZ086djW7+7uLbF+0rYlSHLuy7v5H7n45kXL0M+Djc9mHyCzcRlzsf7PYg+7+/qSTsQ/4BPBJM2vOPzzFPmfzt77JTi3gs4U4nkB8p+DU79Xk79RsXqMU11aFjgCjhftMRmw2L2Cf5XzdBZeTT0bn3keMfD0DGCIyhKYz+bM6AHxp0nG2w90b3f2hKZ4DM58Xpnq9aSWjii9z981EmudNRMfDlBSALR2fI+Y6/PoUj7+fqCZ2tcWk0acQo2XFqutN5QCRY7tQ/0UMP38E+LK73zPH538V+CmRQ9wHYGZdZvaMgoP2AWDHpKHm7wIXmtmVye/gViLXeUHM7Mlmdk7yRR0mgsPsNE/5N+LCrti+ng20uvtfJ3f9EnhC8j6eSPSs5V0HHCTytEWWg5uIi5cbgQsLbpcRab5PL+FrfRd4qpmtTeZmvptIh87rIEbijgC1ZvZKpu84mZG7308EOH+eT6k0szYzu9mSgkfEsWtz0sGS9z9Al5ndYlF16wYiTXNBzOyRZnapRdWwUaJXerpjl8ismdkaM3s9MS/mf7n7iSLbXGZm1yXfwXEmAqP8Be4BJtK45moVMTe0Pil48BsknaMe88J3E9dFtUmH8BsnPb/Yd3Gy9wP/K7kGqEuOE2cD/zSfBicjdh8AfteiYEYjMWffmTS3v5RK+LoL+bwK/RXR+fUmYvrMXAcA/ha41KL4SbOFjWb21BnaOtN5YV4sCoVsSDoZTxLF1qY91ioAWyI8/NdUObLu/s/EQfBviDS4twPPcvdvz+Fl/hg4NxnOnS4Xd8a2EsPJFzPzsHKx52eJYHMU+JZFtcIfEpNg870vf0WkJB5J2tudpDr8HlE58jAxl+Oj830fBbYSF1X9wEPAaiZSLIt5L/D4ZK7Lw5Jg8n9z6ry8dxEXfceJyaXvKnjsZcD/mceBSaRavZIYxf9aMh8pf/sR8GFOX3JjIf4E+AExEf3nROfGQwWP/zHRwbGX6AHeQGkKVDwned18pdWfE9/l/MjaPydt2Z8cuy509/uAVxMTyPuJUcKio+xz1EdcdB0jjonXE3NQReYrXyl5APg2MV/75mRuVDGtwHuINON+koIWBelk/x8RRB03sw/PsS1fJ1LAHiIySf4N+KOCx58PPCp53X/g9CIPp30Xi7zGHxPXVZ8gOmueDzzO3RcyWvUGooDEV4m0tsuBm9x9YNpnLVwpXnchn9fDkt/f54lgtti0mtk8/yqis/te4jP+HHBewWbvAG5J2vr15L6ZzgvzdSPxfRgkrle/QaR+T8niWlmktMzsaUQ1sA3JcPOKYmZvBzrd/bXzfP6FxAXp+bOYPyciIiKyZJjZnwIb3b2UmQ9LhgIwKTmLSn6fBz7n7m+vdHtEREREpDpYlKj/H+ApSfbSiqMURCkpM3s1kWowyKmpACIiIiKygiWpiz8m5n6tyOALNAImIiIiIiJSNhoBExERERERKZPaSjdARESml5RJfgSxyKbKiMtKVwOsBb7j7mOVbsxKpGOSyCnmfExSADYV/+KSz80cy43OvNEM6o8XW/N5Dmxhg6xWP+1C4jPyu7+3oOcDfGb1ws4t9w8MzrzRNHoaF/Y1fdZ7vrOg5wP4e78518VppbQeQZQPFpEJ1xIltaX8dEwSOd2sj0kKwEREqt9+gDvvvJMNGzaU9YW3bt368P93795d1teuJu/55A9P+fn1T7qgQi2RvXv3cu2110LyvZCKqNgxqVRuu+22h///4Q/PYUmre7f+/+3deZgcVdmw8ftJJglLdnYIEAIiCCoKuIKCoIgLLiwGFNleEAV9EVRWNYgK4vLh6wKKQBDEsLiAC6BgEFBBQFEhSIQQIpAoMNmBrM/3R3VCz2Qms2Smq7tz/66rr0ydOqf66c70mX7qnDrVdnvbtbdfVKE3fZIJmCTVv2UAY8aMYezYsaUFUeZzl23kRk+32V6b34s64tS38tRFn7Qm1l133ZU/9+g1tJ9c1KCvX/2i232Si3BIkiRJUo2YgEmSJElSjZiASZIkNYmI+HpE/Dsi5kXE4xFx5mrqHhwR0yJiYUT8JiK2qGWs0trKa8AkSZKax8XA5zJzYSWh+k1E/Cszr6muFBE7ApcC7wP+AJwPXAW8udYBqxzLli2jtbWVJUuWlB1K3RswYADrrbcew4YNI2LNF4Y2AZMkSWoSmfnPdkXLge06qPoh4MbMvAUgIs4C/hsR22bmo/0cpupAa2sr66yzDhtuuGGfJBXNKjNZtmwZ8+bNo7W1lQ022GCNj+kUREmSpCYSEadFxALgCWAocGUH1XYGVt5fITPnAtMr5dXHGhkRY6sfQGOuPa82lixZwtChQ02+uhARtLS0MGrUKBYt6pt7vzsCJkmS1EQy87yI+AqwC/BeYHYH1YYCc9uVzQGGtSs7Cfh8nwbYUyfs1nWd79zb/3E0IZOv7uvL98oETJKkLnzkbS8rOwSpRzIzgb9GxH7A2cDJ7aosAIa3KxsBzG9XdgEwsV3ZGOCOPgm00Yw10dOaMwGTJKkLW4xev+wQpN5qAbbtoPwB4JUrNiJiOLBNpXylzJxDMTJGVd2+jrFxrLNr2RGoCXgNmCRJUhOIiEERcWzluq0BEfFa4ATg1g6qXwnsHxFviYh1gXOAu1yAQ/Vir732IiK4++6725SfeOKJRAQTJ04sJ7A+YAImSZLUHBI4CJgGzAOuAP4P+BZARCyIiD0BMvMh4BjgB8CzwI7AYSXELHVq++235/LLL1+5vXjxYq699lq23bajQd3GYQImSZLUBDJzaWbul5mjM3NoZm6fmedWrgejUnZHVf1rM3NcZq6XmW/LzCfLi1514Z/Ru8djq5ma+diuL9broQ9+8INcd911K1cfvOGGG9htt93YdNNNV9a57LLL2HHHHRk1ahT77rsv06ZNW7nv5JNPZsstt2T48OHstttu/OEPf1i5b8KECRx44IEce+yxjBgxgm233ZYbb7yxxzH2hgmYJEmSpLqz8cYb89rXvpYbbrgBgIkTJ3LkkUeu3H/99ddzzjnncN111/H000+zzz77cPDBB1M558Cuu+7K/fffT2trKwcffDCHHHJIm6Xkf/nLX7L//vvT2trKSSedxNFHH83y5cv7/XWZgEmS1IV7Hvlvm4ektdSc77d9qN8dccQRXH755cyaNYt77rmHAw44YOW+iy66iFNPPZWddtqJlpYWTj31VKZOncrUqVOBYgRtgw02oKWlhc985jPMmzePRx55ZGX717/+9bz//e9n4MCBHH300cyaNYunnnqq31+TCZgkSV34xb2Pt3lIWkvN+kjbh/rdAQccwD333MPXvvY1DjroIIYMGbJy3+OPP84pp5zCyJEjGTlyJKNHj2bp0qU8+WQxm/b8889nhx12YMSIEYwaNYqFCxfyzDPPrGxfPZVx/fWL1W4XLFjQ76/JZeglSZIkwQ7Z98fc5r41aj548GAOOuggvvGNb6yyIuKWW27JqaeeyhFHHLFKu9tvv53zzz+fyZMns9NOOxERjBgxYuX0xDI5AiZJkiSpbn3uc5/j1ltvZffdd29Tfvzxx3PeeefxwAPF7evmzp3Lddddx/Lly1mwYAEtLS1stNFGLF26lAkTJrBw4cIywl+FI2CSJEmS6tYmm2zCJptsskr5+973PhYsWMChhx7K448/zogRI9hrr7048MAD2W+//XjHO97B9ttvz9ChQznllFPYbLPNSoh+VSZgkiRJkurKbbfd1um+O++8c+XPhx9+OIcffvgqdQYOHMill17KpZdeurLslFNOWfnzhAkTVmlTq+mJTkGUJEmSpBoxAZMkSZKkGjEBkyRJkqQa8RowSVK3HDPxnrJDKM0zT89ps702vxf97ZIjd++6kiQ1MEfAJEmSpLVQPdwTq1H05XtlAiZJkiStZQYNGsSCBQtMwrqQmSxdupTZs2czZMiQPjmmUxAlSZKktczo0aNpbW1l/vz5ZYdS9wYMGMB6663HsGHD+uR4JmCSJEnSWmbgwIFstNFGZYexVnIKoiRJkiTViCNgkiR1YejQdcsOQVI92PR7ZUegJmACJklSF9ZZt28uvJbU4EYeV3YEagJOQZQkSZKkGjEBkyRJkqQaMQGTJEmSpBoxAZMkSZKkGjEBkySpC0uXLG3zkOpRRAyJiEsi4vGImB8Rf4uIAzqpu1dELI+IBVWPY2odc8N54b62D6kXXAVRkqQuzJmzoM32hhuNLCcQafVagH8DbwZmAPsB10bEqzNzagf1/5uZm9YywIY3fbe22ztkOXGooZmASZIk1aGI2AZYlpkzulM/MxcCE6qKboyIqcDuQEcJmKQSOAVRkiSpDkTEpRGxR+Xng4F/AdMiYnwvj7cRsCPwYCdVNoiIWRHxWER8MyKGdnCMkRExtvoBjOlNPJIKJmCSJEn1YX/gL5WfTwYOBd4JnNHTA0VEC3AlcHVm3t9BlX8CrwQ2B94CvAr4Zgf1TgIea/e4o6fxSHqRCZgkSVJ9WC8zn4uIYcAOwE8y82Zgq54cJCIGAFdUNo/rqE5mzsrMKZm5PDMfAz4DHNhB1QuAbdo99uxJPJLa8howSZKk+vB0ROwI7AzclZnLI2J9oNsrPUREAJdQjGztn5mLu9k0gVilMHMOMKfdc3Q3HEkdMAGTJEmqDxcA91Z+XnHd15vo/BqujlxIcd3XWzPzuc4qRcTewDSK1RLHAOcBP+thvJJ6wSmIkiRJdSAzv01xXdZOmfmLSvGjwPHdaR8RWwMfAXYBZlbd3+uMyv4FEbFi+uCrgD8CCyv//gP4eF+9FkmdcwSsF3760z9yzTV3QsBnzxrPTjv1aGp2nxyjJ+2PP/ZCHpryBB88/M0cd/zb2uy7/md3c+F3b2bzzUcBcO75h7PJJiNXOcbhJ17F4sXLGDx4INuP24jPnvzWNvvvuHsa3/7BnQwa3MJ66wziK597F6NGrLva13D4CT9i8eKlDB7cwvbbbsRnT37baut/+rPXMus/c1n4/GIOePsrOfKDb2yz/7HHn+H0s3/CoJaBLFm6nAmnvZuXdnCcb143hev/MIOtNxnKZaftAcCU6XM454q/MXBAMHBA8MVjXs2WG6+/StuLzvgTTzwylze9dxxvO2z7leV33zyDa775N77+63ev9jX89Jz7efqx+ezyjjG89qBtWLJoGTd/awrPz1vCOkNbeOsJO7LO+oNWe4zLP3sfTz06j9cfsDV7jR8HwF9vfYr7b32KzGTX/cbwyr02W+0xXrLxljz4uR+z9/87geW5nO8ddiov2XhLtvvcQTw55+nVtm1mETEE+C6wLzCa4uzwZzPzhsr+nYEfAK+o7PtoZt5R2XcE8AngJcB84GrgtBXTfyLiEIqL2XcB/pyZe9XqdUlqHJn5SLvtbi8fn5mP08E0wqr9Q6t+/gbwjd7EKGnNmID10Ny5C7niyslcPelU/vPfOXzmM5fx46s+XdNj9LT9hHMO5e4/Pcx//jO3w/3vP/B1qyRmHfnmF9/DphsP73DftltvyBXfOYzBg1u46qd/4YdX38P/Hvemro/5pfd1esz2vvS59zF4UAtLly7jHQf/Hwe9dzeGrj9k5f4ttxjFjy85jojgT/c8yncvuY1vHrH9Ksc5dN9xvP9NW/O5S/+6smyjketw8afewNB1B/H7v83iWz99iPOP322VtuM/uQtT//o0c555YWXZksXL+PudMxm18eoTToC3fmwHZvx9NgueLdr/47dPscm2w9j9fWN5+A//4b7rZ/DGw7Zd7THe+7878ej9zzLvmUUA/OfxBTx6/7Mc+aVduz0v/7PvOJrf/6t4/Q8+NY3Xf/VYfvmxr3erbZPr9CamFCt//QK4qLL/IOD6iNg2M2cD61EkWH+mSN5uoFi5bELl2K0U04t2oFhxTJLaiIhNgC8CrwGGVe/LzHGlBCWpzzV9AhYRg4CbM7NPvvD8/e/T2XXX7Rg8uIUtx2zIwoUvsHjxEgYPXv2oRV8eo6ftN9105GqP94vr7+EPdz7E7q95CR878e0MGLDqzNQgOPnzNzCoZSAfPfINvG7Xrdvs33zTF5OowYMGMrCl69mtEXDy565/8Zi7jV1t/cGDil/XRYuXstmmI1h3nbavt6Vl4MqfFy5cxEtfsmmHx9l45Do88fTCNmUbjVznxedpGcDAgR0nMiM3WjXJuv3n03jDO7fm5xc9sNr4AYZtsE6b7Tkzn2O7124EwKbbDef+X/27y2OM2LDtMR78w38YPGQgl3/2Pgav08I7j99hlTrVXjN2J2bNe5Zly5cDMO+FhZ3WXdt0cRPTrYF1ga9m5nLgRxHxCeD9wCWZeWFVu5kRcQWwckg0M28BiIj/6d9XIamBXQ4MB74PLCg5Fkn9ZG24BmwAxdnqDnV0g8GIGDtnTsf93pw5CxkxfL2V28OHrcecOZ1e49ovx+iLGFbY+y0v5+e/PJ1LL/84Tz3Vyq9+eV+H9b75xfdw1YUf4ryz3smEr/6GBQsXdVjvmdaF/Ognf+HQ972qy+f+5hffx1UXHc55n30XE752c6fHrPaJU3/Mvu/5BrvusjUDB6766/vAQ0/ygaO+x9lf+QV7vG67Lo/X3nOLlnLBdVM45h0v6V79+YuZ9o9Wdnpdx8leVzbYan2m//VZAKb/5VleWLC0x8eY37qI5+Yv4YhzdmXXt23BTZesfrbKmfsfyXk3/7BX8a5t2t3EdGfgH5Xka4X7K+Ud6emF8yue05ueSmuv1wFvz8zvZObl1Y+yA5PUd5oiAYuI33X2AH7TRfOTWPUGg49dcMF1HVYeMXJ95s1/fuX2/AXPM3Lkeh3W7cyaHqMvYlhh+Ij1GDhwAAMHDmD//V/Ngw+8OALz4x/dweEnXsVZ597IqMrxN9tkODu8ZCNmPDlnlWMtWLiI/z3z50z49H5sMGrV66cArrzuXg4/4Uecde6v2x5zu42Z8cTsVetffReHH/cDzjynWJjp/75yKL/7xSncdufDPDLtv6vU33nHLbj6so/wna9+kHPO/+WLx/ntoxz+5Ts465K/rNJmhSVLl/PJb/+ZY9+1Pdtt0b1pkbdc/S/eckjPE72V8b5lc5YtWc51n/8LC1oXsf7owT0+xrpDB7HdqzcgItju1Rvwn8fnd1r3HTu/gXsff4jWhfN6HfPaooObmA4F2s/jnUO7aUKVth8G9qBYVaynTsKbnkprq/8Ay7usJamhNcsUxNcC5wIzO9g3iOKLUGcuACa2LzzppIMe66jyK18xlgsuuJ4lS5bx9NNzWW+9IT2aftgXx+iLGFaYN+85hldG0+6++1+M3WbjlfsO/eCeHPGO7chMFixcxND1h7Bg4SKmPvp0mymHAC8sWsKJp/+M4494Pa/cafNOn+9DB+3Ghw7areNjbjZi1fofeB0f+sDryEwWL1nK4EEtDBncwjpDBjFkSNtf30WLljBkSPE+DBu2Tpspih9667Z86K2dX1u1fHnymYvuZd9dN2ffXTuPv72nn1jILdOmcsuPYV7rIi7/0r0cceaq1451ZuCgAez9P8VSIf/47ZMM3WBIFy1Wtc3LR/HQn/4L+8FTj8xj9KadJ+O7jNmevbZ/NW8Y93JevsW27LDp1nzgB2cxo3VWj5+3mXVyE9MFFFODqo2gWHCjuu0BwNeAt2Vmb97YC1i1TxqDSZi0NjgV+HZEnJqZ/yk7GEn9o1kSsPuBf2bmKsNWVauadaijGwwWOyZ3WH/EiPU57LA3c/jhX4eAM8/4QI+DXdNj9LT9hM9N4m9/nc7ixUt58IEZfPSEt/OnP07lqGPewsRLJ3PXnx6mpWUgY8duxIGffNcq7ZcuW86HP/5j1hnSwtKlyznx6D0YOby4FupTE37B1ya8mx/95C/885H/8v0r7+L7V97FG3cfy/FHvKHTmJYuW86HT7yqcsxlnHjMi8fsrP4xJ0wEYMnSZbx935ez5RajATjlrGv4+hcP4U/3TOPiy29feQ3bGae8E5Y9tcqxrvzto/z6rid49Kn5HHXenZx91C5MeXwuv//bLJ6Zt4gb/vhvth8znM9++JWrtL36/93PY1Nms2zJMv49dQ7HTHjNyn1fOvKWLpOvWy58iKcenseypcv5z6PzeeNh2/K7ix9mwIBgw62HsueHV78AB8DP/+9BZvxzDsuWLOfJR+Zy2Jm78K+/PMMlp91DZvKeE3fqtO2Xb5rIl28q3sfLPvxZfvCHGxjSMojf/u+3eOWY7fjxMedw1T2/4aLbf9plHM1qNTcxfQD4TEQMqJqGuAtwcVXbtwOXAu+qjJr1mDc9rU/rrNPz0WmpOyJiOW1vtBzA4e0/95k5EJVvxLFlR6AmEJndvrl63YqIg4FnM/N3HewbABze4/nTObnh35hFy1/oulIXBs/uaFCxB2LNZrnG4I6nMnZXTun4mraeuHGTZWvU/vH5a3Yd9QbrrNl5kg984541ag+QF9611mQAEXERRWL11sycX1U+CJhKcULn/ygW3/gOsF1mtkbEW4Brgfdn5u87OO5AihH5I4HDgLcBy6sSvNXFNBZ47LHHHmPs2LFr8vJ6rPpL4NGX/bmmz6210yVH7r7a/dOnT2ebbbYB2CYzp9cipv4UEZ1ep16to36lLDXvk07oxsyS79zbdZ0qe++998qfJ0/u+KS71B296ZOaYgQsM69dzb7lFKsKSdJqVd3EdBHFSoYrdn05M79cmV74A+ALFPcBe29mtlbqfJZiSuKvqto9npkrhiQPBy6rerrngd8De/XPq5HUCKoTq4h4ZWb+rX2diHhFbaOS1J+aIgGTpL7QjZuY/oPimtOO9u3dUXnV/ol0cL2pJFW5g1WvNQW4jeL+gpKaQLOsgtgSEZ+LiJsj4hsRsXG7/f8oKzZJkqRuWuUEUEQMpu01YpIaXLOMgH0F2JNi1bI3AfdHxH6Vs9UAY8sKTJIkaXUiYjJFkrVO5RY61bYGenaBk6S61iwJ2CHAbpUlW79VuQfPbyPi3Zl5D545kiRJ9eu2yr9vpLg2dIXlwCzg6loHJKn/NEsCNhxYcSE8mfnDiJhDcTH8gaVFJUlqCs88PafN9oYbjSwlDjWnzDwbICL+lZlXlR2PVuOf7WaJ7uA5fvVcsyRg/wJeA/xhRUFm3lAZCfsZsE5ZgUmSJHXHiuQrIkYBw9rtm1FKUJL6XFMswkFxT56d2xdm5k0U0xPvrHlEkiRJPRARr4uIR4BngMcqj+mVfyU1iaYYAcvMH65m3++AVW7QLEmSVGcuAn4NfA9YUHIskvpJUyRgABExAng/xUjYMGA+8ADws8ycU2JokiRJ3bEt8OrMXF52IJL6T1NMQYyIPYBpwEeA9SkW5FgPOA54JCLeWGJ4kiRJ3fF3YKuyg5DUv5plBOy7wMc7WjkoIg6lGNJ/ec2jkiRJ6r4rgesi4qvAzOodmXl7OSFJ6mvNkoBtC1zbyb6fAD+oYSySJEm98Z3Kvz9uV57AwBrHIqmfNMUURIoh+//tZN/HgX/UMBZJkqQey8wBnTxMvqQm0iwjYMcCN0TEyRTJ1lyKmzO/HHgBOKDE2CRJkiQJaJIRsMx8ANge+DBwI8WI2E3AEcBLM/PBEsOTJEnqUkQMiIiTImJKRCyo/PvJiIhuth8SEZdExOMRMT8i/hYRnZ6EjoiDI2JaRCyMiN9ExBZ992okdaZZRsAAxgIbAb/LzL9X74iI0zLzvFKikiRJ6p5PAx8DzgceAbarlA0BuvM9pgX4N/BmYAawH3BtRLw6M6dWV4yIHYFLgfcBf6g851WVtpL6UVOMgEXEu4G/Ap8C/lQ5+1OdXJ5RTmSSJEnddgzwrsz8TmbenJnfAd5VKe9SZi7MzAmZOT0zl2fmjcBUYPcOqn8IuDEzb8nM54GzgNdFxLZ99FokdaIpEjDgC8DBmbkrxUjYFsAvImJIZX+3hu4lSZJKtBEwpV3ZP4ENe3OwiNgI2BHo6FKMnYG/rdjIzLnA9Ep59TFGRsTY6gcwpjfxSCo0yxTEcZl5E0BmPh0R76S4l8aNldExSZJ6raXFRehUE1OAo4GLq8qOBB7q6YEqM4GuBK7OzPs7qDKUYtGyanOAYe3KTgI+39PnB+CE3bqu8517e3Xo0gx5ddkRqAk0SwI2OyK2zMx/A2Tmsog4DLgE+C3eO0OStAZGjmr/nVTqF6cCN0fEMcA0YBuKFZ3f3pODRMQA4IrK5nGdVFtAsWJ0tRHA/HZlFwAT25WNAe7oSUxNY5v7yo5ATaBZErBbgKMopiICkJkJHB0RFwGvKyswSWoWlxzZ0WUkkvpKZt4ZES8DDgW2pFjVeXxmPt7dY1RWTLwE2BzYPzMXd1L1AeCVVe2GUyR8D7SLaQ7FyFj1c3Q3HEkdaJYE7GN08loy8/iI+HKN45EkSeqxSrK1Jis3X0hx3ddbM/O51dS7Erg7It4C/Ak4B7grMx9dg+eW1A1NkYBVzu50doaHzJxRw3AkSZJ6JSL2BHaj3bVYmfmFjlu0abs18BFgETCzaqTqy5n55YhYQDEqdkdmPlSZ6vgDYFPgTuCwvnslkjrTFAmYJElSo4uIc4GTKaYBVo9eJVWXWXSmMnrW6fzAzBzabvta4NpeBSup10zAJEmS6sOxwGs7WbVQUpMwAZMkqQsX3tz2Nkof3W+nkiJRk1tIu0UwVGce27XttqsiqhdMwCRJ6sLM2atby0DqM18DPhcRn6+s5qx6s+gvZUegJmACJkmSVB9+TnFrnU9GxNPVOzJzXCkRSepzJmCSJEn14WrgCYqbHzvsKjUpEzBJkqT68Apgw8x8oexAJPWfAWUHIEmSJAAeBEaXHYSk/uUImCRJUn24EvhpRHwDmFW9IzNvLyckSX2t9AQsIgYAOwBTM3Np2fFIakz2JZKawDcr/05qV57AwBrHIqmflJ6AUXQq9wJDu6ooSathXyKpoWWml4ZIa4HSP+iV+1w8CmxSdiySGpd9iSRJagT1MAIG8P+AH0fEBGA6sHzFjsycUVJMkhqPfYkkSapr9ZKA/aDy7+8ophEBBM55ltQz9iWSJKmu1UsCtk3ZAUhqCvYlkiSprtVFApaZj5cdg6TGZ18iqdFExC2ZuW/l55My84KSQ5LUz+oiAQOIiNHA7sDGFFOGAMjMH5YWlKSGY18iqcHsXvXzF4ALSopDUo3URQIWEXsDP6O4TmMYMJ9iKel/A35pktQt9iXqL18Yv3vXlaTe+UdEXAf8HRgSEZ/rqFJmfqG2YalDO2TXdaQu1EUCBnwFOD8zvxwRszNzVER8CZhZdmCSGop9iaRGczhwGrAnxe2B9u6gTlKMjklqAvWSgG0PnF/5ecWUoS8CDwHfLiUiSY3IvkRSQ8nMx4CPAETEPzOzowRMUhMp/UbMFYt4MRmcHRGbVn7esKR4JDUm+xJJDSszdyg7Bkn9r14SsHuA/So//w74EXAtcH9ZAUlqSPYlkhpWFE6KiCkRsaDy7ycjIrpuLalR1MsUxP/hxZukforiOo7hwCfLCij/cusaH+OR7UavUfvtFg9fo/ZDNuiDWyL1xTFKFK/Zr+tKXXhHH8RRpkO++/6yQ6iluutLJKkHPgN8jGIq9SPAdsCngSHAeSXGJakP1UUClpmzqn6eDRxXYjiSGpR9ifrL9fdMb7P9nt3HlhKHmt4xwLsy8x+V7Zsj4vcUq7t2mYBFxInAUcDLgasy88hO6u1FMUvguari/83MS3od+dpiZrs/K5t9v5w41NDqIgEDiIg3AEcCm2XmuyPi1cB6mXlnuZFJaiT2JeoP9z36dJttEzD1k42AKe3K/kn3r2N9CjiHYir2ul3U/W9mbtpFHbU39+K22yZg6oW6uAYsIj4A/ApYCry5UjwAl1yV1AP2JZIa3BTg6HZlR1Ks5NqlzPxpZv4ceLZvw5LUl+plBOws4J2Z+ceIOLRS9g9g5xJjktR47EskNbJTKaYdHgNMA7ahmE749n54rg0iYhbwPHADcGZmLmhfKSJGAiPbFY/ph3iktUZdjIABW2bmHys/r7jF+GLqJ0GU1BjsSyQ1rMpU6R2BnwOzgeuBnfphCvU/gVcCmwNvAV4FfLOTuicBj7V73NHH8UhrlXr5UjI9InbJzPuryl5NcfZHkrrLvkRSQ8vMGfTzioeVBYtWLFr0WER8BriJYhGQ9i4AJrYrG4NJmNRrpY6ARcR1laHtbwA/jYijgJaIGA9cCXy9zPgkNQb7EklaIwl0eK+xzJyTmdOrH8ATNY1OajJlT0Fcj+IGqdOAsymGuVuALwMXZuaPS4tMUiOxL5G01ouIlohYh+J+iAMjYp2IGNRBvb0jYuvKjZ+3pBhx+1mt45XWVqUmYJn5DuBrwI3AWGCXzFwvM8dl5v+VGZukxmFfIklAsRDR88BpwIcqP18MEBELImLPSr1XAX8EFlb+/Qfw8ZpHK62lSr8GLDO/HRG/A34EvDMiHmi3v/1yrJK0CvsSSY0sIloobh5/aWa+0JtjZOYEYEIn+4ZW/fwNiinbkkpQ9hTEFYIiGYwOHpLUXfYlkhpSZi4Fzu1t8iWpcZQ+AhYRnwC+RHEm5uzMXF5ySJIakH2JpCZwd0Tslpn3lh2IpP5TagIWEb+iuEHqOzPz9jJjkdS47EskNYk7gZ9HxA+A6cDKE0mZ+cOygpLUt8oeAVtEcbH87JLjkNTY7EskNYOjgCXAEe3KEzABk5pEqQlYZr6/zOeX1BzsSyQ1g8zcpuwYJPW/skfAJEmqex9528vKDkFrkYgIYNPMnFl2LGpnrJfnac2ZgEmS1IUtRq9fdghaC0TEesAFwIeBZcD6EfEeYOfM/FKZsalinV3LjkBNoF6WoZckSVrbfRXYGngzxbVgAH8BDi0tIkl9zhEwSZKk+nAA8MrMbI2I5QCZ+e+I2KLkuCT1IUfAJEmS6sMgYF51QUSsCzxfTjiS+oMJmCRJUn24B/hIu7IPA3eVEIukfuIUREmSunDPI/9ts737dhuXFIma3KeB2yPiEIoFOG4CdgPeUG5YWmnO99tujzyunDjU0EzAJEnqwi/ufbzNtgmY+kNm/jMidqS4EfODwCzg2Mz8d7mRaaVZ7QYoTcDUCyZgkiRJdSIznwW+UXYckvqP14BJkiTViYg4OCJujIgHIuKmynRESU3EETBJahLHTLyn7BAkrYGIOBk4E7gY+DkwFvhuRGyZmV8vMTRJfcgETJIkqT58HHhHZt69oiAifgZcC5iASU3CKYiSJEn1YSTFUvTV7gOG1z4USf3FBEySJKk+/JTivl/VPlQpl9QknIIoSZJUkoi4tGpzHeB7EfER4DGKa8B2Ba4rITRJ/cQETJIkqTxR9fMi4Kqq7YcrD0lNxARMkiSpJJl5VNkxSKotrwGTJElqAhFxYkTcFxGLI2JiF3UPjohpEbEwIn4TEVvUKExprWcCJkmSVAciYseIuDUi5kbEsupHNw/xFHAOcElXzwNcChwHbEgxzfGq1bWR1HecgihJklQfrgCmUqx8+FxPG2fmTwEiYjdgzGqqfgi4MTNvqdQ/C/hvRGybmY/2OGpJPWICJkmSVB+2B16bmd0d8eqtnYE/r9jIzLkRMb1S3iYBi4iRFPcnq7a65E5SF0zAJEnqwrt327rsELR2uBvYjv5f+XAoMLdd2RxgWAd1TwI+38/xrLkTdutZ/alVb3FP2n7pe30Ty3fu7Zvj9JXuxNOM+ur/qodMwCRJ6sLu221cdghaOxwNXBoRtwAzq3dk5g/78HkWAMPblY0A5ndQ9wJgYruyMcAdfRhP4xh5XNkRqAmYgEmSJNWHDwBvAV5B22vAEujLBOwB4JUrNiJiOLBNpbyNzJxDMTpGVf0+DEVa+5iASZIk1YfTgHdm5k29aRwRLRTf7QYCAyNiHWBZZi5pV/VK4O6IeAvwJ4qVE+9yAQ6pNlyGXpIkqT4sA36zBu3PAp6nSOQ+VPn5YoCIWBARewJk5kPAMcAPgGeBHYHD1uB5JfWAI2CSJEn14QcUidHFvWmcmROACZ3sG9pu+1rg2t48j6Q1YwImSVIXnmxd2GZ7i9HrlxSJmtwbgU9FxMmsugjHW8oJSW28cF/b7XV2LScONTQTMEmSuvC930xps/2F8buXFIma3OTKQ/Vqertly3fIcuJQQzMBkyRJqgOZeXbZMUjqfyZgPfDNax7g+jsfZ+tNhnLZmW9eWX7MubczZfpsPvz2l/DR972sTZsZ02bz3fOLW2UsWbyMp2bM5ce3HLly/6wn5/H/zp5MDAgiglMm7M2Gm7SZpg3A4SdOYvGSpQwe1ML2227IZz+5b4cx3vWXGRz5iau57afHs9kGL5Y/+OAMzvnSNZDJIYfswfvf9/qO29/9MEcc+U1+P/lLbLrpqE7fi5/+9I9cc82dEPDZs8az005bdVq3v45Rdvt6iKHs9pIkSeoZV0HsgUPfui2XVyVeK3zpuN349GGv7KAFbDVuFOdddADnXXQA7z30Fbxxn3Ft9v/qugd52wE7cN5FB7DPO7fnF9escguOlb55znu44tvjO02+MpOJk+5l5x02XWXfOV+6hq+efyQ/vPyTXHHFbcyd+1zH7Sfeys47r/5L+Ny5C7niysn88Icn89WvHs0Xv3T1auv3xzHKbl8PMZTdvhlFxJCIuCQiHo+I+RHxt4g4oGr/zhFxV0Q8FxEPrFhRrLLviIi4LyLmRcSTEfGNiBhctf9rEfGvynEfjohjav36JNW3iFgeEcs6epQdm6S+YwLWAxuPWpcYsOrNBzfdYL1utZ9807/Ye/+XtCnbatwoFixYDMCCeYsYMXrdDttGwMmf/wVHfOJq7rrv8Q7r3PS7h9njtWNZd51BbcoXL17C888vZssxGzJ4cAu77rYtf//H9FXa33jTX9hjj5ex3rpDVvs6/v736ey663YMHtzClmM2ZOHCF1i8uP0tRlZvTY9Rdvt6iKHs9k2qBfg38GZgBMVSzldFxPYRMQj4BfAzYBRwLnB9RKwYKl4POAnYCNgN2BM4o+rYC4F3V477IeCrEbF3f78gSQ1lb4obMa94HA7cD5xQYkyS+ljTJGAR8eaIOL36bHXVvu+WEVO1eXNe4Inpc3jZK9uOTu3ymjHc9LMpnHjYtdz40yns954dOmz/zXMO4KoLD+O8M/dnwtd+y4LnFrfZv2TpMq795d855IBVR+Jmz1nI8GEvJnbDh63H3LltV/RasmQZ1133Bw45eI8uX8ucOQsZMfzFpHP4sPWYM2fVEbX+PEbZ7eshhrLbN6PMXJiZEzJzemYuz8wbganA7sBewLrAVzNzUWb+CPgX8P5K2wsz847KvpnAFRQrmq049ucz85+V494D3Aa8oaYvUFJdy8zft3tcBRxCcdJGUpNoimvAIuJo4KsUX2g+FhEfBw7MzHmVKh8CPtZJ25HAyPblrZNPYeSwdbjy5ke4+c9PsPUmQ/nicbut0r677rjlUfbYZxwRbUfQJn7rbg4/fnfesPc4fn/zI/zwu3/mo58pZjVd+ZO/cPPkqWw9ZiRfPO3tAGy2yXB22G5jZjwxm5dtv8nK41xz/d844G0vY/CggSvLrvzRbdx881/ZaquNmDf/+ZXl8+c/z4gRbZdQvuaaOzng3a9h8OCufyVGjFy/7fEWPM/Ikd0bBeyrY5Tdvh5iKLv92iAiNqK4QemDFGem/5GZy6uq3A/s3EnzN1XadXTcIcBrgB92sG8kq/ZJY3oQtqTmMh14RdlBSOo7zTIC9mlgv8w8ENgOmAFMjojRlf2rzht80UnAY+0fF1z1ZwA+tN92XPHZvdYo+QK4rYPphwBJMnzEOgCMGLUO8+ctWrnvQwe+miu+PZ5zTt2PBQuL8gXPLWbqtKfZfNPhbY7zr8ee4YbfTOF/Tr6WqY8+zWfO+RUHH/RGrvjhJ/nSFz/EuusO5qmnWlmyZBn3/eVRXvHysW3aT/3XU9zwiz9zzLHf5uGpT/LpUyeyaFHH09Fe+Yqx3HffIyxZsoynnmplvfWGMHjwoA7rdmZNj1F2+3qIoez2zS4iWoArgasz835gKDC3XbU5wLAO2n4Y2AM4r5PDf5diZO2GDvadxKp90h09jV9S44mIrdo9dqQ4wTy95NAk9aGmGAEDNs/MewEycxFwTER8Bbg9IvYBVneThguAie0LTzrsNY+1L7vy5kf49Z9m8OhT8znqS7/n7P/Zla02GcpnL76Xv059lsVLl/HAtNl855Q3tmk368l5LFm8jC23KS4VmTb1Gf569xMcePgufOCoV/Od8+5gwMBg2dLlnHD6m1YJcOmy5Xz441ezzpAWli5dzolHv5GRw4sphZ86+5d87fPvYsKn3ray/uEnTuL8z76TIUNe/DJ95hkHc/KnLoVMDjv0TYwYUYx0nPLpy/j6V4/i7AmHvtj+w/+Pr37lyDbtq40YsT6HHfZmDj/86xBw5hkf6Oy97dSaHqPs9vUQQ9ntm1lEDKCYQghwXOXfBcDwdlVHAPPbtT0A+Brwtsyc1cGxvwK8Gti73WjaChewap80BpMwaW0wnbbfWQKYBny4lGgk9YvIbPwbyEXEVOCdmfmvduVnA4cBYzKz49UtOpH3nbXGb8wj243uutJqbLe4/Xe9nokNtlmj9sVBmmWQVGsk9l7dKHJTiWKe8KXAOGD/zHyuUv5WiimDW6xInCLiLuDizLyksv12ilGzd2XmXR0c+2zgYODNmfl0D2IaCzz22GOPMXbs2E7rHTPxnu4estsuPeo1K39uhr8XvfW5SW3fW2/EXJ7p06ezzTbbAGyTmdNLDqdPRcTW7YrmZ2ZrKcGsRnf7JE7oxuyh79zbdZ3uHKeH9v75wyt/nvzel3a/4cfva7vd0Y2Y6/h1d6o78TSjPvi/6k2f1Czfrq+nSLTayMzPU3yRWv2yfpL0ogsprvt614rkq+I24AXglMpy9YcC21OsikhEvAX4EcX1px0lX6cDHwT26UnyJWntkZmPt3vUXfIlac01xRTEzPz0avadS7FctCStVuXs80eARcDMqkVzvpyZX65ML/wB8AWKaUHvrfqC9FmKKYm/qmr3eGbutOIYwGLgX1X7r8zM4/vxJUlqABHxua7qZOYXahGLpP7XFAmYJPWFzHyc1Szak5n/AF7byb7V3tMrM9eaaZySemx1/cfOwGiKEz+SmkBTJGCV1crOoLjnzoPAeZn536r9/8jMl5cVnyRJUmc6OoFTuc7qKxQ3ef9yrWOS1H+aIgGj6KD2pFi17E3A/RGxX+VsNcDYsgKTJDW+XbfdqOwQtJaIiKHAmcAnKK4x3SEz/11uVFppxLFlR6Am0CwJ2CHAbpn5H+BblXvw/DYi3p2Z97D6ZeglSVqt9+w+tuwQ1OQqK7AeRzHV8FHgLZl5d7lRaRWbfb/sCNQEmiUBGw6sXCkoM38YEXMoLoY/sLSoJEmSuhARb6O4f+Aw4BOZeXXJIUnqR82SgP0LeA3whxUFmXlDZSTsZ8A6ZQUmSZLUhZuApylunfPSjlZFdBVEqXk0SwL2fxSrBP2hujAzb4qIQ4CzSolKkiSpa7dTXC7xuk72J66CKDWNpkjAMvOHq9n3O+B3NQxHkiSp2zJzr7JjkFQ7TZGAAUTECOD9FCNhw4D5wAPAzzJzTomhSZIkSRLQJAlYROwBXE9xLdj9FAtyjKBYTeirEfGezPxD50eQJKlzn5t0T5vtL4zfvaRIpNWLiJHA94H9gXnAlzLzux3UOxK4BHi+qvi9mXlLDcJsXP+Mtts7uNC2eq4pEjDgu8DHM/Oq9jsi4lDgIsAbMUuSpGb3bYrvd5sD21LcluehzJzcQd17MrOz684k9ZMBZQfQR7YFru1k30+AcTWMRZIkqeYiYn3gYOCszJyfmfdTrKx4dKmBSWqjWRKwvwP/28m+jwP/qGEskiRJZdgeiMycUlV2P8X18R15RUQ8ExFTI+LzEbHKzKiIGBkRY6sfwJg+j1xaizTLFMRjgRsi4mSKZGsuxc2ZXw68ABxQYmySJEm1MJTiuq9qcygWJ2vvdmAn4PHKv1cDy4Fz2tU7Cfh8XwYpre2aIgHLzAciYntgL4qzPEOBBRR3lb8tM5eWGJ4kSVItLKA4AV1tBMXK0G1k5rSqzX9ExBeA01k1AbsAmNiubAxwx5oEKq3NmiIBqxgLbAT8LjP/Xr0jIk7LzPNKiUqSJKk2pgIZETtm5kOVsl0obsvTlQ6X86vcymdOdVlEdFRVUjc1RQIWEe8GrqLoeHaIiEnAR6pGvs4ATMAkSaXJTFpbW1m0aFHZodS9gQMHMnz4cNZdd92yQ2kombkwIq4DzomIo4BtKBbg+ED7uhGxP/CXzPxPROwAfBa4rqYBS2uppkjAgC8AB2fmTRGxEXAF8IuIeG9mLgI8VSNJKtX8+fOJCDbbbDNHEFYjM1myZAmtra0AJmE9dwJwMTCT4nqwCZk5OSK2AqYAL8vMGcA+wMSIGAr8B7gS+FJJMUtrlWZJwMZl5k0Amfl0RLyToiO5sTI6JklSqZ577jk23HBDk68uRASDBw9m9OjRzJ492wSshypTBg/uoHwGxTXyK7Y/BXyqdpFJWqFZlqGfHRFbrtjIzGXAYcB04LfAwJLikiQJgOXLlzNwoH+OumvQoEEsW7as7DAkqc81ywjYLcBRFFMRAcjMBI6OiIsA7/IuqeldcuTufX7MS4/q80Ou1Rz96j7fK0nNqlkSsI/RyWvJzOMj4ss1jkeSJEmSVtEUUxAzc3FmPrea/TNqGY8kSY1mr732IiK4++6725SfeOKJRAQTJ04sJzBJajLNMgImSVK/2WzUemWHUBPbb789l19+Oa997WsBWLx4Mddeey3bbrttyZFJdWLIq8uOQE2gKUbAJEnqTx/db6c2j2b1wQ9+kOuuu27lvcpuuOEGdtttNzbddNOVdS677DJ23HFHRo0axb777su0adNW7jv55JPZcsstGT58OLvttht/+MMfVu6bMGECBx54IMceeywjRoxg22235cYbb6zdi5P6wjb3tX1IveAImCRJJfncpHt61W6zUet1mgheePODzJxdzMr/wvieLcyy8cYb89rXvpYbbriBgw8+mIkTJ3LkkUfyzW9+E4Drr7+ec845h1/84he89KUv5atf/SoHH3ww9957LxHBrrvuyplnnsmIESP4+te/ziGHHMK0adMYMmQIAL/85S/58Y9/zEUXXcR3v/tdjj76aJ588kkGDPB8sKS1hz2eJEla6YgjjuDyyy9n1qxZ3HPPPRxwwAEr91100UWceuqp7LTTTrS0tHDqqacydepUpk6dChQjaBtssAEtLS185jOfYd68eTzyyCMr27/+9a/n/e9/PwMHDuToo49m1qxZPPXUUzV/jZJUJhMwSZK00gEHHMA999zD1772NQ466KCVo1cAjz/+OKeccgojR45k5MiRjB49mqVLl/Lkk08CcP7557PDDjswYsQIRo0axcKFC3nmmWdWtq+eyrj++usDsGDBghq9MkmqD05BlCRJKw0ePJiDDjqIb3zjG6usiLjlllty6qmncsQRR6zS7vbbb+f8889n8uTJ7LTTTkQEI0aMoLgtpyRpBRMwSZJK0tNrtLqjLxYJ+dznPsdBBx3E7ru3je/444/njDPOYNddd2XnnXdm7ty5/Pa3v+X9738/CxYsoKWlhY022oilS5fypS99iYULF65xLJLUbEzAJEnqwoU3P9hmu5lXQgTYZJNN2GSTTVYpf9/73seCBQs49NBDefzxxxkxYgR77bUXBx54IPvttx/veMc72H777Rk6dCinnHIKm222WQnRS/3osV3bbrsSonrBBEySpC6sWFWwmd12222d7rvzzjtX/nz44Ydz+OGHr1Jn4MCBXHrppVx66aUry0455ZSVP0+YMGGVNk5PVMNZ9JeyI1ATcBEOSZIkSaoREzBJkiRJqhETMEmSJEmqERMwSZIkSaoREzBJkiRJqhETMEmSasRV/7rP90pSszIBkySpBgYNGsSCBQtMLLqQmSxdupTZs2czZMiQssORpD7nfcAkSaqB0aNH09rayvz588sOpe4NGDCA9dZbj2HDhpUdiiT1ORMwSZJqYODAgWy00UZlhyFJKplTECVJkppERIyMiGsiYn5EPBkRH1tN3RMrdeZHxNURMbyWsUprKxMwSZKk5vFtihlOmwPvBM6OiL3bV4qItwKfr9TZAhgEfKuGcUprLRMwSZKkJhAR6wMHA2dl5vzMvB+4FDi6g+pHApdl5v2ZOQ84E/hARKxXq3iltZXXgElS/RsI8MQTT5QaxPTp00t9/jLNefqpNttr83tRtqrPwcAy46hT2wORmVOqyu4H3tZB3Z2BX6/YyMyHIgLgJcDfVpRHxEhgZLu2W0M3+qR5i7qOuDufpe4cp4eeX7r8xRB6cvwn222vM33VOnX8uju1tvZpffB/1as+KTN99OJB0RlNAEauje3rIQZfQ328Bz76/wHsAaQPHz7aPPYo+7NZbw9gT+CZdmX7A490UPdR4F3tyv7T/n2l+PtQ9v+1Dx+N8Oh2nxSVD5d6KCLGAo8B22Tm9LWtfT3E4Guoj/dA/S8ihgC7AzOBZTV++jHAHRRf7ModguueRoq3kWKF+ol3ILAZcE9m1nCIoP5FxKuAuzNzcFXZeODUzHxVu7p/A76SmVdVlT0PvC4zuxoBGwyMA/5F7/qkevhdqocY6iWOeoihXuLoTQw97pOcgihJda7Sod9ZxnNXpiQBPNEICXojxdtIsULdxftoyc9fr6YCGRE7ZuZDlbJdgAc6qPsA8ErgKoCI2AEIiqRqpcycA8zp5Ll6pR5+l+ohhnqJox5iqJc41iCGHvVJLsIhSZLUBDJzIXAdcE5EDIuIV1AswHFpB9UnAkdFxCsiYhjwReDqzHyuZgFLaykTMEmSpOZxAsX1KDOBm4AJmTk5IraKiAURsRVAZv4WOKdSZyawHPh4STFLaxWnIEqSJDWJypTBgzsonwEMbVf2Lbz3l1RzjoD13hzgbDqeF702tK+HGNa0fT3EUHb7vjqGmtccGuv3Yw6NE+8cGidWaLx4Vb/mUP7vUj3EAPURRz3EAPURR01icBVESZIkSaoRR8AkSZIkqUZMwCRJkiSpRkzAJEmSJKlGTMB6KCJOjIj7ImJxREzsRfshEXFJRDweEfMj4m8RcUAPj/H1iPh3RMyrHOfMnsZROc6GEfFMRNzVi7a3RcQLlSVtF0REj2+KGREHRsQDEbGw8jre3812C9o9lkVEj1dxqizJ+8uIaI2I/0bExIgY2nXLle1fEhG/iYg5lfiP6aJ+p787EbFzRNwVEc9V3pM9e9j++xExNSKWR8SRPXn+iNg+Iq6PiKcjYnZE/DYiXtbd90GNLyJGRsQ1lT7pyYj4WKV8y8rv5eyI+Hq7NhdHxHtrENtq+8zVfXYiYp+ImB4RMyNifFX5oIi4OyK27OfYV+lj6zXezvrjeo1X9SkiNouIGyq/ExkRYzuo88XK52JORFwYEYMq5S0RMalSflNEDK9q88GIuKAX8ZTSt/X2731ffqbqpe+M1XxnrXX/Uld9cmb66MEDeD/wXuBCYGIv2q8PTADGUiTA+wMLgO17cIwdgPUrP28BPAgc0otYLgNuB+7qRdvbgOPX4H18C/BvYI/K+7ARMK4Xxxlaef/e1Iu2vwauANYFRgO/B77SzbYtwEPAGZWfd6VYMefNPf3dAQYBjwGnAkOADwKtwKju/u5R3PdlH+Be4MgePv9rgGOADSqv5fOVeKK3/78+GusBXAn8FBgG7AI8DewNfBf4UqX8X8BulfpvBH5eo9g67TO7+uwAU4C3AjtVygdWys8APlmD2Nv0sfUaL530x/Uar4/6fQCbAB8DXk9xL7Kx7fb/D/BI5fO8IfAn4OzKvkMovlsMBq4CPlUpHwncBwzrRTyl9G308u99X36mqJO+k06+s5bRv1BHfXLpH9ZGfVDcMX5iHx3rL8AHe9l2C+AfwBk9bPdm4E7gKMpJwO4Eju2D9+4IYBq9SBYoEqh3VG3/L/CrbrbdCXgeGFBVdhlweU9/dyof7lntjnU3cExPf/cq7+uRPXn+DvYPp/jDucWa/v/4qP8HxR/pRcDLqsq+QnFy4kbgbZWyH1f+aLZQfGnaqsSY/1L5Q7naz07lMzq48vNMYGNgG+APK/6Q9mOMq/Sx9RpvZ/1xvcbro/4flX6iowTsD8DHqrb3B/5d+flU4MuVnz8CfLfy80XAgb2IofS+rf3f27I/U2X3nVR9Z611DNRZn+wUxJJFxEbAjhRnBHrS7rSIWAA8QTEKdGUP2g4Gvk0xapI9ed52vhgRz0bEHyPiLT14/oEUoy6jo5g291REXBYRI3oRwxHAD7Py6eihC4DDImL9yv/DQRSdcndEu39X/PyKXsSxM/CPzFxeVXZ/pbwMb6I40zOzpOdXbW1PcQJjSlXZ/RS/fw8Ab6lMBdqVop86GfhJFjd1rbl2fWZXn50HgH0iYmdgOfAM8H8UZy6X9WOMnfWxdRdvF/1x3cWrhrcz8Leq7fuBMZXftweAPSJiHYovyw9GxGuBzTPzJ714rnrs20r7TJXZd3bynbVmMdRjn2wCVqKIaKH4Jbw6M+/vSdvMPI9i6PzVwA+B2T1ofhpwS2b+rcuanTuV4izA5sD3gF9ExEu62XYTimHf8RRTX15GMRXhgp4EEBFbU3TSl/ekXZU7KYbG5wL/pZhCeGE32z4MPAmcGRGDK38k3ges14s4hlZiqDaH4v+3piJic4r34FPtOiQ1r6HAvHZlcyh+/86l+JzfQTFlZwGVaTVRXLtxe0R8sVaBdtBndvXZOZaiv7sE+DDFtKAZwKwornv8fUQc3A+hdtbH1mO8q+uP6zFeNbb2v1NzKv8Oo7gs4I/Anyn6monAN4BPRMQnKv3NVRExsgfPVW99WymfqbL7zk6+s9Yyhrrrk1t600hrLiIGUAyDAxzXm2NURn3+GhH7Udy1++RuPO92wJEUc6F7LTPvrtq8PCIOBd4F/L9uNH+u8u+3M/OJSlxfBH7ZwzAOB+7MzMd62G7FWd+bgB9QzPlev/LzN4ETu2qfmUsi4j0UZ0I+QZGQTaR3o1YLKKb9VRsBzO/FsXotIjYEfgtckpmX1fK5VapOf/8ysxX4wIrCiLgeOIVi5HkgxQmQ30TE2zPzpv4MspM+c7WfncoXjTdX2g8DJlNcK3kxcDXwK+CBiLi18lr7Is7V9bF1Fy+r74+/XIfxqo5ExAcpTsICPJ6ZO3XRpP1nYMXMl/mV7zSnVR5ExCnADRR/n48DXkVx8ndlnR4+14rnK7Nvq3kfUC99ZwffWf9dixjqtU92BKwEEREU2fTmwPsyc/EaHrIF2LabdfcANgWmRsQsioTj1RExKyKGrEEM3Z4CmJlzKD54azL9EYqzEb0d/RoFjKH40rGo8sG5FHh7dw+QmQ9m5j6ZuWFmvpHiTHKPV5SkGOJ+eaWTXGGXSnlNRMQoiuTr15k5oVbPq7owFciI2LGqbBfa/f5FxPuAmZn5J+DlwL2VP6j30rupt922mj6zJ5+dLwJfy8y5vBj/XIopMdv1Ybid9rEUF3TXVbxd9Mf1+P6qjmTmjzJzaOXRVfIFxe/OK6u2dwGeqPyurBTF6nIHUYyA7Qz8PTOXAPfQ/f6mHvu2mn6m6rTvXPGdtVYx1GWfbALWQ1Esk7oOxRmSgRGxTlSWUO2BCynm4b4rM5/rqnK75x8UEcdGsbTqgMrUtxOAW7t5iKspVrfapfL4HMUFkbtk5qJuxjAyIvarvPaWyhmwN9H966egGG06MSI2rZxVOIPiTFe3RMQbKC7mvLYHz7lSZj5DsXjH8ZX3dATFGZK/9yCGl0fEupX34SiKsyLfWE39zn53bgNeAE6JYtnYQynmrv+sm+2JYhrkOhTXoQ2q7BvYnfZRzIG/GfhjZn66u69fzSEzFwLXAedExLCIeAVwNMUJCQCiuD3DGbx41vkxYK8o5tW/keKz1J866zNvo3ufnVcDL8nMSVXxvyUiNgFeQjGlpK902scCv6vDeKHz/vi2Oo1Xdazyd2bFCd0hlb81K66Xngh8MiK2rsy6+CxVfU2VCyimwi+h+H3avdIP7UU3+5sy+7Y++HvfV5+pUvvOLr6z1uq9qM8+uaerdqztD4olPbPdY2IP2m9dafMCxdDnike3VjGkOHNwM8UiCQsozvCcTi+XDKdIOnq0CiLFEsX3UAzRzqEY9XlrD4/RQjF9r5Xi+qvLgOE9aP894Io1/L98ReXDN5viwsqfUFzs293251b9P9xGkcT26neH4mzK3RQr7jxIB8vqd9H+tg72Hdmd9hRTLhJY2O53cs/+/Cz5qJ8HxTLP11b+35+iapWyyv6vU7VSK8UUjZsp5s5fRf+u0LfaPrOrzw7FicbfA9tWlb2S4sznM8DJ/fzetulj6zHe1fXH9Rivj/p+dPB3JqmshkhxkvBLld+NuRQrHA5q1/5dwPfblV1A8bf6LmBMD2IppW9jDf7e99Vnqh76Trr4zlpG/0Kd9Mkr3gBJkiRJUj9zCqIkSZIk1YgJmCRJkiTViAmYJEmSJNWICZgkSZIk1YgJmCRJkiTViAmYJEmSJNWICZiaSkRMiIjbyo5DkiRJ6ogJmPpURNwWERkR/9OufERELKjsG9uHzzWhL44lqTlU+oXFlf5mXkQ8GBHH9qB9RsRe/RehpLWJfZI6YgKm/vAgcHy7sg8D02sfiqS10JczcygwEjgb+F5EvKlWTx4RLRERtXo+SXXPPkltmICpP1wPbBERu1WVfQT4XnWliDg2Ih6qnBH6a0S8u2rfXpWzPu+LiKmVOjdHxGaV/RcBewJnVM4qzWp37M9HxMyIaI2ICyNiYL+9Wkl1KTOXZ+Y1QCvwGoCIeG3ljPSzEfF4RJwTES2VfQ9Wmt5Y6VeurZRPj4gjq49dfVa6qr8aHxGPAM8B61fKPhYRf6wc7+8R8YaqY+wdEfdGxNxKPH+IiFH9+65IKot9klYwAVN/WAL8APgoQOUszzDgVysqRMQhwPnAccBo4AvAde2SNoD3AbsDWwHDgS8CZObxwB1Uzipl5qZVbd4IzK20eT0wHjisb1+ipHpXOet7GLAB8HBEvBS4BfgOsAnwJuDdwKkAmblTpen+lX7l4B4+5UEUX6qGAwsrZf8DHE5x5vv3wBVV9a+sxDIS2Az4FLC4h88pqUHYJ2kFEzD1l+8DB0fECIrpiBcDy6v2HwNcnJl3ZObSzPwZ8AuKjqHaaZk5NzPnAD+icsaoC49l5gWZuSQzHwZu7WY7Sc3htIiYA7xA8eXijMz8BXAC8PPMvLbS7zwOnAsc1UfPe2pmtmbmC5mZlbKvZeajmbmUYhbAuIjYoLJvMbAtsHlmLs7MP2Xmwo4OLKmh2SepDRMw9YvM/DcwmeLsyQHAJe2qbAlMa1f2CMWoVfVxnqraXEAxktaVp9ptd7edpOZwXmaOBEYBlwH7Vqb0vITixNCcFQ+Kk0Obdnqknnmsg7L2fRi82B8dAIwD7ouIf1WmTjtdWmo+9klqo6XsANTULgR+DfwkM2dG29UP/w1s067+tsCMHhx/eddVJK2tMnN+RJwAPERxpnkW8MPMPG51zToomw+sv2IjIjbv5Pl61Cdl5j+oTI+OiF2Amyn6wMt6chxJjcE+SSs4Aqb+dDPwVuCTHey7FDg2It4YEQMj4j0UZ14u7cHxZwHbr3mYkppVZi6iuMb0LGAicEhEHBgRgyt9z3YR8faqJrOAl7Y7zL3AYVHcTmMEcN6axlV5/qMiYqNK0VxgWeUhqUnZJwlMwNSPsnBrZj7Rwb6rgTMopibOpliW9QOZ+ecePMXXgZ0rw/arPIckVVxBserYvsB+FKuyPgk8C1wHbF1V93TgzIiYHRGTKmVnUVzA/gTFF5+f9VFcBwEPRsRCiovhJ1JcBC+pudknreXixWvyJEmSJEn9yREwSZIkSaoREzBJkiRJqhETMEmSJEmqERMwSZIkSaoREzBJkiRJqhETMEmSJEmqERMwSZIkSaoREzBJkiRJqhETMEmSJEmqERMwSZIkSaoREzBJkiRJqhETMEmSJEmqERMwSZIkSaoREzBJkiRJqhETMEmSJEmqERMwSZIkSaoREzBJkiRJqhETMEmSJEmqERMwSZIkSaoREzBJkiRJqhETMEmSJEmqERMwSZIkSaoREzBJkiRJqhETMEmSJEmqERMwSZIkSaoREzBJkiRJqhETMEmSJEmqERMwSZIkSaoREzBJkiRJqhETMEmSJEmqERMwSZIkSaoREzBJkiRJqhETMEmSJEmqERMwSZIkSaoREzBJkiRJqhETMEmSJEmqERMwSZIkSaoREzBJkiRJqhETMEmSJEmqERMwSZIkSaoREzBJkiRJqhETMEmSJEmqERMwSZIkSaoREzBJkiRJqhETMEmSJEmqERMwSZIkSaoREzBJkiRJqhETMEmSGkhEfDAiHqzanhgRE0sMSZLUAyZgkqQ+FxG3RcTiiFgQEfMi4sGIOLaHx8iI2Kt/ImwMHSVXmfmjzNyppJAkSWvIBEyS1F++nJlDgZHA2cD3IuJNtQwgIloiImr5nJIkrY4JmCSpX2Xm8sy8BmgFXrOiPCJeWxkpezYiHo+IcyKipbJvxRS7GyujaNdWyqdHxJHVx68eKYuIvSrb4yPiEeA5YP1K2cci4o+V4/09It6wurgj4vCI+FdEzI+In0bENyPitqr9XcWyWUT8KiL+WxkFvCci3lJVd2yl/ocq8cyvxLdDZf8ZwAeBD1ZiXhARG0TEkRExfTVxj4yICyvv6bMR8euIGFe1/5DKiOS8iHgmIm5Z3fsgSepbJmCSpH5VGYU6DNgAeLhS9lLgFuA7wCbAm4B3A6cCVE2x2z8zh2bmwT182oMokr3hwMJK2f8Ah1OMyP0euGI1Mb8B+AFwEjAKuATo0RRKYGDlGNsAGwLXAz+LiA3b1TsceCuwETCL4j0hM78M/Aj4UeU9GJqZz67uCSujfT8DhgKvAjYH/g78MiIGRcR6wJXAxzNzODAG+HIPX5ckaQ2YgEmS+stpETEHeIEi2TkjM39R2XcC8PPMvDYzl2bm48C5wFF99NynZmZrZr6QmVkp+1pmPpqZS4HvAeMiYoNO2h9Vie9Xlfh+Bfyik7odyswnMvNnmbkwMxdn5heBBHZvV/XszPxPZr4AXErVKGEvvAp4PfCRyutfBJwJbAW8tlJnCbBjRGxYeX9+twbPJ0nqIRMwSVJ/OS8zR1KMIF0G7LtiiiHwEuDgiJiz4gFcDGzaR8/9WAdlT1X9vKDy77BO2o/p4BgdHbNTETE6Ii6tTFWcV3mNw4GNu4hraE+ep52XAIOBp6re12cpRuO2zMzngLcD+wIPV6Y+nrgGzydJ6qGWrqtIktR7mTk/Ik4AHqIY+fomxVS7H2bmcatr2kHZfGD9FRsRsXknz7m89xED8AQwtl1Z++2uYjmPYvrhG3kxyZoN9GRRkOX07GTpLOB5YMPKSN8qMvMO4I7KdMU3AzdFxIOZObkHzyNJ6iVHwCRJ/a4yFe4LwFkRMRz4LnBIRBwYEYMjYmBEbBcRb69qNgt4abtD3QscFhEjImIERZLTHy4H3hcR+1di25/iGrWexDKCIhmaDawDfJGej27NAraLiIHdrH8nRaL73YjYGCAiRlXe5/UiYtOIODgiRlamZs6hSHSX9TAuSVIvmYBJkmrlCoqVED+dmfcA+wEfAZ6kmCZ3HbB1Vf3TgTMjYnZETKqUnUWxqMYTFAnQz/oj0My8sxLbtyiSlOMoFtSo1lUsn6VIwp6mWHzkP5W6PfF9iumDz1SmFI7uIu5lFAt6vADcHRHzgb8B76NItAI4HpgWEQso3vMzMvP2HsYlSeqlePHaZEmS1JmImADslZl7lRyKJKmBOQImSZIkSTViAiZJkiRJNeIUREmSJEmqEUfAJEmSJKlGvA9YByJiCLA7MBOX5pUkSZLUsYHAZsA9lVuudMkErGO7A3eUHYQkSZKkhrAnxb0Yu2QC1rGZAHfccQdjxowpOxZJkiRJdeiJJ55gzz33hEr+0B0mYB1bBjBmzBjGjh1bciiSJEmS6ly3L1tyEQ5JkiRJqhETMEmSJEmqERMwSZIkSaoREzBJkiRJqhETMEmSJEmqEVdBlCRJUr+6+OKLmTZtWtlh9JmZM4sVxzfbbLOSI+lb48aN49hjjy07jKbXcCNgETEyIq6JiPkR8WREfKwbbSZGREbEDrWIUZIkSc3r+eef5/nnny87DDWoRhwB+zZF3JsD2wK/jYiHMnNyR5UjYi9gm5pFJ0mSpDaabVTl9NNPB+Dcc88tORI1ooYaAYuI9YGDgbMyc35m3g9cChzdSf3BwLeALkfJJEmSJKm/NdoI2PZAZOaUqrL7gbd1Uv804KbMfDAiOqwQESOBke2Kx6xRlJIkSZLUgUZLwIYC89qVzQGGta8YES8BDgde1cUxTwI+3wexSZIkSdJqNVoCtgAY3q5sBDC/g7oXAqdn5oIujnkBMLFd2Rjgjl7EJ0mSJEmdaqhrwICpQEbEjlVluwAPdFB3H+DbETErImZVyu6IiA9XV8rMOZk5vfoBPNEPsUuSJElayzXUCFhmLoyI64BzIuIoitUNjwY+0EH19jdmmAm8D7ivf6OUJEmSpI412ggYwAlAUiRUNwETMnNyRGwVEQsiYiuAzJxV/ai0fSYzvWmDJEmSpFI01AgYFFMGKZaib18+g2KRjs7adbwMoiRJkiTVSCOOgEmSJElSQzIBkyRJkqQaMQGTJEmSpBoxAZMkSZKkGjEBkyRJkqQaMQGTJEmSpBoxAZMkSZKkGjEBkyRJkqQaMQGTJEmSpBoxAZMkSZKkGjEBkyRJkqQaMQGTJEmSpBoxAZMkSZKkGjEBkyRJkqQaMQGTJEmSpBoxAZMkSZKkGjEBkyRJkqQaMQGTJEmSpBoxAZMkSZKkGjEBkyRJkqQaMQGTJEmSpBoxAZMkSZKkGmm4BCwiRkbENRExPyKejIiPdVJvn4j4R0TMiYhnI+JnEbFFreOVJEmSpBUaLgEDvg20AJsD7wTOjoi9O6j3ILBfZo6s1P0XcHGtgpQkSZKk9lrKDqAnImJ94GDgVZk5H7g/Ii4FjgYmV9fNzFntmi8DtqtJoJIkSZLUgYZKwIDtgcjMKVVl9wNv66hyRGwF/B0YTpGAHd9BnZHAyHbFY9Y8VEmSJElqq9ESsKHAvHZlc4BhHVXOzBnAyIgYDRxLMS2xvZOAz/ddiJIkSZLUsUZLwBZQjGZVGwHMX12jzGyNiMuBv0XEFpm5tGr3BcDEdk3GAHesWaiSJEmS1FajJWBTgYyIHTPzoUrZLsAD3WjbAmxMkcC1rijMzDkUo2grRUQfhCpJkiRJbTXUKoiZuRC4DjgnIoZFxCsoFuC4tH3diDgwIl4ShY2B/wf8NTNb29eVJEmSpFpoqASs4gQggZnATcCEzJwcEVtFxILKwhsAWwK/oZi2+DeKRTjeV0bAkiRJkgSNNwVxxZTBgzson0GxSMeK7Qsoru+SJEmSpLrQiCNgkiRJktSQTMAkSZIkqUZMwCRJkiSpRkzAJEmSJKlGTMAkSZIkqUZMwCRJkiSpRkzAJEmSJKlGTMAkSZIkqUZMwCRJkiSpRkzAJEmSJKlGTMAkSeqG1tZWTjvtNGbPnl12KJKkBmYCJklSN0yaNIkpU6YwadKkskORJDUwEzBJkrrQ2trKrbfeSmZyyy23OAomSeo1EzBJkrowadIkli9fDsDy5csdBZMk9ZoJmCRJXbjttttYunQpAEuXLmXy5MklRyRJalQmYJIkdWGvvfaipaUFgJaWFvbee++SI5IkNSoTMEmSujB+/HgGDCj+ZA4YMIDx48eXHJEkqVGZgEmS1IXRo0ezzz77EBHsu+++jBo1quyQJEkNqqXsACRJagTjx49nxowZjn5JktaICZgkSd0wevRozjvvvLLDkCQ1OKcgSpIkSVKNmIBJkiRJUo00XAIWESMj4pqImB8RT0bExzqpd0RE3BcR8yr1vhERg2sdryRJkiSt0HAJGPBtimvXNgfeCZwdER3dkGU94CRgI2A3YE/gjBrFKEmSJEmraKhFOCJifeBg4FWZOR+4PyIuBY4GJlfXzcwLqzZnRsQVwLtrFqwkSZIktdNQCRiwPRCZOaWq7H7gbd1o+ybgwfaFETESGNmueEzvwpMkSZKkzjVaAjYUmNeubA4wbHWNIuLDwB7ALh3sPgn4/JqHJkmSJEmr12gJ2AJgeLuyEcD8zhpExAHA14C3ZeasDqpcAExsVzYGuKPXUUqSJElSBxotAZsKZETsmJkPVcp2AR7oqHJEvB24FHhXZt7fUZ3MnEMxilbdrm+ilSRJkqQqDbUKYmYuBK4DzomIYRHxCooFOC5tXzci3gL8CDgwM++qbaSSJEmStKqGSsAqTgASmAncBEzIzMkRsVVELIiIrSr1PksxPfFXlfIFEbHKIhySJEmSVCsNl4Bl5pzMPDgzh2bm5pn53Ur5jErZjMr23pnZUilb8dip3OjVaFpbWznttNOYPXt22aFIkiSpCTRcAibV0qRJk5gyZQqTJk0qOxRJkiQ1ARMwqROtra3ceuutZCa33HKLo2CSJElaYyZgUicmTZrE8uXLAVi+fLmjYJIkSVpjJmBSJ2677TaWLl0KwNKlS5k8eXLJEUmSJKnRmYBJndhrr71oaSluldfS0sLee+9dckSSJElqdCZgUifGjx/PgAHFR2TAgAGMHz++5IgkSZLU6EzApE6MHj2affbZh4hg3333ZdSoUWWHJEmSpAbXUnYAUj0bP348M2bMcPRLkiRJfcIETFqN0aNHc95555UdhiRJkpqEUxAlSZIkqUZMwCRJkiSpRkzAJEmSJKlGTMAkSZIkqUZchEOSpG5obW3l/PPP59RTT/W2FOp3F198MdOmTSs7DHVixf/N6aefXnIkWp1x48Zx7LHHlh3GKkzAJEnqhkmTJjFlyhQmTZrERz/60bLDUZObNm0a/5r6EBtvsG7ZoagDA1gCwNxnp5cbiDr132efLzuETpmASZLUhdbWVm699VYyk1tuuYXx48c7CqZ+t/EG6zL+gJeWHYbUkCbd8HDZIXTKa8AkSerCpEmTWL58OQDLly9n0qRJJUckSWpUJmCSJHXhtttuY+nSpQAsXbqUyZMnlxyRJKlRmYBJktSFvfbai5aWYtZ+S0sLe++9d8kRSZIalQmYJEldGD9+PAMGFH8yBwwYwPjx40uOSJLUqEzAJEnqwujRo3njG98IwJ577ukCHJKkXjMBkySpGyKi7BAkSU2g4RKwiBgZEddExPyIeDIiPtZJvZ0j4uaIeDYistZxSpKaR2trK3feeScAd9xxB7Nnzy45IklSo2q4BAz4NsX9yzYH3gmcHREdXQ29BLgGOLqGsUmSmpDL0EuS+kpDJWARsT5wMHBWZs7PzPuBS+kgycrMhzPzEuDB2kapZtLa2sppp53m2W5pLecy9JKkvtJSdgA9tD0QmTmlqux+4G29PWBEjARGtise09vjqblMmjSJKVOmMGnSJD760Y+WHY7UUC6++GKmTZtWdhh9Yt111+X5559vs3366aeXGFHfGDduHMcee2zZYUjSWqWhRsCAocC8dmVzgGFrcMyTgMfaPe5Yg+OpSbS2tnLrrbeSmdxyyy2OgklrsY022mjlzxHRZluSpJ5otBGwBcDwdmUjgPlrcMwLgIntysZgErbW6+iaD0fBpO5rtpGVI444gtbWVvbff3/7AklSrzXaCNhUICNix6qyXYAHenvAzJyTmdOrH8ATaxammoHXfEiqttFGG7Heeut5E2ZJ0hppqAQsMxcC1wHnRMSwiHgFxQIcl7avG4V1gMGV7XUq21K3vP71r2+z/YY3vKGkSCTVg0GDBjFu3DhvwixJWiMNlYBVnAAkMBO4CZiQmZMjYquIWBARW1XqbQ08z4urID5feUjdkunt4yRJktS3Gi4Bq0wZPDgzh2bm5pn53Ur5jErZjMr29MyM9o9yo1cj+dOf/tRm+w9/+ENJkUiSJKlZNFwCJtVK+1XONt5445IikSRJUrMwAZM68fTTT692W5IkSeopEzCpE69+9avbbO+6664lRSJJkqRmYQImdWLatGltth955JGSIpEkSVKzMAGTOjFr1qzVbkuSJEk9ZQImSZIkSTViAiZ1ov2Nl/fYY4+SIpEkSVKzMAGTOvGRj3ykzfZxxx1XUiSSJElqFi1lB6DmcvHFF6+yeEUjGzRoEEuWLGH48OGcf/75ZYfTJ8aNG8exxx5bdhiSJElrJUfApNVoaWlhwIABbLbZZmWHIkmSpCbgCJj6VLONrJx++ukAnHvuuSVHIkmSpGbgCJgkSZIk1YgJmCRJkiTViAmYJEmSJNWICZgkSZIk1YgJmCRJkiTViKsgSlKdaLb76DWbFf83K1ZHVf3xPoeSGoEJmCTViWnTpvHgw1MYOGJw2aGoA8uWLwHgn7MeKTkSdWTZ3MVlhyBJ3WICJkl1ZOCIwYx40+ZlhyE1nLm3P1V2CJLULV4DJkmSJEk14ghYibzeo/55zUf985oPSZLUSEzASjRt2jQemPIwA9cZWXYo6sTyxQnAQ9P+U3Ik6siyF+aUHYIkSVKPmICVbOA6I1lv633KDkNqSM89fmvZIUiSJPVIw10DFhEjI+KaiJgfEU9GxMdWU/fESp35EXF1RAyvZaySJEmSVK3hEjDg2xQjd5sD7wTOjoi921eKiLcCn6/U2QIYBHyrhnFKkiRJUhsNlYBFxPrAwcBZmTk/M+8HLgWO7qD6kcBlmXl/Zs4DzgQ+EBHr1SpeSZIkSarWaNeAbQ9EZk6pKrsfeFsHdXcGfr1iIzMfigiAlwB/W1EeESOBke3ajumTaLswc+ZMlr0wz+tYpF5a9sIcZs5cXnYYkiRJ3dZoCdhQYF67sjnAsE7qzm1XNreDuidRTFWUpFLNnDmTpXMXeUNZqReWzlnEzJxZdhh9ZubMmSyY/xyTbni47FCkhvTfZ5/jucX12Sc0WgK2AGi/kMYIYH436w7voO4FwMR2ZWOAO3oVYQ9sttlmzHl+gKsgSr303OO3stlmm5QdhiRJUrc1WgI2FciI2DEzH6qU7QI80EHdB4BXAlcBRMQOQAD/qq6UmXMoRtFWqkxVlKSa2myzzZgbCxnxps3LDkVqOHNvf4rNNt2s7DD6zGabbcbcwYsYf8BLyw5FakiTbniYERvUZ5/QUAlYZi6MiOuAcyLiKGAbigU4PtBB9YnAjyLiR8BjwBeBqzPzuVrF2x3LXpjjNWB1bPniBQAMGDy05EjUkeJGzI6ASZKkxtFQCVjFCcDFwEyK68EmZObkiNgKmAK8LDNnZOZvI+Ic4CaKqYe/Bj5eVtAdGTduXNkhqAvTpi0EYNw4v+TXp038HEmSpIbScAlYZcrgwR2Uz6BYeKO67FvU8b2/jj322LJDUBdOP/10AM4999ySI9HaYtncxS7CUaeWLVgCwMChg0qORB1ZNncxbFp2FJLUtYZLwCSpWTmaV9+mTZsGwLhN/X+qS5v6GZLUGEzAJKlOOCpe3xwRlyT1hQFlByBJkiRJawsTMEmSJEmqERMwSZIkSaoREzBJkiRJqhETMEmSJEmqERMwSZIkSaoREzBJkiRJqhHvAyatxpIlS/j3v//N7NmzGTVqVNnhSJLWIv999nkm3fBw2WGoA7PnLgJg1IghJUeizvz32ecZsUHZUXTMBExajaeffprnnnuOSZMm8dGPfrTscCRJa4lx48aVHYJW49m50wAYscHYcgNRp0ZsUL+fIxMw9amLL76YadOmlR1Gn1iyZAmtra0A3HjjjTz66KMMGjSo5KjW3Lhx4zj22GPLDkOStBr20/Xt9NNPB+Dcc88tORI1Iq8Bkzrx9NNPr/w5M9tsS5IkSb3hCJj6VDOdsTvkkEPabD///POe6ZIkSdIaMQGTOrHXXnvx29/+lqVLl9LS0sLee+9ddkhSQ2mmKcnAyteyYupRM3BKsiTVnlMQpU6MHz+eAQOKj8iAAQMYP358yRFJKtO6667LuuuuW3YYkqQG5wiY1InRo0ezzz77cNNNN7Hvvvu6DL3UQ46sSJK0KhMwaTXGjx/PjBkzHP2SJElSnzABk1Zj9OjRnHfeeWWHIUmSpCbhNWCSJEmSVCMmYJIkSZJUIyZgkiRJklQjDZOARcTgiPheRMyJiKcj4gurqbtZRNwQETMjIiNibA1DlSRJkqQONUwCBnwOeAWwHbA7cFhEHNVJ3eXATcD7axSbJEmSJHWpkRKwo4BzMvOZzJwOfB04uqOKmfmfzPwucE8N45MkSZKk1WqIZegjYhSwOfC3quL7gS/3wbFHAiPbFY9Z0+NKkiRJUnsNkYABQyv/zq0qmwMM64NjnwR8vg+OI0mSJEmrVRdTECPipspiGR09pgMLKlWHVzUbAczvg6e/ANim3WPPPjiuJEmSJLVRFyNgmfn2rupExFPAK4GnKkW7AA/0wXPPoRhNq36uNT2sJEmSJK2iLkbAumkicFZEbBgRWwMnA5d2Vjki1gGGVDaHRMQ6YWYlSZIkqUSNlICdTTHi9ShwH3B1Zl62YmdELIiI6qmDz/Pi1MV/Vra3rlGskiRJkrSKupiC2B2ZuRj4SOXR0f6h7bYd7ZIkSaoDF198MdOmTSs7jD6z4rWcfvrpJUfSt8aNG8exxx5bdhhNr2ESMEmSJKkerLvuumWHoAZmAiZJkqR+5aiK9KJGugZMkiRJkhqaCZgkSZIk1YgJmCRJkiTViAmYJEmSJNWICZgkSZIk1YgJmCRJkiTViAmYJEnd0Nraymmnncbs2bPLDkWS1MBMwCRJ6oZJkyYxZcoUJk2aVHYokqQGZgImSVIXWltbufXWW8lMbrnlFkfBJEm9ZgImSVIXJk2axPLlywFYvny5o2CSpF4zAZMkqQu33XYbS5cuBWDp0qVMnjy55IgkSY3KBEySpC7stddetLS0ANDS0sLee+9dckSSpEZlAiZJUhfGjx/PgAHFn8wBAwYwfvz4kiOSJDUqEzBJkrowevRo9tlnHyKCfffdl1GjRpUdkiSpQbWUHYAkSY1g/PjxzJgxw9EvSdIaMQGTJKkbRo8ezXnnnVd2GJKkBucUREmSJEmqERMwSZIkSaoRpyB2bCDAE088UXYckiRJkupUVb4wsLttIjP7J5oGFhF7AHeUHYckSZKkhrBnZt7ZnYomYB2IiCHA7sBMYFnJ4ahcYyiS8T0Bh0SltZv9gaQV7A+0wkBgM+CezFzUnQZOQexA5c3rVgar5hYRK358IjOnlxiKpJLZH0hawf5A7Tzak8ouwiFJkiRJNWICJkmSJEk1YgImSZIkSTViAiat3hzg7Mq/ktZuc7A/kFSYg/2BeslVECVJkiSpRhwBkyRJkqQaMQGTJEmSpBoxAZO6KSIWRMT2lZ8nRsR5ZcckqXwRMT0i3t7Jvtsi4vhaxySpPBExISImrWa//cJazgRMa41Kh/dCRMyPiHkRcV9EnBYRQ7rTPjOHZubU/o5TUt+ofL5/267snoi4p13Z5Ig4rbbRSaqFyt/+jIjXtiv/dqX8yDU8/l4RMWuNgtRaxwRMa5uTMnMYsBlwCjAe+HVU3dJeUtP4PfD6iGgBiIhhwJbAlpWfiYjBwOuA28oKUlK/mwocsWKj8rk/GHi0tIi0VjMB01opMxdm5m3AAcDrgXdGxG4R8aeImBMRMyPi/yJi0Io2lTNlO7Q/VkQ8EBHvr9oeEBFPRMTetXgtkjp1LxDAbpXtPYA/AXcBb6yUvQZYBvw1Is6PiMcj4r8R8YOIWH/FgSLinRHx10r/cFdEvLqjJ4yIbSPiXxFxbLvywRHxbHW7iBgREc9FxLg+e8WSOvIj4KCqGS8HUPQPswCicGpEPBYRz0TETyNi0xWNK3//j4uIf0bE3IiYFBHrVvqIG4GNK5cpLKj6PA+KiIsr9R+NiP3bB2W/sPYyAdNaLTNnUHTCe1J8CTsZ2JDiy9nbgY904zCXA4dXbe9dOdZtfRmrpJ7JzCXAH4E3VYreBNxeeVSX/RE4D9gJ2BUYR9EPfBEgIl5F8Tn/GDAa+Bbwi4hYr/r5IuIVwO+AMzPz4naxLAYm0bavOAi4LzOn9cHLldS5/wJ3UyReAEcCE6v2H0Hx934/ilHyZ4Gr2h3jIIrvBtsCrwKOysyFwP7AfyuXKQyt+jy/iyI5Gw1cAFwaEW2+d9svrL1MwCR4ChidmX/NzD9l5tJKx/d94M3daH8F8LaIGF3ZPhy4Mr3JnlQPfs+Ln+M3A3dUHivK3lSpcxxwcmY+k5kLgC9RTFGmsu/iSv+wPDN/RHHz1T2rnucNwK+Bj2TmNZ3EMhE4NCIGVrYPB364Zi9PUjddDhxRGdnaHbihat+HgAsyc2pmPg98CnhzRIypqvPlzHw2M5+ptO1wFLzKnzLzp5m5DLgU2BTYvIN6E7FfWOuYgEmwBdAaES+NiF9FxKyImAd8geIs+Gpl5iyK0a7xEbEu8H7sPKV68XvgjZVrvl4K/BX4C7BDpewNFAnZesDdlSmGc4BbgJGVachbA/+7Yl9l/za0/TL1EeA+4ObOAsnMe4BngP0iYiuK6Y+dJWuS+tYNFInXp4DrMnNR1b4tgMdXbGTmXGB2pXyF6oU2FgJDu3i+lfUrI2V01MZ+Ye1kAqa1WkRsSTHl6A7gQuBh4CWZORz4HMX1I90xkeKs1XuBf2bmw30erKTe+DMwBDgeuDczl1XOSN8HfBRoobgm7HnglZk5svIYkZnrVqYx/hv4StW+kZm5XmZeVvU8JwAbABd2sajPiinLHwR+WfmiJ6mfVab7XUdxqcHEdrufpDjRAkBEDAdGVcq7PHQfhGe/sJYxAdNaKSLWi4g3A9dTfEH7NcWZqXnAgojYke5d/7XCDcD2wOk4+iXVjcpZ7rsoVj29vWrX7RRfxO6qfDG7GPhGRGwCEBFbRMQ7KnUvBo6LiNdXFtlZPyL2j4hRVcdbQHEtyCuBb68mpCuAdwJHY18h1doXgH0qo07VfkQxyv2SykyWrwJ3ZOYT3Tjmf4BR7fqDnrJfWMuYgGltc0FEzKfoMC8AfgK8PTOXU0xLOBSYD3wPuLq7B618yZsE7AD8uI9jlrRmfg9sQjHSvcIdlbLfV7Y/A/wT+FNlCvItwI4AmXkvcAzwTaAVeAT4n/ZPkpnzKRbv2T0ivtlRIJUpy3cAw4Gb1vSFSeq+zPxPZk7uYNflwCXAb4EnKPqGw7p5zH9SJHCPVKYob9OLuOwX1jLhOgFS34iIzwBvyMz3lh2LpPoVEd8FFmfmSWXHIqk+2C+sXVrKDkBqBhExAjgW+ETZsUiqX5VV1cZT3JNMkuwX1kJOQZTWUOWGq08Bd2bmjWXHI6k+RcQ5FNMcv52ZU8qOR1L57BfWTk5BlCRJkqQacQRMkiRJkmrEBEySJEmSasQETJIkSZJqxARMkiRJkmrEBEySJEmSasQETJIkSZJq5P8DoipzMwamQpgAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 1008x5184 with 13 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1008x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"==============Compare to DJIA===========\")\n",
        "%matplotlib inline\n",
        "# S&P 500: ^GSPC\n",
        "# Dow Jones Index: ^DJI\n",
        "# NASDAQ 100: ^NDX\n",
        "backtest_plot(df_account_value, \n",
        "              baseline_ticker = '^GSPC', \n",
        "              baseline_start = df_account_value.loc[0,'date'],\n",
        "              baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBQx4bVQFi-a"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "FinRL_Ensemble_StockTrading_ICAIF_2020.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "vscode": {
      "interpreter": {
        "hash": "a1dc24e770f11933509167a1c29cdaaeb86ecb8b4614cc65da123615b71c0aa2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
