{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lb9q2_QZgdNk"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Tutorials/blob/master/2-Advance/FinRL_Ensemble_StockTrading_ICAIF_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading Using Ensemble Strategy\n",
    "\n",
    "Tutorials to use OpenAI DRL to trade multiple stocks using ensemble strategy in one Jupyter Notebook | Presented at ICAIF 2020\n",
    "\n",
    "* This notebook is the reimplementation of our paper: Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, using FinRL.\n",
    "* Check out medium blog for detailed explanations: https://medium.com/@ai4finance/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02\n",
    "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5_PTmOh1hj"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mPT0ipYE28wL",
    "outputId": "4352663d-20eb-4080-a83e-bf6b97183bf4"
   },
   "outputs": [],
   "source": [
    "# # ## install finrl library\n",
    "# !pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EeMK7Uentj1V"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lPqeTTwoh1hn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.config_tickers import DOW_30_TICKER\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.meta.env_stock_trading.env_stocktrading_pair_trading_Prices import StockPairTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent,DRLEnsembleAgent, DRLEnsembleAgentOne\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "w9A8CN5R5PuZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import (\n",
    "    DATA_SAVE_DIR,\n",
    "    TRAINED_MODEL_DIR,\n",
    "    TENSORBOARD_LOG_DIR,\n",
    "    RESULTS_DIR,\n",
    "    INDICATORS,\n",
    "    TRAIN_START_DATE,\n",
    "    TRAIN_END_DATE,\n",
    "    TEST_START_DATE,\n",
    "    TEST_END_DATE,\n",
    "    TRADE_START_DATE,\n",
    "    TRADE_END_DATE,\n",
    ")\n",
    "\n",
    "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzqRRTOX6aFu",
    "outputId": "cd002c5d-2490-4947-9bd3-2b0696cb0f69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'AVGO']\n"
     ]
    }
   ],
   "source": [
    "DOW_30_TICKER = ['A','AVGO']\n",
    "print(DOW_30_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "743f675b-6126-44ea-bf39-7b3333d15044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (6126, 8)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_START_DATE = '2010-04-01'\n",
    "TRAIN_END_DATE = '2021-01-01'\n",
    "TEST_START_DATE = '2021-01-01'\n",
    "TEST_END_DATE = '2022-06-01'\n",
    "\n",
    "df = YahooDownloader(start_date = TRAIN_START_DATE,\n",
    "                     end_date = TEST_END_DATE,\n",
    "                     ticker_list = DOW_30_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "GiRuFOTOtj1Y",
    "outputId": "632ce1e6-ad27-4f50-fec7-0ca27c8e3c96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A       3063\n",
       "AVGO    3063\n",
       "Name: tic, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "DSw4ZEzVtj1Z",
    "outputId": "0015b377-84ec-4a6d-ac4e-e138c2c9bac8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6121</th>\n",
       "      <td>2022-05-26</td>\n",
       "      <td>531.539978</td>\n",
       "      <td>554.570007</td>\n",
       "      <td>527.719971</td>\n",
       "      <td>537.109497</td>\n",
       "      <td>3974300</td>\n",
       "      <td>AVGO</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6122</th>\n",
       "      <td>2022-05-27</td>\n",
       "      <td>124.919998</td>\n",
       "      <td>130.770004</td>\n",
       "      <td>124.489998</td>\n",
       "      <td>130.094025</td>\n",
       "      <td>2698800</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6123</th>\n",
       "      <td>2022-05-27</td>\n",
       "      <td>562.090027</td>\n",
       "      <td>585.460022</td>\n",
       "      <td>560.010010</td>\n",
       "      <td>568.926819</td>\n",
       "      <td>3730100</td>\n",
       "      <td>AVGO</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6124</th>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>128.910004</td>\n",
       "      <td>130.070007</td>\n",
       "      <td>126.720001</td>\n",
       "      <td>127.114464</td>\n",
       "      <td>3403100</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6125</th>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>584.500000</td>\n",
       "      <td>587.030029</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>565.854309</td>\n",
       "      <td>3000900</td>\n",
       "      <td>AVGO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date        open        high         low       close   volume  \\\n",
       "6121  2022-05-26  531.539978  554.570007  527.719971  537.109497  3974300   \n",
       "6122  2022-05-27  124.919998  130.770004  124.489998  130.094025  2698800   \n",
       "6123  2022-05-27  562.090027  585.460022  560.010010  568.926819  3730100   \n",
       "6124  2022-05-31  128.910004  130.070007  126.720001  127.114464  3403100   \n",
       "6125  2022-05-31  584.500000  587.030029  576.000000  565.854309  3000900   \n",
       "\n",
       "       tic  day  \n",
       "6121  AVGO    3  \n",
       "6122     A    4  \n",
       "6123  AVGO    4  \n",
       "6124     A    1  \n",
       "6125  AVGO    1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "42781af6-4cee-4277-8a00-cf46052f991c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6126, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4hYkeaPiICHS",
    "outputId": "59c51c93-f786-469b-c008-4e4416a041b4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>24.706724</td>\n",
       "      <td>24.942776</td>\n",
       "      <td>24.499285</td>\n",
       "      <td>22.442749</td>\n",
       "      <td>3105098</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>20.690001</td>\n",
       "      <td>20.799999</td>\n",
       "      <td>20.090000</td>\n",
       "      <td>15.103765</td>\n",
       "      <td>324600</td>\n",
       "      <td>AVGO</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-05</td>\n",
       "      <td>24.742489</td>\n",
       "      <td>24.921316</td>\n",
       "      <td>24.706724</td>\n",
       "      <td>22.618128</td>\n",
       "      <td>3731961</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-05</td>\n",
       "      <td>20.690001</td>\n",
       "      <td>20.700001</td>\n",
       "      <td>19.790001</td>\n",
       "      <td>14.926945</td>\n",
       "      <td>612000</td>\n",
       "      <td>AVGO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-06</td>\n",
       "      <td>24.778255</td>\n",
       "      <td>24.814020</td>\n",
       "      <td>24.620888</td>\n",
       "      <td>22.449244</td>\n",
       "      <td>3499054</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       open       high        low      close   volume   tic  day\n",
       "0  2010-04-01  24.706724  24.942776  24.499285  22.442749  3105098     A    3\n",
       "1  2010-04-01  20.690001  20.799999  20.090000  15.103765   324600  AVGO    3\n",
       "2  2010-04-05  24.742489  24.921316  24.706724  22.618128  3731961     A    0\n",
       "3  2010-04-05  20.690001  20.700001  19.790001  14.926945   612000  AVGO    0\n",
       "4  2010-04-06  24.778255  24.814020  24.620888  22.449244  3499054     A    1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['date','tic']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2vryMsdNL9H",
    "outputId": "dff3babf-4aba-44dd-ad61-8845df60243e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.tic.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XcNyXa7RNPrF",
    "outputId": "fd13ad85-36fd-4a55-9084-dbf807bbeb02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A       3063\n",
       "AVGO    3063\n",
       "Name: tic, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tic.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "kM5bH9uroCeg"
   },
   "outputs": [],
   "source": [
    "#  INDICATORS = ['macd',\n",
    "#                'rsi_30',\n",
    "#                'cci_30',\n",
    "#                'dx_30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jgXfBcjxtj1a",
    "outputId": "aa687295-c857-4366-d9af-96ea233c6463",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(use_technical_indicator=True,\n",
    "                     tech_indicator_list = INDICATORS,\n",
    "                     use_turbulence=True,\n",
    "                     user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df)\n",
    "processed = processed.copy()\n",
    "processed = processed.fillna(0)\n",
    "processed = processed.replace(np.inf,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "grvhGJJII3Xn",
    "outputId": "6dd919fa-032b-4180-adf4-1f732777cedc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A       3063\n",
       "AVGO    3063\n",
       "Name: tic, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.tic.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "0194749d-62ec-420f-9b54-492873c266a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 2, State Space: 21\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(processed.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 10000, \n",
    "    \"buy_cost_pct\": 0.001, \n",
    "    \"sell_cost_pct\": 0.001, \n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"print_verbosity\":5\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms.\n",
    "\n",
    "* In this notebook, we are training and validating 3 agents (A2C, PPO, DDPG) using Rolling-window Ensemble Method ([reference code](https://github.com/AI4Finance-LLC/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020/blob/80415db8fa7b2179df6bd7e81ce4fe8dbf913806/model/models.py#L92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "v-gthCxMtj1d"
   },
   "outputs": [],
   "source": [
    "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\n",
    "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
    "\n",
    "ensemble_agent = DRLEnsembleAgentOne(df=processed,\n",
    "                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n",
    "                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n",
    "                 rebalance_window=rebalance_window, \n",
    "                 validation_window=validation_window,\n",
    "                 seed=106,\n",
    "                 **env_kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "KsfEHa_Etj1d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A2C_model_kwargs = {\n",
    "                    'n_steps': 5,\n",
    "                    'ent_coef': 0.005,\n",
    "                    'learning_rate': 0.001\n",
    "                    }\n",
    "\n",
    "PPO_model_kwargs = {\n",
    "                    \"ent_coef\":0.01,\n",
    "                    \"n_steps\": 2048,\n",
    "                    \"learning_rate\": 0.00025,\n",
    "                    \"batch_size\": 128\n",
    "                    }\n",
    "\n",
    "DDPG_model_kwargs = {\n",
    "                      #\"action_noise\":\"ornstein_uhlenbeck\",\n",
    "                      \"buffer_size\": 10_000,\n",
    "                      \"learning_rate\": 0.0005,\n",
    "                      \"batch_size\": 64\n",
    "                    }\n",
    "\n",
    "A2C_policy_kwargs = {\n",
    "                    'net_arch' : [500,500],\n",
    "                    #'activation_fn': nn.Tanh,\n",
    "                    \n",
    "                    }\n",
    "\n",
    "timesteps_dict = {'a2c' : 500_000, \n",
    "                 'ppo' : 0, \n",
    "                 'ddpg' : 0\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_1lyCECstj1e",
    "outputId": "b2a1cfbc-ced9-4d06-dd9a-4300845e1113",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Start Ensemble Strategy============\n",
      "============================================\n",
      "turbulence_threshold:  18.96231252984678\n",
      "======Model training from:  2010-04-01 to  2021-01-04\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.001}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c\\a2c_126_1\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 118         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.95       |\n",
      "|    explained_variance | 0.134       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -0.0459     |\n",
      "|    reward             | 0.023846036 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 0.00065     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 176          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 5            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -2.98        |\n",
      "|    explained_variance | -1.48        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -0.00165     |\n",
      "|    reward             | -0.026489466 |\n",
      "|    std                | 1.07         |\n",
      "|    value_loss         | 0.00237      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 210         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 7           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.02       |\n",
      "|    explained_variance | 0.124       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | 0.00548     |\n",
      "|    reward             | 0.032218903 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.00129     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 233         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 8           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.03       |\n",
      "|    explained_variance | 0.361       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | 0.0175      |\n",
      "|    reward             | -0.01305681 |\n",
      "|    std                | 1.1         |\n",
      "|    value_loss         | 0.00123     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 250        |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 9          |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.06      |\n",
      "|    explained_variance | -2.6       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | 1.3        |\n",
      "|    reward             | -0.4714802 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 0.334      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 264          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 11           |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.05        |\n",
      "|    explained_variance | -1.73        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | -0.154       |\n",
      "|    reward             | 0.0046127853 |\n",
      "|    std                | 1.11         |\n",
      "|    value_loss         | 0.00227      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 276          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 12           |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.06        |\n",
      "|    explained_variance | -19.1        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | -0.209       |\n",
      "|    reward             | -0.001385709 |\n",
      "|    std                | 1.12         |\n",
      "|    value_loss         | 0.00721      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 280          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 14           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.12        |\n",
      "|    explained_variance | 0.0434       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | -0.0362      |\n",
      "|    reward             | 0.0027217553 |\n",
      "|    std                | 1.15         |\n",
      "|    value_loss         | 0.000418     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 285         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 15          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.17       |\n",
      "|    explained_variance | -10.5       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | 0.271       |\n",
      "|    reward             | 0.029951302 |\n",
      "|    std                | 1.18        |\n",
      "|    value_loss         | 0.00947     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 291          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 17           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.21        |\n",
      "|    explained_variance | 0.796        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | 0.0889       |\n",
      "|    reward             | 0.0014510559 |\n",
      "|    std                | 1.21         |\n",
      "|    value_loss         | 0.000826     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 295         |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.23       |\n",
      "|    explained_variance | -128        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | -0.561      |\n",
      "|    reward             | 0.006151222 |\n",
      "|    std                | 1.22        |\n",
      "|    value_loss         | 0.0231      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 297         |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 20          |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.23       |\n",
      "|    explained_variance | -30.9       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | 0.0271      |\n",
      "|    reward             | 0.003520284 |\n",
      "|    std                | 1.22        |\n",
      "|    value_loss         | 0.000834    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 300          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.27        |\n",
      "|    explained_variance | -0.125       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | -0.063       |\n",
      "|    reward             | -0.028399289 |\n",
      "|    std                | 1.24         |\n",
      "|    value_loss         | 0.000665     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 303         |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 23          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.3        |\n",
      "|    explained_variance | 0.745       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | 0.171       |\n",
      "|    reward             | 0.019459374 |\n",
      "|    std                | 1.26        |\n",
      "|    value_loss         | 0.00319     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 24          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.3        |\n",
      "|    explained_variance | 0.636       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | 0.151       |\n",
      "|    reward             | -0.55023426 |\n",
      "|    std                | 1.26        |\n",
      "|    value_loss         | 0.00306     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 1600        |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 8000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.32       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1599        |\n",
      "|    policy_loss        | 0.295       |\n",
      "|    reward             | 0.119177744 |\n",
      "|    std                | 1.27        |\n",
      "|    value_loss         | 0.0125      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 27         |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.33      |\n",
      "|    explained_variance | 0.356      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | -0.0819    |\n",
      "|    reward             | 0.02666531 |\n",
      "|    std                | 1.28       |\n",
      "|    value_loss         | 0.000814   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.36        |\n",
      "|    explained_variance | -1.99        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | 0.0846       |\n",
      "|    reward             | 0.0065708393 |\n",
      "|    std                | 1.3          |\n",
      "|    value_loss         | 0.000723     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.4        |\n",
      "|    explained_variance | 0.159       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | 0.218       |\n",
      "|    reward             | -0.06256681 |\n",
      "|    std                | 1.33        |\n",
      "|    value_loss         | 0.00837     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 32           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.43        |\n",
      "|    explained_variance | -0.000315    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | 0.0747       |\n",
      "|    reward             | -0.032610387 |\n",
      "|    std                | 1.35         |\n",
      "|    value_loss         | 0.00434      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 2100        |\n",
      "|    time_elapsed       | 33          |\n",
      "|    total_timesteps    | 10500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.46       |\n",
      "|    explained_variance | 0.0389      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2099        |\n",
      "|    policy_loss        | -0.347      |\n",
      "|    reward             | 0.046455715 |\n",
      "|    std                | 1.36        |\n",
      "|    value_loss         | 0.013       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 2200         |\n",
      "|    time_elapsed       | 35           |\n",
      "|    total_timesteps    | 11000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.48        |\n",
      "|    explained_variance | -0.871       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2199         |\n",
      "|    policy_loss        | 0.0121       |\n",
      "|    reward             | -0.022918776 |\n",
      "|    std                | 1.38         |\n",
      "|    value_loss         | 0.000378     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 2300        |\n",
      "|    time_elapsed       | 36          |\n",
      "|    total_timesteps    | 11500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.51       |\n",
      "|    explained_variance | 0.709       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2299        |\n",
      "|    policy_loss        | -0.0409     |\n",
      "|    reward             | 0.018648954 |\n",
      "|    std                | 1.4         |\n",
      "|    value_loss         | 0.000203    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 317          |\n",
      "|    iterations         | 2400         |\n",
      "|    time_elapsed       | 37           |\n",
      "|    total_timesteps    | 12000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.56        |\n",
      "|    explained_variance | -0.124       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2399         |\n",
      "|    policy_loss        | 0.0101       |\n",
      "|    reward             | -0.026355157 |\n",
      "|    std                | 1.44         |\n",
      "|    value_loss         | 0.000387     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 2500        |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 12500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.62       |\n",
      "|    explained_variance | 0.534       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2499        |\n",
      "|    policy_loss        | 0.37        |\n",
      "|    reward             | -0.08014422 |\n",
      "|    std                | 1.48        |\n",
      "|    value_loss         | 0.00971     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 2600       |\n",
      "|    time_elapsed       | 40         |\n",
      "|    total_timesteps    | 13000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.64      |\n",
      "|    explained_variance | 0.0837     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 2599       |\n",
      "|    policy_loss        | 0.795      |\n",
      "|    reward             | 0.06251187 |\n",
      "|    std                | 1.49       |\n",
      "|    value_loss         | 0.0439     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 2700       |\n",
      "|    time_elapsed       | 41         |\n",
      "|    total_timesteps    | 13500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.66      |\n",
      "|    explained_variance | 0.124      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 2699       |\n",
      "|    policy_loss        | -1.41      |\n",
      "|    reward             | 0.20536698 |\n",
      "|    std                | 1.51       |\n",
      "|    value_loss         | 0.21       |\n",
      "--------------------------------------\n",
      "day: 2707, episode: 5\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 102969.98\n",
      "total_reward: 92969.98\n",
      "total_cost: 27.52\n",
      "total_trades: 5399\n",
      "Sharpe: 0.899\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 2800          |\n",
      "|    time_elapsed       | 43            |\n",
      "|    total_timesteps    | 14000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.69         |\n",
      "|    explained_variance | -0.196        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 2799          |\n",
      "|    policy_loss        | 0.176         |\n",
      "|    reward             | -0.0018868237 |\n",
      "|    std                | 1.53          |\n",
      "|    value_loss         | 0.00279       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 2900         |\n",
      "|    time_elapsed       | 44           |\n",
      "|    total_timesteps    | 14500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.71        |\n",
      "|    explained_variance | 0.175        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2899         |\n",
      "|    policy_loss        | 0.0637       |\n",
      "|    reward             | -0.037728418 |\n",
      "|    std                | 1.55         |\n",
      "|    value_loss         | 0.00112      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 324        |\n",
      "|    iterations         | 3000       |\n",
      "|    time_elapsed       | 46         |\n",
      "|    total_timesteps    | 15000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.75      |\n",
      "|    explained_variance | 0.872      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 2999       |\n",
      "|    policy_loss        | 0.119      |\n",
      "|    reward             | 0.07908181 |\n",
      "|    std                | 1.58       |\n",
      "|    value_loss         | 0.00245    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 325         |\n",
      "|    iterations         | 3100        |\n",
      "|    time_elapsed       | 47          |\n",
      "|    total_timesteps    | 15500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.76       |\n",
      "|    explained_variance | 0.632       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3099        |\n",
      "|    policy_loss        | 0.28        |\n",
      "|    reward             | 0.022153834 |\n",
      "|    std                | 1.59        |\n",
      "|    value_loss         | 0.0106      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 326         |\n",
      "|    iterations         | 3200        |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 16000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.76       |\n",
      "|    explained_variance | 1.11e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3199        |\n",
      "|    policy_loss        | 0.351       |\n",
      "|    reward             | -0.05104513 |\n",
      "|    std                | 1.59        |\n",
      "|    value_loss         | 0.0135      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 326          |\n",
      "|    iterations         | 3300         |\n",
      "|    time_elapsed       | 50           |\n",
      "|    total_timesteps    | 16500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.8         |\n",
      "|    explained_variance | -13.4        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 3299         |\n",
      "|    policy_loss        | 0.0824       |\n",
      "|    reward             | -0.009994237 |\n",
      "|    std                | 1.62         |\n",
      "|    value_loss         | 0.00213      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 3400         |\n",
      "|    time_elapsed       | 51           |\n",
      "|    total_timesteps    | 17000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.82        |\n",
      "|    explained_variance | -1.12        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 3399         |\n",
      "|    policy_loss        | -0.0818      |\n",
      "|    reward             | 0.0074124755 |\n",
      "|    std                | 1.64         |\n",
      "|    value_loss         | 0.000896     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 3500         |\n",
      "|    time_elapsed       | 53           |\n",
      "|    total_timesteps    | 17500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.85        |\n",
      "|    explained_variance | 0.00386      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 3499         |\n",
      "|    policy_loss        | 0.237        |\n",
      "|    reward             | -0.036188614 |\n",
      "|    std                | 1.66         |\n",
      "|    value_loss         | 0.00606      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 3600         |\n",
      "|    time_elapsed       | 54           |\n",
      "|    total_timesteps    | 18000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.86        |\n",
      "|    explained_variance | -0.469       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 3599         |\n",
      "|    policy_loss        | 0.549        |\n",
      "|    reward             | -0.033292256 |\n",
      "|    std                | 1.66         |\n",
      "|    value_loss         | 0.0254       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 3700         |\n",
      "|    time_elapsed       | 56           |\n",
      "|    total_timesteps    | 18500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.86        |\n",
      "|    explained_variance | 0.152        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 3699         |\n",
      "|    policy_loss        | -1.08        |\n",
      "|    reward             | -0.090246364 |\n",
      "|    std                | 1.67         |\n",
      "|    value_loss         | 0.0729       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 3800         |\n",
      "|    time_elapsed       | 57           |\n",
      "|    total_timesteps    | 19000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.83        |\n",
      "|    explained_variance | -0.408       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 3799         |\n",
      "|    policy_loss        | -0.198       |\n",
      "|    reward             | -0.021668095 |\n",
      "|    std                | 1.64         |\n",
      "|    value_loss         | 0.00313      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 3900        |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 19500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.86       |\n",
      "|    explained_variance | -0.351      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3899        |\n",
      "|    policy_loss        | 0.03        |\n",
      "|    reward             | 0.033761278 |\n",
      "|    std                | 1.66        |\n",
      "|    value_loss         | 0.000247    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 4000        |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 20000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.88       |\n",
      "|    explained_variance | -12.8       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3999        |\n",
      "|    policy_loss        | -0.238      |\n",
      "|    reward             | 0.010271083 |\n",
      "|    std                | 1.69        |\n",
      "|    value_loss         | 0.00686     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.9        |\n",
      "|    explained_variance | -0.1        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 4099        |\n",
      "|    policy_loss        | -0.243      |\n",
      "|    reward             | -0.03164108 |\n",
      "|    std                | 1.7         |\n",
      "|    value_loss         | 0.00505     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 4200        |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 21000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.9        |\n",
      "|    explained_variance | 0.447       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 4199        |\n",
      "|    policy_loss        | 0.767       |\n",
      "|    reward             | -0.09240675 |\n",
      "|    std                | 1.7         |\n",
      "|    value_loss         | 0.0366      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 4300       |\n",
      "|    time_elapsed       | 64         |\n",
      "|    total_timesteps    | 21500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.9       |\n",
      "|    explained_variance | 0.32       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 4299       |\n",
      "|    policy_loss        | -0.417     |\n",
      "|    reward             | 0.01171319 |\n",
      "|    std                | 1.71       |\n",
      "|    value_loss         | 0.0371     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 4400         |\n",
      "|    time_elapsed       | 66           |\n",
      "|    total_timesteps    | 22000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.91        |\n",
      "|    explained_variance | 0.552        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4399         |\n",
      "|    policy_loss        | -0.0227      |\n",
      "|    reward             | -0.011048231 |\n",
      "|    std                | 1.71         |\n",
      "|    value_loss         | 0.000122     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 4500         |\n",
      "|    time_elapsed       | 67           |\n",
      "|    total_timesteps    | 22500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.94        |\n",
      "|    explained_variance | -0.29        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4499         |\n",
      "|    policy_loss        | -0.0893      |\n",
      "|    reward             | -0.005059318 |\n",
      "|    std                | 1.74         |\n",
      "|    value_loss         | 0.000976     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 4600       |\n",
      "|    time_elapsed       | 69         |\n",
      "|    total_timesteps    | 23000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.97      |\n",
      "|    explained_variance | 0.0965     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 4599       |\n",
      "|    policy_loss        | 0.512      |\n",
      "|    reward             | 0.06543331 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 0.0188     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 4700        |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 23500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4          |\n",
      "|    explained_variance | 0.117       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 4699        |\n",
      "|    policy_loss        | 0.389       |\n",
      "|    reward             | 0.052701436 |\n",
      "|    std                | 1.79        |\n",
      "|    value_loss         | 0.0228      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 4800       |\n",
      "|    time_elapsed       | 71         |\n",
      "|    total_timesteps    | 24000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.99      |\n",
      "|    explained_variance | -0.000907  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 4799       |\n",
      "|    policy_loss        | -1.8       |\n",
      "|    reward             | 0.09009431 |\n",
      "|    std                | 1.78       |\n",
      "|    value_loss         | 0.275      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 4900         |\n",
      "|    time_elapsed       | 73           |\n",
      "|    total_timesteps    | 24500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.01        |\n",
      "|    explained_variance | -11.8        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4899         |\n",
      "|    policy_loss        | -0.502       |\n",
      "|    reward             | -0.008181194 |\n",
      "|    std                | 1.8          |\n",
      "|    value_loss         | 0.0171       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 5000        |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 25000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.03       |\n",
      "|    explained_variance | 0.32        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 4999        |\n",
      "|    policy_loss        | 0.0126      |\n",
      "|    reward             | 0.011825803 |\n",
      "|    std                | 1.82        |\n",
      "|    value_loss         | 2.22e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 5100        |\n",
      "|    time_elapsed       | 76          |\n",
      "|    total_timesteps    | 25500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.06       |\n",
      "|    explained_variance | 0.305       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5099        |\n",
      "|    policy_loss        | -0.0942     |\n",
      "|    reward             | 0.039880432 |\n",
      "|    std                | 1.84        |\n",
      "|    value_loss         | 0.000993    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 5200        |\n",
      "|    time_elapsed       | 77          |\n",
      "|    total_timesteps    | 26000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.08       |\n",
      "|    explained_variance | 0.408       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5199        |\n",
      "|    policy_loss        | -0.461      |\n",
      "|    reward             | -0.01428537 |\n",
      "|    std                | 1.86        |\n",
      "|    value_loss         | 0.0219      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 334        |\n",
      "|    iterations         | 5300       |\n",
      "|    time_elapsed       | 79         |\n",
      "|    total_timesteps    | 26500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.11      |\n",
      "|    explained_variance | 0.095      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 5299       |\n",
      "|    policy_loss        | -0.356     |\n",
      "|    reward             | 0.16331863 |\n",
      "|    std                | 1.89       |\n",
      "|    value_loss         | 0.0101     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 334       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 80        |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.12     |\n",
      "|    explained_variance | 0.111     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | 2.08      |\n",
      "|    reward             | 0.3044478 |\n",
      "|    std                | 1.9       |\n",
      "|    value_loss         | 0.313     |\n",
      "-------------------------------------\n",
      "day: 2707, episode: 10\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 142970.80\n",
      "total_reward: 132970.80\n",
      "total_cost: 9.97\n",
      "total_trades: 2706\n",
      "Sharpe: 0.845\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 5500         |\n",
      "|    time_elapsed       | 82           |\n",
      "|    total_timesteps    | 27500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.14        |\n",
      "|    explained_variance | -3.05        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5499         |\n",
      "|    policy_loss        | -0.194       |\n",
      "|    reward             | 0.0075168526 |\n",
      "|    std                | 1.91         |\n",
      "|    value_loss         | 0.00699      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 5600        |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 28000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.17       |\n",
      "|    explained_variance | -2.09       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5599        |\n",
      "|    policy_loss        | -0.194      |\n",
      "|    reward             | 0.011046249 |\n",
      "|    std                | 1.95        |\n",
      "|    value_loss         | 0.00366     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 5700         |\n",
      "|    time_elapsed       | 85           |\n",
      "|    total_timesteps    | 28500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.2         |\n",
      "|    explained_variance | -0.0123      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5699         |\n",
      "|    policy_loss        | -0.415       |\n",
      "|    reward             | -0.019694742 |\n",
      "|    std                | 1.98         |\n",
      "|    value_loss         | 0.0225       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 5800         |\n",
      "|    time_elapsed       | 86           |\n",
      "|    total_timesteps    | 29000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.2         |\n",
      "|    explained_variance | 0.0486       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5799         |\n",
      "|    policy_loss        | 0.689        |\n",
      "|    reward             | -0.050074384 |\n",
      "|    std                | 1.98         |\n",
      "|    value_loss         | 0.0535       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 5900         |\n",
      "|    time_elapsed       | 87           |\n",
      "|    total_timesteps    | 29500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.2         |\n",
      "|    explained_variance | 1.05e-05     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5899         |\n",
      "|    policy_loss        | 1.38         |\n",
      "|    reward             | -0.020459656 |\n",
      "|    std                | 1.97         |\n",
      "|    value_loss         | 0.138        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 6000        |\n",
      "|    time_elapsed       | 89          |\n",
      "|    total_timesteps    | 30000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.22       |\n",
      "|    explained_variance | -99.8       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5999        |\n",
      "|    policy_loss        | -0.118      |\n",
      "|    reward             | -0.00690102 |\n",
      "|    std                | 2           |\n",
      "|    value_loss         | 0.00178     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 6100         |\n",
      "|    time_elapsed       | 90           |\n",
      "|    total_timesteps    | 30500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.24        |\n",
      "|    explained_variance | -0.00104     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6099         |\n",
      "|    policy_loss        | 0.0207       |\n",
      "|    reward             | 0.0126400795 |\n",
      "|    std                | 2.02         |\n",
      "|    value_loss         | 9.16e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 6200         |\n",
      "|    time_elapsed       | 92           |\n",
      "|    total_timesteps    | 31000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.27        |\n",
      "|    explained_variance | 0.399        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6199         |\n",
      "|    policy_loss        | 0.0516       |\n",
      "|    reward             | -0.006833838 |\n",
      "|    std                | 2.05         |\n",
      "|    value_loss         | 0.00104      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 335        |\n",
      "|    iterations         | 6300       |\n",
      "|    time_elapsed       | 93         |\n",
      "|    total_timesteps    | 31500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.32      |\n",
      "|    explained_variance | 0.0235     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 6299       |\n",
      "|    policy_loss        | 0.244      |\n",
      "|    reward             | 0.01516601 |\n",
      "|    std                | 2.1        |\n",
      "|    value_loss         | 0.00514    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 335        |\n",
      "|    iterations         | 6400       |\n",
      "|    time_elapsed       | 95         |\n",
      "|    total_timesteps    | 32000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.34      |\n",
      "|    explained_variance | 0.34       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 6399       |\n",
      "|    policy_loss        | -0.891     |\n",
      "|    reward             | 0.16850024 |\n",
      "|    std                | 2.12       |\n",
      "|    value_loss         | 0.111      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 6500         |\n",
      "|    time_elapsed       | 96           |\n",
      "|    total_timesteps    | 32500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.32        |\n",
      "|    explained_variance | 7.67e-05     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6499         |\n",
      "|    policy_loss        | 1.2          |\n",
      "|    reward             | 0.0023408527 |\n",
      "|    std                | 2.1          |\n",
      "|    value_loss         | 0.0475       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 98          |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.35       |\n",
      "|    explained_variance | -11.9       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 6599        |\n",
      "|    policy_loss        | -0.057      |\n",
      "|    reward             | 0.016124342 |\n",
      "|    std                | 2.13        |\n",
      "|    value_loss         | 0.000445    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 6700        |\n",
      "|    time_elapsed       | 99          |\n",
      "|    total_timesteps    | 33500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.39       |\n",
      "|    explained_variance | -0.00302    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 6699        |\n",
      "|    policy_loss        | -0.0672     |\n",
      "|    reward             | 0.035425656 |\n",
      "|    std                | 2.18        |\n",
      "|    value_loss         | 0.000561    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 6800         |\n",
      "|    time_elapsed       | 101          |\n",
      "|    total_timesteps    | 34000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.43        |\n",
      "|    explained_variance | -0.195       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6799         |\n",
      "|    policy_loss        | 0.278        |\n",
      "|    reward             | -0.048417516 |\n",
      "|    std                | 2.21         |\n",
      "|    value_loss         | 0.0088       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 6900        |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 34500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.45       |\n",
      "|    explained_variance | 0.239       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 6899        |\n",
      "|    policy_loss        | 1.55        |\n",
      "|    reward             | -0.27999246 |\n",
      "|    std                | 2.24        |\n",
      "|    value_loss         | 0.117       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 337        |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 103        |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.47      |\n",
      "|    explained_variance | -0.0572    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 6999       |\n",
      "|    policy_loss        | -1.72      |\n",
      "|    reward             | 0.47374836 |\n",
      "|    std                | 2.26       |\n",
      "|    value_loss         | 0.11       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 337         |\n",
      "|    iterations         | 7100        |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 35500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.48       |\n",
      "|    explained_variance | -0.109      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7099        |\n",
      "|    policy_loss        | 0.243       |\n",
      "|    reward             | 0.009228618 |\n",
      "|    std                | 2.28        |\n",
      "|    value_loss         | 0.00384     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 337           |\n",
      "|    iterations         | 7200          |\n",
      "|    time_elapsed       | 106           |\n",
      "|    total_timesteps    | 36000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.53         |\n",
      "|    explained_variance | 0.15          |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 7199          |\n",
      "|    policy_loss        | 0.0152        |\n",
      "|    reward             | -0.0022676229 |\n",
      "|    std                | 2.33          |\n",
      "|    value_loss         | 5.51e-05      |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 338       |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 107       |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.53     |\n",
      "|    explained_variance | 0.257     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | 0.281     |\n",
      "|    reward             | 0.2704317 |\n",
      "|    std                | 2.33      |\n",
      "|    value_loss         | 0.00786   |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 338          |\n",
      "|    iterations         | 7400         |\n",
      "|    time_elapsed       | 109          |\n",
      "|    total_timesteps    | 37000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.56        |\n",
      "|    explained_variance | -0.0288      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 7399         |\n",
      "|    policy_loss        | 0.801        |\n",
      "|    reward             | -0.097274765 |\n",
      "|    std                | 2.36         |\n",
      "|    value_loss         | 0.0383       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 338        |\n",
      "|    iterations         | 7500       |\n",
      "|    time_elapsed       | 110        |\n",
      "|    total_timesteps    | 37500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.57      |\n",
      "|    explained_variance | 0.352      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 7499       |\n",
      "|    policy_loss        | -0.953     |\n",
      "|    reward             | -0.2075229 |\n",
      "|    std                | 2.37       |\n",
      "|    value_loss         | 0.0567     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 338           |\n",
      "|    iterations         | 7600          |\n",
      "|    time_elapsed       | 112           |\n",
      "|    total_timesteps    | 38000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.58         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 7599          |\n",
      "|    policy_loss        | -0.00266      |\n",
      "|    reward             | -0.0020796868 |\n",
      "|    std                | 2.39          |\n",
      "|    value_loss         | 7.23e-07      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 339         |\n",
      "|    iterations         | 7700        |\n",
      "|    time_elapsed       | 113         |\n",
      "|    total_timesteps    | 38500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.59       |\n",
      "|    explained_variance | 0.0552      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7699        |\n",
      "|    policy_loss        | -0.053      |\n",
      "|    reward             | 0.045082655 |\n",
      "|    std                | 2.41        |\n",
      "|    value_loss         | 0.00288     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 339          |\n",
      "|    iterations         | 7800         |\n",
      "|    time_elapsed       | 114          |\n",
      "|    total_timesteps    | 39000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.61        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 7799         |\n",
      "|    policy_loss        | 0.218        |\n",
      "|    reward             | -0.031771526 |\n",
      "|    std                | 2.42         |\n",
      "|    value_loss         | 0.00646      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 339         |\n",
      "|    iterations         | 7900        |\n",
      "|    time_elapsed       | 116         |\n",
      "|    total_timesteps    | 39500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.62       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7899        |\n",
      "|    policy_loss        | 0.564       |\n",
      "|    reward             | -0.03829488 |\n",
      "|    std                | 2.44        |\n",
      "|    value_loss         | 0.0234      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 339         |\n",
      "|    iterations         | 8000        |\n",
      "|    time_elapsed       | 117         |\n",
      "|    total_timesteps    | 40000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.63       |\n",
      "|    explained_variance | 0.137       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7999        |\n",
      "|    policy_loss        | -0.859      |\n",
      "|    reward             | 0.025719607 |\n",
      "|    std                | 2.45        |\n",
      "|    value_loss         | 0.0605      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 339        |\n",
      "|    iterations         | 8100       |\n",
      "|    time_elapsed       | 119        |\n",
      "|    total_timesteps    | 40500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.66      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 8099       |\n",
      "|    policy_loss        | -0.621     |\n",
      "|    reward             | 0.22411399 |\n",
      "|    std                | 2.49       |\n",
      "|    value_loss         | 0.0405     |\n",
      "--------------------------------------\n",
      "day: 2707, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 264931.31\n",
      "total_reward: 254931.31\n",
      "total_cost: 159.46\n",
      "total_trades: 2935\n",
      "Sharpe: 1.044\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 339           |\n",
      "|    iterations         | 8200          |\n",
      "|    time_elapsed       | 120           |\n",
      "|    total_timesteps    | 41000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.68         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 8199          |\n",
      "|    policy_loss        | -0.0587       |\n",
      "|    reward             | 0.00036795496 |\n",
      "|    std                | 2.51          |\n",
      "|    value_loss         | 0.000217      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 339          |\n",
      "|    iterations         | 8300         |\n",
      "|    time_elapsed       | 122          |\n",
      "|    total_timesteps    | 41500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.71        |\n",
      "|    explained_variance | -4.32        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 8299         |\n",
      "|    policy_loss        | -0.0223      |\n",
      "|    reward             | 0.0064542494 |\n",
      "|    std                | 2.55         |\n",
      "|    value_loss         | 0.000554     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 339          |\n",
      "|    iterations         | 8400         |\n",
      "|    time_elapsed       | 123          |\n",
      "|    total_timesteps    | 42000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.75        |\n",
      "|    explained_variance | 0.413        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 8399         |\n",
      "|    policy_loss        | -0.00476     |\n",
      "|    reward             | -0.023690265 |\n",
      "|    std                | 2.6          |\n",
      "|    value_loss         | 0.000483     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 339           |\n",
      "|    iterations         | 8500          |\n",
      "|    time_elapsed       | 125           |\n",
      "|    total_timesteps    | 42500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.76         |\n",
      "|    explained_variance | 0.0637        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 8499          |\n",
      "|    policy_loss        | -0.0691       |\n",
      "|    reward             | -0.0011310417 |\n",
      "|    std                | 2.62          |\n",
      "|    value_loss         | 0.00145       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 339          |\n",
      "|    iterations         | 8600         |\n",
      "|    time_elapsed       | 126          |\n",
      "|    total_timesteps    | 43000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.77        |\n",
      "|    explained_variance | 0.398        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 8599         |\n",
      "|    policy_loss        | 0.0836       |\n",
      "|    reward             | -0.029963614 |\n",
      "|    std                | 2.63         |\n",
      "|    value_loss         | 0.00786      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 339          |\n",
      "|    iterations         | 8700         |\n",
      "|    time_elapsed       | 128          |\n",
      "|    total_timesteps    | 43500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.78        |\n",
      "|    explained_variance | -0.129       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 8699         |\n",
      "|    policy_loss        | -0.19        |\n",
      "|    reward             | 0.0074931514 |\n",
      "|    std                | 2.64         |\n",
      "|    value_loss         | 0.00153      |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.8     |\n",
      "|    explained_variance | -1.34    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | 0.132    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.67     |\n",
      "|    value_loss         | 0.000994 |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 339           |\n",
      "|    iterations         | 8900          |\n",
      "|    time_elapsed       | 131           |\n",
      "|    total_timesteps    | 44500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.84         |\n",
      "|    explained_variance | -0.0869       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 8899          |\n",
      "|    policy_loss        | 0.0693        |\n",
      "|    reward             | 0.00026691283 |\n",
      "|    std                | 2.72          |\n",
      "|    value_loss         | 0.000634      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 339         |\n",
      "|    iterations         | 9000        |\n",
      "|    time_elapsed       | 132         |\n",
      "|    total_timesteps    | 45000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.89       |\n",
      "|    explained_variance | 0.199       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 8999        |\n",
      "|    policy_loss        | -0.804      |\n",
      "|    reward             | 0.030645836 |\n",
      "|    std                | 2.8         |\n",
      "|    value_loss         | 0.0347      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 339        |\n",
      "|    iterations         | 9100       |\n",
      "|    time_elapsed       | 133        |\n",
      "|    total_timesteps    | 45500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.9       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 9099       |\n",
      "|    policy_loss        | 1.38       |\n",
      "|    reward             | 0.03982381 |\n",
      "|    std                | 2.8        |\n",
      "|    value_loss         | 0.0833     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 339        |\n",
      "|    iterations         | 9200       |\n",
      "|    time_elapsed       | 135        |\n",
      "|    total_timesteps    | 46000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.93      |\n",
      "|    explained_variance | 0.175      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 9199       |\n",
      "|    policy_loss        | 0.348      |\n",
      "|    reward             | -0.3924912 |\n",
      "|    std                | 2.85       |\n",
      "|    value_loss         | 0.0231     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 340         |\n",
      "|    iterations         | 9300        |\n",
      "|    time_elapsed       | 136         |\n",
      "|    total_timesteps    | 46500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.94       |\n",
      "|    explained_variance | -0.0409     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9299        |\n",
      "|    policy_loss        | 0.0923      |\n",
      "|    reward             | 0.019010853 |\n",
      "|    std                | 2.86        |\n",
      "|    value_loss         | 0.000354    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 339        |\n",
      "|    iterations         | 9400       |\n",
      "|    time_elapsed       | 138        |\n",
      "|    total_timesteps    | 47000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.97      |\n",
      "|    explained_variance | 0.0253     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 9399       |\n",
      "|    policy_loss        | -0.209     |\n",
      "|    reward             | 0.05139143 |\n",
      "|    std                | 2.91       |\n",
      "|    value_loss         | 0.00298    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 339           |\n",
      "|    iterations         | 9500          |\n",
      "|    time_elapsed       | 139           |\n",
      "|    total_timesteps    | 47500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.97         |\n",
      "|    explained_variance | 0.026         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 9499          |\n",
      "|    policy_loss        | -1.59         |\n",
      "|    reward             | -0.0053849854 |\n",
      "|    std                | 2.9           |\n",
      "|    value_loss         | 0.149         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 339         |\n",
      "|    iterations         | 9600        |\n",
      "|    time_elapsed       | 141         |\n",
      "|    total_timesteps    | 48000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.97       |\n",
      "|    explained_variance | 0.072       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9599        |\n",
      "|    policy_loss        | -1.64       |\n",
      "|    reward             | -0.18922067 |\n",
      "|    std                | 2.91        |\n",
      "|    value_loss         | 0.152       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 340         |\n",
      "|    iterations         | 9700        |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 48500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.95       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9699        |\n",
      "|    policy_loss        | -2.65       |\n",
      "|    reward             | -0.30417097 |\n",
      "|    std                | 2.88        |\n",
      "|    value_loss         | 0.282       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 340        |\n",
      "|    iterations         | 9800       |\n",
      "|    time_elapsed       | 144        |\n",
      "|    total_timesteps    | 49000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.97      |\n",
      "|    explained_variance | -0.726     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 9799       |\n",
      "|    policy_loss        | 0.0733     |\n",
      "|    reward             | 0.03177327 |\n",
      "|    std                | 2.9        |\n",
      "|    value_loss         | 0.000236   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 340         |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 145         |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.98       |\n",
      "|    explained_variance | -1.07       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9899        |\n",
      "|    policy_loss        | 0.0214      |\n",
      "|    reward             | 0.008653765 |\n",
      "|    std                | 2.92        |\n",
      "|    value_loss         | 4.27e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 340        |\n",
      "|    iterations         | 10000      |\n",
      "|    time_elapsed       | 146        |\n",
      "|    total_timesteps    | 50000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5         |\n",
      "|    explained_variance | -2.73      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 9999       |\n",
      "|    policy_loss        | 0.417      |\n",
      "|    reward             | 0.07231091 |\n",
      "|    std                | 2.95       |\n",
      "|    value_loss         | 0.0138     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 340         |\n",
      "|    iterations         | 10100       |\n",
      "|    time_elapsed       | 148         |\n",
      "|    total_timesteps    | 50500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.02       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10099       |\n",
      "|    policy_loss        | -0.428      |\n",
      "|    reward             | -0.01780934 |\n",
      "|    std                | 2.97        |\n",
      "|    value_loss         | 0.00785     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 340         |\n",
      "|    iterations         | 10200       |\n",
      "|    time_elapsed       | 149         |\n",
      "|    total_timesteps    | 51000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.04       |\n",
      "|    explained_variance | 0.406       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10199       |\n",
      "|    policy_loss        | 0.357       |\n",
      "|    reward             | -0.19196264 |\n",
      "|    std                | 3.01        |\n",
      "|    value_loss         | 0.00973     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 339         |\n",
      "|    iterations         | 10300       |\n",
      "|    time_elapsed       | 151         |\n",
      "|    total_timesteps    | 51500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.05       |\n",
      "|    explained_variance | 0.417       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10299       |\n",
      "|    policy_loss        | -0.293      |\n",
      "|    reward             | 0.018662944 |\n",
      "|    std                | 3.02        |\n",
      "|    value_loss         | 0.00429     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 340          |\n",
      "|    iterations         | 10400        |\n",
      "|    time_elapsed       | 152          |\n",
      "|    total_timesteps    | 52000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.07        |\n",
      "|    explained_variance | 0.216        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 10399        |\n",
      "|    policy_loss        | 0.185        |\n",
      "|    reward             | -0.011720238 |\n",
      "|    std                | 3.05         |\n",
      "|    value_loss         | 0.00195      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 339         |\n",
      "|    iterations         | 10500       |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 52500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.11       |\n",
      "|    explained_variance | -1.26       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10499       |\n",
      "|    policy_loss        | 0.357       |\n",
      "|    reward             | 0.026291063 |\n",
      "|    std                | 3.12        |\n",
      "|    value_loss         | 0.00598     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 339         |\n",
      "|    iterations         | 10600       |\n",
      "|    time_elapsed       | 155         |\n",
      "|    total_timesteps    | 53000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.15       |\n",
      "|    explained_variance | -0.000558   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10599       |\n",
      "|    policy_loss        | 0.258       |\n",
      "|    reward             | 0.059847124 |\n",
      "|    std                | 3.19        |\n",
      "|    value_loss         | 0.00365     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 340        |\n",
      "|    iterations         | 10700      |\n",
      "|    time_elapsed       | 157        |\n",
      "|    total_timesteps    | 53500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.16      |\n",
      "|    explained_variance | -0.67      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 10699      |\n",
      "|    policy_loss        | 0.627      |\n",
      "|    reward             | 0.08917661 |\n",
      "|    std                | 3.2        |\n",
      "|    value_loss         | 0.0251     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 340         |\n",
      "|    iterations         | 10800       |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 54000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.17       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10799       |\n",
      "|    policy_loss        | 1.86        |\n",
      "|    reward             | -0.19655462 |\n",
      "|    std                | 3.22        |\n",
      "|    value_loss         | 0.107       |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 20\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 142981.64\n",
      "total_reward: 132981.64\n",
      "total_cost: 14.09\n",
      "total_trades: 2722\n",
      "Sharpe: 0.846\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 340         |\n",
      "|    iterations         | 10900       |\n",
      "|    time_elapsed       | 160         |\n",
      "|    total_timesteps    | 54500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.21       |\n",
      "|    explained_variance | -7.53       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10899       |\n",
      "|    policy_loss        | 0.153       |\n",
      "|    reward             | -0.03671099 |\n",
      "|    std                | 3.28        |\n",
      "|    value_loss         | 0.0138      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 339          |\n",
      "|    iterations         | 11000        |\n",
      "|    time_elapsed       | 161          |\n",
      "|    total_timesteps    | 55000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.25        |\n",
      "|    explained_variance | -0.9         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 10999        |\n",
      "|    policy_loss        | -0.15        |\n",
      "|    reward             | 0.0022914773 |\n",
      "|    std                | 3.34         |\n",
      "|    value_loss         | 0.00108      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 339          |\n",
      "|    iterations         | 11100        |\n",
      "|    time_elapsed       | 163          |\n",
      "|    total_timesteps    | 55500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.3         |\n",
      "|    explained_variance | 0.0983       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11099        |\n",
      "|    policy_loss        | -0.318       |\n",
      "|    reward             | 0.0042513055 |\n",
      "|    std                | 3.42         |\n",
      "|    value_loss         | 0.00418      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 339           |\n",
      "|    iterations         | 11200         |\n",
      "|    time_elapsed       | 164           |\n",
      "|    total_timesteps    | 56000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.3          |\n",
      "|    explained_variance | 0.539         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 11199         |\n",
      "|    policy_loss        | 0.183         |\n",
      "|    reward             | -0.0022008934 |\n",
      "|    std                | 3.43          |\n",
      "|    value_loss         | 0.00419       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 340          |\n",
      "|    iterations         | 11300        |\n",
      "|    time_elapsed       | 166          |\n",
      "|    total_timesteps    | 56500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.31        |\n",
      "|    explained_variance | 0.000673     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11299        |\n",
      "|    policy_loss        | 0.832        |\n",
      "|    reward             | 0.0066254996 |\n",
      "|    std                | 3.44         |\n",
      "|    value_loss         | 0.0383       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 340          |\n",
      "|    iterations         | 11400        |\n",
      "|    time_elapsed       | 167          |\n",
      "|    total_timesteps    | 57000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.29        |\n",
      "|    explained_variance | -145         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11399        |\n",
      "|    policy_loss        | -0.195       |\n",
      "|    reward             | -0.009270609 |\n",
      "|    std                | 3.41         |\n",
      "|    value_loss         | 0.00309      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 340           |\n",
      "|    iterations         | 11500         |\n",
      "|    time_elapsed       | 168           |\n",
      "|    total_timesteps    | 57500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.32         |\n",
      "|    explained_variance | 0.787         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 11499         |\n",
      "|    policy_loss        | -0.115        |\n",
      "|    reward             | -0.0104886005 |\n",
      "|    std                | 3.47          |\n",
      "|    value_loss         | 0.000692      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 340           |\n",
      "|    iterations         | 11600         |\n",
      "|    time_elapsed       | 170           |\n",
      "|    total_timesteps    | 58000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.36         |\n",
      "|    explained_variance | 0.277         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 11599         |\n",
      "|    policy_loss        | -0.313        |\n",
      "|    reward             | -0.0037331218 |\n",
      "|    std                | 3.53          |\n",
      "|    value_loss         | 0.00326       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 340          |\n",
      "|    iterations         | 11700        |\n",
      "|    time_elapsed       | 171          |\n",
      "|    total_timesteps    | 58500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.37        |\n",
      "|    explained_variance | 0.269        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11699        |\n",
      "|    policy_loss        | 0.755        |\n",
      "|    reward             | -0.089978434 |\n",
      "|    std                | 3.56         |\n",
      "|    value_loss         | 0.0349       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 340        |\n",
      "|    iterations         | 11800      |\n",
      "|    time_elapsed       | 173        |\n",
      "|    total_timesteps    | 59000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.37      |\n",
      "|    explained_variance | 0.25       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 11799      |\n",
      "|    policy_loss        | 0.256      |\n",
      "|    reward             | 0.08654217 |\n",
      "|    std                | 3.55       |\n",
      "|    value_loss         | 0.113      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 340        |\n",
      "|    iterations         | 11900      |\n",
      "|    time_elapsed       | 174        |\n",
      "|    total_timesteps    | 59500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.35      |\n",
      "|    explained_variance | 0.0101     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 11899      |\n",
      "|    policy_loss        | -1.5       |\n",
      "|    reward             | 0.21680108 |\n",
      "|    std                | 3.53       |\n",
      "|    value_loss         | 0.296      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 340          |\n",
      "|    iterations         | 12000        |\n",
      "|    time_elapsed       | 175          |\n",
      "|    total_timesteps    | 60000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.36        |\n",
      "|    explained_variance | -4.38        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11999        |\n",
      "|    policy_loss        | -0.177       |\n",
      "|    reward             | -0.002098507 |\n",
      "|    std                | 3.55         |\n",
      "|    value_loss         | 0.00157      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 340         |\n",
      "|    iterations         | 12100       |\n",
      "|    time_elapsed       | 177         |\n",
      "|    total_timesteps    | 60500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.39       |\n",
      "|    explained_variance | -32.7       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12099       |\n",
      "|    policy_loss        | -0.27       |\n",
      "|    reward             | 0.004690015 |\n",
      "|    std                | 3.6         |\n",
      "|    value_loss         | 0.0119      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 340           |\n",
      "|    iterations         | 12200         |\n",
      "|    time_elapsed       | 178           |\n",
      "|    total_timesteps    | 61000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.45         |\n",
      "|    explained_variance | 0.734         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 12199         |\n",
      "|    policy_loss        | 0.337         |\n",
      "|    reward             | 0.00021706696 |\n",
      "|    std                | 3.71          |\n",
      "|    value_loss         | 0.00469       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 341        |\n",
      "|    iterations         | 12300      |\n",
      "|    time_elapsed       | 180        |\n",
      "|    total_timesteps    | 61500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.48      |\n",
      "|    explained_variance | 0.191      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 12299      |\n",
      "|    policy_loss        | -0.479     |\n",
      "|    reward             | 0.05176762 |\n",
      "|    std                | 3.76       |\n",
      "|    value_loss         | 0.0157     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 341        |\n",
      "|    iterations         | 12400      |\n",
      "|    time_elapsed       | 181        |\n",
      "|    total_timesteps    | 62000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.5       |\n",
      "|    explained_variance | -0.0696    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 12399      |\n",
      "|    policy_loss        | 0.404      |\n",
      "|    reward             | 0.07328542 |\n",
      "|    std                | 3.79       |\n",
      "|    value_loss         | 0.0215     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 341         |\n",
      "|    iterations         | 12500       |\n",
      "|    time_elapsed       | 183         |\n",
      "|    total_timesteps    | 62500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.53       |\n",
      "|    explained_variance | -1.2e+03    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12499       |\n",
      "|    policy_loss        | -3.08       |\n",
      "|    reward             | 0.019155351 |\n",
      "|    std                | 3.85        |\n",
      "|    value_loss         | 0.406       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 340         |\n",
      "|    iterations         | 12600       |\n",
      "|    time_elapsed       | 184         |\n",
      "|    total_timesteps    | 63000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.55       |\n",
      "|    explained_variance | -0.536      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12599       |\n",
      "|    policy_loss        | 0.0141      |\n",
      "|    reward             | 0.007166672 |\n",
      "|    std                | 3.89        |\n",
      "|    value_loss         | 6.89e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 340         |\n",
      "|    iterations         | 12700       |\n",
      "|    time_elapsed       | 186         |\n",
      "|    total_timesteps    | 63500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.57       |\n",
      "|    explained_variance | 0.344       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12699       |\n",
      "|    policy_loss        | 0.334       |\n",
      "|    reward             | -0.11291217 |\n",
      "|    std                | 3.94        |\n",
      "|    value_loss         | 0.0053      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 340        |\n",
      "|    iterations         | 12800      |\n",
      "|    time_elapsed       | 187        |\n",
      "|    total_timesteps    | 64000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.59      |\n",
      "|    explained_variance | -0.275     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 12799      |\n",
      "|    policy_loss        | 0.502      |\n",
      "|    reward             | 0.15045416 |\n",
      "|    std                | 3.97       |\n",
      "|    value_loss         | 0.00999    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 341         |\n",
      "|    iterations         | 12900       |\n",
      "|    time_elapsed       | 189         |\n",
      "|    total_timesteps    | 64500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.58       |\n",
      "|    explained_variance | 0.27        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12899       |\n",
      "|    policy_loss        | 1.08        |\n",
      "|    reward             | -0.08591914 |\n",
      "|    std                | 3.97        |\n",
      "|    value_loss         | 0.0617      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 341          |\n",
      "|    iterations         | 13000        |\n",
      "|    time_elapsed       | 190          |\n",
      "|    total_timesteps    | 65000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.57        |\n",
      "|    explained_variance | -17.6        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 12999        |\n",
      "|    policy_loss        | -3.16        |\n",
      "|    reward             | 0.0072581307 |\n",
      "|    std                | 3.93         |\n",
      "|    value_loss         | 0.439        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 341         |\n",
      "|    iterations         | 13100       |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 65500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.57       |\n",
      "|    explained_variance | 0.0261      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13099       |\n",
      "|    policy_loss        | -0.0976     |\n",
      "|    reward             | 0.008916057 |\n",
      "|    std                | 3.94        |\n",
      "|    value_loss         | 0.000596    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 341         |\n",
      "|    iterations         | 13200       |\n",
      "|    time_elapsed       | 193         |\n",
      "|    total_timesteps    | 66000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.61       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13199       |\n",
      "|    policy_loss        | -0.375      |\n",
      "|    reward             | -0.03658869 |\n",
      "|    std                | 4.01        |\n",
      "|    value_loss         | 0.0076      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 341        |\n",
      "|    iterations         | 13300      |\n",
      "|    time_elapsed       | 194        |\n",
      "|    total_timesteps    | 66500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.61      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 13299      |\n",
      "|    policy_loss        | 1.01       |\n",
      "|    reward             | 0.14852403 |\n",
      "|    std                | 4.01       |\n",
      "|    value_loss         | 0.045      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 341         |\n",
      "|    iterations         | 13400       |\n",
      "|    time_elapsed       | 196         |\n",
      "|    total_timesteps    | 67000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.62       |\n",
      "|    explained_variance | 0.11        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13399       |\n",
      "|    policy_loss        | -2.36       |\n",
      "|    reward             | -0.05847264 |\n",
      "|    std                | 4.02        |\n",
      "|    value_loss         | 0.182       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 341       |\n",
      "|    iterations         | 13500     |\n",
      "|    time_elapsed       | 197       |\n",
      "|    total_timesteps    | 67500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.61     |\n",
      "|    explained_variance | 0.0211    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 13499     |\n",
      "|    policy_loss        | -13.5     |\n",
      "|    reward             | 1.5854733 |\n",
      "|    std                | 4         |\n",
      "|    value_loss         | 6.27      |\n",
      "-------------------------------------\n",
      "day: 2707, episode: 25\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 270589.26\n",
      "total_reward: 260589.26\n",
      "total_cost: 72.93\n",
      "total_trades: 2967\n",
      "Sharpe: 1.031\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 341         |\n",
      "|    iterations         | 13600       |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 68000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.62       |\n",
      "|    explained_variance | 7.45e-06    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13599       |\n",
      "|    policy_loss        | -0.0722     |\n",
      "|    reward             | 0.020947816 |\n",
      "|    std                | 4.03        |\n",
      "|    value_loss         | 0.000393    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 341           |\n",
      "|    iterations         | 13700         |\n",
      "|    time_elapsed       | 200           |\n",
      "|    total_timesteps    | 68500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.64         |\n",
      "|    explained_variance | 0.702         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 13699         |\n",
      "|    policy_loss        | 0.412         |\n",
      "|    reward             | -0.0067007225 |\n",
      "|    std                | 4.07          |\n",
      "|    value_loss         | 0.00581       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 342         |\n",
      "|    iterations         | 13800       |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 69000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.69       |\n",
      "|    explained_variance | -0.00078    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13799       |\n",
      "|    policy_loss        | 0.065       |\n",
      "|    reward             | -0.06767326 |\n",
      "|    std                | 4.17        |\n",
      "|    value_loss         | 0.0011      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 342        |\n",
      "|    iterations         | 13900      |\n",
      "|    time_elapsed       | 203        |\n",
      "|    total_timesteps    | 69500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.69      |\n",
      "|    explained_variance | 0.00223    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 13899      |\n",
      "|    policy_loss        | 0.202      |\n",
      "|    reward             | 0.03563859 |\n",
      "|    std                | 4.16       |\n",
      "|    value_loss         | 0.0141     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 341         |\n",
      "|    iterations         | 14000       |\n",
      "|    time_elapsed       | 204         |\n",
      "|    total_timesteps    | 70000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.71       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13999       |\n",
      "|    policy_loss        | -0.0424     |\n",
      "|    reward             | -0.18529102 |\n",
      "|    std                | 4.21        |\n",
      "|    value_loss         | 0.0168      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 342          |\n",
      "|    iterations         | 14100        |\n",
      "|    time_elapsed       | 206          |\n",
      "|    total_timesteps    | 70500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.72        |\n",
      "|    explained_variance | -11.5        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 14099        |\n",
      "|    policy_loss        | -0.284       |\n",
      "|    reward             | 0.0045173327 |\n",
      "|    std                | 4.24         |\n",
      "|    value_loss         | 0.00403      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 342          |\n",
      "|    iterations         | 14200        |\n",
      "|    time_elapsed       | 207          |\n",
      "|    total_timesteps    | 71000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.74        |\n",
      "|    explained_variance | 0.369        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 14199        |\n",
      "|    policy_loss        | 0.117        |\n",
      "|    reward             | -0.000980019 |\n",
      "|    std                | 4.28         |\n",
      "|    value_loss         | 0.000677     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 342         |\n",
      "|    iterations         | 14300       |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 71500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.78       |\n",
      "|    explained_variance | 0.523       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14299       |\n",
      "|    policy_loss        | -0.24       |\n",
      "|    reward             | 0.023922497 |\n",
      "|    std                | 4.35        |\n",
      "|    value_loss         | 0.0034      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 342         |\n",
      "|    iterations         | 14400       |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 72000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.8        |\n",
      "|    explained_variance | 0.272       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14399       |\n",
      "|    policy_loss        | -0.276      |\n",
      "|    reward             | -0.03877727 |\n",
      "|    std                | 4.4         |\n",
      "|    value_loss         | 0.00243     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 342         |\n",
      "|    iterations         | 14500       |\n",
      "|    time_elapsed       | 211         |\n",
      "|    total_timesteps    | 72500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.84       |\n",
      "|    explained_variance | 0.0511      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14499       |\n",
      "|    policy_loss        | -1.97       |\n",
      "|    reward             | 0.018352875 |\n",
      "|    std                | 4.5         |\n",
      "|    value_loss         | 0.503       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 342       |\n",
      "|    iterations         | 14600     |\n",
      "|    time_elapsed       | 213       |\n",
      "|    total_timesteps    | 73000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.86     |\n",
      "|    explained_variance | 0.656     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 14599     |\n",
      "|    policy_loss        | -0.893    |\n",
      "|    reward             | 0.1385354 |\n",
      "|    std                | 4.54      |\n",
      "|    value_loss         | 0.0277    |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 342           |\n",
      "|    iterations         | 14700         |\n",
      "|    time_elapsed       | 214           |\n",
      "|    total_timesteps    | 73500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.89         |\n",
      "|    explained_variance | 0.0054        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 14699         |\n",
      "|    policy_loss        | -0.2          |\n",
      "|    reward             | -0.0029316794 |\n",
      "|    std                | 4.6           |\n",
      "|    value_loss         | 0.00139       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 342         |\n",
      "|    iterations         | 14800       |\n",
      "|    time_elapsed       | 216         |\n",
      "|    total_timesteps    | 74000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.92       |\n",
      "|    explained_variance | 0.714       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14799       |\n",
      "|    policy_loss        | 0.0528      |\n",
      "|    reward             | 0.005367872 |\n",
      "|    std                | 4.67        |\n",
      "|    value_loss         | 7.38e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 342        |\n",
      "|    iterations         | 14900      |\n",
      "|    time_elapsed       | 217        |\n",
      "|    total_timesteps    | 74500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.92      |\n",
      "|    explained_variance | 0.0805     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 14899      |\n",
      "|    policy_loss        | -0.461     |\n",
      "|    reward             | 0.13628106 |\n",
      "|    std                | 4.67       |\n",
      "|    value_loss         | 0.0106     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 342         |\n",
      "|    iterations         | 15000       |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 75000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.95       |\n",
      "|    explained_variance | -0.0863     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14999       |\n",
      "|    policy_loss        | 0.306       |\n",
      "|    reward             | -0.09874675 |\n",
      "|    std                | 4.74        |\n",
      "|    value_loss         | 0.00376     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 342         |\n",
      "|    iterations         | 15100       |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 75500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.96       |\n",
      "|    explained_variance | 0.781       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15099       |\n",
      "|    policy_loss        | -0.594      |\n",
      "|    reward             | -0.10607797 |\n",
      "|    std                | 4.76        |\n",
      "|    value_loss         | 0.0106      |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 342            |\n",
      "|    iterations         | 15200          |\n",
      "|    time_elapsed       | 221            |\n",
      "|    total_timesteps    | 76000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -5.96          |\n",
      "|    explained_variance | -0.144         |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 15199          |\n",
      "|    policy_loss        | -0.28          |\n",
      "|    reward             | -0.00075002486 |\n",
      "|    std                | 4.77           |\n",
      "|    value_loss         | 0.00321        |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 342         |\n",
      "|    iterations         | 15300       |\n",
      "|    time_elapsed       | 223         |\n",
      "|    total_timesteps    | 76500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.99       |\n",
      "|    explained_variance | 0.189       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15299       |\n",
      "|    policy_loss        | 0.373       |\n",
      "|    reward             | 0.027547387 |\n",
      "|    std                | 4.86        |\n",
      "|    value_loss         | 0.00365     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 342       |\n",
      "|    iterations         | 15400     |\n",
      "|    time_elapsed       | 225       |\n",
      "|    total_timesteps    | 77000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.01     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 15399     |\n",
      "|    policy_loss        | 0.237     |\n",
      "|    reward             | 0.0609214 |\n",
      "|    std                | 4.89      |\n",
      "|    value_loss         | 0.00383   |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 341          |\n",
      "|    iterations         | 15500        |\n",
      "|    time_elapsed       | 226          |\n",
      "|    total_timesteps    | 77500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.04        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 15499        |\n",
      "|    policy_loss        | -0.104       |\n",
      "|    reward             | -0.016395107 |\n",
      "|    std                | 4.96         |\n",
      "|    value_loss         | 0.00658      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 341         |\n",
      "|    iterations         | 15600       |\n",
      "|    time_elapsed       | 228         |\n",
      "|    total_timesteps    | 78000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.03       |\n",
      "|    explained_variance | 0.114       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15599       |\n",
      "|    policy_loss        | -3.02       |\n",
      "|    reward             | -0.07381975 |\n",
      "|    std                | 4.93        |\n",
      "|    value_loss         | 0.293       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 341        |\n",
      "|    iterations         | 15700      |\n",
      "|    time_elapsed       | 229        |\n",
      "|    total_timesteps    | 78500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.05      |\n",
      "|    explained_variance | 0.0167     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 15699      |\n",
      "|    policy_loss        | 2.98       |\n",
      "|    reward             | 0.42149666 |\n",
      "|    std                | 4.99       |\n",
      "|    value_loss         | 0.732      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 341         |\n",
      "|    iterations         | 15800       |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 79000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.07       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15799       |\n",
      "|    policy_loss        | 0.193       |\n",
      "|    reward             | 0.015181372 |\n",
      "|    std                | 5.04        |\n",
      "|    value_loss         | 0.000933    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 341           |\n",
      "|    iterations         | 15900         |\n",
      "|    time_elapsed       | 232           |\n",
      "|    total_timesteps    | 79500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.08         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 15899         |\n",
      "|    policy_loss        | -0.486        |\n",
      "|    reward             | -0.0014423599 |\n",
      "|    std                | 5.07          |\n",
      "|    value_loss         | 0.00981       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 341        |\n",
      "|    iterations         | 16000      |\n",
      "|    time_elapsed       | 234        |\n",
      "|    total_timesteps    | 80000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.09      |\n",
      "|    explained_variance | 0.162      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 15999      |\n",
      "|    policy_loss        | 0.108      |\n",
      "|    reward             | 0.21677218 |\n",
      "|    std                | 5.07       |\n",
      "|    value_loss         | 0.0101     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 340         |\n",
      "|    iterations         | 16100       |\n",
      "|    time_elapsed       | 236         |\n",
      "|    total_timesteps    | 80500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.1        |\n",
      "|    explained_variance | -2.11       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16099       |\n",
      "|    policy_loss        | 1.35        |\n",
      "|    reward             | -0.54118025 |\n",
      "|    std                | 5.11        |\n",
      "|    value_loss         | 0.0405      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 340        |\n",
      "|    iterations         | 16200      |\n",
      "|    time_elapsed       | 237        |\n",
      "|    total_timesteps    | 81000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.07      |\n",
      "|    explained_variance | 0.221      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 16199      |\n",
      "|    policy_loss        | 0.736      |\n",
      "|    reward             | 0.30082613 |\n",
      "|    std                | 5.03       |\n",
      "|    value_loss         | 0.102      |\n",
      "--------------------------------------\n",
      "day: 2707, episode: 30\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 280704.23\n",
      "total_reward: 270704.23\n",
      "total_cost: 77.71\n",
      "total_trades: 2946\n",
      "Sharpe: 1.043\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 340          |\n",
      "|    iterations         | 16300        |\n",
      "|    time_elapsed       | 239          |\n",
      "|    total_timesteps    | 81500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.08        |\n",
      "|    explained_variance | -20          |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 16299        |\n",
      "|    policy_loss        | -0.433       |\n",
      "|    reward             | -0.018407274 |\n",
      "|    std                | 5.06         |\n",
      "|    value_loss         | 0.00805      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 340         |\n",
      "|    iterations         | 16400       |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 82000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.1        |\n",
      "|    explained_variance | 0.244       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16399       |\n",
      "|    policy_loss        | -0.118      |\n",
      "|    reward             | 0.014740784 |\n",
      "|    std                | 5.12        |\n",
      "|    value_loss         | 0.000335    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 340         |\n",
      "|    iterations         | 16500       |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 82500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.13       |\n",
      "|    explained_variance | 1.96e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16499       |\n",
      "|    policy_loss        | -0.37       |\n",
      "|    reward             | 0.017981289 |\n",
      "|    std                | 5.19        |\n",
      "|    value_loss         | 0.017       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 340          |\n",
      "|    iterations         | 16600        |\n",
      "|    time_elapsed       | 243          |\n",
      "|    total_timesteps    | 83000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.15        |\n",
      "|    explained_variance | 0.0985       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 16599        |\n",
      "|    policy_loss        | -0.646       |\n",
      "|    reward             | 0.0072315726 |\n",
      "|    std                | 5.23         |\n",
      "|    value_loss         | 0.0157       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 340        |\n",
      "|    iterations         | 16700      |\n",
      "|    time_elapsed       | 245        |\n",
      "|    total_timesteps    | 83500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.17      |\n",
      "|    explained_variance | 0.485      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 16699      |\n",
      "|    policy_loss        | 2.29       |\n",
      "|    reward             | 0.12648505 |\n",
      "|    std                | 5.29       |\n",
      "|    value_loss         | 0.193      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 339         |\n",
      "|    iterations         | 16800       |\n",
      "|    time_elapsed       | 247         |\n",
      "|    total_timesteps    | 84000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.17       |\n",
      "|    explained_variance | -0.194      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16799       |\n",
      "|    policy_loss        | -0.298      |\n",
      "|    reward             | 0.015915867 |\n",
      "|    std                | 5.3         |\n",
      "|    value_loss         | 0.00252     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 339         |\n",
      "|    iterations         | 16900       |\n",
      "|    time_elapsed       | 248         |\n",
      "|    total_timesteps    | 84500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.19       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16899       |\n",
      "|    policy_loss        | -0.0297     |\n",
      "|    reward             | 0.022956394 |\n",
      "|    std                | 5.35        |\n",
      "|    value_loss         | 0.000344    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 340         |\n",
      "|    iterations         | 17000       |\n",
      "|    time_elapsed       | 249         |\n",
      "|    total_timesteps    | 85000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.23       |\n",
      "|    explained_variance | -0.036      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16999       |\n",
      "|    policy_loss        | -0.023      |\n",
      "|    reward             | -0.00642197 |\n",
      "|    std                | 5.46        |\n",
      "|    value_loss         | 0.000374    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 339         |\n",
      "|    iterations         | 17100       |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 85500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.29       |\n",
      "|    explained_variance | 0.181       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17099       |\n",
      "|    policy_loss        | 1.13        |\n",
      "|    reward             | 0.011318646 |\n",
      "|    std                | 5.62        |\n",
      "|    value_loss         | 0.0343      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 339        |\n",
      "|    iterations         | 17200      |\n",
      "|    time_elapsed       | 253        |\n",
      "|    total_timesteps    | 86000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.31      |\n",
      "|    explained_variance | 0.639      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 17199      |\n",
      "|    policy_loss        | -0.591     |\n",
      "|    reward             | 0.18769635 |\n",
      "|    std                | 5.67       |\n",
      "|    value_loss         | 0.00944    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 339       |\n",
      "|    iterations         | 17300     |\n",
      "|    time_elapsed       | 254       |\n",
      "|    total_timesteps    | 86500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.3      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 17299     |\n",
      "|    policy_loss        | -0.789    |\n",
      "|    reward             | -0.122234 |\n",
      "|    std                | 5.64      |\n",
      "|    value_loss         | 0.0389    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 339         |\n",
      "|    iterations         | 17400       |\n",
      "|    time_elapsed       | 256         |\n",
      "|    total_timesteps    | 87000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.32       |\n",
      "|    explained_variance | -3.03       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17399       |\n",
      "|    policy_loss        | -0.0598     |\n",
      "|    reward             | 0.038376223 |\n",
      "|    std                | 5.7         |\n",
      "|    value_loss         | 0.00209     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 339           |\n",
      "|    iterations         | 17500         |\n",
      "|    time_elapsed       | 257           |\n",
      "|    total_timesteps    | 87500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.35         |\n",
      "|    explained_variance | 0.46          |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 17499         |\n",
      "|    policy_loss        | 0.0445        |\n",
      "|    reward             | -0.0024199933 |\n",
      "|    std                | 5.78          |\n",
      "|    value_loss         | 7.67e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 339          |\n",
      "|    iterations         | 17600        |\n",
      "|    time_elapsed       | 259          |\n",
      "|    total_timesteps    | 88000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.38        |\n",
      "|    explained_variance | 0.56         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 17599        |\n",
      "|    policy_loss        | -0.116       |\n",
      "|    reward             | -0.039340734 |\n",
      "|    std                | 5.89         |\n",
      "|    value_loss         | 0.00186      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 339          |\n",
      "|    iterations         | 17700        |\n",
      "|    time_elapsed       | 260          |\n",
      "|    total_timesteps    | 88500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.43        |\n",
      "|    explained_variance | 2.38e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 17699        |\n",
      "|    policy_loss        | -0.0218      |\n",
      "|    reward             | -0.007517692 |\n",
      "|    std                | 6.04         |\n",
      "|    value_loss         | 0.000491     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 339         |\n",
      "|    iterations         | 17800       |\n",
      "|    time_elapsed       | 262         |\n",
      "|    total_timesteps    | 89000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.43       |\n",
      "|    explained_variance | -0.0823     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17799       |\n",
      "|    policy_loss        | 0.661       |\n",
      "|    reward             | -0.05491419 |\n",
      "|    std                | 6.02        |\n",
      "|    value_loss         | 0.015       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 339         |\n",
      "|    iterations         | 17900       |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 89500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.44       |\n",
      "|    explained_variance | -0.0113     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17899       |\n",
      "|    policy_loss        | -0.0481     |\n",
      "|    reward             | 0.005442266 |\n",
      "|    std                | 6.07        |\n",
      "|    value_loss         | 0.000165    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 339         |\n",
      "|    iterations         | 18000       |\n",
      "|    time_elapsed       | 265         |\n",
      "|    total_timesteps    | 90000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.47       |\n",
      "|    explained_variance | -0.272      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17999       |\n",
      "|    policy_loss        | -0.106      |\n",
      "|    reward             | -0.00952052 |\n",
      "|    std                | 6.14        |\n",
      "|    value_loss         | 0.000459    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 339        |\n",
      "|    iterations         | 18100      |\n",
      "|    time_elapsed       | 266        |\n",
      "|    total_timesteps    | 90500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.51      |\n",
      "|    explained_variance | 0.449      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 18099      |\n",
      "|    policy_loss        | -0.0508    |\n",
      "|    reward             | -0.0112784 |\n",
      "|    std                | 6.26       |\n",
      "|    value_loss         | 0.000209   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 339         |\n",
      "|    iterations         | 18200       |\n",
      "|    time_elapsed       | 268         |\n",
      "|    total_timesteps    | 91000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.55       |\n",
      "|    explained_variance | 0.584       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18199       |\n",
      "|    policy_loss        | -0.00692    |\n",
      "|    reward             | 0.019950477 |\n",
      "|    std                | 6.41        |\n",
      "|    value_loss         | 0.000302    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 339          |\n",
      "|    iterations         | 18300        |\n",
      "|    time_elapsed       | 269          |\n",
      "|    total_timesteps    | 91500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.58        |\n",
      "|    explained_variance | -0.0615      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 18299        |\n",
      "|    policy_loss        | 0.796        |\n",
      "|    reward             | -0.025540253 |\n",
      "|    std                | 6.48         |\n",
      "|    value_loss         | 0.0179       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 339          |\n",
      "|    iterations         | 18400        |\n",
      "|    time_elapsed       | 271          |\n",
      "|    total_timesteps    | 92000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.59        |\n",
      "|    explained_variance | 0.162        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 18399        |\n",
      "|    policy_loss        | 0.467        |\n",
      "|    reward             | -0.097020894 |\n",
      "|    std                | 6.52         |\n",
      "|    value_loss         | 0.0113       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 339           |\n",
      "|    iterations         | 18500         |\n",
      "|    time_elapsed       | 272           |\n",
      "|    total_timesteps    | 92500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.6          |\n",
      "|    explained_variance | 0.262         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 18499         |\n",
      "|    policy_loss        | 0.276         |\n",
      "|    reward             | 0.00094811036 |\n",
      "|    std                | 6.57          |\n",
      "|    value_loss         | 0.00205       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 338          |\n",
      "|    iterations         | 18600        |\n",
      "|    time_elapsed       | 274          |\n",
      "|    total_timesteps    | 93000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.62        |\n",
      "|    explained_variance | 0.0578       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 18599        |\n",
      "|    policy_loss        | 0.107        |\n",
      "|    reward             | -0.010196533 |\n",
      "|    std                | 6.63         |\n",
      "|    value_loss         | 0.000502     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 338          |\n",
      "|    iterations         | 18700        |\n",
      "|    time_elapsed       | 276          |\n",
      "|    total_timesteps    | 93500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.62        |\n",
      "|    explained_variance | 1.49e-06     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 18699        |\n",
      "|    policy_loss        | 0.546        |\n",
      "|    reward             | -0.017813265 |\n",
      "|    std                | 6.64         |\n",
      "|    value_loss         | 0.00869      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 338         |\n",
      "|    iterations         | 18800       |\n",
      "|    time_elapsed       | 277         |\n",
      "|    total_timesteps    | 94000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.63       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18799       |\n",
      "|    policy_loss        | 0.672       |\n",
      "|    reward             | 0.051926862 |\n",
      "|    std                | 6.65        |\n",
      "|    value_loss         | 0.0149      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 338         |\n",
      "|    iterations         | 18900       |\n",
      "|    time_elapsed       | 279         |\n",
      "|    total_timesteps    | 94500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.59       |\n",
      "|    explained_variance | -0.906      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18899       |\n",
      "|    policy_loss        | -0.642      |\n",
      "|    reward             | 0.089365974 |\n",
      "|    std                | 6.53        |\n",
      "|    value_loss         | 0.0106      |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 35\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 121415.05\n",
      "total_reward: 111415.05\n",
      "total_cost: 13.54\n",
      "total_trades: 5402\n",
      "Sharpe: 0.823\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 337          |\n",
      "|    iterations         | 19000        |\n",
      "|    time_elapsed       | 281          |\n",
      "|    total_timesteps    | 95000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.61        |\n",
      "|    explained_variance | -6.72        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 18999        |\n",
      "|    policy_loss        | 0.452        |\n",
      "|    reward             | 0.0070165712 |\n",
      "|    std                | 6.59         |\n",
      "|    value_loss         | 0.00528      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 337           |\n",
      "|    iterations         | 19100         |\n",
      "|    time_elapsed       | 282           |\n",
      "|    total_timesteps    | 95500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.63         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 19099         |\n",
      "|    policy_loss        | -0.0551       |\n",
      "|    reward             | -0.0028108298 |\n",
      "|    std                | 6.66          |\n",
      "|    value_loss         | 0.000145      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 337         |\n",
      "|    iterations         | 19200       |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 96000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.67       |\n",
      "|    explained_variance | 0.012       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19199       |\n",
      "|    policy_loss        | -0.0516     |\n",
      "|    reward             | 0.022300545 |\n",
      "|    std                | 6.79        |\n",
      "|    value_loss         | 0.000408    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 337          |\n",
      "|    iterations         | 19300        |\n",
      "|    time_elapsed       | 286          |\n",
      "|    total_timesteps    | 96500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.72        |\n",
      "|    explained_variance | 0.535        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 19299        |\n",
      "|    policy_loss        | 0.905        |\n",
      "|    reward             | -0.033103984 |\n",
      "|    std                | 6.97         |\n",
      "|    value_loss         | 0.0164       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 337          |\n",
      "|    iterations         | 19400        |\n",
      "|    time_elapsed       | 287          |\n",
      "|    total_timesteps    | 97000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.73        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 19399        |\n",
      "|    policy_loss        | 0.784        |\n",
      "|    reward             | -0.008847757 |\n",
      "|    std                | 6.99         |\n",
      "|    value_loss         | 0.0156       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 337         |\n",
      "|    iterations         | 19500       |\n",
      "|    time_elapsed       | 289         |\n",
      "|    total_timesteps    | 97500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.72       |\n",
      "|    explained_variance | -47.7       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19499       |\n",
      "|    policy_loss        | -0.835      |\n",
      "|    reward             | 0.014371057 |\n",
      "|    std                | 6.97        |\n",
      "|    value_loss         | 0.0312      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 336        |\n",
      "|    iterations         | 19600      |\n",
      "|    time_elapsed       | 290        |\n",
      "|    total_timesteps    | 98000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.73      |\n",
      "|    explained_variance | -3.58e-06  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 19599      |\n",
      "|    policy_loss        | -0.0924    |\n",
      "|    reward             | 0.01671088 |\n",
      "|    std                | 7.01       |\n",
      "|    value_loss         | 0.000205   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 19700       |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 98500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.76       |\n",
      "|    explained_variance | 0.684       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19699       |\n",
      "|    policy_loss        | 0.00227     |\n",
      "|    reward             | 0.038600627 |\n",
      "|    std                | 7.11        |\n",
      "|    value_loss         | 5.46e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 19800        |\n",
      "|    time_elapsed       | 293          |\n",
      "|    total_timesteps    | 99000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.79        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 19799        |\n",
      "|    policy_loss        | -0.00942     |\n",
      "|    reward             | -0.021748101 |\n",
      "|    std                | 7.23         |\n",
      "|    value_loss         | 0.000248     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 19900        |\n",
      "|    time_elapsed       | 295          |\n",
      "|    total_timesteps    | 99500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.83        |\n",
      "|    explained_variance | 0.32         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 19899        |\n",
      "|    policy_loss        | -0.288       |\n",
      "|    reward             | -0.008879966 |\n",
      "|    std                | 7.38         |\n",
      "|    value_loss         | 0.0137       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 20000       |\n",
      "|    time_elapsed       | 296         |\n",
      "|    total_timesteps    | 100000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.85       |\n",
      "|    explained_variance | 0.0286      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19999       |\n",
      "|    policy_loss        | -5.08       |\n",
      "|    reward             | 0.097441316 |\n",
      "|    std                | 7.42        |\n",
      "|    value_loss         | 0.647       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 20100        |\n",
      "|    time_elapsed       | 298          |\n",
      "|    total_timesteps    | 100500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.86        |\n",
      "|    explained_variance | 0.33         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20099        |\n",
      "|    policy_loss        | -0.0611      |\n",
      "|    reward             | -0.009200686 |\n",
      "|    std                | 7.46         |\n",
      "|    value_loss         | 8.4e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 20200        |\n",
      "|    time_elapsed       | 299          |\n",
      "|    total_timesteps    | 101000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.9         |\n",
      "|    explained_variance | -0.00269     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20199        |\n",
      "|    policy_loss        | -0.0129      |\n",
      "|    reward             | -0.005075861 |\n",
      "|    std                | 7.61         |\n",
      "|    value_loss         | 0.000437     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 337          |\n",
      "|    iterations         | 20300        |\n",
      "|    time_elapsed       | 301          |\n",
      "|    total_timesteps    | 101500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.95        |\n",
      "|    explained_variance | 0.113        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20299        |\n",
      "|    policy_loss        | 0.605        |\n",
      "|    reward             | -0.086293854 |\n",
      "|    std                | 7.81         |\n",
      "|    value_loss         | 0.0181       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 20400       |\n",
      "|    time_elapsed       | 302         |\n",
      "|    total_timesteps    | 102000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.95       |\n",
      "|    explained_variance | 0.0231      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20399       |\n",
      "|    policy_loss        | 0.401       |\n",
      "|    reward             | -0.08362578 |\n",
      "|    std                | 7.83        |\n",
      "|    value_loss         | 0.00475     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 20500       |\n",
      "|    time_elapsed       | 304         |\n",
      "|    total_timesteps    | 102500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.95       |\n",
      "|    explained_variance | 0.112       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20499       |\n",
      "|    policy_loss        | -2.09       |\n",
      "|    reward             | -0.00654459 |\n",
      "|    std                | 7.84        |\n",
      "|    value_loss         | 0.149       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 20600        |\n",
      "|    time_elapsed       | 305          |\n",
      "|    total_timesteps    | 103000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.96        |\n",
      "|    explained_variance | -0.615       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20599        |\n",
      "|    policy_loss        | 1.54         |\n",
      "|    reward             | 0.0033824185 |\n",
      "|    std                | 7.85         |\n",
      "|    value_loss         | 0.045        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 336           |\n",
      "|    iterations         | 20700         |\n",
      "|    time_elapsed       | 307           |\n",
      "|    total_timesteps    | 103500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.98         |\n",
      "|    explained_variance | -0.292        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 20699         |\n",
      "|    policy_loss        | 0.0647        |\n",
      "|    reward             | -0.0026162625 |\n",
      "|    std                | 7.94          |\n",
      "|    value_loss         | 9.66e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 20800        |\n",
      "|    time_elapsed       | 308          |\n",
      "|    total_timesteps    | 104000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.02        |\n",
      "|    explained_variance | -0.114       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20799        |\n",
      "|    policy_loss        | -0.0396      |\n",
      "|    reward             | 0.0066971057 |\n",
      "|    std                | 8.1          |\n",
      "|    value_loss         | 6.31e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 336        |\n",
      "|    iterations         | 20900      |\n",
      "|    time_elapsed       | 310        |\n",
      "|    total_timesteps    | 104500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.05      |\n",
      "|    explained_variance | -0.333     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 20899      |\n",
      "|    policy_loss        | 0.225      |\n",
      "|    reward             | 0.00812547 |\n",
      "|    std                | 8.21       |\n",
      "|    value_loss         | 0.00129    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 21000       |\n",
      "|    time_elapsed       | 311         |\n",
      "|    total_timesteps    | 105000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.08       |\n",
      "|    explained_variance | 9.36e-06    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20999       |\n",
      "|    policy_loss        | 0.498       |\n",
      "|    reward             | 0.022705479 |\n",
      "|    std                | 8.37        |\n",
      "|    value_loss         | 0.00465     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 21100        |\n",
      "|    time_elapsed       | 313          |\n",
      "|    total_timesteps    | 105500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.09        |\n",
      "|    explained_variance | 0.00688      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 21099        |\n",
      "|    policy_loss        | 0.0586       |\n",
      "|    reward             | -0.047427677 |\n",
      "|    std                | 8.37         |\n",
      "|    value_loss         | 0.000623     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 336           |\n",
      "|    iterations         | 21200         |\n",
      "|    time_elapsed       | 314           |\n",
      "|    total_timesteps    | 106000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.12         |\n",
      "|    explained_variance | -0.0263       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 21199         |\n",
      "|    policy_loss        | 0.061         |\n",
      "|    reward             | 2.0578384e-05 |\n",
      "|    std                | 8.51          |\n",
      "|    value_loss         | 0.000153      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 21300       |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 106500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.17       |\n",
      "|    explained_variance | 5.5e-05     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21299       |\n",
      "|    policy_loss        | -0.0206     |\n",
      "|    reward             | 0.017636918 |\n",
      "|    std                | 8.72        |\n",
      "|    value_loss         | 1.41e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 21400        |\n",
      "|    time_elapsed       | 317          |\n",
      "|    total_timesteps    | 107000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.23        |\n",
      "|    explained_variance | 0.00581      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 21399        |\n",
      "|    policy_loss        | -0.442       |\n",
      "|    reward             | -0.047938507 |\n",
      "|    std                | 9.01         |\n",
      "|    value_loss         | 0.00432      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 336           |\n",
      "|    iterations         | 21500         |\n",
      "|    time_elapsed       | 319           |\n",
      "|    total_timesteps    | 107500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.3          |\n",
      "|    explained_variance | 0.261         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 21499         |\n",
      "|    policy_loss        | -0.715        |\n",
      "|    reward             | -0.0035485688 |\n",
      "|    std                | 9.31          |\n",
      "|    value_loss         | 0.0102        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 21600       |\n",
      "|    time_elapsed       | 320         |\n",
      "|    total_timesteps    | 108000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.31       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21599       |\n",
      "|    policy_loss        | -0.0957     |\n",
      "|    reward             | 0.015145187 |\n",
      "|    std                | 9.39        |\n",
      "|    value_loss         | 0.00423     |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 40\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 63551.92\n",
      "total_reward: 53551.92\n",
      "total_cost: 11.17\n",
      "total_trades: 5410\n",
      "Sharpe: 0.692\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 21700       |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 108500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.33       |\n",
      "|    explained_variance | 2.83e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21699       |\n",
      "|    policy_loss        | 0.00429     |\n",
      "|    reward             | 0.025007945 |\n",
      "|    std                | 9.48        |\n",
      "|    value_loss         | 0.000228    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 21800        |\n",
      "|    time_elapsed       | 323          |\n",
      "|    total_timesteps    | 109000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.36        |\n",
      "|    explained_variance | 2.5e-05      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 21799        |\n",
      "|    policy_loss        | -0.0165      |\n",
      "|    reward             | 0.0065917834 |\n",
      "|    std                | 9.61         |\n",
      "|    value_loss         | 1.84e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 21900        |\n",
      "|    time_elapsed       | 325          |\n",
      "|    total_timesteps    | 109500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.42        |\n",
      "|    explained_variance | 0.0121       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 21899        |\n",
      "|    policy_loss        | -0.229       |\n",
      "|    reward             | -0.051337954 |\n",
      "|    std                | 9.9          |\n",
      "|    value_loss         | 0.00127      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 22000       |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 110000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.47       |\n",
      "|    explained_variance | 0.313       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21999       |\n",
      "|    policy_loss        | 0.484       |\n",
      "|    reward             | -0.11087947 |\n",
      "|    std                | 10.2        |\n",
      "|    value_loss         | 0.00517     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 22100       |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 110500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.5        |\n",
      "|    explained_variance | 0.317       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22099       |\n",
      "|    policy_loss        | -0.271      |\n",
      "|    reward             | 0.008615456 |\n",
      "|    std                | 10.3        |\n",
      "|    value_loss         | 0.00621     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 22200        |\n",
      "|    time_elapsed       | 329          |\n",
      "|    total_timesteps    | 111000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.5         |\n",
      "|    explained_variance | 0.234        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 22199        |\n",
      "|    policy_loss        | -0.129       |\n",
      "|    reward             | 0.0113367755 |\n",
      "|    std                | 10.3         |\n",
      "|    value_loss         | 0.00973      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 336           |\n",
      "|    iterations         | 22300         |\n",
      "|    time_elapsed       | 331           |\n",
      "|    total_timesteps    | 111500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.52         |\n",
      "|    explained_variance | -1.55e-06     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 22299         |\n",
      "|    policy_loss        | 0.0274        |\n",
      "|    reward             | -0.0053050495 |\n",
      "|    std                | 10.4          |\n",
      "|    value_loss         | 0.000133      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 22400       |\n",
      "|    time_elapsed       | 332         |\n",
      "|    total_timesteps    | 112000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.57       |\n",
      "|    explained_variance | 0.0281      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22399       |\n",
      "|    policy_loss        | -0.0702     |\n",
      "|    reward             | 0.034350723 |\n",
      "|    std                | 10.7        |\n",
      "|    value_loss         | 0.00041     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 22500       |\n",
      "|    time_elapsed       | 334         |\n",
      "|    total_timesteps    | 112500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.61       |\n",
      "|    explained_variance | -0.0256     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22499       |\n",
      "|    policy_loss        | 1.1         |\n",
      "|    reward             | -0.14856708 |\n",
      "|    std                | 10.9        |\n",
      "|    value_loss         | 0.0232      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 336        |\n",
      "|    iterations         | 22600      |\n",
      "|    time_elapsed       | 335        |\n",
      "|    total_timesteps    | 113000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.63      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 22599      |\n",
      "|    policy_loss        | -1.26      |\n",
      "|    reward             | 0.13306735 |\n",
      "|    std                | 11         |\n",
      "|    value_loss         | 0.0306     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 336        |\n",
      "|    iterations         | 22700      |\n",
      "|    time_elapsed       | 337        |\n",
      "|    total_timesteps    | 113500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.65      |\n",
      "|    explained_variance | 0.345      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 22699      |\n",
      "|    policy_loss        | 0.247      |\n",
      "|    reward             | 0.19042438 |\n",
      "|    std                | 11.1       |\n",
      "|    value_loss         | 0.00334    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 336           |\n",
      "|    iterations         | 22800         |\n",
      "|    time_elapsed       | 338           |\n",
      "|    total_timesteps    | 114000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.69         |\n",
      "|    explained_variance | 0.183         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 22799         |\n",
      "|    policy_loss        | -0.00808      |\n",
      "|    reward             | -0.0025621923 |\n",
      "|    std                | 11.4          |\n",
      "|    value_loss         | 9.32e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 22900       |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 114500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.73       |\n",
      "|    explained_variance | 0.124       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22899       |\n",
      "|    policy_loss        | -0.0394     |\n",
      "|    reward             | 0.012487481 |\n",
      "|    std                | 11.6        |\n",
      "|    value_loss         | 3.71e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 23000        |\n",
      "|    time_elapsed       | 341          |\n",
      "|    total_timesteps    | 115000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.76        |\n",
      "|    explained_variance | 0.249        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 22999        |\n",
      "|    policy_loss        | -0.153       |\n",
      "|    reward             | -0.005575736 |\n",
      "|    std                | 11.8         |\n",
      "|    value_loss         | 0.00126      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 23100       |\n",
      "|    time_elapsed       | 342         |\n",
      "|    total_timesteps    | 115500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.78       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 23099       |\n",
      "|    policy_loss        | 0.286       |\n",
      "|    reward             | 0.002177719 |\n",
      "|    std                | 11.9        |\n",
      "|    value_loss         | 0.00161     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 336        |\n",
      "|    iterations         | 23200      |\n",
      "|    time_elapsed       | 344        |\n",
      "|    total_timesteps    | 116000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.76      |\n",
      "|    explained_variance | 0.000214   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 23199      |\n",
      "|    policy_loss        | -0.249     |\n",
      "|    reward             | 0.09031969 |\n",
      "|    std                | 11.7       |\n",
      "|    value_loss         | 0.00263    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 23300        |\n",
      "|    time_elapsed       | 345          |\n",
      "|    total_timesteps    | 116500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.76        |\n",
      "|    explained_variance | -1.63        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23299        |\n",
      "|    policy_loss        | -0.228       |\n",
      "|    reward             | -0.012023055 |\n",
      "|    std                | 11.7         |\n",
      "|    value_loss         | 0.0013       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 23400        |\n",
      "|    time_elapsed       | 347          |\n",
      "|    total_timesteps    | 117000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.79        |\n",
      "|    explained_variance | 0.208        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23399        |\n",
      "|    policy_loss        | 0.0961       |\n",
      "|    reward             | -0.010174762 |\n",
      "|    std                | 11.9         |\n",
      "|    value_loss         | 0.000379     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 336           |\n",
      "|    iterations         | 23500         |\n",
      "|    time_elapsed       | 348           |\n",
      "|    total_timesteps    | 117500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.83         |\n",
      "|    explained_variance | 0.00111       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 23499         |\n",
      "|    policy_loss        | -0.0344       |\n",
      "|    reward             | 0.00048334923 |\n",
      "|    std                | 12.2          |\n",
      "|    value_loss         | 4.43e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 23600       |\n",
      "|    time_elapsed       | 350         |\n",
      "|    total_timesteps    | 118000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.89       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 23599       |\n",
      "|    policy_loss        | 0.215       |\n",
      "|    reward             | 0.036673523 |\n",
      "|    std                | 12.5        |\n",
      "|    value_loss         | 0.0018      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 336        |\n",
      "|    iterations         | 23700      |\n",
      "|    time_elapsed       | 351        |\n",
      "|    total_timesteps    | 118500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.92      |\n",
      "|    explained_variance | 0.0961     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 23699      |\n",
      "|    policy_loss        | 0.594      |\n",
      "|    reward             | 0.08101477 |\n",
      "|    std                | 12.7       |\n",
      "|    value_loss         | 0.00631    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 23800       |\n",
      "|    time_elapsed       | 353         |\n",
      "|    total_timesteps    | 119000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.91       |\n",
      "|    explained_variance | 0.119       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 23799       |\n",
      "|    policy_loss        | 1.69        |\n",
      "|    reward             | -0.09329728 |\n",
      "|    std                | 12.7        |\n",
      "|    value_loss         | 0.0605      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 23900        |\n",
      "|    time_elapsed       | 354          |\n",
      "|    total_timesteps    | 119500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.92        |\n",
      "|    explained_variance | 0.0941       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23899        |\n",
      "|    policy_loss        | -0.321       |\n",
      "|    reward             | -0.007966486 |\n",
      "|    std                | 12.7         |\n",
      "|    value_loss         | 0.00469      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 24000        |\n",
      "|    time_elapsed       | 356          |\n",
      "|    total_timesteps    | 120000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.94        |\n",
      "|    explained_variance | 1.16e-05     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23999        |\n",
      "|    policy_loss        | 0.0363       |\n",
      "|    reward             | -0.024600329 |\n",
      "|    std                | 12.9         |\n",
      "|    value_loss         | 0.00011      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 336       |\n",
      "|    iterations         | 24100     |\n",
      "|    time_elapsed       | 358       |\n",
      "|    total_timesteps    | 120500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8        |\n",
      "|    explained_variance | 0.311     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 24099     |\n",
      "|    policy_loss        | -0.339    |\n",
      "|    reward             | 0.1502921 |\n",
      "|    std                | 13.3      |\n",
      "|    value_loss         | 0.00414   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 24200       |\n",
      "|    time_elapsed       | 359         |\n",
      "|    total_timesteps    | 121000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.04       |\n",
      "|    explained_variance | 0.126       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 24199       |\n",
      "|    policy_loss        | -1.35       |\n",
      "|    reward             | -0.10057846 |\n",
      "|    std                | 13.5        |\n",
      "|    value_loss         | 0.0315      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 336        |\n",
      "|    iterations         | 24300      |\n",
      "|    time_elapsed       | 361        |\n",
      "|    total_timesteps    | 121500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.05      |\n",
      "|    explained_variance | 0.0527     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 24299      |\n",
      "|    policy_loss        | 2.79       |\n",
      "|    reward             | -0.3378073 |\n",
      "|    std                | 13.6       |\n",
      "|    value_loss         | 0.164      |\n",
      "--------------------------------------\n",
      "day: 2707, episode: 45\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 164697.85\n",
      "total_reward: 154697.85\n",
      "total_cost: 22.75\n",
      "total_trades: 3238\n",
      "Sharpe: 0.884\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 336          |\n",
      "|    iterations         | 24400        |\n",
      "|    time_elapsed       | 362          |\n",
      "|    total_timesteps    | 122000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.05        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 24399        |\n",
      "|    policy_loss        | -0.0478      |\n",
      "|    reward             | 0.0024751665 |\n",
      "|    std                | 13.5         |\n",
      "|    value_loss         | 6.28e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 336           |\n",
      "|    iterations         | 24500         |\n",
      "|    time_elapsed       | 364           |\n",
      "|    total_timesteps    | 122500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.07         |\n",
      "|    explained_variance | -6.62         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 24499         |\n",
      "|    policy_loss        | -0.0279       |\n",
      "|    reward             | -0.0030081882 |\n",
      "|    std                | 13.7          |\n",
      "|    value_loss         | 2.13e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 336         |\n",
      "|    iterations         | 24600       |\n",
      "|    time_elapsed       | 365         |\n",
      "|    total_timesteps    | 123000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.11       |\n",
      "|    explained_variance | 0.0271      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 24599       |\n",
      "|    policy_loss        | -0.303      |\n",
      "|    reward             | -0.11480482 |\n",
      "|    std                | 14          |\n",
      "|    value_loss         | 0.00178     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 24700       |\n",
      "|    time_elapsed       | 367         |\n",
      "|    total_timesteps    | 123500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.15       |\n",
      "|    explained_variance | 0.00181     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 24699       |\n",
      "|    policy_loss        | 0.00809     |\n",
      "|    reward             | 0.054443285 |\n",
      "|    std                | 14.3        |\n",
      "|    value_loss         | 0.000359    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 24800       |\n",
      "|    time_elapsed       | 369         |\n",
      "|    total_timesteps    | 124000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.19       |\n",
      "|    explained_variance | -0.000339   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 24799       |\n",
      "|    policy_loss        | 0.724       |\n",
      "|    reward             | 0.044749584 |\n",
      "|    std                | 14.6        |\n",
      "|    value_loss         | 0.0112      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 335       |\n",
      "|    iterations         | 24900     |\n",
      "|    time_elapsed       | 370       |\n",
      "|    total_timesteps    | 124500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.22     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 24899     |\n",
      "|    policy_loss        | -0.707    |\n",
      "|    reward             | 0.0738767 |\n",
      "|    std                | 14.8      |\n",
      "|    value_loss         | 0.00925   |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 25000        |\n",
      "|    time_elapsed       | 372          |\n",
      "|    total_timesteps    | 125000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.25        |\n",
      "|    explained_variance | 0.0679       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 24999        |\n",
      "|    policy_loss        | -0.0341      |\n",
      "|    reward             | 0.0023815131 |\n",
      "|    std                | 15           |\n",
      "|    value_loss         | 3.51e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 335           |\n",
      "|    iterations         | 25100         |\n",
      "|    time_elapsed       | 373           |\n",
      "|    total_timesteps    | 125500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.3          |\n",
      "|    explained_variance | -0.603        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 25099         |\n",
      "|    policy_loss        | 0.235         |\n",
      "|    reward             | -0.0020951973 |\n",
      "|    std                | 15.4          |\n",
      "|    value_loss         | 0.000635      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 25200        |\n",
      "|    time_elapsed       | 375          |\n",
      "|    total_timesteps    | 126000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.36        |\n",
      "|    explained_variance | 0.164        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 25199        |\n",
      "|    policy_loss        | 0.417        |\n",
      "|    reward             | -0.008482979 |\n",
      "|    std                | 15.9         |\n",
      "|    value_loss         | 0.0027       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 25300       |\n",
      "|    time_elapsed       | 376         |\n",
      "|    total_timesteps    | 126500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.38       |\n",
      "|    explained_variance | -0.00034    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25299       |\n",
      "|    policy_loss        | 0.611       |\n",
      "|    reward             | -0.07168675 |\n",
      "|    std                | 16          |\n",
      "|    value_loss         | 0.00586     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 25400       |\n",
      "|    time_elapsed       | 378         |\n",
      "|    total_timesteps    | 127000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.41       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25399       |\n",
      "|    policy_loss        | -0.161      |\n",
      "|    reward             | 0.026035242 |\n",
      "|    std                | 16.2        |\n",
      "|    value_loss         | 0.00174     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 25500        |\n",
      "|    time_elapsed       | 380          |\n",
      "|    total_timesteps    | 127500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.43        |\n",
      "|    explained_variance | -0.000461    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 25499        |\n",
      "|    policy_loss        | 0.31         |\n",
      "|    reward             | 0.0069395807 |\n",
      "|    std                | 16.4         |\n",
      "|    value_loss         | 0.00158      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 25600        |\n",
      "|    time_elapsed       | 381          |\n",
      "|    total_timesteps    | 128000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.45        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 25599        |\n",
      "|    policy_loss        | -0.0837      |\n",
      "|    reward             | -0.013650727 |\n",
      "|    std                | 16.6         |\n",
      "|    value_loss         | 0.000378     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 25700       |\n",
      "|    time_elapsed       | 383         |\n",
      "|    total_timesteps    | 128500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.5        |\n",
      "|    explained_variance | 0.102       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25699       |\n",
      "|    policy_loss        | 0.038       |\n",
      "|    reward             | 0.030901639 |\n",
      "|    std                | 16.9        |\n",
      "|    value_loss         | 0.00325     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 25800       |\n",
      "|    time_elapsed       | 385         |\n",
      "|    total_timesteps    | 129000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.53       |\n",
      "|    explained_variance | 0.00108     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25799       |\n",
      "|    policy_loss        | 0.765       |\n",
      "|    reward             | 0.014043078 |\n",
      "|    std                | 17.2        |\n",
      "|    value_loss         | 0.0369      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 25900        |\n",
      "|    time_elapsed       | 386          |\n",
      "|    total_timesteps    | 129500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.54        |\n",
      "|    explained_variance | 0.227        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 25899        |\n",
      "|    policy_loss        | 2.39         |\n",
      "|    reward             | -0.053262006 |\n",
      "|    std                | 17.3         |\n",
      "|    value_loss         | 0.0809       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 26000       |\n",
      "|    time_elapsed       | 388         |\n",
      "|    total_timesteps    | 130000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.55       |\n",
      "|    explained_variance | -0.078      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25999       |\n",
      "|    policy_loss        | -0.265      |\n",
      "|    reward             | 0.009328875 |\n",
      "|    std                | 17.4        |\n",
      "|    value_loss         | 0.0012      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 26100        |\n",
      "|    time_elapsed       | 389          |\n",
      "|    total_timesteps    | 130500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.57        |\n",
      "|    explained_variance | 0.456        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26099        |\n",
      "|    policy_loss        | -0.167       |\n",
      "|    reward             | -0.011051806 |\n",
      "|    std                | 17.6         |\n",
      "|    value_loss         | 0.000789     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 26200       |\n",
      "|    time_elapsed       | 391         |\n",
      "|    total_timesteps    | 131000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.59       |\n",
      "|    explained_variance | 0.633       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 26199       |\n",
      "|    policy_loss        | -0.442      |\n",
      "|    reward             | 0.010389614 |\n",
      "|    std                | 17.8        |\n",
      "|    value_loss         | 0.00387     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 26300        |\n",
      "|    time_elapsed       | 392          |\n",
      "|    total_timesteps    | 131500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.64        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26299        |\n",
      "|    policy_loss        | -0.0265      |\n",
      "|    reward             | -0.015656551 |\n",
      "|    std                | 18.2         |\n",
      "|    value_loss         | 0.00159      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 26400       |\n",
      "|    time_elapsed       | 394         |\n",
      "|    total_timesteps    | 132000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.64       |\n",
      "|    explained_variance | 0.447       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 26399       |\n",
      "|    policy_loss        | -1.59       |\n",
      "|    reward             | -0.01098221 |\n",
      "|    std                | 18.2        |\n",
      "|    value_loss         | 0.0399      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 26500        |\n",
      "|    time_elapsed       | 395          |\n",
      "|    total_timesteps    | 132500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.65        |\n",
      "|    explained_variance | 2.38e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26499        |\n",
      "|    policy_loss        | 5.19         |\n",
      "|    reward             | -0.105815426 |\n",
      "|    std                | 18.3         |\n",
      "|    value_loss         | 0.433        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 26600       |\n",
      "|    time_elapsed       | 397         |\n",
      "|    total_timesteps    | 133000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.65       |\n",
      "|    explained_variance | -3.02       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 26599       |\n",
      "|    policy_loss        | -0.555      |\n",
      "|    reward             | 0.055497963 |\n",
      "|    std                | 18.4        |\n",
      "|    value_loss         | 0.00565     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 334        |\n",
      "|    iterations         | 26700      |\n",
      "|    time_elapsed       | 398        |\n",
      "|    total_timesteps    | 133500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.69      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 26699      |\n",
      "|    policy_loss        | -0.301     |\n",
      "|    reward             | 0.02519546 |\n",
      "|    std                | 18.7       |\n",
      "|    value_loss         | 0.00149    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 26800       |\n",
      "|    time_elapsed       | 400         |\n",
      "|    total_timesteps    | 134000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.73       |\n",
      "|    explained_variance | 0.101       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 26799       |\n",
      "|    policy_loss        | -0.667      |\n",
      "|    reward             | -0.05960305 |\n",
      "|    std                | 19          |\n",
      "|    value_loss         | 0.0111      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 26900       |\n",
      "|    time_elapsed       | 401         |\n",
      "|    total_timesteps    | 134500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.75       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 26899       |\n",
      "|    policy_loss        | -0.248      |\n",
      "|    reward             | 0.022486975 |\n",
      "|    std                | 19.2        |\n",
      "|    value_loss         | 0.00299     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 334       |\n",
      "|    iterations         | 27000     |\n",
      "|    time_elapsed       | 403       |\n",
      "|    total_timesteps    | 135000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.75     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 26999     |\n",
      "|    policy_loss        | -4.09     |\n",
      "|    reward             | 0.4571316 |\n",
      "|    std                | 19.2      |\n",
      "|    value_loss         | 0.294     |\n",
      "-------------------------------------\n",
      "day: 2707, episode: 50\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 186065.89\n",
      "total_reward: 176065.89\n",
      "total_cost: 18.35\n",
      "total_trades: 5408\n",
      "Sharpe: 1.002\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 334           |\n",
      "|    iterations         | 27100         |\n",
      "|    time_elapsed       | 404           |\n",
      "|    total_timesteps    | 135500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.73         |\n",
      "|    explained_variance | -6.03         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 27099         |\n",
      "|    policy_loss        | -0.0534       |\n",
      "|    reward             | -0.0042993547 |\n",
      "|    std                | 19.1          |\n",
      "|    value_loss         | 0.00302       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 27200        |\n",
      "|    time_elapsed       | 406          |\n",
      "|    total_timesteps    | 136000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.75        |\n",
      "|    explained_variance | -0.113       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27199        |\n",
      "|    policy_loss        | 0.0559       |\n",
      "|    reward             | -0.016094847 |\n",
      "|    std                | 19.3         |\n",
      "|    value_loss         | 0.000101     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 27300       |\n",
      "|    time_elapsed       | 408         |\n",
      "|    total_timesteps    | 136500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.79       |\n",
      "|    explained_variance | -9.17       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 27299       |\n",
      "|    policy_loss        | 0.011       |\n",
      "|    reward             | 0.017458951 |\n",
      "|    std                | 19.6        |\n",
      "|    value_loss         | 0.000302    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 27400       |\n",
      "|    time_elapsed       | 409         |\n",
      "|    total_timesteps    | 137000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.83       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 27399       |\n",
      "|    policy_loss        | -0.111      |\n",
      "|    reward             | 0.021499315 |\n",
      "|    std                | 20.1        |\n",
      "|    value_loss         | 0.000207    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 27500       |\n",
      "|    time_elapsed       | 411         |\n",
      "|    total_timesteps    | 137500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.88       |\n",
      "|    explained_variance | 0.652       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 27499       |\n",
      "|    policy_loss        | -0.054      |\n",
      "|    reward             | 0.014391404 |\n",
      "|    std                | 20.6        |\n",
      "|    value_loss         | 0.000824    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 334        |\n",
      "|    iterations         | 27600      |\n",
      "|    time_elapsed       | 412        |\n",
      "|    total_timesteps    | 138000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.9       |\n",
      "|    explained_variance | 0.483      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 27599      |\n",
      "|    policy_loss        | -0.214     |\n",
      "|    reward             | 0.01644917 |\n",
      "|    std                | 20.8       |\n",
      "|    value_loss         | 0.000641   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 27700        |\n",
      "|    time_elapsed       | 414          |\n",
      "|    total_timesteps    | 138500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.93        |\n",
      "|    explained_variance | 0.417        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27699        |\n",
      "|    policy_loss        | 0.114        |\n",
      "|    reward             | -0.027097343 |\n",
      "|    std                | 21           |\n",
      "|    value_loss         | 0.000208     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 27800       |\n",
      "|    time_elapsed       | 415         |\n",
      "|    total_timesteps    | 139000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.98       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 27799       |\n",
      "|    policy_loss        | -0.314      |\n",
      "|    reward             | 0.019721795 |\n",
      "|    std                | 21.5        |\n",
      "|    value_loss         | 0.00128     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 27900       |\n",
      "|    time_elapsed       | 417         |\n",
      "|    total_timesteps    | 139500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.02       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 27899       |\n",
      "|    policy_loss        | -0.141      |\n",
      "|    reward             | 0.014732051 |\n",
      "|    std                | 22.1        |\n",
      "|    value_loss         | 0.00228     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 334        |\n",
      "|    iterations         | 28000      |\n",
      "|    time_elapsed       | 418        |\n",
      "|    total_timesteps    | 140000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.07      |\n",
      "|    explained_variance | 0.433      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 27999      |\n",
      "|    policy_loss        | 0.206      |\n",
      "|    reward             | 0.03616096 |\n",
      "|    std                | 22.6       |\n",
      "|    value_loss         | 0.00186    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 28100       |\n",
      "|    time_elapsed       | 420         |\n",
      "|    total_timesteps    | 140500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.09       |\n",
      "|    explained_variance | 0.212       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 28099       |\n",
      "|    policy_loss        | -1.89       |\n",
      "|    reward             | -0.12765017 |\n",
      "|    std                | 22.8        |\n",
      "|    value_loss         | 0.047       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 28200        |\n",
      "|    time_elapsed       | 421          |\n",
      "|    total_timesteps    | 141000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.12        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28199        |\n",
      "|    policy_loss        | -0.0511      |\n",
      "|    reward             | 0.0052139657 |\n",
      "|    std                | 23.1         |\n",
      "|    value_loss         | 6.28e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 28300       |\n",
      "|    time_elapsed       | 423         |\n",
      "|    total_timesteps    | 141500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.15       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 28299       |\n",
      "|    policy_loss        | 0.108       |\n",
      "|    reward             | 0.010406428 |\n",
      "|    std                | 23.5        |\n",
      "|    value_loss         | 0.000197    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 28400        |\n",
      "|    time_elapsed       | 425          |\n",
      "|    total_timesteps    | 142000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.2         |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28399        |\n",
      "|    policy_loss        | 0.832        |\n",
      "|    reward             | -0.029083345 |\n",
      "|    std                | 24.2         |\n",
      "|    value_loss         | 0.00965      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 28500       |\n",
      "|    time_elapsed       | 426         |\n",
      "|    total_timesteps    | 142500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.22       |\n",
      "|    explained_variance | 0.215       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 28499       |\n",
      "|    policy_loss        | -0.604      |\n",
      "|    reward             | 0.043231215 |\n",
      "|    std                | 24.4        |\n",
      "|    value_loss         | 0.00489     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 28600      |\n",
      "|    time_elapsed       | 428        |\n",
      "|    total_timesteps    | 143000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.23      |\n",
      "|    explained_variance | 0.414      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 28599      |\n",
      "|    policy_loss        | 0.574      |\n",
      "|    reward             | 0.09324138 |\n",
      "|    std                | 24.4       |\n",
      "|    value_loss         | 0.00575    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 28700       |\n",
      "|    time_elapsed       | 429         |\n",
      "|    total_timesteps    | 143500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.24       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 28699       |\n",
      "|    policy_loss        | 0.414       |\n",
      "|    reward             | 0.046550058 |\n",
      "|    std                | 24.6        |\n",
      "|    value_loss         | 0.00469     |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 333            |\n",
      "|    iterations         | 28800          |\n",
      "|    time_elapsed       | 431            |\n",
      "|    total_timesteps    | 144000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -9.28          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 28799          |\n",
      "|    policy_loss        | -0.0691        |\n",
      "|    reward             | -0.00017437592 |\n",
      "|    std                | 25.1           |\n",
      "|    value_loss         | 9.16e-05       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 28900        |\n",
      "|    time_elapsed       | 432          |\n",
      "|    total_timesteps    | 144500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.33        |\n",
      "|    explained_variance | 0.254        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28899        |\n",
      "|    policy_loss        | 0.266        |\n",
      "|    reward             | 0.0036995248 |\n",
      "|    std                | 25.8         |\n",
      "|    value_loss         | 0.000915     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 29000       |\n",
      "|    time_elapsed       | 434         |\n",
      "|    total_timesteps    | 145000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.36       |\n",
      "|    explained_variance | 0.0658      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 28999       |\n",
      "|    policy_loss        | 0.446       |\n",
      "|    reward             | -0.04984193 |\n",
      "|    std                | 26          |\n",
      "|    value_loss         | 0.00597     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 29100      |\n",
      "|    time_elapsed       | 436        |\n",
      "|    total_timesteps    | 145500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.37      |\n",
      "|    explained_variance | 0.305      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 29099      |\n",
      "|    policy_loss        | -1.54      |\n",
      "|    reward             | 0.19945045 |\n",
      "|    std                | 26.2       |\n",
      "|    value_loss         | 0.0324     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 29200        |\n",
      "|    time_elapsed       | 437          |\n",
      "|    total_timesteps    | 146000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.36        |\n",
      "|    explained_variance | 0.304        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29199        |\n",
      "|    policy_loss        | -1.14        |\n",
      "|    reward             | -0.002884285 |\n",
      "|    std                | 26           |\n",
      "|    value_loss         | 0.0219       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 29300        |\n",
      "|    time_elapsed       | 438          |\n",
      "|    total_timesteps    | 146500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.38        |\n",
      "|    explained_variance | 0.000233     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29299        |\n",
      "|    policy_loss        | -0.0547      |\n",
      "|    reward             | -0.006209998 |\n",
      "|    std                | 26.3         |\n",
      "|    value_loss         | 0.000133     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 29400        |\n",
      "|    time_elapsed       | 440          |\n",
      "|    total_timesteps    | 147000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.42        |\n",
      "|    explained_variance | 0.591        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29399        |\n",
      "|    policy_loss        | -0.0204      |\n",
      "|    reward             | 0.0047540166 |\n",
      "|    std                | 26.9         |\n",
      "|    value_loss         | 2.21e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 29500        |\n",
      "|    time_elapsed       | 442          |\n",
      "|    total_timesteps    | 147500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.45        |\n",
      "|    explained_variance | 3.93e-06     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29499        |\n",
      "|    policy_loss        | 0.119        |\n",
      "|    reward             | -0.009269079 |\n",
      "|    std                | 27.3         |\n",
      "|    value_loss         | 0.000204     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 29600         |\n",
      "|    time_elapsed       | 443           |\n",
      "|    total_timesteps    | 148000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -9.47         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 29599         |\n",
      "|    policy_loss        | -0.396        |\n",
      "|    reward             | -0.0038707382 |\n",
      "|    std                | 27.5          |\n",
      "|    value_loss         | 0.00214       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 29700       |\n",
      "|    time_elapsed       | 445         |\n",
      "|    total_timesteps    | 148500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.49       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 29699       |\n",
      "|    policy_loss        | 0.808       |\n",
      "|    reward             | 0.040416647 |\n",
      "|    std                | 28          |\n",
      "|    value_loss         | 0.00731     |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 55\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 83405.65\n",
      "total_reward: 73405.65\n",
      "total_cost: 13.00\n",
      "total_trades: 5411\n",
      "Sharpe: 0.738\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 29800        |\n",
      "|    time_elapsed       | 446          |\n",
      "|    total_timesteps    | 149000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.54        |\n",
      "|    explained_variance | 0.191        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29799        |\n",
      "|    policy_loss        | -0.0832      |\n",
      "|    reward             | 0.0022262337 |\n",
      "|    std                | 28.6         |\n",
      "|    value_loss         | 7.86e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 29900       |\n",
      "|    time_elapsed       | 448         |\n",
      "|    total_timesteps    | 149500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.56       |\n",
      "|    explained_variance | -0.0666     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 29899       |\n",
      "|    policy_loss        | 0.0499      |\n",
      "|    reward             | 0.003574707 |\n",
      "|    std                | 28.9        |\n",
      "|    value_loss         | 4.29e-05    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 30000         |\n",
      "|    time_elapsed       | 449           |\n",
      "|    total_timesteps    | 150000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -9.6          |\n",
      "|    explained_variance | -0.121        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 29999         |\n",
      "|    policy_loss        | -0.0336       |\n",
      "|    reward             | -0.0010686904 |\n",
      "|    std                | 29.5          |\n",
      "|    value_loss         | 1.46e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 30100        |\n",
      "|    time_elapsed       | 451          |\n",
      "|    total_timesteps    | 150500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.65        |\n",
      "|    explained_variance | -0.00551     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 30099        |\n",
      "|    policy_loss        | 0.65         |\n",
      "|    reward             | -0.010737088 |\n",
      "|    std                | 30.1         |\n",
      "|    value_loss         | 0.00543      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 30200       |\n",
      "|    time_elapsed       | 452         |\n",
      "|    total_timesteps    | 151000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.66       |\n",
      "|    explained_variance | 0.398       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30199       |\n",
      "|    policy_loss        | 0.433       |\n",
      "|    reward             | 0.012693815 |\n",
      "|    std                | 30.4        |\n",
      "|    value_loss         | 0.0026      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 30300      |\n",
      "|    time_elapsed       | 454        |\n",
      "|    total_timesteps    | 151500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.7       |\n",
      "|    explained_variance | 1.37e-06   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 30299      |\n",
      "|    policy_loss        | 1.29       |\n",
      "|    reward             | 0.13549265 |\n",
      "|    std                | 30.9       |\n",
      "|    value_loss         | 0.0175     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 30400      |\n",
      "|    time_elapsed       | 455        |\n",
      "|    total_timesteps    | 152000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.75      |\n",
      "|    explained_variance | 0.0428     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 30399      |\n",
      "|    policy_loss        | 0.21       |\n",
      "|    reward             | 0.03866871 |\n",
      "|    std                | 31.7       |\n",
      "|    value_loss         | 0.00135    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 30500       |\n",
      "|    time_elapsed       | 457         |\n",
      "|    total_timesteps    | 152500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.77       |\n",
      "|    explained_variance | 0.554       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30499       |\n",
      "|    policy_loss        | 0.115       |\n",
      "|    reward             | 0.014199404 |\n",
      "|    std                | 32          |\n",
      "|    value_loss         | 0.000159    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 30600       |\n",
      "|    time_elapsed       | 458         |\n",
      "|    total_timesteps    | 153000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.81       |\n",
      "|    explained_variance | 0.123       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30599       |\n",
      "|    policy_loss        | -0.327      |\n",
      "|    reward             | -0.04309871 |\n",
      "|    std                | 32.8        |\n",
      "|    value_loss         | 0.00165     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 30700       |\n",
      "|    time_elapsed       | 460         |\n",
      "|    total_timesteps    | 153500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.84       |\n",
      "|    explained_variance | 0.0684      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30699       |\n",
      "|    policy_loss        | 0.301       |\n",
      "|    reward             | -0.04889239 |\n",
      "|    std                | 33.2        |\n",
      "|    value_loss         | 0.00702     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 30800        |\n",
      "|    time_elapsed       | 461          |\n",
      "|    total_timesteps    | 154000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.88        |\n",
      "|    explained_variance | 0.321        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 30799        |\n",
      "|    policy_loss        | -0.503       |\n",
      "|    reward             | -0.009111563 |\n",
      "|    std                | 33.8         |\n",
      "|    value_loss         | 0.00299      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 30900       |\n",
      "|    time_elapsed       | 463         |\n",
      "|    total_timesteps    | 154500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.9        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30899       |\n",
      "|    policy_loss        | -0.16       |\n",
      "|    reward             | 0.008400717 |\n",
      "|    std                | 34.2        |\n",
      "|    value_loss         | 0.000328    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 31000        |\n",
      "|    time_elapsed       | 464          |\n",
      "|    total_timesteps    | 155000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.92        |\n",
      "|    explained_variance | 0.679        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 30999        |\n",
      "|    policy_loss        | -0.151       |\n",
      "|    reward             | -0.027334273 |\n",
      "|    std                | 34.6         |\n",
      "|    value_loss         | 0.000455     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 31100       |\n",
      "|    time_elapsed       | 466         |\n",
      "|    total_timesteps    | 155500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.95       |\n",
      "|    explained_variance | 0.000213    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 31099       |\n",
      "|    policy_loss        | -0.713      |\n",
      "|    reward             | 0.058036916 |\n",
      "|    std                | 35.1        |\n",
      "|    value_loss         | 0.00643     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 31200       |\n",
      "|    time_elapsed       | 467         |\n",
      "|    total_timesteps    | 156000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10         |\n",
      "|    explained_variance | 0.00808     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 31199       |\n",
      "|    policy_loss        | -0.566      |\n",
      "|    reward             | -0.12581247 |\n",
      "|    std                | 36.1        |\n",
      "|    value_loss         | 0.00327     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 31300       |\n",
      "|    time_elapsed       | 469         |\n",
      "|    total_timesteps    | 156500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 31299       |\n",
      "|    policy_loss        | -0.292      |\n",
      "|    reward             | -0.09364641 |\n",
      "|    std                | 36.8        |\n",
      "|    value_loss         | 0.00209     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 31400      |\n",
      "|    time_elapsed       | 470        |\n",
      "|    total_timesteps    | 157000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.1      |\n",
      "|    explained_variance | 0.0712     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 31399      |\n",
      "|    policy_loss        | -2         |\n",
      "|    reward             | 0.10681552 |\n",
      "|    std                | 37.1       |\n",
      "|    value_loss         | 0.0577     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 31500         |\n",
      "|    time_elapsed       | 472           |\n",
      "|    total_timesteps    | 157500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.1         |\n",
      "|    explained_variance | -1.18         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 31499         |\n",
      "|    policy_loss        | -0.029        |\n",
      "|    reward             | -0.0074193557 |\n",
      "|    std                | 37.3          |\n",
      "|    value_loss         | 0.000289      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 31600        |\n",
      "|    time_elapsed       | 473          |\n",
      "|    total_timesteps    | 158000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.1        |\n",
      "|    explained_variance | 0.254        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 31599        |\n",
      "|    policy_loss        | -0.0401      |\n",
      "|    reward             | 0.0070094946 |\n",
      "|    std                | 37.9         |\n",
      "|    value_loss         | 8.39e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 31700        |\n",
      "|    time_elapsed       | 474          |\n",
      "|    total_timesteps    | 158500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.2        |\n",
      "|    explained_variance | -0.174       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 31699        |\n",
      "|    policy_loss        | 0.648        |\n",
      "|    reward             | -0.013395722 |\n",
      "|    std                | 39           |\n",
      "|    value_loss         | 0.00702      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 31800        |\n",
      "|    time_elapsed       | 476          |\n",
      "|    total_timesteps    | 159000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.2        |\n",
      "|    explained_variance | 0.125        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 31799        |\n",
      "|    policy_loss        | -0.0682      |\n",
      "|    reward             | 0.0063914373 |\n",
      "|    std                | 40           |\n",
      "|    value_loss         | 0.0014       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 31900       |\n",
      "|    time_elapsed       | 477         |\n",
      "|    total_timesteps    | 159500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.2       |\n",
      "|    explained_variance | 0.361       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 31899       |\n",
      "|    policy_loss        | 0.132       |\n",
      "|    reward             | 0.032525755 |\n",
      "|    std                | 40.5        |\n",
      "|    value_loss         | 0.000608    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 32000       |\n",
      "|    time_elapsed       | 479         |\n",
      "|    total_timesteps    | 160000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.3       |\n",
      "|    explained_variance | -0.0431     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 31999       |\n",
      "|    policy_loss        | -0.25       |\n",
      "|    reward             | 0.017656447 |\n",
      "|    std                | 41.3        |\n",
      "|    value_loss         | 0.000719    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 32100      |\n",
      "|    time_elapsed       | 480        |\n",
      "|    total_timesteps    | 160500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.3      |\n",
      "|    explained_variance | -0.352     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 32099      |\n",
      "|    policy_loss        | -0.109     |\n",
      "|    reward             | 0.00326103 |\n",
      "|    std                | 42         |\n",
      "|    value_loss         | 0.000128   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 32200      |\n",
      "|    time_elapsed       | 482        |\n",
      "|    total_timesteps    | 161000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.4      |\n",
      "|    explained_variance | -0.0197    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 32199      |\n",
      "|    policy_loss        | 0.105      |\n",
      "|    reward             | 0.01865872 |\n",
      "|    std                | 43.2       |\n",
      "|    value_loss         | 0.000155   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 32300         |\n",
      "|    time_elapsed       | 483           |\n",
      "|    total_timesteps    | 161500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.4         |\n",
      "|    explained_variance | 0.00372       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 32299         |\n",
      "|    policy_loss        | 0.106         |\n",
      "|    reward             | -0.0018658417 |\n",
      "|    std                | 44.3          |\n",
      "|    value_loss         | 0.000224      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 32400       |\n",
      "|    time_elapsed       | 485         |\n",
      "|    total_timesteps    | 162000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.5       |\n",
      "|    explained_variance | 0.0269      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 32399       |\n",
      "|    policy_loss        | 0.511       |\n",
      "|    reward             | -0.03695676 |\n",
      "|    std                | 45.7        |\n",
      "|    value_loss         | 0.00288     |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 60\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 36308.27\n",
      "total_reward: 26308.27\n",
      "total_cost: 17.52\n",
      "total_trades: 5408\n",
      "Sharpe: 0.556\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 32500        |\n",
      "|    time_elapsed       | 486          |\n",
      "|    total_timesteps    | 162500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.5        |\n",
      "|    explained_variance | 0.326        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32499        |\n",
      "|    policy_loss        | -0.0733      |\n",
      "|    reward             | -0.037988096 |\n",
      "|    std                | 46.6         |\n",
      "|    value_loss         | 0.000133     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 32600       |\n",
      "|    time_elapsed       | 488         |\n",
      "|    total_timesteps    | 163000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.6       |\n",
      "|    explained_variance | 0.0377      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 32599       |\n",
      "|    policy_loss        | 0.0957      |\n",
      "|    reward             | -0.03204107 |\n",
      "|    std                | 47.9        |\n",
      "|    value_loss         | 0.000454    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 32700       |\n",
      "|    time_elapsed       | 490         |\n",
      "|    total_timesteps    | 163500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.6       |\n",
      "|    explained_variance | 0.029       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 32699       |\n",
      "|    policy_loss        | -0.742      |\n",
      "|    reward             | 0.055968408 |\n",
      "|    std                | 49.2        |\n",
      "|    value_loss         | 0.00815     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 32800       |\n",
      "|    time_elapsed       | 491         |\n",
      "|    total_timesteps    | 164000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.7       |\n",
      "|    explained_variance | 0.0528      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 32799       |\n",
      "|    policy_loss        | -0.226      |\n",
      "|    reward             | -0.11574915 |\n",
      "|    std                | 50          |\n",
      "|    value_loss         | 0.00282     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 32900      |\n",
      "|    time_elapsed       | 493        |\n",
      "|    total_timesteps    | 164500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.7      |\n",
      "|    explained_variance | 0.00202    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 32899      |\n",
      "|    policy_loss        | -0.201     |\n",
      "|    reward             | 0.01321616 |\n",
      "|    std                | 50.3       |\n",
      "|    value_loss         | 0.0467     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 333       |\n",
      "|    iterations         | 33000     |\n",
      "|    time_elapsed       | 494       |\n",
      "|    total_timesteps    | 165000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -10.7     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 32999     |\n",
      "|    policy_loss        | 8.69      |\n",
      "|    reward             | 0.7882268 |\n",
      "|    std                | 50.9      |\n",
      "|    value_loss         | 1.18      |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 33100         |\n",
      "|    time_elapsed       | 496           |\n",
      "|    total_timesteps    | 165500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.7         |\n",
      "|    explained_variance | 0.356         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 33099         |\n",
      "|    policy_loss        | -0.24         |\n",
      "|    reward             | -0.0013382512 |\n",
      "|    std                | 51.4          |\n",
      "|    value_loss         | 0.000691      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 33200        |\n",
      "|    time_elapsed       | 497          |\n",
      "|    total_timesteps    | 166000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.7        |\n",
      "|    explained_variance | 0.00564      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 33199        |\n",
      "|    policy_loss        | 0.385        |\n",
      "|    reward             | -0.017920045 |\n",
      "|    std                | 51.8         |\n",
      "|    value_loss         | 0.00157      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 33300      |\n",
      "|    time_elapsed       | 499        |\n",
      "|    total_timesteps    | 166500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.8      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 33299      |\n",
      "|    policy_loss        | -0.000543  |\n",
      "|    reward             | 0.06007585 |\n",
      "|    std                | 52.6       |\n",
      "|    value_loss         | 0.0024     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 33400       |\n",
      "|    time_elapsed       | 500         |\n",
      "|    total_timesteps    | 167000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.8       |\n",
      "|    explained_variance | 2.16e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 33399       |\n",
      "|    policy_loss        | 2.32        |\n",
      "|    reward             | 0.007573286 |\n",
      "|    std                | 52.7        |\n",
      "|    value_loss         | 0.0927      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 333       |\n",
      "|    iterations         | 33500     |\n",
      "|    time_elapsed       | 501       |\n",
      "|    total_timesteps    | 167500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -10.8     |\n",
      "|    explained_variance | -5.13e-06 |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 33499     |\n",
      "|    policy_loss        | -0.613    |\n",
      "|    reward             | 0.1528573 |\n",
      "|    std                | 53.2      |\n",
      "|    value_loss         | 0.00621   |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 33600         |\n",
      "|    time_elapsed       | 503           |\n",
      "|    total_timesteps    | 168000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.8         |\n",
      "|    explained_variance | -2.03         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 33599         |\n",
      "|    policy_loss        | -0.259        |\n",
      "|    reward             | -0.0070073297 |\n",
      "|    std                | 53.5          |\n",
      "|    value_loss         | 0.00079       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 33700        |\n",
      "|    time_elapsed       | 504          |\n",
      "|    total_timesteps    | 168500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.8        |\n",
      "|    explained_variance | -0.147       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 33699        |\n",
      "|    policy_loss        | -0.104       |\n",
      "|    reward             | 0.0033660245 |\n",
      "|    std                | 54.3         |\n",
      "|    value_loss         | 0.000282     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 33800       |\n",
      "|    time_elapsed       | 506         |\n",
      "|    total_timesteps    | 169000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.9       |\n",
      "|    explained_variance | 0.117       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 33799       |\n",
      "|    policy_loss        | 0.165       |\n",
      "|    reward             | 0.014834238 |\n",
      "|    std                | 55.4        |\n",
      "|    value_loss         | 0.000263    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 33900      |\n",
      "|    time_elapsed       | 507        |\n",
      "|    total_timesteps    | 169500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.9      |\n",
      "|    explained_variance | 0.107      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 33899      |\n",
      "|    policy_loss        | 0.436      |\n",
      "|    reward             | 0.06654284 |\n",
      "|    std                | 55.8       |\n",
      "|    value_loss         | 0.00428    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 34000       |\n",
      "|    time_elapsed       | 508         |\n",
      "|    total_timesteps    | 170000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.9       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 33999       |\n",
      "|    policy_loss        | -1.55       |\n",
      "|    reward             | -0.06814476 |\n",
      "|    std                | 57.5        |\n",
      "|    value_loss         | 0.0231      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 34100       |\n",
      "|    time_elapsed       | 510         |\n",
      "|    total_timesteps    | 170500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.9       |\n",
      "|    explained_variance | 0.153       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34099       |\n",
      "|    policy_loss        | -0.517      |\n",
      "|    reward             | 0.029914854 |\n",
      "|    std                | 57          |\n",
      "|    value_loss         | 0.00881     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 34200        |\n",
      "|    time_elapsed       | 511          |\n",
      "|    total_timesteps    | 171000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.9        |\n",
      "|    explained_variance | 0.346        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 34199        |\n",
      "|    policy_loss        | 0.0897       |\n",
      "|    reward             | -0.014879023 |\n",
      "|    std                | 57.4         |\n",
      "|    value_loss         | 0.000112     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 334           |\n",
      "|    iterations         | 34300         |\n",
      "|    time_elapsed       | 513           |\n",
      "|    total_timesteps    | 171500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11           |\n",
      "|    explained_variance | -0.196        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 34299         |\n",
      "|    policy_loss        | 0.0461        |\n",
      "|    reward             | -0.0050630597 |\n",
      "|    std                | 58.3          |\n",
      "|    value_loss         | 9.93e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 34400        |\n",
      "|    time_elapsed       | 514          |\n",
      "|    total_timesteps    | 172000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11          |\n",
      "|    explained_variance | 0.435        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 34399        |\n",
      "|    policy_loss        | -0.222       |\n",
      "|    reward             | -0.008487645 |\n",
      "|    std                | 60.4         |\n",
      "|    value_loss         | 0.000884     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 334        |\n",
      "|    iterations         | 34500      |\n",
      "|    time_elapsed       | 516        |\n",
      "|    total_timesteps    | 172500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.1      |\n",
      "|    explained_variance | -0.00132   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 34499      |\n",
      "|    policy_loss        | -0.2       |\n",
      "|    reward             | 0.05339543 |\n",
      "|    std                | 61.6       |\n",
      "|    value_loss         | 0.000618   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 34600       |\n",
      "|    time_elapsed       | 517         |\n",
      "|    total_timesteps    | 173000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.1       |\n",
      "|    explained_variance | 0.817       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34599       |\n",
      "|    policy_loss        | -0.408      |\n",
      "|    reward             | -0.08730904 |\n",
      "|    std                | 62.3        |\n",
      "|    value_loss         | 0.00144     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 34700        |\n",
      "|    time_elapsed       | 518          |\n",
      "|    total_timesteps    | 173500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.1        |\n",
      "|    explained_variance | 0.216        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 34699        |\n",
      "|    policy_loss        | 0.0537       |\n",
      "|    reward             | 0.0068418356 |\n",
      "|    std                | 62.9         |\n",
      "|    value_loss         | 0.000173     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 334           |\n",
      "|    iterations         | 34800         |\n",
      "|    time_elapsed       | 520           |\n",
      "|    total_timesteps    | 174000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11.2         |\n",
      "|    explained_variance | 0.62          |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 34799         |\n",
      "|    policy_loss        | -0.00792      |\n",
      "|    reward             | -0.0038933745 |\n",
      "|    std                | 63.9          |\n",
      "|    value_loss         | 0.000197      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 34900       |\n",
      "|    time_elapsed       | 521         |\n",
      "|    total_timesteps    | 174500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.2       |\n",
      "|    explained_variance | -0.0707     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34899       |\n",
      "|    policy_loss        | -0.629      |\n",
      "|    reward             | 0.058116786 |\n",
      "|    std                | 66.3        |\n",
      "|    value_loss         | 0.00551     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 35000       |\n",
      "|    time_elapsed       | 523         |\n",
      "|    total_timesteps    | 175000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.2       |\n",
      "|    explained_variance | 0.339       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34999       |\n",
      "|    policy_loss        | -0.555      |\n",
      "|    reward             | 0.027297288 |\n",
      "|    std                | 67          |\n",
      "|    value_loss         | 0.0097      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 334        |\n",
      "|    iterations         | 35100      |\n",
      "|    time_elapsed       | 524        |\n",
      "|    total_timesteps    | 175500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.3      |\n",
      "|    explained_variance | 0.315      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 35099      |\n",
      "|    policy_loss        | 0.647      |\n",
      "|    reward             | 0.23042808 |\n",
      "|    std                | 67.6       |\n",
      "|    value_loss         | 0.0054     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 35200       |\n",
      "|    time_elapsed       | 526         |\n",
      "|    total_timesteps    | 176000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.3       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35199       |\n",
      "|    policy_loss        | 1.06        |\n",
      "|    reward             | -0.09775209 |\n",
      "|    std                | 68.6        |\n",
      "|    value_loss         | 0.018       |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 65\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 110335.62\n",
      "total_reward: 100335.62\n",
      "total_cost: 14.79\n",
      "total_trades: 5412\n",
      "Sharpe: 0.810\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 35300        |\n",
      "|    time_elapsed       | 527          |\n",
      "|    total_timesteps    | 176500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 35299        |\n",
      "|    policy_loss        | -0.038       |\n",
      "|    reward             | 0.0063701645 |\n",
      "|    std                | 69.4         |\n",
      "|    value_loss         | 2e-05        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 35400       |\n",
      "|    time_elapsed       | 528         |\n",
      "|    total_timesteps    | 177000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.3       |\n",
      "|    explained_variance | -0.0804     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35399       |\n",
      "|    policy_loss        | -0.299      |\n",
      "|    reward             | 0.009633651 |\n",
      "|    std                | 70.5        |\n",
      "|    value_loss         | 0.000803    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 35500        |\n",
      "|    time_elapsed       | 530          |\n",
      "|    total_timesteps    | 177500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.4        |\n",
      "|    explained_variance | 0.284        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 35499        |\n",
      "|    policy_loss        | -0.54        |\n",
      "|    reward             | -0.032178767 |\n",
      "|    std                | 71.6         |\n",
      "|    value_loss         | 0.00415      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 334        |\n",
      "|    iterations         | 35600      |\n",
      "|    time_elapsed       | 531        |\n",
      "|    total_timesteps    | 178000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.4      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 35599      |\n",
      "|    policy_loss        | -1.52      |\n",
      "|    reward             | 0.08011623 |\n",
      "|    std                | 74         |\n",
      "|    value_loss         | 0.0217     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 35700       |\n",
      "|    time_elapsed       | 533         |\n",
      "|    total_timesteps    | 178500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.5       |\n",
      "|    explained_variance | 0.86        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35699       |\n",
      "|    policy_loss        | -1.24       |\n",
      "|    reward             | -0.05076534 |\n",
      "|    std                | 76.2        |\n",
      "|    value_loss         | 0.0128      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 35800       |\n",
      "|    time_elapsed       | 534         |\n",
      "|    total_timesteps    | 179000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.5       |\n",
      "|    explained_variance | 0.00526     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35799       |\n",
      "|    policy_loss        | 0.201       |\n",
      "|    reward             | 0.003959305 |\n",
      "|    std                | 77.3        |\n",
      "|    value_loss         | 0.000458    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 35900        |\n",
      "|    time_elapsed       | 536          |\n",
      "|    total_timesteps    | 179500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.6        |\n",
      "|    explained_variance | 0.629        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 35899        |\n",
      "|    policy_loss        | -0.271       |\n",
      "|    reward             | -0.020775175 |\n",
      "|    std                | 78.7         |\n",
      "|    value_loss         | 0.000878     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 36000       |\n",
      "|    time_elapsed       | 537         |\n",
      "|    total_timesteps    | 180000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35999       |\n",
      "|    policy_loss        | -0.0916     |\n",
      "|    reward             | 0.067567416 |\n",
      "|    std                | 80.5        |\n",
      "|    value_loss         | 0.00052     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 334        |\n",
      "|    iterations         | 36100      |\n",
      "|    time_elapsed       | 538        |\n",
      "|    total_timesteps    | 180500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.7      |\n",
      "|    explained_variance | 0.936      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 36099      |\n",
      "|    policy_loss        | 0.0503     |\n",
      "|    reward             | 0.05374306 |\n",
      "|    std                | 82.1       |\n",
      "|    value_loss         | 4.4e-05    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 36200       |\n",
      "|    time_elapsed       | 540         |\n",
      "|    total_timesteps    | 181000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36199       |\n",
      "|    policy_loss        | -0.364      |\n",
      "|    reward             | 0.022195397 |\n",
      "|    std                | 82          |\n",
      "|    value_loss         | 0.00291     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 36300       |\n",
      "|    time_elapsed       | 541         |\n",
      "|    total_timesteps    | 181500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.6       |\n",
      "|    explained_variance | -0.389      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36299       |\n",
      "|    policy_loss        | -0.544      |\n",
      "|    reward             | 0.002150226 |\n",
      "|    std                | 82          |\n",
      "|    value_loss         | 0.00276     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 36400        |\n",
      "|    time_elapsed       | 543          |\n",
      "|    total_timesteps    | 182000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.7        |\n",
      "|    explained_variance | -1.07e-06    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36399        |\n",
      "|    policy_loss        | 0.153        |\n",
      "|    reward             | 0.0029400382 |\n",
      "|    std                | 83.2         |\n",
      "|    value_loss         | 0.000214     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 36500        |\n",
      "|    time_elapsed       | 544          |\n",
      "|    total_timesteps    | 182500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36499        |\n",
      "|    policy_loss        | -0.0712      |\n",
      "|    reward             | -0.009364206 |\n",
      "|    std                | 84.7         |\n",
      "|    value_loss         | 0.000136     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 36600       |\n",
      "|    time_elapsed       | 545         |\n",
      "|    total_timesteps    | 183000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.7       |\n",
      "|    explained_variance | -0.0526     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36599       |\n",
      "|    policy_loss        | -0.581      |\n",
      "|    reward             | -0.04318358 |\n",
      "|    std                | 85.8        |\n",
      "|    value_loss         | 0.00261     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 36700       |\n",
      "|    time_elapsed       | 547         |\n",
      "|    total_timesteps    | 183500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.8       |\n",
      "|    explained_variance | 0.323       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36699       |\n",
      "|    policy_loss        | 1.51        |\n",
      "|    reward             | 0.036789794 |\n",
      "|    std                | 86.6        |\n",
      "|    value_loss         | 0.02        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 36800        |\n",
      "|    time_elapsed       | 548          |\n",
      "|    total_timesteps    | 184000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.8        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36799        |\n",
      "|    policy_loss        | 2.17         |\n",
      "|    reward             | -0.041478343 |\n",
      "|    std                | 87.8         |\n",
      "|    value_loss         | 0.0385       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 36900       |\n",
      "|    time_elapsed       | 550         |\n",
      "|    total_timesteps    | 184500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.8       |\n",
      "|    explained_variance | 0.477       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36899       |\n",
      "|    policy_loss        | -0.675      |\n",
      "|    reward             | 0.019744974 |\n",
      "|    std                | 87.9        |\n",
      "|    value_loss         | 0.00378     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 37000        |\n",
      "|    time_elapsed       | 551          |\n",
      "|    total_timesteps    | 185000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.8        |\n",
      "|    explained_variance | 0.771        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36999        |\n",
      "|    policy_loss        | -0.0477      |\n",
      "|    reward             | 0.0072843004 |\n",
      "|    std                | 89.4         |\n",
      "|    value_loss         | 2.83e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 37100       |\n",
      "|    time_elapsed       | 553         |\n",
      "|    total_timesteps    | 185500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.9       |\n",
      "|    explained_variance | 0.368       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37099       |\n",
      "|    policy_loss        | -0.0596     |\n",
      "|    reward             | -0.07244959 |\n",
      "|    std                | 91.5        |\n",
      "|    value_loss         | 0.000243    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 37200       |\n",
      "|    time_elapsed       | 554         |\n",
      "|    total_timesteps    | 186000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.9       |\n",
      "|    explained_variance | 0.578       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37199       |\n",
      "|    policy_loss        | -0.0255     |\n",
      "|    reward             | 0.029010113 |\n",
      "|    std                | 94.3        |\n",
      "|    value_loss         | 0.000182    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 37300        |\n",
      "|    time_elapsed       | 556          |\n",
      "|    total_timesteps    | 186500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12          |\n",
      "|    explained_variance | 0.178        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 37299        |\n",
      "|    policy_loss        | -3.48        |\n",
      "|    reward             | -0.011863373 |\n",
      "|    std                | 96.6         |\n",
      "|    value_loss         | 0.0876       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 37400        |\n",
      "|    time_elapsed       | 558          |\n",
      "|    total_timesteps    | 187000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12          |\n",
      "|    explained_variance | -0.000415    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 37399        |\n",
      "|    policy_loss        | -0.0353      |\n",
      "|    reward             | -0.010925096 |\n",
      "|    std                | 97.3         |\n",
      "|    value_loss         | 6.32e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 335           |\n",
      "|    iterations         | 37500         |\n",
      "|    time_elapsed       | 559           |\n",
      "|    total_timesteps    | 187500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12           |\n",
      "|    explained_variance | 0.466         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 37499         |\n",
      "|    policy_loss        | -0.0947       |\n",
      "|    reward             | -0.0060591633 |\n",
      "|    std                | 99.1          |\n",
      "|    value_loss         | 9.83e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 37600        |\n",
      "|    time_elapsed       | 560          |\n",
      "|    total_timesteps    | 188000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.1        |\n",
      "|    explained_variance | 0.318        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 37599        |\n",
      "|    policy_loss        | -0.336       |\n",
      "|    reward             | -0.022475002 |\n",
      "|    std                | 103          |\n",
      "|    value_loss         | 0.00564      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 37700        |\n",
      "|    time_elapsed       | 562          |\n",
      "|    total_timesteps    | 188500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.1        |\n",
      "|    explained_variance | 0.218        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 37699        |\n",
      "|    policy_loss        | 0.304        |\n",
      "|    reward             | -0.016709324 |\n",
      "|    std                | 104          |\n",
      "|    value_loss         | 0.00125      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 37800        |\n",
      "|    time_elapsed       | 563          |\n",
      "|    total_timesteps    | 189000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 37799        |\n",
      "|    policy_loss        | -0.0667      |\n",
      "|    reward             | -0.048303425 |\n",
      "|    std                | 106          |\n",
      "|    value_loss         | 0.000369     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 335       |\n",
      "|    iterations         | 37900     |\n",
      "|    time_elapsed       | 565       |\n",
      "|    total_timesteps    | 189500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.2     |\n",
      "|    explained_variance | 0.42      |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 37899     |\n",
      "|    policy_loss        | 0.727     |\n",
      "|    reward             | 0.0507693 |\n",
      "|    std                | 107       |\n",
      "|    value_loss         | 0.00882   |\n",
      "-------------------------------------\n",
      "day: 2707, episode: 70\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 74572.93\n",
      "total_reward: 64572.93\n",
      "total_cost: 15.85\n",
      "total_trades: 5414\n",
      "Sharpe: 0.720\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 38000        |\n",
      "|    time_elapsed       | 566          |\n",
      "|    total_timesteps    | 190000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.2        |\n",
      "|    explained_variance | 0.427        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 37999        |\n",
      "|    policy_loss        | 0.071        |\n",
      "|    reward             | -0.018703012 |\n",
      "|    std                | 108          |\n",
      "|    value_loss         | 8.43e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 38100        |\n",
      "|    time_elapsed       | 568          |\n",
      "|    total_timesteps    | 190500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.2        |\n",
      "|    explained_variance | 0.00398      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 38099        |\n",
      "|    policy_loss        | 1.41         |\n",
      "|    reward             | 0.0075297845 |\n",
      "|    std                | 110          |\n",
      "|    value_loss         | 0.0147       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 38200        |\n",
      "|    time_elapsed       | 569          |\n",
      "|    total_timesteps    | 191000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 38199        |\n",
      "|    policy_loss        | -0.918       |\n",
      "|    reward             | -0.012455073 |\n",
      "|    std                | 111          |\n",
      "|    value_loss         | 0.00536      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 38300       |\n",
      "|    time_elapsed       | 571         |\n",
      "|    total_timesteps    | 191500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.3       |\n",
      "|    explained_variance | 0.377       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38299       |\n",
      "|    policy_loss        | -1.01       |\n",
      "|    reward             | 0.057951797 |\n",
      "|    std                | 111         |\n",
      "|    value_loss         | 0.0182      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 38400       |\n",
      "|    time_elapsed       | 572         |\n",
      "|    total_timesteps    | 192000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.2       |\n",
      "|    explained_variance | 0.0127      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38399       |\n",
      "|    policy_loss        | -2.09       |\n",
      "|    reward             | 0.028507562 |\n",
      "|    std                | 111         |\n",
      "|    value_loss         | 0.0378      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 38500       |\n",
      "|    time_elapsed       | 574         |\n",
      "|    total_timesteps    | 192500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.3       |\n",
      "|    explained_variance | 0.308       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38499       |\n",
      "|    policy_loss        | -0.108      |\n",
      "|    reward             | 0.009528748 |\n",
      "|    std                | 112         |\n",
      "|    value_loss         | 0.000395    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 38600        |\n",
      "|    time_elapsed       | 575          |\n",
      "|    total_timesteps    | 193000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.3        |\n",
      "|    explained_variance | 0.27         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 38599        |\n",
      "|    policy_loss        | -0.0289      |\n",
      "|    reward             | 0.0062519335 |\n",
      "|    std                | 114          |\n",
      "|    value_loss         | 2.7e-05      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 38700       |\n",
      "|    time_elapsed       | 576         |\n",
      "|    total_timesteps    | 193500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.3       |\n",
      "|    explained_variance | 0.25        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38699       |\n",
      "|    policy_loss        | 0.483       |\n",
      "|    reward             | 0.005367682 |\n",
      "|    std                | 116         |\n",
      "|    value_loss         | 0.00243     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 335        |\n",
      "|    iterations         | 38800      |\n",
      "|    time_elapsed       | 578        |\n",
      "|    total_timesteps    | 194000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.4      |\n",
      "|    explained_variance | -0.00101   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 38799      |\n",
      "|    policy_loss        | -0.0701    |\n",
      "|    reward             | 0.02748175 |\n",
      "|    std                | 118        |\n",
      "|    value_loss         | 0.000141   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 38900       |\n",
      "|    time_elapsed       | 579         |\n",
      "|    total_timesteps    | 194500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.4       |\n",
      "|    explained_variance | 0.105       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38899       |\n",
      "|    policy_loss        | 1.01        |\n",
      "|    reward             | 0.028657068 |\n",
      "|    std                | 118         |\n",
      "|    value_loss         | 0.00745     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 39000        |\n",
      "|    time_elapsed       | 581          |\n",
      "|    total_timesteps    | 195000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.4        |\n",
      "|    explained_variance | 0.0279       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 38999        |\n",
      "|    policy_loss        | -0.228       |\n",
      "|    reward             | -0.015457735 |\n",
      "|    std                | 119          |\n",
      "|    value_loss         | 0.000603     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 335           |\n",
      "|    iterations         | 39100         |\n",
      "|    time_elapsed       | 582           |\n",
      "|    total_timesteps    | 195500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.4         |\n",
      "|    explained_variance | 0.54          |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 39099         |\n",
      "|    policy_loss        | -1.47         |\n",
      "|    reward             | -0.0042840624 |\n",
      "|    std                | 122           |\n",
      "|    value_loss         | 0.0153        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 39200        |\n",
      "|    time_elapsed       | 584          |\n",
      "|    total_timesteps    | 196000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.5        |\n",
      "|    explained_variance | -0.0694      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39199        |\n",
      "|    policy_loss        | 0.331        |\n",
      "|    reward             | -0.027712975 |\n",
      "|    std                | 125          |\n",
      "|    value_loss         | 0.000978     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 39300        |\n",
      "|    time_elapsed       | 585          |\n",
      "|    total_timesteps    | 196500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39299        |\n",
      "|    policy_loss        | 0.493        |\n",
      "|    reward             | -0.024610754 |\n",
      "|    std                | 127          |\n",
      "|    value_loss         | 0.00233      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 335        |\n",
      "|    iterations         | 39400      |\n",
      "|    time_elapsed       | 587        |\n",
      "|    total_timesteps    | 197000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 39399      |\n",
      "|    policy_loss        | 0.522      |\n",
      "|    reward             | 0.04053261 |\n",
      "|    std                | 128        |\n",
      "|    value_loss         | 0.00537    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 335        |\n",
      "|    iterations         | 39500      |\n",
      "|    time_elapsed       | 588        |\n",
      "|    total_timesteps    | 197500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | 0.0161     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 39499      |\n",
      "|    policy_loss        | -0.282     |\n",
      "|    reward             | 0.07601638 |\n",
      "|    std                | 128        |\n",
      "|    value_loss         | 0.014      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 39600       |\n",
      "|    time_elapsed       | 590         |\n",
      "|    total_timesteps    | 198000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.6       |\n",
      "|    explained_variance | -1.58       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 39599       |\n",
      "|    policy_loss        | 0.329       |\n",
      "|    reward             | 0.015548064 |\n",
      "|    std                | 130         |\n",
      "|    value_loss         | 0.00207     |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 335            |\n",
      "|    iterations         | 39700          |\n",
      "|    time_elapsed       | 591            |\n",
      "|    total_timesteps    | 198500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -12.6          |\n",
      "|    explained_variance | -0.086         |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 39699          |\n",
      "|    policy_loss        | -0.222         |\n",
      "|    reward             | -0.00032480623 |\n",
      "|    std                | 131            |\n",
      "|    value_loss         | 0.000511       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 39800        |\n",
      "|    time_elapsed       | 593          |\n",
      "|    total_timesteps    | 199000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.6        |\n",
      "|    explained_variance | -0.285       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39799        |\n",
      "|    policy_loss        | -0.453       |\n",
      "|    reward             | -0.021758717 |\n",
      "|    std                | 133          |\n",
      "|    value_loss         | 0.00164      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 335       |\n",
      "|    iterations         | 39900     |\n",
      "|    time_elapsed       | 594       |\n",
      "|    total_timesteps    | 199500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.7     |\n",
      "|    explained_variance | 1.97e-06  |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 39899     |\n",
      "|    policy_loss        | -2.42     |\n",
      "|    reward             | 0.0914252 |\n",
      "|    std                | 136       |\n",
      "|    value_loss         | 0.0387    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 335        |\n",
      "|    iterations         | 40000      |\n",
      "|    time_elapsed       | 595        |\n",
      "|    total_timesteps    | 200000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.7      |\n",
      "|    explained_variance | 0.059      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 39999      |\n",
      "|    policy_loss        | 2.66       |\n",
      "|    reward             | -0.2827452 |\n",
      "|    std                | 138        |\n",
      "|    value_loss         | 0.0681     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 40100        |\n",
      "|    time_elapsed       | 597          |\n",
      "|    total_timesteps    | 200500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.7        |\n",
      "|    explained_variance | 0.26         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 40099        |\n",
      "|    policy_loss        | -0.287       |\n",
      "|    reward             | 0.0034888787 |\n",
      "|    std                | 138          |\n",
      "|    value_loss         | 0.000587     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 40200        |\n",
      "|    time_elapsed       | 599          |\n",
      "|    total_timesteps    | 201000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.7        |\n",
      "|    explained_variance | 0.527        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 40199        |\n",
      "|    policy_loss        | -0.087       |\n",
      "|    reward             | 0.0035887458 |\n",
      "|    std                | 140          |\n",
      "|    value_loss         | 0.000114     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 40300        |\n",
      "|    time_elapsed       | 600          |\n",
      "|    total_timesteps    | 201500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.8        |\n",
      "|    explained_variance | 0.644        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 40299        |\n",
      "|    policy_loss        | 0.351        |\n",
      "|    reward             | 0.0035553838 |\n",
      "|    std                | 144          |\n",
      "|    value_loss         | 0.00112      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 40400       |\n",
      "|    time_elapsed       | 601         |\n",
      "|    total_timesteps    | 202000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.8       |\n",
      "|    explained_variance | -0.0653     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40399       |\n",
      "|    policy_loss        | 0.277       |\n",
      "|    reward             | 0.024122981 |\n",
      "|    std                | 145         |\n",
      "|    value_loss         | 0.000768    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 40500        |\n",
      "|    time_elapsed       | 603          |\n",
      "|    total_timesteps    | 202500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 40499        |\n",
      "|    policy_loss        | 0.435        |\n",
      "|    reward             | -0.032338876 |\n",
      "|    std                | 148          |\n",
      "|    value_loss         | 0.00175      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 40600       |\n",
      "|    time_elapsed       | 604         |\n",
      "|    total_timesteps    | 203000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.8       |\n",
      "|    explained_variance | 0.32        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40599       |\n",
      "|    policy_loss        | 2.93        |\n",
      "|    reward             | -0.06612665 |\n",
      "|    std                | 149         |\n",
      "|    value_loss         | 0.05        |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 75\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 89176.82\n",
      "total_reward: 79176.82\n",
      "total_cost: 10.79\n",
      "total_trades: 5413\n",
      "Sharpe: 0.774\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 40700        |\n",
      "|    time_elapsed       | 606          |\n",
      "|    total_timesteps    | 203500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | -3.68        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 40699        |\n",
      "|    policy_loss        | 0.528        |\n",
      "|    reward             | -0.024767099 |\n",
      "|    std                | 151          |\n",
      "|    value_loss         | 0.00145      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 335           |\n",
      "|    iterations         | 40800         |\n",
      "|    time_elapsed       | 607           |\n",
      "|    total_timesteps    | 204000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.9         |\n",
      "|    explained_variance | -0.265        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 40799         |\n",
      "|    policy_loss        | 0.11          |\n",
      "|    reward             | -0.0031365326 |\n",
      "|    std                | 154           |\n",
      "|    value_loss         | 0.000161      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 40900       |\n",
      "|    time_elapsed       | 609         |\n",
      "|    total_timesteps    | 204500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13         |\n",
      "|    explained_variance | 0.233       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40899       |\n",
      "|    policy_loss        | 0.174       |\n",
      "|    reward             | 0.024606833 |\n",
      "|    std                | 158         |\n",
      "|    value_loss         | 0.000247    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 41000       |\n",
      "|    time_elapsed       | 610         |\n",
      "|    total_timesteps    | 205000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13         |\n",
      "|    explained_variance | 0.662       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40999       |\n",
      "|    policy_loss        | 0.101       |\n",
      "|    reward             | -0.02747805 |\n",
      "|    std                | 163         |\n",
      "|    value_loss         | 0.000148    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 41100        |\n",
      "|    time_elapsed       | 611          |\n",
      "|    total_timesteps    | 205500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.1        |\n",
      "|    explained_variance | 0.0359       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41099        |\n",
      "|    policy_loss        | 0.0404       |\n",
      "|    reward             | 0.0027312583 |\n",
      "|    std                | 167          |\n",
      "|    value_loss         | 0.000838     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 41200       |\n",
      "|    time_elapsed       | 613         |\n",
      "|    total_timesteps    | 206000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.1       |\n",
      "|    explained_variance | -0.573      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 41199       |\n",
      "|    policy_loss        | -0.0887     |\n",
      "|    reward             | 0.002716274 |\n",
      "|    std                | 169         |\n",
      "|    value_loss         | 5.9e-05     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 41300       |\n",
      "|    time_elapsed       | 615         |\n",
      "|    total_timesteps    | 206500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.2       |\n",
      "|    explained_variance | 0.791       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 41299       |\n",
      "|    policy_loss        | -0.0678     |\n",
      "|    reward             | 0.008377147 |\n",
      "|    std                | 174         |\n",
      "|    value_loss         | 4.03e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 335           |\n",
      "|    iterations         | 41400         |\n",
      "|    time_elapsed       | 616           |\n",
      "|    total_timesteps    | 207000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.2         |\n",
      "|    explained_variance | -0.0806       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 41399         |\n",
      "|    policy_loss        | -0.0462       |\n",
      "|    reward             | -0.0011767296 |\n",
      "|    std                | 182           |\n",
      "|    value_loss         | 0.00053       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 41500       |\n",
      "|    time_elapsed       | 617         |\n",
      "|    total_timesteps    | 207500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.3       |\n",
      "|    explained_variance | 0.53        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 41499       |\n",
      "|    policy_loss        | 1.22        |\n",
      "|    reward             | 0.032828573 |\n",
      "|    std                | 183         |\n",
      "|    value_loss         | 0.0115      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 41600       |\n",
      "|    time_elapsed       | 619         |\n",
      "|    total_timesteps    | 208000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.3       |\n",
      "|    explained_variance | 0.318       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 41599       |\n",
      "|    policy_loss        | -0.992      |\n",
      "|    reward             | -0.06153568 |\n",
      "|    std                | 186         |\n",
      "|    value_loss         | 0.0116      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 41700       |\n",
      "|    time_elapsed       | 620         |\n",
      "|    total_timesteps    | 208500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.3       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 41699       |\n",
      "|    policy_loss        | 1.4         |\n",
      "|    reward             | -0.13543117 |\n",
      "|    std                | 189         |\n",
      "|    value_loss         | 0.0193      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 41800        |\n",
      "|    time_elapsed       | 622          |\n",
      "|    total_timesteps    | 209000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.3        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41799        |\n",
      "|    policy_loss        | 0.00726      |\n",
      "|    reward             | -0.013635655 |\n",
      "|    std                | 192          |\n",
      "|    value_loss         | 0.000114     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 41900       |\n",
      "|    time_elapsed       | 623         |\n",
      "|    total_timesteps    | 209500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.4       |\n",
      "|    explained_variance | 1.47e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 41899       |\n",
      "|    policy_loss        | -0.266      |\n",
      "|    reward             | 0.010061414 |\n",
      "|    std                | 194         |\n",
      "|    value_loss         | 0.00107     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 42000       |\n",
      "|    time_elapsed       | 625         |\n",
      "|    total_timesteps    | 210000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.4       |\n",
      "|    explained_variance | 0.323       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 41999       |\n",
      "|    policy_loss        | 1.98        |\n",
      "|    reward             | 0.034463137 |\n",
      "|    std                | 198         |\n",
      "|    value_loss         | 0.0225      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 42100        |\n",
      "|    time_elapsed       | 627          |\n",
      "|    total_timesteps    | 210500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42099        |\n",
      "|    policy_loss        | -0.0859      |\n",
      "|    reward             | -0.042593706 |\n",
      "|    std                | 201          |\n",
      "|    value_loss         | 0.00714      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 42200       |\n",
      "|    time_elapsed       | 628         |\n",
      "|    total_timesteps    | 211000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.5       |\n",
      "|    explained_variance | 0.537       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 42199       |\n",
      "|    policy_loss        | 0.933       |\n",
      "|    reward             | -0.01069824 |\n",
      "|    std                | 203         |\n",
      "|    value_loss         | 0.00854     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 42300        |\n",
      "|    time_elapsed       | 629          |\n",
      "|    total_timesteps    | 211500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.5        |\n",
      "|    explained_variance | 0.121        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42299        |\n",
      "|    policy_loss        | -0.0102      |\n",
      "|    reward             | -0.004527492 |\n",
      "|    std                | 204          |\n",
      "|    value_loss         | 2.1e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 335          |\n",
      "|    iterations         | 42400        |\n",
      "|    time_elapsed       | 631          |\n",
      "|    total_timesteps    | 212000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.5        |\n",
      "|    explained_variance | -3.02        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42399        |\n",
      "|    policy_loss        | 0.109        |\n",
      "|    reward             | 0.0004711731 |\n",
      "|    std                | 208          |\n",
      "|    value_loss         | 9.84e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 42500       |\n",
      "|    time_elapsed       | 633         |\n",
      "|    total_timesteps    | 212500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.6       |\n",
      "|    explained_variance | 0.0795      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 42499       |\n",
      "|    policy_loss        | -0.0601     |\n",
      "|    reward             | 0.007669976 |\n",
      "|    std                | 212         |\n",
      "|    value_loss         | 2.1e-05     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 42600        |\n",
      "|    time_elapsed       | 635          |\n",
      "|    total_timesteps    | 213000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | 0.431        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42599        |\n",
      "|    policy_loss        | -0.105       |\n",
      "|    reward             | 0.0031061089 |\n",
      "|    std                | 218          |\n",
      "|    value_loss         | 7.7e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 42700        |\n",
      "|    time_elapsed       | 637          |\n",
      "|    total_timesteps    | 213500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.7        |\n",
      "|    explained_variance | 0.466        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42699        |\n",
      "|    policy_loss        | -0.0978      |\n",
      "|    reward             | -0.036573518 |\n",
      "|    std                | 226          |\n",
      "|    value_loss         | 6.46e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 42800        |\n",
      "|    time_elapsed       | 639          |\n",
      "|    total_timesteps    | 214000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.7        |\n",
      "|    explained_variance | 0.483        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42799        |\n",
      "|    policy_loss        | 0.131        |\n",
      "|    reward             | 0.0036400596 |\n",
      "|    std                | 234          |\n",
      "|    value_loss         | 0.000101     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 334           |\n",
      "|    iterations         | 42900         |\n",
      "|    time_elapsed       | 641           |\n",
      "|    total_timesteps    | 214500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.8         |\n",
      "|    explained_variance | 2.98e-06      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 42899         |\n",
      "|    policy_loss        | -0.0977       |\n",
      "|    reward             | -0.0067760036 |\n",
      "|    std                | 241           |\n",
      "|    value_loss         | 6.71e-05      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 43000       |\n",
      "|    time_elapsed       | 643         |\n",
      "|    total_timesteps    | 215000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.9       |\n",
      "|    explained_variance | -0.0322     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 42999       |\n",
      "|    policy_loss        | -0.155      |\n",
      "|    reward             | 0.019691488 |\n",
      "|    std                | 249         |\n",
      "|    value_loss         | 0.000148    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 333        |\n",
      "|    iterations         | 43100      |\n",
      "|    time_elapsed       | 645        |\n",
      "|    total_timesteps    | 215500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.9      |\n",
      "|    explained_variance | 0.176      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 43099      |\n",
      "|    policy_loss        | -0.574     |\n",
      "|    reward             | 0.06192252 |\n",
      "|    std                | 257        |\n",
      "|    value_loss         | 0.00288    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 333           |\n",
      "|    iterations         | 43200         |\n",
      "|    time_elapsed       | 647           |\n",
      "|    total_timesteps    | 216000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14           |\n",
      "|    explained_variance | 5.36e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 43199         |\n",
      "|    policy_loss        | -0.26         |\n",
      "|    reward             | -0.0003848465 |\n",
      "|    std                | 262           |\n",
      "|    value_loss         | 0.00282       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 333         |\n",
      "|    iterations         | 43300       |\n",
      "|    time_elapsed       | 649         |\n",
      "|    total_timesteps    | 216500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14         |\n",
      "|    explained_variance | -5.96e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43299       |\n",
      "|    policy_loss        | 3.2         |\n",
      "|    reward             | 0.077675685 |\n",
      "|    std                | 263         |\n",
      "|    value_loss         | 0.093       |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 80\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 91015.13\n",
      "total_reward: 81015.13\n",
      "total_cost: 12.63\n",
      "total_trades: 4009\n",
      "Sharpe: 0.751\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 43400        |\n",
      "|    time_elapsed       | 651          |\n",
      "|    total_timesteps    | 217000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14          |\n",
      "|    explained_variance | -0.0503      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 43399        |\n",
      "|    policy_loss        | 0.979        |\n",
      "|    reward             | -0.022993986 |\n",
      "|    std                | 266          |\n",
      "|    value_loss         | 0.00508      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 43500        |\n",
      "|    time_elapsed       | 653          |\n",
      "|    total_timesteps    | 217500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14          |\n",
      "|    explained_variance | 0.781        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 43499        |\n",
      "|    policy_loss        | 0.0687       |\n",
      "|    reward             | -0.004440871 |\n",
      "|    std                | 270          |\n",
      "|    value_loss         | 3.75e-05     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 332       |\n",
      "|    iterations         | 43600     |\n",
      "|    time_elapsed       | 655       |\n",
      "|    total_timesteps    | 218000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14.1     |\n",
      "|    explained_variance | -0.366    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 43599     |\n",
      "|    policy_loss        | -0.209    |\n",
      "|    reward             | 0.0639256 |\n",
      "|    std                | 277       |\n",
      "|    value_loss         | 0.000308  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 43700       |\n",
      "|    time_elapsed       | 656         |\n",
      "|    total_timesteps    | 218500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.1       |\n",
      "|    explained_variance | 0.29        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43699       |\n",
      "|    policy_loss        | -0.0334     |\n",
      "|    reward             | 0.011835958 |\n",
      "|    std                | 284         |\n",
      "|    value_loss         | 0.00131     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 43800       |\n",
      "|    time_elapsed       | 658         |\n",
      "|    total_timesteps    | 219000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.2       |\n",
      "|    explained_variance | -0.0999     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43799       |\n",
      "|    policy_loss        | 0.415       |\n",
      "|    reward             | 0.060444426 |\n",
      "|    std                | 289         |\n",
      "|    value_loss         | 0.00268     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 43900        |\n",
      "|    time_elapsed       | 659          |\n",
      "|    total_timesteps    | 219500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 43899        |\n",
      "|    policy_loss        | 0.298        |\n",
      "|    reward             | 0.0031784642 |\n",
      "|    std                | 294          |\n",
      "|    value_loss         | 0.00045      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 44000      |\n",
      "|    time_elapsed       | 661        |\n",
      "|    total_timesteps    | 220000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.2      |\n",
      "|    explained_variance | 0.879      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 43999      |\n",
      "|    policy_loss        | 0.0161     |\n",
      "|    reward             | 0.03243804 |\n",
      "|    std                | 299        |\n",
      "|    value_loss         | 1.73e-05   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 44100       |\n",
      "|    time_elapsed       | 662         |\n",
      "|    total_timesteps    | 220500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.3       |\n",
      "|    explained_variance | 0.177       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44099       |\n",
      "|    policy_loss        | 1.77        |\n",
      "|    reward             | 0.054177437 |\n",
      "|    std                | 305         |\n",
      "|    value_loss         | 0.0181      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 44200        |\n",
      "|    time_elapsed       | 664          |\n",
      "|    total_timesteps    | 221000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.3        |\n",
      "|    explained_variance | 0.0361       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44199        |\n",
      "|    policy_loss        | -0.952       |\n",
      "|    reward             | -0.012878955 |\n",
      "|    std                | 315          |\n",
      "|    value_loss         | 0.00786      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 44300        |\n",
      "|    time_elapsed       | 665          |\n",
      "|    total_timesteps    | 221500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.3        |\n",
      "|    explained_variance | -0.0124      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44299        |\n",
      "|    policy_loss        | -3.96        |\n",
      "|    reward             | -0.026073422 |\n",
      "|    std                | 314          |\n",
      "|    value_loss         | 0.0835       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 44400        |\n",
      "|    time_elapsed       | 667          |\n",
      "|    total_timesteps    | 222000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.3        |\n",
      "|    explained_variance | 0.432        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44399        |\n",
      "|    policy_loss        | -0.487       |\n",
      "|    reward             | -0.021727225 |\n",
      "|    std                | 314          |\n",
      "|    value_loss         | 0.00665      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 44500        |\n",
      "|    time_elapsed       | 669          |\n",
      "|    total_timesteps    | 222500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.4        |\n",
      "|    explained_variance | 0.0689       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44499        |\n",
      "|    policy_loss        | -0.296       |\n",
      "|    reward             | -0.010953988 |\n",
      "|    std                | 321          |\n",
      "|    value_loss         | 0.000676     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 44600        |\n",
      "|    time_elapsed       | 670          |\n",
      "|    total_timesteps    | 223000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.4        |\n",
      "|    explained_variance | 0.00107      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44599        |\n",
      "|    policy_loss        | -0.077       |\n",
      "|    reward             | 0.0023617733 |\n",
      "|    std                | 326          |\n",
      "|    value_loss         | 0.000732     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 44700         |\n",
      "|    time_elapsed       | 672           |\n",
      "|    total_timesteps    | 223500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.5         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 44699         |\n",
      "|    policy_loss        | -1.1          |\n",
      "|    reward             | 0.00027241287 |\n",
      "|    std                | 336           |\n",
      "|    value_loss         | 0.00717       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 44800        |\n",
      "|    time_elapsed       | 673          |\n",
      "|    total_timesteps    | 224000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.5        |\n",
      "|    explained_variance | 0.511        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44799        |\n",
      "|    policy_loss        | -0.884       |\n",
      "|    reward             | -0.012575407 |\n",
      "|    std                | 345          |\n",
      "|    value_loss         | 0.00394      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 44900      |\n",
      "|    time_elapsed       | 675        |\n",
      "|    total_timesteps    | 224500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.6      |\n",
      "|    explained_variance | 0.535      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 44899      |\n",
      "|    policy_loss        | 0.103      |\n",
      "|    reward             | 0.17081438 |\n",
      "|    std                | 350        |\n",
      "|    value_loss         | 0.00186    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 45000        |\n",
      "|    time_elapsed       | 676          |\n",
      "|    total_timesteps    | 225000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.6        |\n",
      "|    explained_variance | 0.0743       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44999        |\n",
      "|    policy_loss        | -0.281       |\n",
      "|    reward             | -0.022503182 |\n",
      "|    std                | 356          |\n",
      "|    value_loss         | 0.000743     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 45100        |\n",
      "|    time_elapsed       | 678          |\n",
      "|    total_timesteps    | 225500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.6        |\n",
      "|    explained_variance | 0.452        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45099        |\n",
      "|    policy_loss        | 0.0471       |\n",
      "|    reward             | 0.0062195715 |\n",
      "|    std                | 361          |\n",
      "|    value_loss         | 8.2e-05      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 45200       |\n",
      "|    time_elapsed       | 679         |\n",
      "|    total_timesteps    | 226000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.7       |\n",
      "|    explained_variance | 0.0236      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 45199       |\n",
      "|    policy_loss        | 0.361       |\n",
      "|    reward             | 0.024084784 |\n",
      "|    std                | 369         |\n",
      "|    value_loss         | 0.000731    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 45300       |\n",
      "|    time_elapsed       | 681         |\n",
      "|    total_timesteps    | 226500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.7       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 45299       |\n",
      "|    policy_loss        | -0.000613   |\n",
      "|    reward             | -0.06368114 |\n",
      "|    std                | 373         |\n",
      "|    value_loss         | 0.000297    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 45400       |\n",
      "|    time_elapsed       | 682         |\n",
      "|    total_timesteps    | 227000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 45399       |\n",
      "|    policy_loss        | 1.55        |\n",
      "|    reward             | 0.033096027 |\n",
      "|    std                | 382         |\n",
      "|    value_loss         | 0.0143      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 45500       |\n",
      "|    time_elapsed       | 684         |\n",
      "|    total_timesteps    | 227500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.7       |\n",
      "|    explained_variance | -0.125      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 45499       |\n",
      "|    policy_loss        | -0.115      |\n",
      "|    reward             | 0.005377713 |\n",
      "|    std                | 385         |\n",
      "|    value_loss         | 0.000472    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 45600        |\n",
      "|    time_elapsed       | 685          |\n",
      "|    total_timesteps    | 228000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.8        |\n",
      "|    explained_variance | -7.49        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45599        |\n",
      "|    policy_loss        | 0.113        |\n",
      "|    reward             | -0.015241374 |\n",
      "|    std                | 389          |\n",
      "|    value_loss         | 0.000715     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 45700        |\n",
      "|    time_elapsed       | 687          |\n",
      "|    total_timesteps    | 228500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.8        |\n",
      "|    explained_variance | 0.263        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45699        |\n",
      "|    policy_loss        | -0.194       |\n",
      "|    reward             | 0.0037267245 |\n",
      "|    std                | 398          |\n",
      "|    value_loss         | 0.00022      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 45800       |\n",
      "|    time_elapsed       | 688         |\n",
      "|    total_timesteps    | 229000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.9       |\n",
      "|    explained_variance | -0.166      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 45799       |\n",
      "|    policy_loss        | -0.252      |\n",
      "|    reward             | 0.005911577 |\n",
      "|    std                | 407         |\n",
      "|    value_loss         | 0.000506    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 45900        |\n",
      "|    time_elapsed       | 690          |\n",
      "|    total_timesteps    | 229500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.9        |\n",
      "|    explained_variance | 0.351        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45899        |\n",
      "|    policy_loss        | 0.842        |\n",
      "|    reward             | -0.010958224 |\n",
      "|    std                | 420          |\n",
      "|    value_loss         | 0.00354      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 46000       |\n",
      "|    time_elapsed       | 691         |\n",
      "|    total_timesteps    | 230000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15         |\n",
      "|    explained_variance | -0.00236    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 45999       |\n",
      "|    policy_loss        | 1.21        |\n",
      "|    reward             | 0.045235723 |\n",
      "|    std                | 435         |\n",
      "|    value_loss         | 0.0117      |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 85\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 34376.49\n",
      "total_reward: 24376.49\n",
      "total_cost: 16.14\n",
      "total_trades: 5414\n",
      "Sharpe: 0.560\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 46100        |\n",
      "|    time_elapsed       | 693          |\n",
      "|    total_timesteps    | 230500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15          |\n",
      "|    explained_variance | 0.0513       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46099        |\n",
      "|    policy_loss        | 0.449        |\n",
      "|    reward             | -0.025215816 |\n",
      "|    std                | 448          |\n",
      "|    value_loss         | 0.00102      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 46200       |\n",
      "|    time_elapsed       | 694         |\n",
      "|    total_timesteps    | 231000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46199       |\n",
      "|    policy_loss        | 0.0808      |\n",
      "|    reward             | 0.011171545 |\n",
      "|    std                | 462         |\n",
      "|    value_loss         | 5.4e-05     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 46300       |\n",
      "|    time_elapsed       | 696         |\n",
      "|    total_timesteps    | 231500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.2       |\n",
      "|    explained_variance | -2.38e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46299       |\n",
      "|    policy_loss        | -0.271      |\n",
      "|    reward             | 0.009876408 |\n",
      "|    std                | 474         |\n",
      "|    value_loss         | 0.000438    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 46400       |\n",
      "|    time_elapsed       | 697         |\n",
      "|    total_timesteps    | 232000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.2       |\n",
      "|    explained_variance | 0.545       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46399       |\n",
      "|    policy_loss        | -0.858      |\n",
      "|    reward             | 0.006245856 |\n",
      "|    std                | 479         |\n",
      "|    value_loss         | 0.00338     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 46500       |\n",
      "|    time_elapsed       | 699         |\n",
      "|    total_timesteps    | 232500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46499       |\n",
      "|    policy_loss        | 0.649       |\n",
      "|    reward             | 0.029727975 |\n",
      "|    std                | 487         |\n",
      "|    value_loss         | 0.00476     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 46600        |\n",
      "|    time_elapsed       | 700          |\n",
      "|    total_timesteps    | 233000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.2        |\n",
      "|    explained_variance | 0.737        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46599        |\n",
      "|    policy_loss        | -0.0623      |\n",
      "|    reward             | -0.027163079 |\n",
      "|    std                | 488          |\n",
      "|    value_loss         | 4.51e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 46700        |\n",
      "|    time_elapsed       | 702          |\n",
      "|    total_timesteps    | 233500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.2        |\n",
      "|    explained_variance | -8.34e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46699        |\n",
      "|    policy_loss        | -0.0639      |\n",
      "|    reward             | -0.018693822 |\n",
      "|    std                | 496          |\n",
      "|    value_loss         | 5.61e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 46800       |\n",
      "|    time_elapsed       | 703         |\n",
      "|    total_timesteps    | 234000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.3       |\n",
      "|    explained_variance | 0.145       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46799       |\n",
      "|    policy_loss        | -0.377      |\n",
      "|    reward             | 0.084534965 |\n",
      "|    std                | 505         |\n",
      "|    value_loss         | 0.000615    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 46900       |\n",
      "|    time_elapsed       | 705         |\n",
      "|    total_timesteps    | 234500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.3       |\n",
      "|    explained_variance | 0.251       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46899       |\n",
      "|    policy_loss        | -0.149      |\n",
      "|    reward             | 0.022880757 |\n",
      "|    std                | 512         |\n",
      "|    value_loss         | 0.00107     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 47000      |\n",
      "|    time_elapsed       | 706        |\n",
      "|    total_timesteps    | 235000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 46999      |\n",
      "|    policy_loss        | -4.17      |\n",
      "|    reward             | 0.11760626 |\n",
      "|    std                | 511        |\n",
      "|    value_loss         | 0.0924     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 47100       |\n",
      "|    time_elapsed       | 708         |\n",
      "|    total_timesteps    | 235500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.3       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 47099       |\n",
      "|    policy_loss        | -0.128      |\n",
      "|    reward             | 0.083797306 |\n",
      "|    std                | 512         |\n",
      "|    value_loss         | 0.00959     |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 332            |\n",
      "|    iterations         | 47200          |\n",
      "|    time_elapsed       | 709            |\n",
      "|    total_timesteps    | 236000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -15.3          |\n",
      "|    explained_variance | -0.681         |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 47199          |\n",
      "|    policy_loss        | -0.247         |\n",
      "|    reward             | 0.000121053694 |\n",
      "|    std                | 515            |\n",
      "|    value_loss         | 0.000389       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 47300        |\n",
      "|    time_elapsed       | 711          |\n",
      "|    total_timesteps    | 236500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.3        |\n",
      "|    explained_variance | 0.0862       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47299        |\n",
      "|    policy_loss        | -0.155       |\n",
      "|    reward             | -0.008194605 |\n",
      "|    std                | 521          |\n",
      "|    value_loss         | 0.000227     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 47400      |\n",
      "|    time_elapsed       | 713        |\n",
      "|    total_timesteps    | 237000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.4      |\n",
      "|    explained_variance | -0.0632    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 47399      |\n",
      "|    policy_loss        | 0.134      |\n",
      "|    reward             | 0.07426462 |\n",
      "|    std                | 534        |\n",
      "|    value_loss         | 0.000555   |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 332            |\n",
      "|    iterations         | 47500          |\n",
      "|    time_elapsed       | 714            |\n",
      "|    total_timesteps    | 237500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -15.4          |\n",
      "|    explained_variance | 0.607          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 47499          |\n",
      "|    policy_loss        | -0.393         |\n",
      "|    reward             | -0.00035026245 |\n",
      "|    std                | 541            |\n",
      "|    value_loss         | 0.000891       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 47600        |\n",
      "|    time_elapsed       | 716          |\n",
      "|    total_timesteps    | 238000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.5        |\n",
      "|    explained_variance | -0.108       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47599        |\n",
      "|    policy_loss        | 0.949        |\n",
      "|    reward             | -0.040368937 |\n",
      "|    std                | 553          |\n",
      "|    value_loss         | 0.00808      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 47700       |\n",
      "|    time_elapsed       | 718         |\n",
      "|    total_timesteps    | 238500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.5       |\n",
      "|    explained_variance | -2.26e-06   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 47699       |\n",
      "|    policy_loss        | -0.305      |\n",
      "|    reward             | 0.013596143 |\n",
      "|    std                | 557         |\n",
      "|    value_loss         | 0.000472    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 47800        |\n",
      "|    time_elapsed       | 719          |\n",
      "|    total_timesteps    | 239000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47799        |\n",
      "|    policy_loss        | -0.216       |\n",
      "|    reward             | -0.005472929 |\n",
      "|    std                | 568          |\n",
      "|    value_loss         | 0.000229     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 47900        |\n",
      "|    time_elapsed       | 721          |\n",
      "|    total_timesteps    | 239500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.6        |\n",
      "|    explained_variance | 0.0118       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47899        |\n",
      "|    policy_loss        | 0.308        |\n",
      "|    reward             | -0.009766377 |\n",
      "|    std                | 587          |\n",
      "|    value_loss         | 0.00171      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 48000      |\n",
      "|    time_elapsed       | 723        |\n",
      "|    total_timesteps    | 240000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.6      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 47999      |\n",
      "|    policy_loss        | -0.203     |\n",
      "|    reward             | 0.02084565 |\n",
      "|    std                | 600        |\n",
      "|    value_loss         | 0.000348   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 48100       |\n",
      "|    time_elapsed       | 724         |\n",
      "|    total_timesteps    | 240500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.6       |\n",
      "|    explained_variance | 0.0465      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48099       |\n",
      "|    policy_loss        | 3.87        |\n",
      "|    reward             | -0.05335109 |\n",
      "|    std                | 606         |\n",
      "|    value_loss         | 0.0795      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 48200      |\n",
      "|    time_elapsed       | 726        |\n",
      "|    total_timesteps    | 241000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.6      |\n",
      "|    explained_variance | 0.00151    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 48199      |\n",
      "|    policy_loss        | 3.54       |\n",
      "|    reward             | 0.10326329 |\n",
      "|    std                | 607        |\n",
      "|    value_loss         | 0.0657     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 48300       |\n",
      "|    time_elapsed       | 728         |\n",
      "|    total_timesteps    | 241500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.7       |\n",
      "|    explained_variance | 0.118       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48299       |\n",
      "|    policy_loss        | 0.0721      |\n",
      "|    reward             | 0.008042361 |\n",
      "|    std                | 614         |\n",
      "|    value_loss         | 2.68e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 48400       |\n",
      "|    time_elapsed       | 729         |\n",
      "|    total_timesteps    | 242000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.7       |\n",
      "|    explained_variance | 0.0748      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48399       |\n",
      "|    policy_loss        | -0.044      |\n",
      "|    reward             | 0.009131832 |\n",
      "|    std                | 625         |\n",
      "|    value_loss         | 2.5e-05     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 48500       |\n",
      "|    time_elapsed       | 731         |\n",
      "|    total_timesteps    | 242500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.8       |\n",
      "|    explained_variance | 0.215       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48499       |\n",
      "|    policy_loss        | -0.0594     |\n",
      "|    reward             | 0.026074674 |\n",
      "|    std                | 644         |\n",
      "|    value_loss         | 8.01e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 48600      |\n",
      "|    time_elapsed       | 732        |\n",
      "|    total_timesteps    | 243000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.8      |\n",
      "|    explained_variance | 0.0386     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 48599      |\n",
      "|    policy_loss        | 1.43       |\n",
      "|    reward             | 0.01249933 |\n",
      "|    std                | 665        |\n",
      "|    value_loss         | 0.00945    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 48700        |\n",
      "|    time_elapsed       | 733          |\n",
      "|    total_timesteps    | 243500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.9        |\n",
      "|    explained_variance | 0.41         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48699        |\n",
      "|    policy_loss        | 0.353        |\n",
      "|    reward             | -0.031530634 |\n",
      "|    std                | 686          |\n",
      "|    value_loss         | 0.000635     |\n",
      "----------------------------------------\n",
      "day: 2707, episode: 90\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 27961.51\n",
      "total_reward: 17961.51\n",
      "total_cost: 13.05\n",
      "total_trades: 5413\n",
      "Sharpe: 0.509\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 48800        |\n",
      "|    time_elapsed       | 735          |\n",
      "|    total_timesteps    | 244000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.9        |\n",
      "|    explained_variance | 0.144        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48799        |\n",
      "|    policy_loss        | -0.208       |\n",
      "|    reward             | 9.025116e-05 |\n",
      "|    std                | 703          |\n",
      "|    value_loss         | 0.000291     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 48900       |\n",
      "|    time_elapsed       | 736         |\n",
      "|    total_timesteps    | 244500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16         |\n",
      "|    explained_variance | 0.918       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48899       |\n",
      "|    policy_loss        | -0.285      |\n",
      "|    reward             | 0.023175035 |\n",
      "|    std                | 715         |\n",
      "|    value_loss         | 0.000326    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 49000        |\n",
      "|    time_elapsed       | 738          |\n",
      "|    total_timesteps    | 245000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16          |\n",
      "|    explained_variance | 0.129        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48999        |\n",
      "|    policy_loss        | -1.37        |\n",
      "|    reward             | -0.038804762 |\n",
      "|    std                | 725          |\n",
      "|    value_loss         | 0.0105       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 49100       |\n",
      "|    time_elapsed       | 739         |\n",
      "|    total_timesteps    | 245500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16         |\n",
      "|    explained_variance | 0.301       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49099       |\n",
      "|    policy_loss        | 1.44        |\n",
      "|    reward             | 0.036332585 |\n",
      "|    std                | 741         |\n",
      "|    value_loss         | 0.00901     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 49200       |\n",
      "|    time_elapsed       | 741         |\n",
      "|    total_timesteps    | 246000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16         |\n",
      "|    explained_variance | 0.109       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49199       |\n",
      "|    policy_loss        | 2.43        |\n",
      "|    reward             | -0.03380134 |\n",
      "|    std                | 743         |\n",
      "|    value_loss         | 0.0306      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 49300        |\n",
      "|    time_elapsed       | 742          |\n",
      "|    total_timesteps    | 246500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.1        |\n",
      "|    explained_variance | 0.0295       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 49299        |\n",
      "|    policy_loss        | -1.15        |\n",
      "|    reward             | 0.0050184545 |\n",
      "|    std                | 757          |\n",
      "|    value_loss         | 0.00549      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 49400        |\n",
      "|    time_elapsed       | 744          |\n",
      "|    total_timesteps    | 247000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.1        |\n",
      "|    explained_variance | -1.3e-05     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 49399        |\n",
      "|    policy_loss        | 0.421        |\n",
      "|    reward             | -0.017277172 |\n",
      "|    std                | 766          |\n",
      "|    value_loss         | 0.000735     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 49500        |\n",
      "|    time_elapsed       | 745          |\n",
      "|    total_timesteps    | 247500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 49499        |\n",
      "|    policy_loss        | -0.238       |\n",
      "|    reward             | -0.011015329 |\n",
      "|    std                | 780          |\n",
      "|    value_loss         | 0.000307     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 49600      |\n",
      "|    time_elapsed       | 747        |\n",
      "|    total_timesteps    | 248000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.2      |\n",
      "|    explained_variance | 0.159      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 49599      |\n",
      "|    policy_loss        | -0.308     |\n",
      "|    reward             | 0.07540137 |\n",
      "|    std                | 790        |\n",
      "|    value_loss         | 0.000566   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 49700       |\n",
      "|    time_elapsed       | 749         |\n",
      "|    total_timesteps    | 248500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.2       |\n",
      "|    explained_variance | 0.0273      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49699       |\n",
      "|    policy_loss        | -0.431      |\n",
      "|    reward             | -0.11894999 |\n",
      "|    std                | 814         |\n",
      "|    value_loss         | 0.00292     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 49800       |\n",
      "|    time_elapsed       | 750         |\n",
      "|    total_timesteps    | 249000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.2       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49799       |\n",
      "|    policy_loss        | -3.73       |\n",
      "|    reward             | -0.18254305 |\n",
      "|    std                | 816         |\n",
      "|    value_loss         | 0.0756      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 49900        |\n",
      "|    time_elapsed       | 752          |\n",
      "|    total_timesteps    | 249500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.3        |\n",
      "|    explained_variance | 0.0631       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 49899        |\n",
      "|    policy_loss        | 0.0984       |\n",
      "|    reward             | -0.014186761 |\n",
      "|    std                | 825          |\n",
      "|    value_loss         | 0.000782     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 50000         |\n",
      "|    time_elapsed       | 753           |\n",
      "|    total_timesteps    | 250000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.3         |\n",
      "|    explained_variance | -1.44         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 49999         |\n",
      "|    policy_loss        | -0.251        |\n",
      "|    reward             | -0.0045923083 |\n",
      "|    std                | 840           |\n",
      "|    value_loss         | 0.000416      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 50100       |\n",
      "|    time_elapsed       | 755         |\n",
      "|    total_timesteps    | 250500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.3       |\n",
      "|    explained_variance | 0.656       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50099       |\n",
      "|    policy_loss        | -1.19       |\n",
      "|    reward             | -0.04780157 |\n",
      "|    std                | 859         |\n",
      "|    value_loss         | 0.00558     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 50200        |\n",
      "|    time_elapsed       | 757          |\n",
      "|    total_timesteps    | 251000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.4        |\n",
      "|    explained_variance | -0.00152     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50199        |\n",
      "|    policy_loss        | 0.32         |\n",
      "|    reward             | -0.009268961 |\n",
      "|    std                | 884          |\n",
      "|    value_loss         | 0.00117      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 50300        |\n",
      "|    time_elapsed       | 758          |\n",
      "|    total_timesteps    | 251500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.4        |\n",
      "|    explained_variance | -0.00967     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50299        |\n",
      "|    policy_loss        | 0.654        |\n",
      "|    reward             | -0.011399606 |\n",
      "|    std                | 891          |\n",
      "|    value_loss         | 0.00327      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 50400       |\n",
      "|    time_elapsed       | 760         |\n",
      "|    total_timesteps    | 252000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.5       |\n",
      "|    explained_variance | -2.32       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50399       |\n",
      "|    policy_loss        | 0.287       |\n",
      "|    reward             | 0.006546151 |\n",
      "|    std                | 916         |\n",
      "|    value_loss         | 0.000419    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 50500        |\n",
      "|    time_elapsed       | 761          |\n",
      "|    total_timesteps    | 252500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.5        |\n",
      "|    explained_variance | 0.566        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50499        |\n",
      "|    policy_loss        | -0.19        |\n",
      "|    reward             | -0.024583254 |\n",
      "|    std                | 936          |\n",
      "|    value_loss         | 0.000152     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 50600       |\n",
      "|    time_elapsed       | 763         |\n",
      "|    total_timesteps    | 253000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.6       |\n",
      "|    explained_variance | 0.477       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50599       |\n",
      "|    policy_loss        | 0.1         |\n",
      "|    reward             | 0.013292931 |\n",
      "|    std                | 962         |\n",
      "|    value_loss         | 0.000422    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 50700        |\n",
      "|    time_elapsed       | 764          |\n",
      "|    total_timesteps    | 253500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.6        |\n",
      "|    explained_variance | 0.111        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50699        |\n",
      "|    policy_loss        | 0.666        |\n",
      "|    reward             | -0.012237285 |\n",
      "|    std                | 988          |\n",
      "|    value_loss         | 0.00189      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 50800       |\n",
      "|    time_elapsed       | 766         |\n",
      "|    total_timesteps    | 254000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.6       |\n",
      "|    explained_variance | 0.149       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50799       |\n",
      "|    policy_loss        | 0.965       |\n",
      "|    reward             | -0.00733678 |\n",
      "|    std                | 992         |\n",
      "|    value_loss         | 0.0144      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 50900       |\n",
      "|    time_elapsed       | 767         |\n",
      "|    total_timesteps    | 254500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.6       |\n",
      "|    explained_variance | 0.0244      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50899       |\n",
      "|    policy_loss        | 3.87        |\n",
      "|    reward             | -0.06572243 |\n",
      "|    std                | 987         |\n",
      "|    value_loss         | 0.0629      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 51000       |\n",
      "|    time_elapsed       | 769         |\n",
      "|    total_timesteps    | 255000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.6       |\n",
      "|    explained_variance | -3.26       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50999       |\n",
      "|    policy_loss        | -0.156      |\n",
      "|    reward             | 0.006806212 |\n",
      "|    std                | 993         |\n",
      "|    value_loss         | 0.000175    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 51100       |\n",
      "|    time_elapsed       | 770         |\n",
      "|    total_timesteps    | 255500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51099       |\n",
      "|    policy_loss        | 0.0338      |\n",
      "|    reward             | 0.008112553 |\n",
      "|    std                | 1.01e+03    |\n",
      "|    value_loss         | 2.4e-05     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 51200        |\n",
      "|    time_elapsed       | 772          |\n",
      "|    total_timesteps    | 256000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.7        |\n",
      "|    explained_variance | 8.34e-06     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51199        |\n",
      "|    policy_loss        | 0.744        |\n",
      "|    reward             | -0.027929652 |\n",
      "|    std                | 1.02e+03     |\n",
      "|    value_loss         | 0.0026       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 51300        |\n",
      "|    time_elapsed       | 773          |\n",
      "|    total_timesteps    | 256500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.7        |\n",
      "|    explained_variance | 0.428        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51299        |\n",
      "|    policy_loss        | 0.447        |\n",
      "|    reward             | -0.053864837 |\n",
      "|    std                | 1.01e+03     |\n",
      "|    value_loss         | 0.00105      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 51400       |\n",
      "|    time_elapsed       | 775         |\n",
      "|    total_timesteps    | 257000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.7       |\n",
      "|    explained_variance | 0.303       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51399       |\n",
      "|    policy_loss        | -0.771      |\n",
      "|    reward             | -0.02257103 |\n",
      "|    std                | 1.02e+03    |\n",
      "|    value_loss         | 0.00521     |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 95\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 67440.20\n",
      "total_reward: 57440.20\n",
      "total_cost: 13.42\n",
      "total_trades: 5414\n",
      "Sharpe: 0.702\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 51500        |\n",
      "|    time_elapsed       | 776          |\n",
      "|    total_timesteps    | 257500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.7        |\n",
      "|    explained_variance | 0.0302       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51499        |\n",
      "|    policy_loss        | 0.509        |\n",
      "|    reward             | -0.014111788 |\n",
      "|    std                | 1.03e+03     |\n",
      "|    value_loss         | 0.00186      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 51600         |\n",
      "|    time_elapsed       | 778           |\n",
      "|    total_timesteps    | 258000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.7         |\n",
      "|    explained_variance | -0.763        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 51599         |\n",
      "|    policy_loss        | 0.108         |\n",
      "|    reward             | -0.0024793774 |\n",
      "|    std                | 1.05e+03      |\n",
      "|    value_loss         | 9.14e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 51700        |\n",
      "|    time_elapsed       | 779          |\n",
      "|    total_timesteps    | 258500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.8        |\n",
      "|    explained_variance | 0.000363     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51699        |\n",
      "|    policy_loss        | 0.163        |\n",
      "|    reward             | -0.016565606 |\n",
      "|    std                | 1.07e+03     |\n",
      "|    value_loss         | 0.000174     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 51800       |\n",
      "|    time_elapsed       | 781         |\n",
      "|    total_timesteps    | 259000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51799       |\n",
      "|    policy_loss        | 0.0911      |\n",
      "|    reward             | 0.019578395 |\n",
      "|    std                | 1.1e+03     |\n",
      "|    value_loss         | 0.000135    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 51900       |\n",
      "|    time_elapsed       | 782         |\n",
      "|    total_timesteps    | 259500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.9       |\n",
      "|    explained_variance | 0.00141     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51899       |\n",
      "|    policy_loss        | 0.0367      |\n",
      "|    reward             | -0.02051045 |\n",
      "|    std                | 1.13e+03    |\n",
      "|    value_loss         | 0.000197    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 52000       |\n",
      "|    time_elapsed       | 784         |\n",
      "|    total_timesteps    | 260000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.9       |\n",
      "|    explained_variance | -0.141      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51999       |\n",
      "|    policy_loss        | -0.0341     |\n",
      "|    reward             | -0.03535124 |\n",
      "|    std                | 1.16e+03    |\n",
      "|    value_loss         | 0.000612    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 52100         |\n",
      "|    time_elapsed       | 785           |\n",
      "|    total_timesteps    | 260500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17           |\n",
      "|    explained_variance | 0.553         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 52099         |\n",
      "|    policy_loss        | -0.175        |\n",
      "|    reward             | -0.0034022157 |\n",
      "|    std                | 1.19e+03      |\n",
      "|    value_loss         | 0.00012       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 52200        |\n",
      "|    time_elapsed       | 786          |\n",
      "|    total_timesteps    | 261000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.1        |\n",
      "|    explained_variance | 0.54         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52199        |\n",
      "|    policy_loss        | 0.106        |\n",
      "|    reward             | 0.0063016983 |\n",
      "|    std                | 1.23e+03     |\n",
      "|    value_loss         | 0.000129     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 52300        |\n",
      "|    time_elapsed       | 788          |\n",
      "|    total_timesteps    | 261500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.1        |\n",
      "|    explained_variance | -0.904       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52299        |\n",
      "|    policy_loss        | -0.167       |\n",
      "|    reward             | -0.015850358 |\n",
      "|    std                | 1.27e+03     |\n",
      "|    value_loss         | 0.000141     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 52400       |\n",
      "|    time_elapsed       | 789         |\n",
      "|    total_timesteps    | 262000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.2       |\n",
      "|    explained_variance | 5.36e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52399       |\n",
      "|    policy_loss        | -0.534      |\n",
      "|    reward             | 0.001772055 |\n",
      "|    std                | 1.31e+03    |\n",
      "|    value_loss         | 0.00147     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 52500         |\n",
      "|    time_elapsed       | 791           |\n",
      "|    total_timesteps    | 262500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.2         |\n",
      "|    explained_variance | 0.00022       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 52499         |\n",
      "|    policy_loss        | 0.431         |\n",
      "|    reward             | -0.0038871276 |\n",
      "|    std                | 1.35e+03      |\n",
      "|    value_loss         | 0.00138       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 52600        |\n",
      "|    time_elapsed       | 792          |\n",
      "|    total_timesteps    | 263000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.3        |\n",
      "|    explained_variance | -0.109       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52599        |\n",
      "|    policy_loss        | 0.171        |\n",
      "|    reward             | -0.008612051 |\n",
      "|    std                | 1.38e+03     |\n",
      "|    value_loss         | 0.000189     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 52700        |\n",
      "|    time_elapsed       | 794          |\n",
      "|    total_timesteps    | 263500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.3        |\n",
      "|    explained_variance | 0.0577       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52699        |\n",
      "|    policy_loss        | 0.271        |\n",
      "|    reward             | 0.0066055027 |\n",
      "|    std                | 1.41e+03     |\n",
      "|    value_loss         | 0.000294     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 52800        |\n",
      "|    time_elapsed       | 795          |\n",
      "|    total_timesteps    | 264000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.4        |\n",
      "|    explained_variance | 0.0404       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52799        |\n",
      "|    policy_loss        | -1.95        |\n",
      "|    reward             | -0.014411386 |\n",
      "|    std                | 1.46e+03     |\n",
      "|    value_loss         | 0.0151       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 52900       |\n",
      "|    time_elapsed       | 796         |\n",
      "|    total_timesteps    | 264500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.4       |\n",
      "|    explained_variance | 0.0037      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52899       |\n",
      "|    policy_loss        | 0.802       |\n",
      "|    reward             | -0.10615811 |\n",
      "|    std                | 1.48e+03    |\n",
      "|    value_loss         | 0.00379     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 53000       |\n",
      "|    time_elapsed       | 798         |\n",
      "|    total_timesteps    | 265000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.4       |\n",
      "|    explained_variance | 0.125       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52999       |\n",
      "|    policy_loss        | 0.44        |\n",
      "|    reward             | 0.072471604 |\n",
      "|    std                | 1.48e+03    |\n",
      "|    value_loss         | 0.0119      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 53100       |\n",
      "|    time_elapsed       | 799         |\n",
      "|    total_timesteps    | 265500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53099       |\n",
      "|    policy_loss        | -0.63       |\n",
      "|    reward             | 0.005248745 |\n",
      "|    std                | 1.51e+03    |\n",
      "|    value_loss         | 0.00149     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 53200       |\n",
      "|    time_elapsed       | 801         |\n",
      "|    total_timesteps    | 266000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.5       |\n",
      "|    explained_variance | 0.379       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53199       |\n",
      "|    policy_loss        | 0.0113      |\n",
      "|    reward             | -0.02303498 |\n",
      "|    std                | 1.53e+03    |\n",
      "|    value_loss         | 1.52e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 53300       |\n",
      "|    time_elapsed       | 802         |\n",
      "|    total_timesteps    | 266500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.5       |\n",
      "|    explained_variance | -0.036      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53299       |\n",
      "|    policy_loss        | 1.65        |\n",
      "|    reward             | 0.004818731 |\n",
      "|    std                | 1.56e+03    |\n",
      "|    value_loss         | 0.00862     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 53400         |\n",
      "|    time_elapsed       | 804           |\n",
      "|    total_timesteps    | 267000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.6         |\n",
      "|    explained_variance | -0.55         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 53399         |\n",
      "|    policy_loss        | -0.644        |\n",
      "|    reward             | -0.0125326095 |\n",
      "|    std                | 1.61e+03      |\n",
      "|    value_loss         | 0.002         |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 53500      |\n",
      "|    time_elapsed       | 805        |\n",
      "|    total_timesteps    | 267500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -17.6      |\n",
      "|    explained_variance | 0.34       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 53499      |\n",
      "|    policy_loss        | 0.245      |\n",
      "|    reward             | 0.08409838 |\n",
      "|    std                | 1.63e+03   |\n",
      "|    value_loss         | 0.001      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 53600       |\n",
      "|    time_elapsed       | 806         |\n",
      "|    total_timesteps    | 268000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.6       |\n",
      "|    explained_variance | 0.177       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53599       |\n",
      "|    policy_loss        | -0.277      |\n",
      "|    reward             | 0.030559268 |\n",
      "|    std                | 1.65e+03    |\n",
      "|    value_loss         | 0.00487     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 53700       |\n",
      "|    time_elapsed       | 808         |\n",
      "|    total_timesteps    | 268500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.7       |\n",
      "|    explained_variance | 0.0966      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53699       |\n",
      "|    policy_loss        | -0.178      |\n",
      "|    reward             | 0.008429979 |\n",
      "|    std                | 1.66e+03    |\n",
      "|    value_loss         | 0.000946    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 53800        |\n",
      "|    time_elapsed       | 809          |\n",
      "|    total_timesteps    | 269000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.7        |\n",
      "|    explained_variance | -1.63e-05    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 53799        |\n",
      "|    policy_loss        | -0.218       |\n",
      "|    reward             | -0.027865434 |\n",
      "|    std                | 1.68e+03     |\n",
      "|    value_loss         | 0.000205     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 53900        |\n",
      "|    time_elapsed       | 811          |\n",
      "|    total_timesteps    | 269500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.7        |\n",
      "|    explained_variance | 0.0506       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 53899        |\n",
      "|    policy_loss        | -0.182       |\n",
      "|    reward             | -0.021327205 |\n",
      "|    std                | 1.73e+03     |\n",
      "|    value_loss         | 0.00163      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 332        |\n",
      "|    iterations         | 54000      |\n",
      "|    time_elapsed       | 813        |\n",
      "|    total_timesteps    | 270000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -17.8      |\n",
      "|    explained_variance | 0.782      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 53999      |\n",
      "|    policy_loss        | -0.64      |\n",
      "|    reward             | 0.09406279 |\n",
      "|    std                | 1.75e+03   |\n",
      "|    value_loss         | 0.00156    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 54100       |\n",
      "|    time_elapsed       | 814         |\n",
      "|    total_timesteps    | 270500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.8       |\n",
      "|    explained_variance | 0.464       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 54099       |\n",
      "|    policy_loss        | 0.544       |\n",
      "|    reward             | 0.021456921 |\n",
      "|    std                | 1.77e+03    |\n",
      "|    value_loss         | 0.00326     |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 100\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 70697.67\n",
      "total_reward: 60697.67\n",
      "total_cost: 16.80\n",
      "total_trades: 5410\n",
      "Sharpe: 0.741\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 54200    |\n",
      "|    time_elapsed       | 816      |\n",
      "|    total_timesteps    | 271000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -17.8    |\n",
      "|    explained_variance | -0.0111  |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 54199    |\n",
      "|    policy_loss        | -0.129   |\n",
      "|    reward             | 0.009575 |\n",
      "|    std                | 1.78e+03 |\n",
      "|    value_loss         | 0.000102 |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 54300         |\n",
      "|    time_elapsed       | 817           |\n",
      "|    total_timesteps    | 271500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.8         |\n",
      "|    explained_variance | 0.264         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 54299         |\n",
      "|    policy_loss        | 0.833         |\n",
      "|    reward             | -0.0053213486 |\n",
      "|    std                | 1.81e+03      |\n",
      "|    value_loss         | 0.0027        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 54400       |\n",
      "|    time_elapsed       | 819         |\n",
      "|    total_timesteps    | 272000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.9       |\n",
      "|    explained_variance | 1.14e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 54399       |\n",
      "|    policy_loss        | -0.067      |\n",
      "|    reward             | 0.026792282 |\n",
      "|    std                | 1.84e+03    |\n",
      "|    value_loss         | 0.000139    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 54500        |\n",
      "|    time_elapsed       | 821          |\n",
      "|    total_timesteps    | 272500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 54499        |\n",
      "|    policy_loss        | -0.123       |\n",
      "|    reward             | -0.009913811 |\n",
      "|    std                | 1.88e+03     |\n",
      "|    value_loss         | 0.000324     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 54600       |\n",
      "|    time_elapsed       | 823         |\n",
      "|    total_timesteps    | 273000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.9       |\n",
      "|    explained_variance | 2.98e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 54599       |\n",
      "|    policy_loss        | -2.48       |\n",
      "|    reward             | 0.046354532 |\n",
      "|    std                | 1.89e+03    |\n",
      "|    value_loss         | 0.0226      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 54700       |\n",
      "|    time_elapsed       | 824         |\n",
      "|    total_timesteps    | 273500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18         |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 54699       |\n",
      "|    policy_loss        | -0.839      |\n",
      "|    reward             | -0.08012122 |\n",
      "|    std                | 1.94e+03    |\n",
      "|    value_loss         | 0.00462     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 54800        |\n",
      "|    time_elapsed       | 826          |\n",
      "|    total_timesteps    | 274000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 54799        |\n",
      "|    policy_loss        | -0.531       |\n",
      "|    reward             | -0.020628935 |\n",
      "|    std                | 1.98e+03     |\n",
      "|    value_loss         | 0.00259      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 54900       |\n",
      "|    time_elapsed       | 827         |\n",
      "|    total_timesteps    | 274500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 54899       |\n",
      "|    policy_loss        | 0.657       |\n",
      "|    reward             | 0.047069017 |\n",
      "|    std                | 2.02e+03    |\n",
      "|    value_loss         | 0.00203     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 55000       |\n",
      "|    time_elapsed       | 829         |\n",
      "|    total_timesteps    | 275000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18         |\n",
      "|    explained_variance | 0.394       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 54999       |\n",
      "|    policy_loss        | 1.41        |\n",
      "|    reward             | -0.10251947 |\n",
      "|    std                | 2.01e+03    |\n",
      "|    value_loss         | 0.0087      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 55100       |\n",
      "|    time_elapsed       | 831         |\n",
      "|    total_timesteps    | 275500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.1       |\n",
      "|    explained_variance | 3.99e-06    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 55099       |\n",
      "|    policy_loss        | -0.708      |\n",
      "|    reward             | -0.14385965 |\n",
      "|    std                | 2.03e+03    |\n",
      "|    value_loss         | 0.00558     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 55200      |\n",
      "|    time_elapsed       | 832        |\n",
      "|    total_timesteps    | 276000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.1      |\n",
      "|    explained_variance | 0.431      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 55199      |\n",
      "|    policy_loss        | -0.896     |\n",
      "|    reward             | 0.14755279 |\n",
      "|    std                | 2.05e+03   |\n",
      "|    value_loss         | 0.0379     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 55300        |\n",
      "|    time_elapsed       | 834          |\n",
      "|    total_timesteps    | 276500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.1        |\n",
      "|    explained_variance | -5.64        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55299        |\n",
      "|    policy_loss        | -0.0534      |\n",
      "|    reward             | -0.011833061 |\n",
      "|    std                | 2.08e+03     |\n",
      "|    value_loss         | 0.000654     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 55400       |\n",
      "|    time_elapsed       | 836         |\n",
      "|    total_timesteps    | 277000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.1       |\n",
      "|    explained_variance | -2.41       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 55399       |\n",
      "|    policy_loss        | 0.327       |\n",
      "|    reward             | 0.010775744 |\n",
      "|    std                | 2.11e+03    |\n",
      "|    value_loss         | 0.000519    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 55500       |\n",
      "|    time_elapsed       | 837         |\n",
      "|    total_timesteps    | 277500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.2       |\n",
      "|    explained_variance | 0.000113    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 55499       |\n",
      "|    policy_loss        | 1.26        |\n",
      "|    reward             | 0.021346526 |\n",
      "|    std                | 2.14e+03    |\n",
      "|    value_loss         | 0.00504     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 55600         |\n",
      "|    time_elapsed       | 839           |\n",
      "|    total_timesteps    | 278000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.2         |\n",
      "|    explained_variance | 0.202         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 55599         |\n",
      "|    policy_loss        | 0.676         |\n",
      "|    reward             | -0.0036945664 |\n",
      "|    std                | 2.16e+03      |\n",
      "|    value_loss         | 0.00317       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 55700      |\n",
      "|    time_elapsed       | 841        |\n",
      "|    total_timesteps    | 278500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.2      |\n",
      "|    explained_variance | 0.0956     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 55699      |\n",
      "|    policy_loss        | -1.55      |\n",
      "|    reward             | 0.09820838 |\n",
      "|    std                | 2.2e+03    |\n",
      "|    value_loss         | 0.00879    |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 331            |\n",
      "|    iterations         | 55800          |\n",
      "|    time_elapsed       | 842            |\n",
      "|    total_timesteps    | 279000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -18.3          |\n",
      "|    explained_variance | -0.989         |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 55799          |\n",
      "|    policy_loss        | -0.582         |\n",
      "|    reward             | -0.00055765687 |\n",
      "|    std                | 2.23e+03       |\n",
      "|    value_loss         | 0.00121        |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 55900      |\n",
      "|    time_elapsed       | 844        |\n",
      "|    total_timesteps    | 279500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.3      |\n",
      "|    explained_variance | 0.165      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 55899      |\n",
      "|    policy_loss        | -0.244     |\n",
      "|    reward             | 0.00943453 |\n",
      "|    std                | 2.27e+03   |\n",
      "|    value_loss         | 0.000276   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 56000        |\n",
      "|    time_elapsed       | 846          |\n",
      "|    total_timesteps    | 280000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.3        |\n",
      "|    explained_variance | 0.405        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55999        |\n",
      "|    policy_loss        | 0.356        |\n",
      "|    reward             | 0.0016347084 |\n",
      "|    std                | 2.33e+03     |\n",
      "|    value_loss         | 0.00044      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 56100       |\n",
      "|    time_elapsed       | 847         |\n",
      "|    total_timesteps    | 280500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.4       |\n",
      "|    explained_variance | 0.135       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56099       |\n",
      "|    policy_loss        | -1.17       |\n",
      "|    reward             | 0.011740548 |\n",
      "|    std                | 2.37e+03    |\n",
      "|    value_loss         | 0.00762     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 56200         |\n",
      "|    time_elapsed       | 849           |\n",
      "|    total_timesteps    | 281000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 56199         |\n",
      "|    policy_loss        | -0.741        |\n",
      "|    reward             | -0.0046979906 |\n",
      "|    std                | 2.43e+03      |\n",
      "|    value_loss         | 0.00298       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 56300       |\n",
      "|    time_elapsed       | 850         |\n",
      "|    total_timesteps    | 281500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56299       |\n",
      "|    policy_loss        | 2.12        |\n",
      "|    reward             | 0.025642218 |\n",
      "|    std                | 2.45e+03    |\n",
      "|    value_loss         | 0.0179      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 56400        |\n",
      "|    time_elapsed       | 852          |\n",
      "|    total_timesteps    | 282000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.5        |\n",
      "|    explained_variance | 0.424        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 56399        |\n",
      "|    policy_loss        | 0.0958       |\n",
      "|    reward             | 0.0045500444 |\n",
      "|    std                | 2.49e+03     |\n",
      "|    value_loss         | 0.000105     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 56500         |\n",
      "|    time_elapsed       | 854           |\n",
      "|    total_timesteps    | 282500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 56499         |\n",
      "|    policy_loss        | 0.0425        |\n",
      "|    reward             | -0.0035339447 |\n",
      "|    std                | 2.55e+03      |\n",
      "|    value_loss         | 2.14e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 56600       |\n",
      "|    time_elapsed       | 855         |\n",
      "|    total_timesteps    | 283000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.5       |\n",
      "|    explained_variance | 0.105       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56599       |\n",
      "|    policy_loss        | 1.88        |\n",
      "|    reward             | 0.108585656 |\n",
      "|    std                | 2.58e+03    |\n",
      "|    value_loss         | 0.0209      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 56700       |\n",
      "|    time_elapsed       | 857         |\n",
      "|    total_timesteps    | 283500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.6       |\n",
      "|    explained_variance | 0.447       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56699       |\n",
      "|    policy_loss        | 0.346       |\n",
      "|    reward             | 0.084347196 |\n",
      "|    std                | 2.65e+03    |\n",
      "|    value_loss         | 0.00151     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 56800       |\n",
      "|    time_elapsed       | 858         |\n",
      "|    total_timesteps    | 284000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.6       |\n",
      "|    explained_variance | -0.00282    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56799       |\n",
      "|    policy_loss        | 2.94        |\n",
      "|    reward             | 0.008619397 |\n",
      "|    std                | 2.71e+03    |\n",
      "|    value_loss         | 0.0291      |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 105\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 71857.20\n",
      "total_reward: 61857.20\n",
      "total_cost: 14.16\n",
      "total_trades: 5413\n",
      "Sharpe: 0.713\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 330            |\n",
      "|    iterations         | 56900          |\n",
      "|    time_elapsed       | 860            |\n",
      "|    total_timesteps    | 284500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -18.7          |\n",
      "|    explained_variance | 0.000667       |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 56899          |\n",
      "|    policy_loss        | -0.286         |\n",
      "|    reward             | -0.00083024654 |\n",
      "|    std                | 2.74e+03       |\n",
      "|    value_loss         | 0.000283       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 57000         |\n",
      "|    time_elapsed       | 861           |\n",
      "|    total_timesteps    | 285000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.7         |\n",
      "|    explained_variance | 0.205         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 56999         |\n",
      "|    policy_loss        | 0.446         |\n",
      "|    reward             | -0.0077556823 |\n",
      "|    std                | 2.78e+03      |\n",
      "|    value_loss         | 0.000654      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 57100        |\n",
      "|    time_elapsed       | 863          |\n",
      "|    total_timesteps    | 285500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.7        |\n",
      "|    explained_variance | 0.159        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57099        |\n",
      "|    policy_loss        | 0.715        |\n",
      "|    reward             | -0.029524662 |\n",
      "|    std                | 2.83e+03     |\n",
      "|    value_loss         | 0.00154      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 57200       |\n",
      "|    time_elapsed       | 864         |\n",
      "|    total_timesteps    | 286000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.8       |\n",
      "|    explained_variance | 0.00651     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57199       |\n",
      "|    policy_loss        | -0.843      |\n",
      "|    reward             | 0.031244468 |\n",
      "|    std                | 2.91e+03    |\n",
      "|    value_loss         | 0.0023      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 57300        |\n",
      "|    time_elapsed       | 866          |\n",
      "|    total_timesteps    | 286500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.8        |\n",
      "|    explained_variance | 0.485        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57299        |\n",
      "|    policy_loss        | -0.928       |\n",
      "|    reward             | -0.025784776 |\n",
      "|    std                | 2.95e+03     |\n",
      "|    value_loss         | 0.00422      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 57400        |\n",
      "|    time_elapsed       | 867          |\n",
      "|    total_timesteps    | 287000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57399        |\n",
      "|    policy_loss        | -0.386       |\n",
      "|    reward             | -0.015982911 |\n",
      "|    std                | 3.02e+03     |\n",
      "|    value_loss         | 0.000833     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 57500       |\n",
      "|    time_elapsed       | 869         |\n",
      "|    total_timesteps    | 287500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.9       |\n",
      "|    explained_variance | -0.566      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57499       |\n",
      "|    policy_loss        | 0.166       |\n",
      "|    reward             | 0.004064013 |\n",
      "|    std                | 3.07e+03    |\n",
      "|    value_loss         | 8.9e-05     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 57600        |\n",
      "|    time_elapsed       | 871          |\n",
      "|    total_timesteps    | 288000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.9        |\n",
      "|    explained_variance | 0.169        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57599        |\n",
      "|    policy_loss        | -0.167       |\n",
      "|    reward             | -0.006878858 |\n",
      "|    std                | 3.15e+03     |\n",
      "|    value_loss         | 9.47e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 57700        |\n",
      "|    time_elapsed       | 872          |\n",
      "|    total_timesteps    | 288500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19          |\n",
      "|    explained_variance | 2.33e-05     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57699        |\n",
      "|    policy_loss        | 0.0926       |\n",
      "|    reward             | -0.054258972 |\n",
      "|    std                | 3.22e+03     |\n",
      "|    value_loss         | 0.000106     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 57800      |\n",
      "|    time_elapsed       | 874        |\n",
      "|    total_timesteps    | 289000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19        |\n",
      "|    explained_variance | -0.112     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 57799      |\n",
      "|    policy_loss        | -0.517     |\n",
      "|    reward             | 0.11541504 |\n",
      "|    std                | 3.27e+03   |\n",
      "|    value_loss         | 0.000982   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 57900        |\n",
      "|    time_elapsed       | 875          |\n",
      "|    total_timesteps    | 289500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.1        |\n",
      "|    explained_variance | 0.282        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57899        |\n",
      "|    policy_loss        | -0.179       |\n",
      "|    reward             | -0.017641878 |\n",
      "|    std                | 3.35e+03     |\n",
      "|    value_loss         | 0.00215      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 58000       |\n",
      "|    time_elapsed       | 877         |\n",
      "|    total_timesteps    | 290000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.1       |\n",
      "|    explained_variance | -0.804      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57999       |\n",
      "|    policy_loss        | -0.437      |\n",
      "|    reward             | 0.015599235 |\n",
      "|    std                | 3.41e+03    |\n",
      "|    value_loss         | 0.000721    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 58100       |\n",
      "|    time_elapsed       | 878         |\n",
      "|    total_timesteps    | 290500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.1       |\n",
      "|    explained_variance | 0.944       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58099       |\n",
      "|    policy_loss        | -0.131      |\n",
      "|    reward             | -0.00858235 |\n",
      "|    std                | 3.48e+03    |\n",
      "|    value_loss         | 5.19e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 58200       |\n",
      "|    time_elapsed       | 880         |\n",
      "|    total_timesteps    | 291000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.2       |\n",
      "|    explained_variance | 0.109       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58199       |\n",
      "|    policy_loss        | -0.0557     |\n",
      "|    reward             | 0.009662571 |\n",
      "|    std                | 3.58e+03    |\n",
      "|    value_loss         | 5.06e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 58300        |\n",
      "|    time_elapsed       | 881          |\n",
      "|    total_timesteps    | 291500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.3        |\n",
      "|    explained_variance | 0.418        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 58299        |\n",
      "|    policy_loss        | -0.355       |\n",
      "|    reward             | 0.0036788033 |\n",
      "|    std                | 3.7e+03      |\n",
      "|    value_loss         | 0.000345     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 58400        |\n",
      "|    time_elapsed       | 883          |\n",
      "|    total_timesteps    | 292000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.3        |\n",
      "|    explained_variance | 0.0951       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 58399        |\n",
      "|    policy_loss        | 0.0151       |\n",
      "|    reward             | -0.014467885 |\n",
      "|    std                | 3.78e+03     |\n",
      "|    value_loss         | 0.000216     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 58500        |\n",
      "|    time_elapsed       | 885          |\n",
      "|    total_timesteps    | 292500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.4        |\n",
      "|    explained_variance | -0.329       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 58499        |\n",
      "|    policy_loss        | -0.411       |\n",
      "|    reward             | 0.0017903816 |\n",
      "|    std                | 3.88e+03     |\n",
      "|    value_loss         | 0.000649     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 58600        |\n",
      "|    time_elapsed       | 886          |\n",
      "|    total_timesteps    | 293000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.4        |\n",
      "|    explained_variance | 0.565        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 58599        |\n",
      "|    policy_loss        | -0.442       |\n",
      "|    reward             | -0.011395217 |\n",
      "|    std                | 3.94e+03     |\n",
      "|    value_loss         | 0.00051      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 58700        |\n",
      "|    time_elapsed       | 888          |\n",
      "|    total_timesteps    | 293500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.4        |\n",
      "|    explained_variance | 0.0177       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 58699        |\n",
      "|    policy_loss        | 0.0303       |\n",
      "|    reward             | -0.015425886 |\n",
      "|    std                | 4.04e+03     |\n",
      "|    value_loss         | 5.59e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 58800         |\n",
      "|    time_elapsed       | 890           |\n",
      "|    total_timesteps    | 294000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.5         |\n",
      "|    explained_variance | 0.327         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 58799         |\n",
      "|    policy_loss        | 0.303         |\n",
      "|    reward             | -0.0034274883 |\n",
      "|    std                | 4.18e+03      |\n",
      "|    value_loss         | 0.00026       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 58900       |\n",
      "|    time_elapsed       | 891         |\n",
      "|    total_timesteps    | 294500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.6       |\n",
      "|    explained_variance | 0.307       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58899       |\n",
      "|    policy_loss        | -0.304      |\n",
      "|    reward             | 0.018095978 |\n",
      "|    std                | 4.35e+03    |\n",
      "|    value_loss         | 0.000402    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 59000       |\n",
      "|    time_elapsed       | 893         |\n",
      "|    total_timesteps    | 295000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58999       |\n",
      "|    policy_loss        | -1.07       |\n",
      "|    reward             | 0.050949004 |\n",
      "|    std                | 4.43e+03    |\n",
      "|    value_loss         | 0.00435     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 59100         |\n",
      "|    time_elapsed       | 894           |\n",
      "|    total_timesteps    | 295500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.7         |\n",
      "|    explained_variance | 0.102         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 59099         |\n",
      "|    policy_loss        | -0.641        |\n",
      "|    reward             | -0.0013192726 |\n",
      "|    std                | 4.48e+03      |\n",
      "|    value_loss         | 0.00139       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 330            |\n",
      "|    iterations         | 59200          |\n",
      "|    time_elapsed       | 896            |\n",
      "|    total_timesteps    | 296000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -19.7          |\n",
      "|    explained_variance | 0.326          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 59199          |\n",
      "|    policy_loss        | 0.0669         |\n",
      "|    reward             | -0.00063184206 |\n",
      "|    std                | 4.61e+03       |\n",
      "|    value_loss         | 3.27e-05       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 59300         |\n",
      "|    time_elapsed       | 897           |\n",
      "|    total_timesteps    | 296500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 59299         |\n",
      "|    policy_loss        | -0.166        |\n",
      "|    reward             | -0.0037645637 |\n",
      "|    std                | 4.78e+03      |\n",
      "|    value_loss         | 0.000537      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 59400      |\n",
      "|    time_elapsed       | 899        |\n",
      "|    total_timesteps    | 297000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.8      |\n",
      "|    explained_variance | 0.241      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 59399      |\n",
      "|    policy_loss        | -0.669     |\n",
      "|    reward             | 0.03322376 |\n",
      "|    std                | 4.91e+03   |\n",
      "|    value_loss         | 0.00308    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 59500        |\n",
      "|    time_elapsed       | 900          |\n",
      "|    total_timesteps    | 297500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 59499        |\n",
      "|    policy_loss        | -0.106       |\n",
      "|    reward             | -0.058105525 |\n",
      "|    std                | 5.06e+03     |\n",
      "|    value_loss         | 0.000382     |\n",
      "----------------------------------------\n",
      "day: 2707, episode: 110\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 59841.56\n",
      "total_reward: 49841.56\n",
      "total_cost: 13.44\n",
      "total_trades: 5414\n",
      "Sharpe: 0.681\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 59600        |\n",
      "|    time_elapsed       | 902          |\n",
      "|    total_timesteps    | 298000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.9        |\n",
      "|    explained_variance | -0.0476      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 59599        |\n",
      "|    policy_loss        | -0.0295      |\n",
      "|    reward             | -0.007896301 |\n",
      "|    std                | 5.17e+03     |\n",
      "|    value_loss         | 7.9e-05      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 59700       |\n",
      "|    time_elapsed       | 903         |\n",
      "|    total_timesteps    | 298500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20         |\n",
      "|    explained_variance | 0.634       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 59699       |\n",
      "|    policy_loss        | 0.413       |\n",
      "|    reward             | 0.026818473 |\n",
      "|    std                | 5.27e+03    |\n",
      "|    value_loss         | 0.000479    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 59800       |\n",
      "|    time_elapsed       | 905         |\n",
      "|    total_timesteps    | 299000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20         |\n",
      "|    explained_variance | 0.0329      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 59799       |\n",
      "|    policy_loss        | 1.62        |\n",
      "|    reward             | 0.001827549 |\n",
      "|    std                | 5.38e+03    |\n",
      "|    value_loss         | 0.00946     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 59900        |\n",
      "|    time_elapsed       | 906          |\n",
      "|    total_timesteps    | 299500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 59899        |\n",
      "|    policy_loss        | -0.256       |\n",
      "|    reward             | -0.030046027 |\n",
      "|    std                | 5.43e+03     |\n",
      "|    value_loss         | 0.00069      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 60000       |\n",
      "|    time_elapsed       | 908         |\n",
      "|    total_timesteps    | 300000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.1       |\n",
      "|    explained_variance | -0.116      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 59999       |\n",
      "|    policy_loss        | -0.178      |\n",
      "|    reward             | 0.048003327 |\n",
      "|    std                | 5.58e+03    |\n",
      "|    value_loss         | 0.000922    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 60100        |\n",
      "|    time_elapsed       | 909          |\n",
      "|    total_timesteps    | 300500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.1        |\n",
      "|    explained_variance | 0.14         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60099        |\n",
      "|    policy_loss        | 0.0285       |\n",
      "|    reward             | -0.018959595 |\n",
      "|    std                | 5.57e+03     |\n",
      "|    value_loss         | 0.000898     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 60200        |\n",
      "|    time_elapsed       | 911          |\n",
      "|    total_timesteps    | 301000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.1        |\n",
      "|    explained_variance | -0.014       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60199        |\n",
      "|    policy_loss        | -0.511       |\n",
      "|    reward             | -0.012647221 |\n",
      "|    std                | 5.66e+03     |\n",
      "|    value_loss         | 0.001        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 60300       |\n",
      "|    time_elapsed       | 912         |\n",
      "|    total_timesteps    | 301500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.1       |\n",
      "|    explained_variance | 0.00622     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 60299       |\n",
      "|    policy_loss        | 0.0511      |\n",
      "|    reward             | 0.004393241 |\n",
      "|    std                | 5.74e+03    |\n",
      "|    value_loss         | 1.89e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 60400        |\n",
      "|    time_elapsed       | 914          |\n",
      "|    total_timesteps    | 302000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.2        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60399        |\n",
      "|    policy_loss        | 0.679        |\n",
      "|    reward             | -0.059680693 |\n",
      "|    std                | 5.8e+03      |\n",
      "|    value_loss         | 0.00289      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 60500       |\n",
      "|    time_elapsed       | 916         |\n",
      "|    total_timesteps    | 302500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.2       |\n",
      "|    explained_variance | -0.973      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 60499       |\n",
      "|    policy_loss        | -1.13       |\n",
      "|    reward             | 0.005105965 |\n",
      "|    std                | 5.87e+03    |\n",
      "|    value_loss         | 0.00392     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 60600      |\n",
      "|    time_elapsed       | 917        |\n",
      "|    total_timesteps    | 303000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.2      |\n",
      "|    explained_variance | 0.44       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 60599      |\n",
      "|    policy_loss        | -1.63      |\n",
      "|    reward             | 0.04150951 |\n",
      "|    std                | 5.95e+03   |\n",
      "|    value_loss         | 0.00702    |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 330            |\n",
      "|    iterations         | 60700          |\n",
      "|    time_elapsed       | 919            |\n",
      "|    total_timesteps    | 303500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -20.2          |\n",
      "|    explained_variance | 0.684          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 60699          |\n",
      "|    policy_loss        | -0.135         |\n",
      "|    reward             | -0.00042134096 |\n",
      "|    std                | 6.02e+03       |\n",
      "|    value_loss         | 5.96e-05       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 60800       |\n",
      "|    time_elapsed       | 920         |\n",
      "|    total_timesteps    | 304000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.3       |\n",
      "|    explained_variance | 0.0748      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 60799       |\n",
      "|    policy_loss        | 0.445       |\n",
      "|    reward             | 0.010843961 |\n",
      "|    std                | 6.11e+03    |\n",
      "|    value_loss         | 0.000497    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 60900        |\n",
      "|    time_elapsed       | 922          |\n",
      "|    total_timesteps    | 304500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.3        |\n",
      "|    explained_variance | -0.203       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60899        |\n",
      "|    policy_loss        | -1.67        |\n",
      "|    reward             | -0.016236901 |\n",
      "|    std                | 6.21e+03     |\n",
      "|    value_loss         | 0.00752      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 61000      |\n",
      "|    time_elapsed       | 923        |\n",
      "|    total_timesteps    | 305000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.3      |\n",
      "|    explained_variance | 0.215      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 60999      |\n",
      "|    policy_loss        | -0.747     |\n",
      "|    reward             | 0.05674314 |\n",
      "|    std                | 6.27e+03   |\n",
      "|    value_loss         | 0.00175    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 61100       |\n",
      "|    time_elapsed       | 925         |\n",
      "|    total_timesteps    | 305500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.4       |\n",
      "|    explained_variance | 0.516       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 61099       |\n",
      "|    policy_loss        | 1.35        |\n",
      "|    reward             | -0.43658894 |\n",
      "|    std                | 6.36e+03    |\n",
      "|    value_loss         | 0.0121      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 61200       |\n",
      "|    time_elapsed       | 926         |\n",
      "|    total_timesteps    | 306000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 61199       |\n",
      "|    policy_loss        | 7.51        |\n",
      "|    reward             | 0.014795459 |\n",
      "|    std                | 6.36e+03    |\n",
      "|    value_loss         | 0.159       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 61300        |\n",
      "|    time_elapsed       | 928          |\n",
      "|    total_timesteps    | 306500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.4        |\n",
      "|    explained_variance | 0.647        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61299        |\n",
      "|    policy_loss        | 0.422        |\n",
      "|    reward             | -0.005779179 |\n",
      "|    std                | 6.42e+03     |\n",
      "|    value_loss         | 0.000492     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 61400       |\n",
      "|    time_elapsed       | 929         |\n",
      "|    total_timesteps    | 307000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.4       |\n",
      "|    explained_variance | -0.372      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 61399       |\n",
      "|    policy_loss        | -0.635      |\n",
      "|    reward             | 0.016141849 |\n",
      "|    std                | 6.58e+03    |\n",
      "|    value_loss         | 0.00101     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 61500       |\n",
      "|    time_elapsed       | 931         |\n",
      "|    total_timesteps    | 307500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.5       |\n",
      "|    explained_variance | -0.0693     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 61499       |\n",
      "|    policy_loss        | 1.94        |\n",
      "|    reward             | 0.055965357 |\n",
      "|    std                | 6.76e+03    |\n",
      "|    value_loss         | 0.00929     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 61600        |\n",
      "|    time_elapsed       | 932          |\n",
      "|    total_timesteps    | 308000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.5        |\n",
      "|    explained_variance | 0.122        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61599        |\n",
      "|    policy_loss        | -1.38        |\n",
      "|    reward             | -0.009294728 |\n",
      "|    std                | 6.96e+03     |\n",
      "|    value_loss         | 0.00488      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 61700       |\n",
      "|    time_elapsed       | 934         |\n",
      "|    total_timesteps    | 308500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.6       |\n",
      "|    explained_variance | 0.317       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 61699       |\n",
      "|    policy_loss        | -5.83       |\n",
      "|    reward             | -0.12735805 |\n",
      "|    std                | 7.07e+03    |\n",
      "|    value_loss         | 0.091       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 61800        |\n",
      "|    time_elapsed       | 935          |\n",
      "|    total_timesteps    | 309000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.6        |\n",
      "|    explained_variance | -0.28        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61799        |\n",
      "|    policy_loss        | -0.136       |\n",
      "|    reward             | -0.036493707 |\n",
      "|    std                | 7.22e+03     |\n",
      "|    value_loss         | 9.28e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 61900       |\n",
      "|    time_elapsed       | 937         |\n",
      "|    total_timesteps    | 309500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.6       |\n",
      "|    explained_variance | 0.494       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 61899       |\n",
      "|    policy_loss        | 0.0379      |\n",
      "|    reward             | 0.007840269 |\n",
      "|    std                | 7.34e+03    |\n",
      "|    value_loss         | 6.36e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 62000      |\n",
      "|    time_elapsed       | 939        |\n",
      "|    total_timesteps    | 310000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.7      |\n",
      "|    explained_variance | -0.0879    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 61999      |\n",
      "|    policy_loss        | 0.684      |\n",
      "|    reward             | 0.03932284 |\n",
      "|    std                | 7.48e+03   |\n",
      "|    value_loss         | 0.0019     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 62100       |\n",
      "|    time_elapsed       | 940         |\n",
      "|    total_timesteps    | 310500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 62099       |\n",
      "|    policy_loss        | 0.536       |\n",
      "|    reward             | 0.040756207 |\n",
      "|    std                | 7.58e+03    |\n",
      "|    value_loss         | 0.00086     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 62200        |\n",
      "|    time_elapsed       | 942          |\n",
      "|    total_timesteps    | 311000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.7        |\n",
      "|    explained_variance | 0.216        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62199        |\n",
      "|    policy_loss        | 0.0245       |\n",
      "|    reward             | -0.042187907 |\n",
      "|    std                | 7.68e+03     |\n",
      "|    value_loss         | 0.000201     |\n",
      "----------------------------------------\n",
      "day: 2707, episode: 115\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 66717.01\n",
      "total_reward: 56717.01\n",
      "total_cost: 13.98\n",
      "total_trades: 5412\n",
      "Sharpe: 0.715\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 62300        |\n",
      "|    time_elapsed       | 943          |\n",
      "|    total_timesteps    | 311500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.8        |\n",
      "|    explained_variance | 0.217        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62299        |\n",
      "|    policy_loss        | -0.371       |\n",
      "|    reward             | -0.012139623 |\n",
      "|    std                | 7.81e+03     |\n",
      "|    value_loss         | 0.000455     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 62400       |\n",
      "|    time_elapsed       | 945         |\n",
      "|    total_timesteps    | 312000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.8       |\n",
      "|    explained_variance | 0.312       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 62399       |\n",
      "|    policy_loss        | -0.738      |\n",
      "|    reward             | 0.038264617 |\n",
      "|    std                | 7.91e+03    |\n",
      "|    value_loss         | 0.00164     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 62500       |\n",
      "|    time_elapsed       | 946         |\n",
      "|    total_timesteps    | 312500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.8       |\n",
      "|    explained_variance | -0.025      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 62499       |\n",
      "|    policy_loss        | -0.726      |\n",
      "|    reward             | -0.04467727 |\n",
      "|    std                | 8.13e+03    |\n",
      "|    value_loss         | 0.00155     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 62600       |\n",
      "|    time_elapsed       | 948         |\n",
      "|    total_timesteps    | 313000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.9       |\n",
      "|    explained_variance | 0.192       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 62599       |\n",
      "|    policy_loss        | -0.0483     |\n",
      "|    reward             | 0.034657784 |\n",
      "|    std                | 8.38e+03    |\n",
      "|    value_loss         | 0.00653     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 62700       |\n",
      "|    time_elapsed       | 950         |\n",
      "|    total_timesteps    | 313500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.9       |\n",
      "|    explained_variance | 0.765       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 62699       |\n",
      "|    policy_loss        | -3          |\n",
      "|    reward             | 0.048535142 |\n",
      "|    std                | 8.55e+03    |\n",
      "|    value_loss         | 0.0229      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 62800       |\n",
      "|    time_elapsed       | 951         |\n",
      "|    total_timesteps    | 314000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21         |\n",
      "|    explained_variance | 0.00259     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 62799       |\n",
      "|    policy_loss        | -2.98       |\n",
      "|    reward             | -0.06189467 |\n",
      "|    std                | 8.68e+03    |\n",
      "|    value_loss         | 0.0265      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 62900        |\n",
      "|    time_elapsed       | 953          |\n",
      "|    total_timesteps    | 314500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21          |\n",
      "|    explained_variance | 0.000717     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62899        |\n",
      "|    policy_loss        | 1.09         |\n",
      "|    reward             | -0.030709883 |\n",
      "|    std                | 8.85e+03     |\n",
      "|    value_loss         | 0.00259      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 63000       |\n",
      "|    time_elapsed       | 955         |\n",
      "|    total_timesteps    | 315000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 62999       |\n",
      "|    policy_loss        | 0.255       |\n",
      "|    reward             | 0.009665091 |\n",
      "|    std                | 9e+03       |\n",
      "|    value_loss         | 0.000195    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 63100        |\n",
      "|    time_elapsed       | 956          |\n",
      "|    total_timesteps    | 315500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.1        |\n",
      "|    explained_variance | -0.371       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63099        |\n",
      "|    policy_loss        | -0.884       |\n",
      "|    reward             | -0.004801583 |\n",
      "|    std                | 9.17e+03     |\n",
      "|    value_loss         | 0.00345      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 63200        |\n",
      "|    time_elapsed       | 958          |\n",
      "|    total_timesteps    | 316000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.1        |\n",
      "|    explained_variance | 0.819        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63199        |\n",
      "|    policy_loss        | -0.542       |\n",
      "|    reward             | -0.021765396 |\n",
      "|    std                | 9.41e+03     |\n",
      "|    value_loss         | 0.00145      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 63300       |\n",
      "|    time_elapsed       | 959         |\n",
      "|    total_timesteps    | 316500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.2       |\n",
      "|    explained_variance | 0.415       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63299       |\n",
      "|    policy_loss        | -1.47       |\n",
      "|    reward             | 0.102487534 |\n",
      "|    std                | 9.54e+03    |\n",
      "|    value_loss         | 0.00928     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 63400        |\n",
      "|    time_elapsed       | 961          |\n",
      "|    total_timesteps    | 317000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.2        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63399        |\n",
      "|    policy_loss        | -0.61        |\n",
      "|    reward             | -0.018733343 |\n",
      "|    std                | 9.57e+03     |\n",
      "|    value_loss         | 0.000865     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 63500       |\n",
      "|    time_elapsed       | 962         |\n",
      "|    total_timesteps    | 317500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.2       |\n",
      "|    explained_variance | 0.0372      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63499       |\n",
      "|    policy_loss        | -0.412      |\n",
      "|    reward             | 0.045257896 |\n",
      "|    std                | 9.73e+03    |\n",
      "|    value_loss         | 0.00067     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 63600        |\n",
      "|    time_elapsed       | 964          |\n",
      "|    total_timesteps    | 318000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.2        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63599        |\n",
      "|    policy_loss        | 1.37         |\n",
      "|    reward             | 0.0041565215 |\n",
      "|    std                | 9.92e+03     |\n",
      "|    value_loss         | 0.00526      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 63700         |\n",
      "|    time_elapsed       | 966           |\n",
      "|    total_timesteps    | 318500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.2         |\n",
      "|    explained_variance | 0.703         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 63699         |\n",
      "|    policy_loss        | -0.199        |\n",
      "|    reward             | -0.0024375976 |\n",
      "|    std                | 9.92e+03      |\n",
      "|    value_loss         | 0.000213      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 63800       |\n",
      "|    time_elapsed       | 967         |\n",
      "|    total_timesteps    | 319000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.3       |\n",
      "|    explained_variance | 0.425       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63799       |\n",
      "|    policy_loss        | -3.46       |\n",
      "|    reward             | -0.08009179 |\n",
      "|    std                | 1.01e+04    |\n",
      "|    value_loss         | 0.0307      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 63900      |\n",
      "|    time_elapsed       | 969        |\n",
      "|    total_timesteps    | 319500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.3      |\n",
      "|    explained_variance | 0.128      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 63899      |\n",
      "|    policy_loss        | -0.895     |\n",
      "|    reward             | 0.10793543 |\n",
      "|    std                | 1.02e+04   |\n",
      "|    value_loss         | 0.00553    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 64000        |\n",
      "|    time_elapsed       | 971          |\n",
      "|    total_timesteps    | 320000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.3        |\n",
      "|    explained_variance | 0.631        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63999        |\n",
      "|    policy_loss        | 0.291        |\n",
      "|    reward             | -0.002255139 |\n",
      "|    std                | 1.03e+04     |\n",
      "|    value_loss         | 0.000292     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 64100       |\n",
      "|    time_elapsed       | 973         |\n",
      "|    total_timesteps    | 320500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.4       |\n",
      "|    explained_variance | 0.237       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 64099       |\n",
      "|    policy_loss        | -0.0835     |\n",
      "|    reward             | 0.011239027 |\n",
      "|    std                | 1.05e+04    |\n",
      "|    value_loss         | 3.71e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 64200       |\n",
      "|    time_elapsed       | 974         |\n",
      "|    total_timesteps    | 321000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.4       |\n",
      "|    explained_variance | 0.134       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 64199       |\n",
      "|    policy_loss        | -3.56       |\n",
      "|    reward             | -0.10748613 |\n",
      "|    std                | 1.07e+04    |\n",
      "|    value_loss         | 0.0319      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 64300       |\n",
      "|    time_elapsed       | 976         |\n",
      "|    total_timesteps    | 321500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.4       |\n",
      "|    explained_variance | 3.66e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 64299       |\n",
      "|    policy_loss        | -1.42       |\n",
      "|    reward             | 0.010958961 |\n",
      "|    std                | 1.08e+04    |\n",
      "|    value_loss         | 0.00541     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 64400       |\n",
      "|    time_elapsed       | 977         |\n",
      "|    total_timesteps    | 322000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.4       |\n",
      "|    explained_variance | 0.384       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 64399       |\n",
      "|    policy_loss        | -1.29       |\n",
      "|    reward             | -0.14966023 |\n",
      "|    std                | 1.1e+04     |\n",
      "|    value_loss         | 0.00461     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 64500         |\n",
      "|    time_elapsed       | 979           |\n",
      "|    total_timesteps    | 322500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.5         |\n",
      "|    explained_variance | 0.557         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 64499         |\n",
      "|    policy_loss        | -0.211        |\n",
      "|    reward             | 0.00010579414 |\n",
      "|    std                | 1.12e+04      |\n",
      "|    value_loss         | 0.000232      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 64600         |\n",
      "|    time_elapsed       | 980           |\n",
      "|    total_timesteps    | 323000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.5         |\n",
      "|    explained_variance | -0.512        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 64599         |\n",
      "|    policy_loss        | 0.0544        |\n",
      "|    reward             | -0.0019423374 |\n",
      "|    std                | 1.13e+04      |\n",
      "|    value_loss         | 2.67e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 64700       |\n",
      "|    time_elapsed       | 982         |\n",
      "|    total_timesteps    | 323500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 64699       |\n",
      "|    policy_loss        | -0.627      |\n",
      "|    reward             | 0.012320195 |\n",
      "|    std                | 1.16e+04    |\n",
      "|    value_loss         | 0.00108     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 64800        |\n",
      "|    time_elapsed       | 984          |\n",
      "|    total_timesteps    | 324000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 64799        |\n",
      "|    policy_loss        | -0.0741      |\n",
      "|    reward             | 0.0035313843 |\n",
      "|    std                | 1.19e+04     |\n",
      "|    value_loss         | 9.09e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 64900        |\n",
      "|    time_elapsed       | 985          |\n",
      "|    total_timesteps    | 324500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.7        |\n",
      "|    explained_variance | 0.53         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 64899        |\n",
      "|    policy_loss        | 0.132        |\n",
      "|    reward             | -0.013675871 |\n",
      "|    std                | 1.23e+04     |\n",
      "|    value_loss         | 9.81e-05     |\n",
      "----------------------------------------\n",
      "day: 2707, episode: 120\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 33374.34\n",
      "total_reward: 23374.34\n",
      "total_cost: 19.79\n",
      "total_trades: 5414\n",
      "Sharpe: 0.553\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 65000        |\n",
      "|    time_elapsed       | 987          |\n",
      "|    total_timesteps    | 325000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.7        |\n",
      "|    explained_variance | -6.05        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 64999        |\n",
      "|    policy_loss        | -0.214       |\n",
      "|    reward             | -0.020207467 |\n",
      "|    std                | 1.25e+04     |\n",
      "|    value_loss         | 0.00069      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 65100      |\n",
      "|    time_elapsed       | 988        |\n",
      "|    total_timesteps    | 325500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.7      |\n",
      "|    explained_variance | 0.0147     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 65099      |\n",
      "|    policy_loss        | -0.12      |\n",
      "|    reward             | 0.01079798 |\n",
      "|    std                | 1.28e+04   |\n",
      "|    value_loss         | 6.59e-05   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 65200       |\n",
      "|    time_elapsed       | 990         |\n",
      "|    total_timesteps    | 326000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.8       |\n",
      "|    explained_variance | 1.79e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 65199       |\n",
      "|    policy_loss        | 0.484       |\n",
      "|    reward             | -0.02487778 |\n",
      "|    std                | 1.31e+04    |\n",
      "|    value_loss         | 0.00098     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 65300        |\n",
      "|    time_elapsed       | 991          |\n",
      "|    total_timesteps    | 326500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65299        |\n",
      "|    policy_loss        | -1.52        |\n",
      "|    reward             | -0.031480893 |\n",
      "|    std                | 1.34e+04     |\n",
      "|    value_loss         | 0.0078       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 65400        |\n",
      "|    time_elapsed       | 993          |\n",
      "|    total_timesteps    | 327000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65399        |\n",
      "|    policy_loss        | -1.73        |\n",
      "|    reward             | -0.026385276 |\n",
      "|    std                | 1.34e+04     |\n",
      "|    value_loss         | 0.00822      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 329       |\n",
      "|    iterations         | 65500     |\n",
      "|    time_elapsed       | 994       |\n",
      "|    total_timesteps    | 327500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -21.8     |\n",
      "|    explained_variance | 0.14      |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 65499     |\n",
      "|    policy_loss        | 2.49      |\n",
      "|    reward             | 0.0951125 |\n",
      "|    std                | 1.34e+04  |\n",
      "|    value_loss         | 0.0587    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 65600        |\n",
      "|    time_elapsed       | 996          |\n",
      "|    total_timesteps    | 328000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.9        |\n",
      "|    explained_variance | -3.56        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65599        |\n",
      "|    policy_loss        | -0.0736      |\n",
      "|    reward             | -0.010290125 |\n",
      "|    std                | 1.35e+04     |\n",
      "|    value_loss         | 0.00109      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 65700        |\n",
      "|    time_elapsed       | 997          |\n",
      "|    total_timesteps    | 328500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.9        |\n",
      "|    explained_variance | -0.193       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65699        |\n",
      "|    policy_loss        | 0.186        |\n",
      "|    reward             | -0.004872918 |\n",
      "|    std                | 1.38e+04     |\n",
      "|    value_loss         | 0.000148     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 65800        |\n",
      "|    time_elapsed       | 999          |\n",
      "|    total_timesteps    | 329000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.9        |\n",
      "|    explained_variance | 0.458        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65799        |\n",
      "|    policy_loss        | -0.11        |\n",
      "|    reward             | -0.015085639 |\n",
      "|    std                | 1.4e+04      |\n",
      "|    value_loss         | 0.0014       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 65900      |\n",
      "|    time_elapsed       | 1000       |\n",
      "|    total_timesteps    | 329500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.9      |\n",
      "|    explained_variance | 0.117      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 65899      |\n",
      "|    policy_loss        | -0.847     |\n",
      "|    reward             | 0.06592724 |\n",
      "|    std                | 1.41e+04   |\n",
      "|    value_loss         | 0.00294    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 66000         |\n",
      "|    time_elapsed       | 1002          |\n",
      "|    total_timesteps    | 330000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22           |\n",
      "|    explained_variance | 0.199         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 65999         |\n",
      "|    policy_loss        | 4.56          |\n",
      "|    reward             | 0.00011930695 |\n",
      "|    std                | 1.45e+04      |\n",
      "|    value_loss         | 0.0419        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 66100        |\n",
      "|    time_elapsed       | 1004         |\n",
      "|    total_timesteps    | 330500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22          |\n",
      "|    explained_variance | -17.2        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 66099        |\n",
      "|    policy_loss        | -0.687       |\n",
      "|    reward             | 0.0049797897 |\n",
      "|    std                | 1.47e+04     |\n",
      "|    value_loss         | 0.00153      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 66200        |\n",
      "|    time_elapsed       | 1005         |\n",
      "|    total_timesteps    | 331000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.1        |\n",
      "|    explained_variance | -1.66        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 66199        |\n",
      "|    policy_loss        | -0.455       |\n",
      "|    reward             | -0.017295443 |\n",
      "|    std                | 1.51e+04     |\n",
      "|    value_loss         | 0.000632     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 66300       |\n",
      "|    time_elapsed       | 1007        |\n",
      "|    total_timesteps    | 331500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.1       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66299       |\n",
      "|    policy_loss        | 0.128       |\n",
      "|    reward             | 0.020800961 |\n",
      "|    std                | 1.55e+04    |\n",
      "|    value_loss         | 0.000105    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 66400       |\n",
      "|    time_elapsed       | 1008        |\n",
      "|    total_timesteps    | 332000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.2       |\n",
      "|    explained_variance | 0.0751      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66399       |\n",
      "|    policy_loss        | -1.16       |\n",
      "|    reward             | 0.006350132 |\n",
      "|    std                | 1.57e+04    |\n",
      "|    value_loss         | 0.00326     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 66500      |\n",
      "|    time_elapsed       | 1010       |\n",
      "|    total_timesteps    | 332500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.2      |\n",
      "|    explained_variance | 0.474      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 66499      |\n",
      "|    policy_loss        | 1.15       |\n",
      "|    reward             | 0.22352141 |\n",
      "|    std                | 1.59e+04   |\n",
      "|    value_loss         | 0.0039     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 66600      |\n",
      "|    time_elapsed       | 1011       |\n",
      "|    total_timesteps    | 333000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 66599      |\n",
      "|    policy_loss        | 2.01       |\n",
      "|    reward             | 0.23527631 |\n",
      "|    std                | 1.6e+04    |\n",
      "|    value_loss         | 0.00865    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 66700         |\n",
      "|    time_elapsed       | 1013          |\n",
      "|    total_timesteps    | 333500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.2         |\n",
      "|    explained_variance | 0.0541        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 66699         |\n",
      "|    policy_loss        | -0.493        |\n",
      "|    reward             | -0.0011562653 |\n",
      "|    std                | 1.64e+04      |\n",
      "|    value_loss         | 0.000829      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 66800        |\n",
      "|    time_elapsed       | 1014         |\n",
      "|    total_timesteps    | 334000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.3        |\n",
      "|    explained_variance | 0.141        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 66799        |\n",
      "|    policy_loss        | 0.132        |\n",
      "|    reward             | -0.025546333 |\n",
      "|    std                | 1.66e+04     |\n",
      "|    value_loss         | 0.000315     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 66900       |\n",
      "|    time_elapsed       | 1016        |\n",
      "|    total_timesteps    | 334500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.3       |\n",
      "|    explained_variance | -0.0395     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66899       |\n",
      "|    policy_loss        | 3.69        |\n",
      "|    reward             | -0.06060778 |\n",
      "|    std                | 1.69e+04    |\n",
      "|    value_loss         | 0.0291      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 67000       |\n",
      "|    time_elapsed       | 1017        |\n",
      "|    total_timesteps    | 335000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.3       |\n",
      "|    explained_variance | 0.161       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66999       |\n",
      "|    policy_loss        | 2.45        |\n",
      "|    reward             | 0.028584102 |\n",
      "|    std                | 1.71e+04    |\n",
      "|    value_loss         | 0.0478      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 67100      |\n",
      "|    time_elapsed       | 1019       |\n",
      "|    total_timesteps    | 335500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.3      |\n",
      "|    explained_variance | 0.166      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 67099      |\n",
      "|    policy_loss        | 0.0746     |\n",
      "|    reward             | 0.25927174 |\n",
      "|    std                | 1.72e+04   |\n",
      "|    value_loss         | 0.0123     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 67200       |\n",
      "|    time_elapsed       | 1021        |\n",
      "|    total_timesteps    | 336000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.4       |\n",
      "|    explained_variance | -0.308      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 67199       |\n",
      "|    policy_loss        | -0.811      |\n",
      "|    reward             | -0.00278771 |\n",
      "|    std                | 1.74e+04    |\n",
      "|    value_loss         | 0.00171     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 67300      |\n",
      "|    time_elapsed       | 1022       |\n",
      "|    total_timesteps    | 336500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.4      |\n",
      "|    explained_variance | -0.391     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 67299      |\n",
      "|    policy_loss        | -0.354     |\n",
      "|    reward             | 0.00970588 |\n",
      "|    std                | 1.76e+04   |\n",
      "|    value_loss         | 0.000294   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 67400        |\n",
      "|    time_elapsed       | 1024         |\n",
      "|    total_timesteps    | 337000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.4        |\n",
      "|    explained_variance | 0.123        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67399        |\n",
      "|    policy_loss        | 0.0194       |\n",
      "|    reward             | -0.012051915 |\n",
      "|    std                | 1.79e+04     |\n",
      "|    value_loss         | 0.000601     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 67500        |\n",
      "|    time_elapsed       | 1025         |\n",
      "|    total_timesteps    | 337500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.5        |\n",
      "|    explained_variance | -0.308       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67499        |\n",
      "|    policy_loss        | 0.698        |\n",
      "|    reward             | -0.029761817 |\n",
      "|    std                | 1.85e+04     |\n",
      "|    value_loss         | 0.00164      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 67600      |\n",
      "|    time_elapsed       | 1027       |\n",
      "|    total_timesteps    | 338000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.5      |\n",
      "|    explained_variance | 0.114      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 67599      |\n",
      "|    policy_loss        | 0.157      |\n",
      "|    reward             | 0.06451788 |\n",
      "|    std                | 1.88e+04   |\n",
      "|    value_loss         | 0.00451    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2707, episode: 125\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 52311.20\n",
      "total_reward: 42311.20\n",
      "total_cost: 62.38\n",
      "total_trades: 5408\n",
      "Sharpe: 0.682\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 67700       |\n",
      "|    time_elapsed       | 1028        |\n",
      "|    total_timesteps    | 338500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 67699       |\n",
      "|    policy_loss        | -1.06       |\n",
      "|    reward             | 0.047851045 |\n",
      "|    std                | 1.91e+04    |\n",
      "|    value_loss         | 0.004       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 67800       |\n",
      "|    time_elapsed       | 1029        |\n",
      "|    total_timesteps    | 339000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.6       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 67799       |\n",
      "|    policy_loss        | 0.14        |\n",
      "|    reward             | 0.012569536 |\n",
      "|    std                | 1.95e+04    |\n",
      "|    value_loss         | 0.000175    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 67900       |\n",
      "|    time_elapsed       | 1031        |\n",
      "|    total_timesteps    | 339500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.6       |\n",
      "|    explained_variance | 0.217       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 67899       |\n",
      "|    policy_loss        | -0.184      |\n",
      "|    reward             | -0.01394774 |\n",
      "|    std                | 2e+04       |\n",
      "|    value_loss         | 0.000221    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 68000       |\n",
      "|    time_elapsed       | 1032        |\n",
      "|    total_timesteps    | 340000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 67999       |\n",
      "|    policy_loss        | -0.154      |\n",
      "|    reward             | 0.017602932 |\n",
      "|    std                | 2.04e+04    |\n",
      "|    value_loss         | 0.000421    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 68100         |\n",
      "|    time_elapsed       | 1034          |\n",
      "|    total_timesteps    | 340500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.7         |\n",
      "|    explained_variance | 0.269         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 68099         |\n",
      "|    policy_loss        | 0.0518        |\n",
      "|    reward             | -0.0072861435 |\n",
      "|    std                | 2.1e+04       |\n",
      "|    value_loss         | 0.000405      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 68200       |\n",
      "|    time_elapsed       | 1035        |\n",
      "|    total_timesteps    | 341000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.8       |\n",
      "|    explained_variance | 0.484       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68199       |\n",
      "|    policy_loss        | 0.75        |\n",
      "|    reward             | -0.25186062 |\n",
      "|    std                | 2.16e+04    |\n",
      "|    value_loss         | 0.0029      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 68300        |\n",
      "|    time_elapsed       | 1037         |\n",
      "|    total_timesteps    | 341500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 68299        |\n",
      "|    policy_loss        | -0.282       |\n",
      "|    reward             | 0.0025755507 |\n",
      "|    std                | 2.19e+04     |\n",
      "|    value_loss         | 0.000187     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 68400         |\n",
      "|    time_elapsed       | 1038          |\n",
      "|    total_timesteps    | 342000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.9         |\n",
      "|    explained_variance | -0.742        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 68399         |\n",
      "|    policy_loss        | 0.119         |\n",
      "|    reward             | -0.0005883436 |\n",
      "|    std                | 2.26e+04      |\n",
      "|    value_loss         | 0.000113      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 68500        |\n",
      "|    time_elapsed       | 1040         |\n",
      "|    total_timesteps    | 342500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23          |\n",
      "|    explained_variance | 0.367        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 68499        |\n",
      "|    policy_loss        | -0.0621      |\n",
      "|    reward             | 0.0010553222 |\n",
      "|    std                | 2.34e+04     |\n",
      "|    value_loss         | 0.000108     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 68600       |\n",
      "|    time_elapsed       | 1041        |\n",
      "|    total_timesteps    | 343000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23         |\n",
      "|    explained_variance | 0.506       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68599       |\n",
      "|    policy_loss        | -0.133      |\n",
      "|    reward             | 0.017906288 |\n",
      "|    std                | 2.41e+04    |\n",
      "|    value_loss         | 5.25e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 68700         |\n",
      "|    time_elapsed       | 1043          |\n",
      "|    total_timesteps    | 343500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.1         |\n",
      "|    explained_variance | 0.0873        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 68699         |\n",
      "|    policy_loss        | 0.167         |\n",
      "|    reward             | 0.00063476793 |\n",
      "|    std                | 2.45e+04      |\n",
      "|    value_loss         | 0.000239      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 68800       |\n",
      "|    time_elapsed       | 1044        |\n",
      "|    total_timesteps    | 344000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.1       |\n",
      "|    explained_variance | 0.0833      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68799       |\n",
      "|    policy_loss        | 0.357       |\n",
      "|    reward             | 0.010528633 |\n",
      "|    std                | 2.49e+04    |\n",
      "|    value_loss         | 0.000344    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 68900        |\n",
      "|    time_elapsed       | 1046         |\n",
      "|    total_timesteps    | 344500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 68899        |\n",
      "|    policy_loss        | 0.548        |\n",
      "|    reward             | 0.0061794547 |\n",
      "|    std                | 2.54e+04     |\n",
      "|    value_loss         | 0.000576     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 69000        |\n",
      "|    time_elapsed       | 1047         |\n",
      "|    total_timesteps    | 345000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 68999        |\n",
      "|    policy_loss        | -0.0698      |\n",
      "|    reward             | -0.023105266 |\n",
      "|    std                | 2.61e+04     |\n",
      "|    value_loss         | 7.54e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 69100      |\n",
      "|    time_elapsed       | 1049       |\n",
      "|    total_timesteps    | 345500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.2      |\n",
      "|    explained_variance | 0.25       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 69099      |\n",
      "|    policy_loss        | 1.23       |\n",
      "|    reward             | 0.01592876 |\n",
      "|    std                | 2.69e+04   |\n",
      "|    value_loss         | 0.00362    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 69200      |\n",
      "|    time_elapsed       | 1050       |\n",
      "|    total_timesteps    | 346000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.3      |\n",
      "|    explained_variance | 0.284      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 69199      |\n",
      "|    policy_loss        | 0.768      |\n",
      "|    reward             | -0.4089665 |\n",
      "|    std                | 2.77e+04   |\n",
      "|    value_loss         | 0.00188    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 69300       |\n",
      "|    time_elapsed       | 1052        |\n",
      "|    total_timesteps    | 346500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.3       |\n",
      "|    explained_variance | 0.4         |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 69299       |\n",
      "|    policy_loss        | 1.33        |\n",
      "|    reward             | 0.093158394 |\n",
      "|    std                | 2.82e+04    |\n",
      "|    value_loss         | 0.00459     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 69400       |\n",
      "|    time_elapsed       | 1053        |\n",
      "|    total_timesteps    | 347000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.3       |\n",
      "|    explained_variance | 0.00341     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 69399       |\n",
      "|    policy_loss        | -0.379      |\n",
      "|    reward             | 0.027614802 |\n",
      "|    std                | 2.84e+04    |\n",
      "|    value_loss         | 0.00113     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 69500       |\n",
      "|    time_elapsed       | 1055        |\n",
      "|    total_timesteps    | 347500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.4       |\n",
      "|    explained_variance | -0.0434     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 69499       |\n",
      "|    policy_loss        | 0.482       |\n",
      "|    reward             | 0.008735173 |\n",
      "|    std                | 2.88e+04    |\n",
      "|    value_loss         | 0.000463    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 69600       |\n",
      "|    time_elapsed       | 1056        |\n",
      "|    total_timesteps    | 348000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.4       |\n",
      "|    explained_variance | 0.143       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 69599       |\n",
      "|    policy_loss        | 2.08        |\n",
      "|    reward             | -0.07440921 |\n",
      "|    std                | 2.9e+04     |\n",
      "|    value_loss         | 0.0116      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 69700        |\n",
      "|    time_elapsed       | 1058         |\n",
      "|    total_timesteps    | 348500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.4        |\n",
      "|    explained_variance | 0.118        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69699        |\n",
      "|    policy_loss        | 0.212        |\n",
      "|    reward             | -0.035898786 |\n",
      "|    std                | 2.92e+04     |\n",
      "|    value_loss         | 0.00593      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 69800       |\n",
      "|    time_elapsed       | 1059        |\n",
      "|    total_timesteps    | 349000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.4       |\n",
      "|    explained_variance | 0.611       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 69799       |\n",
      "|    policy_loss        | -2.3        |\n",
      "|    reward             | 0.054289564 |\n",
      "|    std                | 2.91e+04    |\n",
      "|    value_loss         | 0.0122      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 69900        |\n",
      "|    time_elapsed       | 1061         |\n",
      "|    total_timesteps    | 349500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69899        |\n",
      "|    policy_loss        | -0.135       |\n",
      "|    reward             | -0.008206784 |\n",
      "|    std                | 2.92e+04     |\n",
      "|    value_loss         | 7.77e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 70000       |\n",
      "|    time_elapsed       | 1063        |\n",
      "|    total_timesteps    | 350000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.4       |\n",
      "|    explained_variance | 0.766       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 69999       |\n",
      "|    policy_loss        | 0.0109      |\n",
      "|    reward             | 0.006380317 |\n",
      "|    std                | 2.96e+04    |\n",
      "|    value_loss         | 5.53e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 70100        |\n",
      "|    time_elapsed       | 1064         |\n",
      "|    total_timesteps    | 350500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.5        |\n",
      "|    explained_variance | -0.143       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70099        |\n",
      "|    policy_loss        | 0.0206       |\n",
      "|    reward             | -0.012072362 |\n",
      "|    std                | 3.03e+04     |\n",
      "|    value_loss         | 5.05e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 70200        |\n",
      "|    time_elapsed       | 1066         |\n",
      "|    total_timesteps    | 351000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.5        |\n",
      "|    explained_variance | 0.000296     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70199        |\n",
      "|    policy_loss        | 0.829        |\n",
      "|    reward             | -0.031161485 |\n",
      "|    std                | 3.12e+04     |\n",
      "|    value_loss         | 0.00135      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 70300       |\n",
      "|    time_elapsed       | 1067        |\n",
      "|    total_timesteps    | 351500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.6       |\n",
      "|    explained_variance | 0.588       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70299       |\n",
      "|    policy_loss        | 1.85        |\n",
      "|    reward             | 0.031189702 |\n",
      "|    std                | 3.21e+04    |\n",
      "|    value_loss         | 0.00694     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 70400       |\n",
      "|    time_elapsed       | 1068        |\n",
      "|    total_timesteps    | 352000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.6       |\n",
      "|    explained_variance | 0.397       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70399       |\n",
      "|    policy_loss        | -3.88       |\n",
      "|    reward             | 0.085994616 |\n",
      "|    std                | 3.23e+04    |\n",
      "|    value_loss         | 0.0287      |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 130\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 40621.10\n",
      "total_reward: 30621.10\n",
      "total_cost: 12.31\n",
      "total_trades: 5414\n",
      "Sharpe: 0.600\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 329            |\n",
      "|    iterations         | 70500          |\n",
      "|    time_elapsed       | 1070           |\n",
      "|    total_timesteps    | 352500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -23.6          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 70499          |\n",
      "|    policy_loss        | 0.429          |\n",
      "|    reward             | -0.00077516004 |\n",
      "|    std                | 3.27e+04       |\n",
      "|    value_loss         | 0.000744       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 70600        |\n",
      "|    time_elapsed       | 1071         |\n",
      "|    total_timesteps    | 353000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70599        |\n",
      "|    policy_loss        | 0.332        |\n",
      "|    reward             | -0.031135635 |\n",
      "|    std                | 3.35e+04     |\n",
      "|    value_loss         | 0.00056      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 70700       |\n",
      "|    time_elapsed       | 1073        |\n",
      "|    total_timesteps    | 353500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.7       |\n",
      "|    explained_variance | 0.157       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70699       |\n",
      "|    policy_loss        | -0.625      |\n",
      "|    reward             | 0.039609093 |\n",
      "|    std                | 3.37e+04    |\n",
      "|    value_loss         | 0.00304     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 70800      |\n",
      "|    time_elapsed       | 1075       |\n",
      "|    total_timesteps    | 354000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.7      |\n",
      "|    explained_variance | 0.403      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 70799      |\n",
      "|    policy_loss        | 1.65       |\n",
      "|    reward             | 0.02152916 |\n",
      "|    std                | 3.46e+04   |\n",
      "|    value_loss         | 0.00701    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 70900        |\n",
      "|    time_elapsed       | 1077         |\n",
      "|    total_timesteps    | 354500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.8        |\n",
      "|    explained_variance | 0.125        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70899        |\n",
      "|    policy_loss        | 0.94         |\n",
      "|    reward             | -0.009438863 |\n",
      "|    std                | 3.49e+04     |\n",
      "|    value_loss         | 0.00275      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 71000         |\n",
      "|    time_elapsed       | 1078          |\n",
      "|    total_timesteps    | 355000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.8         |\n",
      "|    explained_variance | 0.567         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 70999         |\n",
      "|    policy_loss        | -0.0247       |\n",
      "|    reward             | -0.0066775978 |\n",
      "|    std                | 3.49e+04      |\n",
      "|    value_loss         | 2.78e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 71100        |\n",
      "|    time_elapsed       | 1080         |\n",
      "|    total_timesteps    | 355500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.8        |\n",
      "|    explained_variance | 0.17         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 71099        |\n",
      "|    policy_loss        | -0.234       |\n",
      "|    reward             | 0.0027421876 |\n",
      "|    std                | 3.55e+04     |\n",
      "|    value_loss         | 0.000166     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 71200        |\n",
      "|    time_elapsed       | 1082         |\n",
      "|    total_timesteps    | 356000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.9        |\n",
      "|    explained_variance | 3.7e-06      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 71199        |\n",
      "|    policy_loss        | 0.639        |\n",
      "|    reward             | -0.028755488 |\n",
      "|    std                | 3.69e+04     |\n",
      "|    value_loss         | 0.00122      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 71300        |\n",
      "|    time_elapsed       | 1083         |\n",
      "|    total_timesteps    | 356500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 71299        |\n",
      "|    policy_loss        | 1.55         |\n",
      "|    reward             | -0.008638681 |\n",
      "|    std                | 3.76e+04     |\n",
      "|    value_loss         | 0.00432      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 71400       |\n",
      "|    time_elapsed       | 1085        |\n",
      "|    total_timesteps    | 357000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24         |\n",
      "|    explained_variance | 0.54        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 71399       |\n",
      "|    policy_loss        | -1.43       |\n",
      "|    reward             | -0.02647102 |\n",
      "|    std                | 3.88e+04    |\n",
      "|    value_loss         | 0.00425     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 71500        |\n",
      "|    time_elapsed       | 1087         |\n",
      "|    total_timesteps    | 357500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 71499        |\n",
      "|    policy_loss        | -0.876       |\n",
      "|    reward             | -0.031833503 |\n",
      "|    std                | 3.95e+04     |\n",
      "|    value_loss         | 0.00141      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 71600       |\n",
      "|    time_elapsed       | 1088        |\n",
      "|    total_timesteps    | 358000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24         |\n",
      "|    explained_variance | 0.324       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 71599       |\n",
      "|    policy_loss        | 0.113       |\n",
      "|    reward             | 0.016386965 |\n",
      "|    std                | 4.02e+04    |\n",
      "|    value_loss         | 9.41e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 71700        |\n",
      "|    time_elapsed       | 1090         |\n",
      "|    total_timesteps    | 358500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 71699        |\n",
      "|    policy_loss        | -0.313       |\n",
      "|    reward             | 0.0008364727 |\n",
      "|    std                | 4.1e+04      |\n",
      "|    value_loss         | 0.000364     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 71800       |\n",
      "|    time_elapsed       | 1091        |\n",
      "|    total_timesteps    | 359000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.1       |\n",
      "|    explained_variance | -0.0361     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 71799       |\n",
      "|    policy_loss        | 0.592       |\n",
      "|    reward             | 0.008272068 |\n",
      "|    std                | 4.2e+04     |\n",
      "|    value_loss         | 0.000732    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 71900       |\n",
      "|    time_elapsed       | 1093        |\n",
      "|    total_timesteps    | 359500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.2       |\n",
      "|    explained_variance | -0.12       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 71899       |\n",
      "|    policy_loss        | -0.165      |\n",
      "|    reward             | -0.15530652 |\n",
      "|    std                | 4.36e+04    |\n",
      "|    value_loss         | 0.00012     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 328        |\n",
      "|    iterations         | 72000      |\n",
      "|    time_elapsed       | 1094       |\n",
      "|    total_timesteps    | 360000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24.2      |\n",
      "|    explained_variance | 2.38e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 71999      |\n",
      "|    policy_loss        | -0.651     |\n",
      "|    reward             | 0.03758664 |\n",
      "|    std                | 4.45e+04   |\n",
      "|    value_loss         | 0.00122    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 72100        |\n",
      "|    time_elapsed       | 1096         |\n",
      "|    total_timesteps    | 360500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.3        |\n",
      "|    explained_variance | 0.0689       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72099        |\n",
      "|    policy_loss        | -0.184       |\n",
      "|    reward             | -0.027891735 |\n",
      "|    std                | 4.55e+04     |\n",
      "|    value_loss         | 0.000726     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 72200        |\n",
      "|    time_elapsed       | 1097         |\n",
      "|    total_timesteps    | 361000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.3        |\n",
      "|    explained_variance | 0.449        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72199        |\n",
      "|    policy_loss        | -0.17        |\n",
      "|    reward             | -0.008949612 |\n",
      "|    std                | 4.6e+04      |\n",
      "|    value_loss         | 0.000225     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 328        |\n",
      "|    iterations         | 72300      |\n",
      "|    time_elapsed       | 1099       |\n",
      "|    total_timesteps    | 361500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24.3      |\n",
      "|    explained_variance | 0.509      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 72299      |\n",
      "|    policy_loss        | 3.29       |\n",
      "|    reward             | 0.07858766 |\n",
      "|    std                | 4.65e+04   |\n",
      "|    value_loss         | 0.0229     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 72400       |\n",
      "|    time_elapsed       | 1100        |\n",
      "|    total_timesteps    | 362000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.4       |\n",
      "|    explained_variance | 0.423       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 72399       |\n",
      "|    policy_loss        | 2.84        |\n",
      "|    reward             | 0.058988173 |\n",
      "|    std                | 4.72e+04    |\n",
      "|    value_loss         | 0.026       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 328        |\n",
      "|    iterations         | 72500      |\n",
      "|    time_elapsed       | 1102       |\n",
      "|    total_timesteps    | 362500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 72499      |\n",
      "|    policy_loss        | -15.5      |\n",
      "|    reward             | 0.09246553 |\n",
      "|    std                | 4.82e+04   |\n",
      "|    value_loss         | 0.445      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 72600        |\n",
      "|    time_elapsed       | 1103         |\n",
      "|    total_timesteps    | 363000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.4        |\n",
      "|    explained_variance | -25.8        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72599        |\n",
      "|    policy_loss        | -0.699       |\n",
      "|    reward             | -0.012154072 |\n",
      "|    std                | 4.81e+04     |\n",
      "|    value_loss         | 0.00215      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 72700        |\n",
      "|    time_elapsed       | 1104         |\n",
      "|    total_timesteps    | 363500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.4        |\n",
      "|    explained_variance | -2.83        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72699        |\n",
      "|    policy_loss        | -0.0702      |\n",
      "|    reward             | 0.0062071476 |\n",
      "|    std                | 4.87e+04     |\n",
      "|    value_loss         | 0.000138     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 72800       |\n",
      "|    time_elapsed       | 1106        |\n",
      "|    total_timesteps    | 364000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.5       |\n",
      "|    explained_variance | -1.79e-06   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 72799       |\n",
      "|    policy_loss        | -0.116      |\n",
      "|    reward             | 0.028788533 |\n",
      "|    std                | 4.96e+04    |\n",
      "|    value_loss         | 0.000291    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 72900        |\n",
      "|    time_elapsed       | 1107         |\n",
      "|    total_timesteps    | 364500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.5        |\n",
      "|    explained_variance | 0.517        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72899        |\n",
      "|    policy_loss        | -0.789       |\n",
      "|    reward             | -0.006337671 |\n",
      "|    std                | 5.08e+04     |\n",
      "|    value_loss         | 0.00419      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 73000       |\n",
      "|    time_elapsed       | 1109        |\n",
      "|    total_timesteps    | 365000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.5       |\n",
      "|    explained_variance | -5.96e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 72999       |\n",
      "|    policy_loss        | -1.14       |\n",
      "|    reward             | 0.104537174 |\n",
      "|    std                | 5.16e+04    |\n",
      "|    value_loss         | 0.00329     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 73100      |\n",
      "|    time_elapsed       | 1110       |\n",
      "|    total_timesteps    | 365500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24.6      |\n",
      "|    explained_variance | 0.706      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 73099      |\n",
      "|    policy_loss        | 6.61       |\n",
      "|    reward             | 0.19679552 |\n",
      "|    std                | 5.28e+04   |\n",
      "|    value_loss         | 0.0766     |\n",
      "--------------------------------------\n",
      "day: 2707, episode: 135\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 91173.31\n",
      "total_reward: 81173.31\n",
      "total_cost: 10.96\n",
      "total_trades: 5413\n",
      "Sharpe: 0.778\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 73200         |\n",
      "|    time_elapsed       | 1112          |\n",
      "|    total_timesteps    | 366000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.6         |\n",
      "|    explained_variance | 0.904         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 73199         |\n",
      "|    policy_loss        | -0.419        |\n",
      "|    reward             | 0.00067642384 |\n",
      "|    std                | 5.32e+04      |\n",
      "|    value_loss         | 0.000319      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 73300         |\n",
      "|    time_elapsed       | 1113          |\n",
      "|    total_timesteps    | 366500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.6         |\n",
      "|    explained_variance | -0.0981       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 73299         |\n",
      "|    policy_loss        | 0.524         |\n",
      "|    reward             | -0.0059069647 |\n",
      "|    std                | 5.41e+04      |\n",
      "|    value_loss         | 0.000976      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 73400       |\n",
      "|    time_elapsed       | 1115        |\n",
      "|    total_timesteps    | 367000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.7       |\n",
      "|    explained_variance | 0.137       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73399       |\n",
      "|    policy_loss        | -0.66       |\n",
      "|    reward             | -0.02175941 |\n",
      "|    std                | 5.53e+04    |\n",
      "|    value_loss         | 0.00168     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 73500        |\n",
      "|    time_elapsed       | 1116         |\n",
      "|    total_timesteps    | 367500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.7        |\n",
      "|    explained_variance | 0.0357       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 73499        |\n",
      "|    policy_loss        | 0.961        |\n",
      "|    reward             | -0.010098859 |\n",
      "|    std                | 5.61e+04     |\n",
      "|    value_loss         | 0.00593      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 73600         |\n",
      "|    time_elapsed       | 1118          |\n",
      "|    total_timesteps    | 368000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.7         |\n",
      "|    explained_variance | 0.0515        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 73599         |\n",
      "|    policy_loss        | 3.08          |\n",
      "|    reward             | -0.0026528565 |\n",
      "|    std                | 5.67e+04      |\n",
      "|    value_loss         | 0.0148        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 73700       |\n",
      "|    time_elapsed       | 1119        |\n",
      "|    total_timesteps    | 368500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.8       |\n",
      "|    explained_variance | 0.19        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73699       |\n",
      "|    policy_loss        | -0.158      |\n",
      "|    reward             | -0.02188911 |\n",
      "|    std                | 5.76e+04    |\n",
      "|    value_loss         | 6.93e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 73800         |\n",
      "|    time_elapsed       | 1121          |\n",
      "|    total_timesteps    | 369000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 73799         |\n",
      "|    policy_loss        | 0.347         |\n",
      "|    reward             | -0.0023977198 |\n",
      "|    std                | 5.87e+04      |\n",
      "|    value_loss         | 0.000443      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 73900       |\n",
      "|    time_elapsed       | 1122        |\n",
      "|    total_timesteps    | 369500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.8       |\n",
      "|    explained_variance | 0.201       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73899       |\n",
      "|    policy_loss        | -0.994      |\n",
      "|    reward             | 0.010030938 |\n",
      "|    std                | 6e+04       |\n",
      "|    value_loss         | 0.00306     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 74000        |\n",
      "|    time_elapsed       | 1123         |\n",
      "|    total_timesteps    | 370000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.9        |\n",
      "|    explained_variance | 0.221        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 73999        |\n",
      "|    policy_loss        | 1.59         |\n",
      "|    reward             | -0.017655311 |\n",
      "|    std                | 6.08e+04     |\n",
      "|    value_loss         | 0.00485      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 74100       |\n",
      "|    time_elapsed       | 1125        |\n",
      "|    total_timesteps    | 370500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.9       |\n",
      "|    explained_variance | 0.433       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 74099       |\n",
      "|    policy_loss        | 0.323       |\n",
      "|    reward             | 0.077776164 |\n",
      "|    std                | 6.21e+04    |\n",
      "|    value_loss         | 0.00956     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 74200        |\n",
      "|    time_elapsed       | 1126         |\n",
      "|    total_timesteps    | 371000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 74199        |\n",
      "|    policy_loss        | 1.74         |\n",
      "|    reward             | -0.008024859 |\n",
      "|    std                | 6.17e+04     |\n",
      "|    value_loss         | 0.00557      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 74300       |\n",
      "|    time_elapsed       | 1128        |\n",
      "|    total_timesteps    | 371500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 74299       |\n",
      "|    policy_loss        | -0.163      |\n",
      "|    reward             | 0.012775787 |\n",
      "|    std                | 6.28e+04    |\n",
      "|    value_loss         | 7.3e-05     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 74400      |\n",
      "|    time_elapsed       | 1129       |\n",
      "|    total_timesteps    | 372000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25        |\n",
      "|    explained_variance | 0.203      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 74399      |\n",
      "|    policy_loss        | -0.351     |\n",
      "|    reward             | 0.02680299 |\n",
      "|    std                | 6.42e+04   |\n",
      "|    value_loss         | 0.000401   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 74500        |\n",
      "|    time_elapsed       | 1130         |\n",
      "|    total_timesteps    | 372500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25          |\n",
      "|    explained_variance | 3.4e-06      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 74499        |\n",
      "|    policy_loss        | 1.17         |\n",
      "|    reward             | -0.038919605 |\n",
      "|    std                | 6.53e+04     |\n",
      "|    value_loss         | 0.00512      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 74600       |\n",
      "|    time_elapsed       | 1132        |\n",
      "|    total_timesteps    | 373000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25         |\n",
      "|    explained_variance | 0.217       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 74599       |\n",
      "|    policy_loss        | 6.17        |\n",
      "|    reward             | -0.21502806 |\n",
      "|    std                | 6.6e+04     |\n",
      "|    value_loss         | 0.066       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 329       |\n",
      "|    iterations         | 74700     |\n",
      "|    time_elapsed       | 1133      |\n",
      "|    total_timesteps    | 373500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -25       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 74699     |\n",
      "|    policy_loss        | -5.97     |\n",
      "|    reward             | 0.3919128 |\n",
      "|    std                | 6.56e+04  |\n",
      "|    value_loss         | 0.0786    |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 329            |\n",
      "|    iterations         | 74800          |\n",
      "|    time_elapsed       | 1135           |\n",
      "|    total_timesteps    | 374000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -25            |\n",
      "|    explained_variance | 0.826          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 74799          |\n",
      "|    policy_loss        | -0.269         |\n",
      "|    reward             | -0.00085876696 |\n",
      "|    std                | 6.62e+04       |\n",
      "|    value_loss         | 0.000165       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 74900        |\n",
      "|    time_elapsed       | 1136         |\n",
      "|    total_timesteps    | 374500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.1        |\n",
      "|    explained_variance | 0.214        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 74899        |\n",
      "|    policy_loss        | -0.121       |\n",
      "|    reward             | -0.003663204 |\n",
      "|    std                | 6.76e+04     |\n",
      "|    value_loss         | 4.3e-05      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 75000      |\n",
      "|    time_elapsed       | 1138       |\n",
      "|    total_timesteps    | 375000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.1      |\n",
      "|    explained_variance | 0.227      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 74999      |\n",
      "|    policy_loss        | 0.609      |\n",
      "|    reward             | 0.08622429 |\n",
      "|    std                | 6.89e+04   |\n",
      "|    value_loss         | 0.00096    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 75100       |\n",
      "|    time_elapsed       | 1139        |\n",
      "|    total_timesteps    | 375500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.2       |\n",
      "|    explained_variance | -0.00122    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75099       |\n",
      "|    policy_loss        | 1.25        |\n",
      "|    reward             | -0.02759772 |\n",
      "|    std                | 7.12e+04    |\n",
      "|    value_loss         | 0.00279     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 75200        |\n",
      "|    time_elapsed       | 1141         |\n",
      "|    total_timesteps    | 376000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.2        |\n",
      "|    explained_variance | 0.844        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 75199        |\n",
      "|    policy_loss        | -1           |\n",
      "|    reward             | -0.050994083 |\n",
      "|    std                | 7.31e+04     |\n",
      "|    value_loss         | 0.00213      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 75300        |\n",
      "|    time_elapsed       | 1142         |\n",
      "|    total_timesteps    | 376500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.2        |\n",
      "|    explained_variance | 0.328        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 75299        |\n",
      "|    policy_loss        | -0.598       |\n",
      "|    reward             | 0.0022221005 |\n",
      "|    std                | 7.35e+04     |\n",
      "|    value_loss         | 0.000658     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 75400       |\n",
      "|    time_elapsed       | 1144        |\n",
      "|    total_timesteps    | 377000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.3       |\n",
      "|    explained_variance | 0.503       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75399       |\n",
      "|    policy_loss        | -0.376      |\n",
      "|    reward             | 0.001656149 |\n",
      "|    std                | 7.48e+04    |\n",
      "|    value_loss         | 0.000237    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 75500         |\n",
      "|    time_elapsed       | 1145          |\n",
      "|    total_timesteps    | 377500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.3         |\n",
      "|    explained_variance | 0.551         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 75499         |\n",
      "|    policy_loss        | 0.0657        |\n",
      "|    reward             | -0.0027970986 |\n",
      "|    std                | 7.67e+04      |\n",
      "|    value_loss         | 2.55e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 75600         |\n",
      "|    time_elapsed       | 1147          |\n",
      "|    total_timesteps    | 378000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.4         |\n",
      "|    explained_variance | 0.277         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 75599         |\n",
      "|    policy_loss        | -0.0999       |\n",
      "|    reward             | -0.0017335117 |\n",
      "|    std                | 8.02e+04      |\n",
      "|    value_loss         | 3.39e-05      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 329            |\n",
      "|    iterations         | 75700          |\n",
      "|    time_elapsed       | 1148           |\n",
      "|    total_timesteps    | 378500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -25.5          |\n",
      "|    explained_variance | 0.428          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 75699          |\n",
      "|    policy_loss        | 0.254          |\n",
      "|    reward             | -0.00024434662 |\n",
      "|    std                | 8.37e+04       |\n",
      "|    value_loss         | 0.000238       |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 75800      |\n",
      "|    time_elapsed       | 1150       |\n",
      "|    total_timesteps    | 379000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.6      |\n",
      "|    explained_variance | -0.264     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 75799      |\n",
      "|    policy_loss        | 0.0632     |\n",
      "|    reward             | 0.02224184 |\n",
      "|    std                | 8.77e+04   |\n",
      "|    value_loss         | 8.79e-05   |\n",
      "--------------------------------------\n",
      "day: 2707, episode: 140\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 19714.69\n",
      "total_reward: 9714.69\n",
      "total_cost: 18.00\n",
      "total_trades: 5409\n",
      "Sharpe: 0.415\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 75900        |\n",
      "|    time_elapsed       | 1151         |\n",
      "|    total_timesteps    | 379500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.6        |\n",
      "|    explained_variance | 0.104        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 75899        |\n",
      "|    policy_loss        | -0.592       |\n",
      "|    reward             | -0.029528756 |\n",
      "|    std                | 8.96e+04     |\n",
      "|    value_loss         | 0.0013       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 76000        |\n",
      "|    time_elapsed       | 1153         |\n",
      "|    total_timesteps    | 380000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.7        |\n",
      "|    explained_variance | 0.077        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 75999        |\n",
      "|    policy_loss        | 0.766        |\n",
      "|    reward             | 0.0011561885 |\n",
      "|    std                | 9.14e+04     |\n",
      "|    value_loss         | 0.00133      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 76100        |\n",
      "|    time_elapsed       | 1154         |\n",
      "|    total_timesteps    | 380500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.7        |\n",
      "|    explained_variance | 0.0752       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76099        |\n",
      "|    policy_loss        | -0.0369      |\n",
      "|    reward             | -0.025265815 |\n",
      "|    std                | 9.35e+04     |\n",
      "|    value_loss         | 0.000631     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 76200        |\n",
      "|    time_elapsed       | 1155         |\n",
      "|    total_timesteps    | 381000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76199        |\n",
      "|    policy_loss        | -0.157       |\n",
      "|    reward             | 0.0004837929 |\n",
      "|    std                | 9.57e+04     |\n",
      "|    value_loss         | 0.00088      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 76300        |\n",
      "|    time_elapsed       | 1157         |\n",
      "|    total_timesteps    | 381500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.8        |\n",
      "|    explained_variance | 0.0817       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76299        |\n",
      "|    policy_loss        | 2.8          |\n",
      "|    reward             | -0.036125883 |\n",
      "|    std                | 9.77e+04     |\n",
      "|    value_loss         | 0.0238       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 76400       |\n",
      "|    time_elapsed       | 1158        |\n",
      "|    total_timesteps    | 382000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.8       |\n",
      "|    explained_variance | 0.176       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 76399       |\n",
      "|    policy_loss        | 0.173       |\n",
      "|    reward             | 0.007777427 |\n",
      "|    std                | 9.86e+04    |\n",
      "|    value_loss         | 0.000176    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 76500         |\n",
      "|    time_elapsed       | 1160          |\n",
      "|    total_timesteps    | 382500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.9         |\n",
      "|    explained_variance | 0.367         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 76499         |\n",
      "|    policy_loss        | 0.826         |\n",
      "|    reward             | -0.0003599472 |\n",
      "|    std                | 1e+05         |\n",
      "|    value_loss         | 0.00121       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 76600        |\n",
      "|    time_elapsed       | 1161         |\n",
      "|    total_timesteps    | 383000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.9        |\n",
      "|    explained_variance | 0.000685     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76599        |\n",
      "|    policy_loss        | 2.86         |\n",
      "|    reward             | 0.0050879824 |\n",
      "|    std                | 1.03e+05     |\n",
      "|    value_loss         | 0.0131       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 76700      |\n",
      "|    time_elapsed       | 1162       |\n",
      "|    total_timesteps    | 383500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.9      |\n",
      "|    explained_variance | 0.164      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 76699      |\n",
      "|    policy_loss        | -5.13      |\n",
      "|    reward             | 0.03260162 |\n",
      "|    std                | 1.05e+05   |\n",
      "|    value_loss         | 0.0527     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 76800       |\n",
      "|    time_elapsed       | 1164        |\n",
      "|    total_timesteps    | 384000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 76799       |\n",
      "|    policy_loss        | 10.3        |\n",
      "|    reward             | 0.045333922 |\n",
      "|    std                | 1.06e+05    |\n",
      "|    value_loss         | 0.169       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 76900      |\n",
      "|    time_elapsed       | 1165       |\n",
      "|    total_timesteps    | 384500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26        |\n",
      "|    explained_variance | 0.185      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 76899      |\n",
      "|    policy_loss        | 0.369      |\n",
      "|    reward             | -0.5633687 |\n",
      "|    std                | 1.06e+05   |\n",
      "|    value_loss         | 0.0376     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 77000      |\n",
      "|    time_elapsed       | 1167       |\n",
      "|    total_timesteps    | 385000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26        |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 76999      |\n",
      "|    policy_loss        | 0.266      |\n",
      "|    reward             | 0.00523176 |\n",
      "|    std                | 1.06e+05   |\n",
      "|    value_loss         | 0.000333   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 77100      |\n",
      "|    time_elapsed       | 1168       |\n",
      "|    total_timesteps    | 385500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26        |\n",
      "|    explained_variance | -0.017     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 77099      |\n",
      "|    policy_loss        | -1.13      |\n",
      "|    reward             | 0.05259934 |\n",
      "|    std                | 1.07e+05   |\n",
      "|    value_loss         | 0.00215    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 77200         |\n",
      "|    time_elapsed       | 1170          |\n",
      "|    total_timesteps    | 386000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26           |\n",
      "|    explained_variance | 0.029         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 77199         |\n",
      "|    policy_loss        | -5.37         |\n",
      "|    reward             | -0.0048644533 |\n",
      "|    std                | 1.1e+05       |\n",
      "|    value_loss         | 0.0572        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 77300       |\n",
      "|    time_elapsed       | 1171        |\n",
      "|    total_timesteps    | 386500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.1       |\n",
      "|    explained_variance | -0.0103     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 77299       |\n",
      "|    policy_loss        | -4.88       |\n",
      "|    reward             | -0.09299415 |\n",
      "|    std                | 1.11e+05    |\n",
      "|    value_loss         | 0.0474      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 77400       |\n",
      "|    time_elapsed       | 1173        |\n",
      "|    total_timesteps    | 387000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.1       |\n",
      "|    explained_variance | 0.54        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 77399       |\n",
      "|    policy_loss        | -4.08       |\n",
      "|    reward             | -0.16342214 |\n",
      "|    std                | 1.13e+05    |\n",
      "|    value_loss         | 0.0342      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 77500       |\n",
      "|    time_elapsed       | 1174        |\n",
      "|    total_timesteps    | 387500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.1       |\n",
      "|    explained_variance | 0.228       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 77499       |\n",
      "|    policy_loss        | 1.08        |\n",
      "|    reward             | 0.027100539 |\n",
      "|    std                | 1.14e+05    |\n",
      "|    value_loss         | 0.00183     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 77600       |\n",
      "|    time_elapsed       | 1176        |\n",
      "|    total_timesteps    | 388000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.1       |\n",
      "|    explained_variance | 0.00179     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 77599       |\n",
      "|    policy_loss        | -0.0575     |\n",
      "|    reward             | 0.009402108 |\n",
      "|    std                | 1.16e+05    |\n",
      "|    value_loss         | 2.06e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 77700      |\n",
      "|    time_elapsed       | 1177       |\n",
      "|    total_timesteps    | 388500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.2      |\n",
      "|    explained_variance | 0.0136     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 77699      |\n",
      "|    policy_loss        | 1.93       |\n",
      "|    reward             | 0.06387275 |\n",
      "|    std                | 1.18e+05   |\n",
      "|    value_loss         | 0.00686    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 77800        |\n",
      "|    time_elapsed       | 1179         |\n",
      "|    total_timesteps    | 389000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.2        |\n",
      "|    explained_variance | 0.0495       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77799        |\n",
      "|    policy_loss        | -1.73        |\n",
      "|    reward             | -0.015089602 |\n",
      "|    std                | 1.19e+05     |\n",
      "|    value_loss         | 0.00611      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 77900       |\n",
      "|    time_elapsed       | 1180        |\n",
      "|    total_timesteps    | 389500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.2       |\n",
      "|    explained_variance | 0.687       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 77899       |\n",
      "|    policy_loss        | 0.512       |\n",
      "|    reward             | -0.16532533 |\n",
      "|    std                | 1.2e+05     |\n",
      "|    value_loss         | 0.00236     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 329        |\n",
      "|    iterations         | 78000      |\n",
      "|    time_elapsed       | 1182       |\n",
      "|    total_timesteps    | 390000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.2      |\n",
      "|    explained_variance | -2.98e-06  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 77999      |\n",
      "|    policy_loss        | -0.413     |\n",
      "|    reward             | 0.01758784 |\n",
      "|    std                | 1.21e+05   |\n",
      "|    value_loss         | 0.000469   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 78100        |\n",
      "|    time_elapsed       | 1183         |\n",
      "|    total_timesteps    | 390500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.3        |\n",
      "|    explained_variance | 0.324        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 78099        |\n",
      "|    policy_loss        | 0.385        |\n",
      "|    reward             | -0.008365846 |\n",
      "|    std                | 1.23e+05     |\n",
      "|    value_loss         | 0.000416     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 78200       |\n",
      "|    time_elapsed       | 1185        |\n",
      "|    total_timesteps    | 391000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.3       |\n",
      "|    explained_variance | 0.222       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78199       |\n",
      "|    policy_loss        | 0.784       |\n",
      "|    reward             | 0.006826421 |\n",
      "|    std                | 1.25e+05    |\n",
      "|    value_loss         | 0.000922    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 78300       |\n",
      "|    time_elapsed       | 1186        |\n",
      "|    total_timesteps    | 391500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.3       |\n",
      "|    explained_variance | -0.000343   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78299       |\n",
      "|    policy_loss        | 0.916       |\n",
      "|    reward             | 0.024581026 |\n",
      "|    std                | 1.28e+05    |\n",
      "|    value_loss         | 0.00134     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 78400       |\n",
      "|    time_elapsed       | 1187        |\n",
      "|    total_timesteps    | 392000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.4       |\n",
      "|    explained_variance | 0.000815    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78399       |\n",
      "|    policy_loss        | 1.14        |\n",
      "|    reward             | 0.049575824 |\n",
      "|    std                | 1.31e+05    |\n",
      "|    value_loss         | 0.00327     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 78500       |\n",
      "|    time_elapsed       | 1189        |\n",
      "|    total_timesteps    | 392500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.4       |\n",
      "|    explained_variance | 0.00224     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78499       |\n",
      "|    policy_loss        | 4.19        |\n",
      "|    reward             | -0.05707665 |\n",
      "|    std                | 1.32e+05    |\n",
      "|    value_loss         | 0.0271      |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 145\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 64577.27\n",
      "total_reward: 54577.27\n",
      "total_cost: 17.74\n",
      "total_trades: 5409\n",
      "Sharpe: 0.721\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 78600        |\n",
      "|    time_elapsed       | 1190         |\n",
      "|    total_timesteps    | 393000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.4        |\n",
      "|    explained_variance | 0.0215       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 78599        |\n",
      "|    policy_loss        | -1.99        |\n",
      "|    reward             | -0.025204614 |\n",
      "|    std                | 1.35e+05     |\n",
      "|    value_loss         | 0.0091       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 78700       |\n",
      "|    time_elapsed       | 1192        |\n",
      "|    total_timesteps    | 393500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.5       |\n",
      "|    explained_variance | 0.236       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78699       |\n",
      "|    policy_loss        | -0.803      |\n",
      "|    reward             | 0.008541946 |\n",
      "|    std                | 1.38e+05    |\n",
      "|    value_loss         | 0.000982    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 78800         |\n",
      "|    time_elapsed       | 1193          |\n",
      "|    total_timesteps    | 394000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.5         |\n",
      "|    explained_variance | -1.19e-06     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 78799         |\n",
      "|    policy_loss        | -1.26         |\n",
      "|    reward             | 0.00044831695 |\n",
      "|    std                | 1.41e+05      |\n",
      "|    value_loss         | 0.00242       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 78900       |\n",
      "|    time_elapsed       | 1195        |\n",
      "|    total_timesteps    | 394500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.6       |\n",
      "|    explained_variance | 0.571       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78899       |\n",
      "|    policy_loss        | 1.04        |\n",
      "|    reward             | 0.003109445 |\n",
      "|    std                | 1.43e+05    |\n",
      "|    value_loss         | 0.00291     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 79000        |\n",
      "|    time_elapsed       | 1196         |\n",
      "|    total_timesteps    | 395000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.6        |\n",
      "|    explained_variance | 0.37         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 78999        |\n",
      "|    policy_loss        | 1.13         |\n",
      "|    reward             | -0.043337483 |\n",
      "|    std                | 1.44e+05     |\n",
      "|    value_loss         | 0.00668      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 79100         |\n",
      "|    time_elapsed       | 1198          |\n",
      "|    total_timesteps    | 395500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.6         |\n",
      "|    explained_variance | 0.146         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 79099         |\n",
      "|    policy_loss        | 0.132         |\n",
      "|    reward             | -0.0039235544 |\n",
      "|    std                | 1.45e+05      |\n",
      "|    value_loss         | 3.12e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 79200         |\n",
      "|    time_elapsed       | 1199          |\n",
      "|    total_timesteps    | 396000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.6         |\n",
      "|    explained_variance | -0.0992       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 79199         |\n",
      "|    policy_loss        | 0.811         |\n",
      "|    reward             | -0.0037518924 |\n",
      "|    std                | 1.47e+05      |\n",
      "|    value_loss         | 0.00105       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 79300         |\n",
      "|    time_elapsed       | 1201          |\n",
      "|    total_timesteps    | 396500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.7         |\n",
      "|    explained_variance | 0.28          |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 79299         |\n",
      "|    policy_loss        | -0.771        |\n",
      "|    reward             | -0.0032281124 |\n",
      "|    std                | 1.51e+05      |\n",
      "|    value_loss         | 0.00102       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 79400        |\n",
      "|    time_elapsed       | 1202         |\n",
      "|    total_timesteps    | 397000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.8        |\n",
      "|    explained_variance | 0.224        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 79399        |\n",
      "|    policy_loss        | 1.25         |\n",
      "|    reward             | -0.034035843 |\n",
      "|    std                | 1.57e+05     |\n",
      "|    value_loss         | 0.00514      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 79500       |\n",
      "|    time_elapsed       | 1203        |\n",
      "|    total_timesteps    | 397500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.8       |\n",
      "|    explained_variance | 0.0439      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79499       |\n",
      "|    policy_loss        | 0.62        |\n",
      "|    reward             | 0.041815735 |\n",
      "|    std                | 1.59e+05    |\n",
      "|    value_loss         | 0.0196      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 79600      |\n",
      "|    time_elapsed       | 1205       |\n",
      "|    total_timesteps    | 398000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.8      |\n",
      "|    explained_variance | 0.0401     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 79599      |\n",
      "|    policy_loss        | -5.57      |\n",
      "|    reward             | 0.09507517 |\n",
      "|    std                | 1.6e+05    |\n",
      "|    value_loss         | 0.076      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 79700        |\n",
      "|    time_elapsed       | 1206         |\n",
      "|    total_timesteps    | 398500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 79699        |\n",
      "|    policy_loss        | -0.194       |\n",
      "|    reward             | 0.0031799315 |\n",
      "|    std                | 1.62e+05     |\n",
      "|    value_loss         | 0.000454     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 79800         |\n",
      "|    time_elapsed       | 1208          |\n",
      "|    total_timesteps    | 399000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.9         |\n",
      "|    explained_variance | 0.269         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 79799         |\n",
      "|    policy_loss        | -0.286        |\n",
      "|    reward             | -0.0029966144 |\n",
      "|    std                | 1.65e+05      |\n",
      "|    value_loss         | 0.000255      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 79900        |\n",
      "|    time_elapsed       | 1209         |\n",
      "|    total_timesteps    | 399500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.9        |\n",
      "|    explained_variance | 0.0773       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 79899        |\n",
      "|    policy_loss        | 2.04         |\n",
      "|    reward             | 0.0132413795 |\n",
      "|    std                | 1.67e+05     |\n",
      "|    value_loss         | 0.00592      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 80000       |\n",
      "|    time_elapsed       | 1211        |\n",
      "|    total_timesteps    | 400000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27         |\n",
      "|    explained_variance | 0.0367      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79999       |\n",
      "|    policy_loss        | -1.44       |\n",
      "|    reward             | 0.045068145 |\n",
      "|    std                | 1.73e+05    |\n",
      "|    value_loss         | 0.0053      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 80100      |\n",
      "|    time_elapsed       | 1212       |\n",
      "|    total_timesteps    | 400500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27        |\n",
      "|    explained_variance | -1.41e-05  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 80099      |\n",
      "|    policy_loss        | 0.911      |\n",
      "|    reward             | 0.06121004 |\n",
      "|    std                | 1.75e+05   |\n",
      "|    value_loss         | 0.00229    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 80200       |\n",
      "|    time_elapsed       | 1214        |\n",
      "|    total_timesteps    | 401000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27         |\n",
      "|    explained_variance | 0.339       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80199       |\n",
      "|    policy_loss        | -0.18       |\n",
      "|    reward             | 0.022978647 |\n",
      "|    std                | 1.78e+05    |\n",
      "|    value_loss         | 0.000116    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 80300        |\n",
      "|    time_elapsed       | 1216         |\n",
      "|    total_timesteps    | 401500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 80299        |\n",
      "|    policy_loss        | 0.0918       |\n",
      "|    reward             | 0.0068997485 |\n",
      "|    std                | 1.81e+05     |\n",
      "|    value_loss         | 3.46e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 80400       |\n",
      "|    time_elapsed       | 1217        |\n",
      "|    total_timesteps    | 402000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.1       |\n",
      "|    explained_variance | 0.326       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80399       |\n",
      "|    policy_loss        | 1.18        |\n",
      "|    reward             | -0.08498827 |\n",
      "|    std                | 1.85e+05    |\n",
      "|    value_loss         | 0.00247     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 80500      |\n",
      "|    time_elapsed       | 1219       |\n",
      "|    total_timesteps    | 402500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27.1      |\n",
      "|    explained_variance | -0.17      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 80499      |\n",
      "|    policy_loss        | 2.72       |\n",
      "|    reward             | 0.11376412 |\n",
      "|    std                | 1.89e+05   |\n",
      "|    value_loss         | 0.0101     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 80600       |\n",
      "|    time_elapsed       | 1220        |\n",
      "|    total_timesteps    | 403000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80599       |\n",
      "|    policy_loss        | 4.22        |\n",
      "|    reward             | -0.06501815 |\n",
      "|    std                | 1.92e+05    |\n",
      "|    value_loss         | 0.0461      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 80700       |\n",
      "|    time_elapsed       | 1222        |\n",
      "|    total_timesteps    | 403500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.2       |\n",
      "|    explained_variance | -1.2        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80699       |\n",
      "|    policy_loss        | -15.2       |\n",
      "|    reward             | 0.029658038 |\n",
      "|    std                | 1.95e+05    |\n",
      "|    value_loss         | 0.61        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 80800       |\n",
      "|    time_elapsed       | 1223        |\n",
      "|    total_timesteps    | 404000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.2       |\n",
      "|    explained_variance | 0.224       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80799       |\n",
      "|    policy_loss        | -0.15       |\n",
      "|    reward             | 0.006048232 |\n",
      "|    std                | 1.97e+05    |\n",
      "|    value_loss         | 0.000135    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 80900       |\n",
      "|    time_elapsed       | 1225        |\n",
      "|    total_timesteps    | 404500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80899       |\n",
      "|    policy_loss        | -1.1        |\n",
      "|    reward             | -0.02186006 |\n",
      "|    std                | 2e+05       |\n",
      "|    value_loss         | 0.00279     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 81000      |\n",
      "|    time_elapsed       | 1226       |\n",
      "|    total_timesteps    | 405000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27.3      |\n",
      "|    explained_variance | -0.112     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 80999      |\n",
      "|    policy_loss        | 3.12       |\n",
      "|    reward             | 0.08848883 |\n",
      "|    std                | 2.02e+05   |\n",
      "|    value_loss         | 0.0173     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 81100       |\n",
      "|    time_elapsed       | 1227        |\n",
      "|    total_timesteps    | 405500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.3       |\n",
      "|    explained_variance | 0.14        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 81099       |\n",
      "|    policy_loss        | -6.11       |\n",
      "|    reward             | -0.03634133 |\n",
      "|    std                | 2.04e+05    |\n",
      "|    value_loss         | 0.0665      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 330       |\n",
      "|    iterations         | 81200     |\n",
      "|    time_elapsed       | 1229      |\n",
      "|    total_timesteps    | 406000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.3     |\n",
      "|    explained_variance | 0.0413    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 81199     |\n",
      "|    policy_loss        | -39.9     |\n",
      "|    reward             | 0.9417075 |\n",
      "|    std                | 2.03e+05  |\n",
      "|    value_loss         | 2.29      |\n",
      "-------------------------------------\n",
      "day: 2707, episode: 150\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 162567.33\n",
      "total_reward: 152567.33\n",
      "total_cost: 16.60\n",
      "total_trades: 5400\n",
      "Sharpe: 0.881\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 81300       |\n",
      "|    time_elapsed       | 1230        |\n",
      "|    total_timesteps    | 406500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.3       |\n",
      "|    explained_variance | 0.314       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 81299       |\n",
      "|    policy_loss        | -0.0107     |\n",
      "|    reward             | 0.009059562 |\n",
      "|    std                | 2.03e+05    |\n",
      "|    value_loss         | 2.87e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 81400        |\n",
      "|    time_elapsed       | 1232         |\n",
      "|    total_timesteps    | 407000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.3        |\n",
      "|    explained_variance | -0.0122      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 81399        |\n",
      "|    policy_loss        | 0.0677       |\n",
      "|    reward             | 0.0042433706 |\n",
      "|    std                | 2.05e+05     |\n",
      "|    value_loss         | 1.48e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 81500        |\n",
      "|    time_elapsed       | 1233         |\n",
      "|    total_timesteps    | 407500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 81499        |\n",
      "|    policy_loss        | -0.208       |\n",
      "|    reward             | 0.0012893142 |\n",
      "|    std                | 2.11e+05     |\n",
      "|    value_loss         | 6.54e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 81600        |\n",
      "|    time_elapsed       | 1235         |\n",
      "|    total_timesteps    | 408000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 81599        |\n",
      "|    policy_loss        | -0.26        |\n",
      "|    reward             | 0.0015420272 |\n",
      "|    std                | 2.16e+05     |\n",
      "|    value_loss         | 0.000144     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 81700       |\n",
      "|    time_elapsed       | 1236        |\n",
      "|    total_timesteps    | 408500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.4       |\n",
      "|    explained_variance | 0.623       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 81699       |\n",
      "|    policy_loss        | -3.45       |\n",
      "|    reward             | -0.00791554 |\n",
      "|    std                | 2.23e+05    |\n",
      "|    value_loss         | 0.0166      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 81800        |\n",
      "|    time_elapsed       | 1238         |\n",
      "|    total_timesteps    | 409000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.5        |\n",
      "|    explained_variance | 0.432        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 81799        |\n",
      "|    policy_loss        | 0.35         |\n",
      "|    reward             | -0.001811479 |\n",
      "|    std                | 2.32e+05     |\n",
      "|    value_loss         | 0.000164     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 81900         |\n",
      "|    time_elapsed       | 1239          |\n",
      "|    total_timesteps    | 409500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.6         |\n",
      "|    explained_variance | -0.0439       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 81899         |\n",
      "|    policy_loss        | 0.763         |\n",
      "|    reward             | 0.00017836648 |\n",
      "|    std                | 2.41e+05      |\n",
      "|    value_loss         | 0.00107       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 82000       |\n",
      "|    time_elapsed       | 1241        |\n",
      "|    total_timesteps    | 410000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.6       |\n",
      "|    explained_variance | 0.0835      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 81999       |\n",
      "|    policy_loss        | -1.45       |\n",
      "|    reward             | 0.015229355 |\n",
      "|    std                | 2.47e+05    |\n",
      "|    value_loss         | 0.00412     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 82100        |\n",
      "|    time_elapsed       | 1242         |\n",
      "|    total_timesteps    | 410500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.7        |\n",
      "|    explained_variance | 0.628        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82099        |\n",
      "|    policy_loss        | -0.74        |\n",
      "|    reward             | -0.020432534 |\n",
      "|    std                | 2.52e+05     |\n",
      "|    value_loss         | 0.00075      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 82200       |\n",
      "|    time_elapsed       | 1243        |\n",
      "|    total_timesteps    | 411000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.7       |\n",
      "|    explained_variance | 0.16        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 82199       |\n",
      "|    policy_loss        | -5.24       |\n",
      "|    reward             | 0.020710602 |\n",
      "|    std                | 2.56e+05    |\n",
      "|    value_loss         | 0.143       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 82300       |\n",
      "|    time_elapsed       | 1245        |\n",
      "|    total_timesteps    | 411500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.8       |\n",
      "|    explained_variance | 0.0178      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 82299       |\n",
      "|    policy_loss        | -3.29       |\n",
      "|    reward             | 0.089112535 |\n",
      "|    std                | 2.61e+05    |\n",
      "|    value_loss         | 0.0167      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 82400        |\n",
      "|    time_elapsed       | 1246         |\n",
      "|    total_timesteps    | 412000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82399        |\n",
      "|    policy_loss        | -0.984       |\n",
      "|    reward             | -0.047783457 |\n",
      "|    std                | 2.65e+05     |\n",
      "|    value_loss         | 0.00161      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 82500       |\n",
      "|    time_elapsed       | 1248        |\n",
      "|    total_timesteps    | 412500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 82499       |\n",
      "|    policy_loss        | -0.0481     |\n",
      "|    reward             | 0.018363688 |\n",
      "|    std                | 2.71e+05    |\n",
      "|    value_loss         | 1.52e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 82600      |\n",
      "|    time_elapsed       | 1249       |\n",
      "|    total_timesteps    | 413000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27.8      |\n",
      "|    explained_variance | -0.0385    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 82599      |\n",
      "|    policy_loss        | -1.9       |\n",
      "|    reward             | 0.08747812 |\n",
      "|    std                | 2.73e+05   |\n",
      "|    value_loss         | 0.00736    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 82700       |\n",
      "|    time_elapsed       | 1251        |\n",
      "|    total_timesteps    | 413500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.9       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 82699       |\n",
      "|    policy_loss        | 0.891       |\n",
      "|    reward             | -0.08326219 |\n",
      "|    std                | 2.75e+05    |\n",
      "|    value_loss         | 0.00159     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 82800        |\n",
      "|    time_elapsed       | 1252         |\n",
      "|    total_timesteps    | 414000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.9        |\n",
      "|    explained_variance | 0.0978       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82799        |\n",
      "|    policy_loss        | -0.671       |\n",
      "|    reward             | -0.057080142 |\n",
      "|    std                | 2.78e+05     |\n",
      "|    value_loss         | 0.00643      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 82900       |\n",
      "|    time_elapsed       | 1253        |\n",
      "|    total_timesteps    | 414500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.9       |\n",
      "|    explained_variance | 0.54        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 82899       |\n",
      "|    policy_loss        | -0.371      |\n",
      "|    reward             | 0.004386245 |\n",
      "|    std                | 2.76e+05    |\n",
      "|    value_loss         | 0.000236    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 83000        |\n",
      "|    time_elapsed       | 1255         |\n",
      "|    total_timesteps    | 415000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.9        |\n",
      "|    explained_variance | 0.873        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82999        |\n",
      "|    policy_loss        | 0.13         |\n",
      "|    reward             | 0.0030288552 |\n",
      "|    std                | 2.82e+05     |\n",
      "|    value_loss         | 4.57e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 83100       |\n",
      "|    time_elapsed       | 1256        |\n",
      "|    total_timesteps    | 415500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28         |\n",
      "|    explained_variance | 1.43e-06    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83099       |\n",
      "|    policy_loss        | 0.595       |\n",
      "|    reward             | 0.018711105 |\n",
      "|    std                | 2.89e+05    |\n",
      "|    value_loss         | 0.000575    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 330            |\n",
      "|    iterations         | 83200          |\n",
      "|    time_elapsed       | 1258           |\n",
      "|    total_timesteps    | 416000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -28            |\n",
      "|    explained_variance | 0.58           |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 83199          |\n",
      "|    policy_loss        | -0.305         |\n",
      "|    reward             | -0.00045165824 |\n",
      "|    std                | 2.91e+05       |\n",
      "|    value_loss         | 0.000389       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 83300      |\n",
      "|    time_elapsed       | 1259       |\n",
      "|    total_timesteps    | 416500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28        |\n",
      "|    explained_variance | 0.208      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 83299      |\n",
      "|    policy_loss        | -3.46      |\n",
      "|    reward             | 0.05041415 |\n",
      "|    std                | 2.96e+05   |\n",
      "|    value_loss         | 0.0227     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 83400      |\n",
      "|    time_elapsed       | 1261       |\n",
      "|    total_timesteps    | 417000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.1      |\n",
      "|    explained_variance | 0.218      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 83399      |\n",
      "|    policy_loss        | 3.63       |\n",
      "|    reward             | 0.09550719 |\n",
      "|    std                | 3.03e+05   |\n",
      "|    value_loss         | 0.0449     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 83500       |\n",
      "|    time_elapsed       | 1262        |\n",
      "|    total_timesteps    | 417500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83499       |\n",
      "|    policy_loss        | 0.594       |\n",
      "|    reward             | 0.012507846 |\n",
      "|    std                | 3.08e+05    |\n",
      "|    value_loss         | 0.000666    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 83600        |\n",
      "|    time_elapsed       | 1264         |\n",
      "|    total_timesteps    | 418000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.1        |\n",
      "|    explained_variance | 0.0679       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 83599        |\n",
      "|    policy_loss        | -1.71        |\n",
      "|    reward             | -0.006859238 |\n",
      "|    std                | 3.15e+05     |\n",
      "|    value_loss         | 0.00561      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 83700       |\n",
      "|    time_elapsed       | 1265        |\n",
      "|    total_timesteps    | 418500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.2       |\n",
      "|    explained_variance | 0.515       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83699       |\n",
      "|    policy_loss        | 0.864       |\n",
      "|    reward             | 0.094563894 |\n",
      "|    std                | 3.19e+05    |\n",
      "|    value_loss         | 0.00217     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 83800       |\n",
      "|    time_elapsed       | 1266        |\n",
      "|    total_timesteps    | 419000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83799       |\n",
      "|    policy_loss        | 2.34        |\n",
      "|    reward             | -0.22705947 |\n",
      "|    std                | 3.18e+05    |\n",
      "|    value_loss         | 0.00788     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 83900      |\n",
      "|    time_elapsed       | 1268       |\n",
      "|    total_timesteps    | 419500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.2      |\n",
      "|    explained_variance | 0.321      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 83899      |\n",
      "|    policy_loss        | 1.45       |\n",
      "|    reward             | 0.14257002 |\n",
      "|    std                | 3.23e+05   |\n",
      "|    value_loss         | 0.0127     |\n",
      "--------------------------------------\n",
      "day: 2707, episode: 155\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 150228.13\n",
      "total_reward: 140228.13\n",
      "total_cost: 16.64\n",
      "total_trades: 5410\n",
      "Sharpe: 0.973\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 84000         |\n",
      "|    time_elapsed       | 1269          |\n",
      "|    total_timesteps    | 420000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.2         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 83999         |\n",
      "|    policy_loss        | 0.00847       |\n",
      "|    reward             | -0.0013604466 |\n",
      "|    std                | 3.26e+05      |\n",
      "|    value_loss         | 1.79e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 84100       |\n",
      "|    time_elapsed       | 1271        |\n",
      "|    total_timesteps    | 420500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 84099       |\n",
      "|    policy_loss        | -0.438      |\n",
      "|    reward             | 0.010882533 |\n",
      "|    std                | 3.31e+05    |\n",
      "|    value_loss         | 0.00034     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 84200         |\n",
      "|    time_elapsed       | 1272          |\n",
      "|    total_timesteps    | 421000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.3         |\n",
      "|    explained_variance | 0.0743        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 84199         |\n",
      "|    policy_loss        | -0.135        |\n",
      "|    reward             | -0.0024344276 |\n",
      "|    std                | 3.4e+05       |\n",
      "|    value_loss         | 0.000416      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 84300        |\n",
      "|    time_elapsed       | 1274         |\n",
      "|    total_timesteps    | 421500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.3        |\n",
      "|    explained_variance | 0.136        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84299        |\n",
      "|    policy_loss        | -0.382       |\n",
      "|    reward             | -0.007778569 |\n",
      "|    std                | 3.44e+05     |\n",
      "|    value_loss         | 0.000434     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 84400       |\n",
      "|    time_elapsed       | 1275        |\n",
      "|    total_timesteps    | 422000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.4       |\n",
      "|    explained_variance | 0.672       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 84399       |\n",
      "|    policy_loss        | 0.404       |\n",
      "|    reward             | 0.032221716 |\n",
      "|    std                | 3.58e+05    |\n",
      "|    value_loss         | 0.000282    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 84500        |\n",
      "|    time_elapsed       | 1277         |\n",
      "|    total_timesteps    | 422500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.5        |\n",
      "|    explained_variance | 0.223        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84499        |\n",
      "|    policy_loss        | -0.393       |\n",
      "|    reward             | 0.0074965055 |\n",
      "|    std                | 3.7e+05      |\n",
      "|    value_loss         | 0.000245     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 84600       |\n",
      "|    time_elapsed       | 1278        |\n",
      "|    total_timesteps    | 423000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.5       |\n",
      "|    explained_variance | 0.133       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 84599       |\n",
      "|    policy_loss        | -0.716      |\n",
      "|    reward             | 0.007034241 |\n",
      "|    std                | 3.79e+05    |\n",
      "|    value_loss         | 0.000704    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 330            |\n",
      "|    iterations         | 84700          |\n",
      "|    time_elapsed       | 1280           |\n",
      "|    total_timesteps    | 423500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -28.6          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 84699          |\n",
      "|    policy_loss        | -0.0222        |\n",
      "|    reward             | -0.00075491716 |\n",
      "|    std                | 3.92e+05       |\n",
      "|    value_loss         | 5.3e-05        |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 84800      |\n",
      "|    time_elapsed       | 1281       |\n",
      "|    total_timesteps    | 424000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.6      |\n",
      "|    explained_variance | -0.0661    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 84799      |\n",
      "|    policy_loss        | 1.98       |\n",
      "|    reward             | 0.00447932 |\n",
      "|    std                | 4.05e+05   |\n",
      "|    value_loss         | 0.00534    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 84900       |\n",
      "|    time_elapsed       | 1283        |\n",
      "|    total_timesteps    | 424500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.7       |\n",
      "|    explained_variance | 0.394       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 84899       |\n",
      "|    policy_loss        | -1.91       |\n",
      "|    reward             | 0.063252114 |\n",
      "|    std                | 4.16e+05    |\n",
      "|    value_loss         | 0.00536     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 85000        |\n",
      "|    time_elapsed       | 1284         |\n",
      "|    total_timesteps    | 425000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.7        |\n",
      "|    explained_variance | 0.0803       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84999        |\n",
      "|    policy_loss        | -0.946       |\n",
      "|    reward             | -0.050311256 |\n",
      "|    std                | 4.14e+05     |\n",
      "|    value_loss         | 0.00406      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 85100      |\n",
      "|    time_elapsed       | 1286       |\n",
      "|    total_timesteps    | 425500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.7      |\n",
      "|    explained_variance | 0.484      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 85099      |\n",
      "|    policy_loss        | -2.86      |\n",
      "|    reward             | 0.07593184 |\n",
      "|    std                | 4.18e+05   |\n",
      "|    value_loss         | 0.0111     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 85200        |\n",
      "|    time_elapsed       | 1287         |\n",
      "|    total_timesteps    | 426000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.7        |\n",
      "|    explained_variance | -0.292       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 85199        |\n",
      "|    policy_loss        | 0.303        |\n",
      "|    reward             | -0.009792829 |\n",
      "|    std                | 4.26e+05     |\n",
      "|    value_loss         | 0.000549     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 85300        |\n",
      "|    time_elapsed       | 1288         |\n",
      "|    total_timesteps    | 426500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.8        |\n",
      "|    explained_variance | 0.0771       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 85299        |\n",
      "|    policy_loss        | 0.0655       |\n",
      "|    reward             | -0.037342064 |\n",
      "|    std                | 4.33e+05     |\n",
      "|    value_loss         | 0.00187      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 85400         |\n",
      "|    time_elapsed       | 1290          |\n",
      "|    total_timesteps    | 427000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 85399         |\n",
      "|    policy_loss        | -0.0509       |\n",
      "|    reward             | -0.0005053421 |\n",
      "|    std                | 4.4e+05       |\n",
      "|    value_loss         | 0.000216      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 85500        |\n",
      "|    time_elapsed       | 1291         |\n",
      "|    total_timesteps    | 427500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.8        |\n",
      "|    explained_variance | 0.12         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 85499        |\n",
      "|    policy_loss        | 0.672        |\n",
      "|    reward             | -0.030284332 |\n",
      "|    std                | 4.44e+05     |\n",
      "|    value_loss         | 0.00224      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 85600        |\n",
      "|    time_elapsed       | 1293         |\n",
      "|    total_timesteps    | 428000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 85599        |\n",
      "|    policy_loss        | -0.439       |\n",
      "|    reward             | 0.0009520641 |\n",
      "|    std                | 4.5e+05      |\n",
      "|    value_loss         | 0.000419     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 85700        |\n",
      "|    time_elapsed       | 1294         |\n",
      "|    total_timesteps    | 428500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.9        |\n",
      "|    explained_variance | -2.37        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 85699        |\n",
      "|    policy_loss        | -0.239       |\n",
      "|    reward             | -0.005064131 |\n",
      "|    std                | 4.57e+05     |\n",
      "|    value_loss         | 0.000168     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 85800         |\n",
      "|    time_elapsed       | 1296          |\n",
      "|    total_timesteps    | 429000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.9         |\n",
      "|    explained_variance | 0.00278       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 85799         |\n",
      "|    policy_loss        | -0.117        |\n",
      "|    reward             | -0.0071007055 |\n",
      "|    std                | 4.68e+05      |\n",
      "|    value_loss         | 0.000115      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 85900         |\n",
      "|    time_elapsed       | 1297          |\n",
      "|    total_timesteps    | 429500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29           |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 85899         |\n",
      "|    policy_loss        | 0.259         |\n",
      "|    reward             | -0.0048076822 |\n",
      "|    std                | 4.81e+05      |\n",
      "|    value_loss         | 0.000155      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 86000      |\n",
      "|    time_elapsed       | 1299       |\n",
      "|    total_timesteps    | 430000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29        |\n",
      "|    explained_variance | 0.191      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 85999      |\n",
      "|    policy_loss        | 1.24       |\n",
      "|    reward             | -0.0018209 |\n",
      "|    std                | 4.87e+05   |\n",
      "|    value_loss         | 0.00225    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 86100        |\n",
      "|    time_elapsed       | 1300         |\n",
      "|    total_timesteps    | 430500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29          |\n",
      "|    explained_variance | 0.0882       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 86099        |\n",
      "|    policy_loss        | 1.06         |\n",
      "|    reward             | -0.050057035 |\n",
      "|    std                | 4.94e+05     |\n",
      "|    value_loss         | 0.00289      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 86200         |\n",
      "|    time_elapsed       | 1301          |\n",
      "|    total_timesteps    | 431000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.1         |\n",
      "|    explained_variance | 0.859         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 86199         |\n",
      "|    policy_loss        | 0.126         |\n",
      "|    reward             | -0.0006341471 |\n",
      "|    std                | 5.03e+05      |\n",
      "|    value_loss         | 3.02e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 86300         |\n",
      "|    time_elapsed       | 1303          |\n",
      "|    total_timesteps    | 431500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.1         |\n",
      "|    explained_variance | 0.554         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 86299         |\n",
      "|    policy_loss        | 0.238         |\n",
      "|    reward             | -0.0091875885 |\n",
      "|    std                | 5.17e+05      |\n",
      "|    value_loss         | 0.000121      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 86400        |\n",
      "|    time_elapsed       | 1304         |\n",
      "|    total_timesteps    | 432000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.1        |\n",
      "|    explained_variance | 0.0991       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 86399        |\n",
      "|    policy_loss        | 1.79         |\n",
      "|    reward             | -0.011317051 |\n",
      "|    std                | 5.19e+05     |\n",
      "|    value_loss         | 0.00408      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 86500       |\n",
      "|    time_elapsed       | 1306        |\n",
      "|    total_timesteps    | 432500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.1       |\n",
      "|    explained_variance | 0.149       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 86499       |\n",
      "|    policy_loss        | 1.87        |\n",
      "|    reward             | 0.036987353 |\n",
      "|    std                | 5.21e+05    |\n",
      "|    value_loss         | 0.00585     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 86600      |\n",
      "|    time_elapsed       | 1307       |\n",
      "|    total_timesteps    | 433000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29.2      |\n",
      "|    explained_variance | -0.263     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 86599      |\n",
      "|    policy_loss        | -2.64      |\n",
      "|    reward             | 0.06394859 |\n",
      "|    std                | 5.25e+05   |\n",
      "|    value_loss         | 0.00866    |\n",
      "--------------------------------------\n",
      "day: 2707, episode: 160\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 83653.06\n",
      "total_reward: 73653.06\n",
      "total_cost: 16.86\n",
      "total_trades: 5412\n",
      "Sharpe: 0.737\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 331       |\n",
      "|    iterations         | 86700     |\n",
      "|    time_elapsed       | 1308      |\n",
      "|    total_timesteps    | 433500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.2     |\n",
      "|    explained_variance | -0.584    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 86699     |\n",
      "|    policy_loss        | 0.54      |\n",
      "|    reward             | 0.0085124 |\n",
      "|    std                | 5.32e+05  |\n",
      "|    value_loss         | 0.000494  |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 331            |\n",
      "|    iterations         | 86800          |\n",
      "|    time_elapsed       | 1310           |\n",
      "|    total_timesteps    | 434000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -29.2          |\n",
      "|    explained_variance | 1.19e-07       |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 86799          |\n",
      "|    policy_loss        | -0.0657        |\n",
      "|    reward             | 1.01606365e-05 |\n",
      "|    std                | 5.43e+05       |\n",
      "|    value_loss         | 7.79e-05       |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 86900      |\n",
      "|    time_elapsed       | 1312       |\n",
      "|    total_timesteps    | 434500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29.3      |\n",
      "|    explained_variance | 0.0584     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 86899      |\n",
      "|    policy_loss        | 0.105      |\n",
      "|    reward             | 0.01913559 |\n",
      "|    std                | 5.52e+05   |\n",
      "|    value_loss         | 0.000204   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 87000        |\n",
      "|    time_elapsed       | 1313         |\n",
      "|    total_timesteps    | 435000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.3        |\n",
      "|    explained_variance | 0.112        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 86999        |\n",
      "|    policy_loss        | 4.05         |\n",
      "|    reward             | -0.045068126 |\n",
      "|    std                | 5.64e+05     |\n",
      "|    value_loss         | 0.022        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 87100        |\n",
      "|    time_elapsed       | 1314         |\n",
      "|    total_timesteps    | 435500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.3        |\n",
      "|    explained_variance | 0.15         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 87099        |\n",
      "|    policy_loss        | 2.89         |\n",
      "|    reward             | -0.005639081 |\n",
      "|    std                | 5.76e+05     |\n",
      "|    value_loss         | 0.0109       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 87200       |\n",
      "|    time_elapsed       | 1316        |\n",
      "|    total_timesteps    | 436000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.4       |\n",
      "|    explained_variance | -41.6       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87199       |\n",
      "|    policy_loss        | 0.717       |\n",
      "|    reward             | 0.007839561 |\n",
      "|    std                | 5.81e+05    |\n",
      "|    value_loss         | 0.00756     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 87300       |\n",
      "|    time_elapsed       | 1317        |\n",
      "|    total_timesteps    | 436500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.4       |\n",
      "|    explained_variance | 0.0256      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87299       |\n",
      "|    policy_loss        | -0.455      |\n",
      "|    reward             | 0.010683544 |\n",
      "|    std                | 5.91e+05    |\n",
      "|    value_loss         | 0.000271    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 87400      |\n",
      "|    time_elapsed       | 1319       |\n",
      "|    total_timesteps    | 437000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29.4      |\n",
      "|    explained_variance | 0.453      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 87399      |\n",
      "|    policy_loss        | 0.121      |\n",
      "|    reward             | 0.03462094 |\n",
      "|    std                | 6.04e+05   |\n",
      "|    value_loss         | 7.79e-05   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 87500        |\n",
      "|    time_elapsed       | 1320         |\n",
      "|    total_timesteps    | 437500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 87499        |\n",
      "|    policy_loss        | -0.102       |\n",
      "|    reward             | -0.015965957 |\n",
      "|    std                | 6.14e+05     |\n",
      "|    value_loss         | 0.000235     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 87600        |\n",
      "|    time_elapsed       | 1322         |\n",
      "|    total_timesteps    | 438000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.5        |\n",
      "|    explained_variance | 0.303        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 87599        |\n",
      "|    policy_loss        | -0.14        |\n",
      "|    reward             | -0.015037888 |\n",
      "|    std                | 6.16e+05     |\n",
      "|    value_loss         | 0.0141       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 87700       |\n",
      "|    time_elapsed       | 1323        |\n",
      "|    total_timesteps    | 438500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.5       |\n",
      "|    explained_variance | 0.0761      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87699       |\n",
      "|    policy_loss        | -23.1       |\n",
      "|    reward             | 0.085018426 |\n",
      "|    std                | 6.19e+05    |\n",
      "|    value_loss         | 0.756       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 87800       |\n",
      "|    time_elapsed       | 1325        |\n",
      "|    total_timesteps    | 439000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.5       |\n",
      "|    explained_variance | -14.7       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87799       |\n",
      "|    policy_loss        | -0.57       |\n",
      "|    reward             | -0.02330302 |\n",
      "|    std                | 6.23e+05    |\n",
      "|    value_loss         | 0.00113     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 87900         |\n",
      "|    time_elapsed       | 1326          |\n",
      "|    total_timesteps    | 439500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.6         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 87899         |\n",
      "|    policy_loss        | -0.541        |\n",
      "|    reward             | -0.0074069463 |\n",
      "|    std                | 6.39e+05      |\n",
      "|    value_loss         | 0.000357      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 88000       |\n",
      "|    time_elapsed       | 1327        |\n",
      "|    total_timesteps    | 440000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.6       |\n",
      "|    explained_variance | -0.479      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87999       |\n",
      "|    policy_loss        | 0.332       |\n",
      "|    reward             | -0.01947036 |\n",
      "|    std                | 6.48e+05    |\n",
      "|    value_loss         | 0.000309    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 88100         |\n",
      "|    time_elapsed       | 1329          |\n",
      "|    total_timesteps    | 440500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.7         |\n",
      "|    explained_variance | -0.0243       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 88099         |\n",
      "|    policy_loss        | 1.8           |\n",
      "|    reward             | -0.0040404554 |\n",
      "|    std                | 6.72e+05      |\n",
      "|    value_loss         | 0.00408       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 88200       |\n",
      "|    time_elapsed       | 1330        |\n",
      "|    total_timesteps    | 441000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.7       |\n",
      "|    explained_variance | -0.044      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88199       |\n",
      "|    policy_loss        | -2.65       |\n",
      "|    reward             | 0.003604889 |\n",
      "|    std                | 6.9e+05     |\n",
      "|    value_loss         | 0.0143      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 88300       |\n",
      "|    time_elapsed       | 1332        |\n",
      "|    total_timesteps    | 441500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88299       |\n",
      "|    policy_loss        | -0.476      |\n",
      "|    reward             | 0.007805303 |\n",
      "|    std                | 6.96e+05    |\n",
      "|    value_loss         | 0.000291    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 88400         |\n",
      "|    time_elapsed       | 1333          |\n",
      "|    total_timesteps    | 442000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 88399         |\n",
      "|    policy_loss        | 0.381         |\n",
      "|    reward             | -0.0042935773 |\n",
      "|    std                | 7.08e+05      |\n",
      "|    value_loss         | 0.000208      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 88500       |\n",
      "|    time_elapsed       | 1335        |\n",
      "|    total_timesteps    | 442500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.8       |\n",
      "|    explained_variance | -0.423      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88499       |\n",
      "|    policy_loss        | 0.0598      |\n",
      "|    reward             | 0.016896512 |\n",
      "|    std                | 7.3e+05     |\n",
      "|    value_loss         | 0.000182    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 88600       |\n",
      "|    time_elapsed       | 1337        |\n",
      "|    total_timesteps    | 443000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.8       |\n",
      "|    explained_variance | 0.0523      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88599       |\n",
      "|    policy_loss        | 2.39        |\n",
      "|    reward             | 0.024849635 |\n",
      "|    std                | 7.36e+05    |\n",
      "|    value_loss         | 0.00733     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 88700       |\n",
      "|    time_elapsed       | 1338        |\n",
      "|    total_timesteps    | 443500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88699       |\n",
      "|    policy_loss        | 3.79        |\n",
      "|    reward             | 0.084831424 |\n",
      "|    std                | 7.48e+05    |\n",
      "|    value_loss         | 0.0194      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 88800       |\n",
      "|    time_elapsed       | 1340        |\n",
      "|    total_timesteps    | 444000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.9       |\n",
      "|    explained_variance | -0.00342    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88799       |\n",
      "|    policy_loss        | -0.816      |\n",
      "|    reward             | -0.10276642 |\n",
      "|    std                | 7.5e+05     |\n",
      "|    value_loss         | 0.006       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 88900       |\n",
      "|    time_elapsed       | 1342        |\n",
      "|    total_timesteps    | 444500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.9       |\n",
      "|    explained_variance | 0.425       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88899       |\n",
      "|    policy_loss        | 0.0269      |\n",
      "|    reward             | 0.009780671 |\n",
      "|    std                | 7.59e+05    |\n",
      "|    value_loss         | 7.9e-05     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 89000       |\n",
      "|    time_elapsed       | 1343        |\n",
      "|    total_timesteps    | 445000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88999       |\n",
      "|    policy_loss        | 0.0744      |\n",
      "|    reward             | 0.034589473 |\n",
      "|    std                | 7.73e+05    |\n",
      "|    value_loss         | 8.18e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 89100       |\n",
      "|    time_elapsed       | 1345        |\n",
      "|    total_timesteps    | 445500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30         |\n",
      "|    explained_variance | 0.111       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 89099       |\n",
      "|    policy_loss        | -4.07       |\n",
      "|    reward             | -0.11065066 |\n",
      "|    std                | 7.87e+05    |\n",
      "|    value_loss         | 0.0214      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 89200        |\n",
      "|    time_elapsed       | 1346         |\n",
      "|    total_timesteps    | 446000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30          |\n",
      "|    explained_variance | 0.772        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 89199        |\n",
      "|    policy_loss        | -4.52        |\n",
      "|    reward             | -0.010957797 |\n",
      "|    std                | 7.94e+05     |\n",
      "|    value_loss         | 0.026        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 89300      |\n",
      "|    time_elapsed       | 1348       |\n",
      "|    total_timesteps    | 446500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30        |\n",
      "|    explained_variance | 0.000149   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 89299      |\n",
      "|    policy_loss        | -1.22      |\n",
      "|    reward             | 0.03433285 |\n",
      "|    std                | 8.02e+05   |\n",
      "|    value_loss         | 0.0247     |\n",
      "--------------------------------------\n",
      "day: 2707, episode: 165\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 139562.79\n",
      "total_reward: 129562.79\n",
      "total_cost: 10.50\n",
      "total_trades: 5410\n",
      "Sharpe: 0.842\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 89400       |\n",
      "|    time_elapsed       | 1350        |\n",
      "|    total_timesteps    | 447000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30         |\n",
      "|    explained_variance | 0.788       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 89399       |\n",
      "|    policy_loss        | -0.115      |\n",
      "|    reward             | 0.026617223 |\n",
      "|    std                | 8.1e+05     |\n",
      "|    value_loss         | 3.83e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 89500       |\n",
      "|    time_elapsed       | 1351        |\n",
      "|    total_timesteps    | 447500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.1       |\n",
      "|    explained_variance | 0.213       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 89499       |\n",
      "|    policy_loss        | 0.0962      |\n",
      "|    reward             | 0.009274176 |\n",
      "|    std                | 8.2e+05     |\n",
      "|    value_loss         | 2.32e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 89600        |\n",
      "|    time_elapsed       | 1352         |\n",
      "|    total_timesteps    | 448000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.1        |\n",
      "|    explained_variance | 2.38e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 89599        |\n",
      "|    policy_loss        | -0.938       |\n",
      "|    reward             | -0.047868147 |\n",
      "|    std                | 8.37e+05     |\n",
      "|    value_loss         | 0.00124      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 89700        |\n",
      "|    time_elapsed       | 1354         |\n",
      "|    total_timesteps    | 448500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.1        |\n",
      "|    explained_variance | 0.405        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 89699        |\n",
      "|    policy_loss        | 1.28         |\n",
      "|    reward             | -0.097219765 |\n",
      "|    std                | 8.56e+05     |\n",
      "|    value_loss         | 0.00241      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 89800       |\n",
      "|    time_elapsed       | 1355        |\n",
      "|    total_timesteps    | 449000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.2       |\n",
      "|    explained_variance | 0.0682      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 89799       |\n",
      "|    policy_loss        | -1.15       |\n",
      "|    reward             | 0.007911579 |\n",
      "|    std                | 8.62e+05    |\n",
      "|    value_loss         | 0.00694     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 89900       |\n",
      "|    time_elapsed       | 1357        |\n",
      "|    total_timesteps    | 449500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.2       |\n",
      "|    explained_variance | 0.586       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 89899       |\n",
      "|    policy_loss        | -2.05       |\n",
      "|    reward             | 0.025084563 |\n",
      "|    std                | 8.82e+05    |\n",
      "|    value_loss         | 0.0088      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 90000         |\n",
      "|    time_elapsed       | 1358          |\n",
      "|    total_timesteps    | 450000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.2         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 89999         |\n",
      "|    policy_loss        | -0.0216       |\n",
      "|    reward             | -0.0041697165 |\n",
      "|    std                | 8.89e+05      |\n",
      "|    value_loss         | 4.55e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 90100       |\n",
      "|    time_elapsed       | 1360        |\n",
      "|    total_timesteps    | 450500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.3       |\n",
      "|    explained_variance | 0.188       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90099       |\n",
      "|    policy_loss        | -0.178      |\n",
      "|    reward             | 0.025963925 |\n",
      "|    std                | 9.09e+05    |\n",
      "|    value_loss         | 0.000139    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 90200       |\n",
      "|    time_elapsed       | 1361        |\n",
      "|    total_timesteps    | 451000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.3       |\n",
      "|    explained_variance | 0.35        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90199       |\n",
      "|    policy_loss        | 3.59        |\n",
      "|    reward             | -0.11579089 |\n",
      "|    std                | 9.19e+05    |\n",
      "|    value_loss         | 0.0142      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 90300      |\n",
      "|    time_elapsed       | 1362       |\n",
      "|    total_timesteps    | 451500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30.3      |\n",
      "|    explained_variance | 0.32       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 90299      |\n",
      "|    policy_loss        | -1.87      |\n",
      "|    reward             | 0.10713735 |\n",
      "|    std                | 9.27e+05   |\n",
      "|    value_loss         | 0.00496    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 331       |\n",
      "|    iterations         | 90400     |\n",
      "|    time_elapsed       | 1364      |\n",
      "|    total_timesteps    | 452000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.3     |\n",
      "|    explained_variance | 0.114     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 90399     |\n",
      "|    policy_loss        | 0.74      |\n",
      "|    reward             | 0.1533113 |\n",
      "|    std                | 9.39e+05  |\n",
      "|    value_loss         | 0.00258   |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 90500        |\n",
      "|    time_elapsed       | 1366         |\n",
      "|    total_timesteps    | 452500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.4        |\n",
      "|    explained_variance | 0.0161       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 90499        |\n",
      "|    policy_loss        | -0.181       |\n",
      "|    reward             | -0.014866231 |\n",
      "|    std                | 9.51e+05     |\n",
      "|    value_loss         | 5.9e-05      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 90600       |\n",
      "|    time_elapsed       | 1367        |\n",
      "|    total_timesteps    | 453000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.4       |\n",
      "|    explained_variance | -0.105      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90599       |\n",
      "|    policy_loss        | 0.23        |\n",
      "|    reward             | 0.007959882 |\n",
      "|    std                | 9.7e+05     |\n",
      "|    value_loss         | 0.000122    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 331        |\n",
      "|    iterations         | 90700      |\n",
      "|    time_elapsed       | 1369       |\n",
      "|    total_timesteps    | 453500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30.4      |\n",
      "|    explained_variance | 0.102      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 90699      |\n",
      "|    policy_loss        | 0.203      |\n",
      "|    reward             | 0.02281937 |\n",
      "|    std                | 9.89e+05   |\n",
      "|    value_loss         | 0.000206   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 90800        |\n",
      "|    time_elapsed       | 1370         |\n",
      "|    total_timesteps    | 454000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.5        |\n",
      "|    explained_variance | 0.0384       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 90799        |\n",
      "|    policy_loss        | 0.394        |\n",
      "|    reward             | -0.012939743 |\n",
      "|    std                | 1.01e+06     |\n",
      "|    value_loss         | 0.000211     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 90900       |\n",
      "|    time_elapsed       | 1372        |\n",
      "|    total_timesteps    | 454500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.5       |\n",
      "|    explained_variance | 0.0966      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90899       |\n",
      "|    policy_loss        | -1.46       |\n",
      "|    reward             | 0.049042944 |\n",
      "|    std                | 1.05e+06    |\n",
      "|    value_loss         | 0.00313     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 91000        |\n",
      "|    time_elapsed       | 1373         |\n",
      "|    total_timesteps    | 455000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.6        |\n",
      "|    explained_variance | -0.00539     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 90999        |\n",
      "|    policy_loss        | 0.306        |\n",
      "|    reward             | -0.007204829 |\n",
      "|    std                | 1.06e+06     |\n",
      "|    value_loss         | 0.00012      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 91100        |\n",
      "|    time_elapsed       | 1375         |\n",
      "|    total_timesteps    | 455500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.6        |\n",
      "|    explained_variance | 0.396        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91099        |\n",
      "|    policy_loss        | 0.403        |\n",
      "|    reward             | 0.0037410199 |\n",
      "|    std                | 1.08e+06     |\n",
      "|    value_loss         | 0.000353     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 91200         |\n",
      "|    time_elapsed       | 1376          |\n",
      "|    total_timesteps    | 456000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 91199         |\n",
      "|    policy_loss        | 0.667         |\n",
      "|    reward             | -0.0072979946 |\n",
      "|    std                | 1.1e+06       |\n",
      "|    value_loss         | 0.000474      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 91300        |\n",
      "|    time_elapsed       | 1378         |\n",
      "|    total_timesteps    | 456500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.7        |\n",
      "|    explained_variance | 0.13         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91299        |\n",
      "|    policy_loss        | 0.33         |\n",
      "|    reward             | 0.0020785583 |\n",
      "|    std                | 1.14e+06     |\n",
      "|    value_loss         | 0.000205     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 91400       |\n",
      "|    time_elapsed       | 1379        |\n",
      "|    total_timesteps    | 457000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.8       |\n",
      "|    explained_variance | -0.646      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 91399       |\n",
      "|    policy_loss        | -0.123      |\n",
      "|    reward             | 0.027636603 |\n",
      "|    std                | 1.18e+06    |\n",
      "|    value_loss         | 0.000394    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 331            |\n",
      "|    iterations         | 91500          |\n",
      "|    time_elapsed       | 1381           |\n",
      "|    total_timesteps    | 457500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -30.8          |\n",
      "|    explained_variance | 0.0726         |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 91499          |\n",
      "|    policy_loss        | 0.691          |\n",
      "|    reward             | -0.00015383607 |\n",
      "|    std                | 1.21e+06       |\n",
      "|    value_loss         | 0.00148        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 331           |\n",
      "|    iterations         | 91600         |\n",
      "|    time_elapsed       | 1382          |\n",
      "|    total_timesteps    | 458000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.9         |\n",
      "|    explained_variance | 0.526         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 91599         |\n",
      "|    policy_loss        | -2.41         |\n",
      "|    reward             | -0.0109639065 |\n",
      "|    std                | 1.23e+06      |\n",
      "|    value_loss         | 0.0068        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 91700        |\n",
      "|    time_elapsed       | 1384         |\n",
      "|    total_timesteps    | 458500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.9        |\n",
      "|    explained_variance | 0.000358     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91699        |\n",
      "|    policy_loss        | 0.158        |\n",
      "|    reward             | -0.009982139 |\n",
      "|    std                | 1.26e+06     |\n",
      "|    value_loss         | 8.63e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 91800       |\n",
      "|    time_elapsed       | 1385        |\n",
      "|    total_timesteps    | 459000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31         |\n",
      "|    explained_variance | 0.66        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 91799       |\n",
      "|    policy_loss        | -0.0894     |\n",
      "|    reward             | 0.040414687 |\n",
      "|    std                | 1.31e+06    |\n",
      "|    value_loss         | 9.6e-05     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 91900        |\n",
      "|    time_elapsed       | 1387         |\n",
      "|    total_timesteps    | 459500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31          |\n",
      "|    explained_variance | -0.182       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91899        |\n",
      "|    policy_loss        | -1.55        |\n",
      "|    reward             | -0.019080885 |\n",
      "|    std                | 1.34e+06     |\n",
      "|    value_loss         | 0.00257      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 92000        |\n",
      "|    time_elapsed       | 1388         |\n",
      "|    total_timesteps    | 460000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.1        |\n",
      "|    explained_variance | 0.151        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91999        |\n",
      "|    policy_loss        | 2.34         |\n",
      "|    reward             | -0.085857205 |\n",
      "|    std                | 1.36e+06     |\n",
      "|    value_loss         | 0.00685      |\n",
      "----------------------------------------\n",
      "day: 2707, episode: 170\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 55878.01\n",
      "total_reward: 45878.01\n",
      "total_cost: 14.33\n",
      "total_trades: 5413\n",
      "Sharpe: 0.674\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 92100        |\n",
      "|    time_elapsed       | 1390         |\n",
      "|    total_timesteps    | 460500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.1        |\n",
      "|    explained_variance | -0.0278      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92099        |\n",
      "|    policy_loss        | 0.116        |\n",
      "|    reward             | 0.0045798174 |\n",
      "|    std                | 1.39e+06     |\n",
      "|    value_loss         | 3.09e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 92200        |\n",
      "|    time_elapsed       | 1391         |\n",
      "|    total_timesteps    | 461000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.1        |\n",
      "|    explained_variance | -6.17        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92199        |\n",
      "|    policy_loss        | -0.0833      |\n",
      "|    reward             | -0.004276606 |\n",
      "|    std                | 1.42e+06     |\n",
      "|    value_loss         | 2.01e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 92300       |\n",
      "|    time_elapsed       | 1393        |\n",
      "|    total_timesteps    | 461500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.2       |\n",
      "|    explained_variance | 0.305       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 92299       |\n",
      "|    policy_loss        | -0.78       |\n",
      "|    reward             | -0.11252657 |\n",
      "|    std                | 1.45e+06    |\n",
      "|    value_loss         | 0.000966    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 92400       |\n",
      "|    time_elapsed       | 1394        |\n",
      "|    total_timesteps    | 462000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.2       |\n",
      "|    explained_variance | 0.494       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 92399       |\n",
      "|    policy_loss        | -0.56       |\n",
      "|    reward             | 0.052627955 |\n",
      "|    std                | 1.46e+06    |\n",
      "|    value_loss         | 0.000478    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 331       |\n",
      "|    iterations         | 92500     |\n",
      "|    time_elapsed       | 1396      |\n",
      "|    total_timesteps    | 462500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 92499     |\n",
      "|    policy_loss        | 2.57      |\n",
      "|    reward             | 0.0464853 |\n",
      "|    std                | 1.48e+06  |\n",
      "|    value_loss         | 0.0108    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 92600       |\n",
      "|    time_elapsed       | 1398        |\n",
      "|    total_timesteps    | 463000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.2       |\n",
      "|    explained_variance | 0.293       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 92599       |\n",
      "|    policy_loss        | -1.75       |\n",
      "|    reward             | 0.076407164 |\n",
      "|    std                | 1.49e+06    |\n",
      "|    value_loss         | 0.00401     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 92700       |\n",
      "|    time_elapsed       | 1399        |\n",
      "|    total_timesteps    | 463500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.3       |\n",
      "|    explained_variance | -1.23       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 92699       |\n",
      "|    policy_loss        | -1.78       |\n",
      "|    reward             | 0.011850286 |\n",
      "|    std                | 1.5e+06     |\n",
      "|    value_loss         | 0.00333     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 92800        |\n",
      "|    time_elapsed       | 1401         |\n",
      "|    total_timesteps    | 464000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92799        |\n",
      "|    policy_loss        | 0.88         |\n",
      "|    reward             | 0.0050415047 |\n",
      "|    std                | 1.53e+06     |\n",
      "|    value_loss         | 0.000853     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 92900        |\n",
      "|    time_elapsed       | 1403         |\n",
      "|    total_timesteps    | 464500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.3        |\n",
      "|    explained_variance | 0.132        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92899        |\n",
      "|    policy_loss        | 1.43         |\n",
      "|    reward             | 0.0020786873 |\n",
      "|    std                | 1.56e+06     |\n",
      "|    value_loss         | 0.00402      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 93000       |\n",
      "|    time_elapsed       | 1404        |\n",
      "|    total_timesteps    | 465000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 92999       |\n",
      "|    policy_loss        | 2.75        |\n",
      "|    reward             | -0.09741618 |\n",
      "|    std                | 1.58e+06    |\n",
      "|    value_loss         | 0.00848     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 93100       |\n",
      "|    time_elapsed       | 1406        |\n",
      "|    total_timesteps    | 465500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93099       |\n",
      "|    policy_loss        | -0.546      |\n",
      "|    reward             | 0.033634834 |\n",
      "|    std                | 1.59e+06    |\n",
      "|    value_loss         | 0.00376     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 93200        |\n",
      "|    time_elapsed       | 1407         |\n",
      "|    total_timesteps    | 466000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 93199        |\n",
      "|    policy_loss        | 0.868        |\n",
      "|    reward             | 0.0046968125 |\n",
      "|    std                | 1.59e+06     |\n",
      "|    value_loss         | 0.000852     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 93300        |\n",
      "|    time_elapsed       | 1409         |\n",
      "|    total_timesteps    | 466500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 93299        |\n",
      "|    policy_loss        | -0.216       |\n",
      "|    reward             | -0.022156943 |\n",
      "|    std                | 1.62e+06     |\n",
      "|    value_loss         | 0.000194     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 93400       |\n",
      "|    time_elapsed       | 1411        |\n",
      "|    total_timesteps    | 467000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.4       |\n",
      "|    explained_variance | 0.366       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93399       |\n",
      "|    policy_loss        | 0.121       |\n",
      "|    reward             | 0.018226916 |\n",
      "|    std                | 1.66e+06    |\n",
      "|    value_loss         | 0.000964    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 93500       |\n",
      "|    time_elapsed       | 1412        |\n",
      "|    total_timesteps    | 467500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93499       |\n",
      "|    policy_loss        | 1.72        |\n",
      "|    reward             | 0.008616066 |\n",
      "|    std                | 1.64e+06    |\n",
      "|    value_loss         | 0.0182      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 93600        |\n",
      "|    time_elapsed       | 1414         |\n",
      "|    total_timesteps    | 468000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 93599        |\n",
      "|    policy_loss        | 5.76         |\n",
      "|    reward             | -0.036130857 |\n",
      "|    std                | 1.62e+06     |\n",
      "|    value_loss         | 0.0386       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 93700       |\n",
      "|    time_elapsed       | 1415        |\n",
      "|    total_timesteps    | 468500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.4       |\n",
      "|    explained_variance | -4.34       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93699       |\n",
      "|    policy_loss        | -1.16       |\n",
      "|    reward             | 0.006305146 |\n",
      "|    std                | 1.61e+06    |\n",
      "|    value_loss         | 0.00179     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 93800        |\n",
      "|    time_elapsed       | 1417         |\n",
      "|    total_timesteps    | 469000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.4        |\n",
      "|    explained_variance | 0.268        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 93799        |\n",
      "|    policy_loss        | -0.124       |\n",
      "|    reward             | -0.006247645 |\n",
      "|    std                | 1.63e+06     |\n",
      "|    value_loss         | 0.00016      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 93900      |\n",
      "|    time_elapsed       | 1418       |\n",
      "|    total_timesteps    | 469500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.5      |\n",
      "|    explained_variance | 0.682      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 93899      |\n",
      "|    policy_loss        | -0.76      |\n",
      "|    reward             | 0.00423583 |\n",
      "|    std                | 1.67e+06   |\n",
      "|    value_loss         | 0.00117    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 94000        |\n",
      "|    time_elapsed       | 1420         |\n",
      "|    total_timesteps    | 470000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.5        |\n",
      "|    explained_variance | -0.000127    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 93999        |\n",
      "|    policy_loss        | -0.252       |\n",
      "|    reward             | -0.011711773 |\n",
      "|    std                | 1.7e+06      |\n",
      "|    value_loss         | 0.000957     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 94100        |\n",
      "|    time_elapsed       | 1421         |\n",
      "|    total_timesteps    | 470500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.5        |\n",
      "|    explained_variance | 4.77e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 94099        |\n",
      "|    policy_loss        | -5.72        |\n",
      "|    reward             | -0.013092918 |\n",
      "|    std                | 1.7e+06      |\n",
      "|    value_loss         | 0.0358       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 94200       |\n",
      "|    time_elapsed       | 1423        |\n",
      "|    total_timesteps    | 471000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.5       |\n",
      "|    explained_variance | 0.00746     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94199       |\n",
      "|    policy_loss        | 17.3        |\n",
      "|    reward             | -0.07599067 |\n",
      "|    std                | 1.71e+06    |\n",
      "|    value_loss         | 0.382       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 94300       |\n",
      "|    time_elapsed       | 1424        |\n",
      "|    total_timesteps    | 471500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94299       |\n",
      "|    policy_loss        | 0.418       |\n",
      "|    reward             | 0.045389425 |\n",
      "|    std                | 1.72e+06    |\n",
      "|    value_loss         | 0.000365    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 94400       |\n",
      "|    time_elapsed       | 1426        |\n",
      "|    total_timesteps    | 472000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94399       |\n",
      "|    policy_loss        | -0.77       |\n",
      "|    reward             | 0.017164933 |\n",
      "|    std                | 1.74e+06    |\n",
      "|    value_loss         | 0.00073     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 94500        |\n",
      "|    time_elapsed       | 1427         |\n",
      "|    total_timesteps    | 472500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.6        |\n",
      "|    explained_variance | 0.0919       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 94499        |\n",
      "|    policy_loss        | -1.36        |\n",
      "|    reward             | -0.040451184 |\n",
      "|    std                | 1.76e+06     |\n",
      "|    value_loss         | 0.00373      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 94600       |\n",
      "|    time_elapsed       | 1429        |\n",
      "|    total_timesteps    | 473000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.6       |\n",
      "|    explained_variance | 0.00122     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94599       |\n",
      "|    policy_loss        | -0.213      |\n",
      "|    reward             | 0.021379638 |\n",
      "|    std                | 1.79e+06    |\n",
      "|    value_loss         | 0.000536    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 94700      |\n",
      "|    time_elapsed       | 1430       |\n",
      "|    total_timesteps    | 473500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.6      |\n",
      "|    explained_variance | -0.457     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 94699      |\n",
      "|    policy_loss        | -8.24      |\n",
      "|    reward             | 0.21682732 |\n",
      "|    std                | 1.82e+06   |\n",
      "|    value_loss         | 0.0893     |\n",
      "--------------------------------------\n",
      "day: 2707, episode: 175\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 106578.91\n",
      "total_reward: 96578.91\n",
      "total_cost: 48.21\n",
      "total_trades: 5399\n",
      "Sharpe: 0.904\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 94800       |\n",
      "|    time_elapsed       | 1432        |\n",
      "|    total_timesteps    | 474000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.7       |\n",
      "|    explained_variance | 0.0287      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94799       |\n",
      "|    policy_loss        | -0.899      |\n",
      "|    reward             | -0.00419518 |\n",
      "|    std                | 1.84e+06    |\n",
      "|    value_loss         | 0.00102     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 94900        |\n",
      "|    time_elapsed       | 1433         |\n",
      "|    total_timesteps    | 474500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 94899        |\n",
      "|    policy_loss        | 0.248        |\n",
      "|    reward             | -0.014516955 |\n",
      "|    std                | 1.85e+06     |\n",
      "|    value_loss         | 0.00011      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 95000      |\n",
      "|    time_elapsed       | 1435       |\n",
      "|    total_timesteps    | 475000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.7      |\n",
      "|    explained_variance | 0.205      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 94999      |\n",
      "|    policy_loss        | -0.343     |\n",
      "|    reward             | 0.01873664 |\n",
      "|    std                | 1.88e+06   |\n",
      "|    value_loss         | 0.000144   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 95100       |\n",
      "|    time_elapsed       | 1436        |\n",
      "|    total_timesteps    | 475500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.8       |\n",
      "|    explained_variance | 0.264       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 95099       |\n",
      "|    policy_loss        | -0.445      |\n",
      "|    reward             | 0.023870012 |\n",
      "|    std                | 1.96e+06    |\n",
      "|    value_loss         | 0.000257    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 331         |\n",
      "|    iterations         | 95200       |\n",
      "|    time_elapsed       | 1437        |\n",
      "|    total_timesteps    | 476000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.8       |\n",
      "|    explained_variance | 0.671       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 95199       |\n",
      "|    policy_loss        | -0.134      |\n",
      "|    reward             | 0.015502466 |\n",
      "|    std                | 1.97e+06    |\n",
      "|    value_loss         | 0.000925    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 95300      |\n",
      "|    time_elapsed       | 1439       |\n",
      "|    total_timesteps    | 476500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.9      |\n",
      "|    explained_variance | 0.543      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 95299      |\n",
      "|    policy_loss        | -1.09      |\n",
      "|    reward             | 0.02044671 |\n",
      "|    std                | 2.03e+06   |\n",
      "|    value_loss         | 0.00136    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 95400        |\n",
      "|    time_elapsed       | 1441         |\n",
      "|    total_timesteps    | 477000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.9        |\n",
      "|    explained_variance | 0.303        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 95399        |\n",
      "|    policy_loss        | 0.605        |\n",
      "|    reward             | -0.025776567 |\n",
      "|    std                | 2.07e+06     |\n",
      "|    value_loss         | 0.000404     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 95500      |\n",
      "|    time_elapsed       | 1443       |\n",
      "|    total_timesteps    | 477500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 95499      |\n",
      "|    policy_loss        | -0.983     |\n",
      "|    reward             | 0.01806133 |\n",
      "|    std                | 2.1e+06    |\n",
      "|    value_loss         | 0.00106    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 95600        |\n",
      "|    time_elapsed       | 1444         |\n",
      "|    total_timesteps    | 478000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32          |\n",
      "|    explained_variance | -0.155       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 95599        |\n",
      "|    policy_loss        | -0.495       |\n",
      "|    reward             | 0.0152946245 |\n",
      "|    std                | 2.15e+06     |\n",
      "|    value_loss         | 0.00243      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 95700       |\n",
      "|    time_elapsed       | 1446        |\n",
      "|    total_timesteps    | 478500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 95699       |\n",
      "|    policy_loss        | 2.16        |\n",
      "|    reward             | 0.036161948 |\n",
      "|    std                | 2.18e+06    |\n",
      "|    value_loss         | 0.00683     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 95800        |\n",
      "|    time_elapsed       | 1448         |\n",
      "|    total_timesteps    | 479000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32          |\n",
      "|    explained_variance | 0.308        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 95799        |\n",
      "|    policy_loss        | -3.24        |\n",
      "|    reward             | -0.121556304 |\n",
      "|    std                | 2.22e+06     |\n",
      "|    value_loss         | 0.0122       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 95900        |\n",
      "|    time_elapsed       | 1449         |\n",
      "|    total_timesteps    | 479500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 95899        |\n",
      "|    policy_loss        | -0.152       |\n",
      "|    reward             | 0.0077944137 |\n",
      "|    std                | 2.24e+06     |\n",
      "|    value_loss         | 0.000118     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 96000       |\n",
      "|    time_elapsed       | 1451        |\n",
      "|    total_timesteps    | 480000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 95999       |\n",
      "|    policy_loss        | 0.812       |\n",
      "|    reward             | 0.017553387 |\n",
      "|    std                | 2.26e+06    |\n",
      "|    value_loss         | 0.000729    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 96100        |\n",
      "|    time_elapsed       | 1452         |\n",
      "|    total_timesteps    | 480500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 96099        |\n",
      "|    policy_loss        | 2.99         |\n",
      "|    reward             | -0.043578517 |\n",
      "|    std                | 2.3e+06      |\n",
      "|    value_loss         | 0.0113       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 96200      |\n",
      "|    time_elapsed       | 1454       |\n",
      "|    total_timesteps    | 481000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.2      |\n",
      "|    explained_variance | 0.123      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 96199      |\n",
      "|    policy_loss        | -2.03      |\n",
      "|    reward             | 0.04742547 |\n",
      "|    std                | 2.36e+06   |\n",
      "|    value_loss         | 0.00444    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 96300      |\n",
      "|    time_elapsed       | 1456       |\n",
      "|    total_timesteps    | 481500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.2      |\n",
      "|    explained_variance | -0.263     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 96299      |\n",
      "|    policy_loss        | 4.32       |\n",
      "|    reward             | 0.13280599 |\n",
      "|    std                | 2.42e+06   |\n",
      "|    value_loss         | 0.0241     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 96400      |\n",
      "|    time_elapsed       | 1457       |\n",
      "|    total_timesteps    | 482000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.2      |\n",
      "|    explained_variance | 0.372      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 96399      |\n",
      "|    policy_loss        | 1.51       |\n",
      "|    reward             | 0.04461803 |\n",
      "|    std                | 2.44e+06   |\n",
      "|    value_loss         | 0.00489    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 96500        |\n",
      "|    time_elapsed       | 1459         |\n",
      "|    total_timesteps    | 482500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.3        |\n",
      "|    explained_variance | -1.08e-05    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 96499        |\n",
      "|    policy_loss        | -0.316       |\n",
      "|    reward             | -0.002807326 |\n",
      "|    std                | 2.48e+06     |\n",
      "|    value_loss         | 0.000129     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 96600        |\n",
      "|    time_elapsed       | 1460         |\n",
      "|    total_timesteps    | 483000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.3        |\n",
      "|    explained_variance | 0.0968       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 96599        |\n",
      "|    policy_loss        | 0.77         |\n",
      "|    reward             | 0.0019417553 |\n",
      "|    std                | 2.52e+06     |\n",
      "|    value_loss         | 0.000927     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 96700       |\n",
      "|    time_elapsed       | 1462        |\n",
      "|    total_timesteps    | 483500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.4       |\n",
      "|    explained_variance | 0.107       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 96699       |\n",
      "|    policy_loss        | 1.07        |\n",
      "|    reward             | -0.03698544 |\n",
      "|    std                | 2.59e+06    |\n",
      "|    value_loss         | 0.00291     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 96800      |\n",
      "|    time_elapsed       | 1463       |\n",
      "|    total_timesteps    | 484000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.4      |\n",
      "|    explained_variance | 0.175      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 96799      |\n",
      "|    policy_loss        | -4.19      |\n",
      "|    reward             | 0.13435814 |\n",
      "|    std                | 2.64e+06   |\n",
      "|    value_loss         | 0.0209     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 96900        |\n",
      "|    time_elapsed       | 1465         |\n",
      "|    total_timesteps    | 484500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.5        |\n",
      "|    explained_variance | 0.0962       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 96899        |\n",
      "|    policy_loss        | -3.28        |\n",
      "|    reward             | -0.005064128 |\n",
      "|    std                | 2.73e+06     |\n",
      "|    value_loss         | 0.0134       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 97000        |\n",
      "|    time_elapsed       | 1466         |\n",
      "|    total_timesteps    | 485000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.5        |\n",
      "|    explained_variance | -0.00137     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 96999        |\n",
      "|    policy_loss        | 0.562        |\n",
      "|    reward             | -0.016111134 |\n",
      "|    std                | 2.77e+06     |\n",
      "|    value_loss         | 0.000331     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 330            |\n",
      "|    iterations         | 97100          |\n",
      "|    time_elapsed       | 1468           |\n",
      "|    total_timesteps    | 485500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -32.5          |\n",
      "|    explained_variance | -0.142         |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 97099          |\n",
      "|    policy_loss        | -0.0438        |\n",
      "|    reward             | -0.00054341013 |\n",
      "|    std                | 2.82e+06       |\n",
      "|    value_loss         | 0.000313       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 97200         |\n",
      "|    time_elapsed       | 1469          |\n",
      "|    total_timesteps    | 486000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.6         |\n",
      "|    explained_variance | -0.506        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 97199         |\n",
      "|    policy_loss        | 0.442         |\n",
      "|    reward             | -0.0070776404 |\n",
      "|    std                | 2.87e+06      |\n",
      "|    value_loss         | 0.000241      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 330           |\n",
      "|    iterations         | 97300         |\n",
      "|    time_elapsed       | 1471          |\n",
      "|    total_timesteps    | 486500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.6         |\n",
      "|    explained_variance | -0.00483      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 97299         |\n",
      "|    policy_loss        | -0.468        |\n",
      "|    reward             | -0.0032809419 |\n",
      "|    std                | 2.93e+06      |\n",
      "|    value_loss         | 0.000298      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 97400       |\n",
      "|    time_elapsed       | 1472        |\n",
      "|    total_timesteps    | 487000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.6       |\n",
      "|    explained_variance | 5.01e-06    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97399       |\n",
      "|    policy_loss        | 1.02        |\n",
      "|    reward             | 0.023272203 |\n",
      "|    std                | 2.96e+06    |\n",
      "|    value_loss         | 0.00134     |\n",
      "---------------------------------------\n",
      "day: 2707, episode: 180\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 45797.14\n",
      "total_reward: 35797.14\n",
      "total_cost: 16.75\n",
      "total_trades: 5411\n",
      "Sharpe: 0.622\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 97500        |\n",
      "|    time_elapsed       | 1474         |\n",
      "|    total_timesteps    | 487500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97499        |\n",
      "|    policy_loss        | -0.112       |\n",
      "|    reward             | 0.0037498563 |\n",
      "|    std                | 3e+06        |\n",
      "|    value_loss         | 4.84e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 97600        |\n",
      "|    time_elapsed       | 1476         |\n",
      "|    total_timesteps    | 488000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.7        |\n",
      "|    explained_variance | 1.97e-06     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97599        |\n",
      "|    policy_loss        | 0.345        |\n",
      "|    reward             | 0.0074811857 |\n",
      "|    std                | 3.07e+06     |\n",
      "|    value_loss         | 0.00015      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 97700        |\n",
      "|    time_elapsed       | 1477         |\n",
      "|    total_timesteps    | 488500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97699        |\n",
      "|    policy_loss        | -0.216       |\n",
      "|    reward             | -0.003355281 |\n",
      "|    std                | 3.17e+06     |\n",
      "|    value_loss         | 4.7e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 97800        |\n",
      "|    time_elapsed       | 1479         |\n",
      "|    total_timesteps    | 489000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.8        |\n",
      "|    explained_variance | 0.024        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97799        |\n",
      "|    policy_loss        | 3.21         |\n",
      "|    reward             | -0.012967099 |\n",
      "|    std                | 3.28e+06     |\n",
      "|    value_loss         | 0.012        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 97900      |\n",
      "|    time_elapsed       | 1481       |\n",
      "|    total_timesteps    | 489500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.9      |\n",
      "|    explained_variance | 0.756      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 97899      |\n",
      "|    policy_loss        | 1.32       |\n",
      "|    reward             | 0.01838423 |\n",
      "|    std                | 3.31e+06   |\n",
      "|    value_loss         | 0.00244    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 98000      |\n",
      "|    time_elapsed       | 1482       |\n",
      "|    total_timesteps    | 490000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 97999      |\n",
      "|    policy_loss        | 5.57       |\n",
      "|    reward             | 0.19768254 |\n",
      "|    std                | 3.35e+06   |\n",
      "|    value_loss         | 0.0311     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 98100       |\n",
      "|    time_elapsed       | 1484        |\n",
      "|    total_timesteps    | 490500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.9       |\n",
      "|    explained_variance | 0.499       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 98099       |\n",
      "|    policy_loss        | 0.478       |\n",
      "|    reward             | 0.028711915 |\n",
      "|    std                | 3.36e+06    |\n",
      "|    value_loss         | 0.000554    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 98200       |\n",
      "|    time_elapsed       | 1485        |\n",
      "|    total_timesteps    | 491000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.9       |\n",
      "|    explained_variance | -1.18       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 98199       |\n",
      "|    policy_loss        | 0.107       |\n",
      "|    reward             | 0.011037201 |\n",
      "|    std                | 3.44e+06    |\n",
      "|    value_loss         | 4.52e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 98300        |\n",
      "|    time_elapsed       | 1486         |\n",
      "|    total_timesteps    | 491500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33          |\n",
      "|    explained_variance | 0.296        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98299        |\n",
      "|    policy_loss        | -0.33        |\n",
      "|    reward             | -0.023859495 |\n",
      "|    std                | 3.51e+06     |\n",
      "|    value_loss         | 0.000253     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 98400        |\n",
      "|    time_elapsed       | 1488         |\n",
      "|    total_timesteps    | 492000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33          |\n",
      "|    explained_variance | 0.114        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98399        |\n",
      "|    policy_loss        | 0.584        |\n",
      "|    reward             | -0.031161254 |\n",
      "|    std                | 3.52e+06     |\n",
      "|    value_loss         | 0.00235      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 98500       |\n",
      "|    time_elapsed       | 1489        |\n",
      "|    total_timesteps    | 492500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33         |\n",
      "|    explained_variance | 0.31        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 98499       |\n",
      "|    policy_loss        | -0.809      |\n",
      "|    reward             | 0.008217017 |\n",
      "|    std                | 3.61e+06    |\n",
      "|    value_loss         | 0.000794    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 98600        |\n",
      "|    time_elapsed       | 1491         |\n",
      "|    total_timesteps    | 493000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98599        |\n",
      "|    policy_loss        | -0.427       |\n",
      "|    reward             | 0.0017626098 |\n",
      "|    std                | 3.67e+06     |\n",
      "|    value_loss         | 0.000172     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 98700        |\n",
      "|    time_elapsed       | 1492         |\n",
      "|    total_timesteps    | 493500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.1        |\n",
      "|    explained_variance | 0.598        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98699        |\n",
      "|    policy_loss        | -0.661       |\n",
      "|    reward             | -0.017612869 |\n",
      "|    std                | 3.73e+06     |\n",
      "|    value_loss         | 0.00046      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 98800       |\n",
      "|    time_elapsed       | 1494        |\n",
      "|    total_timesteps    | 494000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.1       |\n",
      "|    explained_variance | 0.379       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 98799       |\n",
      "|    policy_loss        | -1.17       |\n",
      "|    reward             | 0.016293397 |\n",
      "|    std                | 3.82e+06    |\n",
      "|    value_loss         | 0.00131     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 98900        |\n",
      "|    time_elapsed       | 1495         |\n",
      "|    total_timesteps    | 494500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.2        |\n",
      "|    explained_variance | 0.147        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98899        |\n",
      "|    policy_loss        | -0.56        |\n",
      "|    reward             | -0.056373335 |\n",
      "|    std                | 3.92e+06     |\n",
      "|    value_loss         | 0.000314     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 99000       |\n",
      "|    time_elapsed       | 1497        |\n",
      "|    total_timesteps    | 495000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 98999       |\n",
      "|    policy_loss        | -0.461      |\n",
      "|    reward             | -0.03082756 |\n",
      "|    std                | 4.02e+06    |\n",
      "|    value_loss         | 0.000341    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 99100       |\n",
      "|    time_elapsed       | 1498        |\n",
      "|    total_timesteps    | 495500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.3       |\n",
      "|    explained_variance | 0.149       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99099       |\n",
      "|    policy_loss        | -2.64       |\n",
      "|    reward             | 0.033886436 |\n",
      "|    std                | 4.11e+06    |\n",
      "|    value_loss         | 0.00906     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 99200        |\n",
      "|    time_elapsed       | 1500         |\n",
      "|    total_timesteps    | 496000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.3        |\n",
      "|    explained_variance | 0.129        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99199        |\n",
      "|    policy_loss        | -0.67        |\n",
      "|    reward             | -0.014328039 |\n",
      "|    std                | 4.17e+06     |\n",
      "|    value_loss         | 0.000729     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 99300       |\n",
      "|    time_elapsed       | 1501        |\n",
      "|    total_timesteps    | 496500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.4       |\n",
      "|    explained_variance | -2.38e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99299       |\n",
      "|    policy_loss        | -0.306      |\n",
      "|    reward             | 0.008440718 |\n",
      "|    std                | 4.28e+06    |\n",
      "|    value_loss         | 0.000377    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 99400       |\n",
      "|    time_elapsed       | 1503        |\n",
      "|    total_timesteps    | 497000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99399       |\n",
      "|    policy_loss        | 5.05        |\n",
      "|    reward             | -0.02771162 |\n",
      "|    std                | 4.38e+06    |\n",
      "|    value_loss         | 0.0326      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 99500       |\n",
      "|    time_elapsed       | 1504        |\n",
      "|    total_timesteps    | 497500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99499       |\n",
      "|    policy_loss        | -0.865      |\n",
      "|    reward             | 0.008443009 |\n",
      "|    std                | 4.46e+06    |\n",
      "|    value_loss         | 0.00666     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 99600       |\n",
      "|    time_elapsed       | 1506        |\n",
      "|    total_timesteps    | 498000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99599       |\n",
      "|    policy_loss        | 0.324       |\n",
      "|    reward             | 0.061719958 |\n",
      "|    std                | 4.51e+06    |\n",
      "|    value_loss         | 0.00246     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 99700       |\n",
      "|    time_elapsed       | 1507        |\n",
      "|    total_timesteps    | 498500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99699       |\n",
      "|    policy_loss        | -0.269      |\n",
      "|    reward             | 0.007927371 |\n",
      "|    std                | 4.57e+06    |\n",
      "|    value_loss         | 9.29e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 99800        |\n",
      "|    time_elapsed       | 1508         |\n",
      "|    total_timesteps    | 499000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.5        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99799        |\n",
      "|    policy_loss        | 0.105        |\n",
      "|    reward             | 0.0048743985 |\n",
      "|    std                | 4.65e+06     |\n",
      "|    value_loss         | 1.22e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 99900        |\n",
      "|    time_elapsed       | 1510         |\n",
      "|    total_timesteps    | 499500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.6        |\n",
      "|    explained_variance | 0.212        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99899        |\n",
      "|    policy_loss        | 0.706        |\n",
      "|    reward             | -0.004153087 |\n",
      "|    std                | 4.77e+06     |\n",
      "|    value_loss         | 0.000654     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 330          |\n",
      "|    iterations         | 100000       |\n",
      "|    time_elapsed       | 1512         |\n",
      "|    total_timesteps    | 500000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.6        |\n",
      "|    explained_variance | 0.171        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99999        |\n",
      "|    policy_loss        | 0.771        |\n",
      "|    reward             | 0.0014007782 |\n",
      "|    std                | 4.86e+06     |\n",
      "|    value_loss         | 0.00102      |\n",
      "----------------------------------------\n",
      "======A2C Validation from:  2021-01-04 to  2021-04-06\n",
      "A2C Sharpe Ratio:  0.2086761101146743\n",
      "======Best Model Retraining from:  2010-04-01 to  2021-04-06\n",
      "======Trading from:  2021-04-06 to  2021-07-06\n",
      "[[1.00000000e+04 1.29873489e+02 4.58832581e+02 0.00000000e+00\n",
      "  0.00000000e+00 1.74376869e+00 4.65066528e+00 1.28886871e+02\n",
      "  4.69388184e+02 1.16377342e+02 4.13412140e+02 6.06304054e+01\n",
      "  5.49654083e+01 2.25215179e+02 1.10213188e+02 3.74220161e+01\n",
      "  6.06779385e+00 1.21544266e+02 4.39414581e+02 1.22726051e+02\n",
      "  4.38737152e+02]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "turbulence_threshold:  18.96231252984678\n",
      "======Model training from:  2010-04-01 to  2021-04-06\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.001}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c\\a2c_189_1\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 335         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.95       |\n",
      "|    explained_variance | 0.134       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -0.0459     |\n",
      "|    reward             | 0.023846036 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 0.00065     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 333          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 2            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -2.98        |\n",
      "|    explained_variance | -1.48        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -0.00165     |\n",
      "|    reward             | -0.026489466 |\n",
      "|    std                | 1.07         |\n",
      "|    value_loss         | 0.00237      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.02       |\n",
      "|    explained_variance | 0.124       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | 0.00548     |\n",
      "|    reward             | 0.032218903 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.00129     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.03       |\n",
      "|    explained_variance | 0.361       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | 0.0175      |\n",
      "|    reward             | -0.01305681 |\n",
      "|    std                | 1.1         |\n",
      "|    value_loss         | 0.00123     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 328        |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.06      |\n",
      "|    explained_variance | -2.6       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | 1.3        |\n",
      "|    reward             | -0.4714802 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 0.334      |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 600           |\n",
      "|    time_elapsed       | 9             |\n",
      "|    total_timesteps    | 3000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.04         |\n",
      "|    explained_variance | -40           |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 599           |\n",
      "|    policy_loss        | -0.335        |\n",
      "|    reward             | -0.0025904025 |\n",
      "|    std                | 1.11          |\n",
      "|    value_loss         | 0.0157        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 327           |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 10            |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.08         |\n",
      "|    explained_variance | 1.5e-05       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 699           |\n",
      "|    policy_loss        | -0.135        |\n",
      "|    reward             | -0.0038536205 |\n",
      "|    std                | 1.13          |\n",
      "|    value_loss         | 0.0012        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 12           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.1         |\n",
      "|    explained_variance | -211         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | -0.435       |\n",
      "|    reward             | -0.008344532 |\n",
      "|    std                | 1.14         |\n",
      "|    value_loss         | 0.0268       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 900          |\n",
      "|    time_elapsed       | 13           |\n",
      "|    total_timesteps    | 4500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.12        |\n",
      "|    explained_variance | -0.00018     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 899          |\n",
      "|    policy_loss        | 0.0253       |\n",
      "|    reward             | 0.0003379593 |\n",
      "|    std                | 1.15         |\n",
      "|    value_loss         | 0.000275     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 327           |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 15            |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.16         |\n",
      "|    explained_variance | 9.54e-06      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | 0.00832       |\n",
      "|    reward             | -0.0025324402 |\n",
      "|    std                | 1.17          |\n",
      "|    value_loss         | 0.000277      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 326         |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 16          |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.17       |\n",
      "|    explained_variance | 0.482       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | -0.281      |\n",
      "|    reward             | 0.008972778 |\n",
      "|    std                | 1.18        |\n",
      "|    value_loss         | 0.00543     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 326         |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.21       |\n",
      "|    explained_variance | 0.00395     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | 0.0447      |\n",
      "|    reward             | 0.019928988 |\n",
      "|    std                | 1.21        |\n",
      "|    value_loss         | 0.000219    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.27        |\n",
      "|    explained_variance | -0.0494      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | 0.0472       |\n",
      "|    reward             | 0.0031356488 |\n",
      "|    std                | 1.24         |\n",
      "|    value_loss         | 0.000344     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.32        |\n",
      "|    explained_variance | -0.035       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | -0.207       |\n",
      "|    reward             | -0.020360878 |\n",
      "|    std                | 1.28         |\n",
      "|    value_loss         | 0.00547      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.4         |\n",
      "|    explained_variance | 1.28e-05     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | 0.184        |\n",
      "|    reward             | -0.031579133 |\n",
      "|    std                | 1.33         |\n",
      "|    value_loss         | 0.00273      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 1600        |\n",
      "|    time_elapsed       | 24          |\n",
      "|    total_timesteps    | 8000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.46       |\n",
      "|    explained_variance | 0.195       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1599        |\n",
      "|    policy_loss        | -0.0272     |\n",
      "|    reward             | 0.002930168 |\n",
      "|    std                | 1.37        |\n",
      "|    value_loss         | 0.0001      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 25           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.48        |\n",
      "|    explained_variance | -0.53        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | 0.111        |\n",
      "|    reward             | -0.011524441 |\n",
      "|    std                | 1.38         |\n",
      "|    value_loss         | 0.00119      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.53        |\n",
      "|    explained_variance | 0.166        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | 0.319        |\n",
      "|    reward             | -0.008763931 |\n",
      "|    std                | 1.42         |\n",
      "|    value_loss         | 0.00465      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.58       |\n",
      "|    explained_variance | 0.526       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | -0.186      |\n",
      "|    reward             | 0.052084815 |\n",
      "|    std                | 1.45        |\n",
      "|    value_loss         | 0.00354     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 327           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 30            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.65         |\n",
      "|    explained_variance | 0.0505        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | 0.117         |\n",
      "|    reward             | -0.0065421197 |\n",
      "|    std                | 1.5           |\n",
      "|    value_loss         | 0.00117       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 327         |\n",
      "|    iterations         | 2100        |\n",
      "|    time_elapsed       | 32          |\n",
      "|    total_timesteps    | 10500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.72       |\n",
      "|    explained_variance | 5.1e-05     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2099        |\n",
      "|    policy_loss        | 0.359       |\n",
      "|    reward             | -0.07006238 |\n",
      "|    std                | 1.56        |\n",
      "|    value_loss         | 0.00921     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 326         |\n",
      "|    iterations         | 2200        |\n",
      "|    time_elapsed       | 33          |\n",
      "|    total_timesteps    | 11000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.79       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2199        |\n",
      "|    policy_loss        | 0.822       |\n",
      "|    reward             | -0.03379543 |\n",
      "|    std                | 1.61        |\n",
      "|    value_loss         | 0.0465      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 326          |\n",
      "|    iterations         | 2300         |\n",
      "|    time_elapsed       | 35           |\n",
      "|    total_timesteps    | 11500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.8         |\n",
      "|    explained_variance | 0.108        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2299         |\n",
      "|    policy_loss        | -0.0185      |\n",
      "|    reward             | -0.004524414 |\n",
      "|    std                | 1.62         |\n",
      "|    value_loss         | 0.000652     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 2400         |\n",
      "|    time_elapsed       | 36           |\n",
      "|    total_timesteps    | 12000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.83        |\n",
      "|    explained_variance | 0.599        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2399         |\n",
      "|    policy_loss        | 0.00235      |\n",
      "|    reward             | -0.022414062 |\n",
      "|    std                | 1.64         |\n",
      "|    value_loss         | 0.000152     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 325          |\n",
      "|    iterations         | 2500         |\n",
      "|    time_elapsed       | 38           |\n",
      "|    total_timesteps    | 12500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.88        |\n",
      "|    explained_variance | -0.272       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2499         |\n",
      "|    policy_loss        | 0.485        |\n",
      "|    reward             | -0.061792966 |\n",
      "|    std                | 1.69         |\n",
      "|    value_loss         | 0.0145       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 325        |\n",
      "|    iterations         | 2600       |\n",
      "|    time_elapsed       | 39         |\n",
      "|    total_timesteps    | 13000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.89      |\n",
      "|    explained_variance | 0.127      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 2599       |\n",
      "|    policy_loss        | 0.392      |\n",
      "|    reward             | 0.01681726 |\n",
      "|    std                | 1.69       |\n",
      "|    value_loss         | 0.0262     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 326        |\n",
      "|    iterations         | 2700       |\n",
      "|    time_elapsed       | 41         |\n",
      "|    total_timesteps    | 13500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.89      |\n",
      "|    explained_variance | 0.019      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 2699       |\n",
      "|    policy_loss        | 0.148      |\n",
      "|    reward             | 0.15406494 |\n",
      "|    std                | 1.69       |\n",
      "|    value_loss         | 0.0107     |\n",
      "--------------------------------------\n",
      "day: 2770, episode: 5\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 143688.42\n",
      "total_reward: 133688.42\n",
      "total_cost: 24.99\n",
      "total_trades: 5522\n",
      "Sharpe: 0.959\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 326          |\n",
      "|    iterations         | 2800         |\n",
      "|    time_elapsed       | 42           |\n",
      "|    total_timesteps    | 14000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.91        |\n",
      "|    explained_variance | -2.17        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2799         |\n",
      "|    policy_loss        | -0.333       |\n",
      "|    reward             | 0.0050527477 |\n",
      "|    std                | 1.71         |\n",
      "|    value_loss         | 0.00678      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 325          |\n",
      "|    iterations         | 2900         |\n",
      "|    time_elapsed       | 44           |\n",
      "|    total_timesteps    | 14500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.93        |\n",
      "|    explained_variance | -1.4         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2899         |\n",
      "|    policy_loss        | -0.321       |\n",
      "|    reward             | -0.020714097 |\n",
      "|    std                | 1.73         |\n",
      "|    value_loss         | 0.00777      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 325         |\n",
      "|    iterations         | 3000        |\n",
      "|    time_elapsed       | 46          |\n",
      "|    total_timesteps    | 15000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.97       |\n",
      "|    explained_variance | 0.333       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2999        |\n",
      "|    policy_loss        | -0.779      |\n",
      "|    reward             | 0.035432257 |\n",
      "|    std                | 1.76        |\n",
      "|    value_loss         | 0.0416      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 325          |\n",
      "|    iterations         | 3100         |\n",
      "|    time_elapsed       | 47           |\n",
      "|    total_timesteps    | 15500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.01        |\n",
      "|    explained_variance | 0.497        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 3099         |\n",
      "|    policy_loss        | 0.379        |\n",
      "|    reward             | -0.016579468 |\n",
      "|    std                | 1.79         |\n",
      "|    value_loss         | 0.00966      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 325         |\n",
      "|    iterations         | 3200        |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 16000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.03       |\n",
      "|    explained_variance | 0.00219     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3199        |\n",
      "|    policy_loss        | 0.168       |\n",
      "|    reward             | -0.07133699 |\n",
      "|    std                | 1.82        |\n",
      "|    value_loss         | 0.0029      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 325         |\n",
      "|    iterations         | 3300        |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 16500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.05       |\n",
      "|    explained_variance | 0.016       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3299        |\n",
      "|    policy_loss        | 0.0236      |\n",
      "|    reward             | -0.30868036 |\n",
      "|    std                | 1.83        |\n",
      "|    value_loss         | 0.0122      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 325        |\n",
      "|    iterations         | 3400       |\n",
      "|    time_elapsed       | 52         |\n",
      "|    total_timesteps    | 17000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.08      |\n",
      "|    explained_variance | -0.362     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 3399       |\n",
      "|    policy_loss        | 0.214      |\n",
      "|    reward             | 0.03188835 |\n",
      "|    std                | 1.86       |\n",
      "|    value_loss         | 0.0104     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 324        |\n",
      "|    iterations         | 3500       |\n",
      "|    time_elapsed       | 53         |\n",
      "|    total_timesteps    | 17500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.1       |\n",
      "|    explained_variance | -1.64      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 3499       |\n",
      "|    policy_loss        | 0.0784     |\n",
      "|    reward             | 0.04087911 |\n",
      "|    std                | 1.88       |\n",
      "|    value_loss         | 0.00102    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 325         |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 55          |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.12       |\n",
      "|    explained_variance | -0.0674     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3599        |\n",
      "|    policy_loss        | 0.446       |\n",
      "|    reward             | -0.08928617 |\n",
      "|    std                | 1.9         |\n",
      "|    value_loss         | 0.0295      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 325        |\n",
      "|    iterations         | 3700       |\n",
      "|    time_elapsed       | 56         |\n",
      "|    total_timesteps    | 18500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.14      |\n",
      "|    explained_variance | 0.117      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 3699       |\n",
      "|    policy_loss        | 1.02       |\n",
      "|    reward             | 0.15304625 |\n",
      "|    std                | 1.92       |\n",
      "|    value_loss         | 0.0704     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 3800        |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 19000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.13       |\n",
      "|    explained_variance | 0.209       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3799        |\n",
      "|    policy_loss        | 0.608       |\n",
      "|    reward             | 0.045852285 |\n",
      "|    std                | 1.91        |\n",
      "|    value_loss         | 0.0715      |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 321            |\n",
      "|    iterations         | 3900           |\n",
      "|    time_elapsed       | 60             |\n",
      "|    total_timesteps    | 19500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -4.16          |\n",
      "|    explained_variance | -466           |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 3899           |\n",
      "|    policy_loss        | -0.452         |\n",
      "|    reward             | -0.00040433617 |\n",
      "|    std                | 1.93           |\n",
      "|    value_loss         | 0.0467         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 4000         |\n",
      "|    time_elapsed       | 62           |\n",
      "|    total_timesteps    | 20000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.17        |\n",
      "|    explained_variance | 0.091        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 3999         |\n",
      "|    policy_loss        | -0.0554      |\n",
      "|    reward             | 0.0063419756 |\n",
      "|    std                | 1.95         |\n",
      "|    value_loss         | 0.00025      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 4100         |\n",
      "|    time_elapsed       | 63           |\n",
      "|    total_timesteps    | 20500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.2         |\n",
      "|    explained_variance | -0.109       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4099         |\n",
      "|    policy_loss        | -0.014       |\n",
      "|    reward             | 0.0027006103 |\n",
      "|    std                | 1.97         |\n",
      "|    value_loss         | 3.5e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 4200         |\n",
      "|    time_elapsed       | 65           |\n",
      "|    total_timesteps    | 21000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.23        |\n",
      "|    explained_variance | -0.892       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4199         |\n",
      "|    policy_loss        | 0.205        |\n",
      "|    reward             | 0.0039586434 |\n",
      "|    std                | 2            |\n",
      "|    value_loss         | 0.00229      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 4300         |\n",
      "|    time_elapsed       | 66           |\n",
      "|    total_timesteps    | 21500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.23        |\n",
      "|    explained_variance | 0.0307       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4299         |\n",
      "|    policy_loss        | -0.352       |\n",
      "|    reward             | -0.011330329 |\n",
      "|    std                | 2.01         |\n",
      "|    value_loss         | 0.0079       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 4400       |\n",
      "|    time_elapsed       | 68         |\n",
      "|    total_timesteps    | 22000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.22      |\n",
      "|    explained_variance | 0.18       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 4399       |\n",
      "|    policy_loss        | -0.253     |\n",
      "|    reward             | 0.07191474 |\n",
      "|    std                | 2          |\n",
      "|    value_loss         | 0.0046     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 4500         |\n",
      "|    time_elapsed       | 69           |\n",
      "|    total_timesteps    | 22500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.23        |\n",
      "|    explained_variance | 0.701        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4499         |\n",
      "|    policy_loss        | 0.0569       |\n",
      "|    reward             | -0.016069923 |\n",
      "|    std                | 2            |\n",
      "|    value_loss         | 0.000301     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 4600          |\n",
      "|    time_elapsed       | 71            |\n",
      "|    total_timesteps    | 23000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.26         |\n",
      "|    explained_variance | -0.271        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 4599          |\n",
      "|    policy_loss        | 0.0223        |\n",
      "|    reward             | -0.0052885986 |\n",
      "|    std                | 2.04          |\n",
      "|    value_loss         | 9.02e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 4700         |\n",
      "|    time_elapsed       | 72           |\n",
      "|    total_timesteps    | 23500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.31        |\n",
      "|    explained_variance | -0.279       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4699         |\n",
      "|    policy_loss        | -0.0874      |\n",
      "|    reward             | -0.013650634 |\n",
      "|    std                | 2.09         |\n",
      "|    value_loss         | 0.00236      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 4800        |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 24000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.36       |\n",
      "|    explained_variance | 0.186       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 4799        |\n",
      "|    policy_loss        | -0.073      |\n",
      "|    reward             | 0.053375147 |\n",
      "|    std                | 2.14        |\n",
      "|    value_loss         | 0.00103     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 4900         |\n",
      "|    time_elapsed       | 75           |\n",
      "|    total_timesteps    | 24500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.39        |\n",
      "|    explained_variance | -0.0171      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4899         |\n",
      "|    policy_loss        | 0.691        |\n",
      "|    reward             | -0.003293335 |\n",
      "|    std                | 2.18         |\n",
      "|    value_loss         | 0.0275       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 5000         |\n",
      "|    time_elapsed       | 77           |\n",
      "|    total_timesteps    | 25000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.4         |\n",
      "|    explained_variance | -8.7         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4999         |\n",
      "|    policy_loss        | -0.203       |\n",
      "|    reward             | -0.032904588 |\n",
      "|    std                | 2.18         |\n",
      "|    value_loss         | 0.00253      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 324        |\n",
      "|    iterations         | 5100       |\n",
      "|    time_elapsed       | 78         |\n",
      "|    total_timesteps    | 25500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.43      |\n",
      "|    explained_variance | -1.71      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 5099       |\n",
      "|    policy_loss        | -0.00742   |\n",
      "|    reward             | -0.0367464 |\n",
      "|    std                | 2.21       |\n",
      "|    value_loss         | 0.000276   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 5200         |\n",
      "|    time_elapsed       | 80           |\n",
      "|    total_timesteps    | 26000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.46        |\n",
      "|    explained_variance | 0.00033      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5199         |\n",
      "|    policy_loss        | -0.0691      |\n",
      "|    reward             | -0.016154002 |\n",
      "|    std                | 2.25         |\n",
      "|    value_loss         | 0.000276     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 5300        |\n",
      "|    time_elapsed       | 81          |\n",
      "|    total_timesteps    | 26500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.53       |\n",
      "|    explained_variance | -0.607      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5299        |\n",
      "|    policy_loss        | -0.15       |\n",
      "|    reward             | 0.002572999 |\n",
      "|    std                | 2.33        |\n",
      "|    value_loss         | 0.00163     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 5400       |\n",
      "|    time_elapsed       | 83         |\n",
      "|    total_timesteps    | 27000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.56      |\n",
      "|    explained_variance | -0.201     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 5399       |\n",
      "|    policy_loss        | -0.0966    |\n",
      "|    reward             | 0.03927935 |\n",
      "|    std                | 2.37       |\n",
      "|    value_loss         | 0.00245    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 5500       |\n",
      "|    time_elapsed       | 85         |\n",
      "|    total_timesteps    | 27500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.59      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 5499       |\n",
      "|    policy_loss        | 0.409      |\n",
      "|    reward             | 0.02724818 |\n",
      "|    std                | 2.41       |\n",
      "|    value_loss         | 0.0142     |\n",
      "--------------------------------------\n",
      "day: 2770, episode: 10\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 33984.09\n",
      "total_reward: 23984.09\n",
      "total_cost: 18.81\n",
      "total_trades: 3704\n",
      "Sharpe: 0.504\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 5600          |\n",
      "|    time_elapsed       | 86            |\n",
      "|    total_timesteps    | 28000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.62         |\n",
      "|    explained_variance | 0.469         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 5599          |\n",
      "|    policy_loss        | 0.0538        |\n",
      "|    reward             | -0.0019438728 |\n",
      "|    std                | 2.44          |\n",
      "|    value_loss         | 0.000329      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 5700          |\n",
      "|    time_elapsed       | 88            |\n",
      "|    total_timesteps    | 28500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.67         |\n",
      "|    explained_variance | -0.313        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 5699          |\n",
      "|    policy_loss        | 0.198         |\n",
      "|    reward             | -0.0074248835 |\n",
      "|    std                | 2.5           |\n",
      "|    value_loss         | 0.00174       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 5800        |\n",
      "|    time_elapsed       | 89          |\n",
      "|    total_timesteps    | 29000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.73       |\n",
      "|    explained_variance | 0.451       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5799        |\n",
      "|    policy_loss        | 0.0481      |\n",
      "|    reward             | 0.007944866 |\n",
      "|    std                | 2.58        |\n",
      "|    value_loss         | 9.97e-05    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 322            |\n",
      "|    iterations         | 5900           |\n",
      "|    time_elapsed       | 91             |\n",
      "|    total_timesteps    | 29500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -4.8           |\n",
      "|    explained_variance | -0.265         |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 5899           |\n",
      "|    policy_loss        | 0.104          |\n",
      "|    reward             | -0.00029551238 |\n",
      "|    std                | 2.67           |\n",
      "|    value_loss         | 0.000593       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 6000        |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 30000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.82       |\n",
      "|    explained_variance | 0.47        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5999        |\n",
      "|    policy_loss        | -0.0746     |\n",
      "|    reward             | 0.011059816 |\n",
      "|    std                | 2.69        |\n",
      "|    value_loss         | 0.000552    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 6100        |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 30500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.87       |\n",
      "|    explained_variance | -32.3       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 6099        |\n",
      "|    policy_loss        | 0.216       |\n",
      "|    reward             | 0.009045594 |\n",
      "|    std                | 2.77        |\n",
      "|    value_loss         | 0.00337     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 6200         |\n",
      "|    time_elapsed       | 95           |\n",
      "|    total_timesteps    | 31000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.93        |\n",
      "|    explained_variance | 0.261        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6199         |\n",
      "|    policy_loss        | -0.0475      |\n",
      "|    reward             | -0.009076974 |\n",
      "|    std                | 2.85         |\n",
      "|    value_loss         | 0.000188     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 6300         |\n",
      "|    time_elapsed       | 97           |\n",
      "|    total_timesteps    | 31500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.99        |\n",
      "|    explained_variance | -0.233       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6299         |\n",
      "|    policy_loss        | -0.119       |\n",
      "|    reward             | -0.006680374 |\n",
      "|    std                | 2.94         |\n",
      "|    value_loss         | 0.000705     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 6400        |\n",
      "|    time_elapsed       | 99          |\n",
      "|    total_timesteps    | 32000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.07       |\n",
      "|    explained_variance | 0.376       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 6399        |\n",
      "|    policy_loss        | 0.0192      |\n",
      "|    reward             | 0.007711348 |\n",
      "|    std                | 3.05        |\n",
      "|    value_loss         | 3.59e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 6500         |\n",
      "|    time_elapsed       | 101          |\n",
      "|    total_timesteps    | 32500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.13        |\n",
      "|    explained_variance | -0.0151      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6499         |\n",
      "|    policy_loss        | -0.102       |\n",
      "|    reward             | 0.0027725967 |\n",
      "|    std                | 3.15         |\n",
      "|    value_loss         | 0.000883     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 6600         |\n",
      "|    time_elapsed       | 102          |\n",
      "|    total_timesteps    | 33000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.18        |\n",
      "|    explained_variance | -0.154       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6599         |\n",
      "|    policy_loss        | -0.45        |\n",
      "|    reward             | -0.032083955 |\n",
      "|    std                | 3.23         |\n",
      "|    value_loss         | 0.0149       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 6700        |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 33500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.21       |\n",
      "|    explained_variance | 0.858       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 6699        |\n",
      "|    policy_loss        | -0.0448     |\n",
      "|    reward             | 0.004341343 |\n",
      "|    std                | 3.27        |\n",
      "|    value_loss         | 0.000129    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 6800         |\n",
      "|    time_elapsed       | 105          |\n",
      "|    total_timesteps    | 34000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.25        |\n",
      "|    explained_variance | -0.936       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6799         |\n",
      "|    policy_loss        | -0.0379      |\n",
      "|    reward             | -0.009876976 |\n",
      "|    std                | 3.34         |\n",
      "|    value_loss         | 8e-05        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 321            |\n",
      "|    iterations         | 6900           |\n",
      "|    time_elapsed       | 107            |\n",
      "|    total_timesteps    | 34500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -5.3           |\n",
      "|    explained_variance | -1.85          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 6899           |\n",
      "|    policy_loss        | 0.127          |\n",
      "|    reward             | -0.00021106796 |\n",
      "|    std                | 3.43           |\n",
      "|    value_loss         | 0.000778       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 7000         |\n",
      "|    time_elapsed       | 108          |\n",
      "|    total_timesteps    | 35000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.36        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6999         |\n",
      "|    policy_loss        | -0.216       |\n",
      "|    reward             | 0.0076357666 |\n",
      "|    std                | 3.53         |\n",
      "|    value_loss         | 0.00136      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 7100         |\n",
      "|    time_elapsed       | 110          |\n",
      "|    total_timesteps    | 35500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.37        |\n",
      "|    explained_variance | 0.376        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 7099         |\n",
      "|    policy_loss        | 0.551        |\n",
      "|    reward             | -0.008943496 |\n",
      "|    std                | 3.56         |\n",
      "|    value_loss         | 0.00982      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 7200       |\n",
      "|    time_elapsed       | 112        |\n",
      "|    total_timesteps    | 36000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.41      |\n",
      "|    explained_variance | -0.0513    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 7199       |\n",
      "|    policy_loss        | -0.167     |\n",
      "|    reward             | 0.05590351 |\n",
      "|    std                | 3.64       |\n",
      "|    value_loss         | 0.00445    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 7300         |\n",
      "|    time_elapsed       | 113          |\n",
      "|    total_timesteps    | 36500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.46        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 7299         |\n",
      "|    policy_loss        | -0.0685      |\n",
      "|    reward             | 0.0010501568 |\n",
      "|    std                | 3.71         |\n",
      "|    value_loss         | 0.000263     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 7400        |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 37000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.5        |\n",
      "|    explained_variance | 0.866       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7399        |\n",
      "|    policy_loss        | 0.00582     |\n",
      "|    reward             | 0.016329445 |\n",
      "|    std                | 3.79        |\n",
      "|    value_loss         | 1.5e-05     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 7500        |\n",
      "|    time_elapsed       | 116         |\n",
      "|    total_timesteps    | 37500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.57       |\n",
      "|    explained_variance | -2.53       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7499        |\n",
      "|    policy_loss        | -0.0682     |\n",
      "|    reward             | 0.010895343 |\n",
      "|    std                | 3.93        |\n",
      "|    value_loss         | 0.000238    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 7600          |\n",
      "|    time_elapsed       | 118           |\n",
      "|    total_timesteps    | 38000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.65         |\n",
      "|    explained_variance | 0.233         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 7599          |\n",
      "|    policy_loss        | -0.164        |\n",
      "|    reward             | -0.0031570403 |\n",
      "|    std                | 4.09          |\n",
      "|    value_loss         | 0.00103       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 7700        |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 38500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.69       |\n",
      "|    explained_variance | 0.021       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7699        |\n",
      "|    policy_loss        | -0.386      |\n",
      "|    reward             | 0.020728404 |\n",
      "|    std                | 4.18        |\n",
      "|    value_loss         | 0.00533     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 7800         |\n",
      "|    time_elapsed       | 121          |\n",
      "|    total_timesteps    | 39000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.74        |\n",
      "|    explained_variance | -0.0446      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 7799         |\n",
      "|    policy_loss        | 0.0953       |\n",
      "|    reward             | -0.002358286 |\n",
      "|    std                | 4.29         |\n",
      "|    value_loss         | 0.000347     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 7900        |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 39500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.78       |\n",
      "|    explained_variance | 0.179       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7899        |\n",
      "|    policy_loss        | 0.0692      |\n",
      "|    reward             | 0.013887597 |\n",
      "|    std                | 4.37        |\n",
      "|    value_loss         | 0.000404    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 8000         |\n",
      "|    time_elapsed       | 125          |\n",
      "|    total_timesteps    | 40000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.83        |\n",
      "|    explained_variance | 0.529        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 7999         |\n",
      "|    policy_loss        | 0.167        |\n",
      "|    reward             | -0.046030544 |\n",
      "|    std                | 4.47         |\n",
      "|    value_loss         | 0.0012       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 8100        |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 40500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.89       |\n",
      "|    explained_variance | 0.238       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 8099        |\n",
      "|    policy_loss        | 0.072       |\n",
      "|    reward             | 0.004777362 |\n",
      "|    std                | 4.62        |\n",
      "|    value_loss         | 0.000397    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 318        |\n",
      "|    iterations         | 8200       |\n",
      "|    time_elapsed       | 128        |\n",
      "|    total_timesteps    | 41000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.92      |\n",
      "|    explained_variance | 0.0912     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 8199       |\n",
      "|    policy_loss        | 0.379      |\n",
      "|    reward             | 0.06750107 |\n",
      "|    std                | 4.68       |\n",
      "|    value_loss         | 0.0096     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 8300        |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 41500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.95       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 8299        |\n",
      "|    policy_loss        | -0.275      |\n",
      "|    reward             | 0.018813964 |\n",
      "|    std                | 4.75        |\n",
      "|    value_loss         | 0.00355     |\n",
      "---------------------------------------\n",
      "day: 2770, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 65865.13\n",
      "total_reward: 55865.13\n",
      "total_cost: 11.18\n",
      "total_trades: 5528\n",
      "Sharpe: 0.749\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 131         |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.97       |\n",
      "|    explained_variance | 0.57        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 8399        |\n",
      "|    policy_loss        | -0.265      |\n",
      "|    reward             | 0.038296647 |\n",
      "|    std                | 4.8         |\n",
      "|    value_loss         | 0.00215     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 8500        |\n",
      "|    time_elapsed       | 133         |\n",
      "|    total_timesteps    | 42500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.99       |\n",
      "|    explained_variance | 0.0104      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 8499        |\n",
      "|    policy_loss        | 0.193       |\n",
      "|    reward             | 0.030026343 |\n",
      "|    std                | 4.86        |\n",
      "|    value_loss         | 0.00157     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 8600         |\n",
      "|    time_elapsed       | 134          |\n",
      "|    total_timesteps    | 43000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.04        |\n",
      "|    explained_variance | 0.0263       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 8599         |\n",
      "|    policy_loss        | -0.111       |\n",
      "|    reward             | -0.041925903 |\n",
      "|    std                | 4.99         |\n",
      "|    value_loss         | 0.00181      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 8700         |\n",
      "|    time_elapsed       | 136          |\n",
      "|    total_timesteps    | 43500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.09        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 8699         |\n",
      "|    policy_loss        | -0.273       |\n",
      "|    reward             | 2.942505e-05 |\n",
      "|    std                | 5.09         |\n",
      "|    value_loss         | 0.00237      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 8800         |\n",
      "|    time_elapsed       | 138          |\n",
      "|    total_timesteps    | 44000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.13        |\n",
      "|    explained_variance | -9.54e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 8799         |\n",
      "|    policy_loss        | 0.322        |\n",
      "|    reward             | -0.005831085 |\n",
      "|    std                | 5.21         |\n",
      "|    value_loss         | 0.00321      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 318           |\n",
      "|    iterations         | 8900          |\n",
      "|    time_elapsed       | 139           |\n",
      "|    total_timesteps    | 44500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.13         |\n",
      "|    explained_variance | -0.106        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 8899          |\n",
      "|    policy_loss        | -0.071        |\n",
      "|    reward             | -0.0143646095 |\n",
      "|    std                | 5.21          |\n",
      "|    value_loss         | 0.000168      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 9000        |\n",
      "|    time_elapsed       | 141         |\n",
      "|    total_timesteps    | 45000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.17       |\n",
      "|    explained_variance | 0.461       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 8999        |\n",
      "|    policy_loss        | -0.0711     |\n",
      "|    reward             | 0.029172687 |\n",
      "|    std                | 5.31        |\n",
      "|    value_loss         | 0.000189    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 9100         |\n",
      "|    time_elapsed       | 143          |\n",
      "|    total_timesteps    | 45500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.22        |\n",
      "|    explained_variance | 0.213        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 9099         |\n",
      "|    policy_loss        | 0.179        |\n",
      "|    reward             | 0.0001259552 |\n",
      "|    std                | 5.43         |\n",
      "|    value_loss         | 0.000959     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 9200         |\n",
      "|    time_elapsed       | 144          |\n",
      "|    total_timesteps    | 46000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.29        |\n",
      "|    explained_variance | 0.62         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 9199         |\n",
      "|    policy_loss        | 0.0536       |\n",
      "|    reward             | -0.002216687 |\n",
      "|    std                | 5.63         |\n",
      "|    value_loss         | 8.74e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 9300        |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 46500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.36       |\n",
      "|    explained_variance | 0.157       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9299        |\n",
      "|    policy_loss        | -0.0528     |\n",
      "|    reward             | 0.014798564 |\n",
      "|    std                | 5.84        |\n",
      "|    value_loss         | 0.000971    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 9400        |\n",
      "|    time_elapsed       | 147         |\n",
      "|    total_timesteps    | 47000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.4        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9399        |\n",
      "|    policy_loss        | 0.0481      |\n",
      "|    reward             | 0.012157565 |\n",
      "|    std                | 5.97        |\n",
      "|    value_loss         | 0.000606    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 317        |\n",
      "|    iterations         | 9500       |\n",
      "|    time_elapsed       | 149        |\n",
      "|    total_timesteps    | 47500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.42      |\n",
      "|    explained_variance | 0.478      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 9499       |\n",
      "|    policy_loss        | -0.227     |\n",
      "|    reward             | 0.02819955 |\n",
      "|    std                | 6.02       |\n",
      "|    value_loss         | 0.00178    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 317         |\n",
      "|    iterations         | 9600        |\n",
      "|    time_elapsed       | 151         |\n",
      "|    total_timesteps    | 48000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.44       |\n",
      "|    explained_variance | -0.403      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9599        |\n",
      "|    policy_loss        | -0.0688     |\n",
      "|    reward             | 0.031453963 |\n",
      "|    std                | 6.08        |\n",
      "|    value_loss         | 0.000687    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 317         |\n",
      "|    iterations         | 9700        |\n",
      "|    time_elapsed       | 152         |\n",
      "|    total_timesteps    | 48500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.47       |\n",
      "|    explained_variance | 0.32        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9699        |\n",
      "|    policy_loss        | 0.303       |\n",
      "|    reward             | 0.014098132 |\n",
      "|    std                | 6.2         |\n",
      "|    value_loss         | 0.00274     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 317        |\n",
      "|    iterations         | 9800       |\n",
      "|    time_elapsed       | 154        |\n",
      "|    total_timesteps    | 49000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.47      |\n",
      "|    explained_variance | 0.204      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 9799       |\n",
      "|    policy_loss        | -0.231     |\n",
      "|    reward             | 0.01594847 |\n",
      "|    std                | 6.19       |\n",
      "|    value_loss         | 0.00295    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 9900         |\n",
      "|    time_elapsed       | 156          |\n",
      "|    total_timesteps    | 49500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.5         |\n",
      "|    explained_variance | 4.59e-06     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 9899         |\n",
      "|    policy_loss        | 0.0838       |\n",
      "|    reward             | -0.010129375 |\n",
      "|    std                | 6.3          |\n",
      "|    value_loss         | 0.00104      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 10000       |\n",
      "|    time_elapsed       | 157         |\n",
      "|    total_timesteps    | 50000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.55       |\n",
      "|    explained_variance | 0.382       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9999        |\n",
      "|    policy_loss        | 0.171       |\n",
      "|    reward             | 0.039659742 |\n",
      "|    std                | 6.43        |\n",
      "|    value_loss         | 0.000939    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 316           |\n",
      "|    iterations         | 10100         |\n",
      "|    time_elapsed       | 159           |\n",
      "|    total_timesteps    | 50500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.58         |\n",
      "|    explained_variance | 0.522         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 10099         |\n",
      "|    policy_loss        | -0.186        |\n",
      "|    reward             | -0.0017162907 |\n",
      "|    std                | 6.52          |\n",
      "|    value_loss         | 0.000806      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 10200       |\n",
      "|    time_elapsed       | 161         |\n",
      "|    total_timesteps    | 51000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.62       |\n",
      "|    explained_variance | -0.039      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10199       |\n",
      "|    policy_loss        | -0.00252    |\n",
      "|    reward             | 0.008476925 |\n",
      "|    std                | 6.69        |\n",
      "|    value_loss         | 2.63e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 10300       |\n",
      "|    time_elapsed       | 162         |\n",
      "|    total_timesteps    | 51500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.68       |\n",
      "|    explained_variance | -0.66       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10299       |\n",
      "|    policy_loss        | -0.151      |\n",
      "|    reward             | -0.13397914 |\n",
      "|    std                | 6.89        |\n",
      "|    value_loss         | 0.000889    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 10400        |\n",
      "|    time_elapsed       | 164          |\n",
      "|    total_timesteps    | 52000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.72        |\n",
      "|    explained_variance | 0.26         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 10399        |\n",
      "|    policy_loss        | 0.42         |\n",
      "|    reward             | 0.0041083205 |\n",
      "|    std                | 7.05         |\n",
      "|    value_loss         | 0.004        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 10500       |\n",
      "|    time_elapsed       | 166         |\n",
      "|    total_timesteps    | 52500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.74       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10499       |\n",
      "|    policy_loss        | 0.053       |\n",
      "|    reward             | 0.039408334 |\n",
      "|    std                | 7.11        |\n",
      "|    value_loss         | 0.000144    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 10600        |\n",
      "|    time_elapsed       | 167          |\n",
      "|    total_timesteps    | 53000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.76        |\n",
      "|    explained_variance | 0.856        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 10599        |\n",
      "|    policy_loss        | 0.0362       |\n",
      "|    reward             | -0.008461297 |\n",
      "|    std                | 7.17         |\n",
      "|    value_loss         | 7.63e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 316           |\n",
      "|    iterations         | 10700         |\n",
      "|    time_elapsed       | 169           |\n",
      "|    total_timesteps    | 53500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.79         |\n",
      "|    explained_variance | -6.58         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 10699         |\n",
      "|    policy_loss        | 0.0802        |\n",
      "|    reward             | -0.0015472204 |\n",
      "|    std                | 7.29          |\n",
      "|    value_loss         | 0.000195      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 10800       |\n",
      "|    time_elapsed       | 170         |\n",
      "|    total_timesteps    | 54000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.81       |\n",
      "|    explained_variance | -0.0031     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10799       |\n",
      "|    policy_loss        | -0.284      |\n",
      "|    reward             | -0.01712955 |\n",
      "|    std                | 7.36        |\n",
      "|    value_loss         | 0.00168     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 10900        |\n",
      "|    time_elapsed       | 172          |\n",
      "|    total_timesteps    | 54500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.85        |\n",
      "|    explained_variance | 0.203        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 10899        |\n",
      "|    policy_loss        | -0.307       |\n",
      "|    reward             | -0.015575941 |\n",
      "|    std                | 7.52         |\n",
      "|    value_loss         | 0.00312      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 11000       |\n",
      "|    time_elapsed       | 173         |\n",
      "|    total_timesteps    | 55000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.89       |\n",
      "|    explained_variance | 3.1e-05     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10999       |\n",
      "|    policy_loss        | 0.0775      |\n",
      "|    reward             | -0.13255008 |\n",
      "|    std                | 7.69        |\n",
      "|    value_loss         | 0.000725    |\n",
      "---------------------------------------\n",
      "day: 2770, episode: 20\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 65634.32\n",
      "total_reward: 55634.32\n",
      "total_cost: 13.94\n",
      "total_trades: 5525\n",
      "Sharpe: 0.693\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 11100        |\n",
      "|    time_elapsed       | 175          |\n",
      "|    total_timesteps    | 55500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.92        |\n",
      "|    explained_variance | 0.397        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11099        |\n",
      "|    policy_loss        | -0.093       |\n",
      "|    reward             | -0.012192157 |\n",
      "|    std                | 7.8          |\n",
      "|    value_loss         | 0.000289     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 317        |\n",
      "|    iterations         | 11200      |\n",
      "|    time_elapsed       | 176        |\n",
      "|    total_timesteps    | 56000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.94      |\n",
      "|    explained_variance | 0.206      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 11199      |\n",
      "|    policy_loss        | -0.165     |\n",
      "|    reward             | 0.03146653 |\n",
      "|    std                | 7.85       |\n",
      "|    value_loss         | 0.000911   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 317         |\n",
      "|    iterations         | 11300       |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 56500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.97       |\n",
      "|    explained_variance | 0.211       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 11299       |\n",
      "|    policy_loss        | -0.15       |\n",
      "|    reward             | -0.04194276 |\n",
      "|    std                | 7.97        |\n",
      "|    value_loss         | 0.000639    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 317       |\n",
      "|    iterations         | 11400     |\n",
      "|    time_elapsed       | 179       |\n",
      "|    total_timesteps    | 57000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.01     |\n",
      "|    explained_variance | 0.223     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 11399     |\n",
      "|    policy_loss        | -0.0606   |\n",
      "|    reward             | 0.0331778 |\n",
      "|    std                | 8.11      |\n",
      "|    value_loss         | 0.00448   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 317         |\n",
      "|    iterations         | 11500       |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 57500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.03       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 11499       |\n",
      "|    policy_loss        | -0.888      |\n",
      "|    reward             | 0.041718423 |\n",
      "|    std                | 8.25        |\n",
      "|    value_loss         | 0.0269      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 317        |\n",
      "|    iterations         | 11600      |\n",
      "|    time_elapsed       | 182        |\n",
      "|    total_timesteps    | 58000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.05      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 11599      |\n",
      "|    policy_loss        | -0.842     |\n",
      "|    reward             | -0.0515934 |\n",
      "|    std                | 8.31       |\n",
      "|    value_loss         | 0.0205     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 317         |\n",
      "|    iterations         | 11700       |\n",
      "|    time_elapsed       | 184         |\n",
      "|    total_timesteps    | 58500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.06       |\n",
      "|    explained_variance | -0.883      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 11699       |\n",
      "|    policy_loss        | 0.0175      |\n",
      "|    reward             | 0.028845571 |\n",
      "|    std                | 8.37        |\n",
      "|    value_loss         | 6.88e-05    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 317          |\n",
      "|    iterations         | 11800        |\n",
      "|    time_elapsed       | 185          |\n",
      "|    total_timesteps    | 59000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.08        |\n",
      "|    explained_variance | -2.75        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11799        |\n",
      "|    policy_loss        | -0.151       |\n",
      "|    reward             | -0.011791495 |\n",
      "|    std                | 8.47         |\n",
      "|    value_loss         | 0.000549     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 317         |\n",
      "|    iterations         | 11900       |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 59500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.13       |\n",
      "|    explained_variance | -0.752      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 11899       |\n",
      "|    policy_loss        | -0.829      |\n",
      "|    reward             | 0.042894837 |\n",
      "|    std                | 8.67        |\n",
      "|    value_loss         | 0.0175      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 317         |\n",
      "|    iterations         | 12000       |\n",
      "|    time_elapsed       | 188         |\n",
      "|    total_timesteps    | 60000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.15       |\n",
      "|    explained_variance | 0.000204    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 11999       |\n",
      "|    policy_loss        | -0.693      |\n",
      "|    reward             | 0.010702735 |\n",
      "|    std                | 8.8         |\n",
      "|    value_loss         | 0.00961     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 317          |\n",
      "|    iterations         | 12100        |\n",
      "|    time_elapsed       | 190          |\n",
      "|    total_timesteps    | 60500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.18        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 12099        |\n",
      "|    policy_loss        | -1.21        |\n",
      "|    reward             | 0.0008274078 |\n",
      "|    std                | 8.96         |\n",
      "|    value_loss         | 0.0552       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 317         |\n",
      "|    iterations         | 12200       |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 61000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.22       |\n",
      "|    explained_variance | -0.628      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12199       |\n",
      "|    policy_loss        | -0.436      |\n",
      "|    reward             | 0.012547992 |\n",
      "|    std                | 9.13        |\n",
      "|    value_loss         | 0.00636     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 317          |\n",
      "|    iterations         | 12300        |\n",
      "|    time_elapsed       | 193          |\n",
      "|    total_timesteps    | 61500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.23        |\n",
      "|    explained_variance | -0.68        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 12299        |\n",
      "|    policy_loss        | -0.207       |\n",
      "|    reward             | -0.020317234 |\n",
      "|    std                | 9.18         |\n",
      "|    value_loss         | 0.00137      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 12400       |\n",
      "|    time_elapsed       | 194         |\n",
      "|    total_timesteps    | 62000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.26       |\n",
      "|    explained_variance | 0.553       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12399       |\n",
      "|    policy_loss        | 0.0697      |\n",
      "|    reward             | 0.017360972 |\n",
      "|    std                | 9.29        |\n",
      "|    value_loss         | 0.0002      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 12500        |\n",
      "|    time_elapsed       | 196          |\n",
      "|    total_timesteps    | 62500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.29        |\n",
      "|    explained_variance | -0.0474      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 12499        |\n",
      "|    policy_loss        | -0.679       |\n",
      "|    reward             | 0.0074090245 |\n",
      "|    std                | 9.41         |\n",
      "|    value_loss         | 0.00859      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 318        |\n",
      "|    iterations         | 12600      |\n",
      "|    time_elapsed       | 197        |\n",
      "|    total_timesteps    | 63000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.34      |\n",
      "|    explained_variance | -0.0978    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 12599      |\n",
      "|    policy_loss        | -0.507     |\n",
      "|    reward             | 0.06816221 |\n",
      "|    std                | 9.63       |\n",
      "|    value_loss         | 0.00588    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 12700       |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 63500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.35       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12699       |\n",
      "|    policy_loss        | 0.302       |\n",
      "|    reward             | -0.21372297 |\n",
      "|    std                | 9.69        |\n",
      "|    value_loss         | 0.0193      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 12800       |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 64000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.37       |\n",
      "|    explained_variance | 0.232       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12799       |\n",
      "|    policy_loss        | 0.116       |\n",
      "|    reward             | 0.017954472 |\n",
      "|    std                | 9.81        |\n",
      "|    value_loss         | 0.000416    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 12900        |\n",
      "|    time_elapsed       | 202          |\n",
      "|    total_timesteps    | 64500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.41        |\n",
      "|    explained_variance | 0.763        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 12899        |\n",
      "|    policy_loss        | 0.337        |\n",
      "|    reward             | 0.0035933552 |\n",
      "|    std                | 9.99         |\n",
      "|    value_loss         | 0.00202      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 13000       |\n",
      "|    time_elapsed       | 204         |\n",
      "|    total_timesteps    | 65000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.43       |\n",
      "|    explained_variance | -0.118      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12999       |\n",
      "|    policy_loss        | -0.114      |\n",
      "|    reward             | 0.025000473 |\n",
      "|    std                | 10.1        |\n",
      "|    value_loss         | 0.00025     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 318           |\n",
      "|    iterations         | 13100         |\n",
      "|    time_elapsed       | 205           |\n",
      "|    total_timesteps    | 65500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.45         |\n",
      "|    explained_variance | -0.317        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 13099         |\n",
      "|    policy_loss        | -0.246        |\n",
      "|    reward             | -0.0060493657 |\n",
      "|    std                | 10.2          |\n",
      "|    value_loss         | 0.00109       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 13200        |\n",
      "|    time_elapsed       | 207          |\n",
      "|    total_timesteps    | 66000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.48        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 13199        |\n",
      "|    policy_loss        | -0.0532      |\n",
      "|    reward             | -0.059423584 |\n",
      "|    std                | 10.4         |\n",
      "|    value_loss         | 0.00394      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 13300       |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 66500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.51       |\n",
      "|    explained_variance | 2.4e-05     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13299       |\n",
      "|    policy_loss        | -1.03       |\n",
      "|    reward             | -0.16280179 |\n",
      "|    std                | 10.5        |\n",
      "|    value_loss         | 0.0236      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 13400        |\n",
      "|    time_elapsed       | 210          |\n",
      "|    total_timesteps    | 67000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.53        |\n",
      "|    explained_variance | 0.686        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 13399        |\n",
      "|    policy_loss        | 0.125        |\n",
      "|    reward             | -0.008841655 |\n",
      "|    std                | 10.6         |\n",
      "|    value_loss         | 0.000248     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 318       |\n",
      "|    iterations         | 13500     |\n",
      "|    time_elapsed       | 211       |\n",
      "|    total_timesteps    | 67500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.58     |\n",
      "|    explained_variance | -0.256    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 13499     |\n",
      "|    policy_loss        | -0.0477   |\n",
      "|    reward             | 0.0159738 |\n",
      "|    std                | 10.9      |\n",
      "|    value_loss         | 9.73e-05  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 318        |\n",
      "|    iterations         | 13600      |\n",
      "|    time_elapsed       | 213        |\n",
      "|    total_timesteps    | 68000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.63      |\n",
      "|    explained_variance | 0.432      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 13599      |\n",
      "|    policy_loss        | 0.122      |\n",
      "|    reward             | 0.02415708 |\n",
      "|    std                | 11.2       |\n",
      "|    value_loss         | 0.000363   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 13700      |\n",
      "|    time_elapsed       | 214        |\n",
      "|    total_timesteps    | 68500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.71      |\n",
      "|    explained_variance | 0.159      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 13699      |\n",
      "|    policy_loss        | -0.317     |\n",
      "|    reward             | 0.04538689 |\n",
      "|    std                | 11.6       |\n",
      "|    value_loss         | 0.00211    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 13800        |\n",
      "|    time_elapsed       | 216          |\n",
      "|    total_timesteps    | 69000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.8         |\n",
      "|    explained_variance | 0.462        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 13799        |\n",
      "|    policy_loss        | -0.694       |\n",
      "|    reward             | -0.024425536 |\n",
      "|    std                | 12.1         |\n",
      "|    value_loss         | 0.00957      |\n",
      "----------------------------------------\n",
      "day: 2770, episode: 25\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 24919.26\n",
      "total_reward: 14919.26\n",
      "total_cost: 16.26\n",
      "total_trades: 4107\n",
      "Sharpe: 0.427\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 13900        |\n",
      "|    time_elapsed       | 217          |\n",
      "|    total_timesteps    | 69500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.85        |\n",
      "|    explained_variance | -0.0443      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 13899        |\n",
      "|    policy_loss        | 0.136        |\n",
      "|    reward             | -0.026315259 |\n",
      "|    std                | 12.4         |\n",
      "|    value_loss         | 0.000351     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 14000       |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 70000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.88       |\n",
      "|    explained_variance | -0.409      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13999       |\n",
      "|    policy_loss        | -0.0834     |\n",
      "|    reward             | 0.011849865 |\n",
      "|    std                | 12.6        |\n",
      "|    value_loss         | 0.00013     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 14100      |\n",
      "|    time_elapsed       | 220        |\n",
      "|    total_timesteps    | 70500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.94      |\n",
      "|    explained_variance | 0.109      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 14099      |\n",
      "|    policy_loss        | 0.16       |\n",
      "|    reward             | 0.02719641 |\n",
      "|    std                | 13         |\n",
      "|    value_loss         | 0.000765   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 319           |\n",
      "|    iterations         | 14200         |\n",
      "|    time_elapsed       | 222           |\n",
      "|    total_timesteps    | 71000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.98         |\n",
      "|    explained_variance | 0.0305        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 14199         |\n",
      "|    policy_loss        | -0.201        |\n",
      "|    reward             | -0.0004440632 |\n",
      "|    std                | 13.3          |\n",
      "|    value_loss         | 0.00145       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 14300       |\n",
      "|    time_elapsed       | 224         |\n",
      "|    total_timesteps    | 71500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.01       |\n",
      "|    explained_variance | 0.0259      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14299       |\n",
      "|    policy_loss        | 0.6         |\n",
      "|    reward             | 0.054594513 |\n",
      "|    std                | 13.5        |\n",
      "|    value_loss         | 0.00813     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 14400      |\n",
      "|    time_elapsed       | 225        |\n",
      "|    total_timesteps    | 72000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.07      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 14399      |\n",
      "|    policy_loss        | 0.911      |\n",
      "|    reward             | 0.12389074 |\n",
      "|    std                | 13.9       |\n",
      "|    value_loss         | 0.0174     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 14500        |\n",
      "|    time_elapsed       | 226          |\n",
      "|    total_timesteps    | 72500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.11        |\n",
      "|    explained_variance | -3.36        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 14499        |\n",
      "|    policy_loss        | 0.00186      |\n",
      "|    reward             | 0.0011648354 |\n",
      "|    std                | 14.2         |\n",
      "|    value_loss         | 0.00254      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 14600       |\n",
      "|    time_elapsed       | 228         |\n",
      "|    total_timesteps    | 73000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.14       |\n",
      "|    explained_variance | 0.268       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14599       |\n",
      "|    policy_loss        | 0.0773      |\n",
      "|    reward             | 0.027926048 |\n",
      "|    std                | 14.4        |\n",
      "|    value_loss         | 0.000131    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 14700        |\n",
      "|    time_elapsed       | 230          |\n",
      "|    total_timesteps    | 73500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.18        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 14699        |\n",
      "|    policy_loss        | -0.882       |\n",
      "|    reward             | -0.011126167 |\n",
      "|    std                | 14.7         |\n",
      "|    value_loss         | 0.0112       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 318           |\n",
      "|    iterations         | 14800         |\n",
      "|    time_elapsed       | 231           |\n",
      "|    total_timesteps    | 74000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.2          |\n",
      "|    explained_variance | 0.506         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 14799         |\n",
      "|    policy_loss        | -0.349        |\n",
      "|    reward             | -0.0058961455 |\n",
      "|    std                | 14.9          |\n",
      "|    value_loss         | 0.00282       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 14900       |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 74500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.25       |\n",
      "|    explained_variance | 0.632       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14899       |\n",
      "|    policy_loss        | -0.24       |\n",
      "|    reward             | 0.046797328 |\n",
      "|    std                | 15.3        |\n",
      "|    value_loss         | 0.00113     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 15000        |\n",
      "|    time_elapsed       | 235          |\n",
      "|    total_timesteps    | 75000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.26        |\n",
      "|    explained_variance | -19          |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 14999        |\n",
      "|    policy_loss        | 0.241        |\n",
      "|    reward             | 0.0024736298 |\n",
      "|    std                | 15.4         |\n",
      "|    value_loss         | 0.00223      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 15100       |\n",
      "|    time_elapsed       | 236         |\n",
      "|    total_timesteps    | 75500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.3        |\n",
      "|    explained_variance | -0.264      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15099       |\n",
      "|    policy_loss        | -2.54e-06   |\n",
      "|    reward             | 0.019475004 |\n",
      "|    std                | 15.7        |\n",
      "|    value_loss         | 3.86e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 15200       |\n",
      "|    time_elapsed       | 238         |\n",
      "|    total_timesteps    | 76000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.34       |\n",
      "|    explained_variance | 0.0591      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15199       |\n",
      "|    policy_loss        | 1.19        |\n",
      "|    reward             | 0.023545878 |\n",
      "|    std                | 16          |\n",
      "|    value_loss         | 0.0206      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 15300        |\n",
      "|    time_elapsed       | 239          |\n",
      "|    total_timesteps    | 76500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.35        |\n",
      "|    explained_variance | -0.083       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 15299        |\n",
      "|    policy_loss        | -0.143       |\n",
      "|    reward             | -0.019087752 |\n",
      "|    std                | 16.1         |\n",
      "|    value_loss         | 0.00128      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 15400       |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 77000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.36       |\n",
      "|    explained_variance | 0.0238      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15399       |\n",
      "|    policy_loss        | -0.256      |\n",
      "|    reward             | 0.036563817 |\n",
      "|    std                | 16.2        |\n",
      "|    value_loss         | 0.00626     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 15500        |\n",
      "|    time_elapsed       | 242          |\n",
      "|    total_timesteps    | 77500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.4         |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 15499        |\n",
      "|    policy_loss        | 0.114        |\n",
      "|    reward             | -0.029970573 |\n",
      "|    std                | 16.5         |\n",
      "|    value_loss         | 0.00545      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 15600       |\n",
      "|    time_elapsed       | 244         |\n",
      "|    total_timesteps    | 78000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.42       |\n",
      "|    explained_variance | 0.508       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15599       |\n",
      "|    policy_loss        | -0.165      |\n",
      "|    reward             | -0.01188865 |\n",
      "|    std                | 16.7        |\n",
      "|    value_loss         | 0.000478    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 15700       |\n",
      "|    time_elapsed       | 245         |\n",
      "|    total_timesteps    | 78500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.44       |\n",
      "|    explained_variance | 0.146       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15699       |\n",
      "|    policy_loss        | 0.0341      |\n",
      "|    reward             | 0.004102939 |\n",
      "|    std                | 16.9        |\n",
      "|    value_loss         | 2.4e-05     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 15800       |\n",
      "|    time_elapsed       | 247         |\n",
      "|    total_timesteps    | 79000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.46       |\n",
      "|    explained_variance | 0.00142     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15799       |\n",
      "|    policy_loss        | 0.194       |\n",
      "|    reward             | -0.05566238 |\n",
      "|    std                | 17.1        |\n",
      "|    value_loss         | 0.00232     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 15900        |\n",
      "|    time_elapsed       | 249          |\n",
      "|    total_timesteps    | 79500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.53        |\n",
      "|    explained_variance | -0.618       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 15899        |\n",
      "|    policy_loss        | -0.484       |\n",
      "|    reward             | 0.0047304747 |\n",
      "|    std                | 17.6         |\n",
      "|    value_loss         | 0.0035       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 16000      |\n",
      "|    time_elapsed       | 250        |\n",
      "|    total_timesteps    | 80000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.54      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 15999      |\n",
      "|    policy_loss        | -1.37      |\n",
      "|    reward             | 0.03878422 |\n",
      "|    std                | 17.8       |\n",
      "|    value_loss         | 0.0271     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 16100       |\n",
      "|    time_elapsed       | 252         |\n",
      "|    total_timesteps    | 80500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.56       |\n",
      "|    explained_variance | 0.145       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16099       |\n",
      "|    policy_loss        | -0.0114     |\n",
      "|    reward             | 0.000344582 |\n",
      "|    std                | 18          |\n",
      "|    value_loss         | 2.68e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 319           |\n",
      "|    iterations         | 16200         |\n",
      "|    time_elapsed       | 253           |\n",
      "|    total_timesteps    | 81000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.59         |\n",
      "|    explained_variance | -1.82         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 16199         |\n",
      "|    policy_loss        | 0.0222        |\n",
      "|    reward             | 0.00024013576 |\n",
      "|    std                | 18.2          |\n",
      "|    value_loss         | 1.02e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 16300        |\n",
      "|    time_elapsed       | 255          |\n",
      "|    total_timesteps    | 81500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.64        |\n",
      "|    explained_variance | -0.235       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 16299        |\n",
      "|    policy_loss        | -0.0264      |\n",
      "|    reward             | -0.013780157 |\n",
      "|    std                | 18.7         |\n",
      "|    value_loss         | 0.000113     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 16400       |\n",
      "|    time_elapsed       | 256         |\n",
      "|    total_timesteps    | 82000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.71       |\n",
      "|    explained_variance | 0.569       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16399       |\n",
      "|    policy_loss        | -0.0287     |\n",
      "|    reward             | 0.003878538 |\n",
      "|    std                | 19.4        |\n",
      "|    value_loss         | 3.08e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 318           |\n",
      "|    iterations         | 16500         |\n",
      "|    time_elapsed       | 258           |\n",
      "|    total_timesteps    | 82500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.78         |\n",
      "|    explained_variance | -0.0044       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 16499         |\n",
      "|    policy_loss        | 0.0856        |\n",
      "|    reward             | 0.00082603836 |\n",
      "|    std                | 20            |\n",
      "|    value_loss         | 0.000428      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 318        |\n",
      "|    iterations         | 16600      |\n",
      "|    time_elapsed       | 260        |\n",
      "|    total_timesteps    | 83000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.83      |\n",
      "|    explained_variance | 0.37       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 16599      |\n",
      "|    policy_loss        | -0.414     |\n",
      "|    reward             | 0.05806027 |\n",
      "|    std                | 20.5       |\n",
      "|    value_loss         | 0.0021     |\n",
      "--------------------------------------\n",
      "day: 2770, episode: 30\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 33055.84\n",
      "total_reward: 23055.84\n",
      "total_cost: 13.58\n",
      "total_trades: 5537\n",
      "Sharpe: 0.542\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 16700        |\n",
      "|    time_elapsed       | 261          |\n",
      "|    total_timesteps    | 83500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.87        |\n",
      "|    explained_variance | -0.00314     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 16699        |\n",
      "|    policy_loss        | 0.118        |\n",
      "|    reward             | -0.010237377 |\n",
      "|    std                | 20.9         |\n",
      "|    value_loss         | 0.00025      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 16800       |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 84000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.93       |\n",
      "|    explained_variance | -0.0252     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16799       |\n",
      "|    policy_loss        | 0.0624      |\n",
      "|    reward             | 0.003104351 |\n",
      "|    std                | 21.6        |\n",
      "|    value_loss         | 6.79e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 16900        |\n",
      "|    time_elapsed       | 264          |\n",
      "|    total_timesteps    | 84500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.01        |\n",
      "|    explained_variance | 0.0501       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 16899        |\n",
      "|    policy_loss        | 0.0524       |\n",
      "|    reward             | 0.0075727724 |\n",
      "|    std                | 22.5         |\n",
      "|    value_loss         | 0.000347     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 17000        |\n",
      "|    time_elapsed       | 266          |\n",
      "|    total_timesteps    | 85000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.11        |\n",
      "|    explained_variance | 0.671        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 16999        |\n",
      "|    policy_loss        | -0.136       |\n",
      "|    reward             | -0.009888884 |\n",
      "|    std                | 23.6         |\n",
      "|    value_loss         | 0.000291     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 17100       |\n",
      "|    time_elapsed       | 267         |\n",
      "|    total_timesteps    | 85500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.19       |\n",
      "|    explained_variance | 0.405       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17099       |\n",
      "|    policy_loss        | -0.405      |\n",
      "|    reward             | 0.003461628 |\n",
      "|    std                | 24.6        |\n",
      "|    value_loss         | 0.00202     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 17200        |\n",
      "|    time_elapsed       | 269          |\n",
      "|    total_timesteps    | 86000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.22        |\n",
      "|    explained_variance | 0.629        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 17199        |\n",
      "|    policy_loss        | -0.197       |\n",
      "|    reward             | -0.008191101 |\n",
      "|    std                | 24.9         |\n",
      "|    value_loss         | 0.000624     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 17300       |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 86500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.26       |\n",
      "|    explained_variance | 0.302       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17299       |\n",
      "|    policy_loss        | 0.222       |\n",
      "|    reward             | 0.002816241 |\n",
      "|    std                | 25.4        |\n",
      "|    value_loss         | 0.000672    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 17400       |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 87000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.33       |\n",
      "|    explained_variance | 0.287       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17399       |\n",
      "|    policy_loss        | -0.11       |\n",
      "|    reward             | 0.011859431 |\n",
      "|    std                | 26.2        |\n",
      "|    value_loss         | 0.000191    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 17500        |\n",
      "|    time_elapsed       | 274          |\n",
      "|    total_timesteps    | 87500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.36        |\n",
      "|    explained_variance | 0.000369     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 17499        |\n",
      "|    policy_loss        | 0.102        |\n",
      "|    reward             | -0.018028332 |\n",
      "|    std                | 26.6         |\n",
      "|    value_loss         | 0.000578     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 17600        |\n",
      "|    time_elapsed       | 276          |\n",
      "|    total_timesteps    | 88000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.38        |\n",
      "|    explained_variance | 0.416        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 17599        |\n",
      "|    policy_loss        | 0.625        |\n",
      "|    reward             | 0.0026720322 |\n",
      "|    std                | 26.8         |\n",
      "|    value_loss         | 0.00696      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 318       |\n",
      "|    iterations         | 17700     |\n",
      "|    time_elapsed       | 277       |\n",
      "|    total_timesteps    | 88500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.43     |\n",
      "|    explained_variance | 0.235     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 17699     |\n",
      "|    policy_loss        | 0.165     |\n",
      "|    reward             | 0.0490098 |\n",
      "|    std                | 27.5      |\n",
      "|    value_loss         | 0.000994  |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 318           |\n",
      "|    iterations         | 17800         |\n",
      "|    time_elapsed       | 279           |\n",
      "|    total_timesteps    | 89000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -9.46         |\n",
      "|    explained_variance | 0.225         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 17799         |\n",
      "|    policy_loss        | -0.216        |\n",
      "|    reward             | -0.0020761136 |\n",
      "|    std                | 28.1          |\n",
      "|    value_loss         | 0.000998      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 17900        |\n",
      "|    time_elapsed       | 280          |\n",
      "|    total_timesteps    | 89500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.49        |\n",
      "|    explained_variance | 0.58         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 17899        |\n",
      "|    policy_loss        | -0.015       |\n",
      "|    reward             | 0.0006651009 |\n",
      "|    std                | 28.4         |\n",
      "|    value_loss         | 5.35e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 318          |\n",
      "|    iterations         | 18000        |\n",
      "|    time_elapsed       | 282          |\n",
      "|    total_timesteps    | 90000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.52        |\n",
      "|    explained_variance | -0.141       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 17999        |\n",
      "|    policy_loss        | -0.159       |\n",
      "|    reward             | -0.010801953 |\n",
      "|    std                | 28.7         |\n",
      "|    value_loss         | 0.00136      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 318        |\n",
      "|    iterations         | 18100      |\n",
      "|    time_elapsed       | 283        |\n",
      "|    total_timesteps    | 90500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.53      |\n",
      "|    explained_variance | 0.154      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 18099      |\n",
      "|    policy_loss        | -0.428     |\n",
      "|    reward             | 0.05968694 |\n",
      "|    std                | 28.9       |\n",
      "|    value_loss         | 0.00655    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 18200       |\n",
      "|    time_elapsed       | 285         |\n",
      "|    total_timesteps    | 91000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.52       |\n",
      "|    explained_variance | 0.198       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18199       |\n",
      "|    policy_loss        | -0.131      |\n",
      "|    reward             | -0.09495372 |\n",
      "|    std                | 28.8        |\n",
      "|    value_loss         | 0.00095     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 18300       |\n",
      "|    time_elapsed       | 286         |\n",
      "|    total_timesteps    | 91500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.54       |\n",
      "|    explained_variance | -1.69       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18299       |\n",
      "|    policy_loss        | 0.176       |\n",
      "|    reward             | 0.004623114 |\n",
      "|    std                | 29          |\n",
      "|    value_loss         | 0.000451    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 18400       |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 92000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.57       |\n",
      "|    explained_variance | 0.577       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18399       |\n",
      "|    policy_loss        | 0.325       |\n",
      "|    reward             | 0.018091056 |\n",
      "|    std                | 29.4        |\n",
      "|    value_loss         | 0.00134     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 18500        |\n",
      "|    time_elapsed       | 289          |\n",
      "|    total_timesteps    | 92500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.6         |\n",
      "|    explained_variance | -0.0147      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 18499        |\n",
      "|    policy_loss        | 0.026        |\n",
      "|    reward             | -0.005703608 |\n",
      "|    std                | 29.9         |\n",
      "|    value_loss         | 4.21e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 18600        |\n",
      "|    time_elapsed       | 291          |\n",
      "|    total_timesteps    | 93000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.65        |\n",
      "|    explained_variance | 0.176        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 18599        |\n",
      "|    policy_loss        | 0.194        |\n",
      "|    reward             | -0.018116813 |\n",
      "|    std                | 30.7         |\n",
      "|    value_loss         | 0.00069      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 18700      |\n",
      "|    time_elapsed       | 292        |\n",
      "|    total_timesteps    | 93500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.7       |\n",
      "|    explained_variance | 0.253      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 18699      |\n",
      "|    policy_loss        | 1.6        |\n",
      "|    reward             | 0.04677473 |\n",
      "|    std                | 31.4       |\n",
      "|    value_loss         | 0.0306     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 18800      |\n",
      "|    time_elapsed       | 294        |\n",
      "|    total_timesteps    | 94000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.71      |\n",
      "|    explained_variance | 0.391      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 18799      |\n",
      "|    policy_loss        | 0.51       |\n",
      "|    reward             | 0.19296595 |\n",
      "|    std                | 31.6       |\n",
      "|    value_loss         | 0.0135     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 319           |\n",
      "|    iterations         | 18900         |\n",
      "|    time_elapsed       | 295           |\n",
      "|    total_timesteps    | 94500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -9.75         |\n",
      "|    explained_variance | -7.22         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 18899         |\n",
      "|    policy_loss        | 0.188         |\n",
      "|    reward             | -0.0050740032 |\n",
      "|    std                | 32.3          |\n",
      "|    value_loss         | 0.00046       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 19000        |\n",
      "|    time_elapsed       | 297          |\n",
      "|    total_timesteps    | 95000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.77        |\n",
      "|    explained_variance | 0.523        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 18999        |\n",
      "|    policy_loss        | 0.0632       |\n",
      "|    reward             | -0.006375991 |\n",
      "|    std                | 32.6         |\n",
      "|    value_loss         | 5.39e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 19100        |\n",
      "|    time_elapsed       | 299          |\n",
      "|    total_timesteps    | 95500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.81        |\n",
      "|    explained_variance | -45.1        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 19099        |\n",
      "|    policy_loss        | 0.425        |\n",
      "|    reward             | -0.009265775 |\n",
      "|    std                | 33.2         |\n",
      "|    value_loss         | 0.00484      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 19200        |\n",
      "|    time_elapsed       | 300          |\n",
      "|    total_timesteps    | 96000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.86        |\n",
      "|    explained_variance | 0.819        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 19199        |\n",
      "|    policy_loss        | -0.0244      |\n",
      "|    reward             | 0.0019251526 |\n",
      "|    std                | 34.1         |\n",
      "|    value_loss         | 2.5e-05      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 19300       |\n",
      "|    time_elapsed       | 302         |\n",
      "|    total_timesteps    | 96500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.92       |\n",
      "|    explained_variance | 0.195       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19299       |\n",
      "|    policy_loss        | 0.0994      |\n",
      "|    reward             | 0.007076684 |\n",
      "|    std                | 35.2        |\n",
      "|    value_loss         | 0.000102    |\n",
      "---------------------------------------\n",
      "day: 2770, episode: 35\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 23288.68\n",
      "total_reward: 13288.68\n",
      "total_cost: 13.03\n",
      "total_trades: 5533\n",
      "Sharpe: 0.450\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 19400        |\n",
      "|    time_elapsed       | 303          |\n",
      "|    total_timesteps    | 97000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.97        |\n",
      "|    explained_variance | -493         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 19399        |\n",
      "|    policy_loss        | -1.56        |\n",
      "|    reward             | 0.0034296615 |\n",
      "|    std                | 36.1         |\n",
      "|    value_loss         | 0.0546       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 19500       |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 97500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10         |\n",
      "|    explained_variance | 0.309       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19499       |\n",
      "|    policy_loss        | -0.27       |\n",
      "|    reward             | 0.011343951 |\n",
      "|    std                | 37          |\n",
      "|    value_loss         | 0.000859    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 19600        |\n",
      "|    time_elapsed       | 306          |\n",
      "|    total_timesteps    | 98000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.1        |\n",
      "|    explained_variance | 0.854        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 19599        |\n",
      "|    policy_loss        | -0.0435      |\n",
      "|    reward             | -0.002104898 |\n",
      "|    std                | 38.2         |\n",
      "|    value_loss         | 2.62e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 19700        |\n",
      "|    time_elapsed       | 308          |\n",
      "|    total_timesteps    | 98500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.1        |\n",
      "|    explained_variance | -0.0223      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 19699        |\n",
      "|    policy_loss        | 0.153        |\n",
      "|    reward             | 0.0017521179 |\n",
      "|    std                | 39.4         |\n",
      "|    value_loss         | 0.000283     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 319           |\n",
      "|    iterations         | 19800         |\n",
      "|    time_elapsed       | 309           |\n",
      "|    total_timesteps    | 99000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.2         |\n",
      "|    explained_variance | 0.214         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 19799         |\n",
      "|    policy_loss        | -0.376        |\n",
      "|    reward             | 0.00076548156 |\n",
      "|    std                | 40.3          |\n",
      "|    value_loss         | 0.00232       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 19900       |\n",
      "|    time_elapsed       | 311         |\n",
      "|    total_timesteps    | 99500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.3       |\n",
      "|    explained_variance | 0.0658      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19899       |\n",
      "|    policy_loss        | -0.936      |\n",
      "|    reward             | 0.050402746 |\n",
      "|    std                | 41.6        |\n",
      "|    value_loss         | 0.0123      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 20000       |\n",
      "|    time_elapsed       | 312         |\n",
      "|    total_timesteps    | 100000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.3       |\n",
      "|    explained_variance | 0.1         |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19999       |\n",
      "|    policy_loss        | -0.235      |\n",
      "|    reward             | 0.019030267 |\n",
      "|    std                | 42          |\n",
      "|    value_loss         | 0.000748    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 20100        |\n",
      "|    time_elapsed       | 314          |\n",
      "|    total_timesteps    | 100500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.3        |\n",
      "|    explained_variance | 0.697        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20099        |\n",
      "|    policy_loss        | 0.131        |\n",
      "|    reward             | -0.019605683 |\n",
      "|    std                | 42.8         |\n",
      "|    value_loss         | 0.000214     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 20200       |\n",
      "|    time_elapsed       | 316         |\n",
      "|    total_timesteps    | 101000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.4       |\n",
      "|    explained_variance | 0.0038      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20199       |\n",
      "|    policy_loss        | 0.263       |\n",
      "|    reward             | 0.038423795 |\n",
      "|    std                | 43.9        |\n",
      "|    value_loss         | 0.000991    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 20300       |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 101500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.4       |\n",
      "|    explained_variance | 0.0863      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20299       |\n",
      "|    policy_loss        | -0.568      |\n",
      "|    reward             | 0.034282148 |\n",
      "|    std                | 44.6        |\n",
      "|    value_loss         | 0.00507     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 20400       |\n",
      "|    time_elapsed       | 319         |\n",
      "|    total_timesteps    | 102000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20399       |\n",
      "|    policy_loss        | -0.896      |\n",
      "|    reward             | 0.055220753 |\n",
      "|    std                | 44.9        |\n",
      "|    value_loss         | 0.0136      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 20500      |\n",
      "|    time_elapsed       | 320        |\n",
      "|    total_timesteps    | 102500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 20499      |\n",
      "|    policy_loss        | 0.134      |\n",
      "|    reward             | -0.7361132 |\n",
      "|    std                | 45.4       |\n",
      "|    value_loss         | 0.0374     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 20600        |\n",
      "|    time_elapsed       | 322          |\n",
      "|    total_timesteps    | 103000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.5        |\n",
      "|    explained_variance | -0.24        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20599        |\n",
      "|    policy_loss        | -0.013       |\n",
      "|    reward             | 0.0025645923 |\n",
      "|    std                | 46           |\n",
      "|    value_loss         | 5.72e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 20700       |\n",
      "|    time_elapsed       | 323         |\n",
      "|    total_timesteps    | 103500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.5       |\n",
      "|    explained_variance | 0.153       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20699       |\n",
      "|    policy_loss        | -0.155      |\n",
      "|    reward             | 0.009940084 |\n",
      "|    std                | 46.5        |\n",
      "|    value_loss         | 0.000529    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 20800       |\n",
      "|    time_elapsed       | 325         |\n",
      "|    total_timesteps    | 104000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.5       |\n",
      "|    explained_variance | 0.293       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20799       |\n",
      "|    policy_loss        | 1.03        |\n",
      "|    reward             | -0.08271165 |\n",
      "|    std                | 47.1        |\n",
      "|    value_loss         | 0.0118      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 20900       |\n",
      "|    time_elapsed       | 326         |\n",
      "|    total_timesteps    | 104500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.5       |\n",
      "|    explained_variance | 0.13        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20899       |\n",
      "|    policy_loss        | -1.03       |\n",
      "|    reward             | -0.10131177 |\n",
      "|    std                | 47.6        |\n",
      "|    value_loss         | 0.0115      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 21000        |\n",
      "|    time_elapsed       | 328          |\n",
      "|    total_timesteps    | 105000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.6        |\n",
      "|    explained_variance | 0.445        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20999        |\n",
      "|    policy_loss        | 0.462        |\n",
      "|    reward             | -0.007517163 |\n",
      "|    std                | 48           |\n",
      "|    value_loss         | 0.00216      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 21100       |\n",
      "|    time_elapsed       | 329         |\n",
      "|    total_timesteps    | 105500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.6       |\n",
      "|    explained_variance | -0.177      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21099       |\n",
      "|    policy_loss        | 0.316       |\n",
      "|    reward             | -0.04166603 |\n",
      "|    std                | 48.7        |\n",
      "|    value_loss         | 0.000786    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 21200        |\n",
      "|    time_elapsed       | 331          |\n",
      "|    total_timesteps    | 106000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.6        |\n",
      "|    explained_variance | 0.58         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 21199        |\n",
      "|    policy_loss        | 0.0905       |\n",
      "|    reward             | -0.014851423 |\n",
      "|    std                | 49.3         |\n",
      "|    value_loss         | 0.000214     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 21300       |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 106500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21299       |\n",
      "|    policy_loss        | -0.302      |\n",
      "|    reward             | 0.004191473 |\n",
      "|    std                | 49.8        |\n",
      "|    value_loss         | 0.000896    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 21400        |\n",
      "|    time_elapsed       | 334          |\n",
      "|    total_timesteps    | 107000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.7        |\n",
      "|    explained_variance | -0.0309      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 21399        |\n",
      "|    policy_loss        | 0.255        |\n",
      "|    reward             | 0.0035513726 |\n",
      "|    std                | 50.5         |\n",
      "|    value_loss         | 0.000875     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 21500       |\n",
      "|    time_elapsed       | 335         |\n",
      "|    total_timesteps    | 107500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.7       |\n",
      "|    explained_variance | 0.126       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21499       |\n",
      "|    policy_loss        | -2.17       |\n",
      "|    reward             | 0.058176383 |\n",
      "|    std                | 51.1        |\n",
      "|    value_loss         | 0.0468      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 21600       |\n",
      "|    time_elapsed       | 337         |\n",
      "|    total_timesteps    | 108000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21599       |\n",
      "|    policy_loss        | 1.4         |\n",
      "|    reward             | -0.11373801 |\n",
      "|    std                | 51.6        |\n",
      "|    value_loss         | 0.0208      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 319           |\n",
      "|    iterations         | 21700         |\n",
      "|    time_elapsed       | 339           |\n",
      "|    total_timesteps    | 108500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.7         |\n",
      "|    explained_variance | -15.8         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 21699         |\n",
      "|    policy_loss        | -0.127        |\n",
      "|    reward             | -0.0074421405 |\n",
      "|    std                | 51.7          |\n",
      "|    value_loss         | 0.000181      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 21800       |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 109000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.8       |\n",
      "|    explained_variance | -0.81       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21799       |\n",
      "|    policy_loss        | -0.0716     |\n",
      "|    reward             | -0.01065094 |\n",
      "|    std                | 52.7        |\n",
      "|    value_loss         | 9.05e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 21900       |\n",
      "|    time_elapsed       | 342         |\n",
      "|    total_timesteps    | 109500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.8       |\n",
      "|    explained_variance | 0.0013      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21899       |\n",
      "|    policy_loss        | 0.46        |\n",
      "|    reward             | 0.005625714 |\n",
      "|    std                | 53.7        |\n",
      "|    value_loss         | 0.00254     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 22000      |\n",
      "|    time_elapsed       | 343        |\n",
      "|    total_timesteps    | 110000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.8      |\n",
      "|    explained_variance | 0.193      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 21999      |\n",
      "|    policy_loss        | 0.135      |\n",
      "|    reward             | 0.07471215 |\n",
      "|    std                | 54.8       |\n",
      "|    value_loss         | 0.00204    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 22100        |\n",
      "|    time_elapsed       | 345          |\n",
      "|    total_timesteps    | 110500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 22099        |\n",
      "|    policy_loss        | 0.893        |\n",
      "|    reward             | -0.024471374 |\n",
      "|    std                | 56.1         |\n",
      "|    value_loss         | 0.00733      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2770, episode: 40\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 80309.43\n",
      "total_reward: 70309.43\n",
      "total_cost: 12.57\n",
      "total_trades: 5536\n",
      "Sharpe: 0.762\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 22200        |\n",
      "|    time_elapsed       | 346          |\n",
      "|    total_timesteps    | 111000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.9        |\n",
      "|    explained_variance | -1.04        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 22199        |\n",
      "|    policy_loss        | -0.351       |\n",
      "|    reward             | 0.0026498733 |\n",
      "|    std                | 55.6         |\n",
      "|    value_loss         | 0.00115      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 22300       |\n",
      "|    time_elapsed       | 348         |\n",
      "|    total_timesteps    | 111500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.9       |\n",
      "|    explained_variance | 0.853       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22299       |\n",
      "|    policy_loss        | 0.392       |\n",
      "|    reward             | -0.00849869 |\n",
      "|    std                | 55.9        |\n",
      "|    value_loss         | 0.00131     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 22400        |\n",
      "|    time_elapsed       | 349          |\n",
      "|    total_timesteps    | 112000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.9        |\n",
      "|    explained_variance | 0.63         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 22399        |\n",
      "|    policy_loss        | 0.141        |\n",
      "|    reward             | -0.012428476 |\n",
      "|    std                | 57.5         |\n",
      "|    value_loss         | 0.000201     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 22500         |\n",
      "|    time_elapsed       | 351           |\n",
      "|    total_timesteps    | 112500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11           |\n",
      "|    explained_variance | 0.197         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 22499         |\n",
      "|    policy_loss        | -0.516        |\n",
      "|    reward             | -0.0029238304 |\n",
      "|    std                | 59.3          |\n",
      "|    value_loss         | 0.00273       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 22600        |\n",
      "|    time_elapsed       | 353          |\n",
      "|    total_timesteps    | 113000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.1        |\n",
      "|    explained_variance | 0.831        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 22599        |\n",
      "|    policy_loss        | -0.347       |\n",
      "|    reward             | -0.017555336 |\n",
      "|    std                | 61.8         |\n",
      "|    value_loss         | 0.00113      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 22700        |\n",
      "|    time_elapsed       | 354          |\n",
      "|    total_timesteps    | 113500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 22699        |\n",
      "|    policy_loss        | 0.187        |\n",
      "|    reward             | -0.015839355 |\n",
      "|    std                | 62.9         |\n",
      "|    value_loss         | 0.000415     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 22800      |\n",
      "|    time_elapsed       | 356        |\n",
      "|    total_timesteps    | 114000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.1      |\n",
      "|    explained_variance | 0.155      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 22799      |\n",
      "|    policy_loss        | 0.0908     |\n",
      "|    reward             | 0.03203051 |\n",
      "|    std                | 64.1       |\n",
      "|    value_loss         | 0.000342   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 22900         |\n",
      "|    time_elapsed       | 357           |\n",
      "|    total_timesteps    | 114500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11.2         |\n",
      "|    explained_variance | 0.338         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 22899         |\n",
      "|    policy_loss        | 0.0123        |\n",
      "|    reward             | 0.00052067754 |\n",
      "|    std                | 65.5          |\n",
      "|    value_loss         | 1.47e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 23000       |\n",
      "|    time_elapsed       | 359         |\n",
      "|    total_timesteps    | 115000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.2       |\n",
      "|    explained_variance | 0.107       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22999       |\n",
      "|    policy_loss        | 0.288       |\n",
      "|    reward             | 0.032480054 |\n",
      "|    std                | 67.7        |\n",
      "|    value_loss         | 0.00297     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 23100        |\n",
      "|    time_elapsed       | 360          |\n",
      "|    total_timesteps    | 115500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.2        |\n",
      "|    explained_variance | 0.43         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23099        |\n",
      "|    policy_loss        | -1.97        |\n",
      "|    reward             | -0.024674347 |\n",
      "|    std                | 67.4         |\n",
      "|    value_loss         | 0.036        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 23200        |\n",
      "|    time_elapsed       | 362          |\n",
      "|    total_timesteps    | 116000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.2        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23199        |\n",
      "|    policy_loss        | -0.67        |\n",
      "|    reward             | -0.051714636 |\n",
      "|    std                | 67.4         |\n",
      "|    value_loss         | 0.00406      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 23300       |\n",
      "|    time_elapsed       | 363         |\n",
      "|    total_timesteps    | 116500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.3       |\n",
      "|    explained_variance | -0.0318     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 23299       |\n",
      "|    policy_loss        | 0.123       |\n",
      "|    reward             | 0.004955572 |\n",
      "|    std                | 67.8        |\n",
      "|    value_loss         | 0.000193    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 23400         |\n",
      "|    time_elapsed       | 365           |\n",
      "|    total_timesteps    | 117000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11.3         |\n",
      "|    explained_variance | -36.8         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 23399         |\n",
      "|    policy_loss        | -0.00347      |\n",
      "|    reward             | -0.0030145491 |\n",
      "|    std                | 68.7          |\n",
      "|    value_loss         | 3.23e-05      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 23500        |\n",
      "|    time_elapsed       | 367          |\n",
      "|    total_timesteps    | 117500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.3        |\n",
      "|    explained_variance | 0.0836       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23499        |\n",
      "|    policy_loss        | 0.114        |\n",
      "|    reward             | 0.0027801914 |\n",
      "|    std                | 70.2         |\n",
      "|    value_loss         | 0.000132     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 23600         |\n",
      "|    time_elapsed       | 368           |\n",
      "|    total_timesteps    | 118000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11.4         |\n",
      "|    explained_variance | -0.136        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 23599         |\n",
      "|    policy_loss        | -0.0423       |\n",
      "|    reward             | -0.0030650196 |\n",
      "|    std                | 72.6          |\n",
      "|    value_loss         | 8.65e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 23700        |\n",
      "|    time_elapsed       | 370          |\n",
      "|    total_timesteps    | 118500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.5        |\n",
      "|    explained_variance | -0.084       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23699        |\n",
      "|    policy_loss        | 0.0197       |\n",
      "|    reward             | 0.0049722823 |\n",
      "|    std                | 76.5         |\n",
      "|    value_loss         | 3.62e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 23800       |\n",
      "|    time_elapsed       | 371         |\n",
      "|    total_timesteps    | 119000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.6       |\n",
      "|    explained_variance | 0.0616      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 23799       |\n",
      "|    policy_loss        | 0.0021      |\n",
      "|    reward             | 0.012560295 |\n",
      "|    std                | 80.1        |\n",
      "|    value_loss         | 0.00014     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 23900        |\n",
      "|    time_elapsed       | 373          |\n",
      "|    total_timesteps    | 119500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.6        |\n",
      "|    explained_variance | 0.12         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23899        |\n",
      "|    policy_loss        | -0.688       |\n",
      "|    reward             | -0.028628638 |\n",
      "|    std                | 82.3         |\n",
      "|    value_loss         | 0.00962      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 24000       |\n",
      "|    time_elapsed       | 374         |\n",
      "|    total_timesteps    | 120000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.7       |\n",
      "|    explained_variance | 0.342       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 23999       |\n",
      "|    policy_loss        | 0.034       |\n",
      "|    reward             | 0.015185898 |\n",
      "|    std                | 83.6        |\n",
      "|    value_loss         | 0.000206    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 24100       |\n",
      "|    time_elapsed       | 376         |\n",
      "|    total_timesteps    | 120500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.7       |\n",
      "|    explained_variance | 0.0102      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 24099       |\n",
      "|    policy_loss        | -0.778      |\n",
      "|    reward             | -0.02313402 |\n",
      "|    std                | 85.6        |\n",
      "|    value_loss         | 0.00676     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 24200      |\n",
      "|    time_elapsed       | 377        |\n",
      "|    total_timesteps    | 121000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.7      |\n",
      "|    explained_variance | -0.481     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 24199      |\n",
      "|    policy_loss        | 0.611      |\n",
      "|    reward             | 0.15199584 |\n",
      "|    std                | 86.6       |\n",
      "|    value_loss         | 0.00362    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 24300        |\n",
      "|    time_elapsed       | 379          |\n",
      "|    total_timesteps    | 121500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.7        |\n",
      "|    explained_variance | 0.21         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 24299        |\n",
      "|    policy_loss        | 3.81         |\n",
      "|    reward             | -0.073829874 |\n",
      "|    std                | 86.1         |\n",
      "|    value_loss         | 0.124        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 24400         |\n",
      "|    time_elapsed       | 380           |\n",
      "|    total_timesteps    | 122000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11.8         |\n",
      "|    explained_variance | -1.95         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 24399         |\n",
      "|    policy_loss        | -0.225        |\n",
      "|    reward             | -0.0006393223 |\n",
      "|    std                | 87.2          |\n",
      "|    value_loss         | 0.000683      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 24500       |\n",
      "|    time_elapsed       | 382         |\n",
      "|    total_timesteps    | 122500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.8       |\n",
      "|    explained_variance | 0.0457      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 24499       |\n",
      "|    policy_loss        | -0.324      |\n",
      "|    reward             | 0.016916908 |\n",
      "|    std                | 88          |\n",
      "|    value_loss         | 0.00122     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 24600       |\n",
      "|    time_elapsed       | 383         |\n",
      "|    total_timesteps    | 123000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.8       |\n",
      "|    explained_variance | -4.89e-06   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 24599       |\n",
      "|    policy_loss        | 0.443       |\n",
      "|    reward             | 0.003019421 |\n",
      "|    std                | 89.9        |\n",
      "|    value_loss         | 0.0016      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 24700       |\n",
      "|    time_elapsed       | 385         |\n",
      "|    total_timesteps    | 123500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.9       |\n",
      "|    explained_variance | 0.161       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 24699       |\n",
      "|    policy_loss        | -1.05       |\n",
      "|    reward             | 0.022652475 |\n",
      "|    std                | 91.6        |\n",
      "|    value_loss         | 0.0193      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 24800        |\n",
      "|    time_elapsed       | 386          |\n",
      "|    total_timesteps    | 124000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.9        |\n",
      "|    explained_variance | 0.289        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 24799        |\n",
      "|    policy_loss        | -0.76        |\n",
      "|    reward             | -0.004144557 |\n",
      "|    std                | 93.3         |\n",
      "|    value_loss         | 0.00681      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 24900      |\n",
      "|    time_elapsed       | 388        |\n",
      "|    total_timesteps    | 124500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.9      |\n",
      "|    explained_variance | 0.0191     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 24899      |\n",
      "|    policy_loss        | 2.14       |\n",
      "|    reward             | 0.04455158 |\n",
      "|    std                | 93.7       |\n",
      "|    value_loss         | 0.0462     |\n",
      "--------------------------------------\n",
      "day: 2770, episode: 45\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 99646.58\n",
      "total_reward: 89646.58\n",
      "total_cost: 48.79\n",
      "total_trades: 5536\n",
      "Sharpe: 0.880\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 25000         |\n",
      "|    time_elapsed       | 389           |\n",
      "|    total_timesteps    | 125000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11.9         |\n",
      "|    explained_variance | -39           |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 24999         |\n",
      "|    policy_loss        | -1.31         |\n",
      "|    reward             | -0.0057188724 |\n",
      "|    std                | 95            |\n",
      "|    value_loss         | 0.0149        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 25100       |\n",
      "|    time_elapsed       | 391         |\n",
      "|    total_timesteps    | 125500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12         |\n",
      "|    explained_variance | -0.566      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25099       |\n",
      "|    policy_loss        | -0.336      |\n",
      "|    reward             | 0.033245098 |\n",
      "|    std                | 95.9        |\n",
      "|    value_loss         | 0.000905    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 25200       |\n",
      "|    time_elapsed       | 392         |\n",
      "|    total_timesteps    | 126000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12         |\n",
      "|    explained_variance | -0.031      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25199       |\n",
      "|    policy_loss        | 0.519       |\n",
      "|    reward             | 0.038049042 |\n",
      "|    std                | 97.3        |\n",
      "|    value_loss         | 0.0182      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 25300      |\n",
      "|    time_elapsed       | 394        |\n",
      "|    total_timesteps    | 126500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 25299      |\n",
      "|    policy_loss        | 0.978      |\n",
      "|    reward             | 0.47863996 |\n",
      "|    std                | 98         |\n",
      "|    value_loss         | 0.00843    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 25400       |\n",
      "|    time_elapsed       | 395         |\n",
      "|    total_timesteps    | 127000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12         |\n",
      "|    explained_variance | 0.255       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25399       |\n",
      "|    policy_loss        | -5.59       |\n",
      "|    reward             | 0.061138652 |\n",
      "|    std                | 99.5        |\n",
      "|    value_loss         | 0.296       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 25500        |\n",
      "|    time_elapsed       | 396          |\n",
      "|    total_timesteps    | 127500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12          |\n",
      "|    explained_variance | -46.8        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 25499        |\n",
      "|    policy_loss        | -1.14        |\n",
      "|    reward             | -0.015597441 |\n",
      "|    std                | 100          |\n",
      "|    value_loss         | 0.014        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 25600        |\n",
      "|    time_elapsed       | 398          |\n",
      "|    total_timesteps    | 128000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.1        |\n",
      "|    explained_variance | -0.764       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 25599        |\n",
      "|    policy_loss        | -0.868       |\n",
      "|    reward             | -0.004075299 |\n",
      "|    std                | 101          |\n",
      "|    value_loss         | 0.00586      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 25700       |\n",
      "|    time_elapsed       | 399         |\n",
      "|    total_timesteps    | 128500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.1       |\n",
      "|    explained_variance | 0.514       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25699       |\n",
      "|    policy_loss        | 0.204       |\n",
      "|    reward             | 0.027235562 |\n",
      "|    std                | 103         |\n",
      "|    value_loss         | 0.000448    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 25800       |\n",
      "|    time_elapsed       | 401         |\n",
      "|    total_timesteps    | 129000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.1       |\n",
      "|    explained_variance | 0.122       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25799       |\n",
      "|    policy_loss        | -0.306      |\n",
      "|    reward             | 0.011708853 |\n",
      "|    std                | 104         |\n",
      "|    value_loss         | 0.000688    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 25900      |\n",
      "|    time_elapsed       | 402        |\n",
      "|    total_timesteps    | 129500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.2      |\n",
      "|    explained_variance | 0.59       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 25899      |\n",
      "|    policy_loss        | -1.84      |\n",
      "|    reward             | 0.01758469 |\n",
      "|    std                | 107        |\n",
      "|    value_loss         | 0.0245     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 26000       |\n",
      "|    time_elapsed       | 404         |\n",
      "|    total_timesteps    | 130000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.2       |\n",
      "|    explained_variance | 0.065       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25999       |\n",
      "|    policy_loss        | -0.793      |\n",
      "|    reward             | 0.048275683 |\n",
      "|    std                | 109         |\n",
      "|    value_loss         | 0.00742     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 26100       |\n",
      "|    time_elapsed       | 405         |\n",
      "|    total_timesteps    | 130500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.2       |\n",
      "|    explained_variance | -0.623      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 26099       |\n",
      "|    policy_loss        | -0.104      |\n",
      "|    reward             | 0.008478234 |\n",
      "|    std                | 110         |\n",
      "|    value_loss         | 8.92e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 26200      |\n",
      "|    time_elapsed       | 407        |\n",
      "|    total_timesteps    | 131000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.3      |\n",
      "|    explained_variance | -0.354     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 26199      |\n",
      "|    policy_loss        | 0.104      |\n",
      "|    reward             | -0.0167804 |\n",
      "|    std                | 113        |\n",
      "|    value_loss         | 9.2e-05    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 26300        |\n",
      "|    time_elapsed       | 408          |\n",
      "|    total_timesteps    | 131500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.3        |\n",
      "|    explained_variance | 0.362        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26299        |\n",
      "|    policy_loss        | 0.145        |\n",
      "|    reward             | 0.0033569466 |\n",
      "|    std                | 116          |\n",
      "|    value_loss         | 0.000174     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 26400        |\n",
      "|    time_elapsed       | 410          |\n",
      "|    total_timesteps    | 132000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.4        |\n",
      "|    explained_variance | -0.831       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26399        |\n",
      "|    policy_loss        | 0.0775       |\n",
      "|    reward             | 0.0044170753 |\n",
      "|    std                | 122          |\n",
      "|    value_loss         | 7.52e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 26500       |\n",
      "|    time_elapsed       | 411         |\n",
      "|    total_timesteps    | 132500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.5       |\n",
      "|    explained_variance | 0.262       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 26499       |\n",
      "|    policy_loss        | -0.323      |\n",
      "|    reward             | 0.010611585 |\n",
      "|    std                | 127         |\n",
      "|    value_loss         | 0.000713    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 26600        |\n",
      "|    time_elapsed       | 413          |\n",
      "|    total_timesteps    | 133000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.6        |\n",
      "|    explained_variance | 0.122        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26599        |\n",
      "|    policy_loss        | 0.0776       |\n",
      "|    reward             | -0.021283329 |\n",
      "|    std                | 131          |\n",
      "|    value_loss         | 0.000619     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 26700        |\n",
      "|    time_elapsed       | 414          |\n",
      "|    total_timesteps    | 133500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.6        |\n",
      "|    explained_variance | 0.119        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26699        |\n",
      "|    policy_loss        | -0.117       |\n",
      "|    reward             | -0.010371377 |\n",
      "|    std                | 134          |\n",
      "|    value_loss         | 0.000766     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 26800       |\n",
      "|    time_elapsed       | 416         |\n",
      "|    total_timesteps    | 134000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.7       |\n",
      "|    explained_variance | 0.382       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 26799       |\n",
      "|    policy_loss        | 0.248       |\n",
      "|    reward             | 0.021589363 |\n",
      "|    std                | 138         |\n",
      "|    value_loss         | 0.000501    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 26900      |\n",
      "|    time_elapsed       | 417        |\n",
      "|    total_timesteps    | 134500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.7      |\n",
      "|    explained_variance | 0.137      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 26899      |\n",
      "|    policy_loss        | 0.379      |\n",
      "|    reward             | -0.0366696 |\n",
      "|    std                | 140        |\n",
      "|    value_loss         | 0.00156    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 27000        |\n",
      "|    time_elapsed       | 419          |\n",
      "|    total_timesteps    | 135000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.8        |\n",
      "|    explained_variance | 1.85e-05     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26999        |\n",
      "|    policy_loss        | -0.459       |\n",
      "|    reward             | -0.087077826 |\n",
      "|    std                | 144          |\n",
      "|    value_loss         | 0.00332      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 27100       |\n",
      "|    time_elapsed       | 420         |\n",
      "|    total_timesteps    | 135500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.8       |\n",
      "|    explained_variance | 0.525       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 27099       |\n",
      "|    policy_loss        | -0.706      |\n",
      "|    reward             | 0.060518485 |\n",
      "|    std                | 147         |\n",
      "|    value_loss         | 0.00753     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 27200        |\n",
      "|    time_elapsed       | 422          |\n",
      "|    total_timesteps    | 136000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.8        |\n",
      "|    explained_variance | -1.89        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27199        |\n",
      "|    policy_loss        | 0.146        |\n",
      "|    reward             | -0.020163473 |\n",
      "|    std                | 147          |\n",
      "|    value_loss         | 0.000398     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 27300        |\n",
      "|    time_elapsed       | 424          |\n",
      "|    total_timesteps    | 136500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.8        |\n",
      "|    explained_variance | -1.43        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27299        |\n",
      "|    policy_loss        | 0.0171       |\n",
      "|    reward             | 7.012596e-05 |\n",
      "|    std                | 149          |\n",
      "|    value_loss         | 3.3e-05      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 27400         |\n",
      "|    time_elapsed       | 425           |\n",
      "|    total_timesteps    | 137000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.9         |\n",
      "|    explained_variance | -0.188        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 27399         |\n",
      "|    policy_loss        | -0.103        |\n",
      "|    reward             | -0.0032514953 |\n",
      "|    std                | 152           |\n",
      "|    value_loss         | 9.23e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 27500       |\n",
      "|    time_elapsed       | 427         |\n",
      "|    total_timesteps    | 137500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.9       |\n",
      "|    explained_variance | -0.633      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 27499       |\n",
      "|    policy_loss        | 0.0989      |\n",
      "|    reward             | 0.006032126 |\n",
      "|    std                | 156         |\n",
      "|    value_loss         | 8.41e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 27600       |\n",
      "|    time_elapsed       | 428         |\n",
      "|    total_timesteps    | 138000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13         |\n",
      "|    explained_variance | 0.234       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 27599       |\n",
      "|    policy_loss        | 0.0909      |\n",
      "|    reward             | 0.003388632 |\n",
      "|    std                | 162         |\n",
      "|    value_loss         | 0.000123    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 27700        |\n",
      "|    time_elapsed       | 430          |\n",
      "|    total_timesteps    | 138500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.1        |\n",
      "|    explained_variance | -0.026       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27699        |\n",
      "|    policy_loss        | -0.322       |\n",
      "|    reward             | -0.010563629 |\n",
      "|    std                | 166          |\n",
      "|    value_loss         | 0.000631     |\n",
      "----------------------------------------\n",
      "day: 2770, episode: 50\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 21356.86\n",
      "total_reward: 11356.86\n",
      "total_cost: 13.15\n",
      "total_trades: 5538\n",
      "Sharpe: 0.426\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 27800        |\n",
      "|    time_elapsed       | 432          |\n",
      "|    total_timesteps    | 139000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.1        |\n",
      "|    explained_variance | 0.502        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27799        |\n",
      "|    policy_loss        | 0.21         |\n",
      "|    reward             | 0.0058698244 |\n",
      "|    std                | 171          |\n",
      "|    value_loss         | 0.000278     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 321            |\n",
      "|    iterations         | 27900          |\n",
      "|    time_elapsed       | 433            |\n",
      "|    total_timesteps    | 139500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -13.2          |\n",
      "|    explained_variance | 5.96e-08       |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 27899          |\n",
      "|    policy_loss        | -0.172         |\n",
      "|    reward             | -2.0576095e-05 |\n",
      "|    std                | 179            |\n",
      "|    value_loss         | 0.000192       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 28000        |\n",
      "|    time_elapsed       | 435          |\n",
      "|    total_timesteps    | 140000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.3        |\n",
      "|    explained_variance | 0.176        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27999        |\n",
      "|    policy_loss        | 0.0755       |\n",
      "|    reward             | -0.003835414 |\n",
      "|    std                | 189          |\n",
      "|    value_loss         | 0.000119     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 28100        |\n",
      "|    time_elapsed       | 437          |\n",
      "|    total_timesteps    | 140500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | 0.786        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28099        |\n",
      "|    policy_loss        | -0.0274      |\n",
      "|    reward             | 0.0026449356 |\n",
      "|    std                | 199          |\n",
      "|    value_loss         | 1.54e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 28200        |\n",
      "|    time_elapsed       | 438          |\n",
      "|    total_timesteps    | 141000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.5        |\n",
      "|    explained_variance | -0.119       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28199        |\n",
      "|    policy_loss        | -0.0584      |\n",
      "|    reward             | 0.0010087036 |\n",
      "|    std                | 206          |\n",
      "|    value_loss         | 0.000127     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 28300        |\n",
      "|    time_elapsed       | 440          |\n",
      "|    total_timesteps    | 141500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | 0.276        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28299        |\n",
      "|    policy_loss        | 0.117        |\n",
      "|    reward             | -0.011051149 |\n",
      "|    std                | 213          |\n",
      "|    value_loss         | 0.000182     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 321       |\n",
      "|    iterations         | 28400     |\n",
      "|    time_elapsed       | 441       |\n",
      "|    total_timesteps    | 142000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13.6     |\n",
      "|    explained_variance | 0.00589   |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 28399     |\n",
      "|    policy_loss        | 0.0516    |\n",
      "|    reward             | 0.0314451 |\n",
      "|    std                | 218       |\n",
      "|    value_loss         | 0.000123  |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 28500        |\n",
      "|    time_elapsed       | 443          |\n",
      "|    total_timesteps    | 142500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | 0.0861       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28499        |\n",
      "|    policy_loss        | 0.288        |\n",
      "|    reward             | 0.0040647634 |\n",
      "|    std                | 221          |\n",
      "|    value_loss         | 0.000961     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 28600        |\n",
      "|    time_elapsed       | 444          |\n",
      "|    total_timesteps    | 143000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.7        |\n",
      "|    explained_variance | -0.177       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28599        |\n",
      "|    policy_loss        | -0.257       |\n",
      "|    reward             | -0.035884123 |\n",
      "|    std                | 223          |\n",
      "|    value_loss         | 0.000705     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 321       |\n",
      "|    iterations         | 28700     |\n",
      "|    time_elapsed       | 446       |\n",
      "|    total_timesteps    | 143500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13.7     |\n",
      "|    explained_variance | 0.0831    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 28699     |\n",
      "|    policy_loss        | 0.272     |\n",
      "|    reward             | 0.0606642 |\n",
      "|    std                | 229       |\n",
      "|    value_loss         | 0.00512   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 28800      |\n",
      "|    time_elapsed       | 447        |\n",
      "|    total_timesteps    | 144000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.7      |\n",
      "|    explained_variance | 4.77e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 28799      |\n",
      "|    policy_loss        | -1.61      |\n",
      "|    reward             | 0.12631693 |\n",
      "|    std                | 231        |\n",
      "|    value_loss         | 0.0197     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 28900       |\n",
      "|    time_elapsed       | 449         |\n",
      "|    total_timesteps    | 144500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.8       |\n",
      "|    explained_variance | 0.0834      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 28899       |\n",
      "|    policy_loss        | 0.0269      |\n",
      "|    reward             | 0.009924589 |\n",
      "|    std                | 235         |\n",
      "|    value_loss         | 0.00201     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 29000       |\n",
      "|    time_elapsed       | 450         |\n",
      "|    total_timesteps    | 145000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.8       |\n",
      "|    explained_variance | 0.00172     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 28999       |\n",
      "|    policy_loss        | -0.0867     |\n",
      "|    reward             | -0.05608494 |\n",
      "|    std                | 239         |\n",
      "|    value_loss         | 0.000229    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 29100       |\n",
      "|    time_elapsed       | 452         |\n",
      "|    total_timesteps    | 145500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.8       |\n",
      "|    explained_variance | 0.0874      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 29099       |\n",
      "|    policy_loss        | -0.772      |\n",
      "|    reward             | -0.04738154 |\n",
      "|    std                | 245         |\n",
      "|    value_loss         | 0.0104      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 29200      |\n",
      "|    time_elapsed       | 454        |\n",
      "|    total_timesteps    | 146000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.9      |\n",
      "|    explained_variance | 0.534      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 29199      |\n",
      "|    policy_loss        | -0.612     |\n",
      "|    reward             | 0.23312214 |\n",
      "|    std                | 248        |\n",
      "|    value_loss         | 0.00396    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 29300      |\n",
      "|    time_elapsed       | 455        |\n",
      "|    total_timesteps    | 146500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.9      |\n",
      "|    explained_variance | 0.331      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 29299      |\n",
      "|    policy_loss        | 1.82       |\n",
      "|    reward             | 0.05401582 |\n",
      "|    std                | 248        |\n",
      "|    value_loss         | 0.0318     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 29400        |\n",
      "|    time_elapsed       | 457          |\n",
      "|    total_timesteps    | 147000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.9        |\n",
      "|    explained_variance | -0.141       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29399        |\n",
      "|    policy_loss        | -0.0499      |\n",
      "|    reward             | 0.0054490915 |\n",
      "|    std                | 251          |\n",
      "|    value_loss         | 0.000174     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 29500        |\n",
      "|    time_elapsed       | 459          |\n",
      "|    total_timesteps    | 147500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.9        |\n",
      "|    explained_variance | -2.66        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29499        |\n",
      "|    policy_loss        | -0.245       |\n",
      "|    reward             | -0.008209832 |\n",
      "|    std                | 255          |\n",
      "|    value_loss         | 0.000752     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 29600       |\n",
      "|    time_elapsed       | 460         |\n",
      "|    total_timesteps    | 148000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.9       |\n",
      "|    explained_variance | -1.63       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 29599       |\n",
      "|    policy_loss        | -0.121      |\n",
      "|    reward             | -0.03789073 |\n",
      "|    std                | 258         |\n",
      "|    value_loss         | 0.000763    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 29700       |\n",
      "|    time_elapsed       | 462         |\n",
      "|    total_timesteps    | 148500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14         |\n",
      "|    explained_variance | 0.38        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 29699       |\n",
      "|    policy_loss        | -0.535      |\n",
      "|    reward             | 0.011524011 |\n",
      "|    std                | 264         |\n",
      "|    value_loss         | 0.00138     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 29800        |\n",
      "|    time_elapsed       | 463          |\n",
      "|    total_timesteps    | 149000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14          |\n",
      "|    explained_variance | 0.0829       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29799        |\n",
      "|    policy_loss        | 1.56         |\n",
      "|    reward             | -0.030765008 |\n",
      "|    std                | 269          |\n",
      "|    value_loss         | 0.0127       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 29900      |\n",
      "|    time_elapsed       | 465        |\n",
      "|    total_timesteps    | 149500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14        |\n",
      "|    explained_variance | -0.0554    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 29899      |\n",
      "|    policy_loss        | 2.05       |\n",
      "|    reward             | 0.15131965 |\n",
      "|    std                | 268        |\n",
      "|    value_loss         | 0.0267     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 30000       |\n",
      "|    time_elapsed       | 466         |\n",
      "|    total_timesteps    | 150000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14         |\n",
      "|    explained_variance | 0.247       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 29999       |\n",
      "|    policy_loss        | -0.536      |\n",
      "|    reward             | 0.023262687 |\n",
      "|    std                | 270         |\n",
      "|    value_loss         | 0.00164     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 30100       |\n",
      "|    time_elapsed       | 467         |\n",
      "|    total_timesteps    | 150500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.1       |\n",
      "|    explained_variance | 0.154       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30099       |\n",
      "|    policy_loss        | -0.0142     |\n",
      "|    reward             | 0.015647983 |\n",
      "|    std                | 274         |\n",
      "|    value_loss         | 4.19e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 30200       |\n",
      "|    time_elapsed       | 469         |\n",
      "|    total_timesteps    | 151000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.1       |\n",
      "|    explained_variance | 0.23        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30199       |\n",
      "|    policy_loss        | 1.89        |\n",
      "|    reward             | 0.001020208 |\n",
      "|    std                | 280         |\n",
      "|    value_loss         | 0.0192      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 30300        |\n",
      "|    time_elapsed       | 470          |\n",
      "|    total_timesteps    | 151500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.1        |\n",
      "|    explained_variance | 0.268        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 30299        |\n",
      "|    policy_loss        | 0.729        |\n",
      "|    reward             | -0.015043073 |\n",
      "|    std                | 283          |\n",
      "|    value_loss         | 0.00323      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 30400      |\n",
      "|    time_elapsed       | 472        |\n",
      "|    total_timesteps    | 152000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.1      |\n",
      "|    explained_variance | 0.275      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 30399      |\n",
      "|    policy_loss        | 1.02       |\n",
      "|    reward             | 0.05773382 |\n",
      "|    std                | 286        |\n",
      "|    value_loss         | 0.00843    |\n",
      "--------------------------------------\n",
      "day: 2770, episode: 55\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 80979.71\n",
      "total_reward: 70979.71\n",
      "total_cost: 10.12\n",
      "total_trades: 5538\n",
      "Sharpe: 0.764\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 30500       |\n",
      "|    time_elapsed       | 473         |\n",
      "|    total_timesteps    | 152500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.2       |\n",
      "|    explained_variance | -10.4       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30499       |\n",
      "|    policy_loss        | 0.0154      |\n",
      "|    reward             | 0.019874334 |\n",
      "|    std                | 289         |\n",
      "|    value_loss         | 7.02e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 30600        |\n",
      "|    time_elapsed       | 475          |\n",
      "|    total_timesteps    | 153000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.2        |\n",
      "|    explained_variance | -0.156       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 30599        |\n",
      "|    policy_loss        | -0.0123      |\n",
      "|    reward             | 0.0012436169 |\n",
      "|    std                | 294          |\n",
      "|    value_loss         | 4.62e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 30700        |\n",
      "|    time_elapsed       | 476          |\n",
      "|    total_timesteps    | 153500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.2        |\n",
      "|    explained_variance | 0.558        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 30699        |\n",
      "|    policy_loss        | -0.0763      |\n",
      "|    reward             | -0.005488875 |\n",
      "|    std                | 300          |\n",
      "|    value_loss         | 3.41e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 30800       |\n",
      "|    time_elapsed       | 478         |\n",
      "|    total_timesteps    | 154000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.3       |\n",
      "|    explained_variance | 0.579       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30799       |\n",
      "|    policy_loss        | 0.0442      |\n",
      "|    reward             | -0.00974491 |\n",
      "|    std                | 311         |\n",
      "|    value_loss         | 2.18e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 30900        |\n",
      "|    time_elapsed       | 479          |\n",
      "|    total_timesteps    | 154500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.4        |\n",
      "|    explained_variance | 0.157        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 30899        |\n",
      "|    policy_loss        | 0.167        |\n",
      "|    reward             | -0.015039258 |\n",
      "|    std                | 326          |\n",
      "|    value_loss         | 0.000218     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 31000       |\n",
      "|    time_elapsed       | 481         |\n",
      "|    total_timesteps    | 155000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.4       |\n",
      "|    explained_variance | -0.00157    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30999       |\n",
      "|    policy_loss        | 0.369       |\n",
      "|    reward             | 0.002111261 |\n",
      "|    std                | 332         |\n",
      "|    value_loss         | 0.000949    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 31100        |\n",
      "|    time_elapsed       | 482          |\n",
      "|    total_timesteps    | 155500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.5        |\n",
      "|    explained_variance | 0.00477      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 31099        |\n",
      "|    policy_loss        | 0.129        |\n",
      "|    reward             | -0.016121257 |\n",
      "|    std                | 337          |\n",
      "|    value_loss         | 0.0003       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 31200      |\n",
      "|    time_elapsed       | 483        |\n",
      "|    total_timesteps    | 156000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.5      |\n",
      "|    explained_variance | 0.223      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 31199      |\n",
      "|    policy_loss        | 0.357      |\n",
      "|    reward             | 0.01198819 |\n",
      "|    std                | 346        |\n",
      "|    value_loss         | 0.000737   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 31300        |\n",
      "|    time_elapsed       | 485          |\n",
      "|    total_timesteps    | 156500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.6        |\n",
      "|    explained_variance | 0.555        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 31299        |\n",
      "|    policy_loss        | -2.05        |\n",
      "|    reward             | -0.023337755 |\n",
      "|    std                | 358          |\n",
      "|    value_loss         | 0.0234       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 31400      |\n",
      "|    time_elapsed       | 486        |\n",
      "|    total_timesteps    | 157000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.6      |\n",
      "|    explained_variance | 0.0145     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 31399      |\n",
      "|    policy_loss        | 1.18       |\n",
      "|    reward             | -0.1816213 |\n",
      "|    std                | 362        |\n",
      "|    value_loss         | 0.011      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 31500      |\n",
      "|    time_elapsed       | 488        |\n",
      "|    total_timesteps    | 157500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.6      |\n",
      "|    explained_variance | 0.685      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 31499      |\n",
      "|    policy_loss        | 0.422      |\n",
      "|    reward             | 0.12209708 |\n",
      "|    std                | 365        |\n",
      "|    value_loss         | 0.0123     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 322       |\n",
      "|    iterations         | 31600     |\n",
      "|    time_elapsed       | 489       |\n",
      "|    total_timesteps    | 158000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14.6     |\n",
      "|    explained_variance | 0.0896    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 31599     |\n",
      "|    policy_loss        | -0.437    |\n",
      "|    reward             | 0.0065154 |\n",
      "|    std                | 366       |\n",
      "|    value_loss         | 0.00205   |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 31700        |\n",
      "|    time_elapsed       | 491          |\n",
      "|    total_timesteps    | 158500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.7        |\n",
      "|    explained_variance | 0.253        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 31699        |\n",
      "|    policy_loss        | -1.01        |\n",
      "|    reward             | -0.022806166 |\n",
      "|    std                | 369          |\n",
      "|    value_loss         | 0.0068       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 31800       |\n",
      "|    time_elapsed       | 493         |\n",
      "|    total_timesteps    | 159000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.7       |\n",
      "|    explained_variance | -0.208      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 31799       |\n",
      "|    policy_loss        | 0.145       |\n",
      "|    reward             | 0.008121058 |\n",
      "|    std                | 375         |\n",
      "|    value_loss         | 0.000101    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 31900        |\n",
      "|    time_elapsed       | 494          |\n",
      "|    total_timesteps    | 159500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 31899        |\n",
      "|    policy_loss        | 2.09         |\n",
      "|    reward             | 0.0017496025 |\n",
      "|    std                | 376          |\n",
      "|    value_loss         | 0.0255       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 32000        |\n",
      "|    time_elapsed       | 496          |\n",
      "|    total_timesteps    | 160000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.8        |\n",
      "|    explained_variance | 0.0787       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 31999        |\n",
      "|    policy_loss        | -0.387       |\n",
      "|    reward             | -0.041075215 |\n",
      "|    std                | 387          |\n",
      "|    value_loss         | 0.0153       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 32100      |\n",
      "|    time_elapsed       | 498        |\n",
      "|    total_timesteps    | 160500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.8      |\n",
      "|    explained_variance | 0.0784     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 32099      |\n",
      "|    policy_loss        | -3.04      |\n",
      "|    reward             | 0.15610401 |\n",
      "|    std                | 388        |\n",
      "|    value_loss         | 0.0581     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 32200         |\n",
      "|    time_elapsed       | 499           |\n",
      "|    total_timesteps    | 161000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.8         |\n",
      "|    explained_variance | 0.501         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 32199         |\n",
      "|    policy_loss        | 0.279         |\n",
      "|    reward             | -0.0013662489 |\n",
      "|    std                | 390           |\n",
      "|    value_loss         | 0.000427      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 32300        |\n",
      "|    time_elapsed       | 501          |\n",
      "|    total_timesteps    | 161500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.8        |\n",
      "|    explained_variance | -2.07        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32299        |\n",
      "|    policy_loss        | -0.234       |\n",
      "|    reward             | 0.0033749938 |\n",
      "|    std                | 396          |\n",
      "|    value_loss         | 0.000386     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 322            |\n",
      "|    iterations         | 32400          |\n",
      "|    time_elapsed       | 502            |\n",
      "|    total_timesteps    | 162000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -14.8          |\n",
      "|    explained_variance | 0.355          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 32399          |\n",
      "|    policy_loss        | -1.29          |\n",
      "|    reward             | -0.00016835632 |\n",
      "|    std                | 405            |\n",
      "|    value_loss         | 0.01           |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 32500       |\n",
      "|    time_elapsed       | 504         |\n",
      "|    total_timesteps    | 162500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.9       |\n",
      "|    explained_variance | 0.844       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 32499       |\n",
      "|    policy_loss        | 0.0694      |\n",
      "|    reward             | 0.009504955 |\n",
      "|    std                | 407         |\n",
      "|    value_loss         | 0.000179    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 32600        |\n",
      "|    time_elapsed       | 505          |\n",
      "|    total_timesteps    | 163000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.9        |\n",
      "|    explained_variance | -0.162       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32599        |\n",
      "|    policy_loss        | 0.303        |\n",
      "|    reward             | -0.025643948 |\n",
      "|    std                | 410          |\n",
      "|    value_loss         | 0.00469      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 322            |\n",
      "|    iterations         | 32700          |\n",
      "|    time_elapsed       | 507            |\n",
      "|    total_timesteps    | 163500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -14.9          |\n",
      "|    explained_variance | -0.214         |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 32699          |\n",
      "|    policy_loss        | 0.191          |\n",
      "|    reward             | -0.00096387474 |\n",
      "|    std                | 412            |\n",
      "|    value_loss         | 0.000507       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 32800       |\n",
      "|    time_elapsed       | 508         |\n",
      "|    total_timesteps    | 164000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 32799       |\n",
      "|    policy_loss        | -0.0575     |\n",
      "|    reward             | 0.008162122 |\n",
      "|    std                | 415         |\n",
      "|    value_loss         | 6.28e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 32900        |\n",
      "|    time_elapsed       | 510          |\n",
      "|    total_timesteps    | 164500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.9        |\n",
      "|    explained_variance | 0.238        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32899        |\n",
      "|    policy_loss        | 0.323        |\n",
      "|    reward             | 0.0014528873 |\n",
      "|    std                | 424          |\n",
      "|    value_loss         | 0.000546     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 33000        |\n",
      "|    time_elapsed       | 512          |\n",
      "|    total_timesteps    | 165000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15          |\n",
      "|    explained_variance | 0.000217     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32999        |\n",
      "|    policy_loss        | -0.299       |\n",
      "|    reward             | -0.022528533 |\n",
      "|    std                | 432          |\n",
      "|    value_loss         | 0.000585     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 33100       |\n",
      "|    time_elapsed       | 513         |\n",
      "|    total_timesteps    | 165500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15         |\n",
      "|    explained_variance | 0.125       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 33099       |\n",
      "|    policy_loss        | -0.897      |\n",
      "|    reward             | -0.09004678 |\n",
      "|    std                | 441         |\n",
      "|    value_loss         | 0.0126      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 33200      |\n",
      "|    time_elapsed       | 515        |\n",
      "|    total_timesteps    | 166000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 33199      |\n",
      "|    policy_loss        | -4.45      |\n",
      "|    reward             | 0.27802104 |\n",
      "|    std                | 446        |\n",
      "|    value_loss         | 0.198      |\n",
      "--------------------------------------\n",
      "day: 2770, episode: 60\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 78669.71\n",
      "total_reward: 68669.71\n",
      "total_cost: 14.32\n",
      "total_trades: 5535\n",
      "Sharpe: 0.750\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 33300        |\n",
      "|    time_elapsed       | 516          |\n",
      "|    total_timesteps    | 166500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15          |\n",
      "|    explained_variance | -0.128       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 33299        |\n",
      "|    policy_loss        | 0.451        |\n",
      "|    reward             | -0.014028069 |\n",
      "|    std                | 448          |\n",
      "|    value_loss         | 0.00196      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 33400         |\n",
      "|    time_elapsed       | 518           |\n",
      "|    total_timesteps    | 167000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.1         |\n",
      "|    explained_variance | 0.712         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 33399         |\n",
      "|    policy_loss        | 0.00558       |\n",
      "|    reward             | -0.0020724798 |\n",
      "|    std                | 459           |\n",
      "|    value_loss         | 7.42e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 33500        |\n",
      "|    time_elapsed       | 519          |\n",
      "|    total_timesteps    | 167500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.1        |\n",
      "|    explained_variance | -2.96e-05    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 33499        |\n",
      "|    policy_loss        | 0.517        |\n",
      "|    reward             | -0.022770284 |\n",
      "|    std                | 468          |\n",
      "|    value_loss         | 0.00168      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 33600      |\n",
      "|    time_elapsed       | 521        |\n",
      "|    total_timesteps    | 168000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.2      |\n",
      "|    explained_variance | -2.38e-06  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 33599      |\n",
      "|    policy_loss        | 0.242      |\n",
      "|    reward             | 0.02955995 |\n",
      "|    std                | 477        |\n",
      "|    value_loss         | 0.000467   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 33700        |\n",
      "|    time_elapsed       | 522          |\n",
      "|    total_timesteps    | 168500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.2        |\n",
      "|    explained_variance | 0.0167       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 33699        |\n",
      "|    policy_loss        | 0.127        |\n",
      "|    reward             | -0.029633956 |\n",
      "|    std                | 492          |\n",
      "|    value_loss         | 0.000415     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 33800       |\n",
      "|    time_elapsed       | 524         |\n",
      "|    total_timesteps    | 169000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.3       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 33799       |\n",
      "|    policy_loss        | 1.14        |\n",
      "|    reward             | 0.009243304 |\n",
      "|    std                | 502         |\n",
      "|    value_loss         | 0.00538     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 33900       |\n",
      "|    time_elapsed       | 525         |\n",
      "|    total_timesteps    | 169500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 33899       |\n",
      "|    policy_loss        | 0.37        |\n",
      "|    reward             | 0.007173404 |\n",
      "|    std                | 510         |\n",
      "|    value_loss         | 0.000813    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 322       |\n",
      "|    iterations         | 34000     |\n",
      "|    time_elapsed       | 527       |\n",
      "|    total_timesteps    | 170000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.3     |\n",
      "|    explained_variance | 0.0774    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 33999     |\n",
      "|    policy_loss        | 0.18      |\n",
      "|    reward             | 0.0407825 |\n",
      "|    std                | 519       |\n",
      "|    value_loss         | 0.00112   |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 34100        |\n",
      "|    time_elapsed       | 528          |\n",
      "|    total_timesteps    | 170500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.4        |\n",
      "|    explained_variance | 0.000282     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 34099        |\n",
      "|    policy_loss        | 0.221        |\n",
      "|    reward             | -0.113756396 |\n",
      "|    std                | 527          |\n",
      "|    value_loss         | 0.00177      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 34200       |\n",
      "|    time_elapsed       | 530         |\n",
      "|    total_timesteps    | 171000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.4       |\n",
      "|    explained_variance | 6.65e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34199       |\n",
      "|    policy_loss        | 0.607       |\n",
      "|    reward             | 0.104063645 |\n",
      "|    std                | 537         |\n",
      "|    value_loss         | 0.00531     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 34300      |\n",
      "|    time_elapsed       | 531        |\n",
      "|    total_timesteps    | 171500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.4      |\n",
      "|    explained_variance | 0.729      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 34299      |\n",
      "|    policy_loss        | -1.27      |\n",
      "|    reward             | 0.14157887 |\n",
      "|    std                | 537        |\n",
      "|    value_loss         | 0.00909    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 34400        |\n",
      "|    time_elapsed       | 532          |\n",
      "|    total_timesteps    | 172000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.4        |\n",
      "|    explained_variance | 0.215        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 34399        |\n",
      "|    policy_loss        | -0.374       |\n",
      "|    reward             | -0.028658502 |\n",
      "|    std                | 537          |\n",
      "|    value_loss         | 0.000841     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 34500       |\n",
      "|    time_elapsed       | 534         |\n",
      "|    total_timesteps    | 172500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.4       |\n",
      "|    explained_variance | 0.0631      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34499       |\n",
      "|    policy_loss        | 0.428       |\n",
      "|    reward             | 0.021422982 |\n",
      "|    std                | 544         |\n",
      "|    value_loss         | 0.000869    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 34600        |\n",
      "|    time_elapsed       | 535          |\n",
      "|    total_timesteps    | 173000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.5        |\n",
      "|    explained_variance | 0.174        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 34599        |\n",
      "|    policy_loss        | -0.475       |\n",
      "|    reward             | -0.047827847 |\n",
      "|    std                | 555          |\n",
      "|    value_loss         | 0.00126      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 34700        |\n",
      "|    time_elapsed       | 537          |\n",
      "|    total_timesteps    | 173500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 34699        |\n",
      "|    policy_loss        | 1.04         |\n",
      "|    reward             | -0.064641915 |\n",
      "|    std                | 554          |\n",
      "|    value_loss         | 0.00533      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 34800       |\n",
      "|    time_elapsed       | 538         |\n",
      "|    total_timesteps    | 174000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.5       |\n",
      "|    explained_variance | 0.0716      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34799       |\n",
      "|    policy_loss        | 1.11        |\n",
      "|    reward             | -0.35367864 |\n",
      "|    std                | 566         |\n",
      "|    value_loss         | 0.0468      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 34900       |\n",
      "|    time_elapsed       | 540         |\n",
      "|    total_timesteps    | 174500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.5       |\n",
      "|    explained_variance | 0.000452    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34899       |\n",
      "|    policy_loss        | -2.66       |\n",
      "|    reward             | 0.044736385 |\n",
      "|    std                | 573         |\n",
      "|    value_loss         | 0.105       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 35000       |\n",
      "|    time_elapsed       | 541         |\n",
      "|    total_timesteps    | 175000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.5       |\n",
      "|    explained_variance | -0.0783     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34999       |\n",
      "|    policy_loss        | 0.683       |\n",
      "|    reward             | -0.03130591 |\n",
      "|    std                | 574         |\n",
      "|    value_loss         | 0.00226     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 35100       |\n",
      "|    time_elapsed       | 543         |\n",
      "|    total_timesteps    | 175500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.6       |\n",
      "|    explained_variance | -0.286      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35099       |\n",
      "|    policy_loss        | -0.124      |\n",
      "|    reward             | 0.020763509 |\n",
      "|    std                | 579         |\n",
      "|    value_loss         | 0.000101    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 35200        |\n",
      "|    time_elapsed       | 544          |\n",
      "|    total_timesteps    | 176000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.6        |\n",
      "|    explained_variance | 0.3          |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 35199        |\n",
      "|    policy_loss        | 0.351        |\n",
      "|    reward             | 0.0040843794 |\n",
      "|    std                | 591          |\n",
      "|    value_loss         | 0.00107      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 35300      |\n",
      "|    time_elapsed       | 546        |\n",
      "|    total_timesteps    | 176500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.6      |\n",
      "|    explained_variance | -0.519     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 35299      |\n",
      "|    policy_loss        | 1.02       |\n",
      "|    reward             | 0.06470273 |\n",
      "|    std                | 605        |\n",
      "|    value_loss         | 0.00425    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 35400        |\n",
      "|    time_elapsed       | 548          |\n",
      "|    total_timesteps    | 177000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.6        |\n",
      "|    explained_variance | -3.28e-05    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 35399        |\n",
      "|    policy_loss        | 0.0754       |\n",
      "|    reward             | -0.063211314 |\n",
      "|    std                | 610          |\n",
      "|    value_loss         | 0.000209     |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 322      |\n",
      "|    iterations         | 35500    |\n",
      "|    time_elapsed       | 549      |\n",
      "|    total_timesteps    | 177500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.7    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 35499    |\n",
      "|    policy_loss        | 0.432    |\n",
      "|    reward             | 0.012583 |\n",
      "|    std                | 619      |\n",
      "|    value_loss         | 0.000845 |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 35600       |\n",
      "|    time_elapsed       | 551         |\n",
      "|    total_timesteps    | 178000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.7       |\n",
      "|    explained_variance | 0.637       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35599       |\n",
      "|    policy_loss        | -0.00291    |\n",
      "|    reward             | -0.03386232 |\n",
      "|    std                | 631         |\n",
      "|    value_loss         | 2.68e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 35700       |\n",
      "|    time_elapsed       | 552         |\n",
      "|    total_timesteps    | 178500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.7       |\n",
      "|    explained_variance | 0.427       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35699       |\n",
      "|    policy_loss        | 0.162       |\n",
      "|    reward             | 0.037051406 |\n",
      "|    std                | 636         |\n",
      "|    value_loss         | 0.000835    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 35800        |\n",
      "|    time_elapsed       | 554          |\n",
      "|    total_timesteps    | 179000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.7        |\n",
      "|    explained_variance | 0.289        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 35799        |\n",
      "|    policy_loss        | 0.734        |\n",
      "|    reward             | -0.012234629 |\n",
      "|    std                | 639          |\n",
      "|    value_loss         | 0.00275      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 35900       |\n",
      "|    time_elapsed       | 555         |\n",
      "|    total_timesteps    | 179500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.7       |\n",
      "|    explained_variance | 0.338       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35899       |\n",
      "|    policy_loss        | 1.54        |\n",
      "|    reward             | -0.03672261 |\n",
      "|    std                | 641         |\n",
      "|    value_loss         | 0.0233      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 36000        |\n",
      "|    time_elapsed       | 557          |\n",
      "|    total_timesteps    | 180000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.7        |\n",
      "|    explained_variance | 0.266        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 35999        |\n",
      "|    policy_loss        | 3.75         |\n",
      "|    reward             | -0.089959174 |\n",
      "|    std                | 640          |\n",
      "|    value_loss         | 0.071        |\n",
      "----------------------------------------\n",
      "day: 2770, episode: 65\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 132391.10\n",
      "total_reward: 122391.10\n",
      "total_cost: 26.46\n",
      "total_trades: 5534\n",
      "Sharpe: 0.942\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 36100      |\n",
      "|    time_elapsed       | 559        |\n",
      "|    total_timesteps    | 180500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.8      |\n",
      "|    explained_variance | 0.642      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 36099      |\n",
      "|    policy_loss        | -0.0921    |\n",
      "|    reward             | 0.02674786 |\n",
      "|    std                | 651        |\n",
      "|    value_loss         | 0.000152   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 36200        |\n",
      "|    time_elapsed       | 560          |\n",
      "|    total_timesteps    | 181000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36199        |\n",
      "|    policy_loss        | 0.0993       |\n",
      "|    reward             | -0.013846176 |\n",
      "|    std                | 662          |\n",
      "|    value_loss         | 4.81e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 36300       |\n",
      "|    time_elapsed       | 562         |\n",
      "|    total_timesteps    | 181500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.8       |\n",
      "|    explained_variance | 0.393       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36299       |\n",
      "|    policy_loss        | -0.58       |\n",
      "|    reward             | -0.06258729 |\n",
      "|    std                | 678         |\n",
      "|    value_loss         | 0.00279     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 36400       |\n",
      "|    time_elapsed       | 564         |\n",
      "|    total_timesteps    | 182000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.9       |\n",
      "|    explained_variance | 0.756       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36399       |\n",
      "|    policy_loss        | 0.132       |\n",
      "|    reward             | 0.030405013 |\n",
      "|    std                | 681         |\n",
      "|    value_loss         | 0.000361    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 36500       |\n",
      "|    time_elapsed       | 565         |\n",
      "|    total_timesteps    | 182500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.9       |\n",
      "|    explained_variance | 0.064       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36499       |\n",
      "|    policy_loss        | -2.54       |\n",
      "|    reward             | 0.027577374 |\n",
      "|    std                | 686         |\n",
      "|    value_loss         | 0.0315      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 36600        |\n",
      "|    time_elapsed       | 567          |\n",
      "|    total_timesteps    | 183000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.9        |\n",
      "|    explained_variance | 0.045        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36599        |\n",
      "|    policy_loss        | -0.0768      |\n",
      "|    reward             | 0.0019534356 |\n",
      "|    std                | 685          |\n",
      "|    value_loss         | 7.69e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 36700       |\n",
      "|    time_elapsed       | 568         |\n",
      "|    total_timesteps    | 183500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.9       |\n",
      "|    explained_variance | 0.0664      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36699       |\n",
      "|    policy_loss        | -0.12       |\n",
      "|    reward             | 0.012445093 |\n",
      "|    std                | 696         |\n",
      "|    value_loss         | 7.93e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 36800         |\n",
      "|    time_elapsed       | 570           |\n",
      "|    total_timesteps    | 184000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.9         |\n",
      "|    explained_variance | 0.0949        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 36799         |\n",
      "|    policy_loss        | -0.107        |\n",
      "|    reward             | -0.0041507925 |\n",
      "|    std                | 710           |\n",
      "|    value_loss         | 6.49e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 36900        |\n",
      "|    time_elapsed       | 572          |\n",
      "|    total_timesteps    | 184500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16          |\n",
      "|    explained_variance | -0.12        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36899        |\n",
      "|    policy_loss        | -0.111       |\n",
      "|    reward             | 0.0064607086 |\n",
      "|    std                | 732          |\n",
      "|    value_loss         | 0.000292     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 37000         |\n",
      "|    time_elapsed       | 573           |\n",
      "|    total_timesteps    | 185000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.1         |\n",
      "|    explained_variance | 0.255         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 36999         |\n",
      "|    policy_loss        | -0.149        |\n",
      "|    reward             | -0.0024940488 |\n",
      "|    std                | 754           |\n",
      "|    value_loss         | 0.000333      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 37100       |\n",
      "|    time_elapsed       | 575         |\n",
      "|    total_timesteps    | 185500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.1       |\n",
      "|    explained_variance | 0.0258      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37099       |\n",
      "|    policy_loss        | -0.0209     |\n",
      "|    reward             | 0.003154448 |\n",
      "|    std                | 773         |\n",
      "|    value_loss         | 0.000574    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 37200        |\n",
      "|    time_elapsed       | 576          |\n",
      "|    total_timesteps    | 186000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.2        |\n",
      "|    explained_variance | 0.728        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 37199        |\n",
      "|    policy_loss        | 0.00154      |\n",
      "|    reward             | -0.011425642 |\n",
      "|    std                | 792          |\n",
      "|    value_loss         | 4.98e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 37300       |\n",
      "|    time_elapsed       | 578         |\n",
      "|    total_timesteps    | 186500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.2       |\n",
      "|    explained_variance | 0.135       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37299       |\n",
      "|    policy_loss        | -0.117      |\n",
      "|    reward             | 0.005736702 |\n",
      "|    std                | 816         |\n",
      "|    value_loss         | 6.49e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 37400       |\n",
      "|    time_elapsed       | 579         |\n",
      "|    total_timesteps    | 187000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.3       |\n",
      "|    explained_variance | 0.284       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37399       |\n",
      "|    policy_loss        | -1.47       |\n",
      "|    reward             | 0.008344946 |\n",
      "|    std                | 853         |\n",
      "|    value_loss         | 0.00832     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 37500       |\n",
      "|    time_elapsed       | 581         |\n",
      "|    total_timesteps    | 187500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.4       |\n",
      "|    explained_variance | 0.00496     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37499       |\n",
      "|    policy_loss        | 0.18        |\n",
      "|    reward             | -0.07608219 |\n",
      "|    std                | 881         |\n",
      "|    value_loss         | 0.000524    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 37600      |\n",
      "|    time_elapsed       | 583        |\n",
      "|    total_timesteps    | 188000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.4      |\n",
      "|    explained_variance | 0.0459     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 37599      |\n",
      "|    policy_loss        | 0.44       |\n",
      "|    reward             | 0.03951314 |\n",
      "|    std                | 894        |\n",
      "|    value_loss         | 0.00504    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 37700       |\n",
      "|    time_elapsed       | 584         |\n",
      "|    total_timesteps    | 188500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.4       |\n",
      "|    explained_variance | -1.17       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37699       |\n",
      "|    policy_loss        | -0.087      |\n",
      "|    reward             | 0.012130337 |\n",
      "|    std                | 888         |\n",
      "|    value_loss         | 0.000174    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 37800        |\n",
      "|    time_elapsed       | 586          |\n",
      "|    total_timesteps    | 189000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.4        |\n",
      "|    explained_variance | 0.306        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 37799        |\n",
      "|    policy_loss        | 0.53         |\n",
      "|    reward             | -0.026936304 |\n",
      "|    std                | 898          |\n",
      "|    value_loss         | 0.00113      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 37900       |\n",
      "|    time_elapsed       | 587         |\n",
      "|    total_timesteps    | 189500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.4       |\n",
      "|    explained_variance | 0.107       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37899       |\n",
      "|    policy_loss        | -0.254      |\n",
      "|    reward             | -0.01580845 |\n",
      "|    std                | 916         |\n",
      "|    value_loss         | 0.000379    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 38000      |\n",
      "|    time_elapsed       | 589        |\n",
      "|    total_timesteps    | 190000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.5      |\n",
      "|    explained_variance | -1.67e-06  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 37999      |\n",
      "|    policy_loss        | -0.934     |\n",
      "|    reward             | 0.12399315 |\n",
      "|    std                | 924        |\n",
      "|    value_loss         | 0.00414    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 38100       |\n",
      "|    time_elapsed       | 590         |\n",
      "|    total_timesteps    | 190500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38099       |\n",
      "|    policy_loss        | -0.435      |\n",
      "|    reward             | -0.18606299 |\n",
      "|    std                | 939         |\n",
      "|    value_loss         | 0.0082      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 38200       |\n",
      "|    time_elapsed       | 592         |\n",
      "|    total_timesteps    | 191000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.5       |\n",
      "|    explained_variance | 0.0465      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38199       |\n",
      "|    policy_loss        | -5.7        |\n",
      "|    reward             | -0.33405337 |\n",
      "|    std                | 951         |\n",
      "|    value_loss         | 0.167       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 38300        |\n",
      "|    time_elapsed       | 593          |\n",
      "|    total_timesteps    | 191500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.5        |\n",
      "|    explained_variance | 0.0309       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 38299        |\n",
      "|    policy_loss        | -0.785       |\n",
      "|    reward             | -0.015080001 |\n",
      "|    std                | 960          |\n",
      "|    value_loss         | 0.00301      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 38400        |\n",
      "|    time_elapsed       | 595          |\n",
      "|    total_timesteps    | 192000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 38399        |\n",
      "|    policy_loss        | -0.064       |\n",
      "|    reward             | 0.0058419765 |\n",
      "|    std                | 976          |\n",
      "|    value_loss         | 0.000114     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 38500        |\n",
      "|    time_elapsed       | 597          |\n",
      "|    total_timesteps    | 192500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.6        |\n",
      "|    explained_variance | 0.0336       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 38499        |\n",
      "|    policy_loss        | 0.751        |\n",
      "|    reward             | -0.005074361 |\n",
      "|    std                | 986          |\n",
      "|    value_loss         | 0.00222      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 38600       |\n",
      "|    time_elapsed       | 599         |\n",
      "|    total_timesteps    | 193000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.6       |\n",
      "|    explained_variance | 0.154       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38599       |\n",
      "|    policy_loss        | -0.486      |\n",
      "|    reward             | 0.009429059 |\n",
      "|    std                | 1.01e+03    |\n",
      "|    value_loss         | 0.00178     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 38700       |\n",
      "|    time_elapsed       | 600         |\n",
      "|    total_timesteps    | 193500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.7       |\n",
      "|    explained_variance | 0.103       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38699       |\n",
      "|    policy_loss        | -3.66       |\n",
      "|    reward             | -0.05342659 |\n",
      "|    std                | 1.02e+03    |\n",
      "|    value_loss         | 0.0654      |\n",
      "---------------------------------------\n",
      "day: 2770, episode: 70\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 75543.33\n",
      "total_reward: 65543.33\n",
      "total_cost: 41.57\n",
      "total_trades: 5532\n",
      "Sharpe: 0.800\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 38800        |\n",
      "|    time_elapsed       | 602          |\n",
      "|    total_timesteps    | 194000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.7        |\n",
      "|    explained_variance | -0.119       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 38799        |\n",
      "|    policy_loss        | 0.244        |\n",
      "|    reward             | -0.010643234 |\n",
      "|    std                | 1.02e+03     |\n",
      "|    value_loss         | 0.00152      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 38900         |\n",
      "|    time_elapsed       | 603           |\n",
      "|    total_timesteps    | 194500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.7         |\n",
      "|    explained_variance | 0.617         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 38899         |\n",
      "|    policy_loss        | -0.368        |\n",
      "|    reward             | -0.0003463537 |\n",
      "|    std                | 1.04e+03      |\n",
      "|    value_loss         | 0.000638      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 39000       |\n",
      "|    time_elapsed       | 605         |\n",
      "|    total_timesteps    | 195000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.8       |\n",
      "|    explained_variance | 0.429       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38999       |\n",
      "|    policy_loss        | -0.436      |\n",
      "|    reward             | 0.050392263 |\n",
      "|    std                | 1.07e+03    |\n",
      "|    value_loss         | 0.00137     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 39100        |\n",
      "|    time_elapsed       | 607          |\n",
      "|    total_timesteps    | 195500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.8        |\n",
      "|    explained_variance | 0.173        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39099        |\n",
      "|    policy_loss        | -0.381       |\n",
      "|    reward             | -0.042211328 |\n",
      "|    std                | 1.1e+03      |\n",
      "|    value_loss         | 0.00154      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 39200        |\n",
      "|    time_elapsed       | 608          |\n",
      "|    total_timesteps    | 196000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.8        |\n",
      "|    explained_variance | 0.369        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39199        |\n",
      "|    policy_loss        | 1.13         |\n",
      "|    reward             | 0.0018004609 |\n",
      "|    std                | 1.12e+03     |\n",
      "|    value_loss         | 0.00989      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 39300       |\n",
      "|    time_elapsed       | 610         |\n",
      "|    total_timesteps    | 196500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.9       |\n",
      "|    explained_variance | 0.068       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 39299       |\n",
      "|    policy_loss        | 3.53        |\n",
      "|    reward             | -0.25435698 |\n",
      "|    std                | 1.12e+03    |\n",
      "|    value_loss         | 0.0459      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 39400        |\n",
      "|    time_elapsed       | 611          |\n",
      "|    total_timesteps    | 197000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.9        |\n",
      "|    explained_variance | 0.128        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39399        |\n",
      "|    policy_loss        | -0.461       |\n",
      "|    reward             | -0.009289657 |\n",
      "|    std                | 1.13e+03     |\n",
      "|    value_loss         | 0.000829     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 39500       |\n",
      "|    time_elapsed       | 613         |\n",
      "|    total_timesteps    | 197500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.9       |\n",
      "|    explained_variance | 0.529       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 39499       |\n",
      "|    policy_loss        | -0.51       |\n",
      "|    reward             | 0.003672957 |\n",
      "|    std                | 1.15e+03    |\n",
      "|    value_loss         | 0.000967    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 39600        |\n",
      "|    time_elapsed       | 614          |\n",
      "|    total_timesteps    | 198000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17          |\n",
      "|    explained_variance | 0.0396       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39599        |\n",
      "|    policy_loss        | -4.18        |\n",
      "|    reward             | -0.009577611 |\n",
      "|    std                | 1.18e+03     |\n",
      "|    value_loss         | 0.0803       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 39700       |\n",
      "|    time_elapsed       | 616         |\n",
      "|    total_timesteps    | 198500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17         |\n",
      "|    explained_variance | -8.23e-06   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 39699       |\n",
      "|    policy_loss        | -4.41       |\n",
      "|    reward             | 0.067028075 |\n",
      "|    std                | 1.2e+03     |\n",
      "|    value_loss         | 0.0694      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 39800        |\n",
      "|    time_elapsed       | 617          |\n",
      "|    total_timesteps    | 199000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17          |\n",
      "|    explained_variance | 0.413        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39799        |\n",
      "|    policy_loss        | 8.66         |\n",
      "|    reward             | -0.009035685 |\n",
      "|    std                | 1.2e+03      |\n",
      "|    value_loss         | 0.295        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 39900       |\n",
      "|    time_elapsed       | 619         |\n",
      "|    total_timesteps    | 199500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17         |\n",
      "|    explained_variance | 0.0152      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 39899       |\n",
      "|    policy_loss        | 9.61        |\n",
      "|    reward             | -0.75243926 |\n",
      "|    std                | 1.19e+03    |\n",
      "|    value_loss         | 0.458       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 40000       |\n",
      "|    time_elapsed       | 620         |\n",
      "|    total_timesteps    | 200000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 39999       |\n",
      "|    policy_loss        | 0.0503      |\n",
      "|    reward             | 0.008678062 |\n",
      "|    std                | 1.2e+03     |\n",
      "|    value_loss         | 1.56e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 40100       |\n",
      "|    time_elapsed       | 622         |\n",
      "|    total_timesteps    | 200500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17         |\n",
      "|    explained_variance | -0.354      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40099       |\n",
      "|    policy_loss        | -0.00789    |\n",
      "|    reward             | 0.009594362 |\n",
      "|    std                | 1.22e+03    |\n",
      "|    value_loss         | 4.16e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 40200       |\n",
      "|    time_elapsed       | 624         |\n",
      "|    total_timesteps    | 201000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.1       |\n",
      "|    explained_variance | 0.377       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40199       |\n",
      "|    policy_loss        | -0.0902     |\n",
      "|    reward             | 0.031907257 |\n",
      "|    std                | 1.25e+03    |\n",
      "|    value_loss         | 0.000118    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 40300       |\n",
      "|    time_elapsed       | 625         |\n",
      "|    total_timesteps    | 201500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.1       |\n",
      "|    explained_variance | -0.195      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40299       |\n",
      "|    policy_loss        | 1.8         |\n",
      "|    reward             | 0.018985521 |\n",
      "|    std                | 1.27e+03    |\n",
      "|    value_loss         | 0.0138      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 40400       |\n",
      "|    time_elapsed       | 627         |\n",
      "|    total_timesteps    | 202000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.2       |\n",
      "|    explained_variance | 0.000458    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40399       |\n",
      "|    policy_loss        | 0.193       |\n",
      "|    reward             | -0.04148148 |\n",
      "|    std                | 1.31e+03    |\n",
      "|    value_loss         | 0.000453    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 40500        |\n",
      "|    time_elapsed       | 628          |\n",
      "|    total_timesteps    | 202500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.2        |\n",
      "|    explained_variance | 0.209        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 40499        |\n",
      "|    policy_loss        | -0.126       |\n",
      "|    reward             | -0.000328743 |\n",
      "|    std                | 1.33e+03     |\n",
      "|    value_loss         | 7.8e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 40600        |\n",
      "|    time_elapsed       | 630          |\n",
      "|    total_timesteps    | 203000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 40599        |\n",
      "|    policy_loss        | 0.0341       |\n",
      "|    reward             | 0.0018627319 |\n",
      "|    std                | 1.37e+03     |\n",
      "|    value_loss         | 1.09e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 40700       |\n",
      "|    time_elapsed       | 631         |\n",
      "|    total_timesteps    | 203500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.3       |\n",
      "|    explained_variance | 0.706       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40699       |\n",
      "|    policy_loss        | 0.108       |\n",
      "|    reward             | 0.006161735 |\n",
      "|    std                | 1.42e+03    |\n",
      "|    value_loss         | 5.21e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 40800       |\n",
      "|    time_elapsed       | 633         |\n",
      "|    total_timesteps    | 204000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.4       |\n",
      "|    explained_variance | 0.468       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40799       |\n",
      "|    policy_loss        | 0.0582      |\n",
      "|    reward             | 0.007537896 |\n",
      "|    std                | 1.47e+03    |\n",
      "|    value_loss         | 8.05e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 40900         |\n",
      "|    time_elapsed       | 635           |\n",
      "|    total_timesteps    | 204500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.4         |\n",
      "|    explained_variance | 0.301         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 40899         |\n",
      "|    policy_loss        | 1.06          |\n",
      "|    reward             | -0.0015275894 |\n",
      "|    std                | 1.51e+03      |\n",
      "|    value_loss         | 0.00508       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 41000        |\n",
      "|    time_elapsed       | 636          |\n",
      "|    total_timesteps    | 205000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.5        |\n",
      "|    explained_variance | 0.112        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 40999        |\n",
      "|    policy_loss        | 2.17         |\n",
      "|    reward             | -0.040320024 |\n",
      "|    std                | 1.54e+03     |\n",
      "|    value_loss         | 0.0185       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 41100         |\n",
      "|    time_elapsed       | 638           |\n",
      "|    total_timesteps    | 205500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.5         |\n",
      "|    explained_variance | 0.376         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 41099         |\n",
      "|    policy_loss        | 0.086         |\n",
      "|    reward             | -0.0021768876 |\n",
      "|    std                | 1.57e+03      |\n",
      "|    value_loss         | 0.000148      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 41200        |\n",
      "|    time_elapsed       | 639          |\n",
      "|    total_timesteps    | 206000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.6        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41199        |\n",
      "|    policy_loss        | 0.0354       |\n",
      "|    reward             | 0.0076797693 |\n",
      "|    std                | 1.6e+03      |\n",
      "|    value_loss         | 0.00028      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 41300      |\n",
      "|    time_elapsed       | 641        |\n",
      "|    total_timesteps    | 206500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -17.6      |\n",
      "|    explained_variance | 0.00426    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 41299      |\n",
      "|    policy_loss        | 1.43       |\n",
      "|    reward             | 0.04065858 |\n",
      "|    std                | 1.67e+03   |\n",
      "|    value_loss         | 0.00768    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 41400       |\n",
      "|    time_elapsed       | 643         |\n",
      "|    total_timesteps    | 207000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.7       |\n",
      "|    explained_variance | 0.193       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 41399       |\n",
      "|    policy_loss        | -1.06       |\n",
      "|    reward             | -0.09822222 |\n",
      "|    std                | 1.7e+03     |\n",
      "|    value_loss         | 0.00562     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 41500       |\n",
      "|    time_elapsed       | 644         |\n",
      "|    total_timesteps    | 207500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 41499       |\n",
      "|    policy_loss        | 2.83        |\n",
      "|    reward             | 0.090940215 |\n",
      "|    std                | 1.69e+03    |\n",
      "|    value_loss         | 0.0291      |\n",
      "---------------------------------------\n",
      "day: 2770, episode: 75\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 143446.06\n",
      "total_reward: 133446.06\n",
      "total_cost: 18.55\n",
      "total_trades: 5539\n",
      "Sharpe: 0.863\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 41600       |\n",
      "|    time_elapsed       | 646         |\n",
      "|    total_timesteps    | 208000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.7       |\n",
      "|    explained_variance | 0.0391      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 41599       |\n",
      "|    policy_loss        | 0.453       |\n",
      "|    reward             | 0.020444881 |\n",
      "|    std                | 1.69e+03    |\n",
      "|    value_loss         | 0.000976    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 41700        |\n",
      "|    time_elapsed       | 648          |\n",
      "|    total_timesteps    | 208500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.7        |\n",
      "|    explained_variance | 0.733        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41699        |\n",
      "|    policy_loss        | 0.54         |\n",
      "|    reward             | 0.0070969723 |\n",
      "|    std                | 1.72e+03     |\n",
      "|    value_loss         | 0.00107      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 41800       |\n",
      "|    time_elapsed       | 650         |\n",
      "|    total_timesteps    | 209000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.7       |\n",
      "|    explained_variance | 3.04e-06    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 41799       |\n",
      "|    policy_loss        | 0.669       |\n",
      "|    reward             | -0.06715242 |\n",
      "|    std                | 1.75e+03    |\n",
      "|    value_loss         | 0.00137     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 41900       |\n",
      "|    time_elapsed       | 651         |\n",
      "|    total_timesteps    | 209500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.8       |\n",
      "|    explained_variance | 0.481       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 41899       |\n",
      "|    policy_loss        | 0.214       |\n",
      "|    reward             | 0.006927017 |\n",
      "|    std                | 1.79e+03    |\n",
      "|    value_loss         | 0.00172     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 42000       |\n",
      "|    time_elapsed       | 653         |\n",
      "|    total_timesteps    | 210000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.8       |\n",
      "|    explained_variance | 0.571       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 41999       |\n",
      "|    policy_loss        | -3.75       |\n",
      "|    reward             | -0.19418445 |\n",
      "|    std                | 1.81e+03    |\n",
      "|    value_loss         | 0.0498      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 42100      |\n",
      "|    time_elapsed       | 654        |\n",
      "|    total_timesteps    | 210500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -17.8      |\n",
      "|    explained_variance | 0.181      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 42099      |\n",
      "|    policy_loss        | 7.37       |\n",
      "|    reward             | 0.07347315 |\n",
      "|    std                | 1.82e+03   |\n",
      "|    value_loss         | 0.226      |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 42200         |\n",
      "|    time_elapsed       | 656           |\n",
      "|    total_timesteps    | 211000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.9         |\n",
      "|    explained_variance | 0.306         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 42199         |\n",
      "|    policy_loss        | 0.371         |\n",
      "|    reward             | -0.0013411095 |\n",
      "|    std                | 1.85e+03      |\n",
      "|    value_loss         | 0.000481      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 321            |\n",
      "|    iterations         | 42300          |\n",
      "|    time_elapsed       | 658            |\n",
      "|    total_timesteps    | 211500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -17.9          |\n",
      "|    explained_variance | 0.519          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 42299          |\n",
      "|    policy_loss        | -0.0357        |\n",
      "|    reward             | -0.00093444367 |\n",
      "|    std                | 1.87e+03       |\n",
      "|    value_loss         | 4.96e-05       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 42400       |\n",
      "|    time_elapsed       | 659         |\n",
      "|    total_timesteps    | 212000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.9       |\n",
      "|    explained_variance | 0.748       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 42399       |\n",
      "|    policy_loss        | 0.0575      |\n",
      "|    reward             | 0.032549396 |\n",
      "|    std                | 1.9e+03     |\n",
      "|    value_loss         | 3.98e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 42500        |\n",
      "|    time_elapsed       | 661          |\n",
      "|    total_timesteps    | 212500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18          |\n",
      "|    explained_variance | 0.00175      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42499        |\n",
      "|    policy_loss        | -0.121       |\n",
      "|    reward             | -0.002281389 |\n",
      "|    std                | 1.94e+03     |\n",
      "|    value_loss         | 0.000141     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 42600        |\n",
      "|    time_elapsed       | 662          |\n",
      "|    total_timesteps    | 213000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18          |\n",
      "|    explained_variance | -0.277       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42599        |\n",
      "|    policy_loss        | 0.527        |\n",
      "|    reward             | -0.018683085 |\n",
      "|    std                | 1.98e+03     |\n",
      "|    value_loss         | 0.00274      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 42700         |\n",
      "|    time_elapsed       | 664           |\n",
      "|    total_timesteps    | 213500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 42699         |\n",
      "|    policy_loss        | -0.167        |\n",
      "|    reward             | 0.00051386433 |\n",
      "|    std                | 2e+03         |\n",
      "|    value_loss         | 0.000131      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 42800       |\n",
      "|    time_elapsed       | 666         |\n",
      "|    total_timesteps    | 214000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.1       |\n",
      "|    explained_variance | 0.11        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 42799       |\n",
      "|    policy_loss        | -0.267      |\n",
      "|    reward             | 0.002591781 |\n",
      "|    std                | 2.03e+03    |\n",
      "|    value_loss         | 0.000345    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 42900        |\n",
      "|    time_elapsed       | 667          |\n",
      "|    total_timesteps    | 214500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.1        |\n",
      "|    explained_variance | 0.114        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42899        |\n",
      "|    policy_loss        | -0.0565      |\n",
      "|    reward             | -0.022315366 |\n",
      "|    std                | 2.09e+03     |\n",
      "|    value_loss         | 0.000282     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 321            |\n",
      "|    iterations         | 43000          |\n",
      "|    time_elapsed       | 669            |\n",
      "|    total_timesteps    | 215000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -18.2          |\n",
      "|    explained_variance | 0.237          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 42999          |\n",
      "|    policy_loss        | -0.0216        |\n",
      "|    reward             | -0.00036312256 |\n",
      "|    std                | 2.14e+03       |\n",
      "|    value_loss         | 0.000503       |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 43100      |\n",
      "|    time_elapsed       | 670        |\n",
      "|    total_timesteps    | 215500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.2      |\n",
      "|    explained_variance | 0.115      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 43099      |\n",
      "|    policy_loss        | 1.37       |\n",
      "|    reward             | 0.05794535 |\n",
      "|    std                | 2.2e+03    |\n",
      "|    value_loss         | 0.0104     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 43200         |\n",
      "|    time_elapsed       | 672           |\n",
      "|    total_timesteps    | 216000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.2         |\n",
      "|    explained_variance | 0.0154        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 43199         |\n",
      "|    policy_loss        | -0.872        |\n",
      "|    reward             | -0.0070335325 |\n",
      "|    std                | 2.21e+03      |\n",
      "|    value_loss         | 0.0214        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 43300       |\n",
      "|    time_elapsed       | 673         |\n",
      "|    total_timesteps    | 216500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.2       |\n",
      "|    explained_variance | 0.383       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43299       |\n",
      "|    policy_loss        | 0.593       |\n",
      "|    reward             | 0.029303284 |\n",
      "|    std                | 2.2e+03     |\n",
      "|    value_loss         | 0.00165     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 43400       |\n",
      "|    time_elapsed       | 675         |\n",
      "|    total_timesteps    | 217000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.3       |\n",
      "|    explained_variance | -0.464      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43399       |\n",
      "|    policy_loss        | -0.205      |\n",
      "|    reward             | 0.015716912 |\n",
      "|    std                | 2.26e+03    |\n",
      "|    value_loss         | 0.000164    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 43500      |\n",
      "|    time_elapsed       | 676        |\n",
      "|    total_timesteps    | 217500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.3      |\n",
      "|    explained_variance | 0.219      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 43499      |\n",
      "|    policy_loss        | -1.61      |\n",
      "|    reward             | 0.00584177 |\n",
      "|    std                | 2.33e+03   |\n",
      "|    value_loss         | 0.00881    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 43600        |\n",
      "|    time_elapsed       | 678          |\n",
      "|    total_timesteps    | 218000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.4        |\n",
      "|    explained_variance | 0.311        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 43599        |\n",
      "|    policy_loss        | 1.19         |\n",
      "|    reward             | 0.0072277677 |\n",
      "|    std                | 2.4e+03      |\n",
      "|    value_loss         | 0.00504      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 43700         |\n",
      "|    time_elapsed       | 680           |\n",
      "|    total_timesteps    | 218500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.4         |\n",
      "|    explained_variance | 0.507         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 43699         |\n",
      "|    policy_loss        | 0.801         |\n",
      "|    reward             | -0.0012798095 |\n",
      "|    std                | 2.44e+03      |\n",
      "|    value_loss         | 0.00233       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 43800       |\n",
      "|    time_elapsed       | 681         |\n",
      "|    total_timesteps    | 219000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.4       |\n",
      "|    explained_variance | -0.131      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43799       |\n",
      "|    policy_loss        | -0.0174     |\n",
      "|    reward             | -0.06295278 |\n",
      "|    std                | 2.47e+03    |\n",
      "|    value_loss         | 0.000126    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 43900      |\n",
      "|    time_elapsed       | 683        |\n",
      "|    total_timesteps    | 219500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.5      |\n",
      "|    explained_variance | 0.625      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 43899      |\n",
      "|    policy_loss        | 0.738      |\n",
      "|    reward             | 0.03247437 |\n",
      "|    std                | 2.51e+03   |\n",
      "|    value_loss         | 0.00171    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 44000       |\n",
      "|    time_elapsed       | 684         |\n",
      "|    total_timesteps    | 220000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.5       |\n",
      "|    explained_variance | 0.161       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43999       |\n",
      "|    policy_loss        | -1.74       |\n",
      "|    reward             | 0.024228735 |\n",
      "|    std                | 2.56e+03    |\n",
      "|    value_loss         | 0.0103      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 44100       |\n",
      "|    time_elapsed       | 686         |\n",
      "|    total_timesteps    | 220500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.5       |\n",
      "|    explained_variance | 0.00442     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44099       |\n",
      "|    policy_loss        | 0.735       |\n",
      "|    reward             | 0.059273995 |\n",
      "|    std                | 2.59e+03    |\n",
      "|    value_loss         | 0.00297     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 44200      |\n",
      "|    time_elapsed       | 687        |\n",
      "|    total_timesteps    | 221000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.5      |\n",
      "|    explained_variance | 0.149      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 44199      |\n",
      "|    policy_loss        | -12        |\n",
      "|    reward             | 0.15762961 |\n",
      "|    std                | 2.6e+03    |\n",
      "|    value_loss         | 0.654      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 44300      |\n",
      "|    time_elapsed       | 689        |\n",
      "|    total_timesteps    | 221500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.6      |\n",
      "|    explained_variance | 0.188      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 44299      |\n",
      "|    policy_loss        | 0.386      |\n",
      "|    reward             | 0.07057101 |\n",
      "|    std                | 2.63e+03   |\n",
      "|    value_loss         | 0.00613    |\n",
      "--------------------------------------\n",
      "day: 2770, episode: 80\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 165400.06\n",
      "total_reward: 155400.06\n",
      "total_cost: 49.96\n",
      "total_trades: 5532\n",
      "Sharpe: 0.977\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 44400       |\n",
      "|    time_elapsed       | 691         |\n",
      "|    total_timesteps    | 222000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.6       |\n",
      "|    explained_variance | 0.806       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44399       |\n",
      "|    policy_loss        | 0.062       |\n",
      "|    reward             | -0.01943273 |\n",
      "|    std                | 2.66e+03    |\n",
      "|    value_loss         | 2.39e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 44500       |\n",
      "|    time_elapsed       | 692         |\n",
      "|    total_timesteps    | 222500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.6       |\n",
      "|    explained_variance | 0.0131      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44499       |\n",
      "|    policy_loss        | 0.0953      |\n",
      "|    reward             | 0.009385529 |\n",
      "|    std                | 2.7e+03     |\n",
      "|    value_loss         | 3.21e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 44600        |\n",
      "|    time_elapsed       | 694          |\n",
      "|    total_timesteps    | 223000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.7        |\n",
      "|    explained_variance | -2.74        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44599        |\n",
      "|    policy_loss        | -0.108       |\n",
      "|    reward             | 0.0008977287 |\n",
      "|    std                | 2.77e+03     |\n",
      "|    value_loss         | 7.35e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 44700         |\n",
      "|    time_elapsed       | 695           |\n",
      "|    total_timesteps    | 223500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.7         |\n",
      "|    explained_variance | 0.524         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 44699         |\n",
      "|    policy_loss        | -0.259        |\n",
      "|    reward             | -0.0062641646 |\n",
      "|    std                | 2.86e+03      |\n",
      "|    value_loss         | 0.000223      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 44800       |\n",
      "|    time_elapsed       | 697         |\n",
      "|    total_timesteps    | 224000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.8       |\n",
      "|    explained_variance | -7.15e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44799       |\n",
      "|    policy_loss        | 0.312       |\n",
      "|    reward             | 0.013350814 |\n",
      "|    std                | 2.99e+03    |\n",
      "|    value_loss         | 0.000553    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 44900        |\n",
      "|    time_elapsed       | 699          |\n",
      "|    total_timesteps    | 224500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.9        |\n",
      "|    explained_variance | 0.231        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44899        |\n",
      "|    policy_loss        | -0.703       |\n",
      "|    reward             | 0.0067667146 |\n",
      "|    std                | 3.05e+03     |\n",
      "|    value_loss         | 0.00166      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 45000       |\n",
      "|    time_elapsed       | 700         |\n",
      "|    total_timesteps    | 225000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.9       |\n",
      "|    explained_variance | 0.382       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44999       |\n",
      "|    policy_loss        | 1.47        |\n",
      "|    reward             | 0.036666907 |\n",
      "|    std                | 3.1e+03     |\n",
      "|    value_loss         | 0.00748     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 45100         |\n",
      "|    time_elapsed       | 701           |\n",
      "|    total_timesteps    | 225500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.9         |\n",
      "|    explained_variance | -0.12         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 45099         |\n",
      "|    policy_loss        | 1.48          |\n",
      "|    reward             | -0.0052729375 |\n",
      "|    std                | 3.16e+03      |\n",
      "|    value_loss         | 0.00802       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 45200       |\n",
      "|    time_elapsed       | 703         |\n",
      "|    total_timesteps    | 226000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19         |\n",
      "|    explained_variance | 0.0714      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 45199       |\n",
      "|    policy_loss        | 0.406       |\n",
      "|    reward             | -0.02157004 |\n",
      "|    std                | 3.22e+03    |\n",
      "|    value_loss         | 0.00296     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 45300        |\n",
      "|    time_elapsed       | 705          |\n",
      "|    total_timesteps    | 226500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45299        |\n",
      "|    policy_loss        | -0.676       |\n",
      "|    reward             | -0.031074807 |\n",
      "|    std                | 3.27e+03     |\n",
      "|    value_loss         | 0.0136       |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 321       |\n",
      "|    iterations         | 45400     |\n",
      "|    time_elapsed       | 706       |\n",
      "|    total_timesteps    | 227000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -19       |\n",
      "|    explained_variance | 0.15      |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 45399     |\n",
      "|    policy_loss        | 7.15      |\n",
      "|    reward             | 0.6322931 |\n",
      "|    std                | 3.31e+03  |\n",
      "|    value_loss         | 0.18      |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 45500        |\n",
      "|    time_elapsed       | 708          |\n",
      "|    total_timesteps    | 227500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45499        |\n",
      "|    policy_loss        | 0.0326       |\n",
      "|    reward             | 0.0052644145 |\n",
      "|    std                | 3.35e+03     |\n",
      "|    value_loss         | 7.26e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 45600       |\n",
      "|    time_elapsed       | 709         |\n",
      "|    total_timesteps    | 228000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.1       |\n",
      "|    explained_variance | -0.5        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 45599       |\n",
      "|    policy_loss        | -0.315      |\n",
      "|    reward             | 0.011778452 |\n",
      "|    std                | 3.41e+03    |\n",
      "|    value_loss         | 0.000442    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 45700         |\n",
      "|    time_elapsed       | 711           |\n",
      "|    total_timesteps    | 228500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.1         |\n",
      "|    explained_variance | 0.138         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 45699         |\n",
      "|    policy_loss        | -0.281        |\n",
      "|    reward             | -0.0125577375 |\n",
      "|    std                | 3.47e+03      |\n",
      "|    value_loss         | 0.00034       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 45800       |\n",
      "|    time_elapsed       | 712         |\n",
      "|    total_timesteps    | 229000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.2       |\n",
      "|    explained_variance | 0.71        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 45799       |\n",
      "|    policy_loss        | -0.0785     |\n",
      "|    reward             | 0.020070761 |\n",
      "|    std                | 3.58e+03    |\n",
      "|    value_loss         | 0.000279    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 45900        |\n",
      "|    time_elapsed       | 714          |\n",
      "|    total_timesteps    | 229500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.2        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45899        |\n",
      "|    policy_loss        | 0.681        |\n",
      "|    reward             | -0.037290946 |\n",
      "|    std                | 3.66e+03     |\n",
      "|    value_loss         | 0.00133      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 46000        |\n",
      "|    time_elapsed       | 715          |\n",
      "|    total_timesteps    | 230000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.3        |\n",
      "|    explained_variance | -0.306       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45999        |\n",
      "|    policy_loss        | -9.54        |\n",
      "|    reward             | 0.0012510844 |\n",
      "|    std                | 3.76e+03     |\n",
      "|    value_loss         | 0.314        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 46100       |\n",
      "|    time_elapsed       | 717         |\n",
      "|    total_timesteps    | 230500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.3       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46099       |\n",
      "|    policy_loss        | -0.244      |\n",
      "|    reward             | -0.02467368 |\n",
      "|    std                | 3.81e+03    |\n",
      "|    value_loss         | 0.000235    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 46200        |\n",
      "|    time_elapsed       | 718          |\n",
      "|    total_timesteps    | 231000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.3        |\n",
      "|    explained_variance | 0.203        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46199        |\n",
      "|    policy_loss        | -0.827       |\n",
      "|    reward             | -0.008987214 |\n",
      "|    std                | 3.88e+03     |\n",
      "|    value_loss         | 0.00215      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 46300       |\n",
      "|    time_elapsed       | 720         |\n",
      "|    total_timesteps    | 231500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46299       |\n",
      "|    policy_loss        | 1.27        |\n",
      "|    reward             | 0.027500497 |\n",
      "|    std                | 3.89e+03    |\n",
      "|    value_loss         | 0.00584     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 46400       |\n",
      "|    time_elapsed       | 721         |\n",
      "|    total_timesteps    | 232000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.4       |\n",
      "|    explained_variance | 0.145       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46399       |\n",
      "|    policy_loss        | 4.78        |\n",
      "|    reward             | -0.06931684 |\n",
      "|    std                | 3.94e+03    |\n",
      "|    value_loss         | 0.0738      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 46500      |\n",
      "|    time_elapsed       | 723        |\n",
      "|    total_timesteps    | 232500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.4      |\n",
      "|    explained_variance | -0.0124    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 46499      |\n",
      "|    policy_loss        | -13.4      |\n",
      "|    reward             | -0.8741816 |\n",
      "|    std                | 3.97e+03   |\n",
      "|    value_loss         | 0.605      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 46600        |\n",
      "|    time_elapsed       | 724          |\n",
      "|    total_timesteps    | 233000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.4        |\n",
      "|    explained_variance | 0.0929       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46599        |\n",
      "|    policy_loss        | -0.297       |\n",
      "|    reward             | -0.010271751 |\n",
      "|    std                | 4.01e+03     |\n",
      "|    value_loss         | 0.000881     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 46700      |\n",
      "|    time_elapsed       | 725        |\n",
      "|    total_timesteps    | 233500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.4      |\n",
      "|    explained_variance | 0.613      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 46699      |\n",
      "|    policy_loss        | 0.0713     |\n",
      "|    reward             | 0.01692108 |\n",
      "|    std                | 4.06e+03   |\n",
      "|    value_loss         | 0.000102   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 46800       |\n",
      "|    time_elapsed       | 727         |\n",
      "|    total_timesteps    | 234000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46799       |\n",
      "|    policy_loss        | 0.712       |\n",
      "|    reward             | 0.029323561 |\n",
      "|    std                | 4.13e+03    |\n",
      "|    value_loss         | 0.00182     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 46900        |\n",
      "|    time_elapsed       | 728          |\n",
      "|    total_timesteps    | 234500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.5        |\n",
      "|    explained_variance | 0.373        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46899        |\n",
      "|    policy_loss        | 0.574        |\n",
      "|    reward             | -0.029881444 |\n",
      "|    std                | 4.16e+03     |\n",
      "|    value_loss         | 0.000916     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 47000       |\n",
      "|    time_elapsed       | 730         |\n",
      "|    total_timesteps    | 235000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.5       |\n",
      "|    explained_variance | 2.03e-06    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46999       |\n",
      "|    policy_loss        | 1.59        |\n",
      "|    reward             | 0.053931706 |\n",
      "|    std                | 4.24e+03    |\n",
      "|    value_loss         | 0.00818     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 47100      |\n",
      "|    time_elapsed       | 731        |\n",
      "|    total_timesteps    | 235500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.5      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 47099      |\n",
      "|    policy_loss        | -0.0582    |\n",
      "|    reward             | 0.12387751 |\n",
      "|    std                | 4.28e+03   |\n",
      "|    value_loss         | 0.0163     |\n",
      "--------------------------------------\n",
      "day: 2770, episode: 85\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 100414.67\n",
      "total_reward: 90414.67\n",
      "total_cost: 32.86\n",
      "total_trades: 5534\n",
      "Sharpe: 0.883\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 47200      |\n",
      "|    time_elapsed       | 733        |\n",
      "|    total_timesteps    | 236000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.5      |\n",
      "|    explained_variance | 0.00138    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 47199      |\n",
      "|    policy_loss        | 0.15       |\n",
      "|    reward             | 0.03357984 |\n",
      "|    std                | 4.3e+03    |\n",
      "|    value_loss         | 0.000647   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 47300        |\n",
      "|    time_elapsed       | 734          |\n",
      "|    total_timesteps    | 236500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47299        |\n",
      "|    policy_loss        | -1.76        |\n",
      "|    reward             | -0.034566846 |\n",
      "|    std                | 4.37e+03     |\n",
      "|    value_loss         | 0.00879      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 47400        |\n",
      "|    time_elapsed       | 736          |\n",
      "|    total_timesteps    | 237000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.6        |\n",
      "|    explained_variance | -2.11e-05    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47399        |\n",
      "|    policy_loss        | -0.22        |\n",
      "|    reward             | -0.046515137 |\n",
      "|    std                | 4.41e+03     |\n",
      "|    value_loss         | 0.00566      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 47500        |\n",
      "|    time_elapsed       | 738          |\n",
      "|    total_timesteps    | 237500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.6        |\n",
      "|    explained_variance | 0.634        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47499        |\n",
      "|    policy_loss        | -0.216       |\n",
      "|    reward             | -0.059225295 |\n",
      "|    std                | 4.41e+03     |\n",
      "|    value_loss         | 0.00179      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 47600      |\n",
      "|    time_elapsed       | 739        |\n",
      "|    total_timesteps    | 238000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.6      |\n",
      "|    explained_variance | 0.39       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 47599      |\n",
      "|    policy_loss        | -1.83      |\n",
      "|    reward             | 0.09679337 |\n",
      "|    std                | 4.43e+03   |\n",
      "|    value_loss         | 0.0154     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 47700        |\n",
      "|    time_elapsed       | 741          |\n",
      "|    total_timesteps    | 238500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.6        |\n",
      "|    explained_variance | 7.15e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47699        |\n",
      "|    policy_loss        | -0.136       |\n",
      "|    reward             | 0.0070960694 |\n",
      "|    std                | 4.47e+03     |\n",
      "|    value_loss         | 7.89e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 47800        |\n",
      "|    time_elapsed       | 742          |\n",
      "|    total_timesteps    | 239000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.7        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47799        |\n",
      "|    policy_loss        | -0.294       |\n",
      "|    reward             | 0.0036446229 |\n",
      "|    std                | 4.53e+03     |\n",
      "|    value_loss         | 0.000278     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 47900        |\n",
      "|    time_elapsed       | 744          |\n",
      "|    total_timesteps    | 239500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.7        |\n",
      "|    explained_variance | 0.0389       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47899        |\n",
      "|    policy_loss        | 0.677        |\n",
      "|    reward             | 0.0077226562 |\n",
      "|    std                | 4.62e+03     |\n",
      "|    value_loss         | 0.00197      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 48000        |\n",
      "|    time_elapsed       | 745          |\n",
      "|    total_timesteps    | 240000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.8        |\n",
      "|    explained_variance | 0.264        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47999        |\n",
      "|    policy_loss        | 0.723        |\n",
      "|    reward             | 0.0002652588 |\n",
      "|    std                | 4.75e+03     |\n",
      "|    value_loss         | 0.00454      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 48100        |\n",
      "|    time_elapsed       | 747          |\n",
      "|    total_timesteps    | 240500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.8        |\n",
      "|    explained_variance | 0.211        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48099        |\n",
      "|    policy_loss        | 2.57         |\n",
      "|    reward             | -0.022920165 |\n",
      "|    std                | 4.78e+03     |\n",
      "|    value_loss         | 0.0247       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 48200       |\n",
      "|    time_elapsed       | 749         |\n",
      "|    total_timesteps    | 241000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48199       |\n",
      "|    policy_loss        | 2.23        |\n",
      "|    reward             | -0.06820923 |\n",
      "|    std                | 4.69e+03    |\n",
      "|    value_loss         | 0.0174      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 48300        |\n",
      "|    time_elapsed       | 750          |\n",
      "|    total_timesteps    | 241500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.7        |\n",
      "|    explained_variance | 0.235        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48299        |\n",
      "|    policy_loss        | -0.62        |\n",
      "|    reward             | -0.013739719 |\n",
      "|    std                | 4.74e+03     |\n",
      "|    value_loss         | 0.00141      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 48400         |\n",
      "|    time_elapsed       | 752           |\n",
      "|    total_timesteps    | 242000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.8         |\n",
      "|    explained_variance | 0.232         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 48399         |\n",
      "|    policy_loss        | 0.133         |\n",
      "|    reward             | -0.0035707764 |\n",
      "|    std                | 4.83e+03      |\n",
      "|    value_loss         | 0.000468      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 48500       |\n",
      "|    time_elapsed       | 753         |\n",
      "|    total_timesteps    | 242500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.9       |\n",
      "|    explained_variance | 0.846       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48499       |\n",
      "|    policy_loss        | 0.251       |\n",
      "|    reward             | 0.021517158 |\n",
      "|    std                | 4.99e+03    |\n",
      "|    value_loss         | 0.000172    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 48600         |\n",
      "|    time_elapsed       | 755           |\n",
      "|    total_timesteps    | 243000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.9         |\n",
      "|    explained_variance | 0.398         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 48599         |\n",
      "|    policy_loss        | -0.855        |\n",
      "|    reward             | 0.00062316895 |\n",
      "|    std                | 5.15e+03      |\n",
      "|    value_loss         | 0.00202       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 48700        |\n",
      "|    time_elapsed       | 756          |\n",
      "|    total_timesteps    | 243500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20          |\n",
      "|    explained_variance | 0.283        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48699        |\n",
      "|    policy_loss        | 0.15         |\n",
      "|    reward             | -0.019137988 |\n",
      "|    std                | 5.28e+03     |\n",
      "|    value_loss         | 0.000252     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 48800      |\n",
      "|    time_elapsed       | 758        |\n",
      "|    total_timesteps    | 244000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20        |\n",
      "|    explained_variance | -5.38e-05  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 48799      |\n",
      "|    policy_loss        | 0.532      |\n",
      "|    reward             | 0.00350966 |\n",
      "|    std                | 5.35e+03   |\n",
      "|    value_loss         | 0.000787   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 48900       |\n",
      "|    time_elapsed       | 759         |\n",
      "|    total_timesteps    | 244500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20         |\n",
      "|    explained_variance | 0.759       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48899       |\n",
      "|    policy_loss        | -0.0831     |\n",
      "|    reward             | 0.037070435 |\n",
      "|    std                | 5.42e+03    |\n",
      "|    value_loss         | 5.46e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 49000       |\n",
      "|    time_elapsed       | 761         |\n",
      "|    total_timesteps    | 245000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.1       |\n",
      "|    explained_variance | 0.161       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48999       |\n",
      "|    policy_loss        | 2.97        |\n",
      "|    reward             | 0.062430482 |\n",
      "|    std                | 5.55e+03    |\n",
      "|    value_loss         | 0.0234      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 49100        |\n",
      "|    time_elapsed       | 762          |\n",
      "|    total_timesteps    | 245500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.1        |\n",
      "|    explained_variance | 0.024        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 49099        |\n",
      "|    policy_loss        | -1.37        |\n",
      "|    reward             | -0.014604297 |\n",
      "|    std                | 5.62e+03     |\n",
      "|    value_loss         | 0.00908      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 49200        |\n",
      "|    time_elapsed       | 764          |\n",
      "|    total_timesteps    | 246000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.1        |\n",
      "|    explained_variance | 0.206        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 49199        |\n",
      "|    policy_loss        | -7.85        |\n",
      "|    reward             | -0.030020233 |\n",
      "|    std                | 5.65e+03     |\n",
      "|    value_loss         | 0.14         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 49300        |\n",
      "|    time_elapsed       | 766          |\n",
      "|    total_timesteps    | 246500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.1        |\n",
      "|    explained_variance | 0.000197     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 49299        |\n",
      "|    policy_loss        | -0.63        |\n",
      "|    reward             | -0.025151178 |\n",
      "|    std                | 5.65e+03     |\n",
      "|    value_loss         | 0.0138       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 49400       |\n",
      "|    time_elapsed       | 767         |\n",
      "|    total_timesteps    | 247000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.1       |\n",
      "|    explained_variance | 0.0874      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49399       |\n",
      "|    policy_loss        | 0.212       |\n",
      "|    reward             | 0.024945108 |\n",
      "|    std                | 5.7e+03     |\n",
      "|    value_loss         | 0.000499    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 49500       |\n",
      "|    time_elapsed       | 769         |\n",
      "|    total_timesteps    | 247500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49499       |\n",
      "|    policy_loss        | 0.305       |\n",
      "|    reward             | 0.010390863 |\n",
      "|    std                | 5.83e+03    |\n",
      "|    value_loss         | 0.000624    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 49600        |\n",
      "|    time_elapsed       | 770          |\n",
      "|    total_timesteps    | 248000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.2        |\n",
      "|    explained_variance | 0.122        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 49599        |\n",
      "|    policy_loss        | -0.112       |\n",
      "|    reward             | 0.0023147652 |\n",
      "|    std                | 5.95e+03     |\n",
      "|    value_loss         | 0.000109     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 49700        |\n",
      "|    time_elapsed       | 772          |\n",
      "|    total_timesteps    | 248500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 49699        |\n",
      "|    policy_loss        | -0.18        |\n",
      "|    reward             | -0.008001323 |\n",
      "|    std                | 6.1e+03      |\n",
      "|    value_loss         | 0.000179     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 49800        |\n",
      "|    time_elapsed       | 773          |\n",
      "|    total_timesteps    | 249000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 49799        |\n",
      "|    policy_loss        | 1.25         |\n",
      "|    reward             | -0.017062435 |\n",
      "|    std                | 6.22e+03     |\n",
      "|    value_loss         | 0.00562      |\n",
      "----------------------------------------\n",
      "day: 2770, episode: 90\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 35396.83\n",
      "total_reward: 25396.83\n",
      "total_cost: 15.51\n",
      "total_trades: 5536\n",
      "Sharpe: 0.538\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 49900         |\n",
      "|    time_elapsed       | 775           |\n",
      "|    total_timesteps    | 249500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.3         |\n",
      "|    explained_variance | 1.18e-05      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 49899         |\n",
      "|    policy_loss        | -0.279        |\n",
      "|    reward             | -0.0026604652 |\n",
      "|    std                | 6.37e+03      |\n",
      "|    value_loss         | 0.000188      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 50000         |\n",
      "|    time_elapsed       | 776           |\n",
      "|    total_timesteps    | 250000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.4         |\n",
      "|    explained_variance | -1.33         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 49999         |\n",
      "|    policy_loss        | 0.258         |\n",
      "|    reward             | -0.0022657304 |\n",
      "|    std                | 6.51e+03      |\n",
      "|    value_loss         | 0.000211      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 50100         |\n",
      "|    time_elapsed       | 778           |\n",
      "|    total_timesteps    | 250500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.4         |\n",
      "|    explained_variance | 0.521         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 50099         |\n",
      "|    policy_loss        | 0.0602        |\n",
      "|    reward             | -0.0035194259 |\n",
      "|    std                | 6.71e+03      |\n",
      "|    value_loss         | 0.000176      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 50200        |\n",
      "|    time_elapsed       | 779          |\n",
      "|    total_timesteps    | 251000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50199        |\n",
      "|    policy_loss        | 0.0879       |\n",
      "|    reward             | 0.0064740414 |\n",
      "|    std                | 6.9e+03      |\n",
      "|    value_loss         | 8.66e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 50300        |\n",
      "|    time_elapsed       | 781          |\n",
      "|    total_timesteps    | 251500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50299        |\n",
      "|    policy_loss        | -0.349       |\n",
      "|    reward             | -0.019006962 |\n",
      "|    std                | 7.14e+03     |\n",
      "|    value_loss         | 0.000577     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 321       |\n",
      "|    iterations         | 50400     |\n",
      "|    time_elapsed       | 783       |\n",
      "|    total_timesteps    | 252000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -20.6     |\n",
      "|    explained_variance | 0.246     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 50399     |\n",
      "|    policy_loss        | -0.166    |\n",
      "|    reward             | 0.0233586 |\n",
      "|    std                | 7.18e+03  |\n",
      "|    value_loss         | 0.000579  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 50500       |\n",
      "|    time_elapsed       | 784         |\n",
      "|    total_timesteps    | 252500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.6       |\n",
      "|    explained_variance | -0.159      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50499       |\n",
      "|    policy_loss        | -0.594      |\n",
      "|    reward             | -0.02479633 |\n",
      "|    std                | 7.32e+03    |\n",
      "|    value_loss         | 0.00122     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 50600      |\n",
      "|    time_elapsed       | 786        |\n",
      "|    total_timesteps    | 253000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.7      |\n",
      "|    explained_variance | 0.073      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 50599      |\n",
      "|    policy_loss        | 0.00762    |\n",
      "|    reward             | 0.01260856 |\n",
      "|    std                | 7.51e+03   |\n",
      "|    value_loss         | 4.94e-06   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 50700       |\n",
      "|    time_elapsed       | 787         |\n",
      "|    total_timesteps    | 253500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.7       |\n",
      "|    explained_variance | 0.00923     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50699       |\n",
      "|    policy_loss        | -0.0601     |\n",
      "|    reward             | 0.028945064 |\n",
      "|    std                | 7.81e+03    |\n",
      "|    value_loss         | 4.41e-05    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 50800        |\n",
      "|    time_elapsed       | 789          |\n",
      "|    total_timesteps    | 254000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.8        |\n",
      "|    explained_variance | 0.738        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50799        |\n",
      "|    policy_loss        | 0.67         |\n",
      "|    reward             | 0.0019481785 |\n",
      "|    std                | 8.01e+03     |\n",
      "|    value_loss         | 0.00121      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 50900      |\n",
      "|    time_elapsed       | 790        |\n",
      "|    total_timesteps    | 254500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.9      |\n",
      "|    explained_variance | 0.309      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 50899      |\n",
      "|    policy_loss        | -0.924     |\n",
      "|    reward             | 0.03437041 |\n",
      "|    std                | 8.3e+03    |\n",
      "|    value_loss         | 0.00346    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 51000        |\n",
      "|    time_elapsed       | 792          |\n",
      "|    total_timesteps    | 255000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.9        |\n",
      "|    explained_variance | 0.313        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50999        |\n",
      "|    policy_loss        | -0.219       |\n",
      "|    reward             | 0.0020876045 |\n",
      "|    std                | 8.42e+03     |\n",
      "|    value_loss         | 0.00019      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 51100        |\n",
      "|    time_elapsed       | 794          |\n",
      "|    total_timesteps    | 255500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.9        |\n",
      "|    explained_variance | 0.00671      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51099        |\n",
      "|    policy_loss        | -0.274       |\n",
      "|    reward             | -0.005800824 |\n",
      "|    std                | 8.55e+03     |\n",
      "|    value_loss         | 0.000195     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 51200       |\n",
      "|    time_elapsed       | 795         |\n",
      "|    total_timesteps    | 256000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21         |\n",
      "|    explained_variance | -2.74e-06   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51199       |\n",
      "|    policy_loss        | -0.158      |\n",
      "|    reward             | 0.013738804 |\n",
      "|    std                | 8.79e+03    |\n",
      "|    value_loss         | 6.9e-05     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 51300       |\n",
      "|    time_elapsed       | 797         |\n",
      "|    total_timesteps    | 256500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21         |\n",
      "|    explained_variance | 0.0275      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51299       |\n",
      "|    policy_loss        | -0.639      |\n",
      "|    reward             | 0.046678178 |\n",
      "|    std                | 8.96e+03    |\n",
      "|    value_loss         | 0.00182     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 51400         |\n",
      "|    time_elapsed       | 798           |\n",
      "|    total_timesteps    | 257000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.1         |\n",
      "|    explained_variance | 0.0843        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 51399         |\n",
      "|    policy_loss        | -0.165        |\n",
      "|    reward             | -0.0068351226 |\n",
      "|    std                | 9.14e+03      |\n",
      "|    value_loss         | 0.00124       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 51500       |\n",
      "|    time_elapsed       | 800         |\n",
      "|    total_timesteps    | 257500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.1       |\n",
      "|    explained_variance | 0.0152      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51499       |\n",
      "|    policy_loss        | 3.52        |\n",
      "|    reward             | 0.058850084 |\n",
      "|    std                | 9.28e+03    |\n",
      "|    value_loss         | 0.0443      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 51600       |\n",
      "|    time_elapsed       | 801         |\n",
      "|    total_timesteps    | 258000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.1       |\n",
      "|    explained_variance | 0.275       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51599       |\n",
      "|    policy_loss        | 0.0103      |\n",
      "|    reward             | -0.00467831 |\n",
      "|    std                | 9.42e+03    |\n",
      "|    value_loss         | 6.13e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 51700         |\n",
      "|    time_elapsed       | 803           |\n",
      "|    total_timesteps    | 258500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.2         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 51699         |\n",
      "|    policy_loss        | -0.143        |\n",
      "|    reward             | -0.0010187348 |\n",
      "|    std                | 9.57e+03      |\n",
      "|    value_loss         | 6.63e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 51800        |\n",
      "|    time_elapsed       | 804          |\n",
      "|    total_timesteps    | 259000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.2        |\n",
      "|    explained_variance | 0.708        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51799        |\n",
      "|    policy_loss        | 0.0994       |\n",
      "|    reward             | -0.006262626 |\n",
      "|    std                | 9.87e+03     |\n",
      "|    value_loss         | 6.07e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 51900       |\n",
      "|    time_elapsed       | 806         |\n",
      "|    total_timesteps    | 259500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51899       |\n",
      "|    policy_loss        | 0.543       |\n",
      "|    reward             | 0.015144743 |\n",
      "|    std                | 1.02e+04    |\n",
      "|    value_loss         | 0.000776    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 52000        |\n",
      "|    time_elapsed       | 807          |\n",
      "|    total_timesteps    | 260000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.4        |\n",
      "|    explained_variance | 0.433        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51999        |\n",
      "|    policy_loss        | -0.472       |\n",
      "|    reward             | -0.031281304 |\n",
      "|    std                | 1.07e+04     |\n",
      "|    value_loss         | 0.00121      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 52100       |\n",
      "|    time_elapsed       | 809         |\n",
      "|    total_timesteps    | 260500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.4       |\n",
      "|    explained_variance | -1.66e-05   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52099       |\n",
      "|    policy_loss        | -0.324      |\n",
      "|    reward             | 0.023510166 |\n",
      "|    std                | 1.09e+04    |\n",
      "|    value_loss         | 0.000344    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 52200       |\n",
      "|    time_elapsed       | 810         |\n",
      "|    total_timesteps    | 261000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.5       |\n",
      "|    explained_variance | 0.637       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52199       |\n",
      "|    policy_loss        | -0.18       |\n",
      "|    reward             | 0.003995563 |\n",
      "|    std                | 1.11e+04    |\n",
      "|    value_loss         | 0.000292    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 52300      |\n",
      "|    time_elapsed       | 812        |\n",
      "|    total_timesteps    | 261500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.5      |\n",
      "|    explained_variance | 0.567      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 52299      |\n",
      "|    policy_loss        | 0.707      |\n",
      "|    reward             | 0.03400453 |\n",
      "|    std                | 1.15e+04   |\n",
      "|    value_loss         | 0.00126    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 52400        |\n",
      "|    time_elapsed       | 813          |\n",
      "|    total_timesteps    | 262000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52399        |\n",
      "|    policy_loss        | -0.536       |\n",
      "|    reward             | -0.016298749 |\n",
      "|    std                | 1.16e+04     |\n",
      "|    value_loss         | 0.00117      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 52500       |\n",
      "|    time_elapsed       | 815         |\n",
      "|    total_timesteps    | 262500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.6       |\n",
      "|    explained_variance | 0.615       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52499       |\n",
      "|    policy_loss        | 0.601       |\n",
      "|    reward             | -0.09602351 |\n",
      "|    std                | 1.18e+04    |\n",
      "|    value_loss         | 0.00212     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 52600       |\n",
      "|    time_elapsed       | 817         |\n",
      "|    total_timesteps    | 263000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.6       |\n",
      "|    explained_variance | 0.0694      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52599       |\n",
      "|    policy_loss        | 5.06        |\n",
      "|    reward             | -0.15504077 |\n",
      "|    std                | 1.2e+04     |\n",
      "|    value_loss         | 0.074       |\n",
      "---------------------------------------\n",
      "day: 2770, episode: 95\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 78871.36\n",
      "total_reward: 68871.36\n",
      "total_cost: 17.62\n",
      "total_trades: 5540\n",
      "Sharpe: 0.725\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 52700       |\n",
      "|    time_elapsed       | 818         |\n",
      "|    total_timesteps    | 263500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.7       |\n",
      "|    explained_variance | -6.77       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52699       |\n",
      "|    policy_loss        | -0.383      |\n",
      "|    reward             | 0.017705442 |\n",
      "|    std                | 1.24e+04    |\n",
      "|    value_loss         | 0.000366    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 52800        |\n",
      "|    time_elapsed       | 820          |\n",
      "|    total_timesteps    | 264000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.7        |\n",
      "|    explained_variance | -0.127       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52799        |\n",
      "|    policy_loss        | 0.0356       |\n",
      "|    reward             | -0.009734878 |\n",
      "|    std                | 1.26e+04     |\n",
      "|    value_loss         | 1.88e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 52900      |\n",
      "|    time_elapsed       | 821        |\n",
      "|    total_timesteps    | 264500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 52899      |\n",
      "|    policy_loss        | 1.24       |\n",
      "|    reward             | 0.06189174 |\n",
      "|    std                | 1.29e+04   |\n",
      "|    value_loss         | 0.00473    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 53000       |\n",
      "|    time_elapsed       | 823         |\n",
      "|    total_timesteps    | 265000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.8       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52999       |\n",
      "|    policy_loss        | 0.601       |\n",
      "|    reward             | 0.025503315 |\n",
      "|    std                | 1.33e+04    |\n",
      "|    value_loss         | 0.00268     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 53100       |\n",
      "|    time_elapsed       | 824         |\n",
      "|    total_timesteps    | 265500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.9       |\n",
      "|    explained_variance | 0.535       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53099       |\n",
      "|    policy_loss        | 0.0729      |\n",
      "|    reward             | 0.105722465 |\n",
      "|    std                | 1.36e+04    |\n",
      "|    value_loss         | 0.00415     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 53200        |\n",
      "|    time_elapsed       | 826          |\n",
      "|    total_timesteps    | 266000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.9        |\n",
      "|    explained_variance | 0.205        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 53199        |\n",
      "|    policy_loss        | -8.29        |\n",
      "|    reward             | -0.052914664 |\n",
      "|    std                | 1.37e+04     |\n",
      "|    value_loss         | 0.239        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 53300        |\n",
      "|    time_elapsed       | 827          |\n",
      "|    total_timesteps    | 266500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 53299        |\n",
      "|    policy_loss        | -0.0447      |\n",
      "|    reward             | -0.009301214 |\n",
      "|    std                | 1.38e+04     |\n",
      "|    value_loss         | 6.32e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 53400       |\n",
      "|    time_elapsed       | 829         |\n",
      "|    total_timesteps    | 267000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.9       |\n",
      "|    explained_variance | -0.0912     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53399       |\n",
      "|    policy_loss        | -0.342      |\n",
      "|    reward             | 0.008869121 |\n",
      "|    std                | 1.41e+04    |\n",
      "|    value_loss         | 0.00108     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 53500       |\n",
      "|    time_elapsed       | 830         |\n",
      "|    total_timesteps    | 267500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22         |\n",
      "|    explained_variance | 0.257       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53499       |\n",
      "|    policy_loss        | 2.04        |\n",
      "|    reward             | 0.018349137 |\n",
      "|    std                | 1.44e+04    |\n",
      "|    value_loss         | 0.00956     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 53600        |\n",
      "|    time_elapsed       | 832          |\n",
      "|    total_timesteps    | 268000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22          |\n",
      "|    explained_variance | -1.06        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 53599        |\n",
      "|    policy_loss        | -1.04        |\n",
      "|    reward             | -0.018904654 |\n",
      "|    std                | 1.48e+04     |\n",
      "|    value_loss         | 0.00877      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 53700         |\n",
      "|    time_elapsed       | 833           |\n",
      "|    total_timesteps    | 268500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.1         |\n",
      "|    explained_variance | 0.131         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 53699         |\n",
      "|    policy_loss        | 0.715         |\n",
      "|    reward             | -0.0041308245 |\n",
      "|    std                | 1.5e+04       |\n",
      "|    value_loss         | 0.00337       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 53800       |\n",
      "|    time_elapsed       | 835         |\n",
      "|    total_timesteps    | 269000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.1       |\n",
      "|    explained_variance | -0.469      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53799       |\n",
      "|    policy_loss        | 0.338       |\n",
      "|    reward             | 0.008823635 |\n",
      "|    std                | 1.53e+04    |\n",
      "|    value_loss         | 0.000246    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 53900      |\n",
      "|    time_elapsed       | 836        |\n",
      "|    total_timesteps    | 269500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.1      |\n",
      "|    explained_variance | 3.2e-05    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 53899      |\n",
      "|    policy_loss        | -0.168     |\n",
      "|    reward             | 0.01138839 |\n",
      "|    std                | 1.56e+04   |\n",
      "|    value_loss         | 6.38e-05   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 54000        |\n",
      "|    time_elapsed       | 838          |\n",
      "|    total_timesteps    | 270000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.2        |\n",
      "|    explained_variance | 0.0672       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 53999        |\n",
      "|    policy_loss        | 0.304        |\n",
      "|    reward             | -0.031367306 |\n",
      "|    std                | 1.58e+04     |\n",
      "|    value_loss         | 0.00045      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 54100      |\n",
      "|    time_elapsed       | 839        |\n",
      "|    total_timesteps    | 270500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.2      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 54099      |\n",
      "|    policy_loss        | 0.304      |\n",
      "|    reward             | 0.09003857 |\n",
      "|    std                | 1.62e+04   |\n",
      "|    value_loss         | 0.00126    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 54200       |\n",
      "|    time_elapsed       | 841         |\n",
      "|    total_timesteps    | 271000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.2       |\n",
      "|    explained_variance | 0.218       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 54199       |\n",
      "|    policy_loss        | 2.42        |\n",
      "|    reward             | -0.08426056 |\n",
      "|    std                | 1.64e+04    |\n",
      "|    value_loss         | 0.0273      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 54300        |\n",
      "|    time_elapsed       | 842          |\n",
      "|    total_timesteps    | 271500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.2        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 54299        |\n",
      "|    policy_loss        | -1.59        |\n",
      "|    reward             | 0.0038869674 |\n",
      "|    std                | 1.65e+04     |\n",
      "|    value_loss         | 0.0079       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 54400         |\n",
      "|    time_elapsed       | 844           |\n",
      "|    total_timesteps    | 272000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.3         |\n",
      "|    explained_variance | 2.74e-06      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 54399         |\n",
      "|    policy_loss        | 0.427         |\n",
      "|    reward             | -0.0024948753 |\n",
      "|    std                | 1.67e+04      |\n",
      "|    value_loss         | 0.000483      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 54500         |\n",
      "|    time_elapsed       | 845           |\n",
      "|    total_timesteps    | 272500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 54499         |\n",
      "|    policy_loss        | 0.523         |\n",
      "|    reward             | -0.0025763954 |\n",
      "|    std                | 1.71e+04      |\n",
      "|    value_loss         | 0.00096       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 54600       |\n",
      "|    time_elapsed       | 847         |\n",
      "|    total_timesteps    | 273000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.4       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 54599       |\n",
      "|    policy_loss        | -0.148      |\n",
      "|    reward             | 0.008332183 |\n",
      "|    std                | 1.76e+04    |\n",
      "|    value_loss         | 0.00027     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 54700      |\n",
      "|    time_elapsed       | 848        |\n",
      "|    total_timesteps    | 273500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.4      |\n",
      "|    explained_variance | 0.465      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 54699      |\n",
      "|    policy_loss        | 0.136      |\n",
      "|    reward             | 0.03634323 |\n",
      "|    std                | 1.81e+04   |\n",
      "|    value_loss         | 0.000641   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 54800       |\n",
      "|    time_elapsed       | 850         |\n",
      "|    total_timesteps    | 274000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.4       |\n",
      "|    explained_variance | 0.254       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 54799       |\n",
      "|    policy_loss        | 0.315       |\n",
      "|    reward             | 0.047540285 |\n",
      "|    std                | 1.83e+04    |\n",
      "|    value_loss         | 0.00044     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 54900        |\n",
      "|    time_elapsed       | 851          |\n",
      "|    total_timesteps    | 274500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 54899        |\n",
      "|    policy_loss        | 0.549        |\n",
      "|    reward             | -0.041861903 |\n",
      "|    std                | 1.86e+04     |\n",
      "|    value_loss         | 0.000664     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 55000       |\n",
      "|    time_elapsed       | 853         |\n",
      "|    total_timesteps    | 275000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.5       |\n",
      "|    explained_variance | 0.945       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 54999       |\n",
      "|    policy_loss        | 0.525       |\n",
      "|    reward             | 0.013739175 |\n",
      "|    std                | 1.91e+04    |\n",
      "|    value_loss         | 0.000557    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 55100       |\n",
      "|    time_elapsed       | 854         |\n",
      "|    total_timesteps    | 275500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.6       |\n",
      "|    explained_variance | 3.76e-06    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 55099       |\n",
      "|    policy_loss        | 0.584       |\n",
      "|    reward             | 0.023207132 |\n",
      "|    std                | 1.98e+04    |\n",
      "|    value_loss         | 0.00111     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 55200        |\n",
      "|    time_elapsed       | 856          |\n",
      "|    total_timesteps    | 276000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.6        |\n",
      "|    explained_variance | 0.18         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55199        |\n",
      "|    policy_loss        | -2.85        |\n",
      "|    reward             | -0.020945895 |\n",
      "|    std                | 1.99e+04     |\n",
      "|    value_loss         | 0.0181       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 55300      |\n",
      "|    time_elapsed       | 858        |\n",
      "|    total_timesteps    | 276500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.6      |\n",
      "|    explained_variance | 0.0717     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 55299      |\n",
      "|    policy_loss        | 2.67       |\n",
      "|    reward             | 0.03212239 |\n",
      "|    std                | 2.01e+04   |\n",
      "|    value_loss         | 0.024      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 55400       |\n",
      "|    time_elapsed       | 859         |\n",
      "|    total_timesteps    | 277000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.6       |\n",
      "|    explained_variance | 0.107       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 55399       |\n",
      "|    policy_loss        | -2.63       |\n",
      "|    reward             | -0.15036577 |\n",
      "|    std                | 2.02e+04    |\n",
      "|    value_loss         | 0.0441      |\n",
      "---------------------------------------\n",
      "day: 2770, episode: 100\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 150976.92\n",
      "total_reward: 140976.92\n",
      "total_cost: 10.46\n",
      "total_trades: 5536\n",
      "Sharpe: 0.858\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 55500        |\n",
      "|    time_elapsed       | 861          |\n",
      "|    total_timesteps    | 277500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.7        |\n",
      "|    explained_variance | 2.53e-05     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55499        |\n",
      "|    policy_loss        | 0.853        |\n",
      "|    reward             | -0.024211438 |\n",
      "|    std                | 2.05e+04     |\n",
      "|    value_loss         | 0.00145      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 55600         |\n",
      "|    time_elapsed       | 862           |\n",
      "|    total_timesteps    | 278000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.7         |\n",
      "|    explained_variance | 0.0226        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 55599         |\n",
      "|    policy_loss        | 0.797         |\n",
      "|    reward             | -0.0049012145 |\n",
      "|    std                | 2.09e+04      |\n",
      "|    value_loss         | 0.00148       |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 322       |\n",
      "|    iterations         | 55700     |\n",
      "|    time_elapsed       | 864       |\n",
      "|    total_timesteps    | 278500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -22.7     |\n",
      "|    explained_variance | -0.0726   |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 55699     |\n",
      "|    policy_loss        | 2.12      |\n",
      "|    reward             | 0.0907025 |\n",
      "|    std                | 2.13e+04  |\n",
      "|    value_loss         | 0.00951   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 55800      |\n",
      "|    time_elapsed       | 865        |\n",
      "|    total_timesteps    | 279000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.8      |\n",
      "|    explained_variance | 0.778      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 55799      |\n",
      "|    policy_loss        | 0.528      |\n",
      "|    reward             | -0.0849566 |\n",
      "|    std                | 2.16e+04   |\n",
      "|    value_loss         | 0.000988   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 55900       |\n",
      "|    time_elapsed       | 867         |\n",
      "|    total_timesteps    | 279500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.8       |\n",
      "|    explained_variance | 0.381       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 55899       |\n",
      "|    policy_loss        | -0.566      |\n",
      "|    reward             | 0.014073601 |\n",
      "|    std                | 2.13e+04    |\n",
      "|    value_loss         | 0.00481     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 56000       |\n",
      "|    time_elapsed       | 868         |\n",
      "|    total_timesteps    | 280000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 55999       |\n",
      "|    policy_loss        | 0.732       |\n",
      "|    reward             | 0.008997328 |\n",
      "|    std                | 2.16e+04    |\n",
      "|    value_loss         | 0.00127     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 56100       |\n",
      "|    time_elapsed       | 870         |\n",
      "|    total_timesteps    | 280500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.8       |\n",
      "|    explained_variance | 0.792       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56099       |\n",
      "|    policy_loss        | -1.2        |\n",
      "|    reward             | 0.050358288 |\n",
      "|    std                | 2.17e+04    |\n",
      "|    value_loss         | 0.00282     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 56200       |\n",
      "|    time_elapsed       | 871         |\n",
      "|    total_timesteps    | 281000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.8       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56199       |\n",
      "|    policy_loss        | 1.06        |\n",
      "|    reward             | -0.09830341 |\n",
      "|    std                | 2.19e+04    |\n",
      "|    value_loss         | 0.00292     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 56300       |\n",
      "|    time_elapsed       | 873         |\n",
      "|    total_timesteps    | 281500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.8       |\n",
      "|    explained_variance | 0.605       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56299       |\n",
      "|    policy_loss        | -0.427      |\n",
      "|    reward             | -0.07617451 |\n",
      "|    std                | 2.21e+04    |\n",
      "|    value_loss         | 0.0093      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 56400       |\n",
      "|    time_elapsed       | 874         |\n",
      "|    total_timesteps    | 282000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.8       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56399       |\n",
      "|    policy_loss        | 10.9        |\n",
      "|    reward             | 0.026697816 |\n",
      "|    std                | 2.23e+04    |\n",
      "|    value_loss         | 0.239       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 56500        |\n",
      "|    time_elapsed       | 876          |\n",
      "|    total_timesteps    | 282500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.8        |\n",
      "|    explained_variance | 0.414        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 56499        |\n",
      "|    policy_loss        | 24           |\n",
      "|    reward             | -0.108313985 |\n",
      "|    std                | 2.21e+04     |\n",
      "|    value_loss         | 1.1          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 56600        |\n",
      "|    time_elapsed       | 877          |\n",
      "|    total_timesteps    | 283000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.8        |\n",
      "|    explained_variance | 0.799        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 56599        |\n",
      "|    policy_loss        | -2.8         |\n",
      "|    reward             | 0.0010176243 |\n",
      "|    std                | 2.24e+04     |\n",
      "|    value_loss         | 0.0156       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 56700       |\n",
      "|    time_elapsed       | 879         |\n",
      "|    total_timesteps    | 283500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.9       |\n",
      "|    explained_variance | -0.744      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56699       |\n",
      "|    policy_loss        | 0.0713      |\n",
      "|    reward             | 0.013937869 |\n",
      "|    std                | 2.27e+04    |\n",
      "|    value_loss         | 3.53e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 56800       |\n",
      "|    time_elapsed       | 880         |\n",
      "|    total_timesteps    | 284000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.9       |\n",
      "|    explained_variance | -0.12       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56799       |\n",
      "|    policy_loss        | 0.0905      |\n",
      "|    reward             | -0.02419523 |\n",
      "|    std                | 2.33e+04    |\n",
      "|    value_loss         | 0.000432    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 56900      |\n",
      "|    time_elapsed       | 882        |\n",
      "|    total_timesteps    | 284500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23        |\n",
      "|    explained_variance | 0.36       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 56899      |\n",
      "|    policy_loss        | -2.49      |\n",
      "|    reward             | -0.0688446 |\n",
      "|    std                | 2.39e+04   |\n",
      "|    value_loss         | 0.0122     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 57000       |\n",
      "|    time_elapsed       | 884         |\n",
      "|    total_timesteps    | 285000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23         |\n",
      "|    explained_variance | 0.114       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56999       |\n",
      "|    policy_loss        | -1.76       |\n",
      "|    reward             | -0.13571265 |\n",
      "|    std                | 2.42e+04    |\n",
      "|    value_loss         | 0.0154      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 57100       |\n",
      "|    time_elapsed       | 885         |\n",
      "|    total_timesteps    | 285500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23         |\n",
      "|    explained_variance | 8.08e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57099       |\n",
      "|    policy_loss        | -0.488      |\n",
      "|    reward             | 0.004221068 |\n",
      "|    std                | 2.47e+04    |\n",
      "|    value_loss         | 0.000498    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 322            |\n",
      "|    iterations         | 57200          |\n",
      "|    time_elapsed       | 887            |\n",
      "|    total_timesteps    | 286000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -23.1          |\n",
      "|    explained_variance | 0.228          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 57199          |\n",
      "|    policy_loss        | 0.0177         |\n",
      "|    reward             | -0.00031461983 |\n",
      "|    std                | 2.52e+04       |\n",
      "|    value_loss         | 0.000168       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 57300        |\n",
      "|    time_elapsed       | 888          |\n",
      "|    total_timesteps    | 286500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.1        |\n",
      "|    explained_variance | 0.613        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57299        |\n",
      "|    policy_loss        | 0.254        |\n",
      "|    reward             | 0.0042953985 |\n",
      "|    std                | 2.58e+04     |\n",
      "|    value_loss         | 0.000169     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 57400        |\n",
      "|    time_elapsed       | 890          |\n",
      "|    total_timesteps    | 287000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.2        |\n",
      "|    explained_variance | 0.252        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57399        |\n",
      "|    policy_loss        | 1.05         |\n",
      "|    reward             | -0.023541294 |\n",
      "|    std                | 2.64e+04     |\n",
      "|    value_loss         | 0.00263      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 57500       |\n",
      "|    time_elapsed       | 891         |\n",
      "|    total_timesteps    | 287500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.2       |\n",
      "|    explained_variance | 0.578       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57499       |\n",
      "|    policy_loss        | 0.968       |\n",
      "|    reward             | 0.052558534 |\n",
      "|    std                | 2.69e+04    |\n",
      "|    value_loss         | 0.00231     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 57600       |\n",
      "|    time_elapsed       | 893         |\n",
      "|    total_timesteps    | 288000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.2       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57599       |\n",
      "|    policy_loss        | 1.72        |\n",
      "|    reward             | -0.08904587 |\n",
      "|    std                | 2.74e+04    |\n",
      "|    value_loss         | 0.00713     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 57700       |\n",
      "|    time_elapsed       | 895         |\n",
      "|    total_timesteps    | 288500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.3       |\n",
      "|    explained_variance | 0.804       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57699       |\n",
      "|    policy_loss        | 0.00502     |\n",
      "|    reward             | 0.010144145 |\n",
      "|    std                | 2.76e+04    |\n",
      "|    value_loss         | 5.23e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 57800         |\n",
      "|    time_elapsed       | 896           |\n",
      "|    total_timesteps    | 289000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.3         |\n",
      "|    explained_variance | -2.15e-06     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 57799         |\n",
      "|    policy_loss        | -0.301        |\n",
      "|    reward             | 2.3618699e-05 |\n",
      "|    std                | 2.81e+04      |\n",
      "|    value_loss         | 0.000232      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 57900        |\n",
      "|    time_elapsed       | 898          |\n",
      "|    total_timesteps    | 289500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.3        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57899        |\n",
      "|    policy_loss        | -0.597       |\n",
      "|    reward             | -0.016872745 |\n",
      "|    std                | 2.87e+04     |\n",
      "|    value_loss         | 0.000853     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 58000      |\n",
      "|    time_elapsed       | 899        |\n",
      "|    total_timesteps    | 290000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 57999      |\n",
      "|    policy_loss        | -3.01      |\n",
      "|    reward             | 0.06437036 |\n",
      "|    std                | 2.89e+04   |\n",
      "|    value_loss         | 0.0201     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 58100       |\n",
      "|    time_elapsed       | 901         |\n",
      "|    total_timesteps    | 290500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.4       |\n",
      "|    explained_variance | 0.185       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58099       |\n",
      "|    policy_loss        | 3.77        |\n",
      "|    reward             | -0.20449655 |\n",
      "|    std                | 2.98e+04    |\n",
      "|    value_loss         | 0.0352      |\n",
      "---------------------------------------\n",
      "day: 2770, episode: 105\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 75016.67\n",
      "total_reward: 65016.67\n",
      "total_cost: 14.26\n",
      "total_trades: 5539\n",
      "Sharpe: 0.716\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 58200         |\n",
      "|    time_elapsed       | 902           |\n",
      "|    total_timesteps    | 291000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.4         |\n",
      "|    explained_variance | -11.9         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 58199         |\n",
      "|    policy_loss        | -2.09         |\n",
      "|    reward             | -0.0024441772 |\n",
      "|    std                | 2.99e+04      |\n",
      "|    value_loss         | 0.00924       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 58300         |\n",
      "|    time_elapsed       | 904           |\n",
      "|    total_timesteps    | 291500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.5         |\n",
      "|    explained_variance | 6.56e-06      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 58299         |\n",
      "|    policy_loss        | 0.124         |\n",
      "|    reward             | -0.0068721822 |\n",
      "|    std                | 3.03e+04      |\n",
      "|    value_loss         | 6.54e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 58400       |\n",
      "|    time_elapsed       | 906         |\n",
      "|    total_timesteps    | 292000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.5       |\n",
      "|    explained_variance | -0.00501    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58399       |\n",
      "|    policy_loss        | -0.231      |\n",
      "|    reward             | 0.009925893 |\n",
      "|    std                | 3.08e+04    |\n",
      "|    value_loss         | 0.00015     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 58500         |\n",
      "|    time_elapsed       | 907           |\n",
      "|    total_timesteps    | 292500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.5         |\n",
      "|    explained_variance | -1.23         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 58499         |\n",
      "|    policy_loss        | 0.263         |\n",
      "|    reward             | -0.0004351013 |\n",
      "|    std                | 3.14e+04      |\n",
      "|    value_loss         | 0.000266      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 58600       |\n",
      "|    time_elapsed       | 909         |\n",
      "|    total_timesteps    | 293000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.6       |\n",
      "|    explained_variance | 0.0186      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58599       |\n",
      "|    policy_loss        | 0.364       |\n",
      "|    reward             | -0.00713251 |\n",
      "|    std                | 3.27e+04    |\n",
      "|    value_loss         | 0.000218    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 58700        |\n",
      "|    time_elapsed       | 910          |\n",
      "|    total_timesteps    | 293500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.6        |\n",
      "|    explained_variance | 0.149        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 58699        |\n",
      "|    policy_loss        | 0.356        |\n",
      "|    reward             | -0.011547485 |\n",
      "|    std                | 3.33e+04     |\n",
      "|    value_loss         | 0.000436     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 58800        |\n",
      "|    time_elapsed       | 912          |\n",
      "|    total_timesteps    | 294000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 58799        |\n",
      "|    policy_loss        | 0.681        |\n",
      "|    reward             | -0.004930961 |\n",
      "|    std                | 3.42e+04     |\n",
      "|    value_loss         | 0.0015       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 58900         |\n",
      "|    time_elapsed       | 913           |\n",
      "|    total_timesteps    | 294500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.8         |\n",
      "|    explained_variance | 0.439         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 58899         |\n",
      "|    policy_loss        | 0.0269        |\n",
      "|    reward             | -0.0055645118 |\n",
      "|    std                | 3.5e+04       |\n",
      "|    value_loss         | 0.000349      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 59000       |\n",
      "|    time_elapsed       | 915         |\n",
      "|    total_timesteps    | 295000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.8       |\n",
      "|    explained_variance | 0.0039      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58999       |\n",
      "|    policy_loss        | -1.24       |\n",
      "|    reward             | -0.04664553 |\n",
      "|    std                | 3.55e+04    |\n",
      "|    value_loss         | 0.00308     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 59100        |\n",
      "|    time_elapsed       | 916          |\n",
      "|    total_timesteps    | 295500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.8        |\n",
      "|    explained_variance | -0.0345      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 59099        |\n",
      "|    policy_loss        | -0.653       |\n",
      "|    reward             | 0.0064015617 |\n",
      "|    std                | 3.61e+04     |\n",
      "|    value_loss         | 0.000766     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 59200        |\n",
      "|    time_elapsed       | 918          |\n",
      "|    total_timesteps    | 296000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.8        |\n",
      "|    explained_variance | 0.0254       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 59199        |\n",
      "|    policy_loss        | -0.304       |\n",
      "|    reward             | -0.026300274 |\n",
      "|    std                | 3.63e+04     |\n",
      "|    value_loss         | 0.00111      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 59300         |\n",
      "|    time_elapsed       | 919           |\n",
      "|    total_timesteps    | 296500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 59299         |\n",
      "|    policy_loss        | 3.21          |\n",
      "|    reward             | -0.0011172789 |\n",
      "|    std                | 3.65e+04      |\n",
      "|    value_loss         | 0.0348        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 59400       |\n",
      "|    time_elapsed       | 921         |\n",
      "|    total_timesteps    | 297000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 59399       |\n",
      "|    policy_loss        | -0.362      |\n",
      "|    reward             | 0.008144754 |\n",
      "|    std                | 3.72e+04    |\n",
      "|    value_loss         | 0.000232    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 59500        |\n",
      "|    time_elapsed       | 922          |\n",
      "|    total_timesteps    | 297500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 59499        |\n",
      "|    policy_loss        | 0.944        |\n",
      "|    reward             | -0.002475996 |\n",
      "|    std                | 3.83e+04     |\n",
      "|    value_loss         | 0.00174      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 59600       |\n",
      "|    time_elapsed       | 924         |\n",
      "|    total_timesteps    | 298000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 59599       |\n",
      "|    policy_loss        | 2.11        |\n",
      "|    reward             | 0.047698356 |\n",
      "|    std                | 3.93e+04    |\n",
      "|    value_loss         | 0.0146      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 59700       |\n",
      "|    time_elapsed       | 926         |\n",
      "|    total_timesteps    | 298500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24         |\n",
      "|    explained_variance | -0.197      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 59699       |\n",
      "|    policy_loss        | 2.36        |\n",
      "|    reward             | -0.33223248 |\n",
      "|    std                | 3.96e+04    |\n",
      "|    value_loss         | 0.0126      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 59800      |\n",
      "|    time_elapsed       | 927        |\n",
      "|    total_timesteps    | 299000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24        |\n",
      "|    explained_variance | 0.0367     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 59799      |\n",
      "|    policy_loss        | -3.44      |\n",
      "|    reward             | -0.7876957 |\n",
      "|    std                | 3.98e+04   |\n",
      "|    value_loss         | 0.0462     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 59900       |\n",
      "|    time_elapsed       | 929         |\n",
      "|    total_timesteps    | 299500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24         |\n",
      "|    explained_variance | 0.00758     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 59899       |\n",
      "|    policy_loss        | -0.722      |\n",
      "|    reward             | 0.020819852 |\n",
      "|    std                | 3.99e+04    |\n",
      "|    value_loss         | 0.00154     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 60000         |\n",
      "|    time_elapsed       | 930           |\n",
      "|    total_timesteps    | 300000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24           |\n",
      "|    explained_variance | 0.393         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 59999         |\n",
      "|    policy_loss        | -0.254        |\n",
      "|    reward             | -0.0015736549 |\n",
      "|    std                | 4.03e+04      |\n",
      "|    value_loss         | 0.000268      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 60100       |\n",
      "|    time_elapsed       | 932         |\n",
      "|    total_timesteps    | 300500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.1       |\n",
      "|    explained_variance | 0.359       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 60099       |\n",
      "|    policy_loss        | 0.548       |\n",
      "|    reward             | 0.007857653 |\n",
      "|    std                | 4.08e+04    |\n",
      "|    value_loss         | 0.000736    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 60200         |\n",
      "|    time_elapsed       | 933           |\n",
      "|    total_timesteps    | 301000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.1         |\n",
      "|    explained_variance | -5.22         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 60199         |\n",
      "|    policy_loss        | 0.987         |\n",
      "|    reward             | -0.0074199876 |\n",
      "|    std                | 4.17e+04      |\n",
      "|    value_loss         | 0.00202       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 60300       |\n",
      "|    time_elapsed       | 935         |\n",
      "|    total_timesteps    | 301500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 60299       |\n",
      "|    policy_loss        | 0.468       |\n",
      "|    reward             | 0.011776547 |\n",
      "|    std                | 4.25e+04    |\n",
      "|    value_loss         | 0.00042     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 60400       |\n",
      "|    time_elapsed       | 936         |\n",
      "|    total_timesteps    | 302000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.1       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 60399       |\n",
      "|    policy_loss        | 0.154       |\n",
      "|    reward             | 0.035084803 |\n",
      "|    std                | 4.27e+04    |\n",
      "|    value_loss         | 0.00901     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 60500        |\n",
      "|    time_elapsed       | 938          |\n",
      "|    total_timesteps    | 302500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.2        |\n",
      "|    explained_variance | 1.99e-05     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60499        |\n",
      "|    policy_loss        | 0.0883       |\n",
      "|    reward             | 0.0032430629 |\n",
      "|    std                | 4.35e+04     |\n",
      "|    value_loss         | 0.000117     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 60600        |\n",
      "|    time_elapsed       | 939          |\n",
      "|    total_timesteps    | 303000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60599        |\n",
      "|    policy_loss        | 0.183        |\n",
      "|    reward             | 0.0034537334 |\n",
      "|    std                | 4.47e+04     |\n",
      "|    value_loss         | 0.000114     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 60700        |\n",
      "|    time_elapsed       | 941          |\n",
      "|    total_timesteps    | 303500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.3        |\n",
      "|    explained_variance | 0.164        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60699        |\n",
      "|    policy_loss        | -0.902       |\n",
      "|    reward             | 0.0016043205 |\n",
      "|    std                | 4.61e+04     |\n",
      "|    value_loss         | 0.00165      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 60800        |\n",
      "|    time_elapsed       | 942          |\n",
      "|    total_timesteps    | 304000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.4        |\n",
      "|    explained_variance | 0.146        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60799        |\n",
      "|    policy_loss        | 0.806        |\n",
      "|    reward             | -0.009040043 |\n",
      "|    std                | 4.76e+04     |\n",
      "|    value_loss         | 0.00172      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 60900        |\n",
      "|    time_elapsed       | 944          |\n",
      "|    total_timesteps    | 304500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60899        |\n",
      "|    policy_loss        | -0.66        |\n",
      "|    reward             | -0.018245017 |\n",
      "|    std                | 4.91e+04     |\n",
      "|    value_loss         | 0.000829     |\n",
      "----------------------------------------\n",
      "day: 2770, episode: 110\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 32333.62\n",
      "total_reward: 22333.62\n",
      "total_cost: 11.78\n",
      "total_trades: 5540\n",
      "Sharpe: 0.536\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 61000         |\n",
      "|    time_elapsed       | 945           |\n",
      "|    total_timesteps    | 305000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.5         |\n",
      "|    explained_variance | 0.000169      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 60999         |\n",
      "|    policy_loss        | 0.0354        |\n",
      "|    reward             | -0.0054331846 |\n",
      "|    std                | 5.02e+04      |\n",
      "|    value_loss         | 1.87e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 61100       |\n",
      "|    time_elapsed       | 947         |\n",
      "|    total_timesteps    | 305500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.5       |\n",
      "|    explained_variance | 0.415       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 61099       |\n",
      "|    policy_loss        | -0.195      |\n",
      "|    reward             | 0.002223119 |\n",
      "|    std                | 5.15e+04    |\n",
      "|    value_loss         | 0.000142    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 61200       |\n",
      "|    time_elapsed       | 948         |\n",
      "|    total_timesteps    | 306000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 61199       |\n",
      "|    policy_loss        | -1.26       |\n",
      "|    reward             | 0.018477554 |\n",
      "|    std                | 5.33e+04    |\n",
      "|    value_loss         | 0.00324     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 61300       |\n",
      "|    time_elapsed       | 950         |\n",
      "|    total_timesteps    | 306500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.6       |\n",
      "|    explained_variance | 0.739       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 61299       |\n",
      "|    policy_loss        | 1.09        |\n",
      "|    reward             | 0.027255889 |\n",
      "|    std                | 5.47e+04    |\n",
      "|    value_loss         | 0.00218     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 61400      |\n",
      "|    time_elapsed       | 951        |\n",
      "|    total_timesteps    | 307000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 61399      |\n",
      "|    policy_loss        | -0.696     |\n",
      "|    reward             | 0.08497969 |\n",
      "|    std                | 5.54e+04   |\n",
      "|    value_loss         | 0.00331    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 61500      |\n",
      "|    time_elapsed       | 953        |\n",
      "|    total_timesteps    | 307500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 61499      |\n",
      "|    policy_loss        | 3.89       |\n",
      "|    reward             | 0.07747621 |\n",
      "|    std                | 5.64e+04   |\n",
      "|    value_loss         | 0.0267     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 61600       |\n",
      "|    time_elapsed       | 954         |\n",
      "|    total_timesteps    | 308000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.7       |\n",
      "|    explained_variance | 0.49        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 61599       |\n",
      "|    policy_loss        | -2          |\n",
      "|    reward             | 0.019088848 |\n",
      "|    std                | 5.7e+04     |\n",
      "|    value_loss         | 0.00704     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 61700      |\n",
      "|    time_elapsed       | 956        |\n",
      "|    total_timesteps    | 308500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24.8      |\n",
      "|    explained_variance | 0.514      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 61699      |\n",
      "|    policy_loss        | 0.842      |\n",
      "|    reward             | 0.00465127 |\n",
      "|    std                | 5.82e+04   |\n",
      "|    value_loss         | 0.00162    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 61800      |\n",
      "|    time_elapsed       | 958        |\n",
      "|    total_timesteps    | 309000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 61799      |\n",
      "|    policy_loss        | -4.1       |\n",
      "|    reward             | 0.13543573 |\n",
      "|    std                | 5.89e+04   |\n",
      "|    value_loss         | 0.0364     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 61900        |\n",
      "|    time_elapsed       | 959          |\n",
      "|    total_timesteps    | 309500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61899        |\n",
      "|    policy_loss        | 10.5         |\n",
      "|    reward             | 0.0069576446 |\n",
      "|    std                | 5.96e+04     |\n",
      "|    value_loss         | 0.198        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 62000       |\n",
      "|    time_elapsed       | 961         |\n",
      "|    total_timesteps    | 310000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 61999       |\n",
      "|    policy_loss        | 4.61        |\n",
      "|    reward             | 0.070311606 |\n",
      "|    std                | 6e+04       |\n",
      "|    value_loss         | 0.0374      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 62100         |\n",
      "|    time_elapsed       | 962           |\n",
      "|    total_timesteps    | 310500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.8         |\n",
      "|    explained_variance | 0.157         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 62099         |\n",
      "|    policy_loss        | -0.444        |\n",
      "|    reward             | -0.0125845345 |\n",
      "|    std                | 6.01e+04      |\n",
      "|    value_loss         | 0.000478      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 62200         |\n",
      "|    time_elapsed       | 964           |\n",
      "|    total_timesteps    | 311000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.9         |\n",
      "|    explained_variance | 0.786         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 62199         |\n",
      "|    policy_loss        | -0.318        |\n",
      "|    reward             | -0.0045115985 |\n",
      "|    std                | 6.06e+04      |\n",
      "|    value_loss         | 0.000193      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 62300       |\n",
      "|    time_elapsed       | 966         |\n",
      "|    total_timesteps    | 311500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.9       |\n",
      "|    explained_variance | 0.0123      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 62299       |\n",
      "|    policy_loss        | -1.72       |\n",
      "|    reward             | -0.03170922 |\n",
      "|    std                | 6.18e+04    |\n",
      "|    value_loss         | 0.0154      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 62400        |\n",
      "|    time_elapsed       | 967          |\n",
      "|    total_timesteps    | 312000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.9        |\n",
      "|    explained_variance | 0.437        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62399        |\n",
      "|    policy_loss        | 0.694        |\n",
      "|    reward             | -0.018053155 |\n",
      "|    std                | 6.26e+04     |\n",
      "|    value_loss         | 0.00135      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 62500        |\n",
      "|    time_elapsed       | 969          |\n",
      "|    total_timesteps    | 312500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62499        |\n",
      "|    policy_loss        | -0.394       |\n",
      "|    reward             | -0.071898796 |\n",
      "|    std                | 6.37e+04     |\n",
      "|    value_loss         | 0.000851     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 62600      |\n",
      "|    time_elapsed       | 970        |\n",
      "|    total_timesteps    | 313000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25        |\n",
      "|    explained_variance | 0.338      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 62599      |\n",
      "|    policy_loss        | 2.34       |\n",
      "|    reward             | 0.07973965 |\n",
      "|    std                | 6.47e+04   |\n",
      "|    value_loss         | 0.0186     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 62700        |\n",
      "|    time_elapsed       | 972          |\n",
      "|    total_timesteps    | 313500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62699        |\n",
      "|    policy_loss        | -2.39        |\n",
      "|    reward             | -0.059107743 |\n",
      "|    std                | 6.49e+04     |\n",
      "|    value_loss         | 0.00946      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 62800       |\n",
      "|    time_elapsed       | 974         |\n",
      "|    total_timesteps    | 314000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 62799       |\n",
      "|    policy_loss        | 0.648       |\n",
      "|    reward             | 0.002944008 |\n",
      "|    std                | 6.62e+04    |\n",
      "|    value_loss         | 0.000686    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 62900        |\n",
      "|    time_elapsed       | 975          |\n",
      "|    total_timesteps    | 314500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62899        |\n",
      "|    policy_loss        | 1.11         |\n",
      "|    reward             | -0.005483124 |\n",
      "|    std                | 6.78e+04     |\n",
      "|    value_loss         | 0.00469      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 63000       |\n",
      "|    time_elapsed       | 977         |\n",
      "|    total_timesteps    | 315000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.1       |\n",
      "|    explained_variance | -0.481      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 62999       |\n",
      "|    policy_loss        | -1.8        |\n",
      "|    reward             | 0.016474973 |\n",
      "|    std                | 6.87e+04    |\n",
      "|    value_loss         | 0.0071      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 63100       |\n",
      "|    time_elapsed       | 978         |\n",
      "|    total_timesteps    | 315500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.1       |\n",
      "|    explained_variance | 0.0719      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63099       |\n",
      "|    policy_loss        | 1.15        |\n",
      "|    reward             | 0.120967686 |\n",
      "|    std                | 6.96e+04    |\n",
      "|    value_loss         | 0.00592     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 63200       |\n",
      "|    time_elapsed       | 980         |\n",
      "|    total_timesteps    | 316000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.1       |\n",
      "|    explained_variance | 0.48        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63199       |\n",
      "|    policy_loss        | -0.216      |\n",
      "|    reward             | 0.024593437 |\n",
      "|    std                | 6.91e+04    |\n",
      "|    value_loss         | 0.000153    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 63300        |\n",
      "|    time_elapsed       | 981          |\n",
      "|    total_timesteps    | 316500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63299        |\n",
      "|    policy_loss        | -0.0762      |\n",
      "|    reward             | 0.0015173969 |\n",
      "|    std                | 7.02e+04     |\n",
      "|    value_loss         | 0.000112     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 63400         |\n",
      "|    time_elapsed       | 983           |\n",
      "|    total_timesteps    | 317000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.2         |\n",
      "|    explained_variance | 0.504         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 63399         |\n",
      "|    policy_loss        | 1.65          |\n",
      "|    reward             | -0.0023368192 |\n",
      "|    std                | 7.22e+04      |\n",
      "|    value_loss         | 0.00462       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 63500      |\n",
      "|    time_elapsed       | 984        |\n",
      "|    total_timesteps    | 317500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 63499      |\n",
      "|    policy_loss        | 2.25       |\n",
      "|    reward             | 0.01830805 |\n",
      "|    std                | 7.38e+04   |\n",
      "|    value_loss         | 0.012      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 63600       |\n",
      "|    time_elapsed       | 986         |\n",
      "|    total_timesteps    | 318000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63599       |\n",
      "|    policy_loss        | -1.97       |\n",
      "|    reward             | -0.03545042 |\n",
      "|    std                | 7.45e+04    |\n",
      "|    value_loss         | 0.017       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 63700       |\n",
      "|    time_elapsed       | 987         |\n",
      "|    total_timesteps    | 318500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63699       |\n",
      "|    policy_loss        | 5.73        |\n",
      "|    reward             | -0.10446923 |\n",
      "|    std                | 7.47e+04    |\n",
      "|    value_loss         | 0.0575      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2770, episode: 115\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 167262.19\n",
      "total_reward: 157262.19\n",
      "total_cost: 22.92\n",
      "total_trades: 5535\n",
      "Sharpe: 0.883\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 63800        |\n",
      "|    time_elapsed       | 989          |\n",
      "|    total_timesteps    | 319000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.3        |\n",
      "|    explained_variance | -6.1         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63799        |\n",
      "|    policy_loss        | -0.262       |\n",
      "|    reward             | -0.010497892 |\n",
      "|    std                | 7.48e+04     |\n",
      "|    value_loss         | 0.000355     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 63900         |\n",
      "|    time_elapsed       | 990           |\n",
      "|    total_timesteps    | 319500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.3         |\n",
      "|    explained_variance | 4.47e-06      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 63899         |\n",
      "|    policy_loss        | -0.212        |\n",
      "|    reward             | -0.0052002026 |\n",
      "|    std                | 7.58e+04      |\n",
      "|    value_loss         | 0.000109      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 64000        |\n",
      "|    time_elapsed       | 992          |\n",
      "|    total_timesteps    | 320000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.3        |\n",
      "|    explained_variance | 0.386        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63999        |\n",
      "|    policy_loss        | -0.51        |\n",
      "|    reward             | -0.050339576 |\n",
      "|    std                | 7.75e+04     |\n",
      "|    value_loss         | 0.000913     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 64100        |\n",
      "|    time_elapsed       | 993          |\n",
      "|    total_timesteps    | 320500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.4        |\n",
      "|    explained_variance | 0.594        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 64099        |\n",
      "|    policy_loss        | 1.24         |\n",
      "|    reward             | -0.014295236 |\n",
      "|    std                | 7.9e+04      |\n",
      "|    value_loss         | 0.00294      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 64200      |\n",
      "|    time_elapsed       | 995        |\n",
      "|    total_timesteps    | 321000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 64199      |\n",
      "|    policy_loss        | -2.82      |\n",
      "|    reward             | 0.11397674 |\n",
      "|    std                | 7.9e+04    |\n",
      "|    value_loss         | 0.0183     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 64300         |\n",
      "|    time_elapsed       | 996           |\n",
      "|    total_timesteps    | 321500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.4         |\n",
      "|    explained_variance | 0.109         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 64299         |\n",
      "|    policy_loss        | -0.834        |\n",
      "|    reward             | -0.0009007118 |\n",
      "|    std                | 7.9e+04       |\n",
      "|    value_loss         | 0.00145       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 64400        |\n",
      "|    time_elapsed       | 998          |\n",
      "|    total_timesteps    | 322000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.4        |\n",
      "|    explained_variance | 0.385        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 64399        |\n",
      "|    policy_loss        | 0.293        |\n",
      "|    reward             | 0.0031480289 |\n",
      "|    std                | 7.99e+04     |\n",
      "|    value_loss         | 0.000152     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 64500         |\n",
      "|    time_elapsed       | 999           |\n",
      "|    total_timesteps    | 322500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.4         |\n",
      "|    explained_variance | 0.215         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 64499         |\n",
      "|    policy_loss        | -0.0304       |\n",
      "|    reward             | -0.0074756304 |\n",
      "|    std                | 8.15e+04      |\n",
      "|    value_loss         | 3.66e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 64600        |\n",
      "|    time_elapsed       | 1001         |\n",
      "|    total_timesteps    | 323000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.5        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 64599        |\n",
      "|    policy_loss        | -0.961       |\n",
      "|    reward             | -0.025042603 |\n",
      "|    std                | 8.28e+04     |\n",
      "|    value_loss         | 0.00147      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 64700       |\n",
      "|    time_elapsed       | 1003        |\n",
      "|    total_timesteps    | 323500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 64699       |\n",
      "|    policy_loss        | 2.42        |\n",
      "|    reward             | 0.020889826 |\n",
      "|    std                | 8.5e+04     |\n",
      "|    value_loss         | 0.0103      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 64800       |\n",
      "|    time_elapsed       | 1004        |\n",
      "|    total_timesteps    | 324000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 64799       |\n",
      "|    policy_loss        | 3.27        |\n",
      "|    reward             | -0.02744016 |\n",
      "|    std                | 8.6e+04     |\n",
      "|    value_loss         | 0.0172      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 64900        |\n",
      "|    time_elapsed       | 1006         |\n",
      "|    total_timesteps    | 324500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 64899        |\n",
      "|    policy_loss        | -1.58        |\n",
      "|    reward             | -0.019008022 |\n",
      "|    std                | 8.76e+04     |\n",
      "|    value_loss         | 0.00382      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 65000       |\n",
      "|    time_elapsed       | 1008        |\n",
      "|    total_timesteps    | 325000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.6       |\n",
      "|    explained_variance | 0.00142     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 64999       |\n",
      "|    policy_loss        | 0.484       |\n",
      "|    reward             | 0.011262895 |\n",
      "|    std                | 8.95e+04    |\n",
      "|    value_loss         | 0.000494    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 65100        |\n",
      "|    time_elapsed       | 1009         |\n",
      "|    total_timesteps    | 325500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.7        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65099        |\n",
      "|    policy_loss        | 1.53         |\n",
      "|    reward             | 0.0060994676 |\n",
      "|    std                | 9.25e+04     |\n",
      "|    value_loss         | 0.00353      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 65200      |\n",
      "|    time_elapsed       | 1011       |\n",
      "|    total_timesteps    | 326000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.8      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 65199      |\n",
      "|    policy_loss        | 1.04       |\n",
      "|    reward             | 0.03200774 |\n",
      "|    std                | 9.49e+04   |\n",
      "|    value_loss         | 0.00212    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 65300       |\n",
      "|    time_elapsed       | 1012        |\n",
      "|    total_timesteps    | 326500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.8       |\n",
      "|    explained_variance | -0.037      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 65299       |\n",
      "|    policy_loss        | -1.78       |\n",
      "|    reward             | -0.24234559 |\n",
      "|    std                | 9.57e+04    |\n",
      "|    value_loss         | 0.00661     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 65400        |\n",
      "|    time_elapsed       | 1014         |\n",
      "|    total_timesteps    | 327000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.8        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65399        |\n",
      "|    policy_loss        | -1.12        |\n",
      "|    reward             | -0.045081332 |\n",
      "|    std                | 9.73e+04     |\n",
      "|    value_loss         | 0.00203      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 65500       |\n",
      "|    time_elapsed       | 1015        |\n",
      "|    total_timesteps    | 327500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.8       |\n",
      "|    explained_variance | 0.0516      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 65499       |\n",
      "|    policy_loss        | -0.0473     |\n",
      "|    reward             | 0.015834317 |\n",
      "|    std                | 9.89e+04    |\n",
      "|    value_loss         | 0.000277    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 65600       |\n",
      "|    time_elapsed       | 1016        |\n",
      "|    total_timesteps    | 328000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.9       |\n",
      "|    explained_variance | 0.572       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 65599       |\n",
      "|    policy_loss        | -0.705      |\n",
      "|    reward             | 0.020519868 |\n",
      "|    std                | 1e+05       |\n",
      "|    value_loss         | 0.00194     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 65700       |\n",
      "|    time_elapsed       | 1018        |\n",
      "|    total_timesteps    | 328500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.9       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 65699       |\n",
      "|    policy_loss        | -0.688      |\n",
      "|    reward             | -0.09726502 |\n",
      "|    std                | 1.01e+05    |\n",
      "|    value_loss         | 0.00152     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 65800      |\n",
      "|    time_elapsed       | 1019       |\n",
      "|    total_timesteps    | 329000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.9      |\n",
      "|    explained_variance | 0.0119     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 65799      |\n",
      "|    policy_loss        | -4.76      |\n",
      "|    reward             | 0.16235833 |\n",
      "|    std                | 1.01e+05   |\n",
      "|    value_loss         | 0.0426     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 65900      |\n",
      "|    time_elapsed       | 1021       |\n",
      "|    total_timesteps    | 329500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.9      |\n",
      "|    explained_variance | 0.0883     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 65899      |\n",
      "|    policy_loss        | -7.43      |\n",
      "|    reward             | 0.25508714 |\n",
      "|    std                | 1.02e+05   |\n",
      "|    value_loss         | 0.144      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 66000        |\n",
      "|    time_elapsed       | 1022         |\n",
      "|    total_timesteps    | 330000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.9        |\n",
      "|    explained_variance | -16.7        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65999        |\n",
      "|    policy_loss        | -0.326       |\n",
      "|    reward             | 0.0072731315 |\n",
      "|    std                | 1.03e+05     |\n",
      "|    value_loss         | 0.000615     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 322            |\n",
      "|    iterations         | 66100          |\n",
      "|    time_elapsed       | 1024           |\n",
      "|    total_timesteps    | 330500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -25.9          |\n",
      "|    explained_variance | -0.00708       |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 66099          |\n",
      "|    policy_loss        | 0.00383        |\n",
      "|    reward             | -0.00054487097 |\n",
      "|    std                | 1.05e+05       |\n",
      "|    value_loss         | 5.2e-05        |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 66200       |\n",
      "|    time_elapsed       | 1026        |\n",
      "|    total_timesteps    | 331000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66199       |\n",
      "|    policy_loss        | 0.997       |\n",
      "|    reward             | 0.012429776 |\n",
      "|    std                | 1.07e+05    |\n",
      "|    value_loss         | 0.00168     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 66300       |\n",
      "|    time_elapsed       | 1027        |\n",
      "|    total_timesteps    | 331500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26         |\n",
      "|    explained_variance | -2.98e-06   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66299       |\n",
      "|    policy_loss        | 0.592       |\n",
      "|    reward             | -0.03430824 |\n",
      "|    std                | 1.09e+05    |\n",
      "|    value_loss         | 0.000545    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 66400      |\n",
      "|    time_elapsed       | 1029       |\n",
      "|    total_timesteps    | 332000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 66399      |\n",
      "|    policy_loss        | -1.36      |\n",
      "|    reward             | 0.01988598 |\n",
      "|    std                | 1.1e+05    |\n",
      "|    value_loss         | 0.00313    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 66500       |\n",
      "|    time_elapsed       | 1030        |\n",
      "|    total_timesteps    | 332500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.1       |\n",
      "|    explained_variance | 0.0609      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66499       |\n",
      "|    policy_loss        | 5.42        |\n",
      "|    reward             | -0.37274626 |\n",
      "|    std                | 1.11e+05    |\n",
      "|    value_loss         | 0.0539      |\n",
      "---------------------------------------\n",
      "day: 2770, episode: 120\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 70946.86\n",
      "total_reward: 60946.86\n",
      "total_cost: 10.37\n",
      "total_trades: 5540\n",
      "Sharpe: 0.707\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 66600       |\n",
      "|    time_elapsed       | 1032        |\n",
      "|    total_timesteps    | 333000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.1       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66599       |\n",
      "|    policy_loss        | -0.073      |\n",
      "|    reward             | 0.013016949 |\n",
      "|    std                | 1.13e+05    |\n",
      "|    value_loss         | 5.52e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 66700       |\n",
      "|    time_elapsed       | 1033        |\n",
      "|    total_timesteps    | 333500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.1       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66699       |\n",
      "|    policy_loss        | -0.818      |\n",
      "|    reward             | 0.020221008 |\n",
      "|    std                | 1.16e+05    |\n",
      "|    value_loss         | 0.00137     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 66800        |\n",
      "|    time_elapsed       | 1035         |\n",
      "|    total_timesteps    | 334000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.2        |\n",
      "|    explained_variance | 0.247        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 66799        |\n",
      "|    policy_loss        | -3.23        |\n",
      "|    reward             | -0.070248164 |\n",
      "|    std                | 1.18e+05     |\n",
      "|    value_loss         | 0.0246       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 66900      |\n",
      "|    time_elapsed       | 1036       |\n",
      "|    total_timesteps    | 334500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 66899      |\n",
      "|    policy_loss        | -7.72      |\n",
      "|    reward             | 0.17696409 |\n",
      "|    std                | 1.2e+05    |\n",
      "|    value_loss         | 0.098      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 67000      |\n",
      "|    time_elapsed       | 1038       |\n",
      "|    total_timesteps    | 335000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.2      |\n",
      "|    explained_variance | 9.72e-05   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 66999      |\n",
      "|    policy_loss        | -5.95      |\n",
      "|    reward             | -0.1046402 |\n",
      "|    std                | 1.21e+05   |\n",
      "|    value_loss         | 0.0658     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 67100       |\n",
      "|    time_elapsed       | 1039        |\n",
      "|    total_timesteps    | 335500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.3       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 67099       |\n",
      "|    policy_loss        | -0.92       |\n",
      "|    reward             | -0.04983399 |\n",
      "|    std                | 1.23e+05    |\n",
      "|    value_loss         | 0.00167     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 67200      |\n",
      "|    time_elapsed       | 1041       |\n",
      "|    total_timesteps    | 336000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 67199      |\n",
      "|    policy_loss        | 0.497      |\n",
      "|    reward             | 0.01504161 |\n",
      "|    std                | 1.25e+05   |\n",
      "|    value_loss         | 0.000414   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 67300       |\n",
      "|    time_elapsed       | 1042        |\n",
      "|    total_timesteps    | 336500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.3       |\n",
      "|    explained_variance | -0.0286     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 67299       |\n",
      "|    policy_loss        | 0.0872      |\n",
      "|    reward             | 0.018056337 |\n",
      "|    std                | 1.26e+05    |\n",
      "|    value_loss         | 0.00855     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 67400       |\n",
      "|    time_elapsed       | 1044        |\n",
      "|    total_timesteps    | 337000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 67399       |\n",
      "|    policy_loss        | 0.188       |\n",
      "|    reward             | 0.045991004 |\n",
      "|    std                | 1.26e+05    |\n",
      "|    value_loss         | 0.00258     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 67500      |\n",
      "|    time_elapsed       | 1045       |\n",
      "|    total_timesteps    | 337500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.4      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 67499      |\n",
      "|    policy_loss        | -17.8      |\n",
      "|    reward             | 0.10632236 |\n",
      "|    std                | 1.29e+05   |\n",
      "|    value_loss         | 0.451      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 322        |\n",
      "|    iterations         | 67600      |\n",
      "|    time_elapsed       | 1047       |\n",
      "|    total_timesteps    | 338000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 67599      |\n",
      "|    policy_loss        | -0.397     |\n",
      "|    reward             | 0.11047863 |\n",
      "|    std                | 1.33e+05   |\n",
      "|    value_loss         | 0.0162     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 67700        |\n",
      "|    time_elapsed       | 1049         |\n",
      "|    total_timesteps    | 338500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.4        |\n",
      "|    explained_variance | 0.629        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67699        |\n",
      "|    policy_loss        | -0.127       |\n",
      "|    reward             | 0.0057601705 |\n",
      "|    std                | 1.34e+05     |\n",
      "|    value_loss         | 7.04e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 67800        |\n",
      "|    time_elapsed       | 1050         |\n",
      "|    total_timesteps    | 339000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67799        |\n",
      "|    policy_loss        | -0.339       |\n",
      "|    reward             | 0.0012051727 |\n",
      "|    std                | 1.37e+05     |\n",
      "|    value_loss         | 0.000226     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 67900       |\n",
      "|    time_elapsed       | 1052        |\n",
      "|    total_timesteps    | 339500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 67899       |\n",
      "|    policy_loss        | 0.434       |\n",
      "|    reward             | 0.015448572 |\n",
      "|    std                | 1.4e+05     |\n",
      "|    value_loss         | 0.00603     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 68000         |\n",
      "|    time_elapsed       | 1053          |\n",
      "|    total_timesteps    | 340000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.6         |\n",
      "|    explained_variance | -0.198        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 67999         |\n",
      "|    policy_loss        | -7.44         |\n",
      "|    reward             | -0.0011817276 |\n",
      "|    std                | 1.44e+05      |\n",
      "|    value_loss         | 0.0799        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 68100       |\n",
      "|    time_elapsed       | 1055        |\n",
      "|    total_timesteps    | 340500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68099       |\n",
      "|    policy_loss        | -0.429      |\n",
      "|    reward             | 0.068866864 |\n",
      "|    std                | 1.46e+05    |\n",
      "|    value_loss         | 0.000883    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 68200         |\n",
      "|    time_elapsed       | 1057          |\n",
      "|    total_timesteps    | 341000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.6         |\n",
      "|    explained_variance | 9.3e-06       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 68199         |\n",
      "|    policy_loss        | -0.131        |\n",
      "|    reward             | -0.0014144043 |\n",
      "|    std                | 1.48e+05      |\n",
      "|    value_loss         | 0.000108      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 68300       |\n",
      "|    time_elapsed       | 1059        |\n",
      "|    total_timesteps    | 341500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.7       |\n",
      "|    explained_variance | 0.301       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68299       |\n",
      "|    policy_loss        | -0.0139     |\n",
      "|    reward             | 0.012413712 |\n",
      "|    std                | 1.51e+05    |\n",
      "|    value_loss         | 1.04e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 68400       |\n",
      "|    time_elapsed       | 1061        |\n",
      "|    total_timesteps    | 342000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.7       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68399       |\n",
      "|    policy_loss        | -0.183      |\n",
      "|    reward             | 0.051724136 |\n",
      "|    std                | 1.56e+05    |\n",
      "|    value_loss         | 0.00035     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 68500        |\n",
      "|    time_elapsed       | 1063         |\n",
      "|    total_timesteps    | 342500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.8        |\n",
      "|    explained_variance | 0.339        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 68499        |\n",
      "|    policy_loss        | 0.202        |\n",
      "|    reward             | -0.007203488 |\n",
      "|    std                | 1.59e+05     |\n",
      "|    value_loss         | 0.000547     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 68600      |\n",
      "|    time_elapsed       | 1065       |\n",
      "|    total_timesteps    | 343000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.8      |\n",
      "|    explained_variance | -0.11      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 68599      |\n",
      "|    policy_loss        | 3.37       |\n",
      "|    reward             | 0.11926706 |\n",
      "|    std                | 1.6e+05    |\n",
      "|    value_loss         | 0.0243     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 68700       |\n",
      "|    time_elapsed       | 1067        |\n",
      "|    total_timesteps    | 343500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68699       |\n",
      "|    policy_loss        | -7.22       |\n",
      "|    reward             | 0.052803017 |\n",
      "|    std                | 1.62e+05    |\n",
      "|    value_loss         | 0.085       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 68800        |\n",
      "|    time_elapsed       | 1069         |\n",
      "|    total_timesteps    | 344000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.8        |\n",
      "|    explained_variance | -0.0537      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 68799        |\n",
      "|    policy_loss        | 0.129        |\n",
      "|    reward             | -0.015450857 |\n",
      "|    std                | 1.63e+05     |\n",
      "|    value_loss         | 4.21e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 68900         |\n",
      "|    time_elapsed       | 1071          |\n",
      "|    total_timesteps    | 344500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.9         |\n",
      "|    explained_variance | -0.00369      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 68899         |\n",
      "|    policy_loss        | 0.0124        |\n",
      "|    reward             | -0.0085924575 |\n",
      "|    std                | 1.66e+05      |\n",
      "|    value_loss         | 3.77e-05      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 69000         |\n",
      "|    time_elapsed       | 1073          |\n",
      "|    total_timesteps    | 345000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.9         |\n",
      "|    explained_variance | -1            |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 68999         |\n",
      "|    policy_loss        | 0.14          |\n",
      "|    reward             | 0.00035419044 |\n",
      "|    std                | 1.7e+05       |\n",
      "|    value_loss         | 8.25e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 69100       |\n",
      "|    time_elapsed       | 1075        |\n",
      "|    total_timesteps    | 345500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27         |\n",
      "|    explained_variance | -142        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 69099       |\n",
      "|    policy_loss        | -0.00255    |\n",
      "|    reward             | 0.011848173 |\n",
      "|    std                | 1.76e+05    |\n",
      "|    value_loss         | 0.000156    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 69200       |\n",
      "|    time_elapsed       | 1077        |\n",
      "|    total_timesteps    | 346000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.1       |\n",
      "|    explained_variance | -4.1        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 69199       |\n",
      "|    policy_loss        | -0.108      |\n",
      "|    reward             | -0.04885952 |\n",
      "|    std                | 1.84e+05    |\n",
      "|    value_loss         | 0.00018     |\n",
      "---------------------------------------\n",
      "day: 2770, episode: 125\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 31207.02\n",
      "total_reward: 21207.02\n",
      "total_cost: 12.18\n",
      "total_trades: 5540\n",
      "Sharpe: 0.527\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 69300        |\n",
      "|    time_elapsed       | 1079         |\n",
      "|    total_timesteps    | 346500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.1        |\n",
      "|    explained_variance | 0.169        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69299        |\n",
      "|    policy_loss        | 0.00715      |\n",
      "|    reward             | 0.0036700547 |\n",
      "|    std                | 1.87e+05     |\n",
      "|    value_loss         | 5.68e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 69400         |\n",
      "|    time_elapsed       | 1080          |\n",
      "|    total_timesteps    | 347000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.1         |\n",
      "|    explained_variance | 0.341         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 69399         |\n",
      "|    policy_loss        | 0.662         |\n",
      "|    reward             | -0.0021799703 |\n",
      "|    std                | 1.89e+05      |\n",
      "|    value_loss         | 0.000636      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 69500         |\n",
      "|    time_elapsed       | 1082          |\n",
      "|    total_timesteps    | 347500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 69499         |\n",
      "|    policy_loss        | 0.421         |\n",
      "|    reward             | -0.0026680771 |\n",
      "|    std                | 1.93e+05      |\n",
      "|    value_loss         | 0.00024       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 69600        |\n",
      "|    time_elapsed       | 1084         |\n",
      "|    total_timesteps    | 348000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.2        |\n",
      "|    explained_variance | 0.000225     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69599        |\n",
      "|    policy_loss        | -0.185       |\n",
      "|    reward             | 0.0026269844 |\n",
      "|    std                | 1.98e+05     |\n",
      "|    value_loss         | 6.73e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 69700       |\n",
      "|    time_elapsed       | 1086        |\n",
      "|    total_timesteps    | 348500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.3       |\n",
      "|    explained_variance | 0.282       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 69699       |\n",
      "|    policy_loss        | 0.652       |\n",
      "|    reward             | 0.018850375 |\n",
      "|    std                | 2.05e+05    |\n",
      "|    value_loss         | 0.000721    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 69800       |\n",
      "|    time_elapsed       | 1088        |\n",
      "|    total_timesteps    | 349000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.3       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 69799       |\n",
      "|    policy_loss        | 0.219       |\n",
      "|    reward             | -0.10842105 |\n",
      "|    std                | 2.1e+05     |\n",
      "|    value_loss         | 0.000204    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 69900        |\n",
      "|    time_elapsed       | 1089         |\n",
      "|    total_timesteps    | 349500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.4        |\n",
      "|    explained_variance | 0.17         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69899        |\n",
      "|    policy_loss        | -2.83        |\n",
      "|    reward             | -0.032760765 |\n",
      "|    std                | 2.11e+05     |\n",
      "|    value_loss         | 0.0107       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 70000      |\n",
      "|    time_elapsed       | 1091       |\n",
      "|    total_timesteps    | 350000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 69999      |\n",
      "|    policy_loss        | -0.724     |\n",
      "|    reward             | 0.01494354 |\n",
      "|    std                | 2.17e+05   |\n",
      "|    value_loss         | 0.000895   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 70100       |\n",
      "|    time_elapsed       | 1093        |\n",
      "|    total_timesteps    | 350500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.5       |\n",
      "|    explained_variance | 0.176       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70099       |\n",
      "|    policy_loss        | -0.794      |\n",
      "|    reward             | -0.07723852 |\n",
      "|    std                | 2.22e+05    |\n",
      "|    value_loss         | 0.00227     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 70200      |\n",
      "|    time_elapsed       | 1094       |\n",
      "|    total_timesteps    | 351000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27.4      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 70199      |\n",
      "|    policy_loss        | -1.13      |\n",
      "|    reward             | 0.10293607 |\n",
      "|    std                | 2.21e+05   |\n",
      "|    value_loss         | 0.00492    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 70300       |\n",
      "|    time_elapsed       | 1096        |\n",
      "|    total_timesteps    | 351500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70299       |\n",
      "|    policy_loss        | -10.9       |\n",
      "|    reward             | 0.055690773 |\n",
      "|    std                | 2.24e+05    |\n",
      "|    value_loss         | 0.18        |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 70400         |\n",
      "|    time_elapsed       | 1097          |\n",
      "|    total_timesteps    | 352000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 70399         |\n",
      "|    policy_loss        | 0.401         |\n",
      "|    reward             | -0.0052278717 |\n",
      "|    std                | 2.26e+05      |\n",
      "|    value_loss         | 0.000317      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 70500        |\n",
      "|    time_elapsed       | 1099         |\n",
      "|    total_timesteps    | 352500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.5        |\n",
      "|    explained_variance | 0.472        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70499        |\n",
      "|    policy_loss        | 0.0706       |\n",
      "|    reward             | -0.028394038 |\n",
      "|    std                | 2.28e+05     |\n",
      "|    value_loss         | 6.69e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 70600       |\n",
      "|    time_elapsed       | 1100        |\n",
      "|    total_timesteps    | 353000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70599       |\n",
      "|    policy_loss        | -0.277      |\n",
      "|    reward             | 0.023835748 |\n",
      "|    std                | 2.31e+05    |\n",
      "|    value_loss         | 0.00019     |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 320            |\n",
      "|    iterations         | 70700          |\n",
      "|    time_elapsed       | 1102           |\n",
      "|    total_timesteps    | 353500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -27.6          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 70699          |\n",
      "|    policy_loss        | 1.31           |\n",
      "|    reward             | -0.00050612335 |\n",
      "|    std                | 2.34e+05       |\n",
      "|    value_loss         | 0.00349        |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 70800       |\n",
      "|    time_elapsed       | 1103        |\n",
      "|    total_timesteps    | 354000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.6       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70799       |\n",
      "|    policy_loss        | -2.64       |\n",
      "|    reward             | -0.10816432 |\n",
      "|    std                | 2.34e+05    |\n",
      "|    value_loss         | 0.0114      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 70900       |\n",
      "|    time_elapsed       | 1105        |\n",
      "|    total_timesteps    | 354500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.6       |\n",
      "|    explained_variance | -2.15e-06   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70899       |\n",
      "|    policy_loss        | -0.703      |\n",
      "|    reward             | -0.07273538 |\n",
      "|    std                | 2.34e+05    |\n",
      "|    value_loss         | 0.00721     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 71000        |\n",
      "|    time_elapsed       | 1106         |\n",
      "|    total_timesteps    | 355000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.6        |\n",
      "|    explained_variance | 0.519        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70999        |\n",
      "|    policy_loss        | 0.175        |\n",
      "|    reward             | 0.0028710088 |\n",
      "|    std                | 2.35e+05     |\n",
      "|    value_loss         | 6.85e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 71100        |\n",
      "|    time_elapsed       | 1108         |\n",
      "|    total_timesteps    | 355500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.6        |\n",
      "|    explained_variance | -0.0669      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 71099        |\n",
      "|    policy_loss        | 0.0664       |\n",
      "|    reward             | -0.007173573 |\n",
      "|    std                | 2.39e+05     |\n",
      "|    value_loss         | 1.69e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 71200       |\n",
      "|    time_elapsed       | 1109        |\n",
      "|    total_timesteps    | 356000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.7       |\n",
      "|    explained_variance | 1.79e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 71199       |\n",
      "|    policy_loss        | 0.104       |\n",
      "|    reward             | 0.008768713 |\n",
      "|    std                | 2.47e+05    |\n",
      "|    value_loss         | 5.55e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 71300       |\n",
      "|    time_elapsed       | 1111        |\n",
      "|    total_timesteps    | 356500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.7       |\n",
      "|    explained_variance | -0.716      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 71299       |\n",
      "|    policy_loss        | 0.0973      |\n",
      "|    reward             | 0.004201035 |\n",
      "|    std                | 2.55e+05    |\n",
      "|    value_loss         | 0.000402    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 71400       |\n",
      "|    time_elapsed       | 1112        |\n",
      "|    total_timesteps    | 357000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.8       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 71399       |\n",
      "|    policy_loss        | -0.167      |\n",
      "|    reward             | 0.022760086 |\n",
      "|    std                | 2.66e+05    |\n",
      "|    value_loss         | 9.88e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 71500        |\n",
      "|    time_elapsed       | 1114         |\n",
      "|    total_timesteps    | 357500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.9        |\n",
      "|    explained_variance | 0.152        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 71499        |\n",
      "|    policy_loss        | -0.916       |\n",
      "|    reward             | -0.021153104 |\n",
      "|    std                | 2.72e+05     |\n",
      "|    value_loss         | 0.00176      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 71600       |\n",
      "|    time_elapsed       | 1115        |\n",
      "|    total_timesteps    | 358000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 71599       |\n",
      "|    policy_loss        | -0.0576     |\n",
      "|    reward             | 0.042230416 |\n",
      "|    std                | 2.76e+05    |\n",
      "|    value_loss         | 0.00011     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 71700      |\n",
      "|    time_elapsed       | 1117       |\n",
      "|    total_timesteps    | 358500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 71699      |\n",
      "|    policy_loss        | 0.102      |\n",
      "|    reward             | 0.02857421 |\n",
      "|    std                | 2.82e+05   |\n",
      "|    value_loss         | 0.000632   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 71800       |\n",
      "|    time_elapsed       | 1118        |\n",
      "|    total_timesteps    | 359000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28         |\n",
      "|    explained_variance | 0.0802      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 71799       |\n",
      "|    policy_loss        | -0.722      |\n",
      "|    reward             | 0.054479547 |\n",
      "|    std                | 2.86e+05    |\n",
      "|    value_loss         | 0.00226     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 320       |\n",
      "|    iterations         | 71900     |\n",
      "|    time_elapsed       | 1120      |\n",
      "|    total_timesteps    | 359500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28       |\n",
      "|    explained_variance | -2.04     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 71899     |\n",
      "|    policy_loss        | -1.46     |\n",
      "|    reward             | 0.1209199 |\n",
      "|    std                | 2.86e+05  |\n",
      "|    value_loss         | 0.00587   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 320       |\n",
      "|    iterations         | 72000     |\n",
      "|    time_elapsed       | 1121      |\n",
      "|    total_timesteps    | 360000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 71999     |\n",
      "|    policy_loss        | 9.33      |\n",
      "|    reward             | 0.0300782 |\n",
      "|    std                | 2.92e+05  |\n",
      "|    value_loss         | 0.112     |\n",
      "-------------------------------------\n",
      "day: 2770, episode: 130\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 139260.77\n",
      "total_reward: 129260.77\n",
      "total_cost: 12.47\n",
      "total_trades: 5537\n",
      "Sharpe: 0.955\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 72100       |\n",
      "|    time_elapsed       | 1123        |\n",
      "|    total_timesteps    | 360500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28         |\n",
      "|    explained_variance | -0.811      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 72099       |\n",
      "|    policy_loss        | 0.0988      |\n",
      "|    reward             | 0.024569074 |\n",
      "|    std                | 2.98e+05    |\n",
      "|    value_loss         | 8.94e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 72200        |\n",
      "|    time_elapsed       | 1125         |\n",
      "|    total_timesteps    | 361000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.1        |\n",
      "|    explained_variance | 0.0256       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72199        |\n",
      "|    policy_loss        | -0.559       |\n",
      "|    reward             | 0.0063662836 |\n",
      "|    std                | 3.01e+05     |\n",
      "|    value_loss         | 0.000642     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 72300       |\n",
      "|    time_elapsed       | 1127        |\n",
      "|    total_timesteps    | 361500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.1       |\n",
      "|    explained_variance | 0.0657      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 72299       |\n",
      "|    policy_loss        | -1.01       |\n",
      "|    reward             | 0.028413773 |\n",
      "|    std                | 3.1e+05     |\n",
      "|    value_loss         | 0.00141     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 72400       |\n",
      "|    time_elapsed       | 1128        |\n",
      "|    total_timesteps    | 362000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.1       |\n",
      "|    explained_variance | -0.000665   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 72399       |\n",
      "|    policy_loss        | -2.25       |\n",
      "|    reward             | -0.20144482 |\n",
      "|    std                | 3.13e+05    |\n",
      "|    value_loss         | 0.00732     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 72500        |\n",
      "|    time_elapsed       | 1129         |\n",
      "|    total_timesteps    | 362500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72499        |\n",
      "|    policy_loss        | 1.87         |\n",
      "|    reward             | -0.027711893 |\n",
      "|    std                | 3.15e+05     |\n",
      "|    value_loss         | 0.0108       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 72600      |\n",
      "|    time_elapsed       | 1131       |\n",
      "|    total_timesteps    | 363000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.1      |\n",
      "|    explained_variance | 0.0775     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 72599      |\n",
      "|    policy_loss        | 10.5       |\n",
      "|    reward             | 0.36098456 |\n",
      "|    std                | 3.11e+05   |\n",
      "|    value_loss         | 0.185      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 72700        |\n",
      "|    time_elapsed       | 1132         |\n",
      "|    total_timesteps    | 363500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.1        |\n",
      "|    explained_variance | -6.2e-05     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72699        |\n",
      "|    policy_loss        | 0.33         |\n",
      "|    reward             | 0.0036568714 |\n",
      "|    std                | 3.15e+05     |\n",
      "|    value_loss         | 0.000202     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 72800        |\n",
      "|    time_elapsed       | 1134         |\n",
      "|    total_timesteps    | 364000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.2        |\n",
      "|    explained_variance | 0.62         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72799        |\n",
      "|    policy_loss        | -0.344       |\n",
      "|    reward             | -0.017712481 |\n",
      "|    std                | 3.2e+05      |\n",
      "|    value_loss         | 0.000181     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 72900       |\n",
      "|    time_elapsed       | 1135        |\n",
      "|    total_timesteps    | 364500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 72899       |\n",
      "|    policy_loss        | 0.114       |\n",
      "|    reward             | 0.010875396 |\n",
      "|    std                | 3.26e+05    |\n",
      "|    value_loss         | 0.00164     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 73000      |\n",
      "|    time_elapsed       | 1137       |\n",
      "|    total_timesteps    | 365000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.3      |\n",
      "|    explained_variance | 0.395      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 72999      |\n",
      "|    policy_loss        | -1.38      |\n",
      "|    reward             | 0.10354984 |\n",
      "|    std                | 3.32e+05   |\n",
      "|    value_loss         | 0.00389    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 73100       |\n",
      "|    time_elapsed       | 1138        |\n",
      "|    total_timesteps    | 365500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73099       |\n",
      "|    policy_loss        | -6.2        |\n",
      "|    reward             | -0.06830567 |\n",
      "|    std                | 3.34e+05    |\n",
      "|    value_loss         | 0.0719      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 73200      |\n",
      "|    time_elapsed       | 1140       |\n",
      "|    total_timesteps    | 366000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 73199      |\n",
      "|    policy_loss        | -0.243     |\n",
      "|    reward             | 0.01745442 |\n",
      "|    std                | 3.35e+05   |\n",
      "|    value_loss         | 0.000227   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 73300        |\n",
      "|    time_elapsed       | 1141         |\n",
      "|    total_timesteps    | 366500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.3        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 73299        |\n",
      "|    policy_loss        | -0.0609      |\n",
      "|    reward             | 0.0045194905 |\n",
      "|    std                | 3.4e+05      |\n",
      "|    value_loss         | 1.33e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 73400       |\n",
      "|    time_elapsed       | 1143        |\n",
      "|    total_timesteps    | 367000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73399       |\n",
      "|    policy_loss        | 0.479       |\n",
      "|    reward             | 0.013684118 |\n",
      "|    std                | 3.48e+05    |\n",
      "|    value_loss         | 0.000405    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 73500         |\n",
      "|    time_elapsed       | 1144          |\n",
      "|    total_timesteps    | 367500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.4         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 73499         |\n",
      "|    policy_loss        | 0.484         |\n",
      "|    reward             | -0.0009939453 |\n",
      "|    std                | 3.56e+05      |\n",
      "|    value_loss         | 0.000507      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 73600        |\n",
      "|    time_elapsed       | 1145         |\n",
      "|    total_timesteps    | 368000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 73599        |\n",
      "|    policy_loss        | 1.27         |\n",
      "|    reward             | -0.063543744 |\n",
      "|    std                | 3.62e+05     |\n",
      "|    value_loss         | 0.00272      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 73700       |\n",
      "|    time_elapsed       | 1147        |\n",
      "|    total_timesteps    | 368500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73699       |\n",
      "|    policy_loss        | -2.05       |\n",
      "|    reward             | 0.115421765 |\n",
      "|    std                | 3.73e+05    |\n",
      "|    value_loss         | 0.00586     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 73800       |\n",
      "|    time_elapsed       | 1148        |\n",
      "|    total_timesteps    | 369000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.5       |\n",
      "|    explained_variance | -2.38e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73799       |\n",
      "|    policy_loss        | 0.832       |\n",
      "|    reward             | 0.035532624 |\n",
      "|    std                | 3.81e+05    |\n",
      "|    value_loss         | 0.00109     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 73900        |\n",
      "|    time_elapsed       | 1150         |\n",
      "|    total_timesteps    | 369500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 73899        |\n",
      "|    policy_loss        | 0.0889       |\n",
      "|    reward             | 0.0023848438 |\n",
      "|    std                | 3.9e+05      |\n",
      "|    value_loss         | 0.000383     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 74000       |\n",
      "|    time_elapsed       | 1152        |\n",
      "|    total_timesteps    | 370000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.6       |\n",
      "|    explained_variance | 0.0913      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73999       |\n",
      "|    policy_loss        | -7.58       |\n",
      "|    reward             | 0.053696968 |\n",
      "|    std                | 3.95e+05    |\n",
      "|    value_loss         | 0.0789      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 74100        |\n",
      "|    time_elapsed       | 1154         |\n",
      "|    total_timesteps    | 370500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 74099        |\n",
      "|    policy_loss        | 1.42         |\n",
      "|    reward             | -0.014421176 |\n",
      "|    std                | 4.04e+05     |\n",
      "|    value_loss         | 0.00425      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 74200         |\n",
      "|    time_elapsed       | 1155          |\n",
      "|    total_timesteps    | 371000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.7         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 74199         |\n",
      "|    policy_loss        | -2.16         |\n",
      "|    reward             | -0.0013143112 |\n",
      "|    std                | 4.06e+05      |\n",
      "|    value_loss         | 0.00612       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 74300       |\n",
      "|    time_elapsed       | 1157        |\n",
      "|    total_timesteps    | 371500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.7       |\n",
      "|    explained_variance | -0.0274     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 74299       |\n",
      "|    policy_loss        | 0.612       |\n",
      "|    reward             | 0.016743053 |\n",
      "|    std                | 4.08e+05    |\n",
      "|    value_loss         | 0.000525    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 74400        |\n",
      "|    time_elapsed       | 1158         |\n",
      "|    total_timesteps    | 372000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.7        |\n",
      "|    explained_variance | -0.12        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 74399        |\n",
      "|    policy_loss        | -0.213       |\n",
      "|    reward             | 0.0037389717 |\n",
      "|    std                | 4.12e+05     |\n",
      "|    value_loss         | 0.000137     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 74500        |\n",
      "|    time_elapsed       | 1160         |\n",
      "|    total_timesteps    | 372500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.7        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 74499        |\n",
      "|    policy_loss        | 1.36         |\n",
      "|    reward             | -0.018285843 |\n",
      "|    std                | 4.16e+05     |\n",
      "|    value_loss         | 0.00892      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 74600      |\n",
      "|    time_elapsed       | 1161       |\n",
      "|    total_timesteps    | 373000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.7      |\n",
      "|    explained_variance | 0.248      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 74599      |\n",
      "|    policy_loss        | -3.85      |\n",
      "|    reward             | 0.16332607 |\n",
      "|    std                | 4.21e+05   |\n",
      "|    value_loss         | 0.027      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 74700        |\n",
      "|    time_elapsed       | 1163         |\n",
      "|    total_timesteps    | 373500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.8        |\n",
      "|    explained_variance | 0.322        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 74699        |\n",
      "|    policy_loss        | 2.13         |\n",
      "|    reward             | -0.106605895 |\n",
      "|    std                | 4.27e+05     |\n",
      "|    value_loss         | 0.00861      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 74800       |\n",
      "|    time_elapsed       | 1165        |\n",
      "|    total_timesteps    | 374000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.8       |\n",
      "|    explained_variance | -0.0306     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 74799       |\n",
      "|    policy_loss        | 3.19        |\n",
      "|    reward             | 0.049147833 |\n",
      "|    std                | 4.26e+05    |\n",
      "|    value_loss         | 0.0138      |\n",
      "---------------------------------------\n",
      "day: 2770, episode: 135\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 122062.39\n",
      "total_reward: 112062.39\n",
      "total_cost: 12.52\n",
      "total_trades: 5539\n",
      "Sharpe: 0.839\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 74900        |\n",
      "|    time_elapsed       | 1166         |\n",
      "|    total_timesteps    | 374500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.8        |\n",
      "|    explained_variance | 0.0681       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 74899        |\n",
      "|    policy_loss        | -0.349       |\n",
      "|    reward             | -0.025351638 |\n",
      "|    std                | 4.31e+05     |\n",
      "|    value_loss         | 0.000877     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 75000        |\n",
      "|    time_elapsed       | 1168         |\n",
      "|    total_timesteps    | 375000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.8        |\n",
      "|    explained_variance | 0.0271       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 74999        |\n",
      "|    policy_loss        | -0.294       |\n",
      "|    reward             | -0.027601153 |\n",
      "|    std                | 4.37e+05     |\n",
      "|    value_loss         | 0.00054      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 75100         |\n",
      "|    time_elapsed       | 1169          |\n",
      "|    total_timesteps    | 375500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.8         |\n",
      "|    explained_variance | 0.0603        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 75099         |\n",
      "|    policy_loss        | -0.85         |\n",
      "|    reward             | -0.0062650917 |\n",
      "|    std                | 4.47e+05      |\n",
      "|    value_loss         | 0.00184       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 75200       |\n",
      "|    time_elapsed       | 1171        |\n",
      "|    total_timesteps    | 376000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.9       |\n",
      "|    explained_variance | 4.87e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75199       |\n",
      "|    policy_loss        | 6.89        |\n",
      "|    reward             | -0.11492261 |\n",
      "|    std                | 4.48e+05    |\n",
      "|    value_loss         | 0.0698      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 75300      |\n",
      "|    time_elapsed       | 1172       |\n",
      "|    total_timesteps    | 376500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.9      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 75299      |\n",
      "|    policy_loss        | 0.641      |\n",
      "|    reward             | 0.16379195 |\n",
      "|    std                | 4.56e+05   |\n",
      "|    value_loss         | 0.00824    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 75400       |\n",
      "|    time_elapsed       | 1174        |\n",
      "|    total_timesteps    | 377000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.9       |\n",
      "|    explained_variance | -0.000139   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75399       |\n",
      "|    policy_loss        | -0.549      |\n",
      "|    reward             | 0.011770319 |\n",
      "|    std                | 4.61e+05    |\n",
      "|    value_loss         | 0.000368    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 75500         |\n",
      "|    time_elapsed       | 1175          |\n",
      "|    total_timesteps    | 377500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.9         |\n",
      "|    explained_variance | 0.133         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 75499         |\n",
      "|    policy_loss        | -0.669        |\n",
      "|    reward             | -0.0041057947 |\n",
      "|    std                | 4.65e+05      |\n",
      "|    value_loss         | 0.000799      |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 321       |\n",
      "|    iterations         | 75600     |\n",
      "|    time_elapsed       | 1177      |\n",
      "|    total_timesteps    | 378000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29       |\n",
      "|    explained_variance | 0.000348  |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 75599     |\n",
      "|    policy_loss        | -1.82     |\n",
      "|    reward             | 0.0694664 |\n",
      "|    std                | 4.72e+05  |\n",
      "|    value_loss         | 0.00448   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 75700       |\n",
      "|    time_elapsed       | 1179        |\n",
      "|    total_timesteps    | 378500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29         |\n",
      "|    explained_variance | -1.44e-05   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75699       |\n",
      "|    policy_loss        | -1.88       |\n",
      "|    reward             | -0.08998513 |\n",
      "|    std                | 4.82e+05    |\n",
      "|    value_loss         | 0.00467     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 75800        |\n",
      "|    time_elapsed       | 1180         |\n",
      "|    total_timesteps    | 379000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 75799        |\n",
      "|    policy_loss        | -1.13        |\n",
      "|    reward             | -0.099027656 |\n",
      "|    std                | 4.88e+05     |\n",
      "|    value_loss         | 0.00333      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 75900       |\n",
      "|    time_elapsed       | 1182        |\n",
      "|    total_timesteps    | 379500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29         |\n",
      "|    explained_variance | 0.314       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75899       |\n",
      "|    policy_loss        | -3.92       |\n",
      "|    reward             | 0.116627544 |\n",
      "|    std                | 4.9e+05     |\n",
      "|    value_loss         | 0.031       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 76000       |\n",
      "|    time_elapsed       | 1183        |\n",
      "|    total_timesteps    | 380000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29         |\n",
      "|    explained_variance | 0.227       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75999       |\n",
      "|    policy_loss        | 1.63        |\n",
      "|    reward             | -0.03701976 |\n",
      "|    std                | 4.89e+05    |\n",
      "|    value_loss         | 0.00387     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 76100       |\n",
      "|    time_elapsed       | 1185        |\n",
      "|    total_timesteps    | 380500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.1       |\n",
      "|    explained_variance | -0.397      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 76099       |\n",
      "|    policy_loss        | 0.243       |\n",
      "|    reward             | 0.015974635 |\n",
      "|    std                | 4.95e+05    |\n",
      "|    value_loss         | 0.000197    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 76200       |\n",
      "|    time_elapsed       | 1186        |\n",
      "|    total_timesteps    | 381000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.1       |\n",
      "|    explained_variance | 2.8e-05     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 76199       |\n",
      "|    policy_loss        | 2.47        |\n",
      "|    reward             | 0.056282394 |\n",
      "|    std                | 5.11e+05    |\n",
      "|    value_loss         | 0.00868     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 76300        |\n",
      "|    time_elapsed       | 1188         |\n",
      "|    total_timesteps    | 381500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.2        |\n",
      "|    explained_variance | 0.579        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76299        |\n",
      "|    policy_loss        | 1.16         |\n",
      "|    reward             | -0.039919768 |\n",
      "|    std                | 5.22e+05     |\n",
      "|    value_loss         | 0.00417      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 321       |\n",
      "|    iterations         | 76400     |\n",
      "|    time_elapsed       | 1189      |\n",
      "|    total_timesteps    | 382000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.2     |\n",
      "|    explained_variance | 0.253     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 76399     |\n",
      "|    policy_loss        | -2.13     |\n",
      "|    reward             | 0.1706746 |\n",
      "|    std                | 5.25e+05  |\n",
      "|    value_loss         | 0.0175    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 76500        |\n",
      "|    time_elapsed       | 1190         |\n",
      "|    total_timesteps    | 382500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.2        |\n",
      "|    explained_variance | -6.6         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76499        |\n",
      "|    policy_loss        | -0.235       |\n",
      "|    reward             | -0.001616388 |\n",
      "|    std                | 5.29e+05     |\n",
      "|    value_loss         | 0.000682     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 76600        |\n",
      "|    time_elapsed       | 1192         |\n",
      "|    total_timesteps    | 383000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.2        |\n",
      "|    explained_variance | -6.13        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76599        |\n",
      "|    policy_loss        | 0.297        |\n",
      "|    reward             | -0.011362334 |\n",
      "|    std                | 5.33e+05     |\n",
      "|    value_loss         | 0.000605     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 76700      |\n",
      "|    time_elapsed       | 1193       |\n",
      "|    total_timesteps    | 383500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29.2      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 76699      |\n",
      "|    policy_loss        | -0.197     |\n",
      "|    reward             | 0.01670658 |\n",
      "|    std                | 5.43e+05   |\n",
      "|    value_loss         | 0.000148   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 76800       |\n",
      "|    time_elapsed       | 1195        |\n",
      "|    total_timesteps    | 384000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.3       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 76799       |\n",
      "|    policy_loss        | -0.329      |\n",
      "|    reward             | 0.014601193 |\n",
      "|    std                | 5.56e+05    |\n",
      "|    value_loss         | 0.000225    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 321       |\n",
      "|    iterations         | 76900     |\n",
      "|    time_elapsed       | 1196      |\n",
      "|    total_timesteps    | 384500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.3     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 76899     |\n",
      "|    policy_loss        | 0.156     |\n",
      "|    reward             | 0.0395758 |\n",
      "|    std                | 5.65e+05  |\n",
      "|    value_loss         | 0.000614  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 77000      |\n",
      "|    time_elapsed       | 1198       |\n",
      "|    total_timesteps    | 385000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 76999      |\n",
      "|    policy_loss        | 0.692      |\n",
      "|    reward             | 0.08302861 |\n",
      "|    std                | 5.7e+05    |\n",
      "|    value_loss         | 0.00146    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 77100        |\n",
      "|    time_elapsed       | 1199         |\n",
      "|    total_timesteps    | 385500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.4        |\n",
      "|    explained_variance | 2.92e-05     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77099        |\n",
      "|    policy_loss        | -0.713       |\n",
      "|    reward             | -0.007429327 |\n",
      "|    std                | 5.77e+05     |\n",
      "|    value_loss         | 0.00073      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 77200       |\n",
      "|    time_elapsed       | 1201        |\n",
      "|    total_timesteps    | 386000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.4       |\n",
      "|    explained_variance | 0.837       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 77199       |\n",
      "|    policy_loss        | 0.327       |\n",
      "|    reward             | 0.010762206 |\n",
      "|    std                | 5.88e+05    |\n",
      "|    value_loss         | 0.000137    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 77300        |\n",
      "|    time_elapsed       | 1203         |\n",
      "|    total_timesteps    | 386500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.4        |\n",
      "|    explained_variance | -0.0266      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77299        |\n",
      "|    policy_loss        | 0.0148       |\n",
      "|    reward             | 0.0015417839 |\n",
      "|    std                | 6.03e+05     |\n",
      "|    value_loss         | 4.92e-05     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 321            |\n",
      "|    iterations         | 77400          |\n",
      "|    time_elapsed       | 1204           |\n",
      "|    total_timesteps    | 387000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -29.5          |\n",
      "|    explained_variance | 0.0413         |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 77399          |\n",
      "|    policy_loss        | 0.23           |\n",
      "|    reward             | -0.00040258255 |\n",
      "|    std                | 6.27e+05       |\n",
      "|    value_loss         | 8.77e-05       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 77500       |\n",
      "|    time_elapsed       | 1206        |\n",
      "|    total_timesteps    | 387500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.6       |\n",
      "|    explained_variance | -0.262      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 77499       |\n",
      "|    policy_loss        | 0.507       |\n",
      "|    reward             | -0.03953342 |\n",
      "|    std                | 6.43e+05    |\n",
      "|    value_loss         | 0.000622    |\n",
      "---------------------------------------\n",
      "day: 2770, episode: 140\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 27399.85\n",
      "total_reward: 17399.85\n",
      "total_cost: 31.64\n",
      "total_trades: 4215\n",
      "Sharpe: 0.453\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 77600       |\n",
      "|    time_elapsed       | 1207        |\n",
      "|    total_timesteps    | 388000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.6       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 77599       |\n",
      "|    policy_loss        | 0.337       |\n",
      "|    reward             | 0.001795797 |\n",
      "|    std                | 6.54e+05    |\n",
      "|    value_loss         | 0.000314    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 77700        |\n",
      "|    time_elapsed       | 1209         |\n",
      "|    total_timesteps    | 388500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.7        |\n",
      "|    explained_variance | -0.197       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77699        |\n",
      "|    policy_loss        | 0.0842       |\n",
      "|    reward             | 0.0009927177 |\n",
      "|    std                | 6.71e+05     |\n",
      "|    value_loss         | 3.47e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 77800        |\n",
      "|    time_elapsed       | 1210         |\n",
      "|    total_timesteps    | 389000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.7        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77799        |\n",
      "|    policy_loss        | -0.0582      |\n",
      "|    reward             | 0.0011520828 |\n",
      "|    std                | 6.92e+05     |\n",
      "|    value_loss         | 3.34e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 77900        |\n",
      "|    time_elapsed       | 1212         |\n",
      "|    total_timesteps    | 389500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.7        |\n",
      "|    explained_variance | 0.0407       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77899        |\n",
      "|    policy_loss        | 2.08         |\n",
      "|    reward             | -0.015290016 |\n",
      "|    std                | 6.97e+05     |\n",
      "|    value_loss         | 0.00599      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 78000       |\n",
      "|    time_elapsed       | 1213        |\n",
      "|    total_timesteps    | 390000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.8       |\n",
      "|    explained_variance | 0.0806      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 77999       |\n",
      "|    policy_loss        | 0.631       |\n",
      "|    reward             | 0.014121176 |\n",
      "|    std                | 7.11e+05    |\n",
      "|    value_loss         | 0.0013      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 321       |\n",
      "|    iterations         | 78100     |\n",
      "|    time_elapsed       | 1215      |\n",
      "|    total_timesteps    | 390500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29.8     |\n",
      "|    explained_variance | 0.0893    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 78099     |\n",
      "|    policy_loss        | 4.19      |\n",
      "|    reward             | 0.1488491 |\n",
      "|    std                | 7.12e+05  |\n",
      "|    value_loss         | 0.0234    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 78200        |\n",
      "|    time_elapsed       | 1216         |\n",
      "|    total_timesteps    | 391000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 78199        |\n",
      "|    policy_loss        | -0.638       |\n",
      "|    reward             | -0.012502975 |\n",
      "|    std                | 7.14e+05     |\n",
      "|    value_loss         | 0.00074      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 78300       |\n",
      "|    time_elapsed       | 1218        |\n",
      "|    total_timesteps    | 391500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.8       |\n",
      "|    explained_variance | 0.586       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78299       |\n",
      "|    policy_loss        | 0.506       |\n",
      "|    reward             | 0.016060159 |\n",
      "|    std                | 7.28e+05    |\n",
      "|    value_loss         | 0.00034     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 78400       |\n",
      "|    time_elapsed       | 1220        |\n",
      "|    total_timesteps    | 392000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.9       |\n",
      "|    explained_variance | 0.542       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78399       |\n",
      "|    policy_loss        | 1           |\n",
      "|    reward             | 0.009397098 |\n",
      "|    std                | 7.5e+05     |\n",
      "|    value_loss         | 0.00165     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 78500      |\n",
      "|    time_elapsed       | 1221       |\n",
      "|    total_timesteps    | 392500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29.9      |\n",
      "|    explained_variance | 0.192      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 78499      |\n",
      "|    policy_loss        | 0.962      |\n",
      "|    reward             | 0.01065625 |\n",
      "|    std                | 7.71e+05   |\n",
      "|    value_loss         | 0.00146    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 78600       |\n",
      "|    time_elapsed       | 1223        |\n",
      "|    total_timesteps    | 393000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.9       |\n",
      "|    explained_variance | -2.94       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78599       |\n",
      "|    policy_loss        | 2.35        |\n",
      "|    reward             | -0.14140062 |\n",
      "|    std                | 7.74e+05    |\n",
      "|    value_loss         | 0.00669     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 78700       |\n",
      "|    time_elapsed       | 1225        |\n",
      "|    total_timesteps    | 393500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78699       |\n",
      "|    policy_loss        | -0.497      |\n",
      "|    reward             | 0.006851834 |\n",
      "|    std                | 7.8e+05     |\n",
      "|    value_loss         | 0.000492    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 78800       |\n",
      "|    time_elapsed       | 1226        |\n",
      "|    total_timesteps    | 394000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30         |\n",
      "|    explained_variance | 0.174       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78799       |\n",
      "|    policy_loss        | -1          |\n",
      "|    reward             | -0.02956715 |\n",
      "|    std                | 7.88e+05    |\n",
      "|    value_loss         | 0.00146     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 78900       |\n",
      "|    time_elapsed       | 1228        |\n",
      "|    total_timesteps    | 394500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30         |\n",
      "|    explained_variance | 0.67        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78899       |\n",
      "|    policy_loss        | -1.37       |\n",
      "|    reward             | 0.052932374 |\n",
      "|    std                | 7.94e+05    |\n",
      "|    value_loss         | 0.00281     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 79000      |\n",
      "|    time_elapsed       | 1229       |\n",
      "|    total_timesteps    | 395000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30        |\n",
      "|    explained_variance | -0.056     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 78999      |\n",
      "|    policy_loss        | 0.769      |\n",
      "|    reward             | 0.11977555 |\n",
      "|    std                | 8.11e+05   |\n",
      "|    value_loss         | 0.00235    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 321       |\n",
      "|    iterations         | 79100     |\n",
      "|    time_elapsed       | 1231      |\n",
      "|    total_timesteps    | 395500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.1     |\n",
      "|    explained_variance | 0.0727    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 79099     |\n",
      "|    policy_loss        | -12.6     |\n",
      "|    reward             | 0.1850526 |\n",
      "|    std                | 8.2e+05   |\n",
      "|    value_loss         | 0.188     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 79200      |\n",
      "|    time_elapsed       | 1232       |\n",
      "|    total_timesteps    | 396000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30.1      |\n",
      "|    explained_variance | 2.38e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 79199      |\n",
      "|    policy_loss        | 37.6       |\n",
      "|    reward             | 0.45174077 |\n",
      "|    std                | 8.31e+05   |\n",
      "|    value_loss         | 1.67       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 79300       |\n",
      "|    time_elapsed       | 1234        |\n",
      "|    total_timesteps    | 396500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.1       |\n",
      "|    explained_variance | 0.889       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79299       |\n",
      "|    policy_loss        | -0.206      |\n",
      "|    reward             | 0.004731073 |\n",
      "|    std                | 8.36e+05    |\n",
      "|    value_loss         | 0.000181    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 79400        |\n",
      "|    time_elapsed       | 1235         |\n",
      "|    total_timesteps    | 397000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.1        |\n",
      "|    explained_variance | 0.175        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 79399        |\n",
      "|    policy_loss        | 1.19         |\n",
      "|    reward             | -0.018776681 |\n",
      "|    std                | 8.49e+05     |\n",
      "|    value_loss         | 0.00159      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 79500       |\n",
      "|    time_elapsed       | 1237        |\n",
      "|    total_timesteps    | 397500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.2       |\n",
      "|    explained_variance | 0.143       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79499       |\n",
      "|    policy_loss        | -4.34       |\n",
      "|    reward             | -0.02638404 |\n",
      "|    std                | 8.62e+05    |\n",
      "|    value_loss         | 0.0227      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 79600      |\n",
      "|    time_elapsed       | 1238       |\n",
      "|    total_timesteps    | 398000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30.2      |\n",
      "|    explained_variance | 0.129      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 79599      |\n",
      "|    policy_loss        | 3.89       |\n",
      "|    reward             | 0.14165093 |\n",
      "|    std                | 8.77e+05   |\n",
      "|    value_loss         | 0.0207     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 79700      |\n",
      "|    time_elapsed       | 1240       |\n",
      "|    total_timesteps    | 398500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30.2      |\n",
      "|    explained_variance | 0.00271    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 79699      |\n",
      "|    policy_loss        | -1.77      |\n",
      "|    reward             | -0.1840868 |\n",
      "|    std                | 8.73e+05   |\n",
      "|    value_loss         | 0.0144     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 79800       |\n",
      "|    time_elapsed       | 1241        |\n",
      "|    total_timesteps    | 399000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.2       |\n",
      "|    explained_variance | 0.36        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79799       |\n",
      "|    policy_loss        | -14.8       |\n",
      "|    reward             | -0.32640943 |\n",
      "|    std                | 8.76e+05    |\n",
      "|    value_loss         | 0.259       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 79900         |\n",
      "|    time_elapsed       | 1243          |\n",
      "|    total_timesteps    | 399500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 79899         |\n",
      "|    policy_loss        | -0.173        |\n",
      "|    reward             | -0.0005703032 |\n",
      "|    std                | 8.85e+05      |\n",
      "|    value_loss         | 7.12e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 80000        |\n",
      "|    time_elapsed       | 1245         |\n",
      "|    total_timesteps    | 400000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.2        |\n",
      "|    explained_variance | 0.00456      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 79999        |\n",
      "|    policy_loss        | 0.953        |\n",
      "|    reward             | 0.0036425297 |\n",
      "|    std                | 8.98e+05     |\n",
      "|    value_loss         | 0.00159      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 80100        |\n",
      "|    time_elapsed       | 1246         |\n",
      "|    total_timesteps    | 400500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.3        |\n",
      "|    explained_variance | 0.0621       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 80099        |\n",
      "|    policy_loss        | 1.71         |\n",
      "|    reward             | -0.050662924 |\n",
      "|    std                | 9.19e+05     |\n",
      "|    value_loss         | 0.00669      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 80200      |\n",
      "|    time_elapsed       | 1248       |\n",
      "|    total_timesteps    | 401000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30.3      |\n",
      "|    explained_variance | 0.157      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 80199      |\n",
      "|    policy_loss        | -6.07      |\n",
      "|    reward             | 0.20073302 |\n",
      "|    std                | 9.32e+05   |\n",
      "|    value_loss         | 0.0499     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 80300        |\n",
      "|    time_elapsed       | 1249         |\n",
      "|    total_timesteps    | 401500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 80299        |\n",
      "|    policy_loss        | -4.05        |\n",
      "|    reward             | -0.003360942 |\n",
      "|    std                | 9.56e+05     |\n",
      "|    value_loss         | 0.0265       |\n",
      "----------------------------------------\n",
      "day: 2770, episode: 145\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 105028.56\n",
      "total_reward: 95028.56\n",
      "total_cost: 13.16\n",
      "total_trades: 5538\n",
      "Sharpe: 0.804\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 80400        |\n",
      "|    time_elapsed       | 1251         |\n",
      "|    total_timesteps    | 402000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 80399        |\n",
      "|    policy_loss        | -0.115       |\n",
      "|    reward             | 0.0057488587 |\n",
      "|    std                | 9.58e+05     |\n",
      "|    value_loss         | 5.3e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 80500        |\n",
      "|    time_elapsed       | 1253         |\n",
      "|    total_timesteps    | 402500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 80499        |\n",
      "|    policy_loss        | 0.576        |\n",
      "|    reward             | -0.002820735 |\n",
      "|    std                | 9.74e+05     |\n",
      "|    value_loss         | 0.000387     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 80600       |\n",
      "|    time_elapsed       | 1254        |\n",
      "|    total_timesteps    | 403000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.5       |\n",
      "|    explained_variance | 0.256       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80599       |\n",
      "|    policy_loss        | -0.282      |\n",
      "|    reward             | 0.006172497 |\n",
      "|    std                | 1e+06       |\n",
      "|    value_loss         | 0.000575    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 80700       |\n",
      "|    time_elapsed       | 1256        |\n",
      "|    total_timesteps    | 403500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.5       |\n",
      "|    explained_variance | 0.283       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80699       |\n",
      "|    policy_loss        | -0.0433     |\n",
      "|    reward             | 0.005088298 |\n",
      "|    std                | 1.03e+06    |\n",
      "|    value_loss         | 0.000146    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 80800       |\n",
      "|    time_elapsed       | 1257        |\n",
      "|    total_timesteps    | 404000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.5       |\n",
      "|    explained_variance | 0.0242      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80799       |\n",
      "|    policy_loss        | 3.34        |\n",
      "|    reward             | 0.039508708 |\n",
      "|    std                | 1.04e+06    |\n",
      "|    value_loss         | 0.0162      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 80900       |\n",
      "|    time_elapsed       | 1259        |\n",
      "|    total_timesteps    | 404500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.6       |\n",
      "|    explained_variance | 0.318       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80899       |\n",
      "|    policy_loss        | 3.22        |\n",
      "|    reward             | -0.04031426 |\n",
      "|    std                | 1.05e+06    |\n",
      "|    value_loss         | 0.0191      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 81000        |\n",
      "|    time_elapsed       | 1260         |\n",
      "|    total_timesteps    | 405000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.6        |\n",
      "|    explained_variance | 0.761        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 80999        |\n",
      "|    policy_loss        | -0.215       |\n",
      "|    reward             | -0.030695794 |\n",
      "|    std                | 1.07e+06     |\n",
      "|    value_loss         | 6.15e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 81100      |\n",
      "|    time_elapsed       | 1262       |\n",
      "|    total_timesteps    | 405500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30.6      |\n",
      "|    explained_variance | 0.135      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 81099      |\n",
      "|    policy_loss        | 1.09       |\n",
      "|    reward             | 0.11176014 |\n",
      "|    std                | 1.1e+06    |\n",
      "|    value_loss         | 0.00198    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 321       |\n",
      "|    iterations         | 81200     |\n",
      "|    time_elapsed       | 1264      |\n",
      "|    total_timesteps    | 406000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.7     |\n",
      "|    explained_variance | 0.0303    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 81199     |\n",
      "|    policy_loss        | 10.3      |\n",
      "|    reward             | 0.0440743 |\n",
      "|    std                | 1.12e+06  |\n",
      "|    value_loss         | 0.114     |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 81300        |\n",
      "|    time_elapsed       | 1265         |\n",
      "|    total_timesteps    | 406500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 81299        |\n",
      "|    policy_loss        | -1.59        |\n",
      "|    reward             | -0.053281557 |\n",
      "|    std                | 1.12e+06     |\n",
      "|    value_loss         | 0.0123       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 81400       |\n",
      "|    time_elapsed       | 1267        |\n",
      "|    total_timesteps    | 407000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 81399       |\n",
      "|    policy_loss        | 0.286       |\n",
      "|    reward             | -0.15955818 |\n",
      "|    std                | 1.14e+06    |\n",
      "|    value_loss         | 0.00484     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 81500      |\n",
      "|    time_elapsed       | 1268       |\n",
      "|    total_timesteps    | 407500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30.7      |\n",
      "|    explained_variance | -0.649     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 81499      |\n",
      "|    policy_loss        | -0.421     |\n",
      "|    reward             | 0.01860531 |\n",
      "|    std                | 1.15e+06   |\n",
      "|    value_loss         | 0.000604   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 81600        |\n",
      "|    time_elapsed       | 1270         |\n",
      "|    total_timesteps    | 408000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.7        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 81599        |\n",
      "|    policy_loss        | -0.675       |\n",
      "|    reward             | -0.008222142 |\n",
      "|    std                | 1.16e+06     |\n",
      "|    value_loss         | 0.00094      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 81700       |\n",
      "|    time_elapsed       | 1271        |\n",
      "|    total_timesteps    | 408500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 81699       |\n",
      "|    policy_loss        | 1.29        |\n",
      "|    reward             | 0.023039358 |\n",
      "|    std                | 1.17e+06    |\n",
      "|    value_loss         | 0.00427     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 81800      |\n",
      "|    time_elapsed       | 1273       |\n",
      "|    total_timesteps    | 409000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30.8      |\n",
      "|    explained_variance | 0.27       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 81799      |\n",
      "|    policy_loss        | -2.72      |\n",
      "|    reward             | 0.17285986 |\n",
      "|    std                | 1.18e+06   |\n",
      "|    value_loss         | 0.0149     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 321        |\n",
      "|    iterations         | 81900      |\n",
      "|    time_elapsed       | 1275       |\n",
      "|    total_timesteps    | 409500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30.8      |\n",
      "|    explained_variance | 0.345      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 81899      |\n",
      "|    policy_loss        | -3.87      |\n",
      "|    reward             | 0.21724597 |\n",
      "|    std                | 1.2e+06    |\n",
      "|    value_loss         | 0.0328     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 321       |\n",
      "|    iterations         | 82000     |\n",
      "|    time_elapsed       | 1276      |\n",
      "|    total_timesteps    | 410000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -30.8     |\n",
      "|    explained_variance | 0.349     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 81999     |\n",
      "|    policy_loss        | -5.92     |\n",
      "|    reward             | -0.523785 |\n",
      "|    std                | 1.19e+06  |\n",
      "|    value_loss         | 0.0418    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 82100        |\n",
      "|    time_elapsed       | 1278         |\n",
      "|    total_timesteps    | 410500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.8        |\n",
      "|    explained_variance | -5.03        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82099        |\n",
      "|    policy_loss        | -0.642       |\n",
      "|    reward             | -0.004594313 |\n",
      "|    std                | 1.2e+06      |\n",
      "|    value_loss         | 0.000888     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 82200       |\n",
      "|    time_elapsed       | 1279        |\n",
      "|    total_timesteps    | 411000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 82199       |\n",
      "|    policy_loss        | -0.21       |\n",
      "|    reward             | 0.006627591 |\n",
      "|    std                | 1.21e+06    |\n",
      "|    value_loss         | 8.27e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 82300         |\n",
      "|    time_elapsed       | 1281          |\n",
      "|    total_timesteps    | 411500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.9         |\n",
      "|    explained_variance | 0.32          |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 82299         |\n",
      "|    policy_loss        | 0.671         |\n",
      "|    reward             | -0.0035168396 |\n",
      "|    std                | 1.24e+06      |\n",
      "|    value_loss         | 0.000516      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 82400        |\n",
      "|    time_elapsed       | 1283         |\n",
      "|    total_timesteps    | 412000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.9        |\n",
      "|    explained_variance | 0.00018      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82399        |\n",
      "|    policy_loss        | -0.687       |\n",
      "|    reward             | -0.002151573 |\n",
      "|    std                | 1.27e+06     |\n",
      "|    value_loss         | 0.000675     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 82500        |\n",
      "|    time_elapsed       | 1284         |\n",
      "|    total_timesteps    | 412500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31          |\n",
      "|    explained_variance | -0.127       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82499        |\n",
      "|    policy_loss        | -0.241       |\n",
      "|    reward             | -0.021041533 |\n",
      "|    std                | 1.32e+06     |\n",
      "|    value_loss         | 0.000224     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 321            |\n",
      "|    iterations         | 82600          |\n",
      "|    time_elapsed       | 1286           |\n",
      "|    total_timesteps    | 413000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -31            |\n",
      "|    explained_variance | -37.9          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 82599          |\n",
      "|    policy_loss        | -0.312         |\n",
      "|    reward             | -0.00026410073 |\n",
      "|    std                | 1.34e+06       |\n",
      "|    value_loss         | 0.000174       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 82700         |\n",
      "|    time_elapsed       | 1288          |\n",
      "|    total_timesteps    | 413500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.1         |\n",
      "|    explained_variance | 0.392         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 82699         |\n",
      "|    policy_loss        | 0.417         |\n",
      "|    reward             | -0.0002817564 |\n",
      "|    std                | 1.37e+06      |\n",
      "|    value_loss         | 0.000197      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 82800         |\n",
      "|    time_elapsed       | 1289          |\n",
      "|    total_timesteps    | 414000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 82799         |\n",
      "|    policy_loss        | 0.106         |\n",
      "|    reward             | -0.0087020835 |\n",
      "|    std                | 1.43e+06      |\n",
      "|    value_loss         | 4.81e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 82900        |\n",
      "|    time_elapsed       | 1291         |\n",
      "|    total_timesteps    | 414500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.2        |\n",
      "|    explained_variance | 0.449        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82899        |\n",
      "|    policy_loss        | -0.0442      |\n",
      "|    reward             | -0.002467714 |\n",
      "|    std                | 1.48e+06     |\n",
      "|    value_loss         | 1.33e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 83000         |\n",
      "|    time_elapsed       | 1292          |\n",
      "|    total_timesteps    | 415000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.3         |\n",
      "|    explained_variance | 0.00404       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 82999         |\n",
      "|    policy_loss        | 0.799         |\n",
      "|    reward             | -0.0021990272 |\n",
      "|    std                | 1.51e+06      |\n",
      "|    value_loss         | 0.000726      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 83100      |\n",
      "|    time_elapsed       | 1294       |\n",
      "|    total_timesteps    | 415500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 83099      |\n",
      "|    policy_loss        | 0.0859     |\n",
      "|    reward             | 0.02835104 |\n",
      "|    std                | 1.54e+06   |\n",
      "|    value_loss         | 1.76e-05   |\n",
      "--------------------------------------\n",
      "day: 2770, episode: 150\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 31671.71\n",
      "total_reward: 21671.71\n",
      "total_cost: 14.54\n",
      "total_trades: 5538\n",
      "Sharpe: 0.531\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 83200        |\n",
      "|    time_elapsed       | 1296         |\n",
      "|    total_timesteps    | 416000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.4        |\n",
      "|    explained_variance | -0.0729      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 83199        |\n",
      "|    policy_loss        | 1.32         |\n",
      "|    reward             | -0.015934588 |\n",
      "|    std                | 1.56e+06     |\n",
      "|    value_loss         | 0.00238      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 83300         |\n",
      "|    time_elapsed       | 1297          |\n",
      "|    total_timesteps    | 416500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.4         |\n",
      "|    explained_variance | -0.955        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 83299         |\n",
      "|    policy_loss        | 0.24          |\n",
      "|    reward             | -0.0004995527 |\n",
      "|    std                | 1.62e+06      |\n",
      "|    value_loss         | 9.82e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 83400        |\n",
      "|    time_elapsed       | 1299         |\n",
      "|    total_timesteps    | 417000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 83399        |\n",
      "|    policy_loss        | -0.286       |\n",
      "|    reward             | 0.0015314785 |\n",
      "|    std                | 1.67e+06     |\n",
      "|    value_loss         | 0.000225     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 83500       |\n",
      "|    time_elapsed       | 1300        |\n",
      "|    total_timesteps    | 417500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.5       |\n",
      "|    explained_variance | 0.37        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83499       |\n",
      "|    policy_loss        | -1.6        |\n",
      "|    reward             | 0.036978777 |\n",
      "|    std                | 1.71e+06    |\n",
      "|    value_loss         | 0.00306     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 83600       |\n",
      "|    time_elapsed       | 1302        |\n",
      "|    total_timesteps    | 418000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.6       |\n",
      "|    explained_variance | 0.237       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83599       |\n",
      "|    policy_loss        | 0.522       |\n",
      "|    reward             | -0.07393091 |\n",
      "|    std                | 1.73e+06    |\n",
      "|    value_loss         | 0.00154     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 83700         |\n",
      "|    time_elapsed       | 1304          |\n",
      "|    total_timesteps    | 418500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.6         |\n",
      "|    explained_variance | 7.08e-05      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 83699         |\n",
      "|    policy_loss        | -0.863        |\n",
      "|    reward             | 0.00072475645 |\n",
      "|    std                | 1.77e+06      |\n",
      "|    value_loss         | 0.000964      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 83800       |\n",
      "|    time_elapsed       | 1306        |\n",
      "|    total_timesteps    | 419000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.6       |\n",
      "|    explained_variance | 0.132       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83799       |\n",
      "|    policy_loss        | -0.81       |\n",
      "|    reward             | 0.020614332 |\n",
      "|    std                | 1.8e+06     |\n",
      "|    value_loss         | 0.00125     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 83900       |\n",
      "|    time_elapsed       | 1307        |\n",
      "|    total_timesteps    | 419500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.7       |\n",
      "|    explained_variance | 0.122       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83899       |\n",
      "|    policy_loss        | -0.551      |\n",
      "|    reward             | 0.006450888 |\n",
      "|    std                | 1.85e+06    |\n",
      "|    value_loss         | 0.000553    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 84000       |\n",
      "|    time_elapsed       | 1309        |\n",
      "|    total_timesteps    | 420000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.8       |\n",
      "|    explained_variance | 0.0917      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83999       |\n",
      "|    policy_loss        | 2.17        |\n",
      "|    reward             | 0.043551564 |\n",
      "|    std                | 1.92e+06    |\n",
      "|    value_loss         | 0.0121      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 84100      |\n",
      "|    time_elapsed       | 1311       |\n",
      "|    total_timesteps    | 420500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.8      |\n",
      "|    explained_variance | 0.404      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 84099      |\n",
      "|    policy_loss        | -6.2       |\n",
      "|    reward             | 0.13424186 |\n",
      "|    std                | 1.93e+06   |\n",
      "|    value_loss         | 0.0452     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 84200      |\n",
      "|    time_elapsed       | 1312       |\n",
      "|    total_timesteps    | 421000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.8      |\n",
      "|    explained_variance | 0.101      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 84199      |\n",
      "|    policy_loss        | 0.37       |\n",
      "|    reward             | 0.14421453 |\n",
      "|    std                | 1.97e+06   |\n",
      "|    value_loss         | 0.00938    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 84300       |\n",
      "|    time_elapsed       | 1314        |\n",
      "|    total_timesteps    | 421500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.8       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 84299       |\n",
      "|    policy_loss        | 0.176       |\n",
      "|    reward             | 0.030900784 |\n",
      "|    std                | 1.98e+06    |\n",
      "|    value_loss         | 0.000115    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 84400       |\n",
      "|    time_elapsed       | 1316        |\n",
      "|    total_timesteps    | 422000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 84399       |\n",
      "|    policy_loss        | -0.528      |\n",
      "|    reward             | 0.013845473 |\n",
      "|    std                | 2.02e+06    |\n",
      "|    value_loss         | 0.000354    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 84500       |\n",
      "|    time_elapsed       | 1317        |\n",
      "|    total_timesteps    | 422500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.9       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 84499       |\n",
      "|    policy_loss        | -1.19       |\n",
      "|    reward             | -0.03274499 |\n",
      "|    std                | 2.06e+06    |\n",
      "|    value_loss         | 0.00401     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 84600       |\n",
      "|    time_elapsed       | 1319        |\n",
      "|    total_timesteps    | 423000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32         |\n",
      "|    explained_variance | 0.00156     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 84599       |\n",
      "|    policy_loss        | -0.669      |\n",
      "|    reward             | 0.012679593 |\n",
      "|    std                | 2.12e+06    |\n",
      "|    value_loss         | 0.00101     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 84700      |\n",
      "|    time_elapsed       | 1320       |\n",
      "|    total_timesteps    | 423500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 84699      |\n",
      "|    policy_loss        | -7.94      |\n",
      "|    reward             | 0.24616955 |\n",
      "|    std                | 2.14e+06   |\n",
      "|    value_loss         | 0.0837     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 84800         |\n",
      "|    time_elapsed       | 1322          |\n",
      "|    total_timesteps    | 424000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32           |\n",
      "|    explained_variance | 0.326         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 84799         |\n",
      "|    policy_loss        | -2.25         |\n",
      "|    reward             | -0.0058446107 |\n",
      "|    std                | 2.18e+06      |\n",
      "|    value_loss         | 0.00497       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 84900        |\n",
      "|    time_elapsed       | 1323         |\n",
      "|    total_timesteps    | 424500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32          |\n",
      "|    explained_variance | 0.627        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84899        |\n",
      "|    policy_loss        | -1.01        |\n",
      "|    reward             | -0.015752466 |\n",
      "|    std                | 2.2e+06      |\n",
      "|    value_loss         | 0.00132      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 85000        |\n",
      "|    time_elapsed       | 1325         |\n",
      "|    total_timesteps    | 425000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.1        |\n",
      "|    explained_variance | 0.349        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84999        |\n",
      "|    policy_loss        | 1.39         |\n",
      "|    reward             | -0.036176454 |\n",
      "|    std                | 2.23e+06     |\n",
      "|    value_loss         | 0.00234      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 85100      |\n",
      "|    time_elapsed       | 1326       |\n",
      "|    total_timesteps    | 425500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.1      |\n",
      "|    explained_variance | 0.516      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 85099      |\n",
      "|    policy_loss        | -3.18      |\n",
      "|    reward             | 0.06266358 |\n",
      "|    std                | 2.27e+06   |\n",
      "|    value_loss         | 0.0116     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 85200      |\n",
      "|    time_elapsed       | 1328       |\n",
      "|    total_timesteps    | 426000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.1      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 85199      |\n",
      "|    policy_loss        | -0.4       |\n",
      "|    reward             | 0.13065661 |\n",
      "|    std                | 2.28e+06   |\n",
      "|    value_loss         | 0.00902    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 85300       |\n",
      "|    time_elapsed       | 1330        |\n",
      "|    total_timesteps    | 426500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.1       |\n",
      "|    explained_variance | 0.056       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85299       |\n",
      "|    policy_loss        | -1.39       |\n",
      "|    reward             | -0.15821828 |\n",
      "|    std                | 2.31e+06    |\n",
      "|    value_loss         | 0.0367      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 85400       |\n",
      "|    time_elapsed       | 1331        |\n",
      "|    total_timesteps    | 427000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.1       |\n",
      "|    explained_variance | 0.453       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85399       |\n",
      "|    policy_loss        | 0.148       |\n",
      "|    reward             | 0.030053029 |\n",
      "|    std                | 2.32e+06    |\n",
      "|    value_loss         | 5.9e-05     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 85500        |\n",
      "|    time_elapsed       | 1333         |\n",
      "|    total_timesteps    | 427500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.2        |\n",
      "|    explained_variance | -4.52        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 85499        |\n",
      "|    policy_loss        | 0.664        |\n",
      "|    reward             | -0.010971226 |\n",
      "|    std                | 2.36e+06     |\n",
      "|    value_loss         | 0.000593     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 85600        |\n",
      "|    time_elapsed       | 1335         |\n",
      "|    total_timesteps    | 428000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.2        |\n",
      "|    explained_variance | 2.86e-06     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 85599        |\n",
      "|    policy_loss        | 0.286        |\n",
      "|    reward             | -0.007776086 |\n",
      "|    std                | 2.39e+06     |\n",
      "|    value_loss         | 0.000335     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 85700       |\n",
      "|    time_elapsed       | 1336        |\n",
      "|    total_timesteps    | 428500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.2       |\n",
      "|    explained_variance | -0.0842     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85699       |\n",
      "|    policy_loss        | -0.166      |\n",
      "|    reward             | 0.011049915 |\n",
      "|    std                | 2.43e+06    |\n",
      "|    value_loss         | 6.01e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 85800       |\n",
      "|    time_elapsed       | 1338        |\n",
      "|    total_timesteps    | 429000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.3       |\n",
      "|    explained_variance | 0.212       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85799       |\n",
      "|    policy_loss        | -0.857      |\n",
      "|    reward             | 0.023893248 |\n",
      "|    std                | 2.49e+06    |\n",
      "|    value_loss         | 0.00164     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 85900        |\n",
      "|    time_elapsed       | 1339         |\n",
      "|    total_timesteps    | 429500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.3        |\n",
      "|    explained_variance | 0.219        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 85899        |\n",
      "|    policy_loss        | 0.396        |\n",
      "|    reward             | -0.073287174 |\n",
      "|    std                | 2.55e+06     |\n",
      "|    value_loss         | 0.00241      |\n",
      "----------------------------------------\n",
      "day: 2770, episode: 155\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 62351.65\n",
      "total_reward: 52351.65\n",
      "total_cost: 25.73\n",
      "total_trades: 5536\n",
      "Sharpe: 0.702\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 86000       |\n",
      "|    time_elapsed       | 1341        |\n",
      "|    total_timesteps    | 430000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.3       |\n",
      "|    explained_variance | 0.115       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85999       |\n",
      "|    policy_loss        | 0.585       |\n",
      "|    reward             | 0.004169244 |\n",
      "|    std                | 2.57e+06    |\n",
      "|    value_loss         | 0.000884    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 86100       |\n",
      "|    time_elapsed       | 1342        |\n",
      "|    total_timesteps    | 430500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 86099       |\n",
      "|    policy_loss        | -0.556      |\n",
      "|    reward             | 0.030909766 |\n",
      "|    std                | 2.61e+06    |\n",
      "|    value_loss         | 0.001       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 86200       |\n",
      "|    time_elapsed       | 1344        |\n",
      "|    total_timesteps    | 431000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.4       |\n",
      "|    explained_variance | -0.0356     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 86199       |\n",
      "|    policy_loss        | 3.59        |\n",
      "|    reward             | 0.096614726 |\n",
      "|    std                | 2.62e+06    |\n",
      "|    value_loss         | 0.022       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 86300      |\n",
      "|    time_elapsed       | 1345       |\n",
      "|    total_timesteps    | 431500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.4      |\n",
      "|    explained_variance | -1.19      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 86299      |\n",
      "|    policy_loss        | 0.576      |\n",
      "|    reward             | 0.17021841 |\n",
      "|    std                | 2.64e+06   |\n",
      "|    value_loss         | 0.0121     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 320       |\n",
      "|    iterations         | 86400     |\n",
      "|    time_elapsed       | 1347      |\n",
      "|    total_timesteps    | 432000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.4     |\n",
      "|    explained_variance | 0.623     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 86399     |\n",
      "|    policy_loss        | -27.2     |\n",
      "|    reward             | 0.6064641 |\n",
      "|    std                | 2.66e+06  |\n",
      "|    value_loss         | 0.686     |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 86500        |\n",
      "|    time_elapsed       | 1349         |\n",
      "|    total_timesteps    | 432500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.4        |\n",
      "|    explained_variance | -0.0116      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 86499        |\n",
      "|    policy_loss        | 0.28         |\n",
      "|    reward             | 0.0014789271 |\n",
      "|    std                | 2.64e+06     |\n",
      "|    value_loss         | 9.56e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 86600        |\n",
      "|    time_elapsed       | 1350         |\n",
      "|    total_timesteps    | 433000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 86599        |\n",
      "|    policy_loss        | -0.139       |\n",
      "|    reward             | -0.031895746 |\n",
      "|    std                | 2.67e+06     |\n",
      "|    value_loss         | 7.72e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 86700        |\n",
      "|    time_elapsed       | 1352         |\n",
      "|    total_timesteps    | 433500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.5        |\n",
      "|    explained_variance | -0.00143     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 86699        |\n",
      "|    policy_loss        | 0.399        |\n",
      "|    reward             | 0.0005544853 |\n",
      "|    std                | 2.73e+06     |\n",
      "|    value_loss         | 0.00036      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 86800        |\n",
      "|    time_elapsed       | 1354         |\n",
      "|    total_timesteps    | 434000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.5        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 86799        |\n",
      "|    policy_loss        | 0.386        |\n",
      "|    reward             | 0.0009990784 |\n",
      "|    std                | 2.78e+06     |\n",
      "|    value_loss         | 0.00215      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 86900        |\n",
      "|    time_elapsed       | 1355         |\n",
      "|    total_timesteps    | 434500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.5        |\n",
      "|    explained_variance | 0.226        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 86899        |\n",
      "|    policy_loss        | 2.88         |\n",
      "|    reward             | -0.011535664 |\n",
      "|    std                | 2.82e+06     |\n",
      "|    value_loss         | 0.00844      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 87000       |\n",
      "|    time_elapsed       | 1357        |\n",
      "|    total_timesteps    | 435000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.6       |\n",
      "|    explained_variance | -0.108      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 86999       |\n",
      "|    policy_loss        | 2.67        |\n",
      "|    reward             | -0.25837797 |\n",
      "|    std                | 2.87e+06    |\n",
      "|    value_loss         | 0.00872     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 87100       |\n",
      "|    time_elapsed       | 1359        |\n",
      "|    total_timesteps    | 435500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87099       |\n",
      "|    policy_loss        | 1.49        |\n",
      "|    reward             | 0.058170803 |\n",
      "|    std                | 2.91e+06    |\n",
      "|    value_loss         | 0.00244     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 87200      |\n",
      "|    time_elapsed       | 1360       |\n",
      "|    total_timesteps    | 436000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.6      |\n",
      "|    explained_variance | 0.21       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 87199      |\n",
      "|    policy_loss        | 0.176      |\n",
      "|    reward             | 0.06852798 |\n",
      "|    std                | 2.98e+06   |\n",
      "|    value_loss         | 5.28e-05   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 87300        |\n",
      "|    time_elapsed       | 1362         |\n",
      "|    total_timesteps    | 436500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 87299        |\n",
      "|    policy_loss        | -1.83        |\n",
      "|    reward             | -0.023230627 |\n",
      "|    std                | 3.01e+06     |\n",
      "|    value_loss         | 0.00342      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 87400      |\n",
      "|    time_elapsed       | 1364       |\n",
      "|    total_timesteps    | 437000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.7      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 87399      |\n",
      "|    policy_loss        | -5.84      |\n",
      "|    reward             | 0.08334638 |\n",
      "|    std                | 3.07e+06   |\n",
      "|    value_loss         | 0.0352     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 87500      |\n",
      "|    time_elapsed       | 1365       |\n",
      "|    total_timesteps    | 437500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.7      |\n",
      "|    explained_variance | 0.09       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 87499      |\n",
      "|    policy_loss        | -0.647     |\n",
      "|    reward             | -0.0911989 |\n",
      "|    std                | 3.08e+06   |\n",
      "|    value_loss         | 0.0113     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 87600         |\n",
      "|    time_elapsed       | 1367          |\n",
      "|    total_timesteps    | 438000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.7         |\n",
      "|    explained_variance | 0.872         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 87599         |\n",
      "|    policy_loss        | 0.19          |\n",
      "|    reward             | -0.0011047967 |\n",
      "|    std                | 3.12e+06      |\n",
      "|    value_loss         | 4.23e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 87700        |\n",
      "|    time_elapsed       | 1368         |\n",
      "|    total_timesteps    | 438500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 87699        |\n",
      "|    policy_loss        | -0.51        |\n",
      "|    reward             | -0.022572564 |\n",
      "|    std                | 3.16e+06     |\n",
      "|    value_loss         | 0.000284     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 87800        |\n",
      "|    time_elapsed       | 1370         |\n",
      "|    total_timesteps    | 439000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.8        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 87799        |\n",
      "|    policy_loss        | 0.386        |\n",
      "|    reward             | -0.068759546 |\n",
      "|    std                | 3.22e+06     |\n",
      "|    value_loss         | 0.000922     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 87900      |\n",
      "|    time_elapsed       | 1372       |\n",
      "|    total_timesteps    | 439500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.8      |\n",
      "|    explained_variance | 0.762      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 87899      |\n",
      "|    policy_loss        | -1.65      |\n",
      "|    reward             | 0.03624807 |\n",
      "|    std                | 3.23e+06   |\n",
      "|    value_loss         | 0.00274    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 88000       |\n",
      "|    time_elapsed       | 1373        |\n",
      "|    total_timesteps    | 440000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.8       |\n",
      "|    explained_variance | 0.0936      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87999       |\n",
      "|    policy_loss        | 2.2         |\n",
      "|    reward             | 0.009056921 |\n",
      "|    std                | 3.25e+06    |\n",
      "|    value_loss         | 0.01        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 320      |\n",
      "|    iterations         | 88100    |\n",
      "|    time_elapsed       | 1375     |\n",
      "|    total_timesteps    | 440500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.8    |\n",
      "|    explained_variance | 0.546    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 88099    |\n",
      "|    policy_loss        | 1.62     |\n",
      "|    reward             | 0.148842 |\n",
      "|    std                | 3.32e+06 |\n",
      "|    value_loss         | 0.00388  |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 88200         |\n",
      "|    time_elapsed       | 1376          |\n",
      "|    total_timesteps    | 441000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.9         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 88199         |\n",
      "|    policy_loss        | 0.775         |\n",
      "|    reward             | -0.0025447346 |\n",
      "|    std                | 3.35e+06      |\n",
      "|    value_loss         | 0.000993      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 88300       |\n",
      "|    time_elapsed       | 1378        |\n",
      "|    total_timesteps    | 441500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.9       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88299       |\n",
      "|    policy_loss        | -0.419      |\n",
      "|    reward             | 0.025620192 |\n",
      "|    std                | 3.42e+06    |\n",
      "|    value_loss         | 0.000362    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 88400      |\n",
      "|    time_elapsed       | 1379       |\n",
      "|    total_timesteps    | 442000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 88399      |\n",
      "|    policy_loss        | -1.39      |\n",
      "|    reward             | 0.24701996 |\n",
      "|    std                | 3.45e+06   |\n",
      "|    value_loss         | 0.0127     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 88500       |\n",
      "|    time_elapsed       | 1381        |\n",
      "|    total_timesteps    | 442500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.9       |\n",
      "|    explained_variance | -0.324      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88499       |\n",
      "|    policy_loss        | -0.621      |\n",
      "|    reward             | -0.13676345 |\n",
      "|    std                | 3.49e+06    |\n",
      "|    value_loss         | 0.00195     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 88600       |\n",
      "|    time_elapsed       | 1383        |\n",
      "|    total_timesteps    | 443000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33         |\n",
      "|    explained_variance | 0.553       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88599       |\n",
      "|    policy_loss        | -2.52       |\n",
      "|    reward             | -0.10870494 |\n",
      "|    std                | 3.53e+06    |\n",
      "|    value_loss         | 0.00662     |\n",
      "---------------------------------------\n",
      "day: 2770, episode: 160\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 167160.67\n",
      "total_reward: 157160.67\n",
      "total_cost: 30.76\n",
      "total_trades: 5535\n",
      "Sharpe: 0.873\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 88700       |\n",
      "|    time_elapsed       | 1384        |\n",
      "|    total_timesteps    | 443500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88699       |\n",
      "|    policy_loss        | 0.0684      |\n",
      "|    reward             | 0.011432443 |\n",
      "|    std                | 3.54e+06    |\n",
      "|    value_loss         | 4.57e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 88800        |\n",
      "|    time_elapsed       | 1386         |\n",
      "|    total_timesteps    | 444000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33          |\n",
      "|    explained_variance | -0.256       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88799        |\n",
      "|    policy_loss        | 0.0657       |\n",
      "|    reward             | -0.008819707 |\n",
      "|    std                | 3.58e+06     |\n",
      "|    value_loss         | 3.75e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 88900       |\n",
      "|    time_elapsed       | 1388        |\n",
      "|    total_timesteps    | 444500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33         |\n",
      "|    explained_variance | 0.00702     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88899       |\n",
      "|    policy_loss        | -0.832      |\n",
      "|    reward             | -0.13712063 |\n",
      "|    std                | 3.65e+06    |\n",
      "|    value_loss         | 0.00152     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 89000      |\n",
      "|    time_elapsed       | 1389       |\n",
      "|    total_timesteps    | 445000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.1      |\n",
      "|    explained_variance | 0.436      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 88999      |\n",
      "|    policy_loss        | -0.131     |\n",
      "|    reward             | 0.06213368 |\n",
      "|    std                | 3.69e+06   |\n",
      "|    value_loss         | 0.000214   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 89100      |\n",
      "|    time_elapsed       | 1391       |\n",
      "|    total_timesteps    | 445500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 89099      |\n",
      "|    policy_loss        | 2.75       |\n",
      "|    reward             | 0.06377378 |\n",
      "|    std                | 3.71e+06   |\n",
      "|    value_loss         | 0.0132     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 89200      |\n",
      "|    time_elapsed       | 1392       |\n",
      "|    total_timesteps    | 446000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.1      |\n",
      "|    explained_variance | 0.357      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 89199      |\n",
      "|    policy_loss        | -3.09      |\n",
      "|    reward             | 0.10396514 |\n",
      "|    std                | 3.72e+06   |\n",
      "|    value_loss         | 0.0101     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 89300        |\n",
      "|    time_elapsed       | 1394         |\n",
      "|    total_timesteps    | 446500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 89299        |\n",
      "|    policy_loss        | -0.517       |\n",
      "|    reward             | -0.010144173 |\n",
      "|    std                | 3.72e+06     |\n",
      "|    value_loss         | 0.000375     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 89400         |\n",
      "|    time_elapsed       | 1396          |\n",
      "|    total_timesteps    | 447000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 89399         |\n",
      "|    policy_loss        | 0.101         |\n",
      "|    reward             | -0.0023574138 |\n",
      "|    std                | 3.78e+06      |\n",
      "|    value_loss         | 6.31e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 89500        |\n",
      "|    time_elapsed       | 1398         |\n",
      "|    total_timesteps    | 447500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.2        |\n",
      "|    explained_variance | -0.0402      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 89499        |\n",
      "|    policy_loss        | -0.696       |\n",
      "|    reward             | -0.020912532 |\n",
      "|    std                | 3.87e+06     |\n",
      "|    value_loss         | 0.00284      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 89600        |\n",
      "|    time_elapsed       | 1399         |\n",
      "|    total_timesteps    | 448000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.2        |\n",
      "|    explained_variance | 0.789        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 89599        |\n",
      "|    policy_loss        | -0.267       |\n",
      "|    reward             | -0.004175484 |\n",
      "|    std                | 3.93e+06     |\n",
      "|    value_loss         | 0.000181     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 89700      |\n",
      "|    time_elapsed       | 1401       |\n",
      "|    total_timesteps    | 448500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 89699      |\n",
      "|    policy_loss        | 1.41       |\n",
      "|    reward             | 0.04714179 |\n",
      "|    std                | 4.08e+06   |\n",
      "|    value_loss         | 0.00337    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 89800         |\n",
      "|    time_elapsed       | 1402          |\n",
      "|    total_timesteps    | 449000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.3         |\n",
      "|    explained_variance | 0.881         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 89799         |\n",
      "|    policy_loss        | -1.3          |\n",
      "|    reward             | -0.0019144722 |\n",
      "|    std                | 4.13e+06      |\n",
      "|    value_loss         | 0.00174       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 89900         |\n",
      "|    time_elapsed       | 1404          |\n",
      "|    total_timesteps    | 449500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 89899         |\n",
      "|    policy_loss        | 1.17          |\n",
      "|    reward             | -0.0019213798 |\n",
      "|    std                | 4.22e+06      |\n",
      "|    value_loss         | 0.00139       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 90000         |\n",
      "|    time_elapsed       | 1406          |\n",
      "|    total_timesteps    | 450000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.4         |\n",
      "|    explained_variance | 0.39          |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 89999         |\n",
      "|    policy_loss        | -1.41         |\n",
      "|    reward             | -0.0016999756 |\n",
      "|    std                | 4.32e+06      |\n",
      "|    value_loss         | 0.00205       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 90100       |\n",
      "|    time_elapsed       | 1407        |\n",
      "|    total_timesteps    | 450500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.4       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90099       |\n",
      "|    policy_loss        | -0.791      |\n",
      "|    reward             | 0.104989424 |\n",
      "|    std                | 4.39e+06    |\n",
      "|    value_loss         | 0.00517     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 90200       |\n",
      "|    time_elapsed       | 1409        |\n",
      "|    total_timesteps    | 451000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.4       |\n",
      "|    explained_variance | 0.231       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90199       |\n",
      "|    policy_loss        | 12.6        |\n",
      "|    reward             | -0.17579159 |\n",
      "|    std                | 4.39e+06    |\n",
      "|    value_loss         | 0.149       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 90300       |\n",
      "|    time_elapsed       | 1411        |\n",
      "|    total_timesteps    | 451500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.4       |\n",
      "|    explained_variance | 0.000138    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90299       |\n",
      "|    policy_loss        | 0.75        |\n",
      "|    reward             | -0.21941859 |\n",
      "|    std                | 4.39e+06    |\n",
      "|    value_loss         | 0.00562     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 90400       |\n",
      "|    time_elapsed       | 1412        |\n",
      "|    total_timesteps    | 452000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90399       |\n",
      "|    policy_loss        | -4.26       |\n",
      "|    reward             | 0.050537467 |\n",
      "|    std                | 4.45e+06    |\n",
      "|    value_loss         | 0.0176      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 90500       |\n",
      "|    time_elapsed       | 1414        |\n",
      "|    total_timesteps    | 452500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.5       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90499       |\n",
      "|    policy_loss        | -0.0531     |\n",
      "|    reward             | 0.018078683 |\n",
      "|    std                | 4.49e+06    |\n",
      "|    value_loss         | 0.000189    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 90600      |\n",
      "|    time_elapsed       | 1415       |\n",
      "|    total_timesteps    | 453000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.5      |\n",
      "|    explained_variance | 0.312      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 90599      |\n",
      "|    policy_loss        | 2.13       |\n",
      "|    reward             | 0.14117298 |\n",
      "|    std                | 4.56e+06   |\n",
      "|    value_loss         | 0.00861    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 90700       |\n",
      "|    time_elapsed       | 1417        |\n",
      "|    total_timesteps    | 453500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.5       |\n",
      "|    explained_variance | 0.732       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90699       |\n",
      "|    policy_loss        | -4.17       |\n",
      "|    reward             | 0.062464755 |\n",
      "|    std                | 4.63e+06    |\n",
      "|    value_loss         | 0.0166      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 90800      |\n",
      "|    time_elapsed       | 1419       |\n",
      "|    total_timesteps    | 454000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.5      |\n",
      "|    explained_variance | 0.0759     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 90799      |\n",
      "|    policy_loss        | 5.15       |\n",
      "|    reward             | 0.38031727 |\n",
      "|    std                | 4.7e+06    |\n",
      "|    value_loss         | 0.0449     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 90900       |\n",
      "|    time_elapsed       | 1420        |\n",
      "|    total_timesteps    | 454500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90899       |\n",
      "|    policy_loss        | -0.322      |\n",
      "|    reward             | -0.01709138 |\n",
      "|    std                | 4.7e+06     |\n",
      "|    value_loss         | 0.000185    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 91000        |\n",
      "|    time_elapsed       | 1422         |\n",
      "|    total_timesteps    | 455000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.6        |\n",
      "|    explained_variance | 0.561        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 90999        |\n",
      "|    policy_loss        | 0.273        |\n",
      "|    reward             | -0.011851258 |\n",
      "|    std                | 4.76e+06     |\n",
      "|    value_loss         | 0.000377     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 91100        |\n",
      "|    time_elapsed       | 1423         |\n",
      "|    total_timesteps    | 455500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.6        |\n",
      "|    explained_variance | 0.511        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91099        |\n",
      "|    policy_loss        | 0.366        |\n",
      "|    reward             | -0.001327895 |\n",
      "|    std                | 4.84e+06     |\n",
      "|    value_loss         | 0.000135     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 91200      |\n",
      "|    time_elapsed       | 1425       |\n",
      "|    total_timesteps    | 456000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 91199      |\n",
      "|    policy_loss        | 1.26       |\n",
      "|    reward             | 0.04684906 |\n",
      "|    std                | 4.91e+06   |\n",
      "|    value_loss         | 0.00332    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 91300      |\n",
      "|    time_elapsed       | 1426       |\n",
      "|    total_timesteps    | 456500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.7      |\n",
      "|    explained_variance | 0.231      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 91299      |\n",
      "|    policy_loss        | 2.81       |\n",
      "|    reward             | 0.10961323 |\n",
      "|    std                | 4.96e+06   |\n",
      "|    value_loss         | 0.0079     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 91400      |\n",
      "|    time_elapsed       | 1428       |\n",
      "|    total_timesteps    | 457000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.7      |\n",
      "|    explained_variance | 0.0701     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 91399      |\n",
      "|    policy_loss        | 9.82       |\n",
      "|    reward             | -0.1178204 |\n",
      "|    std                | 5e+06      |\n",
      "|    value_loss         | 0.0969     |\n",
      "--------------------------------------\n",
      "day: 2770, episode: 165\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 142587.99\n",
      "total_reward: 132587.99\n",
      "total_cost: 17.11\n",
      "total_trades: 5538\n",
      "Sharpe: 0.850\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 91500        |\n",
      "|    time_elapsed       | 1429         |\n",
      "|    total_timesteps    | 457500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.7        |\n",
      "|    explained_variance | -7.1         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91499        |\n",
      "|    policy_loss        | -0.281       |\n",
      "|    reward             | 0.0054854387 |\n",
      "|    std                | 5.02e+06     |\n",
      "|    value_loss         | 0.000118     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 91600       |\n",
      "|    time_elapsed       | 1431        |\n",
      "|    total_timesteps    | 458000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.7       |\n",
      "|    explained_variance | -3.88       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 91599       |\n",
      "|    policy_loss        | -0.304      |\n",
      "|    reward             | 0.016416902 |\n",
      "|    std                | 5.09e+06    |\n",
      "|    value_loss         | 0.000158    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 91700        |\n",
      "|    time_elapsed       | 1432         |\n",
      "|    total_timesteps    | 458500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91699        |\n",
      "|    policy_loss        | -0.00217     |\n",
      "|    reward             | 0.0011034737 |\n",
      "|    std                | 5.19e+06     |\n",
      "|    value_loss         | 2.64e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 91800        |\n",
      "|    time_elapsed       | 1434         |\n",
      "|    total_timesteps    | 459000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.8        |\n",
      "|    explained_variance | 0.948        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91799        |\n",
      "|    policy_loss        | 0.324        |\n",
      "|    reward             | 0.0058792895 |\n",
      "|    std                | 5.36e+06     |\n",
      "|    value_loss         | 9.73e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 91900       |\n",
      "|    time_elapsed       | 1435        |\n",
      "|    total_timesteps    | 459500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.9       |\n",
      "|    explained_variance | 0.446       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 91899       |\n",
      "|    policy_loss        | -0.119      |\n",
      "|    reward             | -0.01374037 |\n",
      "|    std                | 5.63e+06    |\n",
      "|    value_loss         | 0.000102    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 319           |\n",
      "|    iterations         | 92000         |\n",
      "|    time_elapsed       | 1437          |\n",
      "|    total_timesteps    | 460000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -34           |\n",
      "|    explained_variance | -0.103        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 91999         |\n",
      "|    policy_loss        | 0.727         |\n",
      "|    reward             | 0.00085064827 |\n",
      "|    std                | 5.8e+06       |\n",
      "|    value_loss         | 0.000455      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 92100        |\n",
      "|    time_elapsed       | 1439         |\n",
      "|    total_timesteps    | 460500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34          |\n",
      "|    explained_variance | 0.244        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92099        |\n",
      "|    policy_loss        | -0.905       |\n",
      "|    reward             | -0.006958084 |\n",
      "|    std                | 5.95e+06     |\n",
      "|    value_loss         | 0.000834     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 92200        |\n",
      "|    time_elapsed       | 1440         |\n",
      "|    total_timesteps    | 461000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.1        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92199        |\n",
      "|    policy_loss        | -0.134       |\n",
      "|    reward             | -0.035345737 |\n",
      "|    std                | 6.12e+06     |\n",
      "|    value_loss         | 0.000517     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 92300        |\n",
      "|    time_elapsed       | 1442         |\n",
      "|    total_timesteps    | 461500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.1        |\n",
      "|    explained_variance | 1.15e-05     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92299        |\n",
      "|    policy_loss        | 0.141        |\n",
      "|    reward             | -0.021686248 |\n",
      "|    std                | 6.31e+06     |\n",
      "|    value_loss         | 0.000131     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 92400        |\n",
      "|    time_elapsed       | 1443         |\n",
      "|    total_timesteps    | 462000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.2        |\n",
      "|    explained_variance | 0.0449       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92399        |\n",
      "|    policy_loss        | -1.7         |\n",
      "|    reward             | -0.008138256 |\n",
      "|    std                | 6.47e+06     |\n",
      "|    value_loss         | 0.0087       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 92500        |\n",
      "|    time_elapsed       | 1445         |\n",
      "|    total_timesteps    | 462500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92499        |\n",
      "|    policy_loss        | -2.01        |\n",
      "|    reward             | -0.055064067 |\n",
      "|    std                | 6.54e+06     |\n",
      "|    value_loss         | 0.0288       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 92600       |\n",
      "|    time_elapsed       | 1446        |\n",
      "|    total_timesteps    | 463000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 92599       |\n",
      "|    policy_loss        | -0.457      |\n",
      "|    reward             | 0.013493639 |\n",
      "|    std                | 6.64e+06    |\n",
      "|    value_loss         | 0.000322    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 92700        |\n",
      "|    time_elapsed       | 1448         |\n",
      "|    total_timesteps    | 463500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.3        |\n",
      "|    explained_variance | 0.731        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92699        |\n",
      "|    policy_loss        | 0.198        |\n",
      "|    reward             | -0.009101791 |\n",
      "|    std                | 6.77e+06     |\n",
      "|    value_loss         | 5.24e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 92800         |\n",
      "|    time_elapsed       | 1449          |\n",
      "|    total_timesteps    | 464000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -34.3         |\n",
      "|    explained_variance | 0.00104       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 92799         |\n",
      "|    policy_loss        | 1.39          |\n",
      "|    reward             | -0.0051732864 |\n",
      "|    std                | 7e+06         |\n",
      "|    value_loss         | 0.00779       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 92900        |\n",
      "|    time_elapsed       | 1451         |\n",
      "|    total_timesteps    | 464500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92899        |\n",
      "|    policy_loss        | 0.124        |\n",
      "|    reward             | -0.007880867 |\n",
      "|    std                | 7.11e+06     |\n",
      "|    value_loss         | 0.000572     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 93000      |\n",
      "|    time_elapsed       | 1452       |\n",
      "|    total_timesteps    | 465000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -34.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 92999      |\n",
      "|    policy_loss        | -3.29      |\n",
      "|    reward             | -0.0303097 |\n",
      "|    std                | 7.14e+06   |\n",
      "|    value_loss         | 0.00912    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 320       |\n",
      "|    iterations         | 93100     |\n",
      "|    time_elapsed       | 1454      |\n",
      "|    total_timesteps    | 465500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -34.4     |\n",
      "|    explained_variance | 0.101     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 93099     |\n",
      "|    policy_loss        | 0.688     |\n",
      "|    reward             | 0.1497054 |\n",
      "|    std                | 7.16e+06  |\n",
      "|    value_loss         | 0.0101    |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 93200         |\n",
      "|    time_elapsed       | 1455          |\n",
      "|    total_timesteps    | 466000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -34.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 93199         |\n",
      "|    policy_loss        | 0.364         |\n",
      "|    reward             | -0.0048218532 |\n",
      "|    std                | 7.28e+06      |\n",
      "|    value_loss         | 0.000664      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 93300       |\n",
      "|    time_elapsed       | 1457        |\n",
      "|    total_timesteps    | 466500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.4       |\n",
      "|    explained_variance | 0.0817      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93299       |\n",
      "|    policy_loss        | -0.362      |\n",
      "|    reward             | 0.037533462 |\n",
      "|    std                | 7.43e+06    |\n",
      "|    value_loss         | 0.00112     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 93400       |\n",
      "|    time_elapsed       | 1458        |\n",
      "|    total_timesteps    | 467000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.5       |\n",
      "|    explained_variance | -0.00604    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93399       |\n",
      "|    policy_loss        | 3.1         |\n",
      "|    reward             | -0.14101736 |\n",
      "|    std                | 7.59e+06    |\n",
      "|    value_loss         | 0.00873     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 93500      |\n",
      "|    time_elapsed       | 1460       |\n",
      "|    total_timesteps    | 467500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -34.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 93499      |\n",
      "|    policy_loss        | -2.85      |\n",
      "|    reward             | 0.10541718 |\n",
      "|    std                | 7.66e+06   |\n",
      "|    value_loss         | 0.00767    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 93600      |\n",
      "|    time_elapsed       | 1461       |\n",
      "|    total_timesteps    | 468000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -34.5      |\n",
      "|    explained_variance | 0.168      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 93599      |\n",
      "|    policy_loss        | 1.27       |\n",
      "|    reward             | 0.15089421 |\n",
      "|    std                | 7.73e+06   |\n",
      "|    value_loss         | 0.00426    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 93700        |\n",
      "|    time_elapsed       | 1463         |\n",
      "|    total_timesteps    | 468500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.5        |\n",
      "|    explained_variance | -7.03        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 93699        |\n",
      "|    policy_loss        | -0.507       |\n",
      "|    reward             | -0.015821885 |\n",
      "|    std                | 7.8e+06      |\n",
      "|    value_loss         | 0.000283     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 93800        |\n",
      "|    time_elapsed       | 1465         |\n",
      "|    total_timesteps    | 469000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.6        |\n",
      "|    explained_variance | 0.00309      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 93799        |\n",
      "|    policy_loss        | 0.157        |\n",
      "|    reward             | 0.0034888124 |\n",
      "|    std                | 7.91e+06     |\n",
      "|    value_loss         | 0.000126     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 93900      |\n",
      "|    time_elapsed       | 1466       |\n",
      "|    total_timesteps    | 469500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -34.6      |\n",
      "|    explained_variance | -0.453     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 93899      |\n",
      "|    policy_loss        | -0.692     |\n",
      "|    reward             | 0.07654464 |\n",
      "|    std                | 8.16e+06   |\n",
      "|    value_loss         | 0.000431   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 94000       |\n",
      "|    time_elapsed       | 1468        |\n",
      "|    total_timesteps    | 470000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93999       |\n",
      "|    policy_loss        | 0.333       |\n",
      "|    reward             | 0.026309159 |\n",
      "|    std                | 8.46e+06    |\n",
      "|    value_loss         | 0.000457    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 94100       |\n",
      "|    time_elapsed       | 1470        |\n",
      "|    total_timesteps    | 470500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.7       |\n",
      "|    explained_variance | 0.116       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94099       |\n",
      "|    policy_loss        | -4.77       |\n",
      "|    reward             | 0.044007972 |\n",
      "|    std                | 8.51e+06    |\n",
      "|    value_loss         | 0.0231      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 94200      |\n",
      "|    time_elapsed       | 1471       |\n",
      "|    total_timesteps    | 471000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -34.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 94199      |\n",
      "|    policy_loss        | 1.91       |\n",
      "|    reward             | 0.07403191 |\n",
      "|    std                | 8.52e+06   |\n",
      "|    value_loss         | 0.0161     |\n",
      "--------------------------------------\n",
      "day: 2770, episode: 170\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 90785.78\n",
      "total_reward: 80785.78\n",
      "total_cost: 17.92\n",
      "total_trades: 5535\n",
      "Sharpe: 0.749\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 94300        |\n",
      "|    time_elapsed       | 1473         |\n",
      "|    total_timesteps    | 471500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.7        |\n",
      "|    explained_variance | 0.942        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 94299        |\n",
      "|    policy_loss        | 0.0623       |\n",
      "|    reward             | -0.007855287 |\n",
      "|    std                | 8.59e+06     |\n",
      "|    value_loss         | 1.96e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 94400         |\n",
      "|    time_elapsed       | 1474          |\n",
      "|    total_timesteps    | 472000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -34.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 94399         |\n",
      "|    policy_loss        | -0.249        |\n",
      "|    reward             | -0.0075744833 |\n",
      "|    std                | 8.72e+06      |\n",
      "|    value_loss         | 8.78e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 94500       |\n",
      "|    time_elapsed       | 1476        |\n",
      "|    total_timesteps    | 472500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94499       |\n",
      "|    policy_loss        | 2.46        |\n",
      "|    reward             | 0.049540505 |\n",
      "|    std                | 8.9e+06     |\n",
      "|    value_loss         | 0.00607     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 94600        |\n",
      "|    time_elapsed       | 1477         |\n",
      "|    total_timesteps    | 473000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 94599        |\n",
      "|    policy_loss        | 3.57         |\n",
      "|    reward             | -0.106670216 |\n",
      "|    std                | 8.98e+06     |\n",
      "|    value_loss         | 0.015        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 94700       |\n",
      "|    time_elapsed       | 1479        |\n",
      "|    total_timesteps    | 473500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94699       |\n",
      "|    policy_loss        | -1.37       |\n",
      "|    reward             | 0.085829854 |\n",
      "|    std                | 9.17e+06    |\n",
      "|    value_loss         | 0.00304     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 94800        |\n",
      "|    time_elapsed       | 1480         |\n",
      "|    total_timesteps    | 474000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 94799        |\n",
      "|    policy_loss        | -0.554       |\n",
      "|    reward             | -0.009524818 |\n",
      "|    std                | 9.42e+06     |\n",
      "|    value_loss         | 0.000247     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 320            |\n",
      "|    iterations         | 94900          |\n",
      "|    time_elapsed       | 1481           |\n",
      "|    total_timesteps    | 474500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -34.9          |\n",
      "|    explained_variance | -8.37          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 94899          |\n",
      "|    policy_loss        | 0.195          |\n",
      "|    reward             | -0.00020871105 |\n",
      "|    std                | 9.45e+06       |\n",
      "|    value_loss         | 0.000247       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 95000      |\n",
      "|    time_elapsed       | 1483       |\n",
      "|    total_timesteps    | 475000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -35        |\n",
      "|    explained_variance | 0.354      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 94999      |\n",
      "|    policy_loss        | 0.0137     |\n",
      "|    reward             | 0.01659513 |\n",
      "|    std                | 9.65e+06   |\n",
      "|    value_loss         | 3.7e-05    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 95100         |\n",
      "|    time_elapsed       | 1484          |\n",
      "|    total_timesteps    | 475500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -35           |\n",
      "|    explained_variance | 0.246         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 95099         |\n",
      "|    policy_loss        | -0.824        |\n",
      "|    reward             | -0.0064840424 |\n",
      "|    std                | 9.85e+06      |\n",
      "|    value_loss         | 0.000615      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 95200        |\n",
      "|    time_elapsed       | 1486         |\n",
      "|    total_timesteps    | 476000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.1        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 95199        |\n",
      "|    policy_loss        | -1.62        |\n",
      "|    reward             | -0.035306804 |\n",
      "|    std                | 1.02e+07     |\n",
      "|    value_loss         | 0.00268      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 95300       |\n",
      "|    time_elapsed       | 1488        |\n",
      "|    total_timesteps    | 476500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 95299       |\n",
      "|    policy_loss        | -0.569      |\n",
      "|    reward             | 0.027637908 |\n",
      "|    std                | 1.05e+07    |\n",
      "|    value_loss         | 0.000459    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 95400         |\n",
      "|    time_elapsed       | 1489          |\n",
      "|    total_timesteps    | 477000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -35.2         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 95399         |\n",
      "|    policy_loss        | 1.24          |\n",
      "|    reward             | -0.0122151505 |\n",
      "|    std                | 1.07e+07      |\n",
      "|    value_loss         | 0.00149       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 95500      |\n",
      "|    time_elapsed       | 1491       |\n",
      "|    total_timesteps    | 477500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -35.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 95499      |\n",
      "|    policy_loss        | -0.341     |\n",
      "|    reward             | 0.02197808 |\n",
      "|    std                | 1.09e+07   |\n",
      "|    value_loss         | 0.000101   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 95600       |\n",
      "|    time_elapsed       | 1492        |\n",
      "|    total_timesteps    | 478000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 95599       |\n",
      "|    policy_loss        | -1.71       |\n",
      "|    reward             | -0.03883419 |\n",
      "|    std                | 1.12e+07    |\n",
      "|    value_loss         | 0.00294     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 95700         |\n",
      "|    time_elapsed       | 1494          |\n",
      "|    total_timesteps    | 478500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -35.3         |\n",
      "|    explained_variance | 0.626         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 95699         |\n",
      "|    policy_loss        | -1.79         |\n",
      "|    reward             | 0.00060277403 |\n",
      "|    std                | 1.14e+07      |\n",
      "|    value_loss         | 0.00316       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 95800       |\n",
      "|    time_elapsed       | 1495        |\n",
      "|    total_timesteps    | 479000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 95799       |\n",
      "|    policy_loss        | -0.0606     |\n",
      "|    reward             | 0.013054257 |\n",
      "|    std                | 1.14e+07    |\n",
      "|    value_loss         | 0.00229     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 95900       |\n",
      "|    time_elapsed       | 1497        |\n",
      "|    total_timesteps    | 479500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.3       |\n",
      "|    explained_variance | -0.032      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 95899       |\n",
      "|    policy_loss        | -0.919      |\n",
      "|    reward             | 0.017052872 |\n",
      "|    std                | 1.15e+07    |\n",
      "|    value_loss         | 0.000897    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 96000         |\n",
      "|    time_elapsed       | 1499          |\n",
      "|    total_timesteps    | 480000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -35.3         |\n",
      "|    explained_variance | 2.1e-05       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 95999         |\n",
      "|    policy_loss        | 0.00599       |\n",
      "|    reward             | -0.0027811546 |\n",
      "|    std                | 1.17e+07      |\n",
      "|    value_loss         | 4.09e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 96100        |\n",
      "|    time_elapsed       | 1500         |\n",
      "|    total_timesteps    | 480500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 96099        |\n",
      "|    policy_loss        | 5.01         |\n",
      "|    reward             | 0.0033897492 |\n",
      "|    std                | 1.18e+07     |\n",
      "|    value_loss         | 0.0222       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 96200       |\n",
      "|    time_elapsed       | 1502        |\n",
      "|    total_timesteps    | 481000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 96199       |\n",
      "|    policy_loss        | -0.232      |\n",
      "|    reward             | 0.013655127 |\n",
      "|    std                | 1.18e+07    |\n",
      "|    value_loss         | 0.000508    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 96300       |\n",
      "|    time_elapsed       | 1503        |\n",
      "|    total_timesteps    | 481500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.4       |\n",
      "|    explained_variance | 0.376       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 96299       |\n",
      "|    policy_loss        | 0.508       |\n",
      "|    reward             | 0.035568785 |\n",
      "|    std                | 1.19e+07    |\n",
      "|    value_loss         | 0.000549    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 96400      |\n",
      "|    time_elapsed       | 1505       |\n",
      "|    total_timesteps    | 482000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -35.4      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 96399      |\n",
      "|    policy_loss        | 0.991      |\n",
      "|    reward             | 0.08775621 |\n",
      "|    std                | 1.2e+07    |\n",
      "|    value_loss         | 0.00617    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 96500       |\n",
      "|    time_elapsed       | 1506        |\n",
      "|    total_timesteps    | 482500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.4       |\n",
      "|    explained_variance | 0.472       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 96499       |\n",
      "|    policy_loss        | -3.39       |\n",
      "|    reward             | 0.019474866 |\n",
      "|    std                | 1.22e+07    |\n",
      "|    value_loss         | 0.0096      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 96600      |\n",
      "|    time_elapsed       | 1508       |\n",
      "|    total_timesteps    | 483000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -35.5      |\n",
      "|    explained_variance | -0.762     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 96599      |\n",
      "|    policy_loss        | -0.356     |\n",
      "|    reward             | 0.00826997 |\n",
      "|    std                | 1.24e+07   |\n",
      "|    value_loss         | 0.000258   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 96700        |\n",
      "|    time_elapsed       | 1509         |\n",
      "|    total_timesteps    | 483500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.5        |\n",
      "|    explained_variance | 0.503        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 96699        |\n",
      "|    policy_loss        | -0.171       |\n",
      "|    reward             | -0.020237988 |\n",
      "|    std                | 1.26e+07     |\n",
      "|    value_loss         | 0.000225     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 96800       |\n",
      "|    time_elapsed       | 1511        |\n",
      "|    total_timesteps    | 484000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 96799       |\n",
      "|    policy_loss        | -0.558      |\n",
      "|    reward             | 0.014099389 |\n",
      "|    std                | 1.29e+07    |\n",
      "|    value_loss         | 0.000315    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 96900       |\n",
      "|    time_elapsed       | 1512        |\n",
      "|    total_timesteps    | 484500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.6       |\n",
      "|    explained_variance | -0.0655     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 96899       |\n",
      "|    policy_loss        | 1.29        |\n",
      "|    reward             | 0.022117725 |\n",
      "|    std                | 1.31e+07    |\n",
      "|    value_loss         | 0.00173     |\n",
      "---------------------------------------\n",
      "day: 2770, episode: 175\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 61812.55\n",
      "total_reward: 51812.55\n",
      "total_cost: 16.72\n",
      "total_trades: 5533\n",
      "Sharpe: 0.695\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 97000         |\n",
      "|    time_elapsed       | 1514          |\n",
      "|    total_timesteps    | 485000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -35.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 96999         |\n",
      "|    policy_loss        | 0.0938        |\n",
      "|    reward             | -0.0026903078 |\n",
      "|    std                | 1.35e+07      |\n",
      "|    value_loss         | 0.000104      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 97100        |\n",
      "|    time_elapsed       | 1515         |\n",
      "|    total_timesteps    | 485500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.7        |\n",
      "|    explained_variance | 0.126        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97099        |\n",
      "|    policy_loss        | 0.438        |\n",
      "|    reward             | -0.020577151 |\n",
      "|    std                | 1.37e+07     |\n",
      "|    value_loss         | 0.000552     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 97200        |\n",
      "|    time_elapsed       | 1517         |\n",
      "|    total_timesteps    | 486000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.7        |\n",
      "|    explained_variance | 0.355        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97199        |\n",
      "|    policy_loss        | 0.545        |\n",
      "|    reward             | -0.019532418 |\n",
      "|    std                | 1.41e+07     |\n",
      "|    value_loss         | 0.000365     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 97300        |\n",
      "|    time_elapsed       | 1519         |\n",
      "|    total_timesteps    | 486500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.7        |\n",
      "|    explained_variance | 0.103        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97299        |\n",
      "|    policy_loss        | -6.84        |\n",
      "|    reward             | -0.060884677 |\n",
      "|    std                | 1.43e+07     |\n",
      "|    value_loss         | 0.0386       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 97400         |\n",
      "|    time_elapsed       | 1520          |\n",
      "|    total_timesteps    | 487000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -35.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 97399         |\n",
      "|    policy_loss        | -3.76         |\n",
      "|    reward             | -0.0155000845 |\n",
      "|    std                | 1.47e+07      |\n",
      "|    value_loss         | 0.0171        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 97500       |\n",
      "|    time_elapsed       | 1522        |\n",
      "|    total_timesteps    | 487500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -35.8       |\n",
      "|    explained_variance | 0.0748      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97499       |\n",
      "|    policy_loss        | 3.23        |\n",
      "|    reward             | -0.14374544 |\n",
      "|    std                | 1.47e+07    |\n",
      "|    value_loss         | 0.0253      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 97600        |\n",
      "|    time_elapsed       | 1523         |\n",
      "|    total_timesteps    | 488000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.8        |\n",
      "|    explained_variance | 0.000205     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97599        |\n",
      "|    policy_loss        | -0.287       |\n",
      "|    reward             | -0.044011943 |\n",
      "|    std                | 1.49e+07     |\n",
      "|    value_loss         | 0.000245     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 97700        |\n",
      "|    time_elapsed       | 1525         |\n",
      "|    total_timesteps    | 488500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97699        |\n",
      "|    policy_loss        | -1.29        |\n",
      "|    reward             | -0.013786751 |\n",
      "|    std                | 1.51e+07     |\n",
      "|    value_loss         | 0.0013       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 97800        |\n",
      "|    time_elapsed       | 1527         |\n",
      "|    total_timesteps    | 489000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.9        |\n",
      "|    explained_variance | 0.228        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97799        |\n",
      "|    policy_loss        | -0.792       |\n",
      "|    reward             | -0.029370861 |\n",
      "|    std                | 1.54e+07     |\n",
      "|    value_loss         | 0.000716     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 97900        |\n",
      "|    time_elapsed       | 1528         |\n",
      "|    total_timesteps    | 489500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.9        |\n",
      "|    explained_variance | -0.0672      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97899        |\n",
      "|    policy_loss        | 4.09         |\n",
      "|    reward             | 9.373474e-05 |\n",
      "|    std                | 1.56e+07     |\n",
      "|    value_loss         | 0.0152       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 98000        |\n",
      "|    time_elapsed       | 1530         |\n",
      "|    total_timesteps    | 490000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97999        |\n",
      "|    policy_loss        | -5.46        |\n",
      "|    reward             | 0.0075588226 |\n",
      "|    std                | 1.57e+07     |\n",
      "|    value_loss         | 0.0426       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 98100        |\n",
      "|    time_elapsed       | 1531         |\n",
      "|    total_timesteps    | 490500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.9        |\n",
      "|    explained_variance | -3.31        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98099        |\n",
      "|    policy_loss        | -2.1         |\n",
      "|    reward             | 0.0014825215 |\n",
      "|    std                | 1.58e+07     |\n",
      "|    value_loss         | 0.00431      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 320            |\n",
      "|    iterations         | 98200          |\n",
      "|    time_elapsed       | 1533           |\n",
      "|    total_timesteps    | 491000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -36            |\n",
      "|    explained_variance | 0.156          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 98199          |\n",
      "|    policy_loss        | -1.46          |\n",
      "|    reward             | -0.00031410618 |\n",
      "|    std                | 1.6e+07        |\n",
      "|    value_loss         | 0.00176        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 98300        |\n",
      "|    time_elapsed       | 1535         |\n",
      "|    total_timesteps    | 491500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36          |\n",
      "|    explained_variance | 0.197        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98299        |\n",
      "|    policy_loss        | 1.12         |\n",
      "|    reward             | -0.010211024 |\n",
      "|    std                | 1.62e+07     |\n",
      "|    value_loss         | 0.00142      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 98400        |\n",
      "|    time_elapsed       | 1536         |\n",
      "|    total_timesteps    | 492000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98399        |\n",
      "|    policy_loss        | -0.204       |\n",
      "|    reward             | -0.028189601 |\n",
      "|    std                | 1.63e+07     |\n",
      "|    value_loss         | 0.00118      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 98500       |\n",
      "|    time_elapsed       | 1538        |\n",
      "|    total_timesteps    | 492500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.1       |\n",
      "|    explained_variance | 0.335       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 98499       |\n",
      "|    policy_loss        | -8.73       |\n",
      "|    reward             | -0.07541182 |\n",
      "|    std                | 1.67e+07    |\n",
      "|    value_loss         | 0.0694      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 98600      |\n",
      "|    time_elapsed       | 1539       |\n",
      "|    total_timesteps    | 493000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -36.1      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 98599      |\n",
      "|    policy_loss        | 5.08       |\n",
      "|    reward             | 0.14113447 |\n",
      "|    std                | 1.67e+07   |\n",
      "|    value_loss         | 0.0316     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 98700         |\n",
      "|    time_elapsed       | 1541          |\n",
      "|    total_timesteps    | 493500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -36.1         |\n",
      "|    explained_variance | 0.0673        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 98699         |\n",
      "|    policy_loss        | -0.236        |\n",
      "|    reward             | -0.0011194567 |\n",
      "|    std                | 1.67e+07      |\n",
      "|    value_loss         | 4.73e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 98800       |\n",
      "|    time_elapsed       | 1542        |\n",
      "|    total_timesteps    | 494000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.1       |\n",
      "|    explained_variance | 0.000693    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 98799       |\n",
      "|    policy_loss        | 0.728       |\n",
      "|    reward             | 0.006183595 |\n",
      "|    std                | 1.7e+07     |\n",
      "|    value_loss         | 0.000417    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 98900        |\n",
      "|    time_elapsed       | 1544         |\n",
      "|    total_timesteps    | 494500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.1        |\n",
      "|    explained_variance | 0.555        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98899        |\n",
      "|    policy_loss        | 0.211        |\n",
      "|    reward             | 0.0002275978 |\n",
      "|    std                | 1.74e+07     |\n",
      "|    value_loss         | 8.45e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 99000      |\n",
      "|    time_elapsed       | 1545       |\n",
      "|    total_timesteps    | 495000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -36.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 98999      |\n",
      "|    policy_loss        | -0.278     |\n",
      "|    reward             | -0.0063691 |\n",
      "|    std                | 1.79e+07   |\n",
      "|    value_loss         | 0.00016    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 99100      |\n",
      "|    time_elapsed       | 1547       |\n",
      "|    total_timesteps    | 495500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -36.3      |\n",
      "|    explained_variance | 0.7        |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 99099      |\n",
      "|    policy_loss        | 0.801      |\n",
      "|    reward             | 0.01624313 |\n",
      "|    std                | 1.85e+07   |\n",
      "|    value_loss         | 0.000679   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 99200        |\n",
      "|    time_elapsed       | 1548         |\n",
      "|    total_timesteps    | 496000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99199        |\n",
      "|    policy_loss        | 2.16         |\n",
      "|    reward             | -0.049857244 |\n",
      "|    std                | 1.89e+07     |\n",
      "|    value_loss         | 0.00528      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 99300       |\n",
      "|    time_elapsed       | 1550        |\n",
      "|    total_timesteps    | 496500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99299       |\n",
      "|    policy_loss        | -0.591      |\n",
      "|    reward             | 0.016219644 |\n",
      "|    std                | 1.95e+07    |\n",
      "|    value_loss         | 0.000371    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 320          |\n",
      "|    iterations         | 99400        |\n",
      "|    time_elapsed       | 1552         |\n",
      "|    total_timesteps    | 497000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -36.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99399        |\n",
      "|    policy_loss        | 0.896        |\n",
      "|    reward             | -0.013190479 |\n",
      "|    std                | 2e+07        |\n",
      "|    value_loss         | 0.000756     |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 320      |\n",
      "|    iterations         | 99500    |\n",
      "|    time_elapsed       | 1553     |\n",
      "|    total_timesteps    | 497500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 99499    |\n",
      "|    policy_loss        | 1.07     |\n",
      "|    reward             | 0.108088 |\n",
      "|    std                | 2.09e+07 |\n",
      "|    value_loss         | 0.00115  |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 99600       |\n",
      "|    time_elapsed       | 1555        |\n",
      "|    total_timesteps    | 498000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.5       |\n",
      "|    explained_variance | 0.612       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99599       |\n",
      "|    policy_loss        | -0.424      |\n",
      "|    reward             | -0.06997558 |\n",
      "|    std                | 2.14e+07    |\n",
      "|    value_loss         | 0.000469    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 99700       |\n",
      "|    time_elapsed       | 1557        |\n",
      "|    total_timesteps    | 498500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.6       |\n",
      "|    explained_variance | 0.0277      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99699       |\n",
      "|    policy_loss        | -3.84       |\n",
      "|    reward             | -0.13486843 |\n",
      "|    std                | 2.18e+07    |\n",
      "|    value_loss         | 0.0142      |\n",
      "---------------------------------------\n",
      "day: 2770, episode: 180\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 77151.09\n",
      "total_reward: 67151.09\n",
      "total_cost: 12.97\n",
      "total_trades: 5540\n",
      "Sharpe: 0.721\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 99800       |\n",
      "|    time_elapsed       | 1558        |\n",
      "|    total_timesteps    | 499000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.6       |\n",
      "|    explained_variance | -0.597      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99799       |\n",
      "|    policy_loss        | 0.48        |\n",
      "|    reward             | 0.009665308 |\n",
      "|    std                | 2.2e+07     |\n",
      "|    value_loss         | 0.000358    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 99900         |\n",
      "|    time_elapsed       | 1560          |\n",
      "|    total_timesteps    | 499500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -36.6         |\n",
      "|    explained_variance | 0.427         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 99899         |\n",
      "|    policy_loss        | -0.221        |\n",
      "|    reward             | 0.00022641105 |\n",
      "|    std                | 2.24e+07      |\n",
      "|    value_loss         | 8.16e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 100000      |\n",
      "|    time_elapsed       | 1561        |\n",
      "|    total_timesteps    | 500000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -36.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99999       |\n",
      "|    policy_loss        | 0.0404      |\n",
      "|    reward             | 0.021229774 |\n",
      "|    std                | 2.3e+07     |\n",
      "|    value_loss         | 0.000262    |\n",
      "---------------------------------------\n",
      "======A2C Validation from:  2021-04-06 to  2021-07-06\n",
      "A2C Sharpe Ratio:  0.2793703757949606\n",
      "======Best Model Retraining from:  2010-04-01 to  2021-07-06\n",
      "======Trading from:  2021-07-06 to  2021-10-04\n",
      "[[245.18636   147.84787   452.3036     54.          6.          3.1223803\n",
      "    3.5672264 150.08386   456.6594    138.79758   436.6088     66.72011\n",
      "   53.663357   95.907776   88.577835   37.719433   16.09081   141.26389\n",
      "  445.20514   136.4055    438.4411   ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "turbulence_threshold:  18.96231252984678\n",
      "======Model training from:  2010-04-01 to  2021-07-06\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.001}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c\\a2c_252_1\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.95       |\n",
      "|    explained_variance | 0.134       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -0.0459     |\n",
      "|    reward             | 0.023846036 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 0.00065     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 317          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 3            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -2.98        |\n",
      "|    explained_variance | -1.48        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -0.00165     |\n",
      "|    reward             | -0.026489466 |\n",
      "|    std                | 1.07         |\n",
      "|    value_loss         | 0.00237      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.02       |\n",
      "|    explained_variance | 0.124       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | 0.00548     |\n",
      "|    reward             | 0.032218903 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.00129     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.03       |\n",
      "|    explained_variance | 0.361       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | 0.0175      |\n",
      "|    reward             | -0.01305681 |\n",
      "|    std                | 1.1         |\n",
      "|    value_loss         | 0.00123     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 324        |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.06      |\n",
      "|    explained_variance | -2.6       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | 1.3        |\n",
      "|    reward             | -0.4714802 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 0.334      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 9            |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.05        |\n",
      "|    explained_variance | -5.97        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | 0.0696       |\n",
      "|    reward             | 0.0019272927 |\n",
      "|    std                | 1.11         |\n",
      "|    value_loss         | 0.00319      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 327           |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 10            |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.1          |\n",
      "|    explained_variance | -0.995        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 699           |\n",
      "|    policy_loss        | -0.0992       |\n",
      "|    reward             | -0.0112063475 |\n",
      "|    std                | 1.14          |\n",
      "|    value_loss         | 0.000966      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 329          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 12           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.13        |\n",
      "|    explained_variance | -3.81e-06    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | 0.0632       |\n",
      "|    reward             | -0.013268916 |\n",
      "|    std                | 1.16         |\n",
      "|    value_loss         | 0.000926     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 329         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 13          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.18       |\n",
      "|    explained_variance | -15.3       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | -0.23       |\n",
      "|    reward             | 0.026358427 |\n",
      "|    std                | 1.19        |\n",
      "|    value_loss         | 0.00503     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 330         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 15          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.2        |\n",
      "|    explained_variance | 0.0164      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | 0.137       |\n",
      "|    reward             | 0.025041012 |\n",
      "|    std                | 1.2         |\n",
      "|    value_loss         | 0.00295     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 330        |\n",
      "|    iterations         | 1100       |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 5500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.23      |\n",
      "|    explained_variance | 0.00453    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 1099       |\n",
      "|    policy_loss        | -0.387     |\n",
      "|    reward             | 0.12620877 |\n",
      "|    std                | 1.22       |\n",
      "|    value_loss         | 0.0121     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 328          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.25        |\n",
      "|    explained_variance | -9.88        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | 0.169        |\n",
      "|    reward             | -0.010397742 |\n",
      "|    std                | 1.23         |\n",
      "|    value_loss         | 0.00351      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 329           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 19            |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.3          |\n",
      "|    explained_variance | -0.899        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | 0.000951      |\n",
      "|    reward             | -0.0035191325 |\n",
      "|    std                | 1.26          |\n",
      "|    value_loss         | 2.52e-05      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 331          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.35        |\n",
      "|    explained_variance | 0.357        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | -0.147       |\n",
      "|    reward             | -0.009247459 |\n",
      "|    std                | 1.29         |\n",
      "|    value_loss         | 0.00261      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 22          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.41       |\n",
      "|    explained_variance | 0.593       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | 0.0341      |\n",
      "|    reward             | 0.036612444 |\n",
      "|    std                | 1.33        |\n",
      "|    value_loss         | 0.000239    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 24            |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.45         |\n",
      "|    explained_variance | 0.0537        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | 0.32          |\n",
      "|    reward             | -0.0019851243 |\n",
      "|    std                | 1.36          |\n",
      "|    value_loss         | 0.0122        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.48       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | 0.0849      |\n",
      "|    reward             | -0.03878273 |\n",
      "|    std                | 1.38        |\n",
      "|    value_loss         | 0.000811    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.53        |\n",
      "|    explained_variance | -7.76        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | 0.0646       |\n",
      "|    reward             | -0.007991468 |\n",
      "|    std                | 1.41         |\n",
      "|    value_loss         | 0.000404     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 334          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.56        |\n",
      "|    explained_variance | -0.636       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.0844      |\n",
      "|    reward             | 0.0064918203 |\n",
      "|    std                | 1.43         |\n",
      "|    value_loss         | 0.000819     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 334           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 29            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.61         |\n",
      "|    explained_variance | -0.0932       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | -0.0689       |\n",
      "|    reward             | -0.0032955094 |\n",
      "|    std                | 1.47          |\n",
      "|    value_loss         | 0.00107       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 334         |\n",
      "|    iterations         | 2100        |\n",
      "|    time_elapsed       | 31          |\n",
      "|    total_timesteps    | 10500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.67       |\n",
      "|    explained_variance | 0.329       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2099        |\n",
      "|    policy_loss        | -0.0156     |\n",
      "|    reward             | 0.059182633 |\n",
      "|    std                | 1.52        |\n",
      "|    value_loss         | 0.0011      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 2200        |\n",
      "|    time_elapsed       | 33          |\n",
      "|    total_timesteps    | 11000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.72       |\n",
      "|    explained_variance | 0.131       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2199        |\n",
      "|    policy_loss        | -0.727      |\n",
      "|    reward             | -0.12025082 |\n",
      "|    std                | 1.55        |\n",
      "|    value_loss         | 0.0421      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 2300         |\n",
      "|    time_elapsed       | 34           |\n",
      "|    total_timesteps    | 11500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.76        |\n",
      "|    explained_variance | -0.12        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2299         |\n",
      "|    policy_loss        | -0.0345      |\n",
      "|    reward             | -0.011133567 |\n",
      "|    std                | 1.59         |\n",
      "|    value_loss         | 0.000151     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 332         |\n",
      "|    iterations         | 2400        |\n",
      "|    time_elapsed       | 36          |\n",
      "|    total_timesteps    | 12000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.81       |\n",
      "|    explained_variance | 0.604       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2399        |\n",
      "|    policy_loss        | -0.00417    |\n",
      "|    reward             | 0.027611578 |\n",
      "|    std                | 1.62        |\n",
      "|    value_loss         | 5.2e-05     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 2500         |\n",
      "|    time_elapsed       | 37           |\n",
      "|    total_timesteps    | 12500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.87        |\n",
      "|    explained_variance | 0.00619      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2499         |\n",
      "|    policy_loss        | 0.146        |\n",
      "|    reward             | 0.0028654807 |\n",
      "|    std                | 1.67         |\n",
      "|    value_loss         | 0.00171      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 332           |\n",
      "|    iterations         | 2600          |\n",
      "|    time_elapsed       | 39            |\n",
      "|    total_timesteps    | 13000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.88         |\n",
      "|    explained_variance | 0.237         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 2599          |\n",
      "|    policy_loss        | -0.0103       |\n",
      "|    reward             | -0.0014038421 |\n",
      "|    std                | 1.68          |\n",
      "|    value_loss         | 0.000137      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 2700         |\n",
      "|    time_elapsed       | 40           |\n",
      "|    total_timesteps    | 13500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.9         |\n",
      "|    explained_variance | -0.000638    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2699         |\n",
      "|    policy_loss        | -0.353       |\n",
      "|    reward             | -0.057438497 |\n",
      "|    std                | 1.71         |\n",
      "|    value_loss         | 0.014        |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 332       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 42        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.92     |\n",
      "|    explained_variance | 4.35e-06  |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | -0.183    |\n",
      "|    reward             | 0.0732628 |\n",
      "|    std                | 1.72      |\n",
      "|    value_loss         | 0.00408   |\n",
      "-------------------------------------\n",
      "day: 2833, episode: 5\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 69977.37\n",
      "total_reward: 59977.37\n",
      "total_cost: 10.34\n",
      "total_trades: 5637\n",
      "Sharpe: 0.721\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 332          |\n",
      "|    iterations         | 2900         |\n",
      "|    time_elapsed       | 43           |\n",
      "|    total_timesteps    | 14500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.94        |\n",
      "|    explained_variance | -0.904       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2899         |\n",
      "|    policy_loss        | -0.096       |\n",
      "|    reward             | 0.0075787534 |\n",
      "|    std                | 1.74         |\n",
      "|    value_loss         | 0.00201      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 328         |\n",
      "|    iterations         | 3000        |\n",
      "|    time_elapsed       | 45          |\n",
      "|    total_timesteps    | 15000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.96       |\n",
      "|    explained_variance | -1.51       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2999        |\n",
      "|    policy_loss        | 0.0542      |\n",
      "|    reward             | 0.006783961 |\n",
      "|    std                | 1.76        |\n",
      "|    value_loss         | 0.000671    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 327          |\n",
      "|    iterations         | 3100         |\n",
      "|    time_elapsed       | 47           |\n",
      "|    total_timesteps    | 15500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4           |\n",
      "|    explained_variance | 0.538        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 3099         |\n",
      "|    policy_loss        | -0.386       |\n",
      "|    reward             | -0.015964977 |\n",
      "|    std                | 1.79         |\n",
      "|    value_loss         | 0.0114       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 326         |\n",
      "|    iterations         | 3200        |\n",
      "|    time_elapsed       | 48          |\n",
      "|    total_timesteps    | 16000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.04       |\n",
      "|    explained_variance | 0.366       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3199        |\n",
      "|    policy_loss        | -0.447      |\n",
      "|    reward             | 0.058742866 |\n",
      "|    std                | 1.82        |\n",
      "|    value_loss         | 0.0264      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 325         |\n",
      "|    iterations         | 3300        |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 16500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.05       |\n",
      "|    explained_variance | 0.308       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3299        |\n",
      "|    policy_loss        | 0.699       |\n",
      "|    reward             | -0.06730578 |\n",
      "|    std                | 1.83        |\n",
      "|    value_loss         | 0.0343      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 325       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 52        |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.08     |\n",
      "|    explained_variance | 0.0944    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -0.174    |\n",
      "|    reward             | 0.1394348 |\n",
      "|    std                | 1.86      |\n",
      "|    value_loss         | 0.0118    |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 325           |\n",
      "|    iterations         | 3500          |\n",
      "|    time_elapsed       | 53            |\n",
      "|    total_timesteps    | 17500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.09         |\n",
      "|    explained_variance | 0.314         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 3499          |\n",
      "|    policy_loss        | 0.0321        |\n",
      "|    reward             | -0.0077476897 |\n",
      "|    std                | 1.87          |\n",
      "|    value_loss         | 0.000102      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 55          |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.12       |\n",
      "|    explained_variance | 0.473       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3599        |\n",
      "|    policy_loss        | -0.0295     |\n",
      "|    reward             | 0.015548645 |\n",
      "|    std                | 1.91        |\n",
      "|    value_loss         | 7.08e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 3700        |\n",
      "|    time_elapsed       | 57          |\n",
      "|    total_timesteps    | 18500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.19       |\n",
      "|    explained_variance | -0.155      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3699        |\n",
      "|    policy_loss        | 0.139       |\n",
      "|    reward             | 0.032100283 |\n",
      "|    std                | 1.97        |\n",
      "|    value_loss         | 0.0014      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 3800        |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 19000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.24       |\n",
      "|    explained_variance | 0.269       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3799        |\n",
      "|    policy_loss        | -0.178      |\n",
      "|    reward             | 0.029169604 |\n",
      "|    std                | 2.02        |\n",
      "|    value_loss         | 0.00205     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 3900         |\n",
      "|    time_elapsed       | 60           |\n",
      "|    total_timesteps    | 19500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.29        |\n",
      "|    explained_variance | 0.465        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 3899         |\n",
      "|    policy_loss        | -0.525       |\n",
      "|    reward             | -0.051714357 |\n",
      "|    std                | 2.08         |\n",
      "|    value_loss         | 0.0206       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 4000        |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 20000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.32       |\n",
      "|    explained_variance | -0.759      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3999        |\n",
      "|    policy_loss        | -0.00142    |\n",
      "|    reward             | 0.004585551 |\n",
      "|    std                | 2.1         |\n",
      "|    value_loss         | 0.000179    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 4100         |\n",
      "|    time_elapsed       | 63           |\n",
      "|    total_timesteps    | 20500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.35        |\n",
      "|    explained_variance | -0.562       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4099         |\n",
      "|    policy_loss        | -0.0668      |\n",
      "|    reward             | -0.012952967 |\n",
      "|    std                | 2.14         |\n",
      "|    value_loss         | 0.000415     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 4200        |\n",
      "|    time_elapsed       | 64          |\n",
      "|    total_timesteps    | 21000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.42       |\n",
      "|    explained_variance | 0.117       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 4199        |\n",
      "|    policy_loss        | 0.0172      |\n",
      "|    reward             | 0.004887819 |\n",
      "|    std                | 2.2         |\n",
      "|    value_loss         | 0.000564    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 323            |\n",
      "|    iterations         | 4300           |\n",
      "|    time_elapsed       | 66             |\n",
      "|    total_timesteps    | 21500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -4.42          |\n",
      "|    explained_variance | -1.36          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 4299           |\n",
      "|    policy_loss        | -0.281         |\n",
      "|    reward             | -5.5950164e-05 |\n",
      "|    std                | 2.2            |\n",
      "|    value_loss         | 0.00663        |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 323        |\n",
      "|    iterations         | 4400       |\n",
      "|    time_elapsed       | 68         |\n",
      "|    total_timesteps    | 22000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.44      |\n",
      "|    explained_variance | -0.052     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 4399       |\n",
      "|    policy_loss        | -1.05      |\n",
      "|    reward             | 0.04975325 |\n",
      "|    std                | 2.23       |\n",
      "|    value_loss         | 0.0597     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 4500         |\n",
      "|    time_elapsed       | 69           |\n",
      "|    total_timesteps    | 22500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.44        |\n",
      "|    explained_variance | 0.115        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4499         |\n",
      "|    policy_loss        | -0.212       |\n",
      "|    reward             | -0.026451107 |\n",
      "|    std                | 2.23         |\n",
      "|    value_loss         | 0.00404      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 4600          |\n",
      "|    time_elapsed       | 71            |\n",
      "|    total_timesteps    | 23000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.47         |\n",
      "|    explained_variance | 0.809         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 4599          |\n",
      "|    policy_loss        | -0.165        |\n",
      "|    reward             | -0.0026558295 |\n",
      "|    std                | 2.26          |\n",
      "|    value_loss         | 0.00127       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 323            |\n",
      "|    iterations         | 4700           |\n",
      "|    time_elapsed       | 72             |\n",
      "|    total_timesteps    | 23500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -4.5           |\n",
      "|    explained_variance | 0.19           |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 4699           |\n",
      "|    policy_loss        | -0.0699        |\n",
      "|    reward             | -1.7812728e-05 |\n",
      "|    std                | 2.29           |\n",
      "|    value_loss         | 0.000422       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 4800         |\n",
      "|    time_elapsed       | 74           |\n",
      "|    total_timesteps    | 24000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.53        |\n",
      "|    explained_variance | -0.586       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4799         |\n",
      "|    policy_loss        | -0.0419      |\n",
      "|    reward             | -0.011264924 |\n",
      "|    std                | 2.34         |\n",
      "|    value_loss         | 0.00274      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 324        |\n",
      "|    iterations         | 4900       |\n",
      "|    time_elapsed       | 75         |\n",
      "|    total_timesteps    | 24500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.56      |\n",
      "|    explained_variance | 0.392      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 4899       |\n",
      "|    policy_loss        | -0.112     |\n",
      "|    reward             | 0.07247808 |\n",
      "|    std                | 2.37       |\n",
      "|    value_loss         | 0.00614    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 325         |\n",
      "|    iterations         | 5000        |\n",
      "|    time_elapsed       | 76          |\n",
      "|    total_timesteps    | 25000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.56       |\n",
      "|    explained_variance | -0.0116     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 4999        |\n",
      "|    policy_loss        | -0.0827     |\n",
      "|    reward             | -0.11962825 |\n",
      "|    std                | 2.37        |\n",
      "|    value_loss         | 0.00166     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 325         |\n",
      "|    iterations         | 5100        |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 25500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.57       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5099        |\n",
      "|    policy_loss        | -1.1        |\n",
      "|    reward             | -0.19810666 |\n",
      "|    std                | 2.37        |\n",
      "|    value_loss         | 0.0558      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 324           |\n",
      "|    iterations         | 5200          |\n",
      "|    time_elapsed       | 80            |\n",
      "|    total_timesteps    | 26000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.59         |\n",
      "|    explained_variance | -0.735        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 5199          |\n",
      "|    policy_loss        | 0.191         |\n",
      "|    reward             | -0.0012830102 |\n",
      "|    std                | 2.4           |\n",
      "|    value_loss         | 0.00287       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 324          |\n",
      "|    iterations         | 5300         |\n",
      "|    time_elapsed       | 81           |\n",
      "|    total_timesteps    | 26500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.61        |\n",
      "|    explained_variance | 0.23         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5299         |\n",
      "|    policy_loss        | -0.0576      |\n",
      "|    reward             | -0.008043954 |\n",
      "|    std                | 2.42         |\n",
      "|    value_loss         | 0.000622     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 324         |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.65       |\n",
      "|    explained_variance | -0.0871     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | 0.481       |\n",
      "|    reward             | 0.060174234 |\n",
      "|    std                | 2.47        |\n",
      "|    value_loss         | 0.0183      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 5500        |\n",
      "|    time_elapsed       | 84          |\n",
      "|    total_timesteps    | 27500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.69       |\n",
      "|    explained_variance | -0.0581     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5499        |\n",
      "|    policy_loss        | 0.155       |\n",
      "|    reward             | -0.10092598 |\n",
      "|    std                | 2.52        |\n",
      "|    value_loss         | 0.00284     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 323         |\n",
      "|    iterations         | 5600        |\n",
      "|    time_elapsed       | 86          |\n",
      "|    total_timesteps    | 28000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.71       |\n",
      "|    explained_variance | 0.665       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5599        |\n",
      "|    policy_loss        | -1.25       |\n",
      "|    reward             | -0.04839713 |\n",
      "|    std                | 2.55        |\n",
      "|    value_loss         | 0.0846      |\n",
      "---------------------------------------\n",
      "day: 2833, episode: 10\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 185570.14\n",
      "total_reward: 175570.14\n",
      "total_cost: 206.79\n",
      "total_trades: 5581\n",
      "Sharpe: 1.020\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 322           |\n",
      "|    iterations         | 5700          |\n",
      "|    time_elapsed       | 88            |\n",
      "|    total_timesteps    | 28500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.7          |\n",
      "|    explained_variance | -1.32         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 5699          |\n",
      "|    policy_loss        | -0.211        |\n",
      "|    reward             | -0.0033493198 |\n",
      "|    std                | 2.53          |\n",
      "|    value_loss         | 0.00216       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 5800         |\n",
      "|    time_elapsed       | 89           |\n",
      "|    total_timesteps    | 29000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.71        |\n",
      "|    explained_variance | 0.134        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5799         |\n",
      "|    policy_loss        | 0.121        |\n",
      "|    reward             | -0.007841798 |\n",
      "|    std                | 2.55         |\n",
      "|    value_loss         | 0.000615     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 323          |\n",
      "|    iterations         | 5900         |\n",
      "|    time_elapsed       | 91           |\n",
      "|    total_timesteps    | 29500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.74        |\n",
      "|    explained_variance | 0.311        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5899         |\n",
      "|    policy_loss        | 0.408        |\n",
      "|    reward             | -0.043901056 |\n",
      "|    std                | 2.59         |\n",
      "|    value_loss         | 0.00934      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 6000        |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 30000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.76       |\n",
      "|    explained_variance | 0.429       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5999        |\n",
      "|    policy_loss        | -0.182      |\n",
      "|    reward             | 0.057793383 |\n",
      "|    std                | 2.62        |\n",
      "|    value_loss         | 0.00176     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 322         |\n",
      "|    iterations         | 6100        |\n",
      "|    time_elapsed       | 94          |\n",
      "|    total_timesteps    | 30500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.77       |\n",
      "|    explained_variance | 0.815       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 6099        |\n",
      "|    policy_loss        | -0.579      |\n",
      "|    reward             | -0.03361523 |\n",
      "|    std                | 2.62        |\n",
      "|    value_loss         | 0.0143      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 6200         |\n",
      "|    time_elapsed       | 96           |\n",
      "|    total_timesteps    | 31000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.8         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6199         |\n",
      "|    policy_loss        | -0.186       |\n",
      "|    reward             | -0.017341211 |\n",
      "|    std                | 2.67         |\n",
      "|    value_loss         | 0.00266      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 6300         |\n",
      "|    time_elapsed       | 97           |\n",
      "|    total_timesteps    | 31500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.83        |\n",
      "|    explained_variance | -0.14        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6299         |\n",
      "|    policy_loss        | -0.406       |\n",
      "|    reward             | -0.039513975 |\n",
      "|    std                | 2.72         |\n",
      "|    value_loss         | 0.00818      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 6400         |\n",
      "|    time_elapsed       | 99           |\n",
      "|    total_timesteps    | 32000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.87        |\n",
      "|    explained_variance | 0.182        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6399         |\n",
      "|    policy_loss        | 0.00857      |\n",
      "|    reward             | -0.005803456 |\n",
      "|    std                | 2.77         |\n",
      "|    value_loss         | 0.000178     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 6500         |\n",
      "|    time_elapsed       | 100          |\n",
      "|    total_timesteps    | 32500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.87        |\n",
      "|    explained_variance | 0.416        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6499         |\n",
      "|    policy_loss        | -0.0773      |\n",
      "|    reward             | -0.043781932 |\n",
      "|    std                | 2.76         |\n",
      "|    value_loss         | 0.00299      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 322          |\n",
      "|    iterations         | 6600         |\n",
      "|    time_elapsed       | 102          |\n",
      "|    total_timesteps    | 33000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.86        |\n",
      "|    explained_variance | 4.53e-06     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6599         |\n",
      "|    policy_loss        | -0.295       |\n",
      "|    reward             | -0.054393925 |\n",
      "|    std                | 2.75         |\n",
      "|    value_loss         | 0.00401      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 6700        |\n",
      "|    time_elapsed       | 104         |\n",
      "|    total_timesteps    | 33500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.88       |\n",
      "|    explained_variance | 0.802       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 6699        |\n",
      "|    policy_loss        | 0.133       |\n",
      "|    reward             | 0.079285964 |\n",
      "|    std                | 2.79        |\n",
      "|    value_loss         | 0.0037      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 6800        |\n",
      "|    time_elapsed       | 105         |\n",
      "|    total_timesteps    | 34000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.92       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 6799        |\n",
      "|    policy_loss        | -0.192      |\n",
      "|    reward             | 0.057178985 |\n",
      "|    std                | 2.84        |\n",
      "|    value_loss         | 0.0117      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 321           |\n",
      "|    iterations         | 6900          |\n",
      "|    time_elapsed       | 107           |\n",
      "|    total_timesteps    | 34500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.95         |\n",
      "|    explained_variance | 0.764         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 6899          |\n",
      "|    policy_loss        | -0.0427       |\n",
      "|    reward             | -0.0063451724 |\n",
      "|    std                | 2.87          |\n",
      "|    value_loss         | 0.000153      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 7000        |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 35000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.98       |\n",
      "|    explained_variance | -0.357      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 6999        |\n",
      "|    policy_loss        | 0.0866      |\n",
      "|    reward             | 0.013574473 |\n",
      "|    std                | 2.92        |\n",
      "|    value_loss         | 0.000337    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 321          |\n",
      "|    iterations         | 7100         |\n",
      "|    time_elapsed       | 110          |\n",
      "|    total_timesteps    | 35500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5           |\n",
      "|    explained_variance | 0.208        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 7099         |\n",
      "|    policy_loss        | -0.0309      |\n",
      "|    reward             | -0.025058968 |\n",
      "|    std                | 2.95         |\n",
      "|    value_loss         | 0.00029      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 321         |\n",
      "|    iterations         | 7200        |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 36000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.02       |\n",
      "|    explained_variance | 0.553       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7199        |\n",
      "|    policy_loss        | -0.124      |\n",
      "|    reward             | -0.05067078 |\n",
      "|    std                | 2.98        |\n",
      "|    value_loss         | 0.000884    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 7300       |\n",
      "|    time_elapsed       | 113        |\n",
      "|    total_timesteps    | 36500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.04      |\n",
      "|    explained_variance | 0.365      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 7299       |\n",
      "|    policy_loss        | -0.103     |\n",
      "|    reward             | 0.03943646 |\n",
      "|    std                | 3.01       |\n",
      "|    value_loss         | 0.00331    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 7400        |\n",
      "|    time_elapsed       | 115         |\n",
      "|    total_timesteps    | 37000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.05       |\n",
      "|    explained_variance | 0.817       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7399        |\n",
      "|    policy_loss        | -0.00141    |\n",
      "|    reward             | -0.00869812 |\n",
      "|    std                | 3.02        |\n",
      "|    value_loss         | 1.97e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 320           |\n",
      "|    iterations         | 7500          |\n",
      "|    time_elapsed       | 116           |\n",
      "|    total_timesteps    | 37500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.08         |\n",
      "|    explained_variance | 0.311         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 7499          |\n",
      "|    policy_loss        | 0.00739       |\n",
      "|    reward             | -0.0046074884 |\n",
      "|    std                | 3.07          |\n",
      "|    value_loss         | 0.000123      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 7600        |\n",
      "|    time_elapsed       | 118         |\n",
      "|    total_timesteps    | 38000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.12       |\n",
      "|    explained_variance | -0.0646     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7599        |\n",
      "|    policy_loss        | 0.201       |\n",
      "|    reward             | 0.018373298 |\n",
      "|    std                | 3.14        |\n",
      "|    value_loss         | 0.0018      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 320         |\n",
      "|    iterations         | 7700        |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 38500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.19       |\n",
      "|    explained_variance | 0.419       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7699        |\n",
      "|    policy_loss        | 0.279       |\n",
      "|    reward             | 0.018073188 |\n",
      "|    std                | 3.25        |\n",
      "|    value_loss         | 0.00254     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 320        |\n",
      "|    iterations         | 7800       |\n",
      "|    time_elapsed       | 121        |\n",
      "|    total_timesteps    | 39000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.22      |\n",
      "|    explained_variance | -0.231     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 7799       |\n",
      "|    policy_loss        | -0.482     |\n",
      "|    reward             | 0.07415618 |\n",
      "|    std                | 3.29       |\n",
      "|    value_loss         | 0.0144     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 319         |\n",
      "|    iterations         | 7900        |\n",
      "|    time_elapsed       | 123         |\n",
      "|    total_timesteps    | 39500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.21       |\n",
      "|    explained_variance | 0.0924      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7899        |\n",
      "|    policy_loss        | 0.219       |\n",
      "|    reward             | -0.09320788 |\n",
      "|    std                | 3.28        |\n",
      "|    value_loss         | 0.0105      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 319          |\n",
      "|    iterations         | 8000         |\n",
      "|    time_elapsed       | 125          |\n",
      "|    total_timesteps    | 40000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.24        |\n",
      "|    explained_variance | 0.000923     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 7999         |\n",
      "|    policy_loss        | 0.0236       |\n",
      "|    reward             | -0.008607447 |\n",
      "|    std                | 3.32         |\n",
      "|    value_loss         | 0.000129     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 8100        |\n",
      "|    time_elapsed       | 127         |\n",
      "|    total_timesteps    | 40500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.27       |\n",
      "|    explained_variance | 0.542       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 8099        |\n",
      "|    policy_loss        | 0.0849      |\n",
      "|    reward             | 0.007432178 |\n",
      "|    std                | 3.38        |\n",
      "|    value_loss         | 0.000188    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 8200         |\n",
      "|    time_elapsed       | 129          |\n",
      "|    total_timesteps    | 41000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.29        |\n",
      "|    explained_variance | 0.0605       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 8199         |\n",
      "|    policy_loss        | -0.756       |\n",
      "|    reward             | -0.022419974 |\n",
      "|    std                | 3.41         |\n",
      "|    value_loss         | 0.0258       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 317         |\n",
      "|    iterations         | 8300        |\n",
      "|    time_elapsed       | 130         |\n",
      "|    total_timesteps    | 41500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.32       |\n",
      "|    explained_variance | 0.313       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 8299        |\n",
      "|    policy_loss        | 0.309       |\n",
      "|    reward             | -0.14376636 |\n",
      "|    std                | 3.46        |\n",
      "|    value_loss         | 0.00531     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 317        |\n",
      "|    iterations         | 8400       |\n",
      "|    time_elapsed       | 132        |\n",
      "|    total_timesteps    | 42000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.32      |\n",
      "|    explained_variance | 0.352      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 8399       |\n",
      "|    policy_loss        | -0.145     |\n",
      "|    reward             | 0.10231188 |\n",
      "|    std                | 3.46       |\n",
      "|    value_loss         | 0.0161     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 317        |\n",
      "|    iterations         | 8500       |\n",
      "|    time_elapsed       | 133        |\n",
      "|    total_timesteps    | 42500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.31      |\n",
      "|    explained_variance | -0.142     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 8499       |\n",
      "|    policy_loss        | 0.978      |\n",
      "|    reward             | 0.12255895 |\n",
      "|    std                | 3.45       |\n",
      "|    value_loss         | 0.043      |\n",
      "--------------------------------------\n",
      "day: 2833, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 122780.37\n",
      "total_reward: 112780.37\n",
      "total_cost: 19.16\n",
      "total_trades: 5658\n",
      "Sharpe: 0.825\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 317          |\n",
      "|    iterations         | 8600         |\n",
      "|    time_elapsed       | 135          |\n",
      "|    total_timesteps    | 43000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.33        |\n",
      "|    explained_variance | -0.955       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 8599         |\n",
      "|    policy_loss        | -0.156       |\n",
      "|    reward             | -0.009592034 |\n",
      "|    std                | 3.48         |\n",
      "|    value_loss         | 0.000969     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 316           |\n",
      "|    iterations         | 8700          |\n",
      "|    time_elapsed       | 137           |\n",
      "|    total_timesteps    | 43500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.35         |\n",
      "|    explained_variance | 0.636         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 8699          |\n",
      "|    policy_loss        | 0.213         |\n",
      "|    reward             | -0.0011040085 |\n",
      "|    std                | 3.52          |\n",
      "|    value_loss         | 0.00166       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.37       |\n",
      "|    explained_variance | -0.00659    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 8799        |\n",
      "|    policy_loss        | 0.373       |\n",
      "|    reward             | 0.008212648 |\n",
      "|    std                | 3.55        |\n",
      "|    value_loss         | 0.00614     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 317          |\n",
      "|    iterations         | 8900         |\n",
      "|    time_elapsed       | 140          |\n",
      "|    total_timesteps    | 44500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.41        |\n",
      "|    explained_variance | 0.676        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 8899         |\n",
      "|    policy_loss        | -0.0996      |\n",
      "|    reward             | -0.038331613 |\n",
      "|    std                | 3.61         |\n",
      "|    value_loss         | 0.00147      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 317        |\n",
      "|    iterations         | 9000       |\n",
      "|    time_elapsed       | 141        |\n",
      "|    total_timesteps    | 45000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.44      |\n",
      "|    explained_variance | 0.265      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 8999       |\n",
      "|    policy_loss        | -0.362     |\n",
      "|    reward             | -0.3132841 |\n",
      "|    std                | 3.67       |\n",
      "|    value_loss         | 0.01       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 9100         |\n",
      "|    time_elapsed       | 143          |\n",
      "|    total_timesteps    | 45500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.45        |\n",
      "|    explained_variance | -76.5        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 9099         |\n",
      "|    policy_loss        | -0.126       |\n",
      "|    reward             | 0.0041571287 |\n",
      "|    std                | 3.69         |\n",
      "|    value_loss         | 0.00482      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 9200         |\n",
      "|    time_elapsed       | 145          |\n",
      "|    total_timesteps    | 46000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.48        |\n",
      "|    explained_variance | -0.144       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 9199         |\n",
      "|    policy_loss        | 0.0302       |\n",
      "|    reward             | -0.024009136 |\n",
      "|    std                | 3.74         |\n",
      "|    value_loss         | 7.72e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 9300        |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 46500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.51       |\n",
      "|    explained_variance | 0.28        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9299        |\n",
      "|    policy_loss        | 0.0421      |\n",
      "|    reward             | 0.001230423 |\n",
      "|    std                | 3.81        |\n",
      "|    value_loss         | 0.00066     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 9400         |\n",
      "|    time_elapsed       | 148          |\n",
      "|    total_timesteps    | 47000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.52        |\n",
      "|    explained_variance | -0.219       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 9399         |\n",
      "|    policy_loss        | 0.291        |\n",
      "|    reward             | -0.014849648 |\n",
      "|    std                | 3.83         |\n",
      "|    value_loss         | 0.00325      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 317         |\n",
      "|    iterations         | 9500        |\n",
      "|    time_elapsed       | 149         |\n",
      "|    total_timesteps    | 47500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.55       |\n",
      "|    explained_variance | 0.474       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9499        |\n",
      "|    policy_loss        | 0.261       |\n",
      "|    reward             | 0.009525201 |\n",
      "|    std                | 3.89        |\n",
      "|    value_loss         | 0.0093      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 317         |\n",
      "|    iterations         | 9600        |\n",
      "|    time_elapsed       | 151         |\n",
      "|    total_timesteps    | 48000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.6        |\n",
      "|    explained_variance | 1.07e-06    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9599        |\n",
      "|    policy_loss        | 1.43        |\n",
      "|    reward             | -0.06454529 |\n",
      "|    std                | 3.97        |\n",
      "|    value_loss         | 0.0795      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 317          |\n",
      "|    iterations         | 9700         |\n",
      "|    time_elapsed       | 152          |\n",
      "|    total_timesteps    | 48500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.62        |\n",
      "|    explained_variance | -0.243       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 9699         |\n",
      "|    policy_loss        | 0.193        |\n",
      "|    reward             | -0.050138097 |\n",
      "|    std                | 4.02         |\n",
      "|    value_loss         | 0.00187      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 317         |\n",
      "|    iterations         | 9800        |\n",
      "|    time_elapsed       | 154         |\n",
      "|    total_timesteps    | 49000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.66       |\n",
      "|    explained_variance | -1.06e-05   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9799        |\n",
      "|    policy_loss        | 0.0595      |\n",
      "|    reward             | 0.008135927 |\n",
      "|    std                | 4.09        |\n",
      "|    value_loss         | 0.000151    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 317         |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 156         |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.68       |\n",
      "|    explained_variance | 0.0012      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9899        |\n",
      "|    policy_loss        | -0.447      |\n",
      "|    reward             | 0.057985764 |\n",
      "|    std                | 4.14        |\n",
      "|    value_loss         | 0.00882     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 317        |\n",
      "|    iterations         | 10000      |\n",
      "|    time_elapsed       | 157        |\n",
      "|    total_timesteps    | 50000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.69      |\n",
      "|    explained_variance | 0.0142     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 9999       |\n",
      "|    policy_loss        | -0.0436    |\n",
      "|    reward             | -0.2072037 |\n",
      "|    std                | 4.17       |\n",
      "|    value_loss         | 0.00401    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 316       |\n",
      "|    iterations         | 10100     |\n",
      "|    time_elapsed       | 159       |\n",
      "|    total_timesteps    | 50500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.71     |\n",
      "|    explained_variance | 0.166     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 10099     |\n",
      "|    policy_loss        | -2.18     |\n",
      "|    reward             | 0.1568139 |\n",
      "|    std                | 4.21      |\n",
      "|    value_loss         | 0.152     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 10200      |\n",
      "|    time_elapsed       | 160        |\n",
      "|    total_timesteps    | 51000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.73      |\n",
      "|    explained_variance | 0.223      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 10199      |\n",
      "|    policy_loss        | 0.313      |\n",
      "|    reward             | 0.17525889 |\n",
      "|    std                | 4.24       |\n",
      "|    value_loss         | 0.0226     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 10300       |\n",
      "|    time_elapsed       | 162         |\n",
      "|    total_timesteps    | 51500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.75       |\n",
      "|    explained_variance | 0.00707     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10299       |\n",
      "|    policy_loss        | 0.00957     |\n",
      "|    reward             | 0.013865526 |\n",
      "|    std                | 4.29        |\n",
      "|    value_loss         | 2.35e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 10400       |\n",
      "|    time_elapsed       | 164         |\n",
      "|    total_timesteps    | 52000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.79       |\n",
      "|    explained_variance | 0.154       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10399       |\n",
      "|    policy_loss        | 0.0348      |\n",
      "|    reward             | 0.014822992 |\n",
      "|    std                | 4.37        |\n",
      "|    value_loss         | 0.000133    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 317         |\n",
      "|    iterations         | 10500       |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 52500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.83       |\n",
      "|    explained_variance | 0.625       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10499       |\n",
      "|    policy_loss        | -0.0872     |\n",
      "|    reward             | 0.058348846 |\n",
      "|    std                | 4.47        |\n",
      "|    value_loss         | 0.000415    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 10600       |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 53000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.88       |\n",
      "|    explained_variance | 0.049       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10599       |\n",
      "|    policy_loss        | 0.78        |\n",
      "|    reward             | 0.041076288 |\n",
      "|    std                | 4.57        |\n",
      "|    value_loss         | 0.0269      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 10700        |\n",
      "|    time_elapsed       | 168          |\n",
      "|    total_timesteps    | 53500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.9         |\n",
      "|    explained_variance | -4.77e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 10699        |\n",
      "|    policy_loss        | 0.418        |\n",
      "|    reward             | -0.080849536 |\n",
      "|    std                | 4.62         |\n",
      "|    value_loss         | 0.00692      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 10800        |\n",
      "|    time_elapsed       | 170          |\n",
      "|    total_timesteps    | 54000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.92        |\n",
      "|    explained_variance | 5.36e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 10799        |\n",
      "|    policy_loss        | -0.0121      |\n",
      "|    reward             | -0.010687784 |\n",
      "|    std                | 4.67         |\n",
      "|    value_loss         | 8.84e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 10900       |\n",
      "|    time_elapsed       | 172         |\n",
      "|    total_timesteps    | 54500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.94       |\n",
      "|    explained_variance | -0.0407     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10899       |\n",
      "|    policy_loss        | 0.0425      |\n",
      "|    reward             | 0.009174417 |\n",
      "|    std                | 4.71        |\n",
      "|    value_loss         | 0.000177    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 11000      |\n",
      "|    time_elapsed       | 173        |\n",
      "|    total_timesteps    | 55000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.98      |\n",
      "|    explained_variance | 0.318      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 10999      |\n",
      "|    policy_loss        | 0.272      |\n",
      "|    reward             | -0.0621794 |\n",
      "|    std                | 4.81       |\n",
      "|    value_loss         | 0.00424    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 11100       |\n",
      "|    time_elapsed       | 175         |\n",
      "|    total_timesteps    | 55500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.04       |\n",
      "|    explained_variance | 0.226       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 11099       |\n",
      "|    policy_loss        | 0.273       |\n",
      "|    reward             | -0.07842756 |\n",
      "|    std                | 4.95        |\n",
      "|    value_loss         | 0.00246     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 11200        |\n",
      "|    time_elapsed       | 177          |\n",
      "|    total_timesteps    | 56000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.04        |\n",
      "|    explained_variance | 0.208        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11199        |\n",
      "|    policy_loss        | -0.677       |\n",
      "|    reward             | 0.0045600235 |\n",
      "|    std                | 4.96         |\n",
      "|    value_loss         | 0.0388       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 11300        |\n",
      "|    time_elapsed       | 178          |\n",
      "|    total_timesteps    | 56500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.05        |\n",
      "|    explained_variance | 0.000372     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11299        |\n",
      "|    policy_loss        | 1.31         |\n",
      "|    reward             | -0.010393112 |\n",
      "|    std                | 4.99         |\n",
      "|    value_loss         | 0.0639       |\n",
      "----------------------------------------\n",
      "day: 2833, episode: 20\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 144354.30\n",
      "total_reward: 134354.30\n",
      "total_cost: 12.65\n",
      "total_trades: 5659\n",
      "Sharpe: 0.830\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 11400        |\n",
      "|    time_elapsed       | 180          |\n",
      "|    total_timesteps    | 57000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.06        |\n",
      "|    explained_variance | -0.774       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11399        |\n",
      "|    policy_loss        | -0.00946     |\n",
      "|    reward             | -0.014834641 |\n",
      "|    std                | 5.01         |\n",
      "|    value_loss         | 0.000187     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 11500        |\n",
      "|    time_elapsed       | 181          |\n",
      "|    total_timesteps    | 57500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.08        |\n",
      "|    explained_variance | -1.03        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11499        |\n",
      "|    policy_loss        | -0.000635    |\n",
      "|    reward             | 0.0065188846 |\n",
      "|    std                | 5.07         |\n",
      "|    value_loss         | 1.82e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 11600        |\n",
      "|    time_elapsed       | 183          |\n",
      "|    total_timesteps    | 58000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.11        |\n",
      "|    explained_variance | -2.01        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11599        |\n",
      "|    policy_loss        | -0.0117      |\n",
      "|    reward             | 0.0062724035 |\n",
      "|    std                | 5.14         |\n",
      "|    value_loss         | 0.000105     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 11700       |\n",
      "|    time_elapsed       | 185         |\n",
      "|    total_timesteps    | 58500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.15       |\n",
      "|    explained_variance | 0.134       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 11699       |\n",
      "|    policy_loss        | -0.302      |\n",
      "|    reward             | 0.004436864 |\n",
      "|    std                | 5.23        |\n",
      "|    value_loss         | 0.0024      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 11800       |\n",
      "|    time_elapsed       | 186         |\n",
      "|    total_timesteps    | 59000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.18       |\n",
      "|    explained_variance | 0.219       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 11799       |\n",
      "|    policy_loss        | 0.12        |\n",
      "|    reward             | 0.018147064 |\n",
      "|    std                | 5.32        |\n",
      "|    value_loss         | 0.00144     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 11900        |\n",
      "|    time_elapsed       | 188          |\n",
      "|    total_timesteps    | 59500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.23        |\n",
      "|    explained_variance | -0.0241      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11899        |\n",
      "|    policy_loss        | -0.389       |\n",
      "|    reward             | -0.046693236 |\n",
      "|    std                | 5.45         |\n",
      "|    value_loss         | 0.00666      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 12000         |\n",
      "|    time_elapsed       | 190           |\n",
      "|    total_timesteps    | 60000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.25         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 11999         |\n",
      "|    policy_loss        | 0.0684        |\n",
      "|    reward             | -0.0059584687 |\n",
      "|    std                | 5.51          |\n",
      "|    value_loss         | 0.000201      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 12100       |\n",
      "|    time_elapsed       | 191         |\n",
      "|    total_timesteps    | 60500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.3        |\n",
      "|    explained_variance | 0.312       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12099       |\n",
      "|    policy_loss        | 0.0277      |\n",
      "|    reward             | 0.027443875 |\n",
      "|    std                | 5.64        |\n",
      "|    value_loss         | 0.000105    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 12200       |\n",
      "|    time_elapsed       | 193         |\n",
      "|    total_timesteps    | 61000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.33       |\n",
      "|    explained_variance | 0.273       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12199       |\n",
      "|    policy_loss        | 0.268       |\n",
      "|    reward             | 0.006693441 |\n",
      "|    std                | 5.74        |\n",
      "|    value_loss         | 0.00518     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 12300       |\n",
      "|    time_elapsed       | 194         |\n",
      "|    total_timesteps    | 61500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.36       |\n",
      "|    explained_variance | 0.255       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12299       |\n",
      "|    policy_loss        | 0.396       |\n",
      "|    reward             | -0.00940795 |\n",
      "|    std                | 5.81        |\n",
      "|    value_loss         | 0.00873     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 12400       |\n",
      "|    time_elapsed       | 196         |\n",
      "|    total_timesteps    | 62000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.36       |\n",
      "|    explained_variance | 0.463       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12399       |\n",
      "|    policy_loss        | -0.0116     |\n",
      "|    reward             | -0.10301668 |\n",
      "|    std                | 5.81        |\n",
      "|    value_loss         | 0.00303     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 12500        |\n",
      "|    time_elapsed       | 197          |\n",
      "|    total_timesteps    | 62500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.37        |\n",
      "|    explained_variance | -3.06        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 12499        |\n",
      "|    policy_loss        | -0.0182      |\n",
      "|    reward             | 0.0028262776 |\n",
      "|    std                | 5.86         |\n",
      "|    value_loss         | 6.93e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 12600       |\n",
      "|    time_elapsed       | 199         |\n",
      "|    total_timesteps    | 63000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.41       |\n",
      "|    explained_variance | -0.523      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12599       |\n",
      "|    policy_loss        | 0.0152      |\n",
      "|    reward             | 0.013203651 |\n",
      "|    std                | 5.97        |\n",
      "|    value_loss         | 8.61e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 12700       |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 63500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.45       |\n",
      "|    explained_variance | 0.673       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12699       |\n",
      "|    policy_loss        | 0.041       |\n",
      "|    reward             | 0.015607081 |\n",
      "|    std                | 6.09        |\n",
      "|    value_loss         | 8.88e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 12800        |\n",
      "|    time_elapsed       | 202          |\n",
      "|    total_timesteps    | 64000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.5         |\n",
      "|    explained_variance | 0.217        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 12799        |\n",
      "|    policy_loss        | -0.195       |\n",
      "|    reward             | -0.006664341 |\n",
      "|    std                | 6.23         |\n",
      "|    value_loss         | 0.00134      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 12900        |\n",
      "|    time_elapsed       | 204          |\n",
      "|    total_timesteps    | 64500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.57        |\n",
      "|    explained_variance | 0.202        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 12899        |\n",
      "|    policy_loss        | -0.676       |\n",
      "|    reward             | -0.007823886 |\n",
      "|    std                | 6.45         |\n",
      "|    value_loss         | 0.0102       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 13000         |\n",
      "|    time_elapsed       | 206           |\n",
      "|    total_timesteps    | 65000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.6          |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 12999         |\n",
      "|    policy_loss        | -0.048        |\n",
      "|    reward             | -0.0048332703 |\n",
      "|    std                | 6.55          |\n",
      "|    value_loss         | 0.000842      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 13100       |\n",
      "|    time_elapsed       | 207         |\n",
      "|    total_timesteps    | 65500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.63       |\n",
      "|    explained_variance | 0.187       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13099       |\n",
      "|    policy_loss        | 0.091       |\n",
      "|    reward             | 0.003017627 |\n",
      "|    std                | 6.68        |\n",
      "|    value_loss         | 0.000224    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 13200        |\n",
      "|    time_elapsed       | 209          |\n",
      "|    total_timesteps    | 66000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.66        |\n",
      "|    explained_variance | 0.145        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 13199        |\n",
      "|    policy_loss        | -0.0906      |\n",
      "|    reward             | 0.0075657736 |\n",
      "|    std                | 6.78         |\n",
      "|    value_loss         | 0.000543     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 13300        |\n",
      "|    time_elapsed       | 211          |\n",
      "|    total_timesteps    | 66500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.72        |\n",
      "|    explained_variance | 0.098        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 13299        |\n",
      "|    policy_loss        | 0.00247      |\n",
      "|    reward             | -0.057459813 |\n",
      "|    std                | 6.98         |\n",
      "|    value_loss         | 0.000185     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 13400      |\n",
      "|    time_elapsed       | 212        |\n",
      "|    total_timesteps    | 67000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.78      |\n",
      "|    explained_variance | 0.0496     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 13399      |\n",
      "|    policy_loss        | -1.1       |\n",
      "|    reward             | 0.06858145 |\n",
      "|    std                | 7.15       |\n",
      "|    value_loss         | 0.0314     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 13500      |\n",
      "|    time_elapsed       | 214        |\n",
      "|    total_timesteps    | 67500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.78      |\n",
      "|    explained_variance | 0.283      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 13499      |\n",
      "|    policy_loss        | 1.16       |\n",
      "|    reward             | 0.21159016 |\n",
      "|    std                | 7.17       |\n",
      "|    value_loss         | 0.034      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 13600       |\n",
      "|    time_elapsed       | 215         |\n",
      "|    total_timesteps    | 68000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.8        |\n",
      "|    explained_variance | 0.00703     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13599       |\n",
      "|    policy_loss        | 0.652       |\n",
      "|    reward             | 0.040984936 |\n",
      "|    std                | 7.28        |\n",
      "|    value_loss         | 0.0106      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 13700        |\n",
      "|    time_elapsed       | 217          |\n",
      "|    total_timesteps    | 68500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.83        |\n",
      "|    explained_variance | -0.074       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 13699        |\n",
      "|    policy_loss        | -0.0166      |\n",
      "|    reward             | -0.009269323 |\n",
      "|    std                | 7.37         |\n",
      "|    value_loss         | 7.11e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 13800       |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 69000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.87       |\n",
      "|    explained_variance | 0.138       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13799       |\n",
      "|    policy_loss        | -0.0986     |\n",
      "|    reward             | 0.008780665 |\n",
      "|    std                | 7.5         |\n",
      "|    value_loss         | 0.000889    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 13900       |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 69500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.89       |\n",
      "|    explained_variance | 0.328       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13899       |\n",
      "|    policy_loss        | 0.515       |\n",
      "|    reward             | 0.018435514 |\n",
      "|    std                | 7.6         |\n",
      "|    value_loss         | 0.00611     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 14000        |\n",
      "|    time_elapsed       | 222          |\n",
      "|    total_timesteps    | 70000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.94        |\n",
      "|    explained_variance | 0.0351       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 13999        |\n",
      "|    policy_loss        | -0.0798      |\n",
      "|    reward             | -0.019133538 |\n",
      "|    std                | 7.79         |\n",
      "|    value_loss         | 0.00325      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 14100        |\n",
      "|    time_elapsed       | 224          |\n",
      "|    total_timesteps    | 70500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7           |\n",
      "|    explained_variance | 0.103        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 14099        |\n",
      "|    policy_loss        | 0.391        |\n",
      "|    reward             | -0.004208297 |\n",
      "|    std                | 7.99         |\n",
      "|    value_loss         | 0.0063       |\n",
      "----------------------------------------\n",
      "day: 2833, episode: 25\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 60601.87\n",
      "total_reward: 50601.87\n",
      "total_cost: 12.52\n",
      "total_trades: 5659\n",
      "Sharpe: 0.679\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 14200        |\n",
      "|    time_elapsed       | 225          |\n",
      "|    total_timesteps    | 71000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.01        |\n",
      "|    explained_variance | -10.8        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 14199        |\n",
      "|    policy_loss        | -0.152       |\n",
      "|    reward             | 0.0022894542 |\n",
      "|    std                | 8.08         |\n",
      "|    value_loss         | 0.000576     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 314            |\n",
      "|    iterations         | 14300          |\n",
      "|    time_elapsed       | 227            |\n",
      "|    total_timesteps    | 71500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -7.05          |\n",
      "|    explained_variance | -0.7           |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 14299          |\n",
      "|    policy_loss        | -0.046         |\n",
      "|    reward             | -0.00074619177 |\n",
      "|    std                | 8.23           |\n",
      "|    value_loss         | 7.86e-05       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 14400        |\n",
      "|    time_elapsed       | 228          |\n",
      "|    total_timesteps    | 72000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.09        |\n",
      "|    explained_variance | -4.13        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 14399        |\n",
      "|    policy_loss        | 0.177        |\n",
      "|    reward             | 0.0040335245 |\n",
      "|    std                | 8.38         |\n",
      "|    value_loss         | 0.000856     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 14500        |\n",
      "|    time_elapsed       | 230          |\n",
      "|    total_timesteps    | 72500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.14        |\n",
      "|    explained_variance | -0.177       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 14499        |\n",
      "|    policy_loss        | -0.0952      |\n",
      "|    reward             | 0.0047936416 |\n",
      "|    std                | 8.61         |\n",
      "|    value_loss         | 0.000404     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 14600        |\n",
      "|    time_elapsed       | 231          |\n",
      "|    total_timesteps    | 73000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.19        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 14599        |\n",
      "|    policy_loss        | -0.336       |\n",
      "|    reward             | -0.008088844 |\n",
      "|    std                | 8.85         |\n",
      "|    value_loss         | 0.00257      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 14700       |\n",
      "|    time_elapsed       | 233         |\n",
      "|    total_timesteps    | 73500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.24       |\n",
      "|    explained_variance | -0.017      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14699       |\n",
      "|    policy_loss        | -0.202      |\n",
      "|    reward             | 0.030590191 |\n",
      "|    std                | 9.06        |\n",
      "|    value_loss         | 0.00145     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 14800       |\n",
      "|    time_elapsed       | 234         |\n",
      "|    total_timesteps    | 74000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.28       |\n",
      "|    explained_variance | 0.633       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14799       |\n",
      "|    policy_loss        | -0.129      |\n",
      "|    reward             | 0.008413903 |\n",
      "|    std                | 9.22        |\n",
      "|    value_loss         | 0.00032     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 14900         |\n",
      "|    time_elapsed       | 236           |\n",
      "|    total_timesteps    | 74500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.34         |\n",
      "|    explained_variance | 0.748         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 14899         |\n",
      "|    policy_loss        | -0.01         |\n",
      "|    reward             | -0.0011461163 |\n",
      "|    std                | 9.52          |\n",
      "|    value_loss         | 2.03e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 15000         |\n",
      "|    time_elapsed       | 237           |\n",
      "|    total_timesteps    | 75000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.43         |\n",
      "|    explained_variance | 0.745         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 14999         |\n",
      "|    policy_loss        | -0.0668       |\n",
      "|    reward             | -0.0007481384 |\n",
      "|    std                | 9.93          |\n",
      "|    value_loss         | 9.38e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 15100       |\n",
      "|    time_elapsed       | 239         |\n",
      "|    total_timesteps    | 75500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.51       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15099       |\n",
      "|    policy_loss        | -0.414      |\n",
      "|    reward             | 0.030025346 |\n",
      "|    std                | 10.4        |\n",
      "|    value_loss         | 0.00407     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 15200       |\n",
      "|    time_elapsed       | 240         |\n",
      "|    total_timesteps    | 76000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.56       |\n",
      "|    explained_variance | 0.264       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15199       |\n",
      "|    policy_loss        | 0.467       |\n",
      "|    reward             | -0.07051935 |\n",
      "|    std                | 10.6        |\n",
      "|    value_loss         | 0.00523     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 15300       |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 76500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.6        |\n",
      "|    explained_variance | 0.0599      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15299       |\n",
      "|    policy_loss        | 0.188       |\n",
      "|    reward             | 0.016082581 |\n",
      "|    std                | 10.8        |\n",
      "|    value_loss         | 0.00179     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 15400        |\n",
      "|    time_elapsed       | 243          |\n",
      "|    total_timesteps    | 77000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.64        |\n",
      "|    explained_variance | -0.394       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 15399        |\n",
      "|    policy_loss        | -0.115       |\n",
      "|    reward             | 0.0054647676 |\n",
      "|    std                | 11.1         |\n",
      "|    value_loss         | 0.000431     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 15500      |\n",
      "|    time_elapsed       | 245        |\n",
      "|    total_timesteps    | 77500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.69      |\n",
      "|    explained_variance | 0.418      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 15499      |\n",
      "|    policy_loss        | -0.348     |\n",
      "|    reward             | 0.03367015 |\n",
      "|    std                | 11.3       |\n",
      "|    value_loss         | 0.00413    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 15600      |\n",
      "|    time_elapsed       | 246        |\n",
      "|    total_timesteps    | 78000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.71      |\n",
      "|    explained_variance | 0.254      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 15599      |\n",
      "|    policy_loss        | 0.266      |\n",
      "|    reward             | 0.04013976 |\n",
      "|    std                | 11.5       |\n",
      "|    value_loss         | 0.00298    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 15700      |\n",
      "|    time_elapsed       | 248        |\n",
      "|    total_timesteps    | 78500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.77      |\n",
      "|    explained_variance | 0.164      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 15699      |\n",
      "|    policy_loss        | -0.909     |\n",
      "|    reward             | 0.06626983 |\n",
      "|    std                | 11.8       |\n",
      "|    value_loss         | 0.029      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 15800      |\n",
      "|    time_elapsed       | 250        |\n",
      "|    total_timesteps    | 79000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.79      |\n",
      "|    explained_variance | 0.371      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 15799      |\n",
      "|    policy_loss        | -0.324     |\n",
      "|    reward             | 0.09149596 |\n",
      "|    std                | 11.9       |\n",
      "|    value_loss         | 0.0154     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 15900        |\n",
      "|    time_elapsed       | 251          |\n",
      "|    total_timesteps    | 79500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.83        |\n",
      "|    explained_variance | 0.157        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 15899        |\n",
      "|    policy_loss        | -0.0175      |\n",
      "|    reward             | -0.010655106 |\n",
      "|    std                | 12.2         |\n",
      "|    value_loss         | 3.96e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 16000        |\n",
      "|    time_elapsed       | 253          |\n",
      "|    total_timesteps    | 80000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.85        |\n",
      "|    explained_variance | 0.859        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 15999        |\n",
      "|    policy_loss        | -0.0545      |\n",
      "|    reward             | -0.006038172 |\n",
      "|    std                | 12.3         |\n",
      "|    value_loss         | 5.79e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 16100        |\n",
      "|    time_elapsed       | 255          |\n",
      "|    total_timesteps    | 80500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.91        |\n",
      "|    explained_variance | 0.436        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 16099        |\n",
      "|    policy_loss        | -0.385       |\n",
      "|    reward             | -0.021615935 |\n",
      "|    std                | 12.7         |\n",
      "|    value_loss         | 0.00602      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 16200        |\n",
      "|    time_elapsed       | 256          |\n",
      "|    total_timesteps    | 81000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.95        |\n",
      "|    explained_variance | 0.426        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 16199        |\n",
      "|    policy_loss        | 0.162        |\n",
      "|    reward             | -0.016358688 |\n",
      "|    std                | 12.9         |\n",
      "|    value_loss         | 0.000873     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 16300        |\n",
      "|    time_elapsed       | 258          |\n",
      "|    total_timesteps    | 81500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8           |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 16299        |\n",
      "|    policy_loss        | -0.0621      |\n",
      "|    reward             | -0.046261523 |\n",
      "|    std                | 13.3         |\n",
      "|    value_loss         | 0.000338     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 16400      |\n",
      "|    time_elapsed       | 259        |\n",
      "|    total_timesteps    | 82000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.03      |\n",
      "|    explained_variance | 0.077      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 16399      |\n",
      "|    policy_loss        | 0.76       |\n",
      "|    reward             | 0.04840559 |\n",
      "|    std                | 13.5       |\n",
      "|    value_loss         | 0.0148     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 16500        |\n",
      "|    time_elapsed       | 261          |\n",
      "|    total_timesteps    | 82500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.06        |\n",
      "|    explained_variance | 0.65         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 16499        |\n",
      "|    policy_loss        | 0.0456       |\n",
      "|    reward             | 0.0041521615 |\n",
      "|    std                | 13.7         |\n",
      "|    value_loss         | 9.93e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 16600         |\n",
      "|    time_elapsed       | 263           |\n",
      "|    total_timesteps    | 83000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.09         |\n",
      "|    explained_variance | -0.000158     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 16599         |\n",
      "|    policy_loss        | -0.0525       |\n",
      "|    reward             | -0.0013065625 |\n",
      "|    std                | 13.9          |\n",
      "|    value_loss         | 9.18e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 16700        |\n",
      "|    time_elapsed       | 264          |\n",
      "|    total_timesteps    | 83500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.12        |\n",
      "|    explained_variance | 0.237        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 16699        |\n",
      "|    policy_loss        | -0.0463      |\n",
      "|    reward             | 0.0075493134 |\n",
      "|    std                | 14.2         |\n",
      "|    value_loss         | 0.000112     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 16800       |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 84000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.17       |\n",
      "|    explained_variance | 0.0569      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16799       |\n",
      "|    policy_loss        | 0.0314      |\n",
      "|    reward             | -0.00930401 |\n",
      "|    std                | 14.5        |\n",
      "|    value_loss         | 0.000686    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 16900       |\n",
      "|    time_elapsed       | 268         |\n",
      "|    total_timesteps    | 84500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.17       |\n",
      "|    explained_variance | -0.06       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16899       |\n",
      "|    policy_loss        | 0.402       |\n",
      "|    reward             | -0.01179681 |\n",
      "|    std                | 14.5        |\n",
      "|    value_loss         | 0.00362     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 17000        |\n",
      "|    time_elapsed       | 269          |\n",
      "|    total_timesteps    | 85000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.18        |\n",
      "|    explained_variance | 0.2          |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 16999        |\n",
      "|    policy_loss        | 0.817        |\n",
      "|    reward             | -0.056074888 |\n",
      "|    std                | 14.6         |\n",
      "|    value_loss         | 0.012        |\n",
      "----------------------------------------\n",
      "day: 2833, episode: 30\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 51328.53\n",
      "total_reward: 41328.53\n",
      "total_cost: 14.47\n",
      "total_trades: 5658\n",
      "Sharpe: 0.638\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 17100       |\n",
      "|    time_elapsed       | 271         |\n",
      "|    total_timesteps    | 85500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.22       |\n",
      "|    explained_variance | 0.351       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17099       |\n",
      "|    policy_loss        | -0.144      |\n",
      "|    reward             | 0.009015879 |\n",
      "|    std                | 14.9        |\n",
      "|    value_loss         | 0.000294    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 17200       |\n",
      "|    time_elapsed       | 272         |\n",
      "|    total_timesteps    | 86000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.28       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17199       |\n",
      "|    policy_loss        | -0.373      |\n",
      "|    reward             | 0.013121791 |\n",
      "|    std                | 15.3        |\n",
      "|    value_loss         | 0.00208     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 17300        |\n",
      "|    time_elapsed       | 274          |\n",
      "|    total_timesteps    | 86500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.35        |\n",
      "|    explained_variance | 0.0852       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 17299        |\n",
      "|    policy_loss        | -0.541       |\n",
      "|    reward             | -0.041238062 |\n",
      "|    std                | 15.9         |\n",
      "|    value_loss         | 0.00801      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 17400       |\n",
      "|    time_elapsed       | 275         |\n",
      "|    total_timesteps    | 87000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.38       |\n",
      "|    explained_variance | 0.0972      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17399       |\n",
      "|    policy_loss        | -1.54       |\n",
      "|    reward             | 0.100692116 |\n",
      "|    std                | 16.1        |\n",
      "|    value_loss         | 0.0341      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 17500       |\n",
      "|    time_elapsed       | 277         |\n",
      "|    total_timesteps    | 87500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.41       |\n",
      "|    explained_variance | 0.662       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17499       |\n",
      "|    policy_loss        | -1.34       |\n",
      "|    reward             | -0.07098242 |\n",
      "|    std                | 16.4        |\n",
      "|    value_loss         | 0.0282      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 17600       |\n",
      "|    time_elapsed       | 278         |\n",
      "|    total_timesteps    | 88000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.44       |\n",
      "|    explained_variance | -0.001      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17599       |\n",
      "|    policy_loss        | 0.0266      |\n",
      "|    reward             | 0.003173163 |\n",
      "|    std                | 16.6        |\n",
      "|    value_loss         | 5.55e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 17700        |\n",
      "|    time_elapsed       | 280          |\n",
      "|    total_timesteps    | 88500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.46        |\n",
      "|    explained_variance | 0.376        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 17699        |\n",
      "|    policy_loss        | -0.000203    |\n",
      "|    reward             | 0.0045984564 |\n",
      "|    std                | 16.8         |\n",
      "|    value_loss         | 6.83e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 17800        |\n",
      "|    time_elapsed       | 281          |\n",
      "|    total_timesteps    | 89000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.5         |\n",
      "|    explained_variance | 0.632        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 17799        |\n",
      "|    policy_loss        | -0.564       |\n",
      "|    reward             | 0.0057661934 |\n",
      "|    std                | 17.1         |\n",
      "|    value_loss         | 0.00531      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 17900        |\n",
      "|    time_elapsed       | 283          |\n",
      "|    total_timesteps    | 89500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.55        |\n",
      "|    explained_variance | 0.549        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 17899        |\n",
      "|    policy_loss        | -0.0187      |\n",
      "|    reward             | -0.014937326 |\n",
      "|    std                | 17.5         |\n",
      "|    value_loss         | 6.12e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 18000       |\n",
      "|    time_elapsed       | 284         |\n",
      "|    total_timesteps    | 90000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.61       |\n",
      "|    explained_variance | -0.177      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17999       |\n",
      "|    policy_loss        | 0.249       |\n",
      "|    reward             | 0.018126993 |\n",
      "|    std                | 18.1        |\n",
      "|    value_loss         | 0.00107     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 18100      |\n",
      "|    time_elapsed       | 286        |\n",
      "|    total_timesteps    | 90500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.66      |\n",
      "|    explained_variance | 0.399      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 18099      |\n",
      "|    policy_loss        | 0.756      |\n",
      "|    reward             | 0.12977284 |\n",
      "|    std                | 18.6       |\n",
      "|    value_loss         | 0.00808    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 18200       |\n",
      "|    time_elapsed       | 287         |\n",
      "|    total_timesteps    | 91000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.69       |\n",
      "|    explained_variance | 0.275       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18199       |\n",
      "|    policy_loss        | 0.208       |\n",
      "|    reward             | 0.005703081 |\n",
      "|    std                | 18.8        |\n",
      "|    value_loss         | 0.000625    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 18300        |\n",
      "|    time_elapsed       | 289          |\n",
      "|    total_timesteps    | 91500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.74        |\n",
      "|    explained_variance | -0.00915     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 18299        |\n",
      "|    policy_loss        | -0.00981     |\n",
      "|    reward             | -0.009933565 |\n",
      "|    std                | 19.2         |\n",
      "|    value_loss         | 2.69e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 18400       |\n",
      "|    time_elapsed       | 290         |\n",
      "|    total_timesteps    | 92000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.79       |\n",
      "|    explained_variance | -0.323      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18399       |\n",
      "|    policy_loss        | 0.0508      |\n",
      "|    reward             | 0.004394178 |\n",
      "|    std                | 19.7        |\n",
      "|    value_loss         | 5e-05       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 18500      |\n",
      "|    time_elapsed       | 292        |\n",
      "|    total_timesteps    | 92500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.84      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 18499      |\n",
      "|    policy_loss        | -0.25      |\n",
      "|    reward             | 0.00641032 |\n",
      "|    std                | 20.2       |\n",
      "|    value_loss         | 0.000932   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 18600       |\n",
      "|    time_elapsed       | 293         |\n",
      "|    total_timesteps    | 93000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.87       |\n",
      "|    explained_variance | 3.34e-06    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18599       |\n",
      "|    policy_loss        | -0.0831     |\n",
      "|    reward             | 0.012029855 |\n",
      "|    std                | 20.6        |\n",
      "|    value_loss         | 0.000276    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 18700        |\n",
      "|    time_elapsed       | 295          |\n",
      "|    total_timesteps    | 93500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.91        |\n",
      "|    explained_variance | 0.921        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 18699        |\n",
      "|    policy_loss        | -0.0746      |\n",
      "|    reward             | 0.0062306672 |\n",
      "|    std                | 21           |\n",
      "|    value_loss         | 9.39e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 18800       |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 94000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.96       |\n",
      "|    explained_variance | -0.00608    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18799       |\n",
      "|    policy_loss        | -0.0585     |\n",
      "|    reward             | 0.014377734 |\n",
      "|    std                | 21.5        |\n",
      "|    value_loss         | 7.88e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 18900       |\n",
      "|    time_elapsed       | 298         |\n",
      "|    total_timesteps    | 94500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.02       |\n",
      "|    explained_variance | 0.323       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18899       |\n",
      "|    policy_loss        | 0.24        |\n",
      "|    reward             | 0.017447798 |\n",
      "|    std                | 22.2        |\n",
      "|    value_loss         | 0.000797    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 19000       |\n",
      "|    time_elapsed       | 300         |\n",
      "|    total_timesteps    | 95000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.07       |\n",
      "|    explained_variance | 0.000372    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18999       |\n",
      "|    policy_loss        | -1.02       |\n",
      "|    reward             | 0.049594186 |\n",
      "|    std                | 22.8        |\n",
      "|    value_loss         | 0.0132      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 19100       |\n",
      "|    time_elapsed       | 302         |\n",
      "|    total_timesteps    | 95500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.09       |\n",
      "|    explained_variance | 0.0785      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19099       |\n",
      "|    policy_loss        | -0.826      |\n",
      "|    reward             | -0.09576849 |\n",
      "|    std                | 23          |\n",
      "|    value_loss         | 0.0107      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 19200      |\n",
      "|    time_elapsed       | 303        |\n",
      "|    total_timesteps    | 96000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.1       |\n",
      "|    explained_variance | 0.41       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 19199      |\n",
      "|    policy_loss        | -0.314     |\n",
      "|    reward             | 0.07172172 |\n",
      "|    std                | 23.1       |\n",
      "|    value_loss         | 0.00324    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 19300       |\n",
      "|    time_elapsed       | 305         |\n",
      "|    total_timesteps    | 96500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.11       |\n",
      "|    explained_variance | -0.716      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19299       |\n",
      "|    policy_loss        | -0.0774     |\n",
      "|    reward             | 0.003282705 |\n",
      "|    std                | 23.2        |\n",
      "|    value_loss         | 7.75e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 19400        |\n",
      "|    time_elapsed       | 306          |\n",
      "|    total_timesteps    | 97000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.14        |\n",
      "|    explained_variance | 0.226        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 19399        |\n",
      "|    policy_loss        | -0.121       |\n",
      "|    reward             | -0.017873932 |\n",
      "|    std                | 23.5         |\n",
      "|    value_loss         | 0.000334     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 19500       |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 97500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.17       |\n",
      "|    explained_variance | 0.0361      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19499       |\n",
      "|    policy_loss        | -0.223      |\n",
      "|    reward             | 0.025171451 |\n",
      "|    std                | 23.9        |\n",
      "|    value_loss         | 0.000913    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 19600       |\n",
      "|    time_elapsed       | 309         |\n",
      "|    total_timesteps    | 98000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.21       |\n",
      "|    explained_variance | 0.0854      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19599       |\n",
      "|    policy_loss        | -0.136      |\n",
      "|    reward             | -0.06731526 |\n",
      "|    std                | 24.4        |\n",
      "|    value_loss         | 0.00028     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 19700       |\n",
      "|    time_elapsed       | 311         |\n",
      "|    total_timesteps    | 98500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.25       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19699       |\n",
      "|    policy_loss        | -0.145      |\n",
      "|    reward             | -0.04336328 |\n",
      "|    std                | 25          |\n",
      "|    value_loss         | 0.000501    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 19800      |\n",
      "|    time_elapsed       | 312        |\n",
      "|    total_timesteps    | 99000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.28      |\n",
      "|    explained_variance | 0.144      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 19799      |\n",
      "|    policy_loss        | -1.05      |\n",
      "|    reward             | 0.04868842 |\n",
      "|    std                | 25.3       |\n",
      "|    value_loss         | 0.0171     |\n",
      "--------------------------------------\n",
      "day: 2833, episode: 35\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 76400.89\n",
      "total_reward: 66400.89\n",
      "total_cost: 12.78\n",
      "total_trades: 5660\n",
      "Sharpe: 0.741\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 19900       |\n",
      "|    time_elapsed       | 314         |\n",
      "|    total_timesteps    | 99500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.31       |\n",
      "|    explained_variance | 0.253       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19899       |\n",
      "|    policy_loss        | 0.32        |\n",
      "|    reward             | 0.005026875 |\n",
      "|    std                | 25.7        |\n",
      "|    value_loss         | 0.00157     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 20000       |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 100000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.33       |\n",
      "|    explained_variance | 0.248       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19999       |\n",
      "|    policy_loss        | 0.0715      |\n",
      "|    reward             | -0.04100923 |\n",
      "|    std                | 26          |\n",
      "|    value_loss         | 0.000319    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 20100       |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 100500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.37       |\n",
      "|    explained_variance | 0.189       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20099       |\n",
      "|    policy_loss        | -0.653      |\n",
      "|    reward             | -0.01340362 |\n",
      "|    std                | 26.4        |\n",
      "|    value_loss         | 0.00654     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 20200       |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 101000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.39       |\n",
      "|    explained_variance | 0.000347    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20199       |\n",
      "|    policy_loss        | 2.73        |\n",
      "|    reward             | -0.24585053 |\n",
      "|    std                | 26.7        |\n",
      "|    value_loss         | 0.0812      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 20300      |\n",
      "|    time_elapsed       | 320        |\n",
      "|    total_timesteps    | 101500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.38      |\n",
      "|    explained_variance | -0.0148    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 20299      |\n",
      "|    policy_loss        | -0.794     |\n",
      "|    reward             | 0.16639163 |\n",
      "|    std                | 26.5       |\n",
      "|    value_loss         | 0.0261     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 20400       |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 102000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.43       |\n",
      "|    explained_variance | 0.238       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20399       |\n",
      "|    policy_loss        | 2.31        |\n",
      "|    reward             | -0.11525982 |\n",
      "|    std                | 27.2        |\n",
      "|    value_loss         | 0.0908      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 20500        |\n",
      "|    time_elapsed       | 324          |\n",
      "|    total_timesteps    | 102500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.44        |\n",
      "|    explained_variance | -0.00592     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20499        |\n",
      "|    policy_loss        | -0.155       |\n",
      "|    reward             | -0.007470919 |\n",
      "|    std                | 27.4         |\n",
      "|    value_loss         | 0.000329     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 316           |\n",
      "|    iterations         | 20600         |\n",
      "|    time_elapsed       | 325           |\n",
      "|    total_timesteps    | 103000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -9.49         |\n",
      "|    explained_variance | 0.47          |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 20599         |\n",
      "|    policy_loss        | 0.0662        |\n",
      "|    reward             | -0.0011691643 |\n",
      "|    std                | 28            |\n",
      "|    value_loss         | 0.000193      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 20700        |\n",
      "|    time_elapsed       | 327          |\n",
      "|    total_timesteps    | 103500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.55        |\n",
      "|    explained_variance | 6.68e-05     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20699        |\n",
      "|    policy_loss        | 0.136        |\n",
      "|    reward             | -0.014246905 |\n",
      "|    std                | 29           |\n",
      "|    value_loss         | 0.000481     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 20800       |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 104000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.61       |\n",
      "|    explained_variance | -1.74       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20799       |\n",
      "|    policy_loss        | -0.303      |\n",
      "|    reward             | 0.019198261 |\n",
      "|    std                | 29.9        |\n",
      "|    value_loss         | 0.00124     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 20900        |\n",
      "|    time_elapsed       | 330          |\n",
      "|    total_timesteps    | 104500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.65        |\n",
      "|    explained_variance | 0.0904       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20899        |\n",
      "|    policy_loss        | -0.631       |\n",
      "|    reward             | -0.008926965 |\n",
      "|    std                | 30.4         |\n",
      "|    value_loss         | 0.00455      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 21000        |\n",
      "|    time_elapsed       | 332          |\n",
      "|    total_timesteps    | 105000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.68        |\n",
      "|    explained_variance | -0.119       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20999        |\n",
      "|    policy_loss        | 0.0543       |\n",
      "|    reward             | 0.0037095966 |\n",
      "|    std                | 30.8         |\n",
      "|    value_loss         | 3.5e-05      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 21100       |\n",
      "|    time_elapsed       | 333         |\n",
      "|    total_timesteps    | 105500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.71       |\n",
      "|    explained_variance | 0.667       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21099       |\n",
      "|    policy_loss        | 0.036       |\n",
      "|    reward             | 0.016372258 |\n",
      "|    std                | 31.4        |\n",
      "|    value_loss         | 1.42e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 21200       |\n",
      "|    time_elapsed       | 335         |\n",
      "|    total_timesteps    | 106000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.78       |\n",
      "|    explained_variance | 0.436       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21199       |\n",
      "|    policy_loss        | -0.483      |\n",
      "|    reward             | 0.011071046 |\n",
      "|    std                | 32.5        |\n",
      "|    value_loss         | 0.00281     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 21300        |\n",
      "|    time_elapsed       | 336          |\n",
      "|    total_timesteps    | 106500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.83        |\n",
      "|    explained_variance | -0.0213      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 21299        |\n",
      "|    policy_loss        | 0.248        |\n",
      "|    reward             | 0.0014343689 |\n",
      "|    std                | 33.4         |\n",
      "|    value_loss         | 0.000907     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 21400       |\n",
      "|    time_elapsed       | 338         |\n",
      "|    total_timesteps    | 107000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.89       |\n",
      "|    explained_variance | 0.0807      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21399       |\n",
      "|    policy_loss        | -0.155      |\n",
      "|    reward             | 0.017930243 |\n",
      "|    std                | 34.4        |\n",
      "|    value_loss         | 0.000786    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 21500        |\n",
      "|    time_elapsed       | 340          |\n",
      "|    total_timesteps    | 107500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.93        |\n",
      "|    explained_variance | 0.37         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 21499        |\n",
      "|    policy_loss        | -0.0721      |\n",
      "|    reward             | -0.015180155 |\n",
      "|    std                | 35.1         |\n",
      "|    value_loss         | 0.00251      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 21600       |\n",
      "|    time_elapsed       | 341         |\n",
      "|    total_timesteps    | 108000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.92       |\n",
      "|    explained_variance | 0.0979      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21599       |\n",
      "|    policy_loss        | 0.0562      |\n",
      "|    reward             | 0.058072302 |\n",
      "|    std                | 35          |\n",
      "|    value_loss         | 0.000259    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 21700       |\n",
      "|    time_elapsed       | 343         |\n",
      "|    total_timesteps    | 108500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.97       |\n",
      "|    explained_variance | -0.0429     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21699       |\n",
      "|    policy_loss        | -0.332      |\n",
      "|    reward             | 0.029384315 |\n",
      "|    std                | 35.9        |\n",
      "|    value_loss         | 0.00149     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 21800       |\n",
      "|    time_elapsed       | 344         |\n",
      "|    total_timesteps    | 109000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10         |\n",
      "|    explained_variance | 0.0688      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21799       |\n",
      "|    policy_loss        | -0.73       |\n",
      "|    reward             | -0.06964803 |\n",
      "|    std                | 36.3        |\n",
      "|    value_loss         | 0.0185      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 21900       |\n",
      "|    time_elapsed       | 346         |\n",
      "|    total_timesteps    | 109500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21899       |\n",
      "|    policy_loss        | -0.457      |\n",
      "|    reward             | 0.020907361 |\n",
      "|    std                | 36.6        |\n",
      "|    value_loss         | 0.0062      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 22000      |\n",
      "|    time_elapsed       | 347        |\n",
      "|    total_timesteps    | 110000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 21999      |\n",
      "|    policy_loss        | -6.48      |\n",
      "|    reward             | 0.61615515 |\n",
      "|    std                | 37         |\n",
      "|    value_loss         | 0.534      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 22100      |\n",
      "|    time_elapsed       | 349        |\n",
      "|    total_timesteps    | 110500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.1      |\n",
      "|    explained_variance | 0.0944     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 22099      |\n",
      "|    policy_loss        | 8.24       |\n",
      "|    reward             | 0.39612553 |\n",
      "|    std                | 37.4       |\n",
      "|    value_loss         | 0.722      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 22200        |\n",
      "|    time_elapsed       | 351          |\n",
      "|    total_timesteps    | 111000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.1        |\n",
      "|    explained_variance | 0.15         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 22199        |\n",
      "|    policy_loss        | -0.0223      |\n",
      "|    reward             | 0.0019171219 |\n",
      "|    std                | 37.8         |\n",
      "|    value_loss         | 1.87e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 22300        |\n",
      "|    time_elapsed       | 352          |\n",
      "|    total_timesteps    | 111500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.1        |\n",
      "|    explained_variance | 0.0303       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 22299        |\n",
      "|    policy_loss        | -0.00369     |\n",
      "|    reward             | 0.0017311265 |\n",
      "|    std                | 38.5         |\n",
      "|    value_loss         | 0.000132     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 22400        |\n",
      "|    time_elapsed       | 354          |\n",
      "|    total_timesteps    | 112000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.2        |\n",
      "|    explained_variance | -0.898       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 22399        |\n",
      "|    policy_loss        | -0.0401      |\n",
      "|    reward             | 0.0065332144 |\n",
      "|    std                | 39.4         |\n",
      "|    value_loss         | 0.000153     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 22500       |\n",
      "|    time_elapsed       | 355         |\n",
      "|    total_timesteps    | 112500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.2       |\n",
      "|    explained_variance | -0.393      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22499       |\n",
      "|    policy_loss        | 0.0965      |\n",
      "|    reward             | -0.02151364 |\n",
      "|    std                | 40.8        |\n",
      "|    value_loss         | 9.83e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 22600        |\n",
      "|    time_elapsed       | 357          |\n",
      "|    total_timesteps    | 113000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.3        |\n",
      "|    explained_variance | -0.0459      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 22599        |\n",
      "|    policy_loss        | -0.216       |\n",
      "|    reward             | -0.038451537 |\n",
      "|    std                | 42.3         |\n",
      "|    value_loss         | 0.000468     |\n",
      "----------------------------------------\n",
      "day: 2833, episode: 40\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 21596.14\n",
      "total_reward: 11596.14\n",
      "total_cost: 16.70\n",
      "total_trades: 5655\n",
      "Sharpe: 0.433\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 22700        |\n",
      "|    time_elapsed       | 359          |\n",
      "|    total_timesteps    | 113500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.3        |\n",
      "|    explained_variance | -0.0541      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 22699        |\n",
      "|    policy_loss        | -0.135       |\n",
      "|    reward             | -0.002400013 |\n",
      "|    std                | 43.3         |\n",
      "|    value_loss         | 0.000198     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 22800         |\n",
      "|    time_elapsed       | 360           |\n",
      "|    total_timesteps    | 114000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.4         |\n",
      "|    explained_variance | -5.2          |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 22799         |\n",
      "|    policy_loss        | -0.173        |\n",
      "|    reward             | -0.0011320114 |\n",
      "|    std                | 44.4          |\n",
      "|    value_loss         | 0.000393      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 22900       |\n",
      "|    time_elapsed       | 362         |\n",
      "|    total_timesteps    | 114500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.4       |\n",
      "|    explained_variance | 0.139       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22899       |\n",
      "|    policy_loss        | -0.621      |\n",
      "|    reward             | -0.20235468 |\n",
      "|    std                | 45.3        |\n",
      "|    value_loss         | 0.00467     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 23000      |\n",
      "|    time_elapsed       | 364        |\n",
      "|    total_timesteps    | 115000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.5      |\n",
      "|    explained_variance | 0.255      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 22999      |\n",
      "|    policy_loss        | 0.171      |\n",
      "|    reward             | 0.09826925 |\n",
      "|    std                | 46.1       |\n",
      "|    value_loss         | 0.00128    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 23100      |\n",
      "|    time_elapsed       | 365        |\n",
      "|    total_timesteps    | 115500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.5      |\n",
      "|    explained_variance | 4.89e-06   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 23099      |\n",
      "|    policy_loss        | 1.67       |\n",
      "|    reward             | 0.07063706 |\n",
      "|    std                | 46.3       |\n",
      "|    value_loss         | 0.0392     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 23200      |\n",
      "|    time_elapsed       | 367        |\n",
      "|    total_timesteps    | 116000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.5      |\n",
      "|    explained_variance | 0.126      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 23199      |\n",
      "|    policy_loss        | -1.76      |\n",
      "|    reward             | 0.11766604 |\n",
      "|    std                | 46.6       |\n",
      "|    value_loss         | 0.0281     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 23300         |\n",
      "|    time_elapsed       | 369           |\n",
      "|    total_timesteps    | 116500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.5         |\n",
      "|    explained_variance | -46.6         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 23299         |\n",
      "|    policy_loss        | 0.0516        |\n",
      "|    reward             | -0.0058748727 |\n",
      "|    std                | 47            |\n",
      "|    value_loss         | 0.00119       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 23400       |\n",
      "|    time_elapsed       | 370         |\n",
      "|    total_timesteps    | 117000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.5       |\n",
      "|    explained_variance | 0.873       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 23399       |\n",
      "|    policy_loss        | 0.0244      |\n",
      "|    reward             | 0.002212507 |\n",
      "|    std                | 47.6        |\n",
      "|    value_loss         | 9.51e-06    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 23500       |\n",
      "|    time_elapsed       | 372         |\n",
      "|    total_timesteps    | 117500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.6       |\n",
      "|    explained_variance | 0.0781      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 23499       |\n",
      "|    policy_loss        | -0.309      |\n",
      "|    reward             | 0.026263407 |\n",
      "|    std                | 48.6        |\n",
      "|    value_loss         | 0.00124     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 23600        |\n",
      "|    time_elapsed       | 373          |\n",
      "|    total_timesteps    | 118000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.6        |\n",
      "|    explained_variance | 0.0858       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23599        |\n",
      "|    policy_loss        | 0.249        |\n",
      "|    reward             | -0.024002507 |\n",
      "|    std                | 49.6         |\n",
      "|    value_loss         | 0.00104      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 23700        |\n",
      "|    time_elapsed       | 375          |\n",
      "|    total_timesteps    | 118500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.6        |\n",
      "|    explained_variance | 0.0391       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23699        |\n",
      "|    policy_loss        | -2.34        |\n",
      "|    reward             | -0.048666686 |\n",
      "|    std                | 50.1         |\n",
      "|    value_loss         | 0.0589       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 23800      |\n",
      "|    time_elapsed       | 376        |\n",
      "|    total_timesteps    | 119000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.6      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 23799      |\n",
      "|    policy_loss        | -0.519     |\n",
      "|    reward             | 0.00310791 |\n",
      "|    std                | 50.5       |\n",
      "|    value_loss         | 0.00927    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 23900         |\n",
      "|    time_elapsed       | 378           |\n",
      "|    total_timesteps    | 119500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.7         |\n",
      "|    explained_variance | 1.6e-05       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 23899         |\n",
      "|    policy_loss        | 0.0584        |\n",
      "|    reward             | -0.0045584254 |\n",
      "|    std                | 51            |\n",
      "|    value_loss         | 0.000212      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 24000       |\n",
      "|    time_elapsed       | 379         |\n",
      "|    total_timesteps    | 120000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.7       |\n",
      "|    explained_variance | 0.355       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 23999       |\n",
      "|    policy_loss        | -0.0369     |\n",
      "|    reward             | 0.031137025 |\n",
      "|    std                | 51.9        |\n",
      "|    value_loss         | 0.000274    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 24100       |\n",
      "|    time_elapsed       | 381         |\n",
      "|    total_timesteps    | 120500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.7       |\n",
      "|    explained_variance | 0.0127      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 24099       |\n",
      "|    policy_loss        | 1.27        |\n",
      "|    reward             | -0.12919419 |\n",
      "|    std                | 52.8        |\n",
      "|    value_loss         | 0.0157      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 315       |\n",
      "|    iterations         | 24200     |\n",
      "|    time_elapsed       | 382       |\n",
      "|    total_timesteps    | 121000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -10.8     |\n",
      "|    explained_variance | 0.237     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 24199     |\n",
      "|    policy_loss        | -1.03     |\n",
      "|    reward             | 0.1103516 |\n",
      "|    std                | 53.5      |\n",
      "|    value_loss         | 0.0107    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 24300      |\n",
      "|    time_elapsed       | 384        |\n",
      "|    total_timesteps    | 121500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.8      |\n",
      "|    explained_variance | 0.141      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 24299      |\n",
      "|    policy_loss        | 0.132      |\n",
      "|    reward             | 0.15792711 |\n",
      "|    std                | 53.9       |\n",
      "|    value_loss         | 0.0025     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 24400       |\n",
      "|    time_elapsed       | 386         |\n",
      "|    total_timesteps    | 122000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.8       |\n",
      "|    explained_variance | -0.416      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 24399       |\n",
      "|    policy_loss        | 0.0429      |\n",
      "|    reward             | 0.002402995 |\n",
      "|    std                | 53.8        |\n",
      "|    value_loss         | 2.9e-05     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 24500        |\n",
      "|    time_elapsed       | 388          |\n",
      "|    total_timesteps    | 122500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.8        |\n",
      "|    explained_variance | 0.675        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 24499        |\n",
      "|    policy_loss        | 0.0476       |\n",
      "|    reward             | -0.014851948 |\n",
      "|    std                | 54.8         |\n",
      "|    value_loss         | 2.89e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 24600       |\n",
      "|    time_elapsed       | 389         |\n",
      "|    total_timesteps    | 123000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.9       |\n",
      "|    explained_variance | 0.528       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 24599       |\n",
      "|    policy_loss        | -0.27       |\n",
      "|    reward             | 0.032015957 |\n",
      "|    std                | 56          |\n",
      "|    value_loss         | 0.00062     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 24700         |\n",
      "|    time_elapsed       | 391           |\n",
      "|    total_timesteps    | 123500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.9         |\n",
      "|    explained_variance | -0.019        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 24699         |\n",
      "|    policy_loss        | -0.142        |\n",
      "|    reward             | -0.0151600065 |\n",
      "|    std                | 58.1          |\n",
      "|    value_loss         | 0.000241      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 24800       |\n",
      "|    time_elapsed       | 392         |\n",
      "|    total_timesteps    | 124000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11         |\n",
      "|    explained_variance | -0.0144     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 24799       |\n",
      "|    policy_loss        | 0.995       |\n",
      "|    reward             | 0.015280898 |\n",
      "|    std                | 60.3        |\n",
      "|    value_loss         | 0.00863     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 24900        |\n",
      "|    time_elapsed       | 394          |\n",
      "|    total_timesteps    | 124500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11          |\n",
      "|    explained_variance | 0.01         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 24899        |\n",
      "|    policy_loss        | 0.493        |\n",
      "|    reward             | -0.105924025 |\n",
      "|    std                | 61.3         |\n",
      "|    value_loss         | 0.00316      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 25000        |\n",
      "|    time_elapsed       | 396          |\n",
      "|    total_timesteps    | 125000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.1        |\n",
      "|    explained_variance | 0.131        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 24999        |\n",
      "|    policy_loss        | -0.0619      |\n",
      "|    reward             | -0.017264532 |\n",
      "|    std                | 61.9         |\n",
      "|    value_loss         | 5.88e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 25100         |\n",
      "|    time_elapsed       | 397           |\n",
      "|    total_timesteps    | 125500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11.1         |\n",
      "|    explained_variance | 0.177         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 25099         |\n",
      "|    policy_loss        | -0.0755       |\n",
      "|    reward             | -0.0078085563 |\n",
      "|    std                | 63            |\n",
      "|    value_loss         | 0.000479      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 25200       |\n",
      "|    time_elapsed       | 399         |\n",
      "|    total_timesteps    | 126000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.1       |\n",
      "|    explained_variance | -0.0121     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25199       |\n",
      "|    policy_loss        | 1.41        |\n",
      "|    reward             | -0.09922724 |\n",
      "|    std                | 64          |\n",
      "|    value_loss         | 0.0252      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 25300       |\n",
      "|    time_elapsed       | 400         |\n",
      "|    total_timesteps    | 126500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.2       |\n",
      "|    explained_variance | -0.000129   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25299       |\n",
      "|    policy_loss        | 0.966       |\n",
      "|    reward             | -0.09148964 |\n",
      "|    std                | 65          |\n",
      "|    value_loss         | 0.0101      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 25400         |\n",
      "|    time_elapsed       | 401           |\n",
      "|    total_timesteps    | 127000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11.2         |\n",
      "|    explained_variance | 0.0048        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 25399         |\n",
      "|    policy_loss        | -4.51         |\n",
      "|    reward             | -0.0059251785 |\n",
      "|    std                | 66.5          |\n",
      "|    value_loss         | 0.224         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 25500        |\n",
      "|    time_elapsed       | 403          |\n",
      "|    total_timesteps    | 127500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.2        |\n",
      "|    explained_variance | 0.128        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 25499        |\n",
      "|    policy_loss        | 1.06         |\n",
      "|    reward             | -0.083102755 |\n",
      "|    std                | 66.7         |\n",
      "|    value_loss         | 0.0633       |\n",
      "----------------------------------------\n",
      "day: 2833, episode: 45\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 115944.26\n",
      "total_reward: 105944.26\n",
      "total_cost: 38.17\n",
      "total_trades: 5659\n",
      "Sharpe: 0.801\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 25600       |\n",
      "|    time_elapsed       | 404         |\n",
      "|    total_timesteps    | 128000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.2       |\n",
      "|    explained_variance | 0.42        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25599       |\n",
      "|    policy_loss        | 0.264       |\n",
      "|    reward             | -0.01773375 |\n",
      "|    std                | 67.6        |\n",
      "|    value_loss         | 0.000609    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 25700       |\n",
      "|    time_elapsed       | 406         |\n",
      "|    total_timesteps    | 128500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.3       |\n",
      "|    explained_variance | -0.00669    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25699       |\n",
      "|    policy_loss        | -0.0565     |\n",
      "|    reward             | 0.033541232 |\n",
      "|    std                | 69.1        |\n",
      "|    value_loss         | 0.000111    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 25800        |\n",
      "|    time_elapsed       | 407          |\n",
      "|    total_timesteps    | 129000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.3        |\n",
      "|    explained_variance | -0.0398      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 25799        |\n",
      "|    policy_loss        | -0.532       |\n",
      "|    reward             | -0.036200378 |\n",
      "|    std                | 71.2         |\n",
      "|    value_loss         | 0.00212      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 25900       |\n",
      "|    time_elapsed       | 409         |\n",
      "|    total_timesteps    | 129500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25899       |\n",
      "|    policy_loss        | -0.933      |\n",
      "|    reward             | -0.11186194 |\n",
      "|    std                | 71.8        |\n",
      "|    value_loss         | 0.00848     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 26000       |\n",
      "|    time_elapsed       | 410         |\n",
      "|    total_timesteps    | 130000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.4       |\n",
      "|    explained_variance | 0.275       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25999       |\n",
      "|    policy_loss        | -0.503      |\n",
      "|    reward             | 0.089518204 |\n",
      "|    std                | 72.4        |\n",
      "|    value_loss         | 0.0059      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 26100        |\n",
      "|    time_elapsed       | 412          |\n",
      "|    total_timesteps    | 130500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.4        |\n",
      "|    explained_variance | 0.435        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26099        |\n",
      "|    policy_loss        | -0.179       |\n",
      "|    reward             | 0.0063384147 |\n",
      "|    std                | 72.9         |\n",
      "|    value_loss         | 0.000312     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 26200        |\n",
      "|    time_elapsed       | 413          |\n",
      "|    total_timesteps    | 131000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.4        |\n",
      "|    explained_variance | -4.07        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26199        |\n",
      "|    policy_loss        | -0.418       |\n",
      "|    reward             | -0.008707431 |\n",
      "|    std                | 73.9         |\n",
      "|    value_loss         | 0.00208      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 26300        |\n",
      "|    time_elapsed       | 415          |\n",
      "|    total_timesteps    | 131500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.5        |\n",
      "|    explained_variance | -0.502       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26299        |\n",
      "|    policy_loss        | -0.318       |\n",
      "|    reward             | -0.009543546 |\n",
      "|    std                | 75.8         |\n",
      "|    value_loss         | 0.00115      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 26400       |\n",
      "|    time_elapsed       | 417         |\n",
      "|    total_timesteps    | 132000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.5       |\n",
      "|    explained_variance | 0.68        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 26399       |\n",
      "|    policy_loss        | -0.568      |\n",
      "|    reward             | 0.029048337 |\n",
      "|    std                | 76.6        |\n",
      "|    value_loss         | 0.00302     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 26500        |\n",
      "|    time_elapsed       | 418          |\n",
      "|    total_timesteps    | 132500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.5        |\n",
      "|    explained_variance | -0.106       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26499        |\n",
      "|    policy_loss        | 1.55         |\n",
      "|    reward             | -0.031600147 |\n",
      "|    std                | 77.1         |\n",
      "|    value_loss         | 0.0201       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 26600       |\n",
      "|    time_elapsed       | 420         |\n",
      "|    total_timesteps    | 133000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.5       |\n",
      "|    explained_variance | -0.0452     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 26599       |\n",
      "|    policy_loss        | 0.96        |\n",
      "|    reward             | -0.08982079 |\n",
      "|    std                | 78.2        |\n",
      "|    value_loss         | 0.014       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 26700        |\n",
      "|    time_elapsed       | 421          |\n",
      "|    total_timesteps    | 133500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.5        |\n",
      "|    explained_variance | 0.535        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26699        |\n",
      "|    policy_loss        | -0.187       |\n",
      "|    reward             | -0.008152203 |\n",
      "|    std                | 79.1         |\n",
      "|    value_loss         | 0.000383     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 26800       |\n",
      "|    time_elapsed       | 423         |\n",
      "|    total_timesteps    | 134000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.6       |\n",
      "|    explained_variance | 0.22        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 26799       |\n",
      "|    policy_loss        | 0.394       |\n",
      "|    reward             | -0.01114114 |\n",
      "|    std                | 80.6        |\n",
      "|    value_loss         | 0.00187     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 26900        |\n",
      "|    time_elapsed       | 425          |\n",
      "|    total_timesteps    | 134500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.6        |\n",
      "|    explained_variance | 0.0219       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26899        |\n",
      "|    policy_loss        | 2.18         |\n",
      "|    reward             | -0.043871593 |\n",
      "|    std                | 81.5         |\n",
      "|    value_loss         | 0.0453       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 27000       |\n",
      "|    time_elapsed       | 426         |\n",
      "|    total_timesteps    | 135000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.6       |\n",
      "|    explained_variance | 0.461       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 26999       |\n",
      "|    policy_loss        | 0.326       |\n",
      "|    reward             | -0.02833912 |\n",
      "|    std                | 81.9        |\n",
      "|    value_loss         | 0.00493     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 27100        |\n",
      "|    time_elapsed       | 428          |\n",
      "|    total_timesteps    | 135500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.6        |\n",
      "|    explained_variance | 0.238        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27099        |\n",
      "|    policy_loss        | -2.76        |\n",
      "|    reward             | -0.099483415 |\n",
      "|    std                | 81.3         |\n",
      "|    value_loss         | 0.0673       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 27200      |\n",
      "|    time_elapsed       | 430        |\n",
      "|    total_timesteps    | 136000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.6      |\n",
      "|    explained_variance | 0.14       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 27199      |\n",
      "|    policy_loss        | -6.91      |\n",
      "|    reward             | 0.21975848 |\n",
      "|    std                | 81.4       |\n",
      "|    value_loss         | 0.404      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 27300        |\n",
      "|    time_elapsed       | 431          |\n",
      "|    total_timesteps    | 136500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.6        |\n",
      "|    explained_variance | -7.72e-05    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27299        |\n",
      "|    policy_loss        | 0.0827       |\n",
      "|    reward             | 0.0036423618 |\n",
      "|    std                | 82.5         |\n",
      "|    value_loss         | 7.72e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 27400        |\n",
      "|    time_elapsed       | 433          |\n",
      "|    total_timesteps    | 137000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.7        |\n",
      "|    explained_variance | 0.466        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27399        |\n",
      "|    policy_loss        | -0.196       |\n",
      "|    reward             | -0.002715651 |\n",
      "|    std                | 83.9         |\n",
      "|    value_loss         | 0.000342     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 27500      |\n",
      "|    time_elapsed       | 434        |\n",
      "|    total_timesteps    | 137500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.7      |\n",
      "|    explained_variance | -0.162     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 27499      |\n",
      "|    policy_loss        | 0.152      |\n",
      "|    reward             | 0.01689503 |\n",
      "|    std                | 85.3       |\n",
      "|    value_loss         | 0.000323   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 27600        |\n",
      "|    time_elapsed       | 436          |\n",
      "|    total_timesteps    | 138000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.7        |\n",
      "|    explained_variance | -0.419       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27599        |\n",
      "|    policy_loss        | 0.279        |\n",
      "|    reward             | -0.038408823 |\n",
      "|    std                | 88.1         |\n",
      "|    value_loss         | 0.000594     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 27700       |\n",
      "|    time_elapsed       | 437         |\n",
      "|    total_timesteps    | 138500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.8       |\n",
      "|    explained_variance | 0.00187     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 27699       |\n",
      "|    policy_loss        | 0.217       |\n",
      "|    reward             | 0.028184047 |\n",
      "|    std                | 88.4        |\n",
      "|    value_loss         | 0.000639    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 27800        |\n",
      "|    time_elapsed       | 439          |\n",
      "|    total_timesteps    | 139000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.8        |\n",
      "|    explained_variance | 0.00433      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27799        |\n",
      "|    policy_loss        | -0.039       |\n",
      "|    reward             | -0.007267816 |\n",
      "|    std                | 89.6         |\n",
      "|    value_loss         | 0.000133     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 27900        |\n",
      "|    time_elapsed       | 440          |\n",
      "|    total_timesteps    | 139500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.8        |\n",
      "|    explained_variance | 0.121        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27899        |\n",
      "|    policy_loss        | 0.105        |\n",
      "|    reward             | 0.0009938652 |\n",
      "|    std                | 90.8         |\n",
      "|    value_loss         | 0.000534     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 28000        |\n",
      "|    time_elapsed       | 442          |\n",
      "|    total_timesteps    | 140000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.8        |\n",
      "|    explained_variance | -0.189       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27999        |\n",
      "|    policy_loss        | -0.937       |\n",
      "|    reward             | -0.053646997 |\n",
      "|    std                | 92.2         |\n",
      "|    value_loss         | 0.0077       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 28100       |\n",
      "|    time_elapsed       | 443         |\n",
      "|    total_timesteps    | 140500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.9       |\n",
      "|    explained_variance | 0.124       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 28099       |\n",
      "|    policy_loss        | -0.144      |\n",
      "|    reward             | 0.089514874 |\n",
      "|    std                | 93.5        |\n",
      "|    value_loss         | 0.00288     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 28200      |\n",
      "|    time_elapsed       | 445        |\n",
      "|    total_timesteps    | 141000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.9      |\n",
      "|    explained_variance | 0.00557    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 28199      |\n",
      "|    policy_loss        | 0.558      |\n",
      "|    reward             | 0.05882329 |\n",
      "|    std                | 95.1       |\n",
      "|    value_loss         | 0.00997    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 28300        |\n",
      "|    time_elapsed       | 447          |\n",
      "|    total_timesteps    | 141500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.9        |\n",
      "|    explained_variance | 0.152        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28299        |\n",
      "|    policy_loss        | -1.3         |\n",
      "|    reward             | -0.035058897 |\n",
      "|    std                | 95.5         |\n",
      "|    value_loss         | 0.0828       |\n",
      "----------------------------------------\n",
      "day: 2833, episode: 50\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 154585.78\n",
      "total_reward: 144585.78\n",
      "total_cost: 16.07\n",
      "total_trades: 5664\n",
      "Sharpe: 0.959\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 28400       |\n",
      "|    time_elapsed       | 448         |\n",
      "|    total_timesteps    | 142000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.9       |\n",
      "|    explained_variance | -0.544      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 28399       |\n",
      "|    policy_loss        | -0.392      |\n",
      "|    reward             | 0.016534839 |\n",
      "|    std                | 96.8        |\n",
      "|    value_loss         | 0.00125     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 28500        |\n",
      "|    time_elapsed       | 450          |\n",
      "|    total_timesteps    | 142500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12          |\n",
      "|    explained_variance | -0.18        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28499        |\n",
      "|    policy_loss        | 0.188        |\n",
      "|    reward             | 0.0033802693 |\n",
      "|    std                | 98.2         |\n",
      "|    value_loss         | 0.000277     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 28600        |\n",
      "|    time_elapsed       | 452          |\n",
      "|    total_timesteps    | 143000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12          |\n",
      "|    explained_variance | 0.548        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28599        |\n",
      "|    policy_loss        | -0.0993      |\n",
      "|    reward             | -0.016321637 |\n",
      "|    std                | 100          |\n",
      "|    value_loss         | 0.000113     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 28700       |\n",
      "|    time_elapsed       | 453         |\n",
      "|    total_timesteps    | 143500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12         |\n",
      "|    explained_variance | -0.0257     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 28699       |\n",
      "|    policy_loss        | -0.0706     |\n",
      "|    reward             | 0.011291679 |\n",
      "|    std                | 102         |\n",
      "|    value_loss         | 0.00144     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 28800        |\n",
      "|    time_elapsed       | 455          |\n",
      "|    total_timesteps    | 144000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.1        |\n",
      "|    explained_variance | 0.0735       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28799        |\n",
      "|    policy_loss        | -1.88        |\n",
      "|    reward             | -0.058583852 |\n",
      "|    std                | 104          |\n",
      "|    value_loss         | 0.0278       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 28900        |\n",
      "|    time_elapsed       | 457          |\n",
      "|    total_timesteps    | 144500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28899        |\n",
      "|    policy_loss        | -2.13        |\n",
      "|    reward             | -0.032984436 |\n",
      "|    std                | 107          |\n",
      "|    value_loss         | 0.0276       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 29000        |\n",
      "|    time_elapsed       | 458          |\n",
      "|    total_timesteps    | 145000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.1        |\n",
      "|    explained_variance | -0.0656      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28999        |\n",
      "|    policy_loss        | 0.255        |\n",
      "|    reward             | -0.018327469 |\n",
      "|    std                | 107          |\n",
      "|    value_loss         | 0.0012       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 29100        |\n",
      "|    time_elapsed       | 460          |\n",
      "|    total_timesteps    | 145500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.2        |\n",
      "|    explained_variance | 0.148        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29099        |\n",
      "|    policy_loss        | -0.51        |\n",
      "|    reward             | -0.057805132 |\n",
      "|    std                | 109          |\n",
      "|    value_loss         | 0.00292      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 29200        |\n",
      "|    time_elapsed       | 461          |\n",
      "|    total_timesteps    | 146000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.2        |\n",
      "|    explained_variance | 0.117        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29199        |\n",
      "|    policy_loss        | -0.00108     |\n",
      "|    reward             | -0.028523529 |\n",
      "|    std                | 112          |\n",
      "|    value_loss         | 0.000131     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 29300        |\n",
      "|    time_elapsed       | 463          |\n",
      "|    total_timesteps    | 146500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.3        |\n",
      "|    explained_variance | 0.451        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29299        |\n",
      "|    policy_loss        | 0.19         |\n",
      "|    reward             | 9.998321e-05 |\n",
      "|    std                | 114          |\n",
      "|    value_loss         | 0.000517     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 29400      |\n",
      "|    time_elapsed       | 464        |\n",
      "|    total_timesteps    | 147000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.3      |\n",
      "|    explained_variance | 0.389      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 29399      |\n",
      "|    policy_loss        | 0.407      |\n",
      "|    reward             | 0.03095827 |\n",
      "|    std                | 116        |\n",
      "|    value_loss         | 0.0017     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 316           |\n",
      "|    iterations         | 29500         |\n",
      "|    time_elapsed       | 466           |\n",
      "|    total_timesteps    | 147500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.3         |\n",
      "|    explained_variance | -0.000205     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 29499         |\n",
      "|    policy_loss        | 0.113         |\n",
      "|    reward             | -0.0016466316 |\n",
      "|    std                | 117           |\n",
      "|    value_loss         | 0.000105      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 316           |\n",
      "|    iterations         | 29600         |\n",
      "|    time_elapsed       | 467           |\n",
      "|    total_timesteps    | 148000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.4         |\n",
      "|    explained_variance | 0.56          |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 29599         |\n",
      "|    policy_loss        | -0.22         |\n",
      "|    reward             | -0.0030666562 |\n",
      "|    std                | 120           |\n",
      "|    value_loss         | 0.000344      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 316           |\n",
      "|    iterations         | 29700         |\n",
      "|    time_elapsed       | 469           |\n",
      "|    total_timesteps    | 148500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.4         |\n",
      "|    explained_variance | 0.175         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 29699         |\n",
      "|    policy_loss        | -0.0508       |\n",
      "|    reward             | -0.0031238894 |\n",
      "|    std                | 122           |\n",
      "|    value_loss         | 0.000201      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 29800        |\n",
      "|    time_elapsed       | 470          |\n",
      "|    total_timesteps    | 149000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.5        |\n",
      "|    explained_variance | 0.105        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29799        |\n",
      "|    policy_loss        | 0.558        |\n",
      "|    reward             | -0.028293893 |\n",
      "|    std                | 126          |\n",
      "|    value_loss         | 0.00388      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 29900      |\n",
      "|    time_elapsed       | 472        |\n",
      "|    total_timesteps    | 149500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | 0.0685     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 29899      |\n",
      "|    policy_loss        | 0.294      |\n",
      "|    reward             | 0.03696308 |\n",
      "|    std                | 127        |\n",
      "|    value_loss         | 0.013      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 30000      |\n",
      "|    time_elapsed       | 473        |\n",
      "|    total_timesteps    | 150000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | 0.000535   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 29999      |\n",
      "|    policy_loss        | -2.74      |\n",
      "|    reward             | 0.08220427 |\n",
      "|    std                | 126        |\n",
      "|    value_loss         | 0.0684     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 30100       |\n",
      "|    time_elapsed       | 475         |\n",
      "|    total_timesteps    | 150500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.5       |\n",
      "|    explained_variance | 0.861       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30099       |\n",
      "|    policy_loss        | -0.0777     |\n",
      "|    reward             | 0.013877023 |\n",
      "|    std                | 127         |\n",
      "|    value_loss         | 7.67e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 30200        |\n",
      "|    time_elapsed       | 477          |\n",
      "|    total_timesteps    | 151000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.5        |\n",
      "|    explained_variance | -0.047       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 30199        |\n",
      "|    policy_loss        | -0.00538     |\n",
      "|    reward             | 0.0054515772 |\n",
      "|    std                | 128          |\n",
      "|    value_loss         | 7.39e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 30300      |\n",
      "|    time_elapsed       | 478        |\n",
      "|    total_timesteps    | 151500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | 0.0983     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 30299      |\n",
      "|    policy_loss        | 0.0201     |\n",
      "|    reward             | 0.06642237 |\n",
      "|    std                | 131        |\n",
      "|    value_loss         | 0.000199   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 30400        |\n",
      "|    time_elapsed       | 480          |\n",
      "|    total_timesteps    | 152000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.6        |\n",
      "|    explained_variance | 0.00934      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 30399        |\n",
      "|    policy_loss        | 0.948        |\n",
      "|    reward             | 0.0068409257 |\n",
      "|    std                | 133          |\n",
      "|    value_loss         | 0.00786      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 30500       |\n",
      "|    time_elapsed       | 481         |\n",
      "|    total_timesteps    | 152500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.6       |\n",
      "|    explained_variance | 0.463       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30499       |\n",
      "|    policy_loss        | -2.7        |\n",
      "|    reward             | -0.24723715 |\n",
      "|    std                | 133         |\n",
      "|    value_loss         | 0.0474      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 30600      |\n",
      "|    time_elapsed       | 483        |\n",
      "|    total_timesteps    | 153000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | 0.16       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 30599      |\n",
      "|    policy_loss        | -1.11      |\n",
      "|    reward             | 0.14350727 |\n",
      "|    std                | 135        |\n",
      "|    value_loss         | 0.0264     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 316           |\n",
      "|    iterations         | 30700         |\n",
      "|    time_elapsed       | 485           |\n",
      "|    total_timesteps    | 153500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 30699         |\n",
      "|    policy_loss        | 0.0487        |\n",
      "|    reward             | -0.0028940206 |\n",
      "|    std                | 137           |\n",
      "|    value_loss         | 8.61e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 30800       |\n",
      "|    time_elapsed       | 486         |\n",
      "|    total_timesteps    | 154000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30799       |\n",
      "|    policy_loss        | -0.209      |\n",
      "|    reward             | 0.016652763 |\n",
      "|    std                | 140         |\n",
      "|    value_loss         | 0.000266    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 316           |\n",
      "|    iterations         | 30900         |\n",
      "|    time_elapsed       | 488           |\n",
      "|    total_timesteps    | 154500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.7         |\n",
      "|    explained_variance | 0.0543        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 30899         |\n",
      "|    policy_loss        | -0.167        |\n",
      "|    reward             | -0.0013330834 |\n",
      "|    std                | 143           |\n",
      "|    value_loss         | 0.000336      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 31000        |\n",
      "|    time_elapsed       | 490          |\n",
      "|    total_timesteps    | 155000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.8        |\n",
      "|    explained_variance | -0.341       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 30999        |\n",
      "|    policy_loss        | 0.00482      |\n",
      "|    reward             | 0.0027604774 |\n",
      "|    std                | 148          |\n",
      "|    value_loss         | 0.000136     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 316           |\n",
      "|    iterations         | 31100         |\n",
      "|    time_elapsed       | 491           |\n",
      "|    total_timesteps    | 155500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.8         |\n",
      "|    explained_variance | 0.473         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 31099         |\n",
      "|    policy_loss        | -0.101        |\n",
      "|    reward             | -0.0044314303 |\n",
      "|    std                | 152           |\n",
      "|    value_loss         | 0.000199      |\n",
      "-----------------------------------------\n",
      "day: 2833, episode: 55\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 29232.98\n",
      "total_reward: 19232.98\n",
      "total_cost: 12.32\n",
      "total_trades: 5665\n",
      "Sharpe: 0.512\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 316           |\n",
      "|    iterations         | 31200         |\n",
      "|    time_elapsed       | 493           |\n",
      "|    total_timesteps    | 156000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.9         |\n",
      "|    explained_variance | 0.49          |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 31199         |\n",
      "|    policy_loss        | 0.0733        |\n",
      "|    reward             | -0.0027890597 |\n",
      "|    std                | 155           |\n",
      "|    value_loss         | 4.75e-05      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 316            |\n",
      "|    iterations         | 31300          |\n",
      "|    time_elapsed       | 494            |\n",
      "|    total_timesteps    | 156500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -12.9          |\n",
      "|    explained_variance | -0.943         |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 31299          |\n",
      "|    policy_loss        | -0.0659        |\n",
      "|    reward             | -0.00040765363 |\n",
      "|    std                | 160            |\n",
      "|    value_loss         | 0.000128       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 31400       |\n",
      "|    time_elapsed       | 496         |\n",
      "|    total_timesteps    | 157000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13         |\n",
      "|    explained_variance | 0.0236      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 31399       |\n",
      "|    policy_loss        | 0.0809      |\n",
      "|    reward             | 0.011083036 |\n",
      "|    std                | 164         |\n",
      "|    value_loss         | 0.00013     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 31500       |\n",
      "|    time_elapsed       | 497         |\n",
      "|    total_timesteps    | 157500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.1       |\n",
      "|    explained_variance | -0.152      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 31499       |\n",
      "|    policy_loss        | 0.34        |\n",
      "|    reward             | 0.019882781 |\n",
      "|    std                | 168         |\n",
      "|    value_loss         | 0.0024      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 31600        |\n",
      "|    time_elapsed       | 499          |\n",
      "|    total_timesteps    | 158000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.1        |\n",
      "|    explained_variance | -0.014       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 31599        |\n",
      "|    policy_loss        | 2.86         |\n",
      "|    reward             | -0.017592829 |\n",
      "|    std                | 170          |\n",
      "|    value_loss         | 0.0543       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 31700       |\n",
      "|    time_elapsed       | 501         |\n",
      "|    total_timesteps    | 158500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.1       |\n",
      "|    explained_variance | 0.000525    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 31699       |\n",
      "|    policy_loss        | -0.5        |\n",
      "|    reward             | 0.035002835 |\n",
      "|    std                | 170         |\n",
      "|    value_loss         | 0.0294      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 31800        |\n",
      "|    time_elapsed       | 502          |\n",
      "|    total_timesteps    | 159000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.1        |\n",
      "|    explained_variance | 0.76         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 31799        |\n",
      "|    policy_loss        | -0.251       |\n",
      "|    reward             | -0.008099433 |\n",
      "|    std                | 173          |\n",
      "|    value_loss         | 0.000454     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 31900        |\n",
      "|    time_elapsed       | 504          |\n",
      "|    total_timesteps    | 159500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.2        |\n",
      "|    explained_variance | 0.133        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 31899        |\n",
      "|    policy_loss        | -0.132       |\n",
      "|    reward             | -0.008774008 |\n",
      "|    std                | 176          |\n",
      "|    value_loss         | 0.000178     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 32000      |\n",
      "|    time_elapsed       | 505        |\n",
      "|    total_timesteps    | 160000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.2      |\n",
      "|    explained_variance | 0.713      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 31999      |\n",
      "|    policy_loss        | 0.0564     |\n",
      "|    reward             | 0.07214272 |\n",
      "|    std                | 181        |\n",
      "|    value_loss         | 0.000122   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 32100        |\n",
      "|    time_elapsed       | 507          |\n",
      "|    total_timesteps    | 160500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.2        |\n",
      "|    explained_variance | 0.0928       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32099        |\n",
      "|    policy_loss        | 0.342        |\n",
      "|    reward             | -0.016455166 |\n",
      "|    std                | 184          |\n",
      "|    value_loss         | 0.000774     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 316           |\n",
      "|    iterations         | 32200         |\n",
      "|    time_elapsed       | 509           |\n",
      "|    total_timesteps    | 161000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.3         |\n",
      "|    explained_variance | 0.571         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 32199         |\n",
      "|    policy_loss        | -0.154        |\n",
      "|    reward             | -0.0132054435 |\n",
      "|    std                | 187           |\n",
      "|    value_loss         | 0.00181       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 32300       |\n",
      "|    time_elapsed       | 510         |\n",
      "|    total_timesteps    | 161500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 32299       |\n",
      "|    policy_loss        | -2.12       |\n",
      "|    reward             | 0.019288931 |\n",
      "|    std                | 188         |\n",
      "|    value_loss         | 0.0326      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 32400        |\n",
      "|    time_elapsed       | 512          |\n",
      "|    total_timesteps    | 162000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.3        |\n",
      "|    explained_variance | 0.0813       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32399        |\n",
      "|    policy_loss        | 0.496        |\n",
      "|    reward             | -0.010434597 |\n",
      "|    std                | 192          |\n",
      "|    value_loss         | 0.00187      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 316           |\n",
      "|    iterations         | 32500         |\n",
      "|    time_elapsed       | 513           |\n",
      "|    total_timesteps    | 162500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.4         |\n",
      "|    explained_variance | 0.00534       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 32499         |\n",
      "|    policy_loss        | 0.282         |\n",
      "|    reward             | 0.00028295745 |\n",
      "|    std                | 195           |\n",
      "|    value_loss         | 0.00145       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 32600       |\n",
      "|    time_elapsed       | 515         |\n",
      "|    total_timesteps    | 163000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.4       |\n",
      "|    explained_variance | -0.000155   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 32599       |\n",
      "|    policy_loss        | -0.812      |\n",
      "|    reward             | 0.021297403 |\n",
      "|    std                | 199         |\n",
      "|    value_loss         | 0.00735     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 32700       |\n",
      "|    time_elapsed       | 517         |\n",
      "|    total_timesteps    | 163500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.4       |\n",
      "|    explained_variance | 0.749       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 32699       |\n",
      "|    policy_loss        | 0.411       |\n",
      "|    reward             | 0.068062626 |\n",
      "|    std                | 201         |\n",
      "|    value_loss         | 0.00154     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 32800      |\n",
      "|    time_elapsed       | 518        |\n",
      "|    total_timesteps    | 164000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.4      |\n",
      "|    explained_variance | 0.435      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 32799      |\n",
      "|    policy_loss        | -0.258     |\n",
      "|    reward             | 0.03244042 |\n",
      "|    std                | 201        |\n",
      "|    value_loss         | 0.00315    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 32900        |\n",
      "|    time_elapsed       | 520          |\n",
      "|    total_timesteps    | 164500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | -0.844       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32899        |\n",
      "|    policy_loss        | -0.0639      |\n",
      "|    reward             | -0.019779049 |\n",
      "|    std                | 203          |\n",
      "|    value_loss         | 0.00021      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 33000       |\n",
      "|    time_elapsed       | 521         |\n",
      "|    total_timesteps    | 165000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.4       |\n",
      "|    explained_variance | 0.121       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 32999       |\n",
      "|    policy_loss        | -0.183      |\n",
      "|    reward             | 0.016125899 |\n",
      "|    std                | 205         |\n",
      "|    value_loss         | 0.000252    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 33100      |\n",
      "|    time_elapsed       | 523        |\n",
      "|    total_timesteps    | 165500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.5      |\n",
      "|    explained_variance | -0.0538    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 33099      |\n",
      "|    policy_loss        | -0.227     |\n",
      "|    reward             | 0.06300049 |\n",
      "|    std                | 207        |\n",
      "|    value_loss         | 0.00184    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 33200       |\n",
      "|    time_elapsed       | 524         |\n",
      "|    total_timesteps    | 166000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.5       |\n",
      "|    explained_variance | 0.335       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 33199       |\n",
      "|    policy_loss        | -1.84       |\n",
      "|    reward             | -0.01820669 |\n",
      "|    std                | 209         |\n",
      "|    value_loss         | 0.0416      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 33300      |\n",
      "|    time_elapsed       | 526        |\n",
      "|    total_timesteps    | 166500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.5      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 33299      |\n",
      "|    policy_loss        | -1.72      |\n",
      "|    reward             | 0.24334536 |\n",
      "|    std                | 208        |\n",
      "|    value_loss         | 0.022      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 33400      |\n",
      "|    time_elapsed       | 528        |\n",
      "|    total_timesteps    | 167000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.4      |\n",
      "|    explained_variance | 0.0829     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 33399      |\n",
      "|    policy_loss        | 9.18       |\n",
      "|    reward             | 0.45573938 |\n",
      "|    std                | 204        |\n",
      "|    value_loss         | 0.521      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 33500        |\n",
      "|    time_elapsed       | 529          |\n",
      "|    total_timesteps    | 167500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.5        |\n",
      "|    explained_variance | 0.051        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 33499        |\n",
      "|    policy_loss        | 0.675        |\n",
      "|    reward             | -0.018698942 |\n",
      "|    std                | 208          |\n",
      "|    value_loss         | 0.00311      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 316           |\n",
      "|    iterations         | 33600         |\n",
      "|    time_elapsed       | 531           |\n",
      "|    total_timesteps    | 168000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.5         |\n",
      "|    explained_variance | 0.0272        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 33599         |\n",
      "|    policy_loss        | 0.373         |\n",
      "|    reward             | -0.0039216606 |\n",
      "|    std                | 211           |\n",
      "|    value_loss         | 0.000919      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 33700      |\n",
      "|    time_elapsed       | 532        |\n",
      "|    total_timesteps    | 168500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.5      |\n",
      "|    explained_variance | 0.47       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 33699      |\n",
      "|    policy_loss        | 0.219      |\n",
      "|    reward             | 0.04099091 |\n",
      "|    std                | 215        |\n",
      "|    value_loss         | 0.000392   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 33800      |\n",
      "|    time_elapsed       | 534        |\n",
      "|    total_timesteps    | 169000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.6      |\n",
      "|    explained_variance | 0.342      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 33799      |\n",
      "|    policy_loss        | 0.624      |\n",
      "|    reward             | -0.1386101 |\n",
      "|    std                | 219        |\n",
      "|    value_loss         | 0.00215    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 33900      |\n",
      "|    time_elapsed       | 535        |\n",
      "|    total_timesteps    | 169500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.6      |\n",
      "|    explained_variance | 0.646      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 33899      |\n",
      "|    policy_loss        | -1.01      |\n",
      "|    reward             | 0.15199707 |\n",
      "|    std                | 223        |\n",
      "|    value_loss         | 0.00648    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 34000      |\n",
      "|    time_elapsed       | 537        |\n",
      "|    total_timesteps    | 170000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.6      |\n",
      "|    explained_variance | 0.312      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 33999      |\n",
      "|    policy_loss        | -2.47      |\n",
      "|    reward             | 0.08290651 |\n",
      "|    std                | 223        |\n",
      "|    value_loss         | 0.0371     |\n",
      "--------------------------------------\n",
      "day: 2833, episode: 60\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 93609.30\n",
      "total_reward: 83609.30\n",
      "total_cost: 10.68\n",
      "total_trades: 5664\n",
      "Sharpe: 0.780\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 316           |\n",
      "|    iterations         | 34100         |\n",
      "|    time_elapsed       | 539           |\n",
      "|    total_timesteps    | 170500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.7         |\n",
      "|    explained_variance | 0.12          |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 34099         |\n",
      "|    policy_loss        | 0.138         |\n",
      "|    reward             | -0.0005669252 |\n",
      "|    std                | 227           |\n",
      "|    value_loss         | 0.000185      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 34200        |\n",
      "|    time_elapsed       | 540          |\n",
      "|    total_timesteps    | 171000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.7        |\n",
      "|    explained_variance | 0.00137      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 34199        |\n",
      "|    policy_loss        | 0.11         |\n",
      "|    reward             | -0.018858656 |\n",
      "|    std                | 231          |\n",
      "|    value_loss         | 0.000227     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 34300       |\n",
      "|    time_elapsed       | 542         |\n",
      "|    total_timesteps    | 171500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.8       |\n",
      "|    explained_variance | 0.49        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34299       |\n",
      "|    policy_loss        | -0.0686     |\n",
      "|    reward             | 0.027186912 |\n",
      "|    std                | 238         |\n",
      "|    value_loss         | 0.000621    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 34400      |\n",
      "|    time_elapsed       | 543        |\n",
      "|    total_timesteps    | 172000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.8      |\n",
      "|    explained_variance | 0.673      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 34399      |\n",
      "|    policy_loss        | 0.528      |\n",
      "|    reward             | 0.01263562 |\n",
      "|    std                | 240        |\n",
      "|    value_loss         | 0.00211    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 34500        |\n",
      "|    time_elapsed       | 545          |\n",
      "|    total_timesteps    | 172500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.8        |\n",
      "|    explained_variance | 0.487        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 34499        |\n",
      "|    policy_loss        | 0.334        |\n",
      "|    reward             | -0.009789135 |\n",
      "|    std                | 244          |\n",
      "|    value_loss         | 0.000944     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 34600       |\n",
      "|    time_elapsed       | 547         |\n",
      "|    total_timesteps    | 173000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.9       |\n",
      "|    explained_variance | 0.422       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34599       |\n",
      "|    policy_loss        | 0.136       |\n",
      "|    reward             | 0.006944549 |\n",
      "|    std                | 253         |\n",
      "|    value_loss         | 0.000152    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 34700        |\n",
      "|    time_elapsed       | 548          |\n",
      "|    total_timesteps    | 173500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.9        |\n",
      "|    explained_variance | -2.76        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 34699        |\n",
      "|    policy_loss        | 0.0113       |\n",
      "|    reward             | -0.020316524 |\n",
      "|    std                | 256          |\n",
      "|    value_loss         | 2.41e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 34800        |\n",
      "|    time_elapsed       | 550          |\n",
      "|    total_timesteps    | 174000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 34799        |\n",
      "|    policy_loss        | -0.75        |\n",
      "|    reward             | -0.044698723 |\n",
      "|    std                | 263          |\n",
      "|    value_loss         | 0.00282      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 34900      |\n",
      "|    time_elapsed       | 552        |\n",
      "|    total_timesteps    | 174500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14        |\n",
      "|    explained_variance | 0.192      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 34899      |\n",
      "|    policy_loss        | -1.26      |\n",
      "|    reward             | 0.08417167 |\n",
      "|    std                | 267        |\n",
      "|    value_loss         | 0.0132     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 35000       |\n",
      "|    time_elapsed       | 553         |\n",
      "|    total_timesteps    | 175000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14         |\n",
      "|    explained_variance | 0.082       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34999       |\n",
      "|    policy_loss        | 0.92        |\n",
      "|    reward             | -0.19125524 |\n",
      "|    std                | 269         |\n",
      "|    value_loss         | 0.00652     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 35100      |\n",
      "|    time_elapsed       | 555        |\n",
      "|    total_timesteps    | 175500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 35099      |\n",
      "|    policy_loss        | 2.99       |\n",
      "|    reward             | 0.25944006 |\n",
      "|    std                | 267        |\n",
      "|    value_loss         | 0.0568     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 35200       |\n",
      "|    time_elapsed       | 556         |\n",
      "|    total_timesteps    | 176000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14         |\n",
      "|    explained_variance | 0.102       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35199       |\n",
      "|    policy_loss        | -0.329      |\n",
      "|    reward             | 0.005934819 |\n",
      "|    std                | 269         |\n",
      "|    value_loss         | 0.000719    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 35300        |\n",
      "|    time_elapsed       | 558          |\n",
      "|    total_timesteps    | 176500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14          |\n",
      "|    explained_variance | -0.0834      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 35299        |\n",
      "|    policy_loss        | 0.182        |\n",
      "|    reward             | 0.0004681017 |\n",
      "|    std                | 273          |\n",
      "|    value_loss         | 0.000289     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 316           |\n",
      "|    iterations         | 35400         |\n",
      "|    time_elapsed       | 559           |\n",
      "|    total_timesteps    | 177000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.1         |\n",
      "|    explained_variance | 0.464         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 35399         |\n",
      "|    policy_loss        | -0.0306       |\n",
      "|    reward             | -0.0021371383 |\n",
      "|    std                | 279           |\n",
      "|    value_loss         | 0.000727      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 35500       |\n",
      "|    time_elapsed       | 561         |\n",
      "|    total_timesteps    | 177500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.1       |\n",
      "|    explained_variance | 0.543       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35499       |\n",
      "|    policy_loss        | -0.0811     |\n",
      "|    reward             | 0.052900407 |\n",
      "|    std                | 286         |\n",
      "|    value_loss         | 0.000298    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 316            |\n",
      "|    iterations         | 35600          |\n",
      "|    time_elapsed       | 562            |\n",
      "|    total_timesteps    | 178000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -14.1          |\n",
      "|    explained_variance | 0.345          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 35599          |\n",
      "|    policy_loss        | -0.0219        |\n",
      "|    reward             | -0.00026334915 |\n",
      "|    std                | 286            |\n",
      "|    value_loss         | 0.0016         |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 35700       |\n",
      "|    time_elapsed       | 564         |\n",
      "|    total_timesteps    | 178500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.1       |\n",
      "|    explained_variance | 0.164       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35699       |\n",
      "|    policy_loss        | -1.76       |\n",
      "|    reward             | 0.021216221 |\n",
      "|    std                | 287         |\n",
      "|    value_loss         | 0.0261      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 35800       |\n",
      "|    time_elapsed       | 566         |\n",
      "|    total_timesteps    | 179000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.2       |\n",
      "|    explained_variance | 0.375       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35799       |\n",
      "|    policy_loss        | 0.407       |\n",
      "|    reward             | 0.005405093 |\n",
      "|    std                | 291         |\n",
      "|    value_loss         | 0.000903    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 35900       |\n",
      "|    time_elapsed       | 567         |\n",
      "|    total_timesteps    | 179500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.2       |\n",
      "|    explained_variance | 0.303       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35899       |\n",
      "|    policy_loss        | 0.253       |\n",
      "|    reward             | 0.010937115 |\n",
      "|    std                | 296         |\n",
      "|    value_loss         | 0.000344    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 36000        |\n",
      "|    time_elapsed       | 569          |\n",
      "|    total_timesteps    | 180000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.2        |\n",
      "|    explained_variance | 0.126        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 35999        |\n",
      "|    policy_loss        | -1.4         |\n",
      "|    reward             | -0.057408072 |\n",
      "|    std                | 304          |\n",
      "|    value_loss         | 0.0141       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 36100       |\n",
      "|    time_elapsed       | 570         |\n",
      "|    total_timesteps    | 180500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.3       |\n",
      "|    explained_variance | 0.362       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36099       |\n",
      "|    policy_loss        | 0.925       |\n",
      "|    reward             | -0.06658109 |\n",
      "|    std                | 306         |\n",
      "|    value_loss         | 0.00537     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 36200        |\n",
      "|    time_elapsed       | 572          |\n",
      "|    total_timesteps    | 181000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.3        |\n",
      "|    explained_variance | 0.51         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36199        |\n",
      "|    policy_loss        | -0.786       |\n",
      "|    reward             | -0.011577578 |\n",
      "|    std                | 308          |\n",
      "|    value_loss         | 0.00322      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 36300       |\n",
      "|    time_elapsed       | 574         |\n",
      "|    total_timesteps    | 181500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.3       |\n",
      "|    explained_variance | -0.782      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36299       |\n",
      "|    policy_loss        | -0.193      |\n",
      "|    reward             | 0.002752812 |\n",
      "|    std                | 313         |\n",
      "|    value_loss         | 0.000206    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 316           |\n",
      "|    iterations         | 36400         |\n",
      "|    time_elapsed       | 575           |\n",
      "|    total_timesteps    | 182000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.3         |\n",
      "|    explained_variance | -4.64         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 36399         |\n",
      "|    policy_loss        | 0.195         |\n",
      "|    reward             | -0.0040169745 |\n",
      "|    std                | 319           |\n",
      "|    value_loss         | 0.00028       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 36500        |\n",
      "|    time_elapsed       | 577          |\n",
      "|    total_timesteps    | 182500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36499        |\n",
      "|    policy_loss        | -0.0332      |\n",
      "|    reward             | -0.008700891 |\n",
      "|    std                | 330          |\n",
      "|    value_loss         | 1.03e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 36600        |\n",
      "|    time_elapsed       | 578          |\n",
      "|    total_timesteps    | 183000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.5        |\n",
      "|    explained_variance | -1.06        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36599        |\n",
      "|    policy_loss        | 0.176        |\n",
      "|    reward             | -0.014114698 |\n",
      "|    std                | 342          |\n",
      "|    value_loss         | 0.000179     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 36700       |\n",
      "|    time_elapsed       | 580         |\n",
      "|    total_timesteps    | 183500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.6       |\n",
      "|    explained_variance | -0.978      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36699       |\n",
      "|    policy_loss        | -0.0723     |\n",
      "|    reward             | -0.03615536 |\n",
      "|    std                | 357         |\n",
      "|    value_loss         | 6.51e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 316           |\n",
      "|    iterations         | 36800         |\n",
      "|    time_elapsed       | 581           |\n",
      "|    total_timesteps    | 184000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.6         |\n",
      "|    explained_variance | 0.0509        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 36799         |\n",
      "|    policy_loss        | -0.0785       |\n",
      "|    reward             | -0.0020280129 |\n",
      "|    std                | 368           |\n",
      "|    value_loss         | 0.000123      |\n",
      "-----------------------------------------\n",
      "day: 2833, episode: 65\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 11282.71\n",
      "total_reward: 1282.71\n",
      "total_cost: 13.78\n",
      "total_trades: 4199\n",
      "Sharpe: 0.309\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 36900       |\n",
      "|    time_elapsed       | 583         |\n",
      "|    total_timesteps    | 184500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.7       |\n",
      "|    explained_variance | 0.141       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36899       |\n",
      "|    policy_loss        | 0.0628      |\n",
      "|    reward             | 0.018699212 |\n",
      "|    std                | 374         |\n",
      "|    value_loss         | 0.0005      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 37000        |\n",
      "|    time_elapsed       | 585          |\n",
      "|    total_timesteps    | 185000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.7        |\n",
      "|    explained_variance | 0.212        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36999        |\n",
      "|    policy_loss        | 0.935        |\n",
      "|    reward             | -0.015408637 |\n",
      "|    std                | 381          |\n",
      "|    value_loss         | 0.00384      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 37100       |\n",
      "|    time_elapsed       | 587         |\n",
      "|    total_timesteps    | 185500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.8       |\n",
      "|    explained_variance | 0.103       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37099       |\n",
      "|    policy_loss        | 0.407       |\n",
      "|    reward             | 0.031099733 |\n",
      "|    std                | 390         |\n",
      "|    value_loss         | 0.00115     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 37200         |\n",
      "|    time_elapsed       | 588           |\n",
      "|    total_timesteps    | 186000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 37199         |\n",
      "|    policy_loss        | 0.411         |\n",
      "|    reward             | -0.0024921035 |\n",
      "|    std                | 401           |\n",
      "|    value_loss         | 0.0011        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 37300        |\n",
      "|    time_elapsed       | 590          |\n",
      "|    total_timesteps    | 186500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.8        |\n",
      "|    explained_variance | 0.147        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 37299        |\n",
      "|    policy_loss        | 0.337        |\n",
      "|    reward             | -0.019047156 |\n",
      "|    std                | 411          |\n",
      "|    value_loss         | 0.00156      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 37400       |\n",
      "|    time_elapsed       | 591         |\n",
      "|    total_timesteps    | 187000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.9       |\n",
      "|    explained_variance | -0.0102     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37399       |\n",
      "|    policy_loss        | 2.23        |\n",
      "|    reward             | -0.04599762 |\n",
      "|    std                | 414         |\n",
      "|    value_loss         | 0.0247      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 37500        |\n",
      "|    time_elapsed       | 593          |\n",
      "|    total_timesteps    | 187500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.9        |\n",
      "|    explained_variance | 0.024        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 37499        |\n",
      "|    policy_loss        | 0.68         |\n",
      "|    reward             | -0.005643457 |\n",
      "|    std                | 419          |\n",
      "|    value_loss         | 0.00428      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 37600       |\n",
      "|    time_elapsed       | 594         |\n",
      "|    total_timesteps    | 188000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37599       |\n",
      "|    policy_loss        | 0.0671      |\n",
      "|    reward             | 0.029085567 |\n",
      "|    std                | 425         |\n",
      "|    value_loss         | 0.000314    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 37700       |\n",
      "|    time_elapsed       | 596         |\n",
      "|    total_timesteps    | 188500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15         |\n",
      "|    explained_variance | 0.019       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37699       |\n",
      "|    policy_loss        | -6.61       |\n",
      "|    reward             | -0.27765563 |\n",
      "|    std                | 436         |\n",
      "|    value_loss         | 0.231       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 37800       |\n",
      "|    time_elapsed       | 597         |\n",
      "|    total_timesteps    | 189000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15         |\n",
      "|    explained_variance | 0.595       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37799       |\n",
      "|    policy_loss        | -2.05       |\n",
      "|    reward             | 0.028422466 |\n",
      "|    std                | 444         |\n",
      "|    value_loss         | 0.0216      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 37900       |\n",
      "|    time_elapsed       | 599         |\n",
      "|    total_timesteps    | 189500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15         |\n",
      "|    explained_variance | 0.0401      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37899       |\n",
      "|    policy_loss        | -2.28       |\n",
      "|    reward             | -0.38386655 |\n",
      "|    std                | 444         |\n",
      "|    value_loss         | 0.0291      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 38000       |\n",
      "|    time_elapsed       | 601         |\n",
      "|    total_timesteps    | 190000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15         |\n",
      "|    explained_variance | -3.59       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37999       |\n",
      "|    policy_loss        | -0.91       |\n",
      "|    reward             | 0.017474962 |\n",
      "|    std                | 443         |\n",
      "|    value_loss         | 0.00427     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 38100         |\n",
      "|    time_elapsed       | 602           |\n",
      "|    total_timesteps    | 190500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15           |\n",
      "|    explained_variance | -0.782        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 38099         |\n",
      "|    policy_loss        | 0.227         |\n",
      "|    reward             | -0.0004905615 |\n",
      "|    std                | 448           |\n",
      "|    value_loss         | 0.00034       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 38200       |\n",
      "|    time_elapsed       | 604         |\n",
      "|    total_timesteps    | 191000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.1       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38199       |\n",
      "|    policy_loss        | 0.0391      |\n",
      "|    reward             | 0.010050712 |\n",
      "|    std                | 457         |\n",
      "|    value_loss         | 4.17e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 38300        |\n",
      "|    time_elapsed       | 605          |\n",
      "|    total_timesteps    | 191500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.1        |\n",
      "|    explained_variance | -0.639       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 38299        |\n",
      "|    policy_loss        | -0.2         |\n",
      "|    reward             | -0.097176105 |\n",
      "|    std                | 463          |\n",
      "|    value_loss         | 0.000309     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 38400       |\n",
      "|    time_elapsed       | 607         |\n",
      "|    total_timesteps    | 192000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.1       |\n",
      "|    explained_variance | 0.256       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38399       |\n",
      "|    policy_loss        | 0.411       |\n",
      "|    reward             | 0.013437059 |\n",
      "|    std                | 476         |\n",
      "|    value_loss         | 0.00121     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 38500       |\n",
      "|    time_elapsed       | 609         |\n",
      "|    total_timesteps    | 192500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38499       |\n",
      "|    policy_loss        | 0.396       |\n",
      "|    reward             | 0.031049533 |\n",
      "|    std                | 476         |\n",
      "|    value_loss         | 0.000773    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 38600       |\n",
      "|    time_elapsed       | 610         |\n",
      "|    total_timesteps    | 193000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.2       |\n",
      "|    explained_variance | -0.0571     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38599       |\n",
      "|    policy_loss        | -0.406      |\n",
      "|    reward             | -0.08951159 |\n",
      "|    std                | 481         |\n",
      "|    value_loss         | 0.000878    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 38700       |\n",
      "|    time_elapsed       | 612         |\n",
      "|    total_timesteps    | 193500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.2       |\n",
      "|    explained_variance | 0.429       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38699       |\n",
      "|    policy_loss        | 0.0465      |\n",
      "|    reward             | 0.008784048 |\n",
      "|    std                | 488         |\n",
      "|    value_loss         | 0.000357    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 38800      |\n",
      "|    time_elapsed       | 613        |\n",
      "|    total_timesteps    | 194000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.2      |\n",
      "|    explained_variance | 0.0794     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 38799      |\n",
      "|    policy_loss        | 1.21       |\n",
      "|    reward             | 0.12869473 |\n",
      "|    std                | 497        |\n",
      "|    value_loss         | 0.0146     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 38900       |\n",
      "|    time_elapsed       | 615         |\n",
      "|    total_timesteps    | 194500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.2       |\n",
      "|    explained_variance | 0.0292      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38899       |\n",
      "|    policy_loss        | 1.34        |\n",
      "|    reward             | 0.122802176 |\n",
      "|    std                | 500         |\n",
      "|    value_loss         | 0.00964     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 39000       |\n",
      "|    time_elapsed       | 616         |\n",
      "|    total_timesteps    | 195000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.3       |\n",
      "|    explained_variance | 0.674       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38999       |\n",
      "|    policy_loss        | -0.899      |\n",
      "|    reward             | -0.14887965 |\n",
      "|    std                | 511         |\n",
      "|    value_loss         | 0.00558     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 316       |\n",
      "|    iterations         | 39100     |\n",
      "|    time_elapsed       | 618       |\n",
      "|    total_timesteps    | 195500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.3     |\n",
      "|    explained_variance | 0.205     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 39099     |\n",
      "|    policy_loss        | -7.08     |\n",
      "|    reward             | 0.2677072 |\n",
      "|    std                | 514       |\n",
      "|    value_loss         | 0.358     |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 39200        |\n",
      "|    time_elapsed       | 619          |\n",
      "|    total_timesteps    | 196000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.3        |\n",
      "|    explained_variance | 0.116        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39199        |\n",
      "|    policy_loss        | 0.787        |\n",
      "|    reward             | 0.0067518037 |\n",
      "|    std                | 520          |\n",
      "|    value_loss         | 0.00369      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 39300      |\n",
      "|    time_elapsed       | 621        |\n",
      "|    total_timesteps    | 196500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.3      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 39299      |\n",
      "|    policy_loss        | 0.492      |\n",
      "|    reward             | 0.03547928 |\n",
      "|    std                | 529        |\n",
      "|    value_loss         | 0.0011     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 39400        |\n",
      "|    time_elapsed       | 623          |\n",
      "|    total_timesteps    | 197000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.4        |\n",
      "|    explained_variance | -6.08e-05    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39399        |\n",
      "|    policy_loss        | -1.8         |\n",
      "|    reward             | -0.021275586 |\n",
      "|    std                | 541          |\n",
      "|    value_loss         | 0.0147       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 39500       |\n",
      "|    time_elapsed       | 624         |\n",
      "|    total_timesteps    | 197500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.4       |\n",
      "|    explained_variance | 0.579       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 39499       |\n",
      "|    policy_loss        | -0.689      |\n",
      "|    reward             | -0.01382108 |\n",
      "|    std                | 549         |\n",
      "|    value_loss         | 0.00306     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 39600       |\n",
      "|    time_elapsed       | 626         |\n",
      "|    total_timesteps    | 198000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.5       |\n",
      "|    explained_variance | 0.617       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 39599       |\n",
      "|    policy_loss        | 0.327       |\n",
      "|    reward             | 0.057884082 |\n",
      "|    std                | 562         |\n",
      "|    value_loss         | 0.00065     |\n",
      "---------------------------------------\n",
      "day: 2833, episode: 70\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 133649.75\n",
      "total_reward: 123649.75\n",
      "total_cost: 20.99\n",
      "total_trades: 5657\n",
      "Sharpe: 0.934\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 316           |\n",
      "|    iterations         | 39700         |\n",
      "|    time_elapsed       | 628           |\n",
      "|    total_timesteps    | 198500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.5         |\n",
      "|    explained_variance | -0.378        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 39699         |\n",
      "|    policy_loss        | -0.564        |\n",
      "|    reward             | -0.0037508104 |\n",
      "|    std                | 564           |\n",
      "|    value_loss         | 0.00161       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 39800       |\n",
      "|    time_elapsed       | 629         |\n",
      "|    total_timesteps    | 199000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.5       |\n",
      "|    explained_variance | -2.15       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 39799       |\n",
      "|    policy_loss        | -0.663      |\n",
      "|    reward             | 0.012470779 |\n",
      "|    std                | 566         |\n",
      "|    value_loss         | 0.00203     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 316           |\n",
      "|    iterations         | 39900         |\n",
      "|    time_elapsed       | 631           |\n",
      "|    total_timesteps    | 199500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.5         |\n",
      "|    explained_variance | 0.316         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 39899         |\n",
      "|    policy_loss        | 1.03          |\n",
      "|    reward             | -0.0070311297 |\n",
      "|    std                | 576           |\n",
      "|    value_loss         | 0.00584       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 40000        |\n",
      "|    time_elapsed       | 632          |\n",
      "|    total_timesteps    | 200000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.5        |\n",
      "|    explained_variance | -1.33        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39999        |\n",
      "|    policy_loss        | -0.00293     |\n",
      "|    reward             | -0.028630273 |\n",
      "|    std                | 581          |\n",
      "|    value_loss         | 0.000601     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 40100       |\n",
      "|    time_elapsed       | 634         |\n",
      "|    total_timesteps    | 200500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.6       |\n",
      "|    explained_variance | 0.173       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40099       |\n",
      "|    policy_loss        | -0.151      |\n",
      "|    reward             | 0.039125215 |\n",
      "|    std                | 586         |\n",
      "|    value_loss         | 0.000618    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 40200       |\n",
      "|    time_elapsed       | 635         |\n",
      "|    total_timesteps    | 201000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.5       |\n",
      "|    explained_variance | 0.884       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40199       |\n",
      "|    policy_loss        | -0.357      |\n",
      "|    reward             | -0.01289823 |\n",
      "|    std                | 583         |\n",
      "|    value_loss         | 0.000558    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 315            |\n",
      "|    iterations         | 40300          |\n",
      "|    time_elapsed       | 637            |\n",
      "|    total_timesteps    | 201500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -15.5          |\n",
      "|    explained_variance | -0.0717        |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 40299          |\n",
      "|    policy_loss        | -0.301         |\n",
      "|    reward             | -0.00087197573 |\n",
      "|    std                | 583            |\n",
      "|    value_loss         | 0.000742       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 40400        |\n",
      "|    time_elapsed       | 639          |\n",
      "|    total_timesteps    | 202000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.6        |\n",
      "|    explained_variance | 0.909        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 40399        |\n",
      "|    policy_loss        | 0.191        |\n",
      "|    reward             | -0.004286528 |\n",
      "|    std                | 587          |\n",
      "|    value_loss         | 0.000171     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 40500         |\n",
      "|    time_elapsed       | 641           |\n",
      "|    total_timesteps    | 202500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.6         |\n",
      "|    explained_variance | 0.121         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 40499         |\n",
      "|    policy_loss        | -0.943        |\n",
      "|    reward             | -0.0045169974 |\n",
      "|    std                | 595           |\n",
      "|    value_loss         | 0.00491       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 40600       |\n",
      "|    time_elapsed       | 642         |\n",
      "|    total_timesteps    | 203000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.6       |\n",
      "|    explained_variance | 0.471       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40599       |\n",
      "|    policy_loss        | -0.493      |\n",
      "|    reward             | 0.056345634 |\n",
      "|    std                | 598         |\n",
      "|    value_loss         | 0.00177     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 40700        |\n",
      "|    time_elapsed       | 644          |\n",
      "|    total_timesteps    | 203500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.6        |\n",
      "|    explained_variance | -0.976       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 40699        |\n",
      "|    policy_loss        | -0.198       |\n",
      "|    reward             | -0.054117795 |\n",
      "|    std                | 599          |\n",
      "|    value_loss         | 0.00803      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 40800       |\n",
      "|    time_elapsed       | 645         |\n",
      "|    total_timesteps    | 204000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.6       |\n",
      "|    explained_variance | 0.252       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40799       |\n",
      "|    policy_loss        | -6.5        |\n",
      "|    reward             | -0.12846716 |\n",
      "|    std                | 600         |\n",
      "|    value_loss         | 0.205       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 40900        |\n",
      "|    time_elapsed       | 647          |\n",
      "|    total_timesteps    | 204500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.6        |\n",
      "|    explained_variance | -20          |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 40899        |\n",
      "|    policy_loss        | -0.0126      |\n",
      "|    reward             | 0.0065938276 |\n",
      "|    std                | 604          |\n",
      "|    value_loss         | 0.000486     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 41000        |\n",
      "|    time_elapsed       | 649          |\n",
      "|    total_timesteps    | 205000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.7        |\n",
      "|    explained_variance | 0.000593     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 40999        |\n",
      "|    policy_loss        | -0.264       |\n",
      "|    reward             | -0.013552377 |\n",
      "|    std                | 615          |\n",
      "|    value_loss         | 0.000333     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 315       |\n",
      "|    iterations         | 41100     |\n",
      "|    time_elapsed       | 650       |\n",
      "|    total_timesteps    | 205500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.7     |\n",
      "|    explained_variance | -9.54e-07 |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 41099     |\n",
      "|    policy_loss        | 0.252     |\n",
      "|    reward             | -0.103073 |\n",
      "|    std                | 616       |\n",
      "|    value_loss         | 0.000625  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 41200      |\n",
      "|    time_elapsed       | 652        |\n",
      "|    total_timesteps    | 206000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.7      |\n",
      "|    explained_variance | 0.0854     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 41199      |\n",
      "|    policy_loss        | -0.851     |\n",
      "|    reward             | 0.22596389 |\n",
      "|    std                | 619        |\n",
      "|    value_loss         | 0.00436    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 41300        |\n",
      "|    time_elapsed       | 654          |\n",
      "|    total_timesteps    | 206500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.7        |\n",
      "|    explained_variance | 0.112        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41299        |\n",
      "|    policy_loss        | -0.239       |\n",
      "|    reward             | -0.034688417 |\n",
      "|    std                | 632          |\n",
      "|    value_loss         | 0.00986      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 41400        |\n",
      "|    time_elapsed       | 655          |\n",
      "|    total_timesteps    | 207000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.7        |\n",
      "|    explained_variance | -0.182       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41399        |\n",
      "|    policy_loss        | 0.337        |\n",
      "|    reward             | 0.0066778194 |\n",
      "|    std                | 642          |\n",
      "|    value_loss         | 0.000731     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 41500         |\n",
      "|    time_elapsed       | 657           |\n",
      "|    total_timesteps    | 207500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.8         |\n",
      "|    explained_variance | -1.83         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 41499         |\n",
      "|    policy_loss        | -0.00737      |\n",
      "|    reward             | 0.00073556823 |\n",
      "|    std                | 653           |\n",
      "|    value_loss         | 2.11e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 41600        |\n",
      "|    time_elapsed       | 658          |\n",
      "|    total_timesteps    | 208000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.8        |\n",
      "|    explained_variance | -0.294       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41599        |\n",
      "|    policy_loss        | 0.767        |\n",
      "|    reward             | 0.0059901555 |\n",
      "|    std                | 663          |\n",
      "|    value_loss         | 0.00379      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 41700       |\n",
      "|    time_elapsed       | 660         |\n",
      "|    total_timesteps    | 208500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.9       |\n",
      "|    explained_variance | -0.136      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 41699       |\n",
      "|    policy_loss        | -0.0721     |\n",
      "|    reward             | -0.03420824 |\n",
      "|    std                | 686         |\n",
      "|    value_loss         | 0.000149    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 41800      |\n",
      "|    time_elapsed       | 661        |\n",
      "|    total_timesteps    | 209000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.9      |\n",
      "|    explained_variance | 0.32       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 41799      |\n",
      "|    policy_loss        | -0.154     |\n",
      "|    reward             | 0.00711548 |\n",
      "|    std                | 700        |\n",
      "|    value_loss         | 0.000232   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 41900       |\n",
      "|    time_elapsed       | 663         |\n",
      "|    total_timesteps    | 209500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 41899       |\n",
      "|    policy_loss        | -0.181      |\n",
      "|    reward             | 0.025913049 |\n",
      "|    std                | 714         |\n",
      "|    value_loss         | 0.00124     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 42000        |\n",
      "|    time_elapsed       | 665          |\n",
      "|    total_timesteps    | 210000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16          |\n",
      "|    explained_variance | 0.201        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41999        |\n",
      "|    policy_loss        | 0.918        |\n",
      "|    reward             | -0.014378739 |\n",
      "|    std                | 724          |\n",
      "|    value_loss         | 0.00388      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 42100       |\n",
      "|    time_elapsed       | 666         |\n",
      "|    total_timesteps    | 210500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16         |\n",
      "|    explained_variance | 0.273       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 42099       |\n",
      "|    policy_loss        | 0.154       |\n",
      "|    reward             | 0.014166037 |\n",
      "|    std                | 743         |\n",
      "|    value_loss         | 0.00028     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 42200       |\n",
      "|    time_elapsed       | 668         |\n",
      "|    total_timesteps    | 211000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.1       |\n",
      "|    explained_variance | 0.133       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 42199       |\n",
      "|    policy_loss        | 1.69        |\n",
      "|    reward             | 0.036775883 |\n",
      "|    std                | 752         |\n",
      "|    value_loss         | 0.0122      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 42300        |\n",
      "|    time_elapsed       | 669          |\n",
      "|    total_timesteps    | 211500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.1        |\n",
      "|    explained_variance | 0.384        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42299        |\n",
      "|    policy_loss        | 1.09         |\n",
      "|    reward             | -0.011601596 |\n",
      "|    std                | 761          |\n",
      "|    value_loss         | 0.0103       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 42400      |\n",
      "|    time_elapsed       | 671        |\n",
      "|    total_timesteps    | 212000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.1      |\n",
      "|    explained_variance | 0.123      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 42399      |\n",
      "|    policy_loss        | -1.9       |\n",
      "|    reward             | 0.19865446 |\n",
      "|    std                | 760        |\n",
      "|    value_loss         | 0.0175     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 42500      |\n",
      "|    time_elapsed       | 673        |\n",
      "|    total_timesteps    | 212500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16        |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 42499      |\n",
      "|    policy_loss        | -1.97      |\n",
      "|    reward             | 0.41273132 |\n",
      "|    std                | 747        |\n",
      "|    value_loss         | 0.0287     |\n",
      "--------------------------------------\n",
      "day: 2833, episode: 75\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 187805.76\n",
      "total_reward: 177805.76\n",
      "total_cost: 83.21\n",
      "total_trades: 5661\n",
      "Sharpe: 0.984\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 42600        |\n",
      "|    time_elapsed       | 674          |\n",
      "|    total_timesteps    | 213000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.1        |\n",
      "|    explained_variance | -6.54        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42599        |\n",
      "|    policy_loss        | -0.0795      |\n",
      "|    reward             | 0.0074255336 |\n",
      "|    std                | 754          |\n",
      "|    value_loss         | 0.000126     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 42700        |\n",
      "|    time_elapsed       | 676          |\n",
      "|    total_timesteps    | 213500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.1        |\n",
      "|    explained_variance | -2.72        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42699        |\n",
      "|    policy_loss        | 0.0623       |\n",
      "|    reward             | -0.008943333 |\n",
      "|    std                | 765          |\n",
      "|    value_loss         | 5.65e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 42800       |\n",
      "|    time_elapsed       | 678         |\n",
      "|    total_timesteps    | 214000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.1       |\n",
      "|    explained_variance | -0.0175     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 42799       |\n",
      "|    policy_loss        | 0.394       |\n",
      "|    reward             | -0.07951573 |\n",
      "|    std                | 772         |\n",
      "|    value_loss         | 0.0021      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 42900       |\n",
      "|    time_elapsed       | 679         |\n",
      "|    total_timesteps    | 214500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.2       |\n",
      "|    explained_variance | 0.014       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 42899       |\n",
      "|    policy_loss        | 0.864       |\n",
      "|    reward             | 0.022459941 |\n",
      "|    std                | 788         |\n",
      "|    value_loss         | 0.00441     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 315       |\n",
      "|    iterations         | 43000     |\n",
      "|    time_elapsed       | 681       |\n",
      "|    total_timesteps    | 215000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.2     |\n",
      "|    explained_variance | 0.214     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 42999     |\n",
      "|    policy_loss        | 0.562     |\n",
      "|    reward             | 0.0182331 |\n",
      "|    std                | 801       |\n",
      "|    value_loss         | 0.00704   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 43100       |\n",
      "|    time_elapsed       | 682         |\n",
      "|    total_timesteps    | 215500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.2       |\n",
      "|    explained_variance | 0.466       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43099       |\n",
      "|    policy_loss        | -0.512      |\n",
      "|    reward             | 0.013405331 |\n",
      "|    std                | 814         |\n",
      "|    value_loss         | 0.00109     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 43200        |\n",
      "|    time_elapsed       | 684          |\n",
      "|    total_timesteps    | 216000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.2        |\n",
      "|    explained_variance | -0.218       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 43199        |\n",
      "|    policy_loss        | 0.00218      |\n",
      "|    reward             | -0.027663752 |\n",
      "|    std                | 822          |\n",
      "|    value_loss         | 5.24e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 43300        |\n",
      "|    time_elapsed       | 686          |\n",
      "|    total_timesteps    | 216500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.3        |\n",
      "|    explained_variance | 0.435        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 43299        |\n",
      "|    policy_loss        | 1.72         |\n",
      "|    reward             | 0.0020716942 |\n",
      "|    std                | 833          |\n",
      "|    value_loss         | 0.0119       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 43400      |\n",
      "|    time_elapsed       | 687        |\n",
      "|    total_timesteps    | 217000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.3      |\n",
      "|    explained_variance | -0.181     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 43399      |\n",
      "|    policy_loss        | -0.609     |\n",
      "|    reward             | -0.0168065 |\n",
      "|    std                | 844        |\n",
      "|    value_loss         | 0.00225    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 43500      |\n",
      "|    time_elapsed       | 689        |\n",
      "|    total_timesteps    | 217500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.3      |\n",
      "|    explained_variance | 0.785      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 43499      |\n",
      "|    policy_loss        | -0.461     |\n",
      "|    reward             | 0.09575727 |\n",
      "|    std                | 848        |\n",
      "|    value_loss         | 0.00124    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 43600      |\n",
      "|    time_elapsed       | 690        |\n",
      "|    total_timesteps    | 218000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 43599      |\n",
      "|    policy_loss        | -0.543     |\n",
      "|    reward             | 0.04359591 |\n",
      "|    std                | 852        |\n",
      "|    value_loss         | 0.00927    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 43700        |\n",
      "|    time_elapsed       | 692          |\n",
      "|    total_timesteps    | 218500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.3        |\n",
      "|    explained_variance | 0.0965       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 43699        |\n",
      "|    policy_loss        | 0.516        |\n",
      "|    reward             | 0.0017796438 |\n",
      "|    std                | 863          |\n",
      "|    value_loss         | 0.00128      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 43800       |\n",
      "|    time_elapsed       | 693         |\n",
      "|    total_timesteps    | 219000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.4       |\n",
      "|    explained_variance | 0.279       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43799       |\n",
      "|    policy_loss        | 0.00352     |\n",
      "|    reward             | 0.005932867 |\n",
      "|    std                | 871         |\n",
      "|    value_loss         | 6.51e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 43900         |\n",
      "|    time_elapsed       | 695           |\n",
      "|    total_timesteps    | 219500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.4         |\n",
      "|    explained_variance | 0.365         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 43899         |\n",
      "|    policy_loss        | -2.13         |\n",
      "|    reward             | -0.0002553009 |\n",
      "|    std                | 884           |\n",
      "|    value_loss         | 0.0246        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 44000       |\n",
      "|    time_elapsed       | 696         |\n",
      "|    total_timesteps    | 220000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.4       |\n",
      "|    explained_variance | 0.884       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43999       |\n",
      "|    policy_loss        | 0.384       |\n",
      "|    reward             | 0.016307304 |\n",
      "|    std                | 893         |\n",
      "|    value_loss         | 0.000873    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 44100       |\n",
      "|    time_elapsed       | 698         |\n",
      "|    total_timesteps    | 220500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.4       |\n",
      "|    explained_variance | -0.497      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44099       |\n",
      "|    policy_loss        | 1.07        |\n",
      "|    reward             | -0.03708822 |\n",
      "|    std                | 890         |\n",
      "|    value_loss         | 0.0168      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 44200       |\n",
      "|    time_elapsed       | 699         |\n",
      "|    total_timesteps    | 221000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.4       |\n",
      "|    explained_variance | -2.38e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44199       |\n",
      "|    policy_loss        | -4.36       |\n",
      "|    reward             | 0.082920395 |\n",
      "|    std                | 891         |\n",
      "|    value_loss         | 0.0728      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 44300        |\n",
      "|    time_elapsed       | 701          |\n",
      "|    total_timesteps    | 221500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.4        |\n",
      "|    explained_variance | 0.0488       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44299        |\n",
      "|    policy_loss        | -0.552       |\n",
      "|    reward             | 0.0124108875 |\n",
      "|    std                | 897          |\n",
      "|    value_loss         | 0.00123      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 44400       |\n",
      "|    time_elapsed       | 703         |\n",
      "|    total_timesteps    | 222000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44399       |\n",
      "|    policy_loss        | 0.0765      |\n",
      "|    reward             | 0.014812311 |\n",
      "|    std                | 909         |\n",
      "|    value_loss         | 0.0001      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 44500       |\n",
      "|    time_elapsed       | 704         |\n",
      "|    total_timesteps    | 222500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44499       |\n",
      "|    policy_loss        | 1.27        |\n",
      "|    reward             | -0.05251754 |\n",
      "|    std                | 914         |\n",
      "|    value_loss         | 0.00885     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 44600      |\n",
      "|    time_elapsed       | 706        |\n",
      "|    total_timesteps    | 223000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.5      |\n",
      "|    explained_variance | 0.801      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 44599      |\n",
      "|    policy_loss        | 0.391      |\n",
      "|    reward             | -0.1016147 |\n",
      "|    std                | 926        |\n",
      "|    value_loss         | 0.00114    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 44700       |\n",
      "|    time_elapsed       | 708         |\n",
      "|    total_timesteps    | 223500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44699       |\n",
      "|    policy_loss        | -1.59       |\n",
      "|    reward             | -0.04324478 |\n",
      "|    std                | 931         |\n",
      "|    value_loss         | 0.0251      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 44800       |\n",
      "|    time_elapsed       | 709         |\n",
      "|    total_timesteps    | 224000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.5       |\n",
      "|    explained_variance | 0.309       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44799       |\n",
      "|    policy_loss        | -0.158      |\n",
      "|    reward             | 0.012004722 |\n",
      "|    std                | 942         |\n",
      "|    value_loss         | 0.000441    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 44900       |\n",
      "|    time_elapsed       | 711         |\n",
      "|    total_timesteps    | 224500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.5       |\n",
      "|    explained_variance | 0.141       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44899       |\n",
      "|    policy_loss        | -0.0585     |\n",
      "|    reward             | 0.033420343 |\n",
      "|    std                | 948         |\n",
      "|    value_loss         | 5.54e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 45000        |\n",
      "|    time_elapsed       | 712          |\n",
      "|    total_timesteps    | 225000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44999        |\n",
      "|    policy_loss        | -0.34        |\n",
      "|    reward             | 0.0004246208 |\n",
      "|    std                | 971          |\n",
      "|    value_loss         | 0.000585     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 45100       |\n",
      "|    time_elapsed       | 714         |\n",
      "|    total_timesteps    | 225500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.6       |\n",
      "|    explained_variance | -0.00393    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 45099       |\n",
      "|    policy_loss        | 0.0099      |\n",
      "|    reward             | 0.012681326 |\n",
      "|    std                | 989         |\n",
      "|    value_loss         | 0.000828    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 45200        |\n",
      "|    time_elapsed       | 716          |\n",
      "|    total_timesteps    | 226000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.7        |\n",
      "|    explained_variance | 0.573        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45199        |\n",
      "|    policy_loss        | -0.291       |\n",
      "|    reward             | -0.025082985 |\n",
      "|    std                | 1e+03        |\n",
      "|    value_loss         | 0.00228      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 45300       |\n",
      "|    time_elapsed       | 717         |\n",
      "|    total_timesteps    | 226500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 45299       |\n",
      "|    policy_loss        | 1.06        |\n",
      "|    reward             | 0.011701869 |\n",
      "|    std                | 995         |\n",
      "|    value_loss         | 0.00821     |\n",
      "---------------------------------------\n",
      "day: 2833, episode: 80\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 120932.78\n",
      "total_reward: 110932.78\n",
      "total_cost: 25.83\n",
      "total_trades: 5663\n",
      "Sharpe: 0.917\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 45400        |\n",
      "|    time_elapsed       | 719          |\n",
      "|    total_timesteps    | 227000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.7        |\n",
      "|    explained_variance | -0.0221      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45399        |\n",
      "|    policy_loss        | -0.258       |\n",
      "|    reward             | 0.0015047158 |\n",
      "|    std                | 1.01e+03     |\n",
      "|    value_loss         | 0.00049      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 45500       |\n",
      "|    time_elapsed       | 721         |\n",
      "|    total_timesteps    | 227500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.7       |\n",
      "|    explained_variance | 0.126       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 45499       |\n",
      "|    policy_loss        | -0.452      |\n",
      "|    reward             | 0.025596956 |\n",
      "|    std                | 1.02e+03    |\n",
      "|    value_loss         | 0.000824    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 45600       |\n",
      "|    time_elapsed       | 722         |\n",
      "|    total_timesteps    | 228000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.7       |\n",
      "|    explained_variance | 0.373       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 45599       |\n",
      "|    policy_loss        | -1.45       |\n",
      "|    reward             | -0.04521147 |\n",
      "|    std                | 1.04e+03    |\n",
      "|    value_loss         | 0.0118      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 45700      |\n",
      "|    time_elapsed       | 724        |\n",
      "|    total_timesteps    | 228500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.8      |\n",
      "|    explained_variance | 0.514      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 45699      |\n",
      "|    policy_loss        | 1.12       |\n",
      "|    reward             | 0.04006931 |\n",
      "|    std                | 1.06e+03   |\n",
      "|    value_loss         | 0.00558    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 45800       |\n",
      "|    time_elapsed       | 726         |\n",
      "|    total_timesteps    | 229000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.8       |\n",
      "|    explained_variance | 0.00281     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 45799       |\n",
      "|    policy_loss        | 4.33        |\n",
      "|    reward             | -0.03983487 |\n",
      "|    std                | 1.07e+03    |\n",
      "|    value_loss         | 0.0889      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 45900       |\n",
      "|    time_elapsed       | 727         |\n",
      "|    total_timesteps    | 229500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.8       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 45899       |\n",
      "|    policy_loss        | -1.85       |\n",
      "|    reward             | -0.55416495 |\n",
      "|    std                | 1.07e+03    |\n",
      "|    value_loss         | 0.0183      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 46000        |\n",
      "|    time_elapsed       | 729          |\n",
      "|    total_timesteps    | 230000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.8        |\n",
      "|    explained_variance | 0.478        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45999        |\n",
      "|    policy_loss        | -0.0151      |\n",
      "|    reward             | 0.0036649657 |\n",
      "|    std                | 1.09e+03     |\n",
      "|    value_loss         | 0.000154     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 46100       |\n",
      "|    time_elapsed       | 730         |\n",
      "|    total_timesteps    | 230500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.8       |\n",
      "|    explained_variance | -0.161      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46099       |\n",
      "|    policy_loss        | 0.0112      |\n",
      "|    reward             | 0.016423505 |\n",
      "|    std                | 1.1e+03     |\n",
      "|    value_loss         | 0.000374    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 46200       |\n",
      "|    time_elapsed       | 732         |\n",
      "|    total_timesteps    | 231000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46199       |\n",
      "|    policy_loss        | 1.06        |\n",
      "|    reward             | 0.045802433 |\n",
      "|    std                | 1.13e+03    |\n",
      "|    value_loss         | 0.00578     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 46300        |\n",
      "|    time_elapsed       | 733          |\n",
      "|    total_timesteps    | 231500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.9        |\n",
      "|    explained_variance | 0.415        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46299        |\n",
      "|    policy_loss        | -0.737       |\n",
      "|    reward             | -0.080252744 |\n",
      "|    std                | 1.15e+03     |\n",
      "|    value_loss         | 0.00267      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 46400       |\n",
      "|    time_elapsed       | 735         |\n",
      "|    total_timesteps    | 232000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17         |\n",
      "|    explained_variance | 0.221       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46399       |\n",
      "|    policy_loss        | 2.72        |\n",
      "|    reward             | 0.065786995 |\n",
      "|    std                | 1.17e+03    |\n",
      "|    value_loss         | 0.0267      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 46500        |\n",
      "|    time_elapsed       | 736          |\n",
      "|    total_timesteps    | 232500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17          |\n",
      "|    explained_variance | 0.698        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46499        |\n",
      "|    policy_loss        | -0.436       |\n",
      "|    reward             | -0.011841495 |\n",
      "|    std                | 1.18e+03     |\n",
      "|    value_loss         | 0.000687     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 46600        |\n",
      "|    time_elapsed       | 738          |\n",
      "|    total_timesteps    | 233000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17          |\n",
      "|    explained_variance | -0.0923      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46599        |\n",
      "|    policy_loss        | 0.0553       |\n",
      "|    reward             | -0.008285761 |\n",
      "|    std                | 1.2e+03      |\n",
      "|    value_loss         | 1.98e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 46700       |\n",
      "|    time_elapsed       | 740         |\n",
      "|    total_timesteps    | 233500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17         |\n",
      "|    explained_variance | 0.000519    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46699       |\n",
      "|    policy_loss        | -0.135      |\n",
      "|    reward             | 0.038079113 |\n",
      "|    std                | 1.22e+03    |\n",
      "|    value_loss         | 7.73e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 46800       |\n",
      "|    time_elapsed       | 741         |\n",
      "|    total_timesteps    | 234000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46799       |\n",
      "|    policy_loss        | -0.315      |\n",
      "|    reward             | 0.011105734 |\n",
      "|    std                | 1.23e+03    |\n",
      "|    value_loss         | 0.000585    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 46900       |\n",
      "|    time_elapsed       | 743         |\n",
      "|    total_timesteps    | 234500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.1       |\n",
      "|    explained_variance | 0.703       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46899       |\n",
      "|    policy_loss        | -1.49       |\n",
      "|    reward             | 0.052114103 |\n",
      "|    std                | 1.24e+03    |\n",
      "|    value_loss         | 0.00838     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 47000       |\n",
      "|    time_elapsed       | 744         |\n",
      "|    total_timesteps    | 235000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.1       |\n",
      "|    explained_variance | 0.00288     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46999       |\n",
      "|    policy_loss        | -0.106      |\n",
      "|    reward             | 0.036743242 |\n",
      "|    std                | 1.26e+03    |\n",
      "|    value_loss         | 0.00168     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 47100        |\n",
      "|    time_elapsed       | 746          |\n",
      "|    total_timesteps    | 235500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47099        |\n",
      "|    policy_loss        | 0.0248       |\n",
      "|    reward             | 0.0024551337 |\n",
      "|    std                | 1.27e+03     |\n",
      "|    value_loss         | 2.3e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 47200        |\n",
      "|    time_elapsed       | 747          |\n",
      "|    total_timesteps    | 236000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.2        |\n",
      "|    explained_variance | -0.241       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47199        |\n",
      "|    policy_loss        | -0.195       |\n",
      "|    reward             | 0.0056981454 |\n",
      "|    std                | 1.3e+03      |\n",
      "|    value_loss         | 0.000164     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 47300        |\n",
      "|    time_elapsed       | 749          |\n",
      "|    total_timesteps    | 236500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.2        |\n",
      "|    explained_variance | 0.335        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47299        |\n",
      "|    policy_loss        | -0.00326     |\n",
      "|    reward             | -0.006699573 |\n",
      "|    std                | 1.33e+03     |\n",
      "|    value_loss         | 1.56e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 47400       |\n",
      "|    time_elapsed       | 750         |\n",
      "|    total_timesteps    | 237000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.3       |\n",
      "|    explained_variance | -0.16       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 47399       |\n",
      "|    policy_loss        | -0.443      |\n",
      "|    reward             | 0.009315601 |\n",
      "|    std                | 1.37e+03    |\n",
      "|    value_loss         | 0.000809    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 315       |\n",
      "|    iterations         | 47500     |\n",
      "|    time_elapsed       | 752       |\n",
      "|    total_timesteps    | 237500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -17.3     |\n",
      "|    explained_variance | -0.0229   |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 47499     |\n",
      "|    policy_loss        | 0.316     |\n",
      "|    reward             | -0.017115 |\n",
      "|    std                | 1.41e+03  |\n",
      "|    value_loss         | 0.000378  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 47600       |\n",
      "|    time_elapsed       | 753         |\n",
      "|    total_timesteps    | 238000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.4       |\n",
      "|    explained_variance | 0.497       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 47599       |\n",
      "|    policy_loss        | 0.224       |\n",
      "|    reward             | 0.023250347 |\n",
      "|    std                | 1.43e+03    |\n",
      "|    value_loss         | 0.000896    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 47700         |\n",
      "|    time_elapsed       | 755           |\n",
      "|    total_timesteps    | 238500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.4         |\n",
      "|    explained_variance | -0.28         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 47699         |\n",
      "|    policy_loss        | 0.247         |\n",
      "|    reward             | -0.0059036165 |\n",
      "|    std                | 1.46e+03      |\n",
      "|    value_loss         | 0.000455      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 47800         |\n",
      "|    time_elapsed       | 757           |\n",
      "|    total_timesteps    | 239000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.4         |\n",
      "|    explained_variance | -0.00139      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 47799         |\n",
      "|    policy_loss        | 0.0481        |\n",
      "|    reward             | -0.0014252655 |\n",
      "|    std                | 1.5e+03       |\n",
      "|    value_loss         | 0.000222      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 47900       |\n",
      "|    time_elapsed       | 758         |\n",
      "|    total_timesteps    | 239500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.5       |\n",
      "|    explained_variance | 1.19e-06    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 47899       |\n",
      "|    policy_loss        | -0.338      |\n",
      "|    reward             | 0.007470328 |\n",
      "|    std                | 1.53e+03    |\n",
      "|    value_loss         | 0.00058     |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 315            |\n",
      "|    iterations         | 48000          |\n",
      "|    time_elapsed       | 760            |\n",
      "|    total_timesteps    | 240000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -17.6          |\n",
      "|    explained_variance | -1.85          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 47999          |\n",
      "|    policy_loss        | -0.395         |\n",
      "|    reward             | -0.00033199004 |\n",
      "|    std                | 1.59e+03       |\n",
      "|    value_loss         | 0.000728       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 48100       |\n",
      "|    time_elapsed       | 761         |\n",
      "|    total_timesteps    | 240500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.6       |\n",
      "|    explained_variance | 0.276       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48099       |\n",
      "|    policy_loss        | 0.0427      |\n",
      "|    reward             | 0.044975355 |\n",
      "|    std                | 1.64e+03    |\n",
      "|    value_loss         | 0.00035     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2833, episode: 85\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 52626.44\n",
      "total_reward: 42626.44\n",
      "total_cost: 10.51\n",
      "total_trades: 5663\n",
      "Sharpe: 0.649\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 48200        |\n",
      "|    time_elapsed       | 763          |\n",
      "|    total_timesteps    | 241000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.6        |\n",
      "|    explained_variance | -1.38        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48199        |\n",
      "|    policy_loss        | -0.156       |\n",
      "|    reward             | -0.007648289 |\n",
      "|    std                | 1.64e+03     |\n",
      "|    value_loss         | 0.000142     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 48300       |\n",
      "|    time_elapsed       | 764         |\n",
      "|    total_timesteps    | 241500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.7       |\n",
      "|    explained_variance | 0.145       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48299       |\n",
      "|    policy_loss        | -0.141      |\n",
      "|    reward             | -0.00853328 |\n",
      "|    std                | 1.67e+03    |\n",
      "|    value_loss         | 0.000102    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 48400        |\n",
      "|    time_elapsed       | 766          |\n",
      "|    total_timesteps    | 242000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.7        |\n",
      "|    explained_variance | 0.375        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48399        |\n",
      "|    policy_loss        | 0.214        |\n",
      "|    reward             | 0.0004150692 |\n",
      "|    std                | 1.72e+03     |\n",
      "|    value_loss         | 0.000418     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 48500       |\n",
      "|    time_elapsed       | 767         |\n",
      "|    total_timesteps    | 242500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48499       |\n",
      "|    policy_loss        | -0.083      |\n",
      "|    reward             | 0.022506513 |\n",
      "|    std                | 1.76e+03    |\n",
      "|    value_loss         | 0.00052     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 48600         |\n",
      "|    time_elapsed       | 769           |\n",
      "|    total_timesteps    | 243000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.8         |\n",
      "|    explained_variance | 0.182         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 48599         |\n",
      "|    policy_loss        | -1.51         |\n",
      "|    reward             | -0.0035403762 |\n",
      "|    std                | 1.79e+03      |\n",
      "|    value_loss         | 0.0076        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 48700        |\n",
      "|    time_elapsed       | 771          |\n",
      "|    total_timesteps    | 243500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.8        |\n",
      "|    explained_variance | 0.325        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48699        |\n",
      "|    policy_loss        | 1.37         |\n",
      "|    reward             | -0.049521893 |\n",
      "|    std                | 1.8e+03      |\n",
      "|    value_loss         | 0.0124       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 48800       |\n",
      "|    time_elapsed       | 772         |\n",
      "|    total_timesteps    | 244000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.8       |\n",
      "|    explained_variance | -9.54e-06   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48799       |\n",
      "|    policy_loss        | 0.0108      |\n",
      "|    reward             | 0.004007483 |\n",
      "|    std                | 1.83e+03    |\n",
      "|    value_loss         | 2.1e-05     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 48900       |\n",
      "|    time_elapsed       | 774         |\n",
      "|    total_timesteps    | 244500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.9       |\n",
      "|    explained_variance | 0.742       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48899       |\n",
      "|    policy_loss        | 0.00142     |\n",
      "|    reward             | 0.006935495 |\n",
      "|    std                | 1.85e+03    |\n",
      "|    value_loss         | 9.87e-06    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 49000       |\n",
      "|    time_elapsed       | 776         |\n",
      "|    total_timesteps    | 245000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.9       |\n",
      "|    explained_variance | 0.176       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48999       |\n",
      "|    policy_loss        | -0.383      |\n",
      "|    reward             | -0.02120655 |\n",
      "|    std                | 1.89e+03    |\n",
      "|    value_loss         | 0.000625    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 49100         |\n",
      "|    time_elapsed       | 777           |\n",
      "|    total_timesteps    | 245500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18           |\n",
      "|    explained_variance | 0.631         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 49099         |\n",
      "|    policy_loss        | -0.507        |\n",
      "|    reward             | -0.0038101827 |\n",
      "|    std                | 1.93e+03      |\n",
      "|    value_loss         | 0.00126       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 49200      |\n",
      "|    time_elapsed       | 779        |\n",
      "|    total_timesteps    | 246000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18        |\n",
      "|    explained_variance | 0.452      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 49199      |\n",
      "|    policy_loss        | 0.456      |\n",
      "|    reward             | 0.00478258 |\n",
      "|    std                | 1.95e+03   |\n",
      "|    value_loss         | 0.000674   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 49300       |\n",
      "|    time_elapsed       | 780         |\n",
      "|    total_timesteps    | 246500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18         |\n",
      "|    explained_variance | 0.302       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49299       |\n",
      "|    policy_loss        | 1.78        |\n",
      "|    reward             | 0.024132747 |\n",
      "|    std                | 1.96e+03    |\n",
      "|    value_loss         | 0.0182      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 49400       |\n",
      "|    time_elapsed       | 782         |\n",
      "|    total_timesteps    | 247000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18         |\n",
      "|    explained_variance | -1.04e-05   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49399       |\n",
      "|    policy_loss        | 0.282       |\n",
      "|    reward             | -0.00872531 |\n",
      "|    std                | 2.01e+03    |\n",
      "|    value_loss         | 0.000544    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 315            |\n",
      "|    iterations         | 49500          |\n",
      "|    time_elapsed       | 784            |\n",
      "|    total_timesteps    | 247500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -18.1          |\n",
      "|    explained_variance | 0.0325         |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 49499          |\n",
      "|    policy_loss        | 1.14           |\n",
      "|    reward             | -0.00034368096 |\n",
      "|    std                | 2.03e+03       |\n",
      "|    value_loss         | 0.015          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 49600        |\n",
      "|    time_elapsed       | 785          |\n",
      "|    total_timesteps    | 248000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.1        |\n",
      "|    explained_variance | 0.0382       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 49599        |\n",
      "|    policy_loss        | -1.32        |\n",
      "|    reward             | -0.013202882 |\n",
      "|    std                | 2.06e+03     |\n",
      "|    value_loss         | 0.0101       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 49700      |\n",
      "|    time_elapsed       | 787        |\n",
      "|    total_timesteps    | 248500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.1      |\n",
      "|    explained_variance | 0.188      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 49699      |\n",
      "|    policy_loss        | -2.93      |\n",
      "|    reward             | 0.21189545 |\n",
      "|    std                | 2.07e+03   |\n",
      "|    value_loss         | 0.0396     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 49800      |\n",
      "|    time_elapsed       | 788        |\n",
      "|    total_timesteps    | 249000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 49799      |\n",
      "|    policy_loss        | -1.02      |\n",
      "|    reward             | 0.28854173 |\n",
      "|    std                | 2.05e+03   |\n",
      "|    value_loss         | 0.0281     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 49900       |\n",
      "|    time_elapsed       | 790         |\n",
      "|    total_timesteps    | 249500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.1       |\n",
      "|    explained_variance | -3.61       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49899       |\n",
      "|    policy_loss        | -0.57       |\n",
      "|    reward             | 0.015919404 |\n",
      "|    std                | 2.08e+03    |\n",
      "|    value_loss         | 0.00278     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 50000        |\n",
      "|    time_elapsed       | 791          |\n",
      "|    total_timesteps    | 250000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.1        |\n",
      "|    explained_variance | -0.0907      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 49999        |\n",
      "|    policy_loss        | -0.662       |\n",
      "|    reward             | -0.010056037 |\n",
      "|    std                | 2.09e+03     |\n",
      "|    value_loss         | 0.00334      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 50100        |\n",
      "|    time_elapsed       | 793          |\n",
      "|    total_timesteps    | 250500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.1        |\n",
      "|    explained_variance | 0.159        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50099        |\n",
      "|    policy_loss        | 1.26         |\n",
      "|    reward             | 0.0038325065 |\n",
      "|    std                | 2.13e+03     |\n",
      "|    value_loss         | 0.00664      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 50200      |\n",
      "|    time_elapsed       | 794        |\n",
      "|    total_timesteps    | 251000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.2      |\n",
      "|    explained_variance | 0.00861    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 50199      |\n",
      "|    policy_loss        | 0.39       |\n",
      "|    reward             | 0.03868387 |\n",
      "|    std                | 2.16e+03   |\n",
      "|    value_loss         | 0.000596   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 50300       |\n",
      "|    time_elapsed       | 796         |\n",
      "|    total_timesteps    | 251500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50299       |\n",
      "|    policy_loss        | 1.03        |\n",
      "|    reward             | -0.08050561 |\n",
      "|    std                | 2.19e+03    |\n",
      "|    value_loss         | 0.0051      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 50400       |\n",
      "|    time_elapsed       | 797         |\n",
      "|    total_timesteps    | 252000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.2       |\n",
      "|    explained_variance | 0.103       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50399       |\n",
      "|    policy_loss        | 1.45        |\n",
      "|    reward             | -0.05240161 |\n",
      "|    std                | 2.2e+03     |\n",
      "|    value_loss         | 0.0104      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 50500        |\n",
      "|    time_elapsed       | 799          |\n",
      "|    total_timesteps    | 252500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.2        |\n",
      "|    explained_variance | 0.0725       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50499        |\n",
      "|    policy_loss        | 0.298        |\n",
      "|    reward             | -0.023606518 |\n",
      "|    std                | 2.21e+03     |\n",
      "|    value_loss         | 0.000732     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 50600        |\n",
      "|    time_elapsed       | 800          |\n",
      "|    total_timesteps    | 253000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.3        |\n",
      "|    explained_variance | 0.409        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50599        |\n",
      "|    policy_loss        | 0.00997      |\n",
      "|    reward             | -0.015630493 |\n",
      "|    std                | 2.24e+03     |\n",
      "|    value_loss         | 0.00104      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 50700       |\n",
      "|    time_elapsed       | 802         |\n",
      "|    total_timesteps    | 253500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.3       |\n",
      "|    explained_variance | 0.114       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50699       |\n",
      "|    policy_loss        | -2.2        |\n",
      "|    reward             | -0.13004638 |\n",
      "|    std                | 2.27e+03    |\n",
      "|    value_loss         | 0.0157      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 50800       |\n",
      "|    time_elapsed       | 803         |\n",
      "|    total_timesteps    | 254000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50799       |\n",
      "|    policy_loss        | -0.345      |\n",
      "|    reward             | 0.016024984 |\n",
      "|    std                | 2.28e+03    |\n",
      "|    value_loss         | 0.000858    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 50900        |\n",
      "|    time_elapsed       | 805          |\n",
      "|    total_timesteps    | 254500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50899        |\n",
      "|    policy_loss        | -0.172       |\n",
      "|    reward             | -0.031382095 |\n",
      "|    std                | 2.28e+03     |\n",
      "|    value_loss         | 0.00312      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 51000       |\n",
      "|    time_elapsed       | 806         |\n",
      "|    total_timesteps    | 255000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.3       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50999       |\n",
      "|    policy_loss        | 5.43        |\n",
      "|    reward             | 0.012615997 |\n",
      "|    std                | 2.31e+03    |\n",
      "|    value_loss         | 0.191       |\n",
      "---------------------------------------\n",
      "day: 2833, episode: 90\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 188821.35\n",
      "total_reward: 178821.35\n",
      "total_cost: 131.77\n",
      "total_trades: 5627\n",
      "Sharpe: 0.995\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 51100        |\n",
      "|    time_elapsed       | 808          |\n",
      "|    total_timesteps    | 255500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.3        |\n",
      "|    explained_variance | -0.858       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51099        |\n",
      "|    policy_loss        | 0.204        |\n",
      "|    reward             | -0.016755577 |\n",
      "|    std                | 2.33e+03     |\n",
      "|    value_loss         | 0.000189     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 51200        |\n",
      "|    time_elapsed       | 809          |\n",
      "|    total_timesteps    | 256000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.4        |\n",
      "|    explained_variance | 0.616        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51199        |\n",
      "|    policy_loss        | 1.18         |\n",
      "|    reward             | 0.0015753502 |\n",
      "|    std                | 2.37e+03     |\n",
      "|    value_loss         | 0.00381      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 51300        |\n",
      "|    time_elapsed       | 811          |\n",
      "|    total_timesteps    | 256500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.4        |\n",
      "|    explained_variance | 0.000965     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51299        |\n",
      "|    policy_loss        | -0.723       |\n",
      "|    reward             | -0.012679099 |\n",
      "|    std                | 2.38e+03     |\n",
      "|    value_loss         | 0.00155      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 51400       |\n",
      "|    time_elapsed       | 812         |\n",
      "|    total_timesteps    | 257000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.4       |\n",
      "|    explained_variance | 0.2         |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51399       |\n",
      "|    policy_loss        | -1.2        |\n",
      "|    reward             | 0.024579886 |\n",
      "|    std                | 2.42e+03    |\n",
      "|    value_loss         | 0.00933     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 51500       |\n",
      "|    time_elapsed       | 814         |\n",
      "|    total_timesteps    | 257500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.4       |\n",
      "|    explained_variance | 0.426       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51499       |\n",
      "|    policy_loss        | -1.92       |\n",
      "|    reward             | 0.027127167 |\n",
      "|    std                | 2.45e+03    |\n",
      "|    value_loss         | 0.0117      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 51600       |\n",
      "|    time_elapsed       | 815         |\n",
      "|    total_timesteps    | 258000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.4       |\n",
      "|    explained_variance | -0.375      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51599       |\n",
      "|    policy_loss        | -0.651      |\n",
      "|    reward             | 0.021649167 |\n",
      "|    std                | 2.45e+03    |\n",
      "|    value_loss         | 0.00154     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 51700        |\n",
      "|    time_elapsed       | 817          |\n",
      "|    total_timesteps    | 258500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.5        |\n",
      "|    explained_variance | -0.15        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51699        |\n",
      "|    policy_loss        | -0.208       |\n",
      "|    reward             | 0.0009986279 |\n",
      "|    std                | 2.48e+03     |\n",
      "|    value_loss         | 0.000239     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 316           |\n",
      "|    iterations         | 51800         |\n",
      "|    time_elapsed       | 818           |\n",
      "|    total_timesteps    | 259000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.5         |\n",
      "|    explained_variance | 0.473         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 51799         |\n",
      "|    policy_loss        | 1.07          |\n",
      "|    reward             | -0.0017951577 |\n",
      "|    std                | 2.53e+03      |\n",
      "|    value_loss         | 0.00336       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 51900       |\n",
      "|    time_elapsed       | 820         |\n",
      "|    total_timesteps    | 259500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.5       |\n",
      "|    explained_variance | 0.0801      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51899       |\n",
      "|    policy_loss        | 1.41        |\n",
      "|    reward             | 0.016972583 |\n",
      "|    std                | 2.55e+03    |\n",
      "|    value_loss         | 0.00961     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 52000        |\n",
      "|    time_elapsed       | 822          |\n",
      "|    total_timesteps    | 260000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51999        |\n",
      "|    policy_loss        | -1.51        |\n",
      "|    reward             | -0.032805882 |\n",
      "|    std                | 2.57e+03     |\n",
      "|    value_loss         | 0.0158       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 52100       |\n",
      "|    time_elapsed       | 823         |\n",
      "|    total_timesteps    | 260500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52099       |\n",
      "|    policy_loss        | 4.08        |\n",
      "|    reward             | -0.09881658 |\n",
      "|    std                | 2.58e+03    |\n",
      "|    value_loss         | 0.0511      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 52200        |\n",
      "|    time_elapsed       | 825          |\n",
      "|    total_timesteps    | 261000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.6        |\n",
      "|    explained_variance | -0.171       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52199        |\n",
      "|    policy_loss        | 0.94         |\n",
      "|    reward             | -0.006458782 |\n",
      "|    std                | 2.59e+03     |\n",
      "|    value_loss         | 0.00274      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 52300        |\n",
      "|    time_elapsed       | 827          |\n",
      "|    total_timesteps    | 261500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.6        |\n",
      "|    explained_variance | 0.519        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52299        |\n",
      "|    policy_loss        | 0.408        |\n",
      "|    reward             | -0.039442405 |\n",
      "|    std                | 2.64e+03     |\n",
      "|    value_loss         | 0.00116      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 52400       |\n",
      "|    time_elapsed       | 828         |\n",
      "|    total_timesteps    | 262000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.6       |\n",
      "|    explained_variance | -0.519      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52399       |\n",
      "|    policy_loss        | 0.195       |\n",
      "|    reward             | 0.027021125 |\n",
      "|    std                | 2.69e+03    |\n",
      "|    value_loss         | 0.000481    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 316        |\n",
      "|    iterations         | 52500      |\n",
      "|    time_elapsed       | 830        |\n",
      "|    total_timesteps    | 262500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 52499      |\n",
      "|    policy_loss        | -0.308     |\n",
      "|    reward             | 0.05965746 |\n",
      "|    std                | 2.76e+03   |\n",
      "|    value_loss         | 0.000473   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 52600        |\n",
      "|    time_elapsed       | 832          |\n",
      "|    total_timesteps    | 263000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.7        |\n",
      "|    explained_variance | 0.0924       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52599        |\n",
      "|    policy_loss        | -0.379       |\n",
      "|    reward             | -0.007737111 |\n",
      "|    std                | 2.81e+03     |\n",
      "|    value_loss         | 0.00201      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 52700       |\n",
      "|    time_elapsed       | 833         |\n",
      "|    total_timesteps    | 263500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.7       |\n",
      "|    explained_variance | 6.9e-05     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52699       |\n",
      "|    policy_loss        | -1.1        |\n",
      "|    reward             | -0.07612758 |\n",
      "|    std                | 2.84e+03    |\n",
      "|    value_loss         | 0.0218      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 316          |\n",
      "|    iterations         | 52800        |\n",
      "|    time_elapsed       | 835          |\n",
      "|    total_timesteps    | 264000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52799        |\n",
      "|    policy_loss        | -0.0997      |\n",
      "|    reward             | 0.0048657334 |\n",
      "|    std                | 2.89e+03     |\n",
      "|    value_loss         | 0.00011      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 316           |\n",
      "|    iterations         | 52900         |\n",
      "|    time_elapsed       | 837           |\n",
      "|    total_timesteps    | 264500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.8         |\n",
      "|    explained_variance | 0.00995       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 52899         |\n",
      "|    policy_loss        | -0.0762       |\n",
      "|    reward             | -0.0022810425 |\n",
      "|    std                | 2.95e+03      |\n",
      "|    value_loss         | 2.41e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 53000       |\n",
      "|    time_elapsed       | 838         |\n",
      "|    total_timesteps    | 265000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.9       |\n",
      "|    explained_variance | -0.0134     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52999       |\n",
      "|    policy_loss        | 0.135       |\n",
      "|    reward             | 0.010006819 |\n",
      "|    std                | 3.06e+03    |\n",
      "|    value_loss         | 0.000619    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 53100        |\n",
      "|    time_elapsed       | 840          |\n",
      "|    total_timesteps    | 265500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19          |\n",
      "|    explained_variance | 0.0854       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 53099        |\n",
      "|    policy_loss        | -1.62        |\n",
      "|    reward             | -0.003804245 |\n",
      "|    std                | 3.19e+03     |\n",
      "|    value_loss         | 0.00783      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 53200       |\n",
      "|    time_elapsed       | 841         |\n",
      "|    total_timesteps    | 266000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53199       |\n",
      "|    policy_loss        | 0.067       |\n",
      "|    reward             | 0.026242057 |\n",
      "|    std                | 3.28e+03    |\n",
      "|    value_loss         | 0.000256    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 53300        |\n",
      "|    time_elapsed       | 843          |\n",
      "|    total_timesteps    | 266500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19          |\n",
      "|    explained_variance | 0.245        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 53299        |\n",
      "|    policy_loss        | -0.406       |\n",
      "|    reward             | -0.013035029 |\n",
      "|    std                | 3.29e+03     |\n",
      "|    value_loss         | 0.000574     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 53400       |\n",
      "|    time_elapsed       | 845         |\n",
      "|    total_timesteps    | 267000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19         |\n",
      "|    explained_variance | 0.147       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53399       |\n",
      "|    policy_loss        | -0.264      |\n",
      "|    reward             | 0.007541343 |\n",
      "|    std                | 3.31e+03    |\n",
      "|    value_loss         | 0.000609    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 53500       |\n",
      "|    time_elapsed       | 846         |\n",
      "|    total_timesteps    | 267500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.1       |\n",
      "|    explained_variance | 0.021       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53499       |\n",
      "|    policy_loss        | 0.313       |\n",
      "|    reward             | 0.022214912 |\n",
      "|    std                | 3.37e+03    |\n",
      "|    value_loss         | 0.00043     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 53600       |\n",
      "|    time_elapsed       | 848         |\n",
      "|    total_timesteps    | 268000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.1       |\n",
      "|    explained_variance | 1.47e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53599       |\n",
      "|    policy_loss        | 1.4         |\n",
      "|    reward             | 0.109369904 |\n",
      "|    std                | 3.38e+03    |\n",
      "|    value_loss         | 0.0122      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 53700        |\n",
      "|    time_elapsed       | 849          |\n",
      "|    total_timesteps    | 268500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.1        |\n",
      "|    explained_variance | 8.34e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 53699        |\n",
      "|    policy_loss        | -4.02        |\n",
      "|    reward             | -0.115765974 |\n",
      "|    std                | 3.4e+03      |\n",
      "|    value_loss         | 0.06         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 53800      |\n",
      "|    time_elapsed       | 851        |\n",
      "|    total_timesteps    | 269000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.1      |\n",
      "|    explained_variance | 0.0682     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 53799      |\n",
      "|    policy_loss        | -1.12      |\n",
      "|    reward             | 0.05143529 |\n",
      "|    std                | 3.43e+03   |\n",
      "|    value_loss         | 0.023      |\n",
      "--------------------------------------\n",
      "day: 2833, episode: 95\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 216144.77\n",
      "total_reward: 206144.77\n",
      "total_cost: 117.36\n",
      "total_trades: 5657\n",
      "Sharpe: 1.014\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 53900       |\n",
      "|    time_elapsed       | 853         |\n",
      "|    total_timesteps    | 269500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.1       |\n",
      "|    explained_variance | -7.06       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 53899       |\n",
      "|    policy_loss        | -0.756      |\n",
      "|    reward             | 0.011426515 |\n",
      "|    std                | 3.43e+03    |\n",
      "|    value_loss         | 0.00215     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 54000        |\n",
      "|    time_elapsed       | 854          |\n",
      "|    total_timesteps    | 270000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.1        |\n",
      "|    explained_variance | -1.2         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 53999        |\n",
      "|    policy_loss        | 0.032        |\n",
      "|    reward             | 0.0031698467 |\n",
      "|    std                | 3.47e+03     |\n",
      "|    value_loss         | 0.000104     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 54100        |\n",
      "|    time_elapsed       | 856          |\n",
      "|    total_timesteps    | 270500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.2        |\n",
      "|    explained_variance | 0.143        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 54099        |\n",
      "|    policy_loss        | -0.337       |\n",
      "|    reward             | 0.0121010225 |\n",
      "|    std                | 3.53e+03     |\n",
      "|    value_loss         | 0.000314     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 54200       |\n",
      "|    time_elapsed       | 857         |\n",
      "|    total_timesteps    | 271000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.2       |\n",
      "|    explained_variance | 0.141       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 54199       |\n",
      "|    policy_loss        | -0.663      |\n",
      "|    reward             | -0.08124791 |\n",
      "|    std                | 3.58e+03    |\n",
      "|    value_loss         | 0.00129     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 54300       |\n",
      "|    time_elapsed       | 859         |\n",
      "|    total_timesteps    | 271500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.2       |\n",
      "|    explained_variance | 0.103       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 54299       |\n",
      "|    policy_loss        | 0.477       |\n",
      "|    reward             | -0.01208937 |\n",
      "|    std                | 3.64e+03    |\n",
      "|    value_loss         | 0.0017      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 54400      |\n",
      "|    time_elapsed       | 861        |\n",
      "|    total_timesteps    | 272000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.3      |\n",
      "|    explained_variance | 0.446      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 54399      |\n",
      "|    policy_loss        | 2.02       |\n",
      "|    reward             | 0.15365735 |\n",
      "|    std                | 3.72e+03   |\n",
      "|    value_loss         | 0.0173     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 54500        |\n",
      "|    time_elapsed       | 862          |\n",
      "|    total_timesteps    | 272500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.3        |\n",
      "|    explained_variance | 0.837        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 54499        |\n",
      "|    policy_loss        | -0.543       |\n",
      "|    reward             | -0.038798824 |\n",
      "|    std                | 3.76e+03     |\n",
      "|    value_loss         | 0.00101      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 54600         |\n",
      "|    time_elapsed       | 864           |\n",
      "|    total_timesteps    | 273000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.3         |\n",
      "|    explained_variance | 0.181         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 54599         |\n",
      "|    policy_loss        | -0.385        |\n",
      "|    reward             | -0.0011399391 |\n",
      "|    std                | 3.81e+03      |\n",
      "|    value_loss         | 0.00217       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 54700        |\n",
      "|    time_elapsed       | 865          |\n",
      "|    total_timesteps    | 273500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 54699        |\n",
      "|    policy_loss        | 8.91         |\n",
      "|    reward             | -0.083715215 |\n",
      "|    std                | 3.79e+03     |\n",
      "|    value_loss         | 0.317        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 54800       |\n",
      "|    time_elapsed       | 867         |\n",
      "|    total_timesteps    | 274000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.3       |\n",
      "|    explained_variance | 0.0708      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 54799       |\n",
      "|    policy_loss        | -0.59       |\n",
      "|    reward             | 0.004497678 |\n",
      "|    std                | 3.79e+03    |\n",
      "|    value_loss         | 0.0473      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 54900      |\n",
      "|    time_elapsed       | 869        |\n",
      "|    total_timesteps    | 274500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.3      |\n",
      "|    explained_variance | 0.000168   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 54899      |\n",
      "|    policy_loss        | 0.278      |\n",
      "|    reward             | 0.16198504 |\n",
      "|    std                | 3.81e+03   |\n",
      "|    value_loss         | 0.0177     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 55000        |\n",
      "|    time_elapsed       | 870          |\n",
      "|    total_timesteps    | 275000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.4        |\n",
      "|    explained_variance | -22.8        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 54999        |\n",
      "|    policy_loss        | -1.43        |\n",
      "|    reward             | 0.0007859802 |\n",
      "|    std                | 3.87e+03     |\n",
      "|    value_loss         | 0.00927      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 55100        |\n",
      "|    time_elapsed       | 872          |\n",
      "|    total_timesteps    | 275500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.4        |\n",
      "|    explained_variance | -0.0261      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55099        |\n",
      "|    policy_loss        | -0.226       |\n",
      "|    reward             | -0.014461655 |\n",
      "|    std                | 3.91e+03     |\n",
      "|    value_loss         | 0.000178     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 55200       |\n",
      "|    time_elapsed       | 873         |\n",
      "|    total_timesteps    | 276000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.4       |\n",
      "|    explained_variance | 0.0202      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 55199       |\n",
      "|    policy_loss        | -0.492      |\n",
      "|    reward             | 0.016641235 |\n",
      "|    std                | 3.98e+03    |\n",
      "|    value_loss         | 0.000738    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 55300       |\n",
      "|    time_elapsed       | 875         |\n",
      "|    total_timesteps    | 276500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.4       |\n",
      "|    explained_variance | 0.443       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 55299       |\n",
      "|    policy_loss        | 0.197       |\n",
      "|    reward             | 0.012728968 |\n",
      "|    std                | 4.04e+03    |\n",
      "|    value_loss         | 0.00017     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 55400       |\n",
      "|    time_elapsed       | 876         |\n",
      "|    total_timesteps    | 277000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.5       |\n",
      "|    explained_variance | 0.428       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 55399       |\n",
      "|    policy_loss        | -0.214      |\n",
      "|    reward             | 0.055244695 |\n",
      "|    std                | 4.14e+03    |\n",
      "|    value_loss         | 0.000974    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 55500      |\n",
      "|    time_elapsed       | 878        |\n",
      "|    total_timesteps    | 277500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.5      |\n",
      "|    explained_variance | 0.3        |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 55499      |\n",
      "|    policy_loss        | 0.691      |\n",
      "|    reward             | 0.09940607 |\n",
      "|    std                | 4.15e+03   |\n",
      "|    value_loss         | 0.00353    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 55600        |\n",
      "|    time_elapsed       | 879          |\n",
      "|    total_timesteps    | 278000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.5        |\n",
      "|    explained_variance | 0.72         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55599        |\n",
      "|    policy_loss        | 0.337        |\n",
      "|    reward             | -0.027891299 |\n",
      "|    std                | 4.14e+03     |\n",
      "|    value_loss         | 0.000341     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 55700        |\n",
      "|    time_elapsed       | 881          |\n",
      "|    total_timesteps    | 278500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.5        |\n",
      "|    explained_variance | 0.326        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55699        |\n",
      "|    policy_loss        | -0.29        |\n",
      "|    reward             | 0.0029215398 |\n",
      "|    std                | 4.19e+03     |\n",
      "|    value_loss         | 0.000722     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 55800        |\n",
      "|    time_elapsed       | 883          |\n",
      "|    total_timesteps    | 279000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.5        |\n",
      "|    explained_variance | 0.212        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55799        |\n",
      "|    policy_loss        | 0.427        |\n",
      "|    reward             | -0.017342517 |\n",
      "|    std                | 4.23e+03     |\n",
      "|    value_loss         | 0.000525     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 55900        |\n",
      "|    time_elapsed       | 885          |\n",
      "|    total_timesteps    | 279500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.6        |\n",
      "|    explained_variance | -0.0348      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55899        |\n",
      "|    policy_loss        | -0.833       |\n",
      "|    reward             | -0.007707825 |\n",
      "|    std                | 4.27e+03     |\n",
      "|    value_loss         | 0.00232      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 56000      |\n",
      "|    time_elapsed       | 886        |\n",
      "|    total_timesteps    | 280000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.5      |\n",
      "|    explained_variance | 6.29e-05   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 55999      |\n",
      "|    policy_loss        | 2.14       |\n",
      "|    reward             | 0.06475817 |\n",
      "|    std                | 4.25e+03   |\n",
      "|    value_loss         | 0.0151     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 56100      |\n",
      "|    time_elapsed       | 888        |\n",
      "|    total_timesteps    | 280500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.6      |\n",
      "|    explained_variance | 0.213      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 56099      |\n",
      "|    policy_loss        | -6.82      |\n",
      "|    reward             | 0.23245354 |\n",
      "|    std                | 4.31e+03   |\n",
      "|    value_loss         | 0.145      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 56200        |\n",
      "|    time_elapsed       | 889          |\n",
      "|    total_timesteps    | 281000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.6        |\n",
      "|    explained_variance | 0.347        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 56199        |\n",
      "|    policy_loss        | -1.25        |\n",
      "|    reward             | -0.024714915 |\n",
      "|    std                | 4.32e+03     |\n",
      "|    value_loss         | 0.00427      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 56300      |\n",
      "|    time_elapsed       | 891        |\n",
      "|    total_timesteps    | 281500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.6      |\n",
      "|    explained_variance | 0.374      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 56299      |\n",
      "|    policy_loss        | 0.715      |\n",
      "|    reward             | 0.07663521 |\n",
      "|    std                | 4.37e+03   |\n",
      "|    value_loss         | 0.00182    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 56400      |\n",
      "|    time_elapsed       | 892        |\n",
      "|    total_timesteps    | 282000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 56399      |\n",
      "|    policy_loss        | 3.82       |\n",
      "|    reward             | 0.03657499 |\n",
      "|    std                | 4.46e+03   |\n",
      "|    value_loss         | 0.0398     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 56500       |\n",
      "|    time_elapsed       | 894         |\n",
      "|    total_timesteps    | 282500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.7       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56499       |\n",
      "|    policy_loss        | -0.197      |\n",
      "|    reward             | -0.04657357 |\n",
      "|    std                | 4.53e+03    |\n",
      "|    value_loss         | 0.00415     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 56600        |\n",
      "|    time_elapsed       | 896          |\n",
      "|    total_timesteps    | 283000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 56599        |\n",
      "|    policy_loss        | 0.244        |\n",
      "|    reward             | -0.118540674 |\n",
      "|    std                | 4.62e+03     |\n",
      "|    value_loss         | 0.00338      |\n",
      "----------------------------------------\n",
      "day: 2833, episode: 100\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 140390.93\n",
      "total_reward: 130390.93\n",
      "total_cost: 50.84\n",
      "total_trades: 5656\n",
      "Sharpe: 0.943\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 56700        |\n",
      "|    time_elapsed       | 897          |\n",
      "|    total_timesteps    | 283500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.7        |\n",
      "|    explained_variance | -0.216       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 56699        |\n",
      "|    policy_loss        | -0.66        |\n",
      "|    reward             | -0.007527409 |\n",
      "|    std                | 4.64e+03     |\n",
      "|    value_loss         | 0.00248      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 56800        |\n",
      "|    time_elapsed       | 899          |\n",
      "|    total_timesteps    | 284000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.7        |\n",
      "|    explained_variance | -0.428       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 56799        |\n",
      "|    policy_loss        | 0.418        |\n",
      "|    reward             | -0.025761517 |\n",
      "|    std                | 4.7e+03      |\n",
      "|    value_loss         | 0.000711     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 56900      |\n",
      "|    time_elapsed       | 901        |\n",
      "|    total_timesteps    | 284500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.8      |\n",
      "|    explained_variance | 0.768      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 56899      |\n",
      "|    policy_loss        | -0.308     |\n",
      "|    reward             | 0.03402897 |\n",
      "|    std                | 4.8e+03    |\n",
      "|    value_loss         | 0.000275   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 57000      |\n",
      "|    time_elapsed       | 902        |\n",
      "|    total_timesteps    | 285000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.8      |\n",
      "|    explained_variance | 0.349      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 56999      |\n",
      "|    policy_loss        | -0.36      |\n",
      "|    reward             | 0.04352675 |\n",
      "|    std                | 4.88e+03   |\n",
      "|    value_loss         | 0.000476   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 57100       |\n",
      "|    time_elapsed       | 904         |\n",
      "|    total_timesteps    | 285500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.9       |\n",
      "|    explained_variance | 0.549       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57099       |\n",
      "|    policy_loss        | -0.185      |\n",
      "|    reward             | 0.028167829 |\n",
      "|    std                | 4.95e+03    |\n",
      "|    value_loss         | 0.00411     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 57200       |\n",
      "|    time_elapsed       | 905         |\n",
      "|    total_timesteps    | 286000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57199       |\n",
      "|    policy_loss        | -1.46       |\n",
      "|    reward             | 0.037746854 |\n",
      "|    std                | 4.95e+03    |\n",
      "|    value_loss         | 0.00643     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 57300       |\n",
      "|    time_elapsed       | 907         |\n",
      "|    total_timesteps    | 286500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -19.9       |\n",
      "|    explained_variance | -0.358      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57299       |\n",
      "|    policy_loss        | 0.186       |\n",
      "|    reward             | 0.016688103 |\n",
      "|    std                | 5.05e+03    |\n",
      "|    value_loss         | 0.000102    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 57400        |\n",
      "|    time_elapsed       | 909          |\n",
      "|    total_timesteps    | 287000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.9        |\n",
      "|    explained_variance | -3.29        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57399        |\n",
      "|    policy_loss        | 0.213        |\n",
      "|    reward             | -0.003946072 |\n",
      "|    std                | 5.13e+03     |\n",
      "|    value_loss         | 0.000142     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 315            |\n",
      "|    iterations         | 57500          |\n",
      "|    time_elapsed       | 910            |\n",
      "|    total_timesteps    | 287500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -20            |\n",
      "|    explained_variance | -29.2          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 57499          |\n",
      "|    policy_loss        | -0.0253        |\n",
      "|    reward             | -0.00082825316 |\n",
      "|    std                | 5.26e+03       |\n",
      "|    value_loss         | 0.000551       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 57600        |\n",
      "|    time_elapsed       | 912          |\n",
      "|    total_timesteps    | 288000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57599        |\n",
      "|    policy_loss        | -0.0683      |\n",
      "|    reward             | 0.0058124396 |\n",
      "|    std                | 5.43e+03     |\n",
      "|    value_loss         | 1.49e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 57700       |\n",
      "|    time_elapsed       | 914         |\n",
      "|    total_timesteps    | 288500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57699       |\n",
      "|    policy_loss        | -0.443      |\n",
      "|    reward             | 0.011249266 |\n",
      "|    std                | 5.67e+03    |\n",
      "|    value_loss         | 0.000766    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 57800        |\n",
      "|    time_elapsed       | 915          |\n",
      "|    total_timesteps    | 289000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.2        |\n",
      "|    explained_variance | -0.3         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57799        |\n",
      "|    policy_loss        | -0.11        |\n",
      "|    reward             | -0.012655973 |\n",
      "|    std                | 5.93e+03     |\n",
      "|    value_loss         | 0.000237     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 57900      |\n",
      "|    time_elapsed       | 917        |\n",
      "|    total_timesteps    | 289500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.2      |\n",
      "|    explained_variance | 0.00357    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 57899      |\n",
      "|    policy_loss        | -1.17      |\n",
      "|    reward             | 0.01302573 |\n",
      "|    std                | 6e+03      |\n",
      "|    value_loss         | 0.00329    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 58000       |\n",
      "|    time_elapsed       | 918         |\n",
      "|    total_timesteps    | 290000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.3       |\n",
      "|    explained_variance | 0.00356     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57999       |\n",
      "|    policy_loss        | 0.356       |\n",
      "|    reward             | 0.007740952 |\n",
      "|    std                | 6.11e+03    |\n",
      "|    value_loss         | 0.000377    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 58100       |\n",
      "|    time_elapsed       | 920         |\n",
      "|    total_timesteps    | 290500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.3       |\n",
      "|    explained_variance | 0.252       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58099       |\n",
      "|    policy_loss        | 0.479       |\n",
      "|    reward             | 0.008582715 |\n",
      "|    std                | 6.22e+03    |\n",
      "|    value_loss         | 0.00177     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 58200       |\n",
      "|    time_elapsed       | 922         |\n",
      "|    total_timesteps    | 291000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.3       |\n",
      "|    explained_variance | 0.0217      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58199       |\n",
      "|    policy_loss        | 0.63        |\n",
      "|    reward             | -0.07020826 |\n",
      "|    std                | 6.34e+03    |\n",
      "|    value_loss         | 0.00176     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 58300      |\n",
      "|    time_elapsed       | 923        |\n",
      "|    total_timesteps    | 291500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.3      |\n",
      "|    explained_variance | -0.0261    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 58299      |\n",
      "|    policy_loss        | 0.0715     |\n",
      "|    reward             | 0.02333226 |\n",
      "|    std                | 6.34e+03   |\n",
      "|    value_loss         | 0.00267    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 58400        |\n",
      "|    time_elapsed       | 925          |\n",
      "|    total_timesteps    | 292000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.3        |\n",
      "|    explained_variance | -2.06        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 58399        |\n",
      "|    policy_loss        | 1.02         |\n",
      "|    reward             | -0.000808601 |\n",
      "|    std                | 6.35e+03     |\n",
      "|    value_loss         | 0.00351      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 58500         |\n",
      "|    time_elapsed       | 926           |\n",
      "|    total_timesteps    | 292500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.4         |\n",
      "|    explained_variance | 0.511         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 58499         |\n",
      "|    policy_loss        | 0.19          |\n",
      "|    reward             | -0.0010334465 |\n",
      "|    std                | 6.46e+03      |\n",
      "|    value_loss         | 9.65e-05      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 58600        |\n",
      "|    time_elapsed       | 928          |\n",
      "|    total_timesteps    | 293000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.4        |\n",
      "|    explained_variance | 0.638        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 58599        |\n",
      "|    policy_loss        | 0.0432       |\n",
      "|    reward             | 0.0014882064 |\n",
      "|    std                | 6.59e+03     |\n",
      "|    value_loss         | 2.08e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 58700       |\n",
      "|    time_elapsed       | 930         |\n",
      "|    total_timesteps    | 293500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.5       |\n",
      "|    explained_variance | 0.0969      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58699       |\n",
      "|    policy_loss        | -0.244      |\n",
      "|    reward             | 0.039284185 |\n",
      "|    std                | 6.78e+03    |\n",
      "|    value_loss         | 0.000711    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 58800        |\n",
      "|    time_elapsed       | 931          |\n",
      "|    total_timesteps    | 294000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.5        |\n",
      "|    explained_variance | 0.0299       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 58799        |\n",
      "|    policy_loss        | 2.92         |\n",
      "|    reward             | -0.065865315 |\n",
      "|    std                | 6.99e+03     |\n",
      "|    value_loss         | 0.0222       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 58900        |\n",
      "|    time_elapsed       | 933          |\n",
      "|    total_timesteps    | 294500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.6        |\n",
      "|    explained_variance | -0.308       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 58899        |\n",
      "|    policy_loss        | -0.0775      |\n",
      "|    reward             | -0.079715714 |\n",
      "|    std                | 7.06e+03     |\n",
      "|    value_loss         | 0.000949     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 59000        |\n",
      "|    time_elapsed       | 935          |\n",
      "|    total_timesteps    | 295000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.6        |\n",
      "|    explained_variance | 0.553        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 58999        |\n",
      "|    policy_loss        | -0.237       |\n",
      "|    reward             | -0.011179076 |\n",
      "|    std                | 7.1e+03      |\n",
      "|    value_loss         | 0.000168     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 59100        |\n",
      "|    time_elapsed       | 936          |\n",
      "|    total_timesteps    | 295500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.6        |\n",
      "|    explained_variance | -1.45        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 59099        |\n",
      "|    policy_loss        | 0.163        |\n",
      "|    reward             | 0.0132332165 |\n",
      "|    std                | 7.22e+03     |\n",
      "|    value_loss         | 0.000134     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 59200       |\n",
      "|    time_elapsed       | 938         |\n",
      "|    total_timesteps    | 296000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.7       |\n",
      "|    explained_variance | 0.204       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 59199       |\n",
      "|    policy_loss        | -0.487      |\n",
      "|    reward             | 0.010959854 |\n",
      "|    std                | 7.39e+03    |\n",
      "|    value_loss         | 0.00121     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 59300        |\n",
      "|    time_elapsed       | 939          |\n",
      "|    total_timesteps    | 296500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.7        |\n",
      "|    explained_variance | 0.0101       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 59299        |\n",
      "|    policy_loss        | 0.404        |\n",
      "|    reward             | -0.006856384 |\n",
      "|    std                | 7.53e+03     |\n",
      "|    value_loss         | 0.000511     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 59400      |\n",
      "|    time_elapsed       | 941        |\n",
      "|    total_timesteps    | 297000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 59399      |\n",
      "|    policy_loss        | -1.33      |\n",
      "|    reward             | 0.09025801 |\n",
      "|    std                | 7.61e+03   |\n",
      "|    value_loss         | 0.00613    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 59500      |\n",
      "|    time_elapsed       | 943        |\n",
      "|    total_timesteps    | 297500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.7      |\n",
      "|    explained_variance | 0.236      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 59499      |\n",
      "|    policy_loss        | -2.15      |\n",
      "|    reward             | 0.08231626 |\n",
      "|    std                | 7.7e+03    |\n",
      "|    value_loss         | 0.0368     |\n",
      "--------------------------------------\n",
      "day: 2833, episode: 105\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 93443.24\n",
      "total_reward: 83443.24\n",
      "total_cost: 22.59\n",
      "total_trades: 5663\n",
      "Sharpe: 0.782\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 59600        |\n",
      "|    time_elapsed       | 945          |\n",
      "|    total_timesteps    | 298000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.7        |\n",
      "|    explained_variance | 0.771        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 59599        |\n",
      "|    policy_loss        | 0.0225       |\n",
      "|    reward             | -0.012792029 |\n",
      "|    std                | 7.76e+03     |\n",
      "|    value_loss         | 0.000218     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 59700        |\n",
      "|    time_elapsed       | 946          |\n",
      "|    total_timesteps    | 298500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.8        |\n",
      "|    explained_variance | 0.12         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 59699        |\n",
      "|    policy_loss        | -0.156       |\n",
      "|    reward             | -0.022267155 |\n",
      "|    std                | 7.9e+03      |\n",
      "|    value_loss         | 0.000203     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 59800      |\n",
      "|    time_elapsed       | 948        |\n",
      "|    total_timesteps    | 299000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.8      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 59799      |\n",
      "|    policy_loss        | 3.04       |\n",
      "|    reward             | 0.10748382 |\n",
      "|    std                | 7.87e+03   |\n",
      "|    value_loss         | 0.0242     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 59900       |\n",
      "|    time_elapsed       | 950         |\n",
      "|    total_timesteps    | 299500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.8       |\n",
      "|    explained_variance | 0.00094     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 59899       |\n",
      "|    policy_loss        | 5.05        |\n",
      "|    reward             | -0.23324987 |\n",
      "|    std                | 7.86e+03    |\n",
      "|    value_loss         | 0.0798      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 60000      |\n",
      "|    time_elapsed       | 951        |\n",
      "|    total_timesteps    | 300000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.8      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 59999      |\n",
      "|    policy_loss        | -1.94      |\n",
      "|    reward             | 0.19409707 |\n",
      "|    std                | 7.93e+03   |\n",
      "|    value_loss         | 0.0171     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 60100        |\n",
      "|    time_elapsed       | 953          |\n",
      "|    total_timesteps    | 300500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.8        |\n",
      "|    explained_variance | -1.07        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60099        |\n",
      "|    policy_loss        | 3.29         |\n",
      "|    reward             | 0.0056586005 |\n",
      "|    std                | 7.94e+03     |\n",
      "|    value_loss         | 0.0269       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 60200         |\n",
      "|    time_elapsed       | 954           |\n",
      "|    total_timesteps    | 301000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 60199         |\n",
      "|    policy_loss        | 0.437         |\n",
      "|    reward             | -0.0026417903 |\n",
      "|    std                | 8.02e+03      |\n",
      "|    value_loss         | 0.000497      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 60300       |\n",
      "|    time_elapsed       | 956         |\n",
      "|    total_timesteps    | 301500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.8       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 60299       |\n",
      "|    policy_loss        | -0.00544    |\n",
      "|    reward             | 0.012712273 |\n",
      "|    std                | 8.15e+03    |\n",
      "|    value_loss         | 7.23e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 60400       |\n",
      "|    time_elapsed       | 958         |\n",
      "|    total_timesteps    | 302000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.9       |\n",
      "|    explained_variance | -0.108      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 60399       |\n",
      "|    policy_loss        | 1.41        |\n",
      "|    reward             | 0.019805383 |\n",
      "|    std                | 8.22e+03    |\n",
      "|    value_loss         | 0.00493     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 60500      |\n",
      "|    time_elapsed       | 959        |\n",
      "|    total_timesteps    | 302500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.9      |\n",
      "|    explained_variance | 0.605      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 60499      |\n",
      "|    policy_loss        | 2.24       |\n",
      "|    reward             | 0.07085067 |\n",
      "|    std                | 8.44e+03   |\n",
      "|    value_loss         | 0.0115     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 60600       |\n",
      "|    time_elapsed       | 961         |\n",
      "|    total_timesteps    | 303000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21         |\n",
      "|    explained_variance | 0.0503      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 60599       |\n",
      "|    policy_loss        | -0.781      |\n",
      "|    reward             | -0.07300855 |\n",
      "|    std                | 8.59e+03    |\n",
      "|    value_loss         | 0.00479     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 60700         |\n",
      "|    time_elapsed       | 962           |\n",
      "|    total_timesteps    | 303500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21           |\n",
      "|    explained_variance | -0.00328      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 60699         |\n",
      "|    policy_loss        | -0.578        |\n",
      "|    reward             | -0.0044597113 |\n",
      "|    std                | 8.7e+03       |\n",
      "|    value_loss         | 0.00079       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 60800        |\n",
      "|    time_elapsed       | 964          |\n",
      "|    total_timesteps    | 304000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21          |\n",
      "|    explained_variance | 0.614        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60799        |\n",
      "|    policy_loss        | 0.166        |\n",
      "|    reward             | 0.0065260767 |\n",
      "|    std                | 8.83e+03     |\n",
      "|    value_loss         | 9.76e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 60900       |\n",
      "|    time_elapsed       | 965         |\n",
      "|    total_timesteps    | 304500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.1       |\n",
      "|    explained_variance | -0.00128    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 60899       |\n",
      "|    policy_loss        | 0.0965      |\n",
      "|    reward             | 0.004968019 |\n",
      "|    std                | 9.03e+03    |\n",
      "|    value_loss         | 0.000894    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 61000        |\n",
      "|    time_elapsed       | 967          |\n",
      "|    total_timesteps    | 305000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.1        |\n",
      "|    explained_variance | 0.0371       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60999        |\n",
      "|    policy_loss        | -0.257       |\n",
      "|    reward             | -0.014134678 |\n",
      "|    std                | 9.29e+03     |\n",
      "|    value_loss         | 0.000786     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 61100      |\n",
      "|    time_elapsed       | 968        |\n",
      "|    total_timesteps    | 305500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.2      |\n",
      "|    explained_variance | 0.26       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 61099      |\n",
      "|    policy_loss        | 1.61       |\n",
      "|    reward             | 0.03842461 |\n",
      "|    std                | 9.49e+03   |\n",
      "|    value_loss         | 0.0111     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 61200       |\n",
      "|    time_elapsed       | 970         |\n",
      "|    total_timesteps    | 306000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.2       |\n",
      "|    explained_variance | 0.169       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 61199       |\n",
      "|    policy_loss        | 4.23        |\n",
      "|    reward             | -0.12982106 |\n",
      "|    std                | 9.66e+03    |\n",
      "|    value_loss         | 0.0528      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 61300       |\n",
      "|    time_elapsed       | 972         |\n",
      "|    total_timesteps    | 306500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.2       |\n",
      "|    explained_variance | 0.283       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 61299       |\n",
      "|    policy_loss        | 0.308       |\n",
      "|    reward             | 0.025488958 |\n",
      "|    std                | 9.76e+03    |\n",
      "|    value_loss         | 0.00151     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 61400      |\n",
      "|    time_elapsed       | 973        |\n",
      "|    total_timesteps    | 307000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.3      |\n",
      "|    explained_variance | 0.0458     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 61399      |\n",
      "|    policy_loss        | -0.111     |\n",
      "|    reward             | 0.03755666 |\n",
      "|    std                | 1e+04      |\n",
      "|    value_loss         | 0.000122   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 61500        |\n",
      "|    time_elapsed       | 975          |\n",
      "|    total_timesteps    | 307500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.3        |\n",
      "|    explained_variance | 0.194        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61499        |\n",
      "|    policy_loss        | 1.19         |\n",
      "|    reward             | -0.026555575 |\n",
      "|    std                | 1.03e+04     |\n",
      "|    value_loss         | 0.0035       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 315            |\n",
      "|    iterations         | 61600          |\n",
      "|    time_elapsed       | 977            |\n",
      "|    total_timesteps    | 308000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -21.3          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 61599          |\n",
      "|    policy_loss        | 0.803          |\n",
      "|    reward             | -0.00042106476 |\n",
      "|    std                | 1.05e+04       |\n",
      "|    value_loss         | 0.00203        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 61700         |\n",
      "|    time_elapsed       | 978           |\n",
      "|    total_timesteps    | 308500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.4         |\n",
      "|    explained_variance | -0.135        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 61699         |\n",
      "|    policy_loss        | 0.000901      |\n",
      "|    reward             | -0.0064384826 |\n",
      "|    std                | 1.07e+04      |\n",
      "|    value_loss         | 0.000377      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 315            |\n",
      "|    iterations         | 61800          |\n",
      "|    time_elapsed       | 980            |\n",
      "|    total_timesteps    | 309000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -21.4          |\n",
      "|    explained_variance | -1.91          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 61799          |\n",
      "|    policy_loss        | -0.0839        |\n",
      "|    reward             | -0.00033207436 |\n",
      "|    std                | 1.09e+04       |\n",
      "|    value_loss         | 9.09e-05       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 61900       |\n",
      "|    time_elapsed       | 982         |\n",
      "|    total_timesteps    | 309500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.5       |\n",
      "|    explained_variance | 0.499       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 61899       |\n",
      "|    policy_loss        | 0.247       |\n",
      "|    reward             | 0.005187737 |\n",
      "|    std                | 1.11e+04    |\n",
      "|    value_loss         | 0.000252    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 62000       |\n",
      "|    time_elapsed       | 983         |\n",
      "|    total_timesteps    | 310000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.5       |\n",
      "|    explained_variance | 0.815       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 61999       |\n",
      "|    policy_loss        | -0.162      |\n",
      "|    reward             | 0.005228939 |\n",
      "|    std                | 1.14e+04    |\n",
      "|    value_loss         | 0.000117    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 62100        |\n",
      "|    time_elapsed       | 985          |\n",
      "|    total_timesteps    | 310500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.6        |\n",
      "|    explained_variance | 0.16         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62099        |\n",
      "|    policy_loss        | -0.487       |\n",
      "|    reward             | 0.0068650404 |\n",
      "|    std                | 1.16e+04     |\n",
      "|    value_loss         | 0.000633     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 62200        |\n",
      "|    time_elapsed       | 986          |\n",
      "|    total_timesteps    | 311000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.6        |\n",
      "|    explained_variance | -0.125       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62199        |\n",
      "|    policy_loss        | 0.999        |\n",
      "|    reward             | -0.007578212 |\n",
      "|    std                | 1.19e+04     |\n",
      "|    value_loss         | 0.00289      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 62300        |\n",
      "|    time_elapsed       | 988          |\n",
      "|    total_timesteps    | 311500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.6        |\n",
      "|    explained_variance | 0.572        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62299        |\n",
      "|    policy_loss        | -0.392       |\n",
      "|    reward             | 0.0012698944 |\n",
      "|    std                | 1.21e+04     |\n",
      "|    value_loss         | 0.00101      |\n",
      "----------------------------------------\n",
      "day: 2833, episode: 110\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 65097.22\n",
      "total_reward: 55097.22\n",
      "total_cost: 11.72\n",
      "total_trades: 5665\n",
      "Sharpe: 0.696\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 62400         |\n",
      "|    time_elapsed       | 990           |\n",
      "|    total_timesteps    | 312000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 62399         |\n",
      "|    policy_loss        | 0.0841        |\n",
      "|    reward             | -0.0068689566 |\n",
      "|    std                | 1.24e+04      |\n",
      "|    value_loss         | 4.35e-05      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 62500       |\n",
      "|    time_elapsed       | 991         |\n",
      "|    total_timesteps    | 312500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.7       |\n",
      "|    explained_variance | 0.591       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 62499       |\n",
      "|    policy_loss        | -0.107      |\n",
      "|    reward             | 0.012244944 |\n",
      "|    std                | 1.26e+04    |\n",
      "|    value_loss         | 6.19e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 62600       |\n",
      "|    time_elapsed       | 993         |\n",
      "|    total_timesteps    | 313000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.8       |\n",
      "|    explained_variance | 0.11        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 62599       |\n",
      "|    policy_loss        | -0.646      |\n",
      "|    reward             | 0.004118259 |\n",
      "|    std                | 1.3e+04     |\n",
      "|    value_loss         | 0.00311     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 62700        |\n",
      "|    time_elapsed       | 994          |\n",
      "|    total_timesteps    | 313500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.8        |\n",
      "|    explained_variance | 0.0956       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62699        |\n",
      "|    policy_loss        | -0.775       |\n",
      "|    reward             | -0.003026371 |\n",
      "|    std                | 1.33e+04     |\n",
      "|    value_loss         | 0.00244      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 62800       |\n",
      "|    time_elapsed       | 996         |\n",
      "|    total_timesteps    | 314000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.9       |\n",
      "|    explained_variance | 0.234       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 62799       |\n",
      "|    policy_loss        | 3.68        |\n",
      "|    reward             | 0.062952094 |\n",
      "|    std                | 1.36e+04    |\n",
      "|    value_loss         | 0.0337      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 315       |\n",
      "|    iterations         | 62900     |\n",
      "|    time_elapsed       | 997       |\n",
      "|    total_timesteps    | 314500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -21.9     |\n",
      "|    explained_variance | 0.114     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 62899     |\n",
      "|    policy_loss        | 2.05      |\n",
      "|    reward             | 0.1311742 |\n",
      "|    std                | 1.38e+04  |\n",
      "|    value_loss         | 0.023     |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 63000         |\n",
      "|    time_elapsed       | 999           |\n",
      "|    total_timesteps    | 315000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.9         |\n",
      "|    explained_variance | 0.688         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 62999         |\n",
      "|    policy_loss        | 0.783         |\n",
      "|    reward             | -0.0028053261 |\n",
      "|    std                | 1.41e+04      |\n",
      "|    value_loss         | 0.0014        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 63100       |\n",
      "|    time_elapsed       | 1001        |\n",
      "|    total_timesteps    | 315500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22         |\n",
      "|    explained_variance | 0.197       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63099       |\n",
      "|    policy_loss        | 0.29        |\n",
      "|    reward             | 0.011815411 |\n",
      "|    std                | 1.44e+04    |\n",
      "|    value_loss         | 0.000226    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 315            |\n",
      "|    iterations         | 63200          |\n",
      "|    time_elapsed       | 1003           |\n",
      "|    total_timesteps    | 316000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -22            |\n",
      "|    explained_variance | 0.172          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 63199          |\n",
      "|    policy_loss        | 1.59           |\n",
      "|    reward             | -0.00018341828 |\n",
      "|    std                | 1.44e+04       |\n",
      "|    value_loss         | 0.00811        |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 63300       |\n",
      "|    time_elapsed       | 1005        |\n",
      "|    total_timesteps    | 316500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22         |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63299       |\n",
      "|    policy_loss        | -0.639      |\n",
      "|    reward             | -0.05539971 |\n",
      "|    std                | 1.48e+04    |\n",
      "|    value_loss         | 0.00416     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 314        |\n",
      "|    iterations         | 63400      |\n",
      "|    time_elapsed       | 1006       |\n",
      "|    total_timesteps    | 317000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 63399      |\n",
      "|    policy_loss        | 1.1        |\n",
      "|    reward             | 0.13165423 |\n",
      "|    std                | 1.49e+04   |\n",
      "|    value_loss         | 0.00264    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 63500        |\n",
      "|    time_elapsed       | 1008         |\n",
      "|    total_timesteps    | 317500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22          |\n",
      "|    explained_variance | -0.274       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63499        |\n",
      "|    policy_loss        | -1.53        |\n",
      "|    reward             | -0.009297024 |\n",
      "|    std                | 1.49e+04     |\n",
      "|    value_loss         | 0.00495      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 63600        |\n",
      "|    time_elapsed       | 1010         |\n",
      "|    total_timesteps    | 318000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.1        |\n",
      "|    explained_variance | 0.724        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63599        |\n",
      "|    policy_loss        | 0.398        |\n",
      "|    reward             | 0.0015855851 |\n",
      "|    std                | 1.51e+04     |\n",
      "|    value_loss         | 0.000381     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 63700       |\n",
      "|    time_elapsed       | 1012        |\n",
      "|    total_timesteps    | 318500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.1       |\n",
      "|    explained_variance | 0.768       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63699       |\n",
      "|    policy_loss        | 0.14        |\n",
      "|    reward             | 0.006787274 |\n",
      "|    std                | 1.53e+04    |\n",
      "|    value_loss         | 9.26e-05    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 314           |\n",
      "|    iterations         | 63800         |\n",
      "|    time_elapsed       | 1014          |\n",
      "|    total_timesteps    | 319000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.2         |\n",
      "|    explained_variance | 0.00247       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 63799         |\n",
      "|    policy_loss        | -0.38         |\n",
      "|    reward             | -0.0011209229 |\n",
      "|    std                | 1.58e+04      |\n",
      "|    value_loss         | 0.000306      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 63900       |\n",
      "|    time_elapsed       | 1016        |\n",
      "|    total_timesteps    | 319500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.3       |\n",
      "|    explained_variance | 0.228       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63899       |\n",
      "|    policy_loss        | -1.39       |\n",
      "|    reward             | 0.026176514 |\n",
      "|    std                | 1.65e+04    |\n",
      "|    value_loss         | 0.0115      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 314        |\n",
      "|    iterations         | 64000      |\n",
      "|    time_elapsed       | 1019       |\n",
      "|    total_timesteps    | 320000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 63999      |\n",
      "|    policy_loss        | -1.24      |\n",
      "|    reward             | 0.04144048 |\n",
      "|    std                | 1.66e+04   |\n",
      "|    value_loss         | 0.00306    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 313           |\n",
      "|    iterations         | 64100         |\n",
      "|    time_elapsed       | 1021          |\n",
      "|    total_timesteps    | 320500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.3         |\n",
      "|    explained_variance | -1.28         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 64099         |\n",
      "|    policy_loss        | -0.0919       |\n",
      "|    reward             | 0.00092004373 |\n",
      "|    std                | 1.69e+04      |\n",
      "|    value_loss         | 2.97e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 64200        |\n",
      "|    time_elapsed       | 1023         |\n",
      "|    total_timesteps    | 321000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.3        |\n",
      "|    explained_variance | -0.335       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 64199        |\n",
      "|    policy_loss        | -0.138       |\n",
      "|    reward             | 0.0033585324 |\n",
      "|    std                | 1.73e+04     |\n",
      "|    value_loss         | 4.56e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 64300        |\n",
      "|    time_elapsed       | 1024         |\n",
      "|    total_timesteps    | 321500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 64299        |\n",
      "|    policy_loss        | -1.98        |\n",
      "|    reward             | -0.013047851 |\n",
      "|    std                | 1.77e+04     |\n",
      "|    value_loss         | 0.00819      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 64400        |\n",
      "|    time_elapsed       | 1026         |\n",
      "|    total_timesteps    | 322000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 64399        |\n",
      "|    policy_loss        | -0.845       |\n",
      "|    reward             | 0.0017155304 |\n",
      "|    std                | 1.81e+04     |\n",
      "|    value_loss         | 0.00189      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 313        |\n",
      "|    iterations         | 64500      |\n",
      "|    time_elapsed       | 1028       |\n",
      "|    total_timesteps    | 322500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.5      |\n",
      "|    explained_variance | 0.675      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 64499      |\n",
      "|    policy_loss        | 3.81       |\n",
      "|    reward             | -0.0597493 |\n",
      "|    std                | 1.84e+04   |\n",
      "|    value_loss         | 0.029      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 64600       |\n",
      "|    time_elapsed       | 1029        |\n",
      "|    total_timesteps    | 323000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.5       |\n",
      "|    explained_variance | 0.253       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 64599       |\n",
      "|    policy_loss        | -0.731      |\n",
      "|    reward             | 0.054480072 |\n",
      "|    std                | 1.86e+04    |\n",
      "|    value_loss         | 0.0197      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 64700        |\n",
      "|    time_elapsed       | 1031         |\n",
      "|    total_timesteps    | 323500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.5        |\n",
      "|    explained_variance | -0.0143      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 64699        |\n",
      "|    policy_loss        | -0.481       |\n",
      "|    reward             | 0.0025756971 |\n",
      "|    std                | 1.89e+04     |\n",
      "|    value_loss         | 0.00077      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 313           |\n",
      "|    iterations         | 64800         |\n",
      "|    time_elapsed       | 1032          |\n",
      "|    total_timesteps    | 324000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.6         |\n",
      "|    explained_variance | 0.0553        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 64799         |\n",
      "|    policy_loss        | -0.208        |\n",
      "|    reward             | -0.0020188298 |\n",
      "|    std                | 1.92e+04      |\n",
      "|    value_loss         | 0.0003        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 64900       |\n",
      "|    time_elapsed       | 1034        |\n",
      "|    total_timesteps    | 324500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.6       |\n",
      "|    explained_variance | -0.0422     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 64899       |\n",
      "|    policy_loss        | 1.89        |\n",
      "|    reward             | 0.012073611 |\n",
      "|    std                | 1.97e+04    |\n",
      "|    value_loss         | 0.00746     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 313        |\n",
      "|    iterations         | 65000      |\n",
      "|    time_elapsed       | 1036       |\n",
      "|    total_timesteps    | 325000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 64999      |\n",
      "|    policy_loss        | -1.67      |\n",
      "|    reward             | 0.04877629 |\n",
      "|    std                | 2.02e+04   |\n",
      "|    value_loss         | 0.00867    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 313        |\n",
      "|    iterations         | 65100      |\n",
      "|    time_elapsed       | 1037       |\n",
      "|    total_timesteps    | 325500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.7      |\n",
      "|    explained_variance | -0.159     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 65099      |\n",
      "|    policy_loss        | 0.959      |\n",
      "|    reward             | 0.06669444 |\n",
      "|    std                | 2.04e+04   |\n",
      "|    value_loss         | 0.00438    |\n",
      "--------------------------------------\n",
      "day: 2833, episode: 115\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 77760.57\n",
      "total_reward: 67760.57\n",
      "total_cost: 23.21\n",
      "total_trades: 5662\n",
      "Sharpe: 0.745\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 65200        |\n",
      "|    time_elapsed       | 1039         |\n",
      "|    total_timesteps    | 326000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.7        |\n",
      "|    explained_variance | 0.365        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65199        |\n",
      "|    policy_loss        | -0.454       |\n",
      "|    reward             | -0.008104709 |\n",
      "|    std                | 2.07e+04     |\n",
      "|    value_loss         | 0.000529     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 65300        |\n",
      "|    time_elapsed       | 1041         |\n",
      "|    total_timesteps    | 326500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.7        |\n",
      "|    explained_variance | 0.604        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65299        |\n",
      "|    policy_loss        | -0.167       |\n",
      "|    reward             | -0.005761843 |\n",
      "|    std                | 2.1e+04      |\n",
      "|    value_loss         | 0.000162     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 65400        |\n",
      "|    time_elapsed       | 1043         |\n",
      "|    total_timesteps    | 327000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.8        |\n",
      "|    explained_variance | 0.521        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65399        |\n",
      "|    policy_loss        | -0.00892     |\n",
      "|    reward             | -0.016093554 |\n",
      "|    std                | 2.15e+04     |\n",
      "|    value_loss         | 0.000153     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 65500       |\n",
      "|    time_elapsed       | 1044        |\n",
      "|    total_timesteps    | 327500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.8       |\n",
      "|    explained_variance | 0.157       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 65499       |\n",
      "|    policy_loss        | 0.138       |\n",
      "|    reward             | 0.040839344 |\n",
      "|    std                | 2.2e+04     |\n",
      "|    value_loss         | 0.0002      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 313           |\n",
      "|    iterations         | 65600         |\n",
      "|    time_elapsed       | 1046          |\n",
      "|    total_timesteps    | 328000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.9         |\n",
      "|    explained_variance | 0.0261        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 65599         |\n",
      "|    policy_loss        | -6.32         |\n",
      "|    reward             | -0.0051775663 |\n",
      "|    std                | 2.26e+04      |\n",
      "|    value_loss         | 0.0904        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 65700        |\n",
      "|    time_elapsed       | 1048         |\n",
      "|    total_timesteps    | 328500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.9        |\n",
      "|    explained_variance | 0.0328       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65699        |\n",
      "|    policy_loss        | 0.999        |\n",
      "|    reward             | -0.021759186 |\n",
      "|    std                | 2.26e+04     |\n",
      "|    value_loss         | 0.00247      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 65800       |\n",
      "|    time_elapsed       | 1049        |\n",
      "|    total_timesteps    | 329000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.9       |\n",
      "|    explained_variance | -13.5       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 65799       |\n",
      "|    policy_loss        | 0.098       |\n",
      "|    reward             | 0.014454352 |\n",
      "|    std                | 2.3e+04     |\n",
      "|    value_loss         | 7.61e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 65900       |\n",
      "|    time_elapsed       | 1051        |\n",
      "|    total_timesteps    | 329500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23         |\n",
      "|    explained_variance | 0.208       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 65899       |\n",
      "|    policy_loss        | -0.0549     |\n",
      "|    reward             | 0.012258584 |\n",
      "|    std                | 2.34e+04    |\n",
      "|    value_loss         | 3.66e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 66000       |\n",
      "|    time_elapsed       | 1053        |\n",
      "|    total_timesteps    | 330000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 65999       |\n",
      "|    policy_loss        | 0.93        |\n",
      "|    reward             | 0.041939072 |\n",
      "|    std                | 2.39e+04    |\n",
      "|    value_loss         | 0.00195     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 66100       |\n",
      "|    time_elapsed       | 1054        |\n",
      "|    total_timesteps    | 330500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66099       |\n",
      "|    policy_loss        | -0.833      |\n",
      "|    reward             | -0.00768757 |\n",
      "|    std                | 2.43e+04    |\n",
      "|    value_loss         | 0.00215     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 66200       |\n",
      "|    time_elapsed       | 1056        |\n",
      "|    total_timesteps    | 331000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.1       |\n",
      "|    explained_variance | 0.568       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66199       |\n",
      "|    policy_loss        | 0.707       |\n",
      "|    reward             | -0.09388998 |\n",
      "|    std                | 2.47e+04    |\n",
      "|    value_loss         | 0.00193     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 66300     |\n",
      "|    time_elapsed       | 1058      |\n",
      "|    total_timesteps    | 331500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -23.1     |\n",
      "|    explained_variance | -0.00309  |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 66299     |\n",
      "|    policy_loss        | -18.2     |\n",
      "|    reward             | 0.3735039 |\n",
      "|    std                | 2.47e+04  |\n",
      "|    value_loss         | 0.746     |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 66400        |\n",
      "|    time_elapsed       | 1059         |\n",
      "|    total_timesteps    | 332000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.1        |\n",
      "|    explained_variance | 0.374        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 66399        |\n",
      "|    policy_loss        | 0.32         |\n",
      "|    reward             | 0.0017294621 |\n",
      "|    std                | 2.48e+04     |\n",
      "|    value_loss         | 0.000304     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 313           |\n",
      "|    iterations         | 66500         |\n",
      "|    time_elapsed       | 1061          |\n",
      "|    total_timesteps    | 332500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.1         |\n",
      "|    explained_variance | 0.52          |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 66499         |\n",
      "|    policy_loss        | -0.186        |\n",
      "|    reward             | 0.00042681885 |\n",
      "|    std                | 2.53e+04      |\n",
      "|    value_loss         | 0.000126      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 313           |\n",
      "|    iterations         | 66600         |\n",
      "|    time_elapsed       | 1062          |\n",
      "|    total_timesteps    | 333000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.2         |\n",
      "|    explained_variance | 0.286         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 66599         |\n",
      "|    policy_loss        | 0.198         |\n",
      "|    reward             | -0.0062909606 |\n",
      "|    std                | 2.61e+04      |\n",
      "|    value_loss         | 0.000402      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 66700       |\n",
      "|    time_elapsed       | 1064        |\n",
      "|    total_timesteps    | 333500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66699       |\n",
      "|    policy_loss        | -1.04       |\n",
      "|    reward             | 0.053586494 |\n",
      "|    std                | 2.7e+04     |\n",
      "|    value_loss         | 0.0035      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 66800        |\n",
      "|    time_elapsed       | 1065         |\n",
      "|    total_timesteps    | 334000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.3        |\n",
      "|    explained_variance | 0.174        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 66799        |\n",
      "|    policy_loss        | 2.03         |\n",
      "|    reward             | -0.011996993 |\n",
      "|    std                | 2.75e+04     |\n",
      "|    value_loss         | 0.0101       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 66900        |\n",
      "|    time_elapsed       | 1067         |\n",
      "|    total_timesteps    | 334500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.3        |\n",
      "|    explained_variance | 0.567        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 66899        |\n",
      "|    policy_loss        | -0.092       |\n",
      "|    reward             | 0.0004968828 |\n",
      "|    std                | 2.82e+04     |\n",
      "|    value_loss         | 7.38e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 67000       |\n",
      "|    time_elapsed       | 1069        |\n",
      "|    total_timesteps    | 335000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.4       |\n",
      "|    explained_variance | 0.598       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66999       |\n",
      "|    policy_loss        | -0.386      |\n",
      "|    reward             | 0.011772268 |\n",
      "|    std                | 2.87e+04    |\n",
      "|    value_loss         | 0.000387    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 67100        |\n",
      "|    time_elapsed       | 1070         |\n",
      "|    total_timesteps    | 335500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.4        |\n",
      "|    explained_variance | 0.219        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67099        |\n",
      "|    policy_loss        | 0.437        |\n",
      "|    reward             | -0.009840541 |\n",
      "|    std                | 2.94e+04     |\n",
      "|    value_loss         | 0.000598     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 67200        |\n",
      "|    time_elapsed       | 1072         |\n",
      "|    total_timesteps    | 336000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.4        |\n",
      "|    explained_variance | 0.1          |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67199        |\n",
      "|    policy_loss        | 0.722        |\n",
      "|    reward             | -0.010309324 |\n",
      "|    std                | 2.99e+04     |\n",
      "|    value_loss         | 0.00127      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 67300        |\n",
      "|    time_elapsed       | 1074         |\n",
      "|    total_timesteps    | 336500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.5        |\n",
      "|    explained_variance | 0.308        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67299        |\n",
      "|    policy_loss        | -0.826       |\n",
      "|    reward             | 0.0055894777 |\n",
      "|    std                | 3.04e+04     |\n",
      "|    value_loss         | 0.00335      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 67400       |\n",
      "|    time_elapsed       | 1075        |\n",
      "|    total_timesteps    | 337000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.5       |\n",
      "|    explained_variance | 0.119       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 67399       |\n",
      "|    policy_loss        | -0.69       |\n",
      "|    reward             | 0.071793586 |\n",
      "|    std                | 3.1e+04     |\n",
      "|    value_loss         | 0.00258     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 67500        |\n",
      "|    time_elapsed       | 1077         |\n",
      "|    total_timesteps    | 337500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67499        |\n",
      "|    policy_loss        | -0.113       |\n",
      "|    reward             | -0.016123975 |\n",
      "|    std                | 3.1e+04      |\n",
      "|    value_loss         | 7.39e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 67600        |\n",
      "|    time_elapsed       | 1078         |\n",
      "|    total_timesteps    | 338000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.6        |\n",
      "|    explained_variance | -8.46e-05    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67599        |\n",
      "|    policy_loss        | -0.499       |\n",
      "|    reward             | -0.010736341 |\n",
      "|    std                | 3.15e+04     |\n",
      "|    value_loss         | 0.000586     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 313           |\n",
      "|    iterations         | 67700         |\n",
      "|    time_elapsed       | 1080          |\n",
      "|    total_timesteps    | 338500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 67699         |\n",
      "|    policy_loss        | 1.32          |\n",
      "|    reward             | -0.0002589943 |\n",
      "|    std                | 3.22e+04      |\n",
      "|    value_loss         | 0.00441       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 67800        |\n",
      "|    time_elapsed       | 1082         |\n",
      "|    total_timesteps    | 339000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67799        |\n",
      "|    policy_loss        | 0.455        |\n",
      "|    reward             | -0.074907295 |\n",
      "|    std                | 3.31e+04     |\n",
      "|    value_loss         | 0.00229      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 67900       |\n",
      "|    time_elapsed       | 1083        |\n",
      "|    total_timesteps    | 339500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.7       |\n",
      "|    explained_variance | 0.702       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 67899       |\n",
      "|    policy_loss        | 0.446       |\n",
      "|    reward             | 0.038927693 |\n",
      "|    std                | 3.38e+04    |\n",
      "|    value_loss         | 0.00321     |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 68000    |\n",
      "|    time_elapsed       | 1085     |\n",
      "|    total_timesteps    | 340000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -23.7    |\n",
      "|    explained_variance | 0.128    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 67999    |\n",
      "|    policy_loss        | -15.3    |\n",
      "|    reward             | 0.271622 |\n",
      "|    std                | 3.41e+04 |\n",
      "|    value_loss         | 0.424    |\n",
      "------------------------------------\n",
      "day: 2833, episode: 120\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 110956.23\n",
      "total_reward: 100956.23\n",
      "total_cost: 53.32\n",
      "total_trades: 5656\n",
      "Sharpe: 0.895\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 68100       |\n",
      "|    time_elapsed       | 1086        |\n",
      "|    total_timesteps    | 340500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.7       |\n",
      "|    explained_variance | 0.326       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68099       |\n",
      "|    policy_loss        | -2.27       |\n",
      "|    reward             | 0.008690081 |\n",
      "|    std                | 3.43e+04    |\n",
      "|    value_loss         | 0.0107      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 68200       |\n",
      "|    time_elapsed       | 1088        |\n",
      "|    total_timesteps    | 341000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.7       |\n",
      "|    explained_variance | 0.244       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68199       |\n",
      "|    policy_loss        | -0.238      |\n",
      "|    reward             | 0.007896964 |\n",
      "|    std                | 3.45e+04    |\n",
      "|    value_loss         | 0.00113     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 68300       |\n",
      "|    time_elapsed       | 1089        |\n",
      "|    total_timesteps    | 341500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.8       |\n",
      "|    explained_variance | 0.24        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68299       |\n",
      "|    policy_loss        | -2.92       |\n",
      "|    reward             | -0.03688331 |\n",
      "|    std                | 3.52e+04    |\n",
      "|    value_loss         | 0.0313      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 68400       |\n",
      "|    time_elapsed       | 1091        |\n",
      "|    total_timesteps    | 342000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.8       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68399       |\n",
      "|    policy_loss        | 3.44        |\n",
      "|    reward             | -0.06183952 |\n",
      "|    std                | 3.57e+04    |\n",
      "|    value_loss         | 0.0933      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 68500        |\n",
      "|    time_elapsed       | 1092         |\n",
      "|    total_timesteps    | 342500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 68499        |\n",
      "|    policy_loss        | 11.5         |\n",
      "|    reward             | -0.024226232 |\n",
      "|    std                | 3.57e+04     |\n",
      "|    value_loss         | 0.25         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 68600       |\n",
      "|    time_elapsed       | 1094        |\n",
      "|    total_timesteps    | 343000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.8       |\n",
      "|    explained_variance | -16.9       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68599       |\n",
      "|    policy_loss        | 2.14        |\n",
      "|    reward             | 0.009760504 |\n",
      "|    std                | 3.56e+04    |\n",
      "|    value_loss         | 0.0154      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 68700       |\n",
      "|    time_elapsed       | 1095        |\n",
      "|    total_timesteps    | 343500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.8       |\n",
      "|    explained_variance | 0.817       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68699       |\n",
      "|    policy_loss        | -0.524      |\n",
      "|    reward             | 0.022394786 |\n",
      "|    std                | 3.6e+04     |\n",
      "|    value_loss         | 0.000532    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 68800        |\n",
      "|    time_elapsed       | 1097         |\n",
      "|    total_timesteps    | 344000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.9        |\n",
      "|    explained_variance | 0.298        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 68799        |\n",
      "|    policy_loss        | 0.108        |\n",
      "|    reward             | -0.016771667 |\n",
      "|    std                | 3.66e+04     |\n",
      "|    value_loss         | 0.000162     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 68900       |\n",
      "|    time_elapsed       | 1098        |\n",
      "|    total_timesteps    | 344500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.9       |\n",
      "|    explained_variance | 0.417       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68899       |\n",
      "|    policy_loss        | 0.559       |\n",
      "|    reward             | 0.010966299 |\n",
      "|    std                | 3.69e+04    |\n",
      "|    value_loss         | 0.00104     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 69000        |\n",
      "|    time_elapsed       | 1100         |\n",
      "|    total_timesteps    | 345000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.9        |\n",
      "|    explained_variance | 0.316        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 68999        |\n",
      "|    policy_loss        | 1.12         |\n",
      "|    reward             | -0.010162134 |\n",
      "|    std                | 3.75e+04     |\n",
      "|    value_loss         | 0.00239      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 69100        |\n",
      "|    time_elapsed       | 1101         |\n",
      "|    total_timesteps    | 345500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69099        |\n",
      "|    policy_loss        | 1.08         |\n",
      "|    reward             | -0.022373259 |\n",
      "|    std                | 3.82e+04     |\n",
      "|    value_loss         | 0.00318      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 69200        |\n",
      "|    time_elapsed       | 1103         |\n",
      "|    total_timesteps    | 346000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24          |\n",
      "|    explained_variance | 0.765        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69199        |\n",
      "|    policy_loss        | 0.0617       |\n",
      "|    reward             | -0.008102538 |\n",
      "|    std                | 3.9e+04      |\n",
      "|    value_loss         | 3.24e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 69300        |\n",
      "|    time_elapsed       | 1104         |\n",
      "|    total_timesteps    | 346500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69299        |\n",
      "|    policy_loss        | -0.276       |\n",
      "|    reward             | 0.0039633177 |\n",
      "|    std                | 3.98e+04     |\n",
      "|    value_loss         | 0.000245     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 69400        |\n",
      "|    time_elapsed       | 1106         |\n",
      "|    total_timesteps    | 347000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.1        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69399        |\n",
      "|    policy_loss        | 0.876        |\n",
      "|    reward             | -0.033574995 |\n",
      "|    std                | 4.1e+04      |\n",
      "|    value_loss         | 0.00218      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 69500        |\n",
      "|    time_elapsed       | 1107         |\n",
      "|    total_timesteps    | 347500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69499        |\n",
      "|    policy_loss        | 2.31         |\n",
      "|    reward             | -0.014396573 |\n",
      "|    std                | 4.18e+04     |\n",
      "|    value_loss         | 0.00926      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 69600        |\n",
      "|    time_elapsed       | 1109         |\n",
      "|    total_timesteps    | 348000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.1        |\n",
      "|    explained_variance | 0.189        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69599        |\n",
      "|    policy_loss        | -3.13        |\n",
      "|    reward             | -0.041852143 |\n",
      "|    std                | 4.22e+04     |\n",
      "|    value_loss         | 0.0176       |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 69700    |\n",
      "|    time_elapsed       | 1110     |\n",
      "|    total_timesteps    | 348500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -24.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 69699    |\n",
      "|    policy_loss        | 1.89     |\n",
      "|    reward             | 0.440015 |\n",
      "|    std                | 4.28e+04 |\n",
      "|    value_loss         | 0.0466   |\n",
      "------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 69800        |\n",
      "|    time_elapsed       | 1112         |\n",
      "|    total_timesteps    | 349000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.2        |\n",
      "|    explained_variance | -1.62        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69799        |\n",
      "|    policy_loss        | -0.027       |\n",
      "|    reward             | 0.0075398283 |\n",
      "|    std                | 4.34e+04     |\n",
      "|    value_loss         | 0.000486     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 69900       |\n",
      "|    time_elapsed       | 1114        |\n",
      "|    total_timesteps    | 349500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.2       |\n",
      "|    explained_variance | 0.29        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 69899       |\n",
      "|    policy_loss        | 0.48        |\n",
      "|    reward             | 0.008634285 |\n",
      "|    std                | 4.41e+04    |\n",
      "|    value_loss         | 0.000422    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 70000       |\n",
      "|    time_elapsed       | 1115        |\n",
      "|    total_timesteps    | 350000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.3       |\n",
      "|    explained_variance | -1.02       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 69999       |\n",
      "|    policy_loss        | 0.695       |\n",
      "|    reward             | 0.024655253 |\n",
      "|    std                | 4.53e+04    |\n",
      "|    value_loss         | 0.00212     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 70100        |\n",
      "|    time_elapsed       | 1117         |\n",
      "|    total_timesteps    | 350500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.3        |\n",
      "|    explained_variance | 0.0734       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70099        |\n",
      "|    policy_loss        | -2.06        |\n",
      "|    reward             | -0.013706164 |\n",
      "|    std                | 4.64e+04     |\n",
      "|    value_loss         | 0.00756      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 70200       |\n",
      "|    time_elapsed       | 1118        |\n",
      "|    total_timesteps    | 351000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.4       |\n",
      "|    explained_variance | -0.00183    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70199       |\n",
      "|    policy_loss        | -0.693      |\n",
      "|    reward             | 0.013758447 |\n",
      "|    std                | 4.73e+04    |\n",
      "|    value_loss         | 0.0011      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 70300        |\n",
      "|    time_elapsed       | 1120         |\n",
      "|    total_timesteps    | 351500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.4        |\n",
      "|    explained_variance | -0.719       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70299        |\n",
      "|    policy_loss        | 0.525        |\n",
      "|    reward             | 0.0127805015 |\n",
      "|    std                | 4.79e+04     |\n",
      "|    value_loss         | 0.00066      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 70400       |\n",
      "|    time_elapsed       | 1121        |\n",
      "|    total_timesteps    | 352000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70399       |\n",
      "|    policy_loss        | 0.336       |\n",
      "|    reward             | 0.007592195 |\n",
      "|    std                | 4.88e+04    |\n",
      "|    value_loss         | 0.00022     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 70500        |\n",
      "|    time_elapsed       | 1123         |\n",
      "|    total_timesteps    | 352500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.5        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70499        |\n",
      "|    policy_loss        | 0.0182       |\n",
      "|    reward             | -0.012965995 |\n",
      "|    std                | 5.01e+04     |\n",
      "|    value_loss         | 2.57e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 70600       |\n",
      "|    time_elapsed       | 1125        |\n",
      "|    total_timesteps    | 353000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.5       |\n",
      "|    explained_variance | 0.233       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70599       |\n",
      "|    policy_loss        | 0.807       |\n",
      "|    reward             | 0.009059279 |\n",
      "|    std                | 5.07e+04    |\n",
      "|    value_loss         | 0.00141     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 70700       |\n",
      "|    time_elapsed       | 1127        |\n",
      "|    total_timesteps    | 353500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.5       |\n",
      "|    explained_variance | 0.37        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70699       |\n",
      "|    policy_loss        | 0.566       |\n",
      "|    reward             | -0.18136042 |\n",
      "|    std                | 5.11e+04    |\n",
      "|    value_loss         | 0.000689    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 70800       |\n",
      "|    time_elapsed       | 1128        |\n",
      "|    total_timesteps    | 354000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.6       |\n",
      "|    explained_variance | 0.000488    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70799       |\n",
      "|    policy_loss        | 1.2         |\n",
      "|    reward             | 0.047546756 |\n",
      "|    std                | 5.28e+04    |\n",
      "|    value_loss         | 0.00379     |\n",
      "---------------------------------------\n",
      "day: 2833, episode: 125\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 62203.99\n",
      "total_reward: 52203.99\n",
      "total_cost: 11.87\n",
      "total_trades: 5665\n",
      "Sharpe: 0.694\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 70900        |\n",
      "|    time_elapsed       | 1129         |\n",
      "|    total_timesteps    | 354500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.6        |\n",
      "|    explained_variance | 0.76         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70899        |\n",
      "|    policy_loss        | -0.519       |\n",
      "|    reward             | 0.0021238702 |\n",
      "|    std                | 5.37e+04     |\n",
      "|    value_loss         | 0.000484     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 71000       |\n",
      "|    time_elapsed       | 1131        |\n",
      "|    total_timesteps    | 355000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70999       |\n",
      "|    policy_loss        | -0.478      |\n",
      "|    reward             | 0.008061781 |\n",
      "|    std                | 5.45e+04    |\n",
      "|    value_loss         | 0.000493    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 71100       |\n",
      "|    time_elapsed       | 1132        |\n",
      "|    total_timesteps    | 355500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.7       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 71099       |\n",
      "|    policy_loss        | -1.03       |\n",
      "|    reward             | 0.024760818 |\n",
      "|    std                | 5.58e+04    |\n",
      "|    value_loss         | 0.00278     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 71200       |\n",
      "|    time_elapsed       | 1134        |\n",
      "|    total_timesteps    | 356000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.7       |\n",
      "|    explained_variance | 1.84e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 71199       |\n",
      "|    policy_loss        | 0.778       |\n",
      "|    reward             | 0.043625806 |\n",
      "|    std                | 5.61e+04    |\n",
      "|    value_loss         | 0.00157     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 71300       |\n",
      "|    time_elapsed       | 1135        |\n",
      "|    total_timesteps    | 356500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.7       |\n",
      "|    explained_variance | 0.0665      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 71299       |\n",
      "|    policy_loss        | 1.25        |\n",
      "|    reward             | 0.016271729 |\n",
      "|    std                | 5.66e+04    |\n",
      "|    value_loss         | 0.00349     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 313        |\n",
      "|    iterations         | 71400      |\n",
      "|    time_elapsed       | 1137       |\n",
      "|    total_timesteps    | 357000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24.8      |\n",
      "|    explained_variance | 0.287      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 71399      |\n",
      "|    policy_loss        | -3.39      |\n",
      "|    reward             | 0.16135521 |\n",
      "|    std                | 5.77e+04   |\n",
      "|    value_loss         | 0.0771     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 313           |\n",
      "|    iterations         | 71500         |\n",
      "|    time_elapsed       | 1138          |\n",
      "|    total_timesteps    | 357500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.8         |\n",
      "|    explained_variance | 0.582         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 71499         |\n",
      "|    policy_loss        | -0.0909       |\n",
      "|    reward             | -0.0009699669 |\n",
      "|    std                | 5.83e+04      |\n",
      "|    value_loss         | 5.53e-05      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 313           |\n",
      "|    iterations         | 71600         |\n",
      "|    time_elapsed       | 1140          |\n",
      "|    total_timesteps    | 358000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.8         |\n",
      "|    explained_variance | 0.283         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 71599         |\n",
      "|    policy_loss        | 0.048         |\n",
      "|    reward             | -0.0120870555 |\n",
      "|    std                | 5.93e+04      |\n",
      "|    value_loss         | 6.03e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 71700        |\n",
      "|    time_elapsed       | 1141         |\n",
      "|    total_timesteps    | 358500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.9        |\n",
      "|    explained_variance | -0.714       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 71699        |\n",
      "|    policy_loss        | 1.98         |\n",
      "|    reward             | -0.029714251 |\n",
      "|    std                | 6.11e+04     |\n",
      "|    value_loss         | 0.00698      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 71800       |\n",
      "|    time_elapsed       | 1143        |\n",
      "|    total_timesteps    | 359000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.9       |\n",
      "|    explained_variance | 0.151       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 71799       |\n",
      "|    policy_loss        | 1.29        |\n",
      "|    reward             | 0.012528903 |\n",
      "|    std                | 6.24e+04    |\n",
      "|    value_loss         | 0.0104      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 313        |\n",
      "|    iterations         | 71900      |\n",
      "|    time_elapsed       | 1145       |\n",
      "|    total_timesteps    | 359500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24.9      |\n",
      "|    explained_variance | 0.555      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 71899      |\n",
      "|    policy_loss        | -0.0468    |\n",
      "|    reward             | 0.11382689 |\n",
      "|    std                | 6.33e+04   |\n",
      "|    value_loss         | 0.00137    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 313           |\n",
      "|    iterations         | 72000         |\n",
      "|    time_elapsed       | 1146          |\n",
      "|    total_timesteps    | 360000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25           |\n",
      "|    explained_variance | 0.317         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 71999         |\n",
      "|    policy_loss        | -0.411        |\n",
      "|    reward             | -0.0011322107 |\n",
      "|    std                | 6.36e+04      |\n",
      "|    value_loss         | 0.000393      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 72100        |\n",
      "|    time_elapsed       | 1148         |\n",
      "|    total_timesteps    | 360500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25          |\n",
      "|    explained_variance | 0.184        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72099        |\n",
      "|    policy_loss        | -0.0539      |\n",
      "|    reward             | -0.011683178 |\n",
      "|    std                | 6.46e+04     |\n",
      "|    value_loss         | 1.67e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 72200       |\n",
      "|    time_elapsed       | 1149        |\n",
      "|    total_timesteps    | 361000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25         |\n",
      "|    explained_variance | 0.588       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 72199       |\n",
      "|    policy_loss        | -0.208      |\n",
      "|    reward             | 0.006567591 |\n",
      "|    std                | 6.62e+04    |\n",
      "|    value_loss         | 0.00013     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 72300       |\n",
      "|    time_elapsed       | 1151        |\n",
      "|    total_timesteps    | 361500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.1       |\n",
      "|    explained_variance | 0.782       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 72299       |\n",
      "|    policy_loss        | -0.71       |\n",
      "|    reward             | 0.049354956 |\n",
      "|    std                | 6.76e+04    |\n",
      "|    value_loss         | 0.00107     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 314        |\n",
      "|    iterations         | 72400      |\n",
      "|    time_elapsed       | 1152       |\n",
      "|    total_timesteps    | 362000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.1      |\n",
      "|    explained_variance | 0.761      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 72399      |\n",
      "|    policy_loss        | -1.14      |\n",
      "|    reward             | 0.04864455 |\n",
      "|    std                | 6.75e+04   |\n",
      "|    value_loss         | 0.0029     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 72500       |\n",
      "|    time_elapsed       | 1154        |\n",
      "|    total_timesteps    | 362500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 72499       |\n",
      "|    policy_loss        | -0.889      |\n",
      "|    reward             | 0.056061093 |\n",
      "|    std                | 6.87e+04    |\n",
      "|    value_loss         | 0.00489     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 72600        |\n",
      "|    time_elapsed       | 1155         |\n",
      "|    total_timesteps    | 363000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.1        |\n",
      "|    explained_variance | 0.15         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72599        |\n",
      "|    policy_loss        | -0.195       |\n",
      "|    reward             | -0.002776236 |\n",
      "|    std                | 6.98e+04     |\n",
      "|    value_loss         | 0.000535     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 72700        |\n",
      "|    time_elapsed       | 1157         |\n",
      "|    total_timesteps    | 363500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.2        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72699        |\n",
      "|    policy_loss        | 0.113        |\n",
      "|    reward             | 0.0016569565 |\n",
      "|    std                | 7.08e+04     |\n",
      "|    value_loss         | 0.000118     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 72800       |\n",
      "|    time_elapsed       | 1158        |\n",
      "|    total_timesteps    | 364000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 72799       |\n",
      "|    policy_loss        | -2.02       |\n",
      "|    reward             | 0.033882797 |\n",
      "|    std                | 7.22e+04    |\n",
      "|    value_loss         | 0.0085      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 72900        |\n",
      "|    time_elapsed       | 1160         |\n",
      "|    total_timesteps    | 364500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.2        |\n",
      "|    explained_variance | -0.0301      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72899        |\n",
      "|    policy_loss        | 0.635        |\n",
      "|    reward             | 0.0042767576 |\n",
      "|    std                | 7.23e+04     |\n",
      "|    value_loss         | 0.00226      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 73000        |\n",
      "|    time_elapsed       | 1161         |\n",
      "|    total_timesteps    | 365000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.2        |\n",
      "|    explained_variance | 0.454        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72999        |\n",
      "|    policy_loss        | -0.644       |\n",
      "|    reward             | -0.031129688 |\n",
      "|    std                | 7.18e+04     |\n",
      "|    value_loss         | 0.00193      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 73100       |\n",
      "|    time_elapsed       | 1163        |\n",
      "|    total_timesteps    | 365500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.2       |\n",
      "|    explained_variance | 0.0302      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73099       |\n",
      "|    policy_loss        | -1.06       |\n",
      "|    reward             | -0.39243844 |\n",
      "|    std                | 7.2e+04     |\n",
      "|    value_loss         | 0.0254      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 73200        |\n",
      "|    time_elapsed       | 1165         |\n",
      "|    total_timesteps    | 366000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.2        |\n",
      "|    explained_variance | 0.871        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 73199        |\n",
      "|    policy_loss        | 0.265        |\n",
      "|    reward             | -0.013010812 |\n",
      "|    std                | 7.27e+04     |\n",
      "|    value_loss         | 0.000122     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 73300       |\n",
      "|    time_elapsed       | 1166        |\n",
      "|    total_timesteps    | 366500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.3       |\n",
      "|    explained_variance | -0.193      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73299       |\n",
      "|    policy_loss        | 0.0132      |\n",
      "|    reward             | 0.031907167 |\n",
      "|    std                | 7.39e+04    |\n",
      "|    value_loss         | 7.3e-05     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 314           |\n",
      "|    iterations         | 73400         |\n",
      "|    time_elapsed       | 1168          |\n",
      "|    total_timesteps    | 367000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.3         |\n",
      "|    explained_variance | 0.113         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 73399         |\n",
      "|    policy_loss        | 0.222         |\n",
      "|    reward             | -0.0009550575 |\n",
      "|    std                | 7.6e+04       |\n",
      "|    value_loss         | 0.000441      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 73500       |\n",
      "|    time_elapsed       | 1169        |\n",
      "|    total_timesteps    | 367500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.3       |\n",
      "|    explained_variance | 0.134       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73499       |\n",
      "|    policy_loss        | 3.29        |\n",
      "|    reward             | 0.035932127 |\n",
      "|    std                | 7.73e+04    |\n",
      "|    value_loss         | 0.0173      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 314        |\n",
      "|    iterations         | 73600      |\n",
      "|    time_elapsed       | 1171       |\n",
      "|    total_timesteps    | 368000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.4      |\n",
      "|    explained_variance | 0.969      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 73599      |\n",
      "|    policy_loss        | -0.293     |\n",
      "|    reward             | 0.04536299 |\n",
      "|    std                | 7.81e+04   |\n",
      "|    value_loss         | 0.000177   |\n",
      "--------------------------------------\n",
      "day: 2833, episode: 130\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 60182.54\n",
      "total_reward: 50182.54\n",
      "total_cost: 14.46\n",
      "total_trades: 5666\n",
      "Sharpe: 0.668\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 73700        |\n",
      "|    time_elapsed       | 1172         |\n",
      "|    total_timesteps    | 368500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.4        |\n",
      "|    explained_variance | 0.188        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 73699        |\n",
      "|    policy_loss        | -0.621       |\n",
      "|    reward             | -0.011851155 |\n",
      "|    std                | 7.79e+04     |\n",
      "|    value_loss         | 0.000814     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 73800       |\n",
      "|    time_elapsed       | 1174        |\n",
      "|    total_timesteps    | 369000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.4       |\n",
      "|    explained_variance | 0.447       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73799       |\n",
      "|    policy_loss        | -0.486      |\n",
      "|    reward             | 0.043040223 |\n",
      "|    std                | 7.88e+04    |\n",
      "|    value_loss         | 0.000658    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 314        |\n",
      "|    iterations         | 73900      |\n",
      "|    time_elapsed       | 1175       |\n",
      "|    total_timesteps    | 369500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 73899      |\n",
      "|    policy_loss        | -0.736     |\n",
      "|    reward             | -0.0460058 |\n",
      "|    std                | 8.07e+04   |\n",
      "|    value_loss         | 0.00116    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 74000       |\n",
      "|    time_elapsed       | 1177        |\n",
      "|    total_timesteps    | 370000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.5       |\n",
      "|    explained_variance | 0.648       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73999       |\n",
      "|    policy_loss        | -0.222      |\n",
      "|    reward             | 0.035164867 |\n",
      "|    std                | 8.15e+04    |\n",
      "|    value_loss         | 0.00339     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 74100       |\n",
      "|    time_elapsed       | 1179        |\n",
      "|    total_timesteps    | 370500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.5       |\n",
      "|    explained_variance | 0.329       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 74099       |\n",
      "|    policy_loss        | -1.32       |\n",
      "|    reward             | 0.053118184 |\n",
      "|    std                | 8.25e+04    |\n",
      "|    value_loss         | 0.0123      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 74200       |\n",
      "|    time_elapsed       | 1180        |\n",
      "|    total_timesteps    | 371000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.5       |\n",
      "|    explained_variance | 1.79e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 74199       |\n",
      "|    policy_loss        | -3.51       |\n",
      "|    reward             | -0.06905211 |\n",
      "|    std                | 8.41e+04    |\n",
      "|    value_loss         | 0.029       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 74300       |\n",
      "|    time_elapsed       | 1182        |\n",
      "|    total_timesteps    | 371500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.5       |\n",
      "|    explained_variance | -0.0237     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 74299       |\n",
      "|    policy_loss        | 0.444       |\n",
      "|    reward             | 0.008699609 |\n",
      "|    std                | 8.49e+04    |\n",
      "|    value_loss         | 0.000303    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 74400       |\n",
      "|    time_elapsed       | 1184        |\n",
      "|    total_timesteps    | 372000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.6       |\n",
      "|    explained_variance | 0.55        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 74399       |\n",
      "|    policy_loss        | 0.667       |\n",
      "|    reward             | 0.019115454 |\n",
      "|    std                | 8.58e+04    |\n",
      "|    value_loss         | 0.000726    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 314       |\n",
      "|    iterations         | 74500     |\n",
      "|    time_elapsed       | 1185      |\n",
      "|    total_timesteps    | 372500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -25.6     |\n",
      "|    explained_variance | -0.0121   |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 74499     |\n",
      "|    policy_loss        | -2.14     |\n",
      "|    reward             | 0.1578756 |\n",
      "|    std                | 8.69e+04  |\n",
      "|    value_loss         | 0.0081    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 314        |\n",
      "|    iterations         | 74600      |\n",
      "|    time_elapsed       | 1187       |\n",
      "|    total_timesteps    | 373000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.6      |\n",
      "|    explained_variance | -0.000214  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 74599      |\n",
      "|    policy_loss        | 3.74       |\n",
      "|    reward             | 0.07995324 |\n",
      "|    std                | 8.73e+04   |\n",
      "|    value_loss         | 0.0251     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 74700       |\n",
      "|    time_elapsed       | 1188        |\n",
      "|    total_timesteps    | 373500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.6       |\n",
      "|    explained_variance | 0.00226     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 74699       |\n",
      "|    policy_loss        | -3.92       |\n",
      "|    reward             | -0.20151006 |\n",
      "|    std                | 8.88e+04    |\n",
      "|    value_loss         | 0.0374      |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 314      |\n",
      "|    iterations         | 74800    |\n",
      "|    time_elapsed       | 1190     |\n",
      "|    total_timesteps    | 374000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -25.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 74799    |\n",
      "|    policy_loss        | -10.3    |\n",
      "|    reward             | 0.763954 |\n",
      "|    std                | 8.93e+04 |\n",
      "|    value_loss         | 0.18     |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 314           |\n",
      "|    iterations         | 74900         |\n",
      "|    time_elapsed       | 1192          |\n",
      "|    total_timesteps    | 374500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.7         |\n",
      "|    explained_variance | 0.377         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 74899         |\n",
      "|    policy_loss        | -0.393        |\n",
      "|    reward             | -0.0065877764 |\n",
      "|    std                | 9.05e+04      |\n",
      "|    value_loss         | 0.00039       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 75000        |\n",
      "|    time_elapsed       | 1193         |\n",
      "|    total_timesteps    | 375000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.7        |\n",
      "|    explained_variance | -3.71        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 74999        |\n",
      "|    policy_loss        | 0.00122      |\n",
      "|    reward             | 0.0027869018 |\n",
      "|    std                | 9.14e+04     |\n",
      "|    value_loss         | 1.55e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 75100        |\n",
      "|    time_elapsed       | 1195         |\n",
      "|    total_timesteps    | 375500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.7        |\n",
      "|    explained_variance | 0.123        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 75099        |\n",
      "|    policy_loss        | 0.733        |\n",
      "|    reward             | -0.039247856 |\n",
      "|    std                | 9.36e+04     |\n",
      "|    value_loss         | 0.00147      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 75200        |\n",
      "|    time_elapsed       | 1196         |\n",
      "|    total_timesteps    | 376000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.8        |\n",
      "|    explained_variance | 0.385        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 75199        |\n",
      "|    policy_loss        | -0.345       |\n",
      "|    reward             | 0.0039476072 |\n",
      "|    std                | 9.48e+04     |\n",
      "|    value_loss         | 0.000292     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 75300       |\n",
      "|    time_elapsed       | 1198        |\n",
      "|    total_timesteps    | 376500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.8       |\n",
      "|    explained_variance | 0.214       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75299       |\n",
      "|    policy_loss        | -2.45       |\n",
      "|    reward             | 0.026004039 |\n",
      "|    std                | 9.51e+04    |\n",
      "|    value_loss         | 0.00956     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 75400        |\n",
      "|    time_elapsed       | 1200         |\n",
      "|    total_timesteps    | 377000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.8        |\n",
      "|    explained_variance | -0.49        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 75399        |\n",
      "|    policy_loss        | -0.495       |\n",
      "|    reward             | 0.0023084905 |\n",
      "|    std                | 9.64e+04     |\n",
      "|    value_loss         | 0.000393     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 75500        |\n",
      "|    time_elapsed       | 1201         |\n",
      "|    total_timesteps    | 377500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.8        |\n",
      "|    explained_variance | -0.00522     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 75499        |\n",
      "|    policy_loss        | -0.41        |\n",
      "|    reward             | 0.0046022125 |\n",
      "|    std                | 9.79e+04     |\n",
      "|    value_loss         | 0.000367     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 314           |\n",
      "|    iterations         | 75600         |\n",
      "|    time_elapsed       | 1203          |\n",
      "|    total_timesteps    | 378000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 75599         |\n",
      "|    policy_loss        | -0.355        |\n",
      "|    reward             | -0.0066049783 |\n",
      "|    std                | 1e+05         |\n",
      "|    value_loss         | 0.000286      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 314        |\n",
      "|    iterations         | 75700      |\n",
      "|    time_elapsed       | 1204       |\n",
      "|    total_timesteps    | 378500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.9      |\n",
      "|    explained_variance | 0.274      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 75699      |\n",
      "|    policy_loss        | 0.705      |\n",
      "|    reward             | 0.04685315 |\n",
      "|    std                | 1.04e+05   |\n",
      "|    value_loss         | 0.00334    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 75800        |\n",
      "|    time_elapsed       | 1206         |\n",
      "|    total_timesteps    | 379000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26          |\n",
      "|    explained_variance | 0.167        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 75799        |\n",
      "|    policy_loss        | -2.12        |\n",
      "|    reward             | -0.030279396 |\n",
      "|    std                | 1.06e+05     |\n",
      "|    value_loss         | 0.00821      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 75900       |\n",
      "|    time_elapsed       | 1207        |\n",
      "|    total_timesteps    | 379500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26         |\n",
      "|    explained_variance | 0.0395      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75899       |\n",
      "|    policy_loss        | 1.59        |\n",
      "|    reward             | 0.035530563 |\n",
      "|    std                | 1.09e+05    |\n",
      "|    value_loss         | 0.00718     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 314        |\n",
      "|    iterations         | 76000      |\n",
      "|    time_elapsed       | 1209       |\n",
      "|    total_timesteps    | 380000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26        |\n",
      "|    explained_variance | 0.664      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 75999      |\n",
      "|    policy_loss        | -0.384     |\n",
      "|    reward             | 0.01642812 |\n",
      "|    std                | 1.09e+05   |\n",
      "|    value_loss         | 0.000279   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 76100        |\n",
      "|    time_elapsed       | 1210         |\n",
      "|    total_timesteps    | 380500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.1        |\n",
      "|    explained_variance | 0.623        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76099        |\n",
      "|    policy_loss        | -0.0255      |\n",
      "|    reward             | -0.014925412 |\n",
      "|    std                | 1.11e+05     |\n",
      "|    value_loss         | 5.33e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 76200       |\n",
      "|    time_elapsed       | 1212        |\n",
      "|    total_timesteps    | 381000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 76199       |\n",
      "|    policy_loss        | 0.405       |\n",
      "|    reward             | 0.027340245 |\n",
      "|    std                | 1.14e+05    |\n",
      "|    value_loss         | 0.000418    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 314       |\n",
      "|    iterations         | 76300     |\n",
      "|    time_elapsed       | 1214      |\n",
      "|    total_timesteps    | 381500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -26.2     |\n",
      "|    explained_variance | 0.261     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 76299     |\n",
      "|    policy_loss        | -1.17     |\n",
      "|    reward             | 0.0230737 |\n",
      "|    std                | 1.16e+05  |\n",
      "|    value_loss         | 0.00267   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 76400       |\n",
      "|    time_elapsed       | 1215        |\n",
      "|    total_timesteps    | 382000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 76399       |\n",
      "|    policy_loss        | -1.48       |\n",
      "|    reward             | 0.031721402 |\n",
      "|    std                | 1.17e+05    |\n",
      "|    value_loss         | 0.00576     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 314        |\n",
      "|    iterations         | 76500      |\n",
      "|    time_elapsed       | 1217       |\n",
      "|    total_timesteps    | 382500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 76499      |\n",
      "|    policy_loss        | 0.0554     |\n",
      "|    reward             | -0.5152734 |\n",
      "|    std                | 1.17e+05   |\n",
      "|    value_loss         | 0.0178     |\n",
      "--------------------------------------\n",
      "day: 2833, episode: 135\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 110855.74\n",
      "total_reward: 100855.74\n",
      "total_cost: 12.04\n",
      "total_trades: 5665\n",
      "Sharpe: 0.794\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 76600        |\n",
      "|    time_elapsed       | 1218         |\n",
      "|    total_timesteps    | 383000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.2        |\n",
      "|    explained_variance | 0.0564       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76599        |\n",
      "|    policy_loss        | 0.405        |\n",
      "|    reward             | 0.0015485603 |\n",
      "|    std                | 1.18e+05     |\n",
      "|    value_loss         | 0.000655     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 76700       |\n",
      "|    time_elapsed       | 1220        |\n",
      "|    total_timesteps    | 383500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 76699       |\n",
      "|    policy_loss        | -0.168      |\n",
      "|    reward             | 0.014770444 |\n",
      "|    std                | 1.19e+05    |\n",
      "|    value_loss         | 0.000175    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 76800        |\n",
      "|    time_elapsed       | 1221         |\n",
      "|    total_timesteps    | 384000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.3        |\n",
      "|    explained_variance | 0.357        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76799        |\n",
      "|    policy_loss        | 1.08         |\n",
      "|    reward             | -0.004306846 |\n",
      "|    std                | 1.22e+05     |\n",
      "|    value_loss         | 0.00178      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 76900       |\n",
      "|    time_elapsed       | 1223        |\n",
      "|    total_timesteps    | 384500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.3       |\n",
      "|    explained_variance | 0.0376      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 76899       |\n",
      "|    policy_loss        | -0.127      |\n",
      "|    reward             | 0.024924057 |\n",
      "|    std                | 1.25e+05    |\n",
      "|    value_loss         | 0.000185    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 77000       |\n",
      "|    time_elapsed       | 1224        |\n",
      "|    total_timesteps    | 385000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.3       |\n",
      "|    explained_variance | -0.506      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 76999       |\n",
      "|    policy_loss        | 0.0357      |\n",
      "|    reward             | 0.033930313 |\n",
      "|    std                | 1.28e+05    |\n",
      "|    value_loss         | 0.000641    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 314           |\n",
      "|    iterations         | 77100         |\n",
      "|    time_elapsed       | 1226          |\n",
      "|    total_timesteps    | 385500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.4         |\n",
      "|    explained_variance | -0.318        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 77099         |\n",
      "|    policy_loss        | -0.422        |\n",
      "|    reward             | -0.0016940144 |\n",
      "|    std                | 1.29e+05      |\n",
      "|    value_loss         | 0.00031       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 77200        |\n",
      "|    time_elapsed       | 1227         |\n",
      "|    total_timesteps    | 386000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.4        |\n",
      "|    explained_variance | -0.247       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77199        |\n",
      "|    policy_loss        | -0.344       |\n",
      "|    reward             | 0.0069693844 |\n",
      "|    std                | 1.31e+05     |\n",
      "|    value_loss         | 0.000248     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 314           |\n",
      "|    iterations         | 77300         |\n",
      "|    time_elapsed       | 1229          |\n",
      "|    total_timesteps    | 386500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.5         |\n",
      "|    explained_variance | 0.26          |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 77299         |\n",
      "|    policy_loss        | 0.549         |\n",
      "|    reward             | 0.00089381525 |\n",
      "|    std                | 1.36e+05      |\n",
      "|    value_loss         | 0.000545      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 77400        |\n",
      "|    time_elapsed       | 1230         |\n",
      "|    total_timesteps    | 387000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.5        |\n",
      "|    explained_variance | 0.0976       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77399        |\n",
      "|    policy_loss        | -0.887       |\n",
      "|    reward             | 0.0029819058 |\n",
      "|    std                | 1.37e+05     |\n",
      "|    value_loss         | 0.00479      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 77500        |\n",
      "|    time_elapsed       | 1232         |\n",
      "|    total_timesteps    | 387500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77499        |\n",
      "|    policy_loss        | -0.802       |\n",
      "|    reward             | -0.018684944 |\n",
      "|    std                | 1.4e+05      |\n",
      "|    value_loss         | 0.00192      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 77600       |\n",
      "|    time_elapsed       | 1233        |\n",
      "|    total_timesteps    | 388000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 77599       |\n",
      "|    policy_loss        | 3.98        |\n",
      "|    reward             | 0.024015937 |\n",
      "|    std                | 1.41e+05    |\n",
      "|    value_loss         | 0.0295      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 314           |\n",
      "|    iterations         | 77700         |\n",
      "|    time_elapsed       | 1235          |\n",
      "|    total_timesteps    | 388500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.6         |\n",
      "|    explained_variance | 0.277         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 77699         |\n",
      "|    policy_loss        | -0.893        |\n",
      "|    reward             | -0.0046341186 |\n",
      "|    std                | 1.42e+05      |\n",
      "|    value_loss         | 0.0014        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 77800       |\n",
      "|    time_elapsed       | 1237        |\n",
      "|    total_timesteps    | 389000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.6       |\n",
      "|    explained_variance | 0.504       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 77799       |\n",
      "|    policy_loss        | 0.152       |\n",
      "|    reward             | 0.015201578 |\n",
      "|    std                | 1.44e+05    |\n",
      "|    value_loss         | 9.07e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 77900       |\n",
      "|    time_elapsed       | 1238        |\n",
      "|    total_timesteps    | 389500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.6       |\n",
      "|    explained_variance | 1.03e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 77899       |\n",
      "|    policy_loss        | 3           |\n",
      "|    reward             | -0.04881076 |\n",
      "|    std                | 1.48e+05    |\n",
      "|    value_loss         | 0.04        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 314        |\n",
      "|    iterations         | 78000      |\n",
      "|    time_elapsed       | 1240       |\n",
      "|    total_timesteps    | 390000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.7      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 77999      |\n",
      "|    policy_loss        | -0.937     |\n",
      "|    reward             | 0.02593537 |\n",
      "|    std                | 1.51e+05   |\n",
      "|    value_loss         | 0.00311    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 314        |\n",
      "|    iterations         | 78100      |\n",
      "|    time_elapsed       | 1241       |\n",
      "|    total_timesteps    | 390500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.7      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 78099      |\n",
      "|    policy_loss        | -1.29      |\n",
      "|    reward             | 0.09398454 |\n",
      "|    std                | 1.52e+05   |\n",
      "|    value_loss         | 0.00259    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 78200       |\n",
      "|    time_elapsed       | 1243        |\n",
      "|    total_timesteps    | 391000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78199       |\n",
      "|    policy_loss        | 8.07        |\n",
      "|    reward             | -0.12220207 |\n",
      "|    std                | 1.52e+05    |\n",
      "|    value_loss         | 0.108       |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 314            |\n",
      "|    iterations         | 78300          |\n",
      "|    time_elapsed       | 1244           |\n",
      "|    total_timesteps    | 391500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -26.7          |\n",
      "|    explained_variance | -0.216         |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 78299          |\n",
      "|    policy_loss        | 0.265          |\n",
      "|    reward             | -0.00029685916 |\n",
      "|    std                | 1.53e+05       |\n",
      "|    value_loss         | 0.000224       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 78400        |\n",
      "|    time_elapsed       | 1246         |\n",
      "|    total_timesteps    | 392000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.7        |\n",
      "|    explained_variance | 0.115        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 78399        |\n",
      "|    policy_loss        | -0.115       |\n",
      "|    reward             | -0.024208518 |\n",
      "|    std                | 1.54e+05     |\n",
      "|    value_loss         | 4.67e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 78500        |\n",
      "|    time_elapsed       | 1248         |\n",
      "|    total_timesteps    | 392500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.8        |\n",
      "|    explained_variance | 0.0482       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 78499        |\n",
      "|    policy_loss        | -0.743       |\n",
      "|    reward             | -0.023350228 |\n",
      "|    std                | 1.57e+05     |\n",
      "|    value_loss         | 0.00304      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 314        |\n",
      "|    iterations         | 78600      |\n",
      "|    time_elapsed       | 1249       |\n",
      "|    total_timesteps    | 393000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.8      |\n",
      "|    explained_variance | 0.842      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 78599      |\n",
      "|    policy_loss        | -0.481     |\n",
      "|    reward             | 0.12911506 |\n",
      "|    std                | 1.59e+05   |\n",
      "|    value_loss         | 0.000518   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 78700       |\n",
      "|    time_elapsed       | 1251        |\n",
      "|    total_timesteps    | 393500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.8       |\n",
      "|    explained_variance | 0.481       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78699       |\n",
      "|    policy_loss        | 1.31        |\n",
      "|    reward             | 0.030359235 |\n",
      "|    std                | 1.61e+05    |\n",
      "|    value_loss         | 0.00617     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 78800        |\n",
      "|    time_elapsed       | 1252         |\n",
      "|    total_timesteps    | 394000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.9        |\n",
      "|    explained_variance | -8.37        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 78799        |\n",
      "|    policy_loss        | -0.307       |\n",
      "|    reward             | 0.0074250456 |\n",
      "|    std                | 1.65e+05     |\n",
      "|    value_loss         | 0.00035      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 78900        |\n",
      "|    time_elapsed       | 1254         |\n",
      "|    total_timesteps    | 394500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.9        |\n",
      "|    explained_variance | -0.182       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 78899        |\n",
      "|    policy_loss        | 0.523        |\n",
      "|    reward             | -0.006469435 |\n",
      "|    std                | 1.67e+05     |\n",
      "|    value_loss         | 0.000531     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 79000       |\n",
      "|    time_elapsed       | 1256        |\n",
      "|    total_timesteps    | 395000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.9       |\n",
      "|    explained_variance | 0.365       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78999       |\n",
      "|    policy_loss        | 0.745       |\n",
      "|    reward             | 0.008773725 |\n",
      "|    std                | 1.71e+05    |\n",
      "|    value_loss         | 0.00082     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 79100        |\n",
      "|    time_elapsed       | 1257         |\n",
      "|    total_timesteps    | 395500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27          |\n",
      "|    explained_variance | -0.138       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 79099        |\n",
      "|    policy_loss        | -3.06        |\n",
      "|    reward             | -0.012788801 |\n",
      "|    std                | 1.74e+05     |\n",
      "|    value_loss         | 0.0126       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 79200       |\n",
      "|    time_elapsed       | 1259        |\n",
      "|    total_timesteps    | 396000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27         |\n",
      "|    explained_variance | 0.000273    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79199       |\n",
      "|    policy_loss        | -1.67       |\n",
      "|    reward             | -0.07173863 |\n",
      "|    std                | 1.77e+05    |\n",
      "|    value_loss         | 0.0059      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 79300       |\n",
      "|    time_elapsed       | 1260        |\n",
      "|    total_timesteps    | 396500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79299       |\n",
      "|    policy_loss        | 1.27        |\n",
      "|    reward             | -0.02495893 |\n",
      "|    std                | 1.79e+05    |\n",
      "|    value_loss         | 0.0273      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2833, episode: 140\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 91412.56\n",
      "total_reward: 81412.56\n",
      "total_cost: 10.61\n",
      "total_trades: 5665\n",
      "Sharpe: 0.763\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 79400        |\n",
      "|    time_elapsed       | 1262         |\n",
      "|    total_timesteps    | 397000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.1        |\n",
      "|    explained_variance | -0.973       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 79399        |\n",
      "|    policy_loss        | 1.41         |\n",
      "|    reward             | -0.012548753 |\n",
      "|    std                | 1.82e+05     |\n",
      "|    value_loss         | 0.00413      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 79500        |\n",
      "|    time_elapsed       | 1263         |\n",
      "|    total_timesteps    | 397500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.1        |\n",
      "|    explained_variance | 0.177        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 79499        |\n",
      "|    policy_loss        | 0.302        |\n",
      "|    reward             | -0.001564896 |\n",
      "|    std                | 1.84e+05     |\n",
      "|    value_loss         | 0.00015      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 79600        |\n",
      "|    time_elapsed       | 1266         |\n",
      "|    total_timesteps    | 398000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.1        |\n",
      "|    explained_variance | 0.0472       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 79599        |\n",
      "|    policy_loss        | 1.29         |\n",
      "|    reward             | -0.025014177 |\n",
      "|    std                | 1.86e+05     |\n",
      "|    value_loss         | 0.00321      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 79700       |\n",
      "|    time_elapsed       | 1267        |\n",
      "|    total_timesteps    | 398500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.1       |\n",
      "|    explained_variance | 2.97e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79699       |\n",
      "|    policy_loss        | 0.695       |\n",
      "|    reward             | 0.033884473 |\n",
      "|    std                | 1.9e+05     |\n",
      "|    value_loss         | 0.000841    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 79800        |\n",
      "|    time_elapsed       | 1269         |\n",
      "|    total_timesteps    | 399000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.2        |\n",
      "|    explained_variance | 0.00156      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 79799        |\n",
      "|    policy_loss        | 0.206        |\n",
      "|    reward             | -0.033322394 |\n",
      "|    std                | 1.96e+05     |\n",
      "|    value_loss         | 0.000474     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 79900       |\n",
      "|    time_elapsed       | 1270        |\n",
      "|    total_timesteps    | 399500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.2       |\n",
      "|    explained_variance | 1.87e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79899       |\n",
      "|    policy_loss        | 1.71        |\n",
      "|    reward             | 0.021643475 |\n",
      "|    std                | 1.98e+05    |\n",
      "|    value_loss         | 0.00404     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 80000       |\n",
      "|    time_elapsed       | 1272        |\n",
      "|    total_timesteps    | 400000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.2       |\n",
      "|    explained_variance | -0.348      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79999       |\n",
      "|    policy_loss        | -0.586      |\n",
      "|    reward             | 0.006373675 |\n",
      "|    std                | 2e+05       |\n",
      "|    value_loss         | 0.000527    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 314            |\n",
      "|    iterations         | 80100          |\n",
      "|    time_elapsed       | 1274           |\n",
      "|    total_timesteps    | 400500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -27.3          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 80099          |\n",
      "|    policy_loss        | -0.158         |\n",
      "|    reward             | -0.00020985794 |\n",
      "|    std                | 2.04e+05       |\n",
      "|    value_loss         | 0.000223       |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 314        |\n",
      "|    iterations         | 80200      |\n",
      "|    time_elapsed       | 1275       |\n",
      "|    total_timesteps    | 401000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27.4      |\n",
      "|    explained_variance | 0.0185     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 80199      |\n",
      "|    policy_loss        | 4.83       |\n",
      "|    reward             | 0.06595588 |\n",
      "|    std                | 2.12e+05   |\n",
      "|    value_loss         | 0.0339     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 80300       |\n",
      "|    time_elapsed       | 1277        |\n",
      "|    total_timesteps    | 401500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.4       |\n",
      "|    explained_variance | 0.059       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80299       |\n",
      "|    policy_loss        | -2.45       |\n",
      "|    reward             | -0.04110214 |\n",
      "|    std                | 2.15e+05    |\n",
      "|    value_loss         | 0.0127      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 80400       |\n",
      "|    time_elapsed       | 1279        |\n",
      "|    total_timesteps    | 402000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.4       |\n",
      "|    explained_variance | 0.759       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80399       |\n",
      "|    policy_loss        | 7.34        |\n",
      "|    reward             | -0.05488161 |\n",
      "|    std                | 2.17e+05    |\n",
      "|    value_loss         | 0.0749      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 314           |\n",
      "|    iterations         | 80500         |\n",
      "|    time_elapsed       | 1280          |\n",
      "|    total_timesteps    | 402500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 80499         |\n",
      "|    policy_loss        | -0.464        |\n",
      "|    reward             | -0.0033409165 |\n",
      "|    std                | 2.19e+05      |\n",
      "|    value_loss         | 0.000452      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 314           |\n",
      "|    iterations         | 80600         |\n",
      "|    time_elapsed       | 1282          |\n",
      "|    total_timesteps    | 403000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.5         |\n",
      "|    explained_variance | 0.564         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 80599         |\n",
      "|    policy_loss        | 0.418         |\n",
      "|    reward             | -0.0066640573 |\n",
      "|    std                | 2.22e+05      |\n",
      "|    value_loss         | 0.000258      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 314           |\n",
      "|    iterations         | 80700         |\n",
      "|    time_elapsed       | 1283          |\n",
      "|    total_timesteps    | 403500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.5         |\n",
      "|    explained_variance | 4.16e-05      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 80699         |\n",
      "|    policy_loss        | -0.237        |\n",
      "|    reward             | -0.0059216223 |\n",
      "|    std                | 2.27e+05      |\n",
      "|    value_loss         | 0.000121      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 80800       |\n",
      "|    time_elapsed       | 1285        |\n",
      "|    total_timesteps    | 404000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.5       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80799       |\n",
      "|    policy_loss        | 0.0308      |\n",
      "|    reward             | 0.021195613 |\n",
      "|    std                | 2.33e+05    |\n",
      "|    value_loss         | 5.05e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 80900       |\n",
      "|    time_elapsed       | 1286        |\n",
      "|    total_timesteps    | 404500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80899       |\n",
      "|    policy_loss        | -0.821      |\n",
      "|    reward             | -0.04513113 |\n",
      "|    std                | 2.41e+05    |\n",
      "|    value_loss         | 0.000914    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 81000        |\n",
      "|    time_elapsed       | 1288         |\n",
      "|    total_timesteps    | 405000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.6        |\n",
      "|    explained_variance | 0.0945       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 80999        |\n",
      "|    policy_loss        | -2.35        |\n",
      "|    reward             | -0.009808653 |\n",
      "|    std                | 2.41e+05     |\n",
      "|    value_loss         | 0.0112       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 81100       |\n",
      "|    time_elapsed       | 1289        |\n",
      "|    total_timesteps    | 405500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.7       |\n",
      "|    explained_variance | 0.491       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 81099       |\n",
      "|    policy_loss        | 1.59        |\n",
      "|    reward             | 0.006640584 |\n",
      "|    std                | 2.47e+05    |\n",
      "|    value_loss         | 0.00333     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 314           |\n",
      "|    iterations         | 81200         |\n",
      "|    time_elapsed       | 1291          |\n",
      "|    total_timesteps    | 406000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.7         |\n",
      "|    explained_variance | 0.693         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 81199         |\n",
      "|    policy_loss        | 0.0363        |\n",
      "|    reward             | -0.0026862323 |\n",
      "|    std                | 2.54e+05      |\n",
      "|    value_loss         | 8.99e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 314           |\n",
      "|    iterations         | 81300         |\n",
      "|    time_elapsed       | 1292          |\n",
      "|    total_timesteps    | 406500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.8         |\n",
      "|    explained_variance | 9.66e-06      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 81299         |\n",
      "|    policy_loss        | 0.209         |\n",
      "|    reward             | -0.0035958386 |\n",
      "|    std                | 2.63e+05      |\n",
      "|    value_loss         | 9.11e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 81400        |\n",
      "|    time_elapsed       | 1294         |\n",
      "|    total_timesteps    | 407000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 81399        |\n",
      "|    policy_loss        | 0.43         |\n",
      "|    reward             | 0.0023871001 |\n",
      "|    std                | 2.75e+05     |\n",
      "|    value_loss         | 0.000292     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 81500       |\n",
      "|    time_elapsed       | 1296        |\n",
      "|    total_timesteps    | 407500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.9       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 81499       |\n",
      "|    policy_loss        | 0.532       |\n",
      "|    reward             | 0.004447165 |\n",
      "|    std                | 2.82e+05    |\n",
      "|    value_loss         | 0.000755    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 81600       |\n",
      "|    time_elapsed       | 1297        |\n",
      "|    total_timesteps    | 408000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28         |\n",
      "|    explained_variance | -0.00211    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 81599       |\n",
      "|    policy_loss        | -0.205      |\n",
      "|    reward             | 0.035102952 |\n",
      "|    std                | 2.91e+05    |\n",
      "|    value_loss         | 0.000362    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 314           |\n",
      "|    iterations         | 81700         |\n",
      "|    time_elapsed       | 1299          |\n",
      "|    total_timesteps    | 408500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28           |\n",
      "|    explained_variance | -0.0238       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 81699         |\n",
      "|    policy_loss        | 1.24          |\n",
      "|    reward             | -0.0021006307 |\n",
      "|    std                | 2.98e+05      |\n",
      "|    value_loss         | 0.0025        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 314           |\n",
      "|    iterations         | 81800         |\n",
      "|    time_elapsed       | 1300          |\n",
      "|    total_timesteps    | 409000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.1         |\n",
      "|    explained_variance | -0.0419       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 81799         |\n",
      "|    policy_loss        | -0.281        |\n",
      "|    reward             | -0.0025384217 |\n",
      "|    std                | 3.04e+05      |\n",
      "|    value_loss         | 0.000395      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 81900       |\n",
      "|    time_elapsed       | 1302        |\n",
      "|    total_timesteps    | 409500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.2       |\n",
      "|    explained_variance | 0.366       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 81899       |\n",
      "|    policy_loss        | 0.257       |\n",
      "|    reward             | 0.061005745 |\n",
      "|    std                | 3.18e+05    |\n",
      "|    value_loss         | 0.000306    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 314           |\n",
      "|    iterations         | 82000         |\n",
      "|    time_elapsed       | 1304          |\n",
      "|    total_timesteps    | 410000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.2         |\n",
      "|    explained_variance | 0.00446       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 81999         |\n",
      "|    policy_loss        | -0.433        |\n",
      "|    reward             | -0.0036456299 |\n",
      "|    std                | 3.23e+05      |\n",
      "|    value_loss         | 0.000549      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 82100        |\n",
      "|    time_elapsed       | 1305         |\n",
      "|    total_timesteps    | 410500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.2        |\n",
      "|    explained_variance | 0.351        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82099        |\n",
      "|    policy_loss        | 0.508        |\n",
      "|    reward             | -0.034723617 |\n",
      "|    std                | 3.25e+05     |\n",
      "|    value_loss         | 0.00314      |\n",
      "----------------------------------------\n",
      "day: 2833, episode: 145\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 79547.25\n",
      "total_reward: 69547.25\n",
      "total_cost: 22.35\n",
      "total_trades: 5659\n",
      "Sharpe: 0.749\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 82200       |\n",
      "|    time_elapsed       | 1307        |\n",
      "|    total_timesteps    | 411000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.2       |\n",
      "|    explained_variance | -0.432      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 82199       |\n",
      "|    policy_loss        | -1.34       |\n",
      "|    reward             | 0.008328179 |\n",
      "|    std                | 3.27e+05    |\n",
      "|    value_loss         | 0.00321     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 314           |\n",
      "|    iterations         | 82300         |\n",
      "|    time_elapsed       | 1308          |\n",
      "|    total_timesteps    | 411500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.3         |\n",
      "|    explained_variance | -1.14         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 82299         |\n",
      "|    policy_loss        | -0.126        |\n",
      "|    reward             | -0.0026473154 |\n",
      "|    std                | 3.31e+05      |\n",
      "|    value_loss         | 0.00049       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 314           |\n",
      "|    iterations         | 82400         |\n",
      "|    time_elapsed       | 1310          |\n",
      "|    total_timesteps    | 412000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.3         |\n",
      "|    explained_variance | 0.589         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 82399         |\n",
      "|    policy_loss        | 0.0973        |\n",
      "|    reward             | -0.0025074864 |\n",
      "|    std                | 3.38e+05      |\n",
      "|    value_loss         | 4.75e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 82500        |\n",
      "|    time_elapsed       | 1311         |\n",
      "|    total_timesteps    | 412500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82499        |\n",
      "|    policy_loss        | 0.442        |\n",
      "|    reward             | -0.045994595 |\n",
      "|    std                | 3.47e+05     |\n",
      "|    value_loss         | 0.00025      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 82600        |\n",
      "|    time_elapsed       | 1313         |\n",
      "|    total_timesteps    | 413000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.4        |\n",
      "|    explained_variance | -0.0147      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82599        |\n",
      "|    policy_loss        | 0.555        |\n",
      "|    reward             | 0.0028864173 |\n",
      "|    std                | 3.57e+05     |\n",
      "|    value_loss         | 0.000481     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 82700        |\n",
      "|    time_elapsed       | 1314         |\n",
      "|    total_timesteps    | 413500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.5        |\n",
      "|    explained_variance | -0.167       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82699        |\n",
      "|    policy_loss        | -0.72        |\n",
      "|    reward             | 0.0148253245 |\n",
      "|    std                | 3.66e+05     |\n",
      "|    value_loss         | 0.000765     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 82800        |\n",
      "|    time_elapsed       | 1316         |\n",
      "|    total_timesteps    | 414000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.5        |\n",
      "|    explained_variance | 0.169        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82799        |\n",
      "|    policy_loss        | -0.286       |\n",
      "|    reward             | -0.014155049 |\n",
      "|    std                | 3.73e+05     |\n",
      "|    value_loss         | 0.000439     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 82900       |\n",
      "|    time_elapsed       | 1317        |\n",
      "|    total_timesteps    | 414500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.5       |\n",
      "|    explained_variance | 0.456       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 82899       |\n",
      "|    policy_loss        | 0.0752      |\n",
      "|    reward             | 0.010348824 |\n",
      "|    std                | 3.81e+05    |\n",
      "|    value_loss         | 8.3e-05     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 83000       |\n",
      "|    time_elapsed       | 1319        |\n",
      "|    total_timesteps    | 415000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.6       |\n",
      "|    explained_variance | 0.0835      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 82999       |\n",
      "|    policy_loss        | 0.742       |\n",
      "|    reward             | 0.023528019 |\n",
      "|    std                | 3.92e+05    |\n",
      "|    value_loss         | 0.000819    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 83100        |\n",
      "|    time_elapsed       | 1320         |\n",
      "|    total_timesteps    | 415500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.6        |\n",
      "|    explained_variance | 0.374        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 83099        |\n",
      "|    policy_loss        | 0.191        |\n",
      "|    reward             | -0.040428907 |\n",
      "|    std                | 3.98e+05     |\n",
      "|    value_loss         | 0.000117     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 83200       |\n",
      "|    time_elapsed       | 1322        |\n",
      "|    total_timesteps    | 416000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.7       |\n",
      "|    explained_variance | 0.115       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83199       |\n",
      "|    policy_loss        | 1.9         |\n",
      "|    reward             | 0.038563985 |\n",
      "|    std                | 4.08e+05    |\n",
      "|    value_loss         | 0.00563     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 314        |\n",
      "|    iterations         | 83300      |\n",
      "|    time_elapsed       | 1323       |\n",
      "|    total_timesteps    | 416500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 83299      |\n",
      "|    policy_loss        | -0.48      |\n",
      "|    reward             | 0.12518713 |\n",
      "|    std                | 4.11e+05   |\n",
      "|    value_loss         | 0.0168     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 314           |\n",
      "|    iterations         | 83400         |\n",
      "|    time_elapsed       | 1325          |\n",
      "|    total_timesteps    | 417000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.7         |\n",
      "|    explained_variance | -0.0622       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 83399         |\n",
      "|    policy_loss        | -0.233        |\n",
      "|    reward             | -0.0033571655 |\n",
      "|    std                | 4.16e+05      |\n",
      "|    value_loss         | 0.000135      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 83500        |\n",
      "|    time_elapsed       | 1326         |\n",
      "|    total_timesteps    | 417500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 83499        |\n",
      "|    policy_loss        | -0.344       |\n",
      "|    reward             | -0.012860098 |\n",
      "|    std                | 4.25e+05     |\n",
      "|    value_loss         | 0.000268     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 83600        |\n",
      "|    time_elapsed       | 1328         |\n",
      "|    total_timesteps    | 418000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.8        |\n",
      "|    explained_variance | 0.285        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 83599        |\n",
      "|    policy_loss        | 0.254        |\n",
      "|    reward             | -0.077776045 |\n",
      "|    std                | 4.35e+05     |\n",
      "|    value_loss         | 0.00135      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 83700       |\n",
      "|    time_elapsed       | 1329        |\n",
      "|    total_timesteps    | 418500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.9       |\n",
      "|    explained_variance | 0.581       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83699       |\n",
      "|    policy_loss        | 0.0115      |\n",
      "|    reward             | 0.004963935 |\n",
      "|    std                | 4.48e+05    |\n",
      "|    value_loss         | 0.000223    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 83800        |\n",
      "|    time_elapsed       | 1331         |\n",
      "|    total_timesteps    | 419000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.9        |\n",
      "|    explained_variance | 0.347        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 83799        |\n",
      "|    policy_loss        | -0.552       |\n",
      "|    reward             | -0.027773947 |\n",
      "|    std                | 4.56e+05     |\n",
      "|    value_loss         | 0.00302      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 83900        |\n",
      "|    time_elapsed       | 1332         |\n",
      "|    total_timesteps    | 419500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.9        |\n",
      "|    explained_variance | 0.329        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 83899        |\n",
      "|    policy_loss        | -0.54        |\n",
      "|    reward             | 0.0055001187 |\n",
      "|    std                | 4.62e+05     |\n",
      "|    value_loss         | 0.000675     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 84000        |\n",
      "|    time_elapsed       | 1334         |\n",
      "|    total_timesteps    | 420000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 83999        |\n",
      "|    policy_loss        | -1.02        |\n",
      "|    reward             | -0.016403006 |\n",
      "|    std                | 4.67e+05     |\n",
      "|    value_loss         | 0.0014       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 84100       |\n",
      "|    time_elapsed       | 1336        |\n",
      "|    total_timesteps    | 420500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29         |\n",
      "|    explained_variance | 0.146       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 84099       |\n",
      "|    policy_loss        | -0.571      |\n",
      "|    reward             | 0.037627313 |\n",
      "|    std                | 4.77e+05    |\n",
      "|    value_loss         | 0.000536    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 314        |\n",
      "|    iterations         | 84200      |\n",
      "|    time_elapsed       | 1337       |\n",
      "|    total_timesteps    | 421000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29        |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 84199      |\n",
      "|    policy_loss        | -2.21      |\n",
      "|    reward             | 0.12951085 |\n",
      "|    std                | 4.79e+05   |\n",
      "|    value_loss         | 0.0131     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 84300        |\n",
      "|    time_elapsed       | 1339         |\n",
      "|    total_timesteps    | 421500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29          |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84299        |\n",
      "|    policy_loss        | -0.645       |\n",
      "|    reward             | -0.021876644 |\n",
      "|    std                | 4.82e+05     |\n",
      "|    value_loss         | 0.00965      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 314       |\n",
      "|    iterations         | 84400     |\n",
      "|    time_elapsed       | 1340      |\n",
      "|    total_timesteps    | 422000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -29       |\n",
      "|    explained_variance | 0.0844    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 84399     |\n",
      "|    policy_loss        | 12.9      |\n",
      "|    reward             | 0.1634145 |\n",
      "|    std                | 4.8e+05   |\n",
      "|    value_loss         | 0.32      |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 84500        |\n",
      "|    time_elapsed       | 1342         |\n",
      "|    total_timesteps    | 422500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29          |\n",
      "|    explained_variance | 0.273        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84499        |\n",
      "|    policy_loss        | -0.138       |\n",
      "|    reward             | -0.012264059 |\n",
      "|    std                | 4.79e+05     |\n",
      "|    value_loss         | 0.000212     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 314           |\n",
      "|    iterations         | 84600         |\n",
      "|    time_elapsed       | 1344          |\n",
      "|    total_timesteps    | 423000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29           |\n",
      "|    explained_variance | -1.09         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 84599         |\n",
      "|    policy_loss        | -0.2          |\n",
      "|    reward             | -0.0024777593 |\n",
      "|    std                | 4.82e+05      |\n",
      "|    value_loss         | 0.000294      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 314        |\n",
      "|    iterations         | 84700      |\n",
      "|    time_elapsed       | 1345       |\n",
      "|    total_timesteps    | 423500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 84699      |\n",
      "|    policy_loss        | 0.244      |\n",
      "|    reward             | 0.26706582 |\n",
      "|    std                | 4.9e+05    |\n",
      "|    value_loss         | 0.000225   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 84800       |\n",
      "|    time_elapsed       | 1346        |\n",
      "|    total_timesteps    | 424000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 84799       |\n",
      "|    policy_loss        | -0.094      |\n",
      "|    reward             | 0.038723152 |\n",
      "|    std                | 4.95e+05    |\n",
      "|    value_loss         | 0.000239    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 84900       |\n",
      "|    time_elapsed       | 1348        |\n",
      "|    total_timesteps    | 424500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 84899       |\n",
      "|    policy_loss        | 1.03        |\n",
      "|    reward             | 0.007725092 |\n",
      "|    std                | 4.97e+05    |\n",
      "|    value_loss         | 0.00414     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 85000        |\n",
      "|    time_elapsed       | 1349         |\n",
      "|    total_timesteps    | 425000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.1        |\n",
      "|    explained_variance | 0.218        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84999        |\n",
      "|    policy_loss        | 2.15         |\n",
      "|    reward             | -0.087728165 |\n",
      "|    std                | 5.05e+05     |\n",
      "|    value_loss         | 0.0404       |\n",
      "----------------------------------------\n",
      "day: 2833, episode: 150\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 91441.95\n",
      "total_reward: 81441.95\n",
      "total_cost: 11.58\n",
      "total_trades: 5665\n",
      "Sharpe: 0.736\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 85100        |\n",
      "|    time_elapsed       | 1351         |\n",
      "|    total_timesteps    | 425500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.1        |\n",
      "|    explained_variance | -1.76        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 85099        |\n",
      "|    policy_loss        | 0.602        |\n",
      "|    reward             | -0.014432804 |\n",
      "|    std                | 5.08e+05     |\n",
      "|    value_loss         | 0.000502     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 85200        |\n",
      "|    time_elapsed       | 1352         |\n",
      "|    total_timesteps    | 426000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 85199        |\n",
      "|    policy_loss        | 0.482        |\n",
      "|    reward             | -0.002611737 |\n",
      "|    std                | 5.17e+05     |\n",
      "|    value_loss         | 0.000328     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 85300       |\n",
      "|    time_elapsed       | 1353        |\n",
      "|    total_timesteps    | 426500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.2       |\n",
      "|    explained_variance | 0.212       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85299       |\n",
      "|    policy_loss        | 0.836       |\n",
      "|    reward             | 0.042811938 |\n",
      "|    std                | 5.31e+05    |\n",
      "|    value_loss         | 0.000952    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 85400        |\n",
      "|    time_elapsed       | 1355         |\n",
      "|    total_timesteps    | 427000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.2        |\n",
      "|    explained_variance | 0.589        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 85399        |\n",
      "|    policy_loss        | 0.402        |\n",
      "|    reward             | -0.040831324 |\n",
      "|    std                | 5.38e+05     |\n",
      "|    value_loss         | 0.000433     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 85500        |\n",
      "|    time_elapsed       | 1356         |\n",
      "|    total_timesteps    | 427500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.2        |\n",
      "|    explained_variance | 0.311        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 85499        |\n",
      "|    policy_loss        | -0.297       |\n",
      "|    reward             | 0.0064633484 |\n",
      "|    std                | 5.47e+05     |\n",
      "|    value_loss         | 0.00121      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 85600       |\n",
      "|    time_elapsed       | 1358        |\n",
      "|    total_timesteps    | 428000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.3       |\n",
      "|    explained_variance | 0.848       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85599       |\n",
      "|    policy_loss        | 0.26        |\n",
      "|    reward             | 0.007870988 |\n",
      "|    std                | 5.59e+05    |\n",
      "|    value_loss         | 0.000107    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 85700        |\n",
      "|    time_elapsed       | 1359         |\n",
      "|    total_timesteps    | 428500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.3        |\n",
      "|    explained_variance | 0.00326      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 85699        |\n",
      "|    policy_loss        | -0.199       |\n",
      "|    reward             | -0.006037325 |\n",
      "|    std                | 5.67e+05     |\n",
      "|    value_loss         | 8.96e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 85800         |\n",
      "|    time_elapsed       | 1361          |\n",
      "|    total_timesteps    | 429000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 85799         |\n",
      "|    policy_loss        | -0.0991       |\n",
      "|    reward             | -0.0025522152 |\n",
      "|    std                | 5.81e+05      |\n",
      "|    value_loss         | 1.7e-05       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 85900         |\n",
      "|    time_elapsed       | 1362          |\n",
      "|    total_timesteps    | 429500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.4         |\n",
      "|    explained_variance | 0.252         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 85899         |\n",
      "|    policy_loss        | -0.613        |\n",
      "|    reward             | -0.0021178287 |\n",
      "|    std                | 6e+05         |\n",
      "|    value_loss         | 0.000515      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 86000       |\n",
      "|    time_elapsed       | 1364        |\n",
      "|    total_timesteps    | 430000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.5       |\n",
      "|    explained_variance | 0.000274    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85999       |\n",
      "|    policy_loss        | 0.778       |\n",
      "|    reward             | 0.001794672 |\n",
      "|    std                | 6.24e+05    |\n",
      "|    value_loss         | 0.00112     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 86100       |\n",
      "|    time_elapsed       | 1365        |\n",
      "|    total_timesteps    | 430500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.6       |\n",
      "|    explained_variance | 0.109       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 86099       |\n",
      "|    policy_loss        | 1.35        |\n",
      "|    reward             | -0.10663365 |\n",
      "|    std                | 6.48e+05    |\n",
      "|    value_loss         | 0.00309     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 86200       |\n",
      "|    time_elapsed       | 1367        |\n",
      "|    total_timesteps    | 431000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.6       |\n",
      "|    explained_variance | 0.112       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 86199       |\n",
      "|    policy_loss        | -0.472      |\n",
      "|    reward             | 0.020745466 |\n",
      "|    std                | 6.66e+05    |\n",
      "|    value_loss         | 0.000967    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 86300        |\n",
      "|    time_elapsed       | 1368         |\n",
      "|    total_timesteps    | 431500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.7        |\n",
      "|    explained_variance | 0.31         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 86299        |\n",
      "|    policy_loss        | -0.431       |\n",
      "|    reward             | 0.0017345045 |\n",
      "|    std                | 6.9e+05      |\n",
      "|    value_loss         | 0.00036      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 86400       |\n",
      "|    time_elapsed       | 1370        |\n",
      "|    total_timesteps    | 432000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.8       |\n",
      "|    explained_variance | 0.287       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 86399       |\n",
      "|    policy_loss        | 1.16        |\n",
      "|    reward             | 0.008668656 |\n",
      "|    std                | 7.11e+05    |\n",
      "|    value_loss         | 0.00205     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 86500        |\n",
      "|    time_elapsed       | 1372         |\n",
      "|    total_timesteps    | 432500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.8        |\n",
      "|    explained_variance | 0.338        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 86499        |\n",
      "|    policy_loss        | -0.212       |\n",
      "|    reward             | 0.0072325193 |\n",
      "|    std                | 7.32e+05     |\n",
      "|    value_loss         | 0.000117     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 86600       |\n",
      "|    time_elapsed       | 1373        |\n",
      "|    total_timesteps    | 433000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.8       |\n",
      "|    explained_variance | 2.5e-06     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 86599       |\n",
      "|    policy_loss        | 1.65        |\n",
      "|    reward             | 0.022755574 |\n",
      "|    std                | 7.37e+05    |\n",
      "|    value_loss         | 0.00333     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 86700      |\n",
      "|    time_elapsed       | 1375       |\n",
      "|    total_timesteps    | 433500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29.9      |\n",
      "|    explained_variance | 0.275      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 86699      |\n",
      "|    policy_loss        | 1.63       |\n",
      "|    reward             | 0.07778934 |\n",
      "|    std                | 7.51e+05   |\n",
      "|    value_loss         | 0.0179     |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 315            |\n",
      "|    iterations         | 86800          |\n",
      "|    time_elapsed       | 1377           |\n",
      "|    total_timesteps    | 434000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -29.9          |\n",
      "|    explained_variance | 0.38           |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 86799          |\n",
      "|    policy_loss        | -0.179         |\n",
      "|    reward             | -0.00015268802 |\n",
      "|    std                | 7.6e+05        |\n",
      "|    value_loss         | 0.0001         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 86900        |\n",
      "|    time_elapsed       | 1378         |\n",
      "|    total_timesteps    | 434500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 86899        |\n",
      "|    policy_loss        | 0.451        |\n",
      "|    reward             | 0.0015868606 |\n",
      "|    std                | 7.77e+05     |\n",
      "|    value_loss         | 0.000261     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 87000       |\n",
      "|    time_elapsed       | 1380        |\n",
      "|    total_timesteps    | 435000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30         |\n",
      "|    explained_variance | 0.0435      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 86999       |\n",
      "|    policy_loss        | -1.95       |\n",
      "|    reward             | 0.015196389 |\n",
      "|    std                | 7.98e+05    |\n",
      "|    value_loss         | 0.00449     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 87100        |\n",
      "|    time_elapsed       | 1381         |\n",
      "|    total_timesteps    | 435500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30          |\n",
      "|    explained_variance | -1.25        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 87099        |\n",
      "|    policy_loss        | -0.562       |\n",
      "|    reward             | -0.013147827 |\n",
      "|    std                | 8.14e+05     |\n",
      "|    value_loss         | 0.00159      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 87200       |\n",
      "|    time_elapsed       | 1383        |\n",
      "|    total_timesteps    | 436000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.1       |\n",
      "|    explained_variance | 0.191       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87199       |\n",
      "|    policy_loss        | -0.0738     |\n",
      "|    reward             | 0.023740036 |\n",
      "|    std                | 8.21e+05    |\n",
      "|    value_loss         | 0.00187     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 87300        |\n",
      "|    time_elapsed       | 1384         |\n",
      "|    total_timesteps    | 436500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 87299        |\n",
      "|    policy_loss        | -1.06        |\n",
      "|    reward             | -0.004570654 |\n",
      "|    std                | 8.31e+05     |\n",
      "|    value_loss         | 0.00219      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 87400       |\n",
      "|    time_elapsed       | 1386        |\n",
      "|    total_timesteps    | 437000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87399       |\n",
      "|    policy_loss        | 1.16        |\n",
      "|    reward             | 0.009327576 |\n",
      "|    std                | 8.38e+05    |\n",
      "|    value_loss         | 0.00174     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 87500        |\n",
      "|    time_elapsed       | 1387         |\n",
      "|    total_timesteps    | 437500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 87499        |\n",
      "|    policy_loss        | -0.205       |\n",
      "|    reward             | -0.020635497 |\n",
      "|    std                | 8.53e+05     |\n",
      "|    value_loss         | 0.000405     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 87600        |\n",
      "|    time_elapsed       | 1389         |\n",
      "|    total_timesteps    | 438000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.2        |\n",
      "|    explained_variance | -0.159       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 87599        |\n",
      "|    policy_loss        | -2.61        |\n",
      "|    reward             | -0.061615575 |\n",
      "|    std                | 8.64e+05     |\n",
      "|    value_loss         | 0.00792      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 87700      |\n",
      "|    time_elapsed       | 1390       |\n",
      "|    total_timesteps    | 438500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30.2      |\n",
      "|    explained_variance | 0.00189    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 87699      |\n",
      "|    policy_loss        | 7.33       |\n",
      "|    reward             | 0.05091014 |\n",
      "|    std                | 8.74e+05   |\n",
      "|    value_loss         | 0.0703     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 87800       |\n",
      "|    time_elapsed       | 1392        |\n",
      "|    total_timesteps    | 439000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87799       |\n",
      "|    policy_loss        | 10          |\n",
      "|    reward             | -0.07122723 |\n",
      "|    std                | 8.86e+05    |\n",
      "|    value_loss         | 0.126       |\n",
      "---------------------------------------\n",
      "day: 2833, episode: 155\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 166841.80\n",
      "total_reward: 156841.80\n",
      "total_cost: 15.89\n",
      "total_trades: 5663\n",
      "Sharpe: 0.971\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 87900        |\n",
      "|    time_elapsed       | 1393         |\n",
      "|    total_timesteps    | 439500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.2        |\n",
      "|    explained_variance | -2.4         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 87899        |\n",
      "|    policy_loss        | -1.41        |\n",
      "|    reward             | -0.031735223 |\n",
      "|    std                | 9.02e+05     |\n",
      "|    value_loss         | 0.00276      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 88000         |\n",
      "|    time_elapsed       | 1395          |\n",
      "|    total_timesteps    | 440000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.3         |\n",
      "|    explained_variance | -0.933        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 87999         |\n",
      "|    policy_loss        | -0.742        |\n",
      "|    reward             | -0.0026818104 |\n",
      "|    std                | 9.14e+05      |\n",
      "|    value_loss         | 0.000967      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 88100      |\n",
      "|    time_elapsed       | 1396       |\n",
      "|    total_timesteps    | 440500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30.3      |\n",
      "|    explained_variance | 0.35       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 88099      |\n",
      "|    policy_loss        | 0.914      |\n",
      "|    reward             | 0.02360768 |\n",
      "|    std                | 9.35e+05   |\n",
      "|    value_loss         | 0.00107    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 88200        |\n",
      "|    time_elapsed       | 1398         |\n",
      "|    total_timesteps    | 441000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88199        |\n",
      "|    policy_loss        | 0.589        |\n",
      "|    reward             | -0.013600983 |\n",
      "|    std                | 9.59e+05     |\n",
      "|    value_loss         | 0.000782     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 88300      |\n",
      "|    time_elapsed       | 1400       |\n",
      "|    total_timesteps    | 441500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 88299      |\n",
      "|    policy_loss        | 1.54       |\n",
      "|    reward             | 0.01964413 |\n",
      "|    std                | 9.68e+05   |\n",
      "|    value_loss         | 0.00343    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 88400      |\n",
      "|    time_elapsed       | 1401       |\n",
      "|    total_timesteps    | 442000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30.4      |\n",
      "|    explained_variance | 0.177      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 88399      |\n",
      "|    policy_loss        | -5.32      |\n",
      "|    reward             | 0.08785533 |\n",
      "|    std                | 9.81e+05   |\n",
      "|    value_loss         | 0.0489     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 88500        |\n",
      "|    time_elapsed       | 1403         |\n",
      "|    total_timesteps    | 442500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.4        |\n",
      "|    explained_variance | 0.241        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88499        |\n",
      "|    policy_loss        | 0.0193       |\n",
      "|    reward             | -0.026797628 |\n",
      "|    std                | 9.97e+05     |\n",
      "|    value_loss         | 4.43e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 88600        |\n",
      "|    time_elapsed       | 1405         |\n",
      "|    total_timesteps    | 443000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.5        |\n",
      "|    explained_variance | 0.00695      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88599        |\n",
      "|    policy_loss        | 0.0574       |\n",
      "|    reward             | -0.013313245 |\n",
      "|    std                | 1.02e+06     |\n",
      "|    value_loss         | 0.000136     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 88700        |\n",
      "|    time_elapsed       | 1406         |\n",
      "|    total_timesteps    | 443500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.5        |\n",
      "|    explained_variance | 0.326        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88699        |\n",
      "|    policy_loss        | -0.299       |\n",
      "|    reward             | -0.003755058 |\n",
      "|    std                | 1.04e+06     |\n",
      "|    value_loss         | 0.00035      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 88800       |\n",
      "|    time_elapsed       | 1408        |\n",
      "|    total_timesteps    | 444000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.6       |\n",
      "|    explained_variance | -4.14       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88799       |\n",
      "|    policy_loss        | 0.327       |\n",
      "|    reward             | 0.041328065 |\n",
      "|    std                | 1.07e+06    |\n",
      "|    value_loss         | 0.000348    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 88900       |\n",
      "|    time_elapsed       | 1409        |\n",
      "|    total_timesteps    | 444500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.6       |\n",
      "|    explained_variance | 0.123       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88899       |\n",
      "|    policy_loss        | -1.85       |\n",
      "|    reward             | -0.10466457 |\n",
      "|    std                | 1.06e+06    |\n",
      "|    value_loss         | 0.00451     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 89000        |\n",
      "|    time_elapsed       | 1411         |\n",
      "|    total_timesteps    | 445000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.6        |\n",
      "|    explained_variance | -9.62e-05    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88999        |\n",
      "|    policy_loss        | -0.908       |\n",
      "|    reward             | -0.006140939 |\n",
      "|    std                | 1.06e+06     |\n",
      "|    value_loss         | 0.00105      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 89100        |\n",
      "|    time_elapsed       | 1412         |\n",
      "|    total_timesteps    | 445500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.6        |\n",
      "|    explained_variance | -0.000196    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 89099        |\n",
      "|    policy_loss        | 0.477        |\n",
      "|    reward             | 0.0024664307 |\n",
      "|    std                | 1.08e+06     |\n",
      "|    value_loss         | 0.000265     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 89200       |\n",
      "|    time_elapsed       | 1414        |\n",
      "|    total_timesteps    | 446000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.6       |\n",
      "|    explained_variance | 3.64e-06    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 89199       |\n",
      "|    policy_loss        | -0.419      |\n",
      "|    reward             | 0.008211771 |\n",
      "|    std                | 1.1e+06     |\n",
      "|    value_loss         | 0.00021     |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 315            |\n",
      "|    iterations         | 89300          |\n",
      "|    time_elapsed       | 1415           |\n",
      "|    total_timesteps    | 446500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -30.7          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 89299          |\n",
      "|    policy_loss        | 1.09           |\n",
      "|    reward             | -0.00058948324 |\n",
      "|    std                | 1.13e+06       |\n",
      "|    value_loss         | 0.00296        |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 89400       |\n",
      "|    time_elapsed       | 1417        |\n",
      "|    total_timesteps    | 447000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.7       |\n",
      "|    explained_variance | 0.334       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 89399       |\n",
      "|    policy_loss        | 2.28        |\n",
      "|    reward             | 0.038040433 |\n",
      "|    std                | 1.16e+06    |\n",
      "|    value_loss         | 0.00589     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 89500      |\n",
      "|    time_elapsed       | 1418       |\n",
      "|    total_timesteps    | 447500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30.8      |\n",
      "|    explained_variance | 0.0899     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 89499      |\n",
      "|    policy_loss        | 4.87       |\n",
      "|    reward             | 0.09153028 |\n",
      "|    std                | 1.17e+06   |\n",
      "|    value_loss         | 0.0297     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 89600       |\n",
      "|    time_elapsed       | 1420        |\n",
      "|    total_timesteps    | 448000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.8       |\n",
      "|    explained_variance | -3.46e-05   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 89599       |\n",
      "|    policy_loss        | -0.153      |\n",
      "|    reward             | 0.009050092 |\n",
      "|    std                | 1.19e+06    |\n",
      "|    value_loss         | 5.98e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 89700        |\n",
      "|    time_elapsed       | 1421         |\n",
      "|    total_timesteps    | 448500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.8        |\n",
      "|    explained_variance | 0.0145       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 89699        |\n",
      "|    policy_loss        | -0.0327      |\n",
      "|    reward             | 0.0034108162 |\n",
      "|    std                | 1.21e+06     |\n",
      "|    value_loss         | 5e-06        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 89800        |\n",
      "|    time_elapsed       | 1423         |\n",
      "|    total_timesteps    | 449000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.9        |\n",
      "|    explained_variance | 0.35         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 89799        |\n",
      "|    policy_loss        | 0.426        |\n",
      "|    reward             | 0.0031729646 |\n",
      "|    std                | 1.23e+06     |\n",
      "|    value_loss         | 0.000258     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 89900         |\n",
      "|    time_elapsed       | 1425          |\n",
      "|    total_timesteps    | 449500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.9         |\n",
      "|    explained_variance | 0.291         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 89899         |\n",
      "|    policy_loss        | 0.445         |\n",
      "|    reward             | 0.00018532715 |\n",
      "|    std                | 1.26e+06      |\n",
      "|    value_loss         | 0.000344      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 90000        |\n",
      "|    time_elapsed       | 1426         |\n",
      "|    total_timesteps    | 450000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31          |\n",
      "|    explained_variance | 0.00112      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 89999        |\n",
      "|    policy_loss        | 0.553        |\n",
      "|    reward             | -0.055198222 |\n",
      "|    std                | 1.29e+06     |\n",
      "|    value_loss         | 0.000774     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 90100      |\n",
      "|    time_elapsed       | 1428       |\n",
      "|    total_timesteps    | 450500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31        |\n",
      "|    explained_variance | 0.574      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 90099      |\n",
      "|    policy_loss        | -1.2       |\n",
      "|    reward             | 0.09306138 |\n",
      "|    std                | 1.3e+06    |\n",
      "|    value_loss         | 0.00165    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 90200      |\n",
      "|    time_elapsed       | 1429       |\n",
      "|    total_timesteps    | 451000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31        |\n",
      "|    explained_variance | 0.33       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 90199      |\n",
      "|    policy_loss        | 0.853      |\n",
      "|    reward             | 0.03368757 |\n",
      "|    std                | 1.32e+06   |\n",
      "|    value_loss         | 0.00116    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 90300       |\n",
      "|    time_elapsed       | 1431        |\n",
      "|    total_timesteps    | 451500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31         |\n",
      "|    explained_variance | 0.104       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90299       |\n",
      "|    policy_loss        | 0.472       |\n",
      "|    reward             | 0.017307231 |\n",
      "|    std                | 1.35e+06    |\n",
      "|    value_loss         | 0.000665    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 90400       |\n",
      "|    time_elapsed       | 1432        |\n",
      "|    total_timesteps    | 452000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.1       |\n",
      "|    explained_variance | 0.385       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90399       |\n",
      "|    policy_loss        | -0.293      |\n",
      "|    reward             | 0.021757767 |\n",
      "|    std                | 1.39e+06    |\n",
      "|    value_loss         | 0.000484    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 90500       |\n",
      "|    time_elapsed       | 1434        |\n",
      "|    total_timesteps    | 452500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.1       |\n",
      "|    explained_variance | 0.827       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90499       |\n",
      "|    policy_loss        | -0.00635    |\n",
      "|    reward             | 0.013836385 |\n",
      "|    std                | 1.4e+06     |\n",
      "|    value_loss         | 7.41e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 90600      |\n",
      "|    time_elapsed       | 1435       |\n",
      "|    total_timesteps    | 453000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.1      |\n",
      "|    explained_variance | 0.0651     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 90599      |\n",
      "|    policy_loss        | -3.61      |\n",
      "|    reward             | 0.14810194 |\n",
      "|    std                | 1.42e+06   |\n",
      "|    value_loss         | 0.02       |\n",
      "--------------------------------------\n",
      "day: 2833, episode: 160\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 108528.45\n",
      "total_reward: 98528.45\n",
      "total_cost: 34.03\n",
      "total_trades: 5656\n",
      "Sharpe: 0.892\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 90700        |\n",
      "|    time_elapsed       | 1437         |\n",
      "|    total_timesteps    | 453500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.2        |\n",
      "|    explained_variance | -0.000542    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 90699        |\n",
      "|    policy_loss        | -0.924       |\n",
      "|    reward             | 0.0039249463 |\n",
      "|    std                | 1.42e+06     |\n",
      "|    value_loss         | 0.000978     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 90800        |\n",
      "|    time_elapsed       | 1439         |\n",
      "|    total_timesteps    | 454000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.2        |\n",
      "|    explained_variance | -0.465       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 90799        |\n",
      "|    policy_loss        | -0.0299      |\n",
      "|    reward             | 0.0066551324 |\n",
      "|    std                | 1.44e+06     |\n",
      "|    value_loss         | 5.83e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 315           |\n",
      "|    iterations         | 90900         |\n",
      "|    time_elapsed       | 1440          |\n",
      "|    total_timesteps    | 454500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.2         |\n",
      "|    explained_variance | -2.38e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 90899         |\n",
      "|    policy_loss        | -0.192        |\n",
      "|    reward             | -0.0022599236 |\n",
      "|    std                | 1.48e+06      |\n",
      "|    value_loss         | 4.58e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 91000        |\n",
      "|    time_elapsed       | 1442         |\n",
      "|    total_timesteps    | 455000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.3        |\n",
      "|    explained_variance | 0.256        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 90999        |\n",
      "|    policy_loss        | 3.14         |\n",
      "|    reward             | -0.017693203 |\n",
      "|    std                | 1.5e+06      |\n",
      "|    value_loss         | 0.0129       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 91100       |\n",
      "|    time_elapsed       | 1444        |\n",
      "|    total_timesteps    | 455500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.3       |\n",
      "|    explained_variance | 0.654       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 91099       |\n",
      "|    policy_loss        | 0.244       |\n",
      "|    reward             | 0.021655547 |\n",
      "|    std                | 1.54e+06    |\n",
      "|    value_loss         | 0.00125     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 91200      |\n",
      "|    time_elapsed       | 1446       |\n",
      "|    total_timesteps    | 456000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.3      |\n",
      "|    explained_variance | 0.0463     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 91199      |\n",
      "|    policy_loss        | 6.45       |\n",
      "|    reward             | 0.23149997 |\n",
      "|    std                | 1.55e+06   |\n",
      "|    value_loss         | 0.0465     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 91300       |\n",
      "|    time_elapsed       | 1447        |\n",
      "|    total_timesteps    | 456500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.4       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 91299       |\n",
      "|    policy_loss        | -1.2        |\n",
      "|    reward             | -0.03505306 |\n",
      "|    std                | 1.56e+06    |\n",
      "|    value_loss         | 0.00145     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 91400        |\n",
      "|    time_elapsed       | 1449         |\n",
      "|    total_timesteps    | 457000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91399        |\n",
      "|    policy_loss        | -0.238       |\n",
      "|    reward             | -0.014961173 |\n",
      "|    std                | 1.59e+06     |\n",
      "|    value_loss         | 6.45e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 91500        |\n",
      "|    time_elapsed       | 1450         |\n",
      "|    total_timesteps    | 457500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.4        |\n",
      "|    explained_variance | 0.406        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91499        |\n",
      "|    policy_loss        | 0.241        |\n",
      "|    reward             | 0.0046214815 |\n",
      "|    std                | 1.62e+06     |\n",
      "|    value_loss         | 0.000248     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 91600       |\n",
      "|    time_elapsed       | 1452        |\n",
      "|    total_timesteps    | 458000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.5       |\n",
      "|    explained_variance | 0.211       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 91599       |\n",
      "|    policy_loss        | 0.411       |\n",
      "|    reward             | 0.010456379 |\n",
      "|    std                | 1.67e+06    |\n",
      "|    value_loss         | 0.000302    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 91700        |\n",
      "|    time_elapsed       | 1454         |\n",
      "|    total_timesteps    | 458500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.5        |\n",
      "|    explained_variance | 2.92e-06     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91699        |\n",
      "|    policy_loss        | 0.963        |\n",
      "|    reward             | -0.003338913 |\n",
      "|    std                | 1.72e+06     |\n",
      "|    value_loss         | 0.00208      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 91800       |\n",
      "|    time_elapsed       | 1455        |\n",
      "|    total_timesteps    | 459000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 91799       |\n",
      "|    policy_loss        | -0.133      |\n",
      "|    reward             | -0.03742909 |\n",
      "|    std                | 1.74e+06    |\n",
      "|    value_loss         | 0.00152     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 91900        |\n",
      "|    time_elapsed       | 1457         |\n",
      "|    total_timesteps    | 459500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.6        |\n",
      "|    explained_variance | 0.153        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91899        |\n",
      "|    policy_loss        | 0.674        |\n",
      "|    reward             | -0.043814328 |\n",
      "|    std                | 1.78e+06     |\n",
      "|    value_loss         | 0.000739     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 92000       |\n",
      "|    time_elapsed       | 1458        |\n",
      "|    total_timesteps    | 460000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.6       |\n",
      "|    explained_variance | 0.342       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 91999       |\n",
      "|    policy_loss        | -1.53       |\n",
      "|    reward             | 0.032449286 |\n",
      "|    std                | 1.81e+06    |\n",
      "|    value_loss         | 0.00253     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 92100       |\n",
      "|    time_elapsed       | 1460        |\n",
      "|    total_timesteps    | 460500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.7       |\n",
      "|    explained_variance | -0.0014     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 92099       |\n",
      "|    policy_loss        | -1.49       |\n",
      "|    reward             | 0.022793699 |\n",
      "|    std                | 1.86e+06    |\n",
      "|    value_loss         | 0.00701     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 92200      |\n",
      "|    time_elapsed       | 1462       |\n",
      "|    total_timesteps    | 461000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.7      |\n",
      "|    explained_variance | 0.268      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 92199      |\n",
      "|    policy_loss        | 3.74       |\n",
      "|    reward             | 0.05705539 |\n",
      "|    std                | 1.87e+06   |\n",
      "|    value_loss         | 0.0191     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 92300       |\n",
      "|    time_elapsed       | 1463        |\n",
      "|    total_timesteps    | 461500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.7       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 92299       |\n",
      "|    policy_loss        | -12.8       |\n",
      "|    reward             | -0.20629789 |\n",
      "|    std                | 1.87e+06    |\n",
      "|    value_loss         | 0.166       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 92400       |\n",
      "|    time_elapsed       | 1465        |\n",
      "|    total_timesteps    | 462000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.7       |\n",
      "|    explained_variance | -0.46       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 92399       |\n",
      "|    policy_loss        | -0.0264     |\n",
      "|    reward             | -0.04225438 |\n",
      "|    std                | 1.86e+06    |\n",
      "|    value_loss         | 0.000102    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 92500       |\n",
      "|    time_elapsed       | 1466        |\n",
      "|    total_timesteps    | 462500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.7       |\n",
      "|    explained_variance | 0.352       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 92499       |\n",
      "|    policy_loss        | 0.142       |\n",
      "|    reward             | 0.011936734 |\n",
      "|    std                | 1.88e+06    |\n",
      "|    value_loss         | 0.000718    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 92600        |\n",
      "|    time_elapsed       | 1468         |\n",
      "|    total_timesteps    | 463000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92599        |\n",
      "|    policy_loss        | 0.732        |\n",
      "|    reward             | -0.011177259 |\n",
      "|    std                | 1.9e+06      |\n",
      "|    value_loss         | 0.000736     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 92700        |\n",
      "|    time_elapsed       | 1469         |\n",
      "|    total_timesteps    | 463500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92699        |\n",
      "|    policy_loss        | 0.102        |\n",
      "|    reward             | 0.0042054625 |\n",
      "|    std                | 1.93e+06     |\n",
      "|    value_loss         | 6.26e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 92800       |\n",
      "|    time_elapsed       | 1471        |\n",
      "|    total_timesteps    | 464000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.8       |\n",
      "|    explained_variance | 0.331       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 92799       |\n",
      "|    policy_loss        | -0.316      |\n",
      "|    reward             | 0.017294776 |\n",
      "|    std                | 1.97e+06    |\n",
      "|    value_loss         | 0.000768    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 92900       |\n",
      "|    time_elapsed       | 1472        |\n",
      "|    total_timesteps    | 464500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.8       |\n",
      "|    explained_variance | 0.197       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 92899       |\n",
      "|    policy_loss        | 4.6         |\n",
      "|    reward             | 0.036987666 |\n",
      "|    std                | 1.95e+06    |\n",
      "|    value_loss         | 0.0293      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 93000        |\n",
      "|    time_elapsed       | 1475         |\n",
      "|    total_timesteps    | 465000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.8        |\n",
      "|    explained_variance | 0.0724       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92999        |\n",
      "|    policy_loss        | 0.381        |\n",
      "|    reward             | 0.0021452568 |\n",
      "|    std                | 1.95e+06     |\n",
      "|    value_loss         | 0.000157     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 93100        |\n",
      "|    time_elapsed       | 1477         |\n",
      "|    total_timesteps    | 465500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.8        |\n",
      "|    explained_variance | 0.332        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 93099        |\n",
      "|    policy_loss        | 0.0698       |\n",
      "|    reward             | -0.012513589 |\n",
      "|    std                | 1.98e+06     |\n",
      "|    value_loss         | 3.04e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 93200       |\n",
      "|    time_elapsed       | 1479        |\n",
      "|    total_timesteps    | 466000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.9       |\n",
      "|    explained_variance | 0.664       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93199       |\n",
      "|    policy_loss        | 0.339       |\n",
      "|    reward             | 0.007827099 |\n",
      "|    std                | 2.03e+06    |\n",
      "|    value_loss         | 0.000212    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 93300       |\n",
      "|    time_elapsed       | 1481        |\n",
      "|    total_timesteps    | 466500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.9       |\n",
      "|    explained_variance | -0.0197     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93299       |\n",
      "|    policy_loss        | 0.803       |\n",
      "|    reward             | 0.003770742 |\n",
      "|    std                | 2.07e+06    |\n",
      "|    value_loss         | 0.00379     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 93400       |\n",
      "|    time_elapsed       | 1484        |\n",
      "|    total_timesteps    | 467000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32         |\n",
      "|    explained_variance | 0.00587     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93399       |\n",
      "|    policy_loss        | 3.01        |\n",
      "|    reward             | -0.01651793 |\n",
      "|    std                | 2.13e+06    |\n",
      "|    value_loss         | 0.00979     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 314        |\n",
      "|    iterations         | 93500      |\n",
      "|    time_elapsed       | 1486       |\n",
      "|    total_timesteps    | 467500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32        |\n",
      "|    explained_variance | 0.0326     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 93499      |\n",
      "|    policy_loss        | 3.21       |\n",
      "|    reward             | -0.2629159 |\n",
      "|    std                | 2.13e+06   |\n",
      "|    value_loss         | 0.0125     |\n",
      "--------------------------------------\n",
      "day: 2833, episode: 165\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 66320.08\n",
      "total_reward: 56320.08\n",
      "total_cost: 10.31\n",
      "total_trades: 5666\n",
      "Sharpe: 0.685\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 93600        |\n",
      "|    time_elapsed       | 1488         |\n",
      "|    total_timesteps    | 468000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32          |\n",
      "|    explained_variance | 0.0429       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 93599        |\n",
      "|    policy_loss        | 0.809        |\n",
      "|    reward             | -0.012967028 |\n",
      "|    std                | 2.15e+06     |\n",
      "|    value_loss         | 0.00081      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 314        |\n",
      "|    iterations         | 93700      |\n",
      "|    time_elapsed       | 1489       |\n",
      "|    total_timesteps    | 468500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32        |\n",
      "|    explained_variance | -1.54      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 93699      |\n",
      "|    policy_loss        | -0.309     |\n",
      "|    reward             | 0.01752476 |\n",
      "|    std                | 2.19e+06   |\n",
      "|    value_loss         | 0.000123   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 93800        |\n",
      "|    time_elapsed       | 1491         |\n",
      "|    total_timesteps    | 469000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.1        |\n",
      "|    explained_variance | 0.0977       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 93799        |\n",
      "|    policy_loss        | -0.513       |\n",
      "|    reward             | -0.035378132 |\n",
      "|    std                | 2.22e+06     |\n",
      "|    value_loss         | 0.00297      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 93900        |\n",
      "|    time_elapsed       | 1493         |\n",
      "|    total_timesteps    | 469500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.1        |\n",
      "|    explained_variance | 0.478        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 93899        |\n",
      "|    policy_loss        | -1.9         |\n",
      "|    reward             | -0.017868362 |\n",
      "|    std                | 2.23e+06     |\n",
      "|    value_loss         | 0.00977      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 94000       |\n",
      "|    time_elapsed       | 1495        |\n",
      "|    total_timesteps    | 470000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.1       |\n",
      "|    explained_variance | 0.0341      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93999       |\n",
      "|    policy_loss        | -0.999      |\n",
      "|    reward             | 0.045155063 |\n",
      "|    std                | 2.25e+06    |\n",
      "|    value_loss         | 0.00195     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 94100        |\n",
      "|    time_elapsed       | 1497         |\n",
      "|    total_timesteps    | 470500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.1        |\n",
      "|    explained_variance | -2.1         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 94099        |\n",
      "|    policy_loss        | -0.41        |\n",
      "|    reward             | -0.007476342 |\n",
      "|    std                | 2.29e+06     |\n",
      "|    value_loss         | 0.000345     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 94200        |\n",
      "|    time_elapsed       | 1499         |\n",
      "|    total_timesteps    | 471000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.2        |\n",
      "|    explained_variance | 0.269        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 94199        |\n",
      "|    policy_loss        | 0.29         |\n",
      "|    reward             | 0.0030758989 |\n",
      "|    std                | 2.32e+06     |\n",
      "|    value_loss         | 0.000304     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 94300        |\n",
      "|    time_elapsed       | 1501         |\n",
      "|    total_timesteps    | 471500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.2        |\n",
      "|    explained_variance | -1.34e-05    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 94299        |\n",
      "|    policy_loss        | 0.668        |\n",
      "|    reward             | -0.006951323 |\n",
      "|    std                | 2.37e+06     |\n",
      "|    value_loss         | 0.000446     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 94400        |\n",
      "|    time_elapsed       | 1502         |\n",
      "|    total_timesteps    | 472000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.2        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 94399        |\n",
      "|    policy_loss        | 0.422        |\n",
      "|    reward             | 0.0037872451 |\n",
      "|    std                | 2.43e+06     |\n",
      "|    value_loss         | 0.000307     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 94500       |\n",
      "|    time_elapsed       | 1504        |\n",
      "|    total_timesteps    | 472500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.3       |\n",
      "|    explained_variance | 0.523       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94499       |\n",
      "|    policy_loss        | -0.0591     |\n",
      "|    reward             | 0.030391483 |\n",
      "|    std                | 2.48e+06    |\n",
      "|    value_loss         | 0.000105    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 94600       |\n",
      "|    time_elapsed       | 1506        |\n",
      "|    total_timesteps    | 473000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94599       |\n",
      "|    policy_loss        | 1.09        |\n",
      "|    reward             | -0.00472791 |\n",
      "|    std                | 2.52e+06    |\n",
      "|    value_loss         | 0.00243     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 94700       |\n",
      "|    time_elapsed       | 1507        |\n",
      "|    total_timesteps    | 473500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.3       |\n",
      "|    explained_variance | -0.000196   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94699       |\n",
      "|    policy_loss        | 1.82        |\n",
      "|    reward             | 0.029139051 |\n",
      "|    std                | 2.56e+06    |\n",
      "|    value_loss         | 0.00491     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 94800       |\n",
      "|    time_elapsed       | 1509        |\n",
      "|    total_timesteps    | 474000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.4       |\n",
      "|    explained_variance | 0.00544     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94799       |\n",
      "|    policy_loss        | 0.354       |\n",
      "|    reward             | 0.002533155 |\n",
      "|    std                | 2.61e+06    |\n",
      "|    value_loss         | 0.000362    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 94900       |\n",
      "|    time_elapsed       | 1511        |\n",
      "|    total_timesteps    | 474500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.4       |\n",
      "|    explained_variance | 0.422       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94899       |\n",
      "|    policy_loss        | -1.8        |\n",
      "|    reward             | -0.07293304 |\n",
      "|    std                | 2.66e+06    |\n",
      "|    value_loss         | 0.00457     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 95000        |\n",
      "|    time_elapsed       | 1513         |\n",
      "|    total_timesteps    | 475000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.4        |\n",
      "|    explained_variance | 0.0935       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 94999        |\n",
      "|    policy_loss        | 8.81         |\n",
      "|    reward             | 0.0028473511 |\n",
      "|    std                | 2.68e+06     |\n",
      "|    value_loss         | 0.0949       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 313        |\n",
      "|    iterations         | 95100      |\n",
      "|    time_elapsed       | 1514       |\n",
      "|    total_timesteps    | 475500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.5      |\n",
      "|    explained_variance | 0.314      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 95099      |\n",
      "|    policy_loss        | 1.41       |\n",
      "|    reward             | 0.17027393 |\n",
      "|    std                | 2.74e+06   |\n",
      "|    value_loss         | 0.00812    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 95200        |\n",
      "|    time_elapsed       | 1516         |\n",
      "|    total_timesteps    | 476000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 95199        |\n",
      "|    policy_loss        | -4.87        |\n",
      "|    reward             | -0.024685418 |\n",
      "|    std                | 2.76e+06     |\n",
      "|    value_loss         | 0.0262       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 313           |\n",
      "|    iterations         | 95300         |\n",
      "|    time_elapsed       | 1518          |\n",
      "|    total_timesteps    | 476500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.5         |\n",
      "|    explained_variance | 0.000211      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 95299         |\n",
      "|    policy_loss        | 0.306         |\n",
      "|    reward             | -0.0026115158 |\n",
      "|    std                | 2.81e+06      |\n",
      "|    value_loss         | 0.000323      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 95400       |\n",
      "|    time_elapsed       | 1520        |\n",
      "|    total_timesteps    | 477000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.5       |\n",
      "|    explained_variance | -0.0382     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 95399       |\n",
      "|    policy_loss        | 0.0666      |\n",
      "|    reward             | 0.029978124 |\n",
      "|    std                | 2.83e+06    |\n",
      "|    value_loss         | 2.79e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 95500       |\n",
      "|    time_elapsed       | 1521        |\n",
      "|    total_timesteps    | 477500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 95499       |\n",
      "|    policy_loss        | -3.31       |\n",
      "|    reward             | -0.07696337 |\n",
      "|    std                | 2.87e+06    |\n",
      "|    value_loss         | 0.012       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 313           |\n",
      "|    iterations         | 95600         |\n",
      "|    time_elapsed       | 1523          |\n",
      "|    total_timesteps    | 478000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.6         |\n",
      "|    explained_variance | 0.0766        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 95599         |\n",
      "|    policy_loss        | -5.09         |\n",
      "|    reward             | -0.0049452605 |\n",
      "|    std                | 2.87e+06      |\n",
      "|    value_loss         | 0.0308        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 95700       |\n",
      "|    time_elapsed       | 1525        |\n",
      "|    total_timesteps    | 478500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.6       |\n",
      "|    explained_variance | 0.0514      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 95699       |\n",
      "|    policy_loss        | -0.703      |\n",
      "|    reward             | 0.024484802 |\n",
      "|    std                | 2.88e+06    |\n",
      "|    value_loss         | 0.0105      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 95800        |\n",
      "|    time_elapsed       | 1527         |\n",
      "|    total_timesteps    | 479000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.6        |\n",
      "|    explained_variance | -7.37        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 95799        |\n",
      "|    policy_loss        | -0.833       |\n",
      "|    reward             | 0.0031712013 |\n",
      "|    std                | 2.91e+06     |\n",
      "|    value_loss         | 0.00183      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 95900        |\n",
      "|    time_elapsed       | 1528         |\n",
      "|    total_timesteps    | 479500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.6        |\n",
      "|    explained_variance | 0.312        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 95899        |\n",
      "|    policy_loss        | -1.34        |\n",
      "|    reward             | 0.0145337805 |\n",
      "|    std                | 2.95e+06     |\n",
      "|    value_loss         | 0.00335      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 96000       |\n",
      "|    time_elapsed       | 1530        |\n",
      "|    total_timesteps    | 480000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 95999       |\n",
      "|    policy_loss        | 0.169       |\n",
      "|    reward             | -0.01058545 |\n",
      "|    std                | 3e+06       |\n",
      "|    value_loss         | 6.57e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 96100       |\n",
      "|    time_elapsed       | 1532        |\n",
      "|    total_timesteps    | 480500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.7       |\n",
      "|    explained_variance | -0.0349     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 96099       |\n",
      "|    policy_loss        | 0.929       |\n",
      "|    reward             | 0.008889572 |\n",
      "|    std                | 3.06e+06    |\n",
      "|    value_loss         | 0.00112     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 96200       |\n",
      "|    time_elapsed       | 1533        |\n",
      "|    total_timesteps    | 481000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.7       |\n",
      "|    explained_variance | 0.421       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 96199       |\n",
      "|    policy_loss        | 0.343       |\n",
      "|    reward             | 0.032978892 |\n",
      "|    std                | 3.12e+06    |\n",
      "|    value_loss         | 0.00133     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 96300       |\n",
      "|    time_elapsed       | 1535        |\n",
      "|    total_timesteps    | 481500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 96299       |\n",
      "|    policy_loss        | 3.74        |\n",
      "|    reward             | 0.059630226 |\n",
      "|    std                | 3.12e+06    |\n",
      "|    value_loss         | 0.014       |\n",
      "---------------------------------------\n",
      "day: 2833, episode: 170\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 72801.29\n",
      "total_reward: 62801.29\n",
      "total_cost: 42.93\n",
      "total_trades: 5653\n",
      "Sharpe: 0.773\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 96400       |\n",
      "|    time_elapsed       | 1536        |\n",
      "|    total_timesteps    | 482000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.8       |\n",
      "|    explained_variance | -0.15       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 96399       |\n",
      "|    policy_loss        | 1.87        |\n",
      "|    reward             | 0.021065066 |\n",
      "|    std                | 3.17e+06    |\n",
      "|    value_loss         | 0.00417     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 313           |\n",
      "|    iterations         | 96500         |\n",
      "|    time_elapsed       | 1538          |\n",
      "|    total_timesteps    | 482500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 96499         |\n",
      "|    policy_loss        | -0.482        |\n",
      "|    reward             | -0.0023116625 |\n",
      "|    std                | 3.21e+06      |\n",
      "|    value_loss         | 0.000637      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 313        |\n",
      "|    iterations         | 96600      |\n",
      "|    time_elapsed       | 1540       |\n",
      "|    total_timesteps    | 483000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.8      |\n",
      "|    explained_variance | 3.55e-05   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 96599      |\n",
      "|    policy_loss        | 0.49       |\n",
      "|    reward             | 0.05276415 |\n",
      "|    std                | 3.28e+06   |\n",
      "|    value_loss         | 0.00165    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 96700       |\n",
      "|    time_elapsed       | 1541        |\n",
      "|    total_timesteps    | 483500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.8       |\n",
      "|    explained_variance | 0.0596      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 96699       |\n",
      "|    policy_loss        | 11.4        |\n",
      "|    reward             | -0.10817454 |\n",
      "|    std                | 3.26e+06    |\n",
      "|    value_loss         | 0.141       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 96800        |\n",
      "|    time_elapsed       | 1543         |\n",
      "|    total_timesteps    | 484000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.8        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 96799        |\n",
      "|    policy_loss        | 9.2          |\n",
      "|    reward             | -0.017435651 |\n",
      "|    std                | 3.29e+06     |\n",
      "|    value_loss         | 0.089        |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 313       |\n",
      "|    iterations         | 96900     |\n",
      "|    time_elapsed       | 1544      |\n",
      "|    total_timesteps    | 484500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.9     |\n",
      "|    explained_variance | 0.0629    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 96899     |\n",
      "|    policy_loss        | 7.28      |\n",
      "|    reward             | 0.1791238 |\n",
      "|    std                | 3.32e+06  |\n",
      "|    value_loss         | 0.159     |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 97000        |\n",
      "|    time_elapsed       | 1546         |\n",
      "|    total_timesteps    | 485000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.9        |\n",
      "|    explained_variance | 0.51         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 96999        |\n",
      "|    policy_loss        | 1.06         |\n",
      "|    reward             | 0.0035766324 |\n",
      "|    std                | 3.32e+06     |\n",
      "|    value_loss         | 0.00112      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 97100        |\n",
      "|    time_elapsed       | 1547         |\n",
      "|    total_timesteps    | 485500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.9        |\n",
      "|    explained_variance | 0.506        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97099        |\n",
      "|    policy_loss        | 0.116        |\n",
      "|    reward             | -0.008583397 |\n",
      "|    std                | 3.36e+06     |\n",
      "|    value_loss         | 1.39e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 97200       |\n",
      "|    time_elapsed       | 1549        |\n",
      "|    total_timesteps    | 486000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.9       |\n",
      "|    explained_variance | 0.823       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97199       |\n",
      "|    policy_loss        | -0.586      |\n",
      "|    reward             | 0.013425017 |\n",
      "|    std                | 3.41e+06    |\n",
      "|    value_loss         | 0.000329    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 97300       |\n",
      "|    time_elapsed       | 1551        |\n",
      "|    total_timesteps    | 486500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97299       |\n",
      "|    policy_loss        | -0.56       |\n",
      "|    reward             | 0.013353928 |\n",
      "|    std                | 3.48e+06    |\n",
      "|    value_loss         | 0.000342    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 97400       |\n",
      "|    time_elapsed       | 1552        |\n",
      "|    total_timesteps    | 487000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97399       |\n",
      "|    policy_loss        | -0.758      |\n",
      "|    reward             | -0.03354288 |\n",
      "|    std                | 3.6e+06     |\n",
      "|    value_loss         | 0.000888    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 313        |\n",
      "|    iterations         | 97500      |\n",
      "|    time_elapsed       | 1554       |\n",
      "|    total_timesteps    | 487500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.1      |\n",
      "|    explained_variance | 0.286      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 97499      |\n",
      "|    policy_loss        | -1.24      |\n",
      "|    reward             | 0.01009762 |\n",
      "|    std                | 3.65e+06   |\n",
      "|    value_loss         | 0.00169    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 97600        |\n",
      "|    time_elapsed       | 1555         |\n",
      "|    total_timesteps    | 488000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.1        |\n",
      "|    explained_variance | 0.461        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97599        |\n",
      "|    policy_loss        | -1.18        |\n",
      "|    reward             | 0.0023138602 |\n",
      "|    std                | 3.73e+06     |\n",
      "|    value_loss         | 0.00131      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 97700       |\n",
      "|    time_elapsed       | 1557        |\n",
      "|    total_timesteps    | 488500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.2       |\n",
      "|    explained_variance | -0.0093     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97699       |\n",
      "|    policy_loss        | 0.186       |\n",
      "|    reward             | 0.003318251 |\n",
      "|    std                | 3.86e+06    |\n",
      "|    value_loss         | 0.000134    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 97800       |\n",
      "|    time_elapsed       | 1559        |\n",
      "|    total_timesteps    | 489000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.2       |\n",
      "|    explained_variance | -0.0235     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97799       |\n",
      "|    policy_loss        | 1.9         |\n",
      "|    reward             | 0.004446611 |\n",
      "|    std                | 3.92e+06    |\n",
      "|    value_loss         | 0.00371     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 313        |\n",
      "|    iterations         | 97900      |\n",
      "|    time_elapsed       | 1560       |\n",
      "|    total_timesteps    | 489500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.2      |\n",
      "|    explained_variance | 0.333      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 97899      |\n",
      "|    policy_loss        | -2.06      |\n",
      "|    reward             | 0.03768122 |\n",
      "|    std                | 4.03e+06   |\n",
      "|    value_loss         | 0.00793    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 98000       |\n",
      "|    time_elapsed       | 1562        |\n",
      "|    total_timesteps    | 490000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97999       |\n",
      "|    policy_loss        | -0.297      |\n",
      "|    reward             | -0.05435524 |\n",
      "|    std                | 4.04e+06    |\n",
      "|    value_loss         | 0.00303     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 98100        |\n",
      "|    time_elapsed       | 1563         |\n",
      "|    total_timesteps    | 490500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.3        |\n",
      "|    explained_variance | 0.232        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98099        |\n",
      "|    policy_loss        | -0.159       |\n",
      "|    reward             | 0.0025936458 |\n",
      "|    std                | 4.07e+06     |\n",
      "|    value_loss         | 0.000112     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 98200        |\n",
      "|    time_elapsed       | 1565         |\n",
      "|    total_timesteps    | 491000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98199        |\n",
      "|    policy_loss        | 0.417        |\n",
      "|    reward             | -0.008695949 |\n",
      "|    std                | 4.12e+06     |\n",
      "|    value_loss         | 0.000174     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 98300       |\n",
      "|    time_elapsed       | 1566        |\n",
      "|    total_timesteps    | 491500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.3       |\n",
      "|    explained_variance | -0.0102     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 98299       |\n",
      "|    policy_loss        | -0.718      |\n",
      "|    reward             | 0.023111902 |\n",
      "|    std                | 4.2e+06     |\n",
      "|    value_loss         | 0.000565    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 98400       |\n",
      "|    time_elapsed       | 1568        |\n",
      "|    total_timesteps    | 492000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.4       |\n",
      "|    explained_variance | 0.292       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 98399       |\n",
      "|    policy_loss        | 2.6         |\n",
      "|    reward             | 0.026250262 |\n",
      "|    std                | 4.26e+06    |\n",
      "|    value_loss         | 0.00673     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 98500       |\n",
      "|    time_elapsed       | 1569        |\n",
      "|    total_timesteps    | 492500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.4       |\n",
      "|    explained_variance | 0.00654     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 98499       |\n",
      "|    policy_loss        | -0.0824     |\n",
      "|    reward             | 0.087573476 |\n",
      "|    std                | 4.34e+06    |\n",
      "|    value_loss         | 0.00187     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 313        |\n",
      "|    iterations         | 98600      |\n",
      "|    time_elapsed       | 1571       |\n",
      "|    total_timesteps    | 493000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.4      |\n",
      "|    explained_variance | -0.00834   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 98599      |\n",
      "|    policy_loss        | 7.65       |\n",
      "|    reward             | 0.20975272 |\n",
      "|    std                | 4.39e+06   |\n",
      "|    value_loss         | 0.0811     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 313        |\n",
      "|    iterations         | 98700      |\n",
      "|    time_elapsed       | 1572       |\n",
      "|    total_timesteps    | 493500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.4      |\n",
      "|    explained_variance | -0.695     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 98699      |\n",
      "|    policy_loss        | -0.0832    |\n",
      "|    reward             | -0.0175778 |\n",
      "|    std                | 4.45e+06   |\n",
      "|    value_loss         | 7.27e-05   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 98800        |\n",
      "|    time_elapsed       | 1574         |\n",
      "|    total_timesteps    | 494000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98799        |\n",
      "|    policy_loss        | -0.0874      |\n",
      "|    reward             | 0.0061982702 |\n",
      "|    std                | 4.55e+06     |\n",
      "|    value_loss         | 9.76e-06     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 313        |\n",
      "|    iterations         | 98900      |\n",
      "|    time_elapsed       | 1575       |\n",
      "|    total_timesteps    | 494500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.6      |\n",
      "|    explained_variance | 0.235      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 98899      |\n",
      "|    policy_loss        | -0.287     |\n",
      "|    reward             | 0.01498499 |\n",
      "|    std                | 4.71e+06   |\n",
      "|    value_loss         | 0.000115   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 99000        |\n",
      "|    time_elapsed       | 1577         |\n",
      "|    total_timesteps    | 495000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98999        |\n",
      "|    policy_loss        | -0.116       |\n",
      "|    reward             | -0.018330112 |\n",
      "|    std                | 4.89e+06     |\n",
      "|    value_loss         | 4.35e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 99100        |\n",
      "|    time_elapsed       | 1578         |\n",
      "|    total_timesteps    | 495500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.7        |\n",
      "|    explained_variance | 1.01e-06     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99099        |\n",
      "|    policy_loss        | 0.41         |\n",
      "|    reward             | -0.007524768 |\n",
      "|    std                | 5.04e+06     |\n",
      "|    value_loss         | 0.000527     |\n",
      "----------------------------------------\n",
      "day: 2833, episode: 175\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 26836.23\n",
      "total_reward: 16836.23\n",
      "total_cost: 12.33\n",
      "total_trades: 5664\n",
      "Sharpe: 0.490\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 313           |\n",
      "|    iterations         | 99200         |\n",
      "|    time_elapsed       | 1580          |\n",
      "|    total_timesteps    | 496000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.7         |\n",
      "|    explained_variance | -0.201        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 99199         |\n",
      "|    policy_loss        | -0.61         |\n",
      "|    reward             | -0.0019953926 |\n",
      "|    std                | 5.17e+06      |\n",
      "|    value_loss         | 0.000452      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 99300       |\n",
      "|    time_elapsed       | 1581        |\n",
      "|    total_timesteps    | 496500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.8       |\n",
      "|    explained_variance | 0.237       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99299       |\n",
      "|    policy_loss        | 0.0541      |\n",
      "|    reward             | 0.033198815 |\n",
      "|    std                | 5.33e+06    |\n",
      "|    value_loss         | 0.000311    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 99400        |\n",
      "|    time_elapsed       | 1583         |\n",
      "|    total_timesteps    | 497000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.9        |\n",
      "|    explained_variance | -0.000873    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99399        |\n",
      "|    policy_loss        | 0.707        |\n",
      "|    reward             | 0.0040080207 |\n",
      "|    std                | 5.49e+06     |\n",
      "|    value_loss         | 0.00101      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 99500       |\n",
      "|    time_elapsed       | 1585        |\n",
      "|    total_timesteps    | 497500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99499       |\n",
      "|    policy_loss        | 2.95        |\n",
      "|    reward             | 0.007383595 |\n",
      "|    std                | 5.63e+06    |\n",
      "|    value_loss         | 0.00801     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 99600       |\n",
      "|    time_elapsed       | 1586        |\n",
      "|    total_timesteps    | 498000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.9       |\n",
      "|    explained_variance | 0.249       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99599       |\n",
      "|    policy_loss        | -2.35       |\n",
      "|    reward             | 0.033199172 |\n",
      "|    std                | 5.68e+06    |\n",
      "|    value_loss         | 0.00663     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 99700        |\n",
      "|    time_elapsed       | 1588         |\n",
      "|    total_timesteps    | 498500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99699        |\n",
      "|    policy_loss        | -1.22        |\n",
      "|    reward             | -0.045395944 |\n",
      "|    std                | 5.72e+06     |\n",
      "|    value_loss         | 0.0101       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 99800        |\n",
      "|    time_elapsed       | 1590         |\n",
      "|    total_timesteps    | 499000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.9        |\n",
      "|    explained_variance | 0.114        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99799        |\n",
      "|    policy_loss        | -0.503       |\n",
      "|    reward             | 0.0035112556 |\n",
      "|    std                | 5.67e+06     |\n",
      "|    value_loss         | 0.00029      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 99900        |\n",
      "|    time_elapsed       | 1591         |\n",
      "|    total_timesteps    | 499500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99899        |\n",
      "|    policy_loss        | -0.0298      |\n",
      "|    reward             | 0.0058120377 |\n",
      "|    std                | 5.75e+06     |\n",
      "|    value_loss         | 5.35e-06     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 313        |\n",
      "|    iterations         | 100000     |\n",
      "|    time_elapsed       | 1593       |\n",
      "|    total_timesteps    | 500000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -34        |\n",
      "|    explained_variance | 0.327      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 99999      |\n",
      "|    policy_loss        | 0.53       |\n",
      "|    reward             | -0.0244278 |\n",
      "|    std                | 5.89e+06   |\n",
      "|    value_loss         | 0.000304   |\n",
      "--------------------------------------\n",
      "======A2C Validation from:  2021-07-06 to  2021-10-04\n",
      "A2C Sharpe Ratio:  0.1526777604542209\n",
      "======Best Model Retraining from:  2010-04-01 to  2021-10-04\n",
      "======Trading from:  2021-10-04 to  2022-01-03\n",
      "[[ 2.4518636e+02  1.5139046e+02  4.5818875e+02  5.4000000e+01\n",
      "   6.0000000e+00 -3.0756168e+00 -1.5466705e-01  1.8381165e+02\n",
      "   4.9193372e+02  1.5252881e+02  4.6105875e+02  3.8965446e+01\n",
      "   4.6421913e+01 -2.4250760e+02 -1.6717532e+02  4.8588673e+01\n",
      "   2.3755117e+01  1.6987848e+02  4.7400714e+02  1.6155258e+02\n",
      "   4.6655853e+02]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "turbulence_threshold:  18.96231252984678\n",
      "======Model training from:  2010-04-01 to  2021-10-04\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.001}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c\\a2c_315_1\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.95       |\n",
      "|    explained_variance | 0.134       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -0.0459     |\n",
      "|    reward             | 0.023846036 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 0.00065     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 3            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -2.98        |\n",
      "|    explained_variance | -1.48        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -0.00165     |\n",
      "|    reward             | -0.026489466 |\n",
      "|    std                | 1.07         |\n",
      "|    value_loss         | 0.00237      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.02       |\n",
      "|    explained_variance | 0.124       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | 0.00548     |\n",
      "|    reward             | 0.032218903 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.00129     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.03       |\n",
      "|    explained_variance | 0.361       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | 0.0175      |\n",
      "|    reward             | -0.01305681 |\n",
      "|    std                | 1.1         |\n",
      "|    value_loss         | 0.00123     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.06      |\n",
      "|    explained_variance | -2.6       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | 1.3        |\n",
      "|    reward             | -0.4714802 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 0.334      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 9           |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.06       |\n",
      "|    explained_variance | -5.71       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 599         |\n",
      "|    policy_loss        | -0.033      |\n",
      "|    reward             | 0.007343822 |\n",
      "|    std                | 1.12        |\n",
      "|    value_loss         | 0.00217     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 319        |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 10         |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.1       |\n",
      "|    explained_variance | -5.17      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | -0.412     |\n",
      "|    reward             | 0.01572265 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 0.0103     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 318         |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 12          |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.13       |\n",
      "|    explained_variance | -5.25       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | -0.0325     |\n",
      "|    reward             | 0.004053556 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 0.000553    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 14          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.14       |\n",
      "|    explained_variance | 0.126       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | 0.134       |\n",
      "|    reward             | 0.005149049 |\n",
      "|    std                | 1.17        |\n",
      "|    value_loss         | 0.00174     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 15          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.16       |\n",
      "|    explained_variance | -0.0476     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | -0.451      |\n",
      "|    reward             | -0.02128623 |\n",
      "|    std                | 1.18        |\n",
      "|    value_loss         | 0.0215      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 316         |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.19       |\n",
      "|    explained_variance | 0.294       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | -0.36       |\n",
      "|    reward             | 0.047619868 |\n",
      "|    std                | 1.19        |\n",
      "|    value_loss         | 0.0129      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 316           |\n",
      "|    iterations         | 1200          |\n",
      "|    time_elapsed       | 18            |\n",
      "|    total_timesteps    | 6000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.2          |\n",
      "|    explained_variance | -0.815        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 1199          |\n",
      "|    policy_loss        | 0.331         |\n",
      "|    reward             | -0.0024606723 |\n",
      "|    std                | 1.2           |\n",
      "|    value_loss         | 0.00926       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 317        |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 20         |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.23      |\n",
      "|    explained_variance | 0.473      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | 0.0141     |\n",
      "|    reward             | 0.01247312 |\n",
      "|    std                | 1.22       |\n",
      "|    value_loss         | 0.000208   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 317          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 22           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.26        |\n",
      "|    explained_variance | 0.247        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | 0.142        |\n",
      "|    reward             | -0.052175097 |\n",
      "|    std                | 1.23         |\n",
      "|    value_loss         | 0.00311      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 23          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.28       |\n",
      "|    explained_variance | 0.4         |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | 0.0251      |\n",
      "|    reward             | 0.023648933 |\n",
      "|    std                | 1.25        |\n",
      "|    value_loss         | 0.000533    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 25         |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.32      |\n",
      "|    explained_variance | 0.0405     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | 0.277      |\n",
      "|    reward             | 0.08789073 |\n",
      "|    std                | 1.27       |\n",
      "|    value_loss         | 0.0163     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 315         |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 26          |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.31       |\n",
      "|    explained_variance | 0.00102     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | 0.0423      |\n",
      "|    reward             | 0.052984457 |\n",
      "|    std                | 1.27        |\n",
      "|    value_loss         | 0.00511     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.36        |\n",
      "|    explained_variance | -2.95        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | -0.23        |\n",
      "|    reward             | -0.037528515 |\n",
      "|    std                | 1.29         |\n",
      "|    value_loss         | 0.00287      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.37       |\n",
      "|    explained_variance | -0.556      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | -0.0953     |\n",
      "|    reward             | -0.03704541 |\n",
      "|    std                | 1.3         |\n",
      "|    value_loss         | 0.00113     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 31           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.4         |\n",
      "|    explained_variance | -1.58        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | -0.0214      |\n",
      "|    reward             | -0.029432466 |\n",
      "|    std                | 1.32         |\n",
      "|    value_loss         | 0.000564     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 315          |\n",
      "|    iterations         | 2100         |\n",
      "|    time_elapsed       | 33           |\n",
      "|    total_timesteps    | 10500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.42        |\n",
      "|    explained_variance | 5.78e-06     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2099         |\n",
      "|    policy_loss        | 0.285        |\n",
      "|    reward             | -0.026138546 |\n",
      "|    std                | 1.34         |\n",
      "|    value_loss         | 0.0064       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 315        |\n",
      "|    iterations         | 2200       |\n",
      "|    time_elapsed       | 34         |\n",
      "|    total_timesteps    | 11000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.47      |\n",
      "|    explained_variance | 0.274      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 2199       |\n",
      "|    policy_loss        | 0.0149     |\n",
      "|    reward             | 0.01875731 |\n",
      "|    std                | 1.37       |\n",
      "|    value_loss         | 0.00106    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 2300         |\n",
      "|    time_elapsed       | 36           |\n",
      "|    total_timesteps    | 11500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.49        |\n",
      "|    explained_variance | -0.54        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2299         |\n",
      "|    policy_loss        | -0.0804      |\n",
      "|    reward             | -0.003004184 |\n",
      "|    std                | 1.39         |\n",
      "|    value_loss         | 0.00183      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 312         |\n",
      "|    iterations         | 2400        |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 12000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.52       |\n",
      "|    explained_variance | -2.76       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2399        |\n",
      "|    policy_loss        | -0.0583     |\n",
      "|    reward             | 0.004406551 |\n",
      "|    std                | 1.41        |\n",
      "|    value_loss         | 0.000493    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 312            |\n",
      "|    iterations         | 2500           |\n",
      "|    time_elapsed       | 40             |\n",
      "|    total_timesteps    | 12500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -3.55          |\n",
      "|    explained_variance | -17.1          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 2499           |\n",
      "|    policy_loss        | -0.0129        |\n",
      "|    reward             | -0.00032900926 |\n",
      "|    std                | 1.43           |\n",
      "|    value_loss         | 7.46e-05       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 2600        |\n",
      "|    time_elapsed       | 41          |\n",
      "|    total_timesteps    | 13000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.59       |\n",
      "|    explained_variance | 0.123       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2599        |\n",
      "|    policy_loss        | 0.0449      |\n",
      "|    reward             | 0.001121909 |\n",
      "|    std                | 1.46        |\n",
      "|    value_loss         | 0.000161    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 2700         |\n",
      "|    time_elapsed       | 43           |\n",
      "|    total_timesteps    | 13500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.65        |\n",
      "|    explained_variance | -0.426       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2699         |\n",
      "|    policy_loss        | 0.0145       |\n",
      "|    reward             | 0.0013256607 |\n",
      "|    std                | 1.5          |\n",
      "|    value_loss         | 2.81e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 2800         |\n",
      "|    time_elapsed       | 44           |\n",
      "|    total_timesteps    | 14000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.71        |\n",
      "|    explained_variance | -1.35e-05    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2799         |\n",
      "|    policy_loss        | 0.0415       |\n",
      "|    reward             | -0.003899253 |\n",
      "|    std                | 1.55         |\n",
      "|    value_loss         | 0.000137     |\n",
      "----------------------------------------\n",
      "day: 2896, episode: 5\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 15726.02\n",
      "total_reward: 5726.02\n",
      "total_cost: 12.09\n",
      "total_trades: 4404\n",
      "Sharpe: 0.348\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 2900         |\n",
      "|    time_elapsed       | 46           |\n",
      "|    total_timesteps    | 14500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.76        |\n",
      "|    explained_variance | -1.19e+03    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 2899         |\n",
      "|    policy_loss        | 0.797        |\n",
      "|    reward             | 0.0020194347 |\n",
      "|    std                | 1.59         |\n",
      "|    value_loss         | 0.0651       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 3000        |\n",
      "|    time_elapsed       | 47          |\n",
      "|    total_timesteps    | 15000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.81       |\n",
      "|    explained_variance | 0.0394      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 2999        |\n",
      "|    policy_loss        | -0.0419     |\n",
      "|    reward             | 0.005754515 |\n",
      "|    std                | 1.62        |\n",
      "|    value_loss         | 0.000147    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 313           |\n",
      "|    iterations         | 3100          |\n",
      "|    time_elapsed       | 49            |\n",
      "|    total_timesteps    | 15500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.89         |\n",
      "|    explained_variance | 0.152         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 3099          |\n",
      "|    policy_loss        | 0.0618        |\n",
      "|    reward             | -0.0015517147 |\n",
      "|    std                | 1.7           |\n",
      "|    value_loss         | 0.000292      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 313            |\n",
      "|    iterations         | 3200           |\n",
      "|    time_elapsed       | 51             |\n",
      "|    total_timesteps    | 16000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -3.98          |\n",
      "|    explained_variance | 0.345          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 3199           |\n",
      "|    policy_loss        | 0.0166         |\n",
      "|    reward             | -0.00041105042 |\n",
      "|    std                | 1.77           |\n",
      "|    value_loss         | 3.02e-05       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 313           |\n",
      "|    iterations         | 3300          |\n",
      "|    time_elapsed       | 52            |\n",
      "|    total_timesteps    | 16500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.06         |\n",
      "|    explained_variance | 0.216         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 3299          |\n",
      "|    policy_loss        | -0.0796       |\n",
      "|    reward             | 0.00017616729 |\n",
      "|    std                | 1.84          |\n",
      "|    value_loss         | 0.000693      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 3400        |\n",
      "|    time_elapsed       | 54          |\n",
      "|    total_timesteps    | 17000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.12       |\n",
      "|    explained_variance | -0.0255     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3399        |\n",
      "|    policy_loss        | -0.306      |\n",
      "|    reward             | 0.016089473 |\n",
      "|    std                | 1.9         |\n",
      "|    value_loss         | 0.00633     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 3500        |\n",
      "|    time_elapsed       | 55          |\n",
      "|    total_timesteps    | 17500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.17       |\n",
      "|    explained_variance | 0.273       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3499        |\n",
      "|    policy_loss        | -0.00462    |\n",
      "|    reward             | 0.008272781 |\n",
      "|    std                | 1.95        |\n",
      "|    value_loss         | 3.53e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 313           |\n",
      "|    iterations         | 3600          |\n",
      "|    time_elapsed       | 57            |\n",
      "|    total_timesteps    | 18000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.21         |\n",
      "|    explained_variance | 0.453         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 3599          |\n",
      "|    policy_loss        | 0.0133        |\n",
      "|    reward             | -0.0053245528 |\n",
      "|    std                | 1.99          |\n",
      "|    value_loss         | 1.32e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 314         |\n",
      "|    iterations         | 3700        |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 18500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.28       |\n",
      "|    explained_variance | 0.211       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3699        |\n",
      "|    policy_loss        | 0.0399      |\n",
      "|    reward             | 0.004504621 |\n",
      "|    std                | 2.06        |\n",
      "|    value_loss         | 0.000114    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 314           |\n",
      "|    iterations         | 3800          |\n",
      "|    time_elapsed       | 60            |\n",
      "|    total_timesteps    | 19000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.34         |\n",
      "|    explained_variance | -0.406        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 3799          |\n",
      "|    policy_loss        | -0.0307       |\n",
      "|    reward             | -0.0032855247 |\n",
      "|    std                | 2.13          |\n",
      "|    value_loss         | 0.000292      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 3900        |\n",
      "|    time_elapsed       | 62          |\n",
      "|    total_timesteps    | 19500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.39       |\n",
      "|    explained_variance | 0.279       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3899        |\n",
      "|    policy_loss        | 0.0691      |\n",
      "|    reward             | 0.008275403 |\n",
      "|    std                | 2.17        |\n",
      "|    value_loss         | 0.000374    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 313         |\n",
      "|    iterations         | 4000        |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 20000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.4        |\n",
      "|    explained_variance | 0.561       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 3999        |\n",
      "|    policy_loss        | 0.00324     |\n",
      "|    reward             | 0.020420853 |\n",
      "|    std                | 2.18        |\n",
      "|    value_loss         | 0.000176    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 4100         |\n",
      "|    time_elapsed       | 65           |\n",
      "|    total_timesteps    | 20500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.42        |\n",
      "|    explained_variance | -0.873       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4099         |\n",
      "|    policy_loss        | 0.00862      |\n",
      "|    reward             | -0.021697735 |\n",
      "|    std                | 2.2          |\n",
      "|    value_loss         | 0.000192     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 4200         |\n",
      "|    time_elapsed       | 66           |\n",
      "|    total_timesteps    | 21000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.46        |\n",
      "|    explained_variance | -0.0605      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4199         |\n",
      "|    policy_loss        | 0.0401       |\n",
      "|    reward             | 0.0007652191 |\n",
      "|    std                | 2.26         |\n",
      "|    value_loss         | 7.43e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 314           |\n",
      "|    iterations         | 4300          |\n",
      "|    time_elapsed       | 68            |\n",
      "|    total_timesteps    | 21500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.54         |\n",
      "|    explained_variance | -0.219        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 4299          |\n",
      "|    policy_loss        | 0.00435       |\n",
      "|    reward             | 0.00036805382 |\n",
      "|    std                | 2.34          |\n",
      "|    value_loss         | 2.05e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 314           |\n",
      "|    iterations         | 4400          |\n",
      "|    time_elapsed       | 70            |\n",
      "|    total_timesteps    | 22000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.62         |\n",
      "|    explained_variance | -1.35         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 4399          |\n",
      "|    policy_loss        | -0.158        |\n",
      "|    reward             | -0.0050611678 |\n",
      "|    std                | 2.44          |\n",
      "|    value_loss         | 0.00156       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 314          |\n",
      "|    iterations         | 4500         |\n",
      "|    time_elapsed       | 71           |\n",
      "|    total_timesteps    | 22500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.68        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4499         |\n",
      "|    policy_loss        | 0.0078       |\n",
      "|    reward             | 0.0076983976 |\n",
      "|    std                | 2.51         |\n",
      "|    value_loss         | 1.49e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 313          |\n",
      "|    iterations         | 4600         |\n",
      "|    time_elapsed       | 73           |\n",
      "|    total_timesteps    | 23000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.75        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4599         |\n",
      "|    policy_loss        | -0.178       |\n",
      "|    reward             | -0.005932403 |\n",
      "|    std                | 2.59         |\n",
      "|    value_loss         | 0.00134      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 312          |\n",
      "|    iterations         | 4700         |\n",
      "|    time_elapsed       | 75           |\n",
      "|    total_timesteps    | 23500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.78        |\n",
      "|    explained_variance | -0.445       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4699         |\n",
      "|    policy_loss        | 0.0531       |\n",
      "|    reward             | -0.010747158 |\n",
      "|    std                | 2.64         |\n",
      "|    value_loss         | 0.00026      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 311          |\n",
      "|    iterations         | 4800         |\n",
      "|    time_elapsed       | 77           |\n",
      "|    total_timesteps    | 24000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.86        |\n",
      "|    explained_variance | 0.733        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 4799         |\n",
      "|    policy_loss        | 0.0408       |\n",
      "|    reward             | 0.0071587814 |\n",
      "|    std                | 2.75         |\n",
      "|    value_loss         | 9.56e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 4900          |\n",
      "|    time_elapsed       | 78            |\n",
      "|    total_timesteps    | 24500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.93         |\n",
      "|    explained_variance | 0.154         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 4899          |\n",
      "|    policy_loss        | -0.459        |\n",
      "|    reward             | -0.0075138933 |\n",
      "|    std                | 2.84          |\n",
      "|    value_loss         | 0.0103        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 5000        |\n",
      "|    time_elapsed       | 80          |\n",
      "|    total_timesteps    | 25000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.95       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 4999        |\n",
      "|    policy_loss        | 0.21        |\n",
      "|    reward             | -0.08328127 |\n",
      "|    std                | 2.88        |\n",
      "|    value_loss         | 0.00286     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 5100        |\n",
      "|    time_elapsed       | 82          |\n",
      "|    total_timesteps    | 25500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.98       |\n",
      "|    explained_variance | 0.0101      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5099        |\n",
      "|    policy_loss        | 0.174       |\n",
      "|    reward             | 0.051412735 |\n",
      "|    std                | 2.92        |\n",
      "|    value_loss         | 0.00937     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 5200       |\n",
      "|    time_elapsed       | 84         |\n",
      "|    total_timesteps    | 26000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.97      |\n",
      "|    explained_variance | -0.0815    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 5199       |\n",
      "|    policy_loss        | 0.708      |\n",
      "|    reward             | 0.08258662 |\n",
      "|    std                | 2.91       |\n",
      "|    value_loss         | 0.023      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 5300         |\n",
      "|    time_elapsed       | 86           |\n",
      "|    total_timesteps    | 26500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5           |\n",
      "|    explained_variance | -2.55        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5299         |\n",
      "|    policy_loss        | -0.105       |\n",
      "|    reward             | -0.024974685 |\n",
      "|    std                | 2.95         |\n",
      "|    value_loss         | 0.00172      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 88          |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.03       |\n",
      "|    explained_variance | -7.67       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | -0.189      |\n",
      "|    reward             | 0.052762825 |\n",
      "|    std                | 2.99        |\n",
      "|    value_loss         | 0.00238     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 5500        |\n",
      "|    time_elapsed       | 89          |\n",
      "|    total_timesteps    | 27500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.08       |\n",
      "|    explained_variance | 0.0371      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5499        |\n",
      "|    policy_loss        | 0.13        |\n",
      "|    reward             | 0.035489496 |\n",
      "|    std                | 3.07        |\n",
      "|    value_loss         | 0.0024      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 306        |\n",
      "|    iterations         | 5600       |\n",
      "|    time_elapsed       | 91         |\n",
      "|    total_timesteps    | 28000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.12      |\n",
      "|    explained_variance | 0.297      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 5599       |\n",
      "|    policy_loss        | 0.462      |\n",
      "|    reward             | 0.13563144 |\n",
      "|    std                | 3.13       |\n",
      "|    value_loss         | 0.00837    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 5700        |\n",
      "|    time_elapsed       | 92          |\n",
      "|    total_timesteps    | 28500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.14       |\n",
      "|    explained_variance | 0.65        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 5699        |\n",
      "|    policy_loss        | 0.00552     |\n",
      "|    reward             | -0.12808047 |\n",
      "|    std                | 3.16        |\n",
      "|    value_loss         | 0.000171    |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 10\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 121677.39\n",
      "total_reward: 111677.39\n",
      "total_cost: 17.72\n",
      "total_trades: 5773\n",
      "Sharpe: 0.818\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 305          |\n",
      "|    iterations         | 5800         |\n",
      "|    time_elapsed       | 94           |\n",
      "|    total_timesteps    | 29000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.18        |\n",
      "|    explained_variance | -0.153       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5799         |\n",
      "|    policy_loss        | -0.743       |\n",
      "|    reward             | -0.025520617 |\n",
      "|    std                | 3.22         |\n",
      "|    value_loss         | 0.0194       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 305          |\n",
      "|    iterations         | 5900         |\n",
      "|    time_elapsed       | 96           |\n",
      "|    total_timesteps    | 29500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.2         |\n",
      "|    explained_variance | 0.73         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5899         |\n",
      "|    policy_loss        | -0.0218      |\n",
      "|    reward             | -0.015039212 |\n",
      "|    std                | 3.26         |\n",
      "|    value_loss         | 0.000238     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 304          |\n",
      "|    iterations         | 6000         |\n",
      "|    time_elapsed       | 98           |\n",
      "|    total_timesteps    | 30000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.24        |\n",
      "|    explained_variance | 0.571        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 5999         |\n",
      "|    policy_loss        | -0.214       |\n",
      "|    reward             | 0.0023001228 |\n",
      "|    std                | 3.33         |\n",
      "|    value_loss         | 0.00158      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 304          |\n",
      "|    iterations         | 6100         |\n",
      "|    time_elapsed       | 100          |\n",
      "|    total_timesteps    | 30500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.28        |\n",
      "|    explained_variance | -0.863       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6099         |\n",
      "|    policy_loss        | 0.0826       |\n",
      "|    reward             | -0.018471472 |\n",
      "|    std                | 3.39         |\n",
      "|    value_loss         | 0.000299     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 303         |\n",
      "|    iterations         | 6200        |\n",
      "|    time_elapsed       | 102         |\n",
      "|    total_timesteps    | 31000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.32       |\n",
      "|    explained_variance | 0.254       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 6199        |\n",
      "|    policy_loss        | 0.423       |\n",
      "|    reward             | -0.03125571 |\n",
      "|    std                | 3.46        |\n",
      "|    value_loss         | 0.00841     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 303         |\n",
      "|    iterations         | 6300        |\n",
      "|    time_elapsed       | 103         |\n",
      "|    total_timesteps    | 31500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.32       |\n",
      "|    explained_variance | 0.133       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 6299        |\n",
      "|    policy_loss        | 0.77        |\n",
      "|    reward             | -0.19223572 |\n",
      "|    std                | 3.46        |\n",
      "|    value_loss         | 0.0236      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 303          |\n",
      "|    iterations         | 6400         |\n",
      "|    time_elapsed       | 105          |\n",
      "|    total_timesteps    | 32000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.35        |\n",
      "|    explained_variance | -0.697       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6399         |\n",
      "|    policy_loss        | -0.266       |\n",
      "|    reward             | 0.0021675378 |\n",
      "|    std                | 3.52         |\n",
      "|    value_loss         | 0.00301      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 303         |\n",
      "|    iterations         | 6500        |\n",
      "|    time_elapsed       | 107         |\n",
      "|    total_timesteps    | 32500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.39       |\n",
      "|    explained_variance | -1.37       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 6499        |\n",
      "|    policy_loss        | -0.475      |\n",
      "|    reward             | 0.004984137 |\n",
      "|    std                | 3.57        |\n",
      "|    value_loss         | 0.00637     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 302          |\n",
      "|    iterations         | 6600         |\n",
      "|    time_elapsed       | 108          |\n",
      "|    total_timesteps    | 33000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.42        |\n",
      "|    explained_variance | 0.646        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6599         |\n",
      "|    policy_loss        | 0.142        |\n",
      "|    reward             | -0.045416795 |\n",
      "|    std                | 3.65         |\n",
      "|    value_loss         | 0.000983     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 303          |\n",
      "|    iterations         | 6700         |\n",
      "|    time_elapsed       | 110          |\n",
      "|    total_timesteps    | 33500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.43        |\n",
      "|    explained_variance | 0.267        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6699         |\n",
      "|    policy_loss        | 0.0604       |\n",
      "|    reward             | 6.336212e-06 |\n",
      "|    std                | 3.65         |\n",
      "|    value_loss         | 0.00341      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 302        |\n",
      "|    iterations         | 6800       |\n",
      "|    time_elapsed       | 112        |\n",
      "|    total_timesteps    | 34000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.45      |\n",
      "|    explained_variance | 0.0135     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 6799       |\n",
      "|    policy_loss        | 0.868      |\n",
      "|    reward             | 0.11366484 |\n",
      "|    std                | 3.69       |\n",
      "|    value_loss         | 0.0579     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 302          |\n",
      "|    iterations         | 6900         |\n",
      "|    time_elapsed       | 113          |\n",
      "|    total_timesteps    | 34500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.48        |\n",
      "|    explained_variance | -0.06        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6899         |\n",
      "|    policy_loss        | -0.0169      |\n",
      "|    reward             | -0.007258528 |\n",
      "|    std                | 3.75         |\n",
      "|    value_loss         | 0.094        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 302          |\n",
      "|    iterations         | 7000         |\n",
      "|    time_elapsed       | 115          |\n",
      "|    total_timesteps    | 35000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.48        |\n",
      "|    explained_variance | -3.48        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 6999         |\n",
      "|    policy_loss        | -0.482       |\n",
      "|    reward             | -0.041248664 |\n",
      "|    std                | 3.74         |\n",
      "|    value_loss         | 0.0114       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 302         |\n",
      "|    iterations         | 7100        |\n",
      "|    time_elapsed       | 117         |\n",
      "|    total_timesteps    | 35500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.49       |\n",
      "|    explained_variance | 0.594       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7099        |\n",
      "|    policy_loss        | 0.0342      |\n",
      "|    reward             | 0.011064647 |\n",
      "|    std                | 3.77        |\n",
      "|    value_loss         | 0.000187    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 302        |\n",
      "|    iterations         | 7200       |\n",
      "|    time_elapsed       | 118        |\n",
      "|    total_timesteps    | 36000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.51      |\n",
      "|    explained_variance | -0.757     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 7199       |\n",
      "|    policy_loss        | 0.185      |\n",
      "|    reward             | 0.04371052 |\n",
      "|    std                | 3.81       |\n",
      "|    value_loss         | 0.00171    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 302         |\n",
      "|    iterations         | 7300        |\n",
      "|    time_elapsed       | 120         |\n",
      "|    total_timesteps    | 36500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.53       |\n",
      "|    explained_variance | 0.638       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7299        |\n",
      "|    policy_loss        | -0.157      |\n",
      "|    reward             | -0.11670906 |\n",
      "|    std                | 3.84        |\n",
      "|    value_loss         | 0.00113     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 302         |\n",
      "|    iterations         | 7400        |\n",
      "|    time_elapsed       | 122         |\n",
      "|    total_timesteps    | 37000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.53       |\n",
      "|    explained_variance | 3.9e-05     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7399        |\n",
      "|    policy_loss        | 1.1         |\n",
      "|    reward             | 0.059739362 |\n",
      "|    std                | 3.84        |\n",
      "|    value_loss         | 0.0485      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 302        |\n",
      "|    iterations         | 7500       |\n",
      "|    time_elapsed       | 123        |\n",
      "|    total_timesteps    | 37500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.54      |\n",
      "|    explained_variance | 0.0475     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 7499       |\n",
      "|    policy_loss        | -0.247     |\n",
      "|    reward             | 0.29778758 |\n",
      "|    std                | 3.86       |\n",
      "|    value_loss         | 0.0977     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 302          |\n",
      "|    iterations         | 7600         |\n",
      "|    time_elapsed       | 125          |\n",
      "|    total_timesteps    | 38000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.56        |\n",
      "|    explained_variance | 0.947        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 7599         |\n",
      "|    policy_loss        | 0.335        |\n",
      "|    reward             | -0.044706985 |\n",
      "|    std                | 3.91         |\n",
      "|    value_loss         | 0.00275      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 302         |\n",
      "|    iterations         | 7700        |\n",
      "|    time_elapsed       | 127         |\n",
      "|    total_timesteps    | 38500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.58       |\n",
      "|    explained_variance | -1.91       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7699        |\n",
      "|    policy_loss        | 0.618       |\n",
      "|    reward             | 0.021607136 |\n",
      "|    std                | 3.94        |\n",
      "|    value_loss         | 0.0118      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 301         |\n",
      "|    iterations         | 7800        |\n",
      "|    time_elapsed       | 129         |\n",
      "|    total_timesteps    | 39000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.6        |\n",
      "|    explained_variance | -9.72       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 7799        |\n",
      "|    policy_loss        | -0.305      |\n",
      "|    reward             | 0.062059917 |\n",
      "|    std                | 3.99        |\n",
      "|    value_loss         | 0.00514     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 301          |\n",
      "|    iterations         | 7900         |\n",
      "|    time_elapsed       | 131          |\n",
      "|    total_timesteps    | 39500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.63        |\n",
      "|    explained_variance | 0.644        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 7899         |\n",
      "|    policy_loss        | 0.319        |\n",
      "|    reward             | 0.0008257877 |\n",
      "|    std                | 4.04         |\n",
      "|    value_loss         | 0.00394      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 301        |\n",
      "|    iterations         | 8000       |\n",
      "|    time_elapsed       | 132        |\n",
      "|    total_timesteps    | 40000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.64      |\n",
      "|    explained_variance | 0.0326     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 7999       |\n",
      "|    policy_loss        | -0.577     |\n",
      "|    reward             | 0.07796654 |\n",
      "|    std                | 4.07       |\n",
      "|    value_loss         | 0.0183     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 301          |\n",
      "|    iterations         | 8100         |\n",
      "|    time_elapsed       | 134          |\n",
      "|    total_timesteps    | 40500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.66        |\n",
      "|    explained_variance | 0.575        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 8099         |\n",
      "|    policy_loss        | -0.387       |\n",
      "|    reward             | -0.031626355 |\n",
      "|    std                | 4.1          |\n",
      "|    value_loss         | 0.00514      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 301           |\n",
      "|    iterations         | 8200          |\n",
      "|    time_elapsed       | 135           |\n",
      "|    total_timesteps    | 41000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.69         |\n",
      "|    explained_variance | -1.06         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 8199          |\n",
      "|    policy_loss        | 0.0413        |\n",
      "|    reward             | -0.0031634613 |\n",
      "|    std                | 4.17          |\n",
      "|    value_loss         | 0.000126      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 301           |\n",
      "|    iterations         | 8300          |\n",
      "|    time_elapsed       | 137           |\n",
      "|    total_timesteps    | 41500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.73         |\n",
      "|    explained_variance | 0.0627        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 8299          |\n",
      "|    policy_loss        | 0.11          |\n",
      "|    reward             | 0.00022165108 |\n",
      "|    std                | 4.25          |\n",
      "|    value_loss         | 0.00205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 301           |\n",
      "|    iterations         | 8400          |\n",
      "|    time_elapsed       | 139           |\n",
      "|    total_timesteps    | 42000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.79         |\n",
      "|    explained_variance | -0.167        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 8399          |\n",
      "|    policy_loss        | -0.208        |\n",
      "|    reward             | -0.0064785597 |\n",
      "|    std                | 4.37          |\n",
      "|    value_loss         | 0.00181       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 301         |\n",
      "|    iterations         | 8500        |\n",
      "|    time_elapsed       | 140         |\n",
      "|    total_timesteps    | 42500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.79       |\n",
      "|    explained_variance | -0.401      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 8499        |\n",
      "|    policy_loss        | -0.506      |\n",
      "|    reward             | 0.080212794 |\n",
      "|    std                | 4.38        |\n",
      "|    value_loss         | 0.0111      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 301        |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 142        |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.85      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | -0.124     |\n",
      "|    reward             | 0.10949947 |\n",
      "|    std                | 4.52       |\n",
      "|    value_loss         | 0.0048     |\n",
      "--------------------------------------\n",
      "day: 2896, episode: 15\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 74229.91\n",
      "total_reward: 64229.91\n",
      "total_cost: 29.41\n",
      "total_trades: 5780\n",
      "Sharpe: 0.698\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 301           |\n",
      "|    iterations         | 8700          |\n",
      "|    time_elapsed       | 144           |\n",
      "|    total_timesteps    | 43500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.88         |\n",
      "|    explained_variance | -0.0213       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 8699          |\n",
      "|    policy_loss        | 0.0645        |\n",
      "|    reward             | -0.0045622326 |\n",
      "|    std                | 4.57          |\n",
      "|    value_loss         | 0.000522      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 301          |\n",
      "|    iterations         | 8800         |\n",
      "|    time_elapsed       | 145          |\n",
      "|    total_timesteps    | 44000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.9         |\n",
      "|    explained_variance | 0.429        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 8799         |\n",
      "|    policy_loss        | 0.152        |\n",
      "|    reward             | -0.043012366 |\n",
      "|    std                | 4.63         |\n",
      "|    value_loss         | 0.000805     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 301          |\n",
      "|    iterations         | 8900         |\n",
      "|    time_elapsed       | 147          |\n",
      "|    total_timesteps    | 44500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.95        |\n",
      "|    explained_variance | 0.448        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 8899         |\n",
      "|    policy_loss        | -0.237       |\n",
      "|    reward             | -0.005611458 |\n",
      "|    std                | 4.75         |\n",
      "|    value_loss         | 0.0019       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 302        |\n",
      "|    iterations         | 9000       |\n",
      "|    time_elapsed       | 148        |\n",
      "|    total_timesteps    | 45000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.99      |\n",
      "|    explained_variance | 0.255      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 8999       |\n",
      "|    policy_loss        | -0.366     |\n",
      "|    reward             | 0.09994819 |\n",
      "|    std                | 4.83       |\n",
      "|    value_loss         | 0.00435    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 302         |\n",
      "|    iterations         | 9100        |\n",
      "|    time_elapsed       | 150         |\n",
      "|    total_timesteps    | 45500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.99       |\n",
      "|    explained_variance | 0.517       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9099        |\n",
      "|    policy_loss        | 0.715       |\n",
      "|    reward             | -0.03885309 |\n",
      "|    std                | 4.83        |\n",
      "|    value_loss         | 0.0209      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 302         |\n",
      "|    iterations         | 9200        |\n",
      "|    time_elapsed       | 152         |\n",
      "|    total_timesteps    | 46000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.01       |\n",
      "|    explained_variance | -0.00678    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9199        |\n",
      "|    policy_loss        | -0.441      |\n",
      "|    reward             | -0.21705943 |\n",
      "|    std                | 4.9         |\n",
      "|    value_loss         | 0.0524      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 302          |\n",
      "|    iterations         | 9300         |\n",
      "|    time_elapsed       | 153          |\n",
      "|    total_timesteps    | 46500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.01        |\n",
      "|    explained_variance | 0.238        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 9299         |\n",
      "|    policy_loss        | -0.254       |\n",
      "|    reward             | -0.012167854 |\n",
      "|    std                | 4.89         |\n",
      "|    value_loss         | 0.00162      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 302           |\n",
      "|    iterations         | 9400          |\n",
      "|    time_elapsed       | 155           |\n",
      "|    total_timesteps    | 47000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.03         |\n",
      "|    explained_variance | -5.44         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 9399          |\n",
      "|    policy_loss        | -0.202        |\n",
      "|    reward             | -0.0068984292 |\n",
      "|    std                | 4.93          |\n",
      "|    value_loss         | 0.0013        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 303          |\n",
      "|    iterations         | 9500         |\n",
      "|    time_elapsed       | 156          |\n",
      "|    total_timesteps    | 47500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.06        |\n",
      "|    explained_variance | 0.817        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 9499         |\n",
      "|    policy_loss        | -0.13        |\n",
      "|    reward             | -0.024677776 |\n",
      "|    std                | 5            |\n",
      "|    value_loss         | 0.00207      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 303          |\n",
      "|    iterations         | 9600         |\n",
      "|    time_elapsed       | 158          |\n",
      "|    total_timesteps    | 48000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.09        |\n",
      "|    explained_variance | 0.00211      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 9599         |\n",
      "|    policy_loss        | 0.188        |\n",
      "|    reward             | -0.018682644 |\n",
      "|    std                | 5.08         |\n",
      "|    value_loss         | 0.00174      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 303          |\n",
      "|    iterations         | 9700         |\n",
      "|    time_elapsed       | 159          |\n",
      "|    total_timesteps    | 48500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.1         |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 9699         |\n",
      "|    policy_loss        | -0.0692      |\n",
      "|    reward             | -0.052809734 |\n",
      "|    std                | 5.11         |\n",
      "|    value_loss         | 0.000448     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 303        |\n",
      "|    iterations         | 9800       |\n",
      "|    time_elapsed       | 161        |\n",
      "|    total_timesteps    | 49000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.1       |\n",
      "|    explained_variance | 0.253      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 9799       |\n",
      "|    policy_loss        | 0.568      |\n",
      "|    reward             | 0.05525214 |\n",
      "|    std                | 5.12       |\n",
      "|    value_loss         | 0.0181     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 303         |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 162         |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.12       |\n",
      "|    explained_variance | 0.436       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 9899        |\n",
      "|    policy_loss        | 0.0777      |\n",
      "|    reward             | 0.022551173 |\n",
      "|    std                | 5.16        |\n",
      "|    value_loss         | 0.000529    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 303           |\n",
      "|    iterations         | 10000         |\n",
      "|    time_elapsed       | 164           |\n",
      "|    total_timesteps    | 50000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.14         |\n",
      "|    explained_variance | 0.109         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 9999          |\n",
      "|    policy_loss        | -0.00652      |\n",
      "|    reward             | -0.0036988603 |\n",
      "|    std                | 5.22          |\n",
      "|    value_loss         | 0.000525      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 303        |\n",
      "|    iterations         | 10100      |\n",
      "|    time_elapsed       | 166        |\n",
      "|    total_timesteps    | 50500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.16      |\n",
      "|    explained_variance | 0.0753     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 10099      |\n",
      "|    policy_loss        | 0.897      |\n",
      "|    reward             | 0.04445868 |\n",
      "|    std                | 5.28       |\n",
      "|    value_loss         | 0.0203     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 303         |\n",
      "|    iterations         | 10200       |\n",
      "|    time_elapsed       | 167         |\n",
      "|    total_timesteps    | 51000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.17       |\n",
      "|    explained_variance | 0.0929      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10199       |\n",
      "|    policy_loss        | 0.635       |\n",
      "|    reward             | -0.11252056 |\n",
      "|    std                | 5.29        |\n",
      "|    value_loss         | 0.0109      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 304         |\n",
      "|    iterations         | 10300       |\n",
      "|    time_elapsed       | 169         |\n",
      "|    total_timesteps    | 51500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.18       |\n",
      "|    explained_variance | 0.00122     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10299       |\n",
      "|    policy_loss        | -0.838      |\n",
      "|    reward             | 0.069052435 |\n",
      "|    std                | 5.31        |\n",
      "|    value_loss         | 0.0266      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 303        |\n",
      "|    iterations         | 10400      |\n",
      "|    time_elapsed       | 171        |\n",
      "|    total_timesteps    | 52000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.15      |\n",
      "|    explained_variance | -0.0155    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 10399      |\n",
      "|    policy_loss        | 4.62       |\n",
      "|    reward             | -1.3298713 |\n",
      "|    std                | 5.24       |\n",
      "|    value_loss         | 0.786      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 304         |\n",
      "|    iterations         | 10500       |\n",
      "|    time_elapsed       | 172         |\n",
      "|    total_timesteps    | 52500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.15       |\n",
      "|    explained_variance | -19         |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10499       |\n",
      "|    policy_loss        | -0.739      |\n",
      "|    reward             | -0.04092328 |\n",
      "|    std                | 5.24        |\n",
      "|    value_loss         | 0.0173      |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 303            |\n",
      "|    iterations         | 10600          |\n",
      "|    time_elapsed       | 174            |\n",
      "|    total_timesteps    | 53000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -6.19          |\n",
      "|    explained_variance | 0.124          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 10599          |\n",
      "|    policy_loss        | -0.173         |\n",
      "|    reward             | -0.00060067023 |\n",
      "|    std                | 5.34           |\n",
      "|    value_loss         | 0.000959       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 303         |\n",
      "|    iterations         | 10700       |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 53500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.23       |\n",
      "|    explained_variance | 0.16        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10699       |\n",
      "|    policy_loss        | 0.0198      |\n",
      "|    reward             | -0.10378884 |\n",
      "|    std                | 5.46        |\n",
      "|    value_loss         | 0.00206     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 303        |\n",
      "|    iterations         | 10800      |\n",
      "|    time_elapsed       | 178        |\n",
      "|    total_timesteps    | 54000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.24      |\n",
      "|    explained_variance | 0.0329     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 10799      |\n",
      "|    policy_loss        | -0.366     |\n",
      "|    reward             | 0.11124854 |\n",
      "|    std                | 5.47       |\n",
      "|    value_loss         | 0.00718    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 303         |\n",
      "|    iterations         | 10900       |\n",
      "|    time_elapsed       | 179         |\n",
      "|    total_timesteps    | 54500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.25       |\n",
      "|    explained_variance | 9.73e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10899       |\n",
      "|    policy_loss        | -2.84       |\n",
      "|    reward             | 0.030064916 |\n",
      "|    std                | 5.5         |\n",
      "|    value_loss         | 0.224       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 303         |\n",
      "|    iterations         | 11000       |\n",
      "|    time_elapsed       | 181         |\n",
      "|    total_timesteps    | 55000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.27       |\n",
      "|    explained_variance | 0.26        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 10999       |\n",
      "|    policy_loss        | -0.721      |\n",
      "|    reward             | 0.078722656 |\n",
      "|    std                | 5.55        |\n",
      "|    value_loss         | 0.0344      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 303         |\n",
      "|    iterations         | 11100       |\n",
      "|    time_elapsed       | 183         |\n",
      "|    total_timesteps    | 55500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.29       |\n",
      "|    explained_variance | 0.625       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 11099       |\n",
      "|    policy_loss        | 0.000997    |\n",
      "|    reward             | 0.009647333 |\n",
      "|    std                | 5.61        |\n",
      "|    value_loss         | 5.14e-05    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 303            |\n",
      "|    iterations         | 11200          |\n",
      "|    time_elapsed       | 184            |\n",
      "|    total_timesteps    | 56000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -6.32          |\n",
      "|    explained_variance | -1.31          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 11199          |\n",
      "|    policy_loss        | -0.071         |\n",
      "|    reward             | -0.00022172126 |\n",
      "|    std                | 5.7            |\n",
      "|    value_loss         | 0.000326       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 303         |\n",
      "|    iterations         | 11300       |\n",
      "|    time_elapsed       | 186         |\n",
      "|    total_timesteps    | 56500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.37       |\n",
      "|    explained_variance | -0.0378     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 11299       |\n",
      "|    policy_loss        | -2          |\n",
      "|    reward             | 0.047065515 |\n",
      "|    std                | 5.84        |\n",
      "|    value_loss         | 0.108       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 303         |\n",
      "|    iterations         | 11400       |\n",
      "|    time_elapsed       | 187         |\n",
      "|    total_timesteps    | 57000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.4        |\n",
      "|    explained_variance | 0.00291     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 11399       |\n",
      "|    policy_loss        | 0.643       |\n",
      "|    reward             | -0.08236539 |\n",
      "|    std                | 5.95        |\n",
      "|    value_loss         | 0.0126      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 303          |\n",
      "|    iterations         | 11500        |\n",
      "|    time_elapsed       | 189          |\n",
      "|    total_timesteps    | 57500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.39        |\n",
      "|    explained_variance | 9.53e-05     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11499        |\n",
      "|    policy_loss        | -0.453       |\n",
      "|    reward             | -0.011060163 |\n",
      "|    std                | 5.9          |\n",
      "|    value_loss         | 0.00689      |\n",
      "----------------------------------------\n",
      "day: 2896, episode: 20\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 143657.24\n",
      "total_reward: 133657.24\n",
      "total_cost: 14.68\n",
      "total_trades: 5785\n",
      "Sharpe: 0.831\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 303          |\n",
      "|    iterations         | 11600        |\n",
      "|    time_elapsed       | 191          |\n",
      "|    total_timesteps    | 58000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.41        |\n",
      "|    explained_variance | -0.562       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11599        |\n",
      "|    policy_loss        | -0.133       |\n",
      "|    reward             | 0.0040336307 |\n",
      "|    std                | 5.95         |\n",
      "|    value_loss         | 0.000433     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 303          |\n",
      "|    iterations         | 11700        |\n",
      "|    time_elapsed       | 192          |\n",
      "|    total_timesteps    | 58500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.43        |\n",
      "|    explained_variance | -0.395       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11699        |\n",
      "|    policy_loss        | 0.0549       |\n",
      "|    reward             | 0.0067899246 |\n",
      "|    std                | 6.02         |\n",
      "|    value_loss         | 0.000114     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 303           |\n",
      "|    iterations         | 11800         |\n",
      "|    time_elapsed       | 194           |\n",
      "|    total_timesteps    | 59000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.46         |\n",
      "|    explained_variance | 0.5           |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 11799         |\n",
      "|    policy_loss        | 0.0372        |\n",
      "|    reward             | -0.0022697814 |\n",
      "|    std                | 6.11          |\n",
      "|    value_loss         | 3.59e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 303          |\n",
      "|    iterations         | 11900        |\n",
      "|    time_elapsed       | 195          |\n",
      "|    total_timesteps    | 59500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.47        |\n",
      "|    explained_variance | -0.484       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 11899        |\n",
      "|    policy_loss        | 0.881        |\n",
      "|    reward             | -0.018356657 |\n",
      "|    std                | 6.16         |\n",
      "|    value_loss         | 0.0258       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 303         |\n",
      "|    iterations         | 12000       |\n",
      "|    time_elapsed       | 197         |\n",
      "|    total_timesteps    | 60000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.53       |\n",
      "|    explained_variance | 0.59        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 11999       |\n",
      "|    policy_loss        | 0.418       |\n",
      "|    reward             | 0.022356808 |\n",
      "|    std                | 6.33        |\n",
      "|    value_loss         | 0.00573     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 303       |\n",
      "|    iterations         | 12100     |\n",
      "|    time_elapsed       | 199       |\n",
      "|    total_timesteps    | 60500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.55     |\n",
      "|    explained_variance | 1.07e-06  |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 12099     |\n",
      "|    policy_loss        | 1.38      |\n",
      "|    reward             | 0.2389457 |\n",
      "|    std                | 6.39      |\n",
      "|    value_loss         | 0.0526    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 303         |\n",
      "|    iterations         | 12200       |\n",
      "|    time_elapsed       | 200         |\n",
      "|    total_timesteps    | 61000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.56       |\n",
      "|    explained_variance | -0.0374     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12199       |\n",
      "|    policy_loss        | -0.0512     |\n",
      "|    reward             | 0.023283051 |\n",
      "|    std                | 6.44        |\n",
      "|    value_loss         | 0.000324    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 303          |\n",
      "|    iterations         | 12300        |\n",
      "|    time_elapsed       | 202          |\n",
      "|    total_timesteps    | 61500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.6         |\n",
      "|    explained_variance | 0.143        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 12299        |\n",
      "|    policy_loss        | -0.0758      |\n",
      "|    reward             | -0.010159987 |\n",
      "|    std                | 6.56         |\n",
      "|    value_loss         | 0.000559     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 304         |\n",
      "|    iterations         | 12400       |\n",
      "|    time_elapsed       | 203         |\n",
      "|    total_timesteps    | 62000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.62       |\n",
      "|    explained_variance | 0.0798      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12399       |\n",
      "|    policy_loss        | 0.264       |\n",
      "|    reward             | 0.029365692 |\n",
      "|    std                | 6.63        |\n",
      "|    value_loss         | 0.00445     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 304        |\n",
      "|    iterations         | 12500      |\n",
      "|    time_elapsed       | 205        |\n",
      "|    total_timesteps    | 62500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.64      |\n",
      "|    explained_variance | 0.26       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 12499      |\n",
      "|    policy_loss        | -0.824     |\n",
      "|    reward             | 0.19117002 |\n",
      "|    std                | 6.7        |\n",
      "|    value_loss         | 0.0213     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 304        |\n",
      "|    iterations         | 12600      |\n",
      "|    time_elapsed       | 206        |\n",
      "|    total_timesteps    | 63000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.64      |\n",
      "|    explained_variance | 0.209      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 12599      |\n",
      "|    policy_loss        | -1.29      |\n",
      "|    reward             | 0.25326914 |\n",
      "|    std                | 6.71       |\n",
      "|    value_loss         | 0.0564     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 304        |\n",
      "|    iterations         | 12700      |\n",
      "|    time_elapsed       | 208        |\n",
      "|    total_timesteps    | 63500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.67      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 12699      |\n",
      "|    policy_loss        | -1.93      |\n",
      "|    reward             | -0.5759978 |\n",
      "|    std                | 6.81       |\n",
      "|    value_loss         | 0.103      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 304         |\n",
      "|    iterations         | 12800       |\n",
      "|    time_elapsed       | 210         |\n",
      "|    total_timesteps    | 64000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.68       |\n",
      "|    explained_variance | 0.197       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 12799       |\n",
      "|    policy_loss        | -0.0522     |\n",
      "|    reward             | 0.030379405 |\n",
      "|    std                | 6.82        |\n",
      "|    value_loss         | 0.000117    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 304           |\n",
      "|    iterations         | 12900         |\n",
      "|    time_elapsed       | 211           |\n",
      "|    total_timesteps    | 64500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.71         |\n",
      "|    explained_variance | 0.746         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 12899         |\n",
      "|    policy_loss        | 0.239         |\n",
      "|    reward             | -0.0041407947 |\n",
      "|    std                | 6.93          |\n",
      "|    value_loss         | 0.00116       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 304          |\n",
      "|    iterations         | 13000        |\n",
      "|    time_elapsed       | 213          |\n",
      "|    total_timesteps    | 65000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.74        |\n",
      "|    explained_variance | 0.123        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 12999        |\n",
      "|    policy_loss        | 0.131        |\n",
      "|    reward             | 0.0034398711 |\n",
      "|    std                | 7.05         |\n",
      "|    value_loss         | 0.000338     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 304         |\n",
      "|    iterations         | 13100       |\n",
      "|    time_elapsed       | 214         |\n",
      "|    total_timesteps    | 65500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.79       |\n",
      "|    explained_variance | 0.0042      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13099       |\n",
      "|    policy_loss        | -0.0158     |\n",
      "|    reward             | 0.010122516 |\n",
      "|    std                | 7.24        |\n",
      "|    value_loss         | 2.7e-05     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 305         |\n",
      "|    iterations         | 13200       |\n",
      "|    time_elapsed       | 216         |\n",
      "|    total_timesteps    | 66000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.86       |\n",
      "|    explained_variance | 0.215       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13199       |\n",
      "|    policy_loss        | -0.217      |\n",
      "|    reward             | 0.017616808 |\n",
      "|    std                | 7.49        |\n",
      "|    value_loss         | 0.00158     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 305         |\n",
      "|    iterations         | 13300       |\n",
      "|    time_elapsed       | 217         |\n",
      "|    total_timesteps    | 66500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.94       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13299       |\n",
      "|    policy_loss        | 0.0268      |\n",
      "|    reward             | 0.016714606 |\n",
      "|    std                | 7.78        |\n",
      "|    value_loss         | 0.000648    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 305         |\n",
      "|    iterations         | 13400       |\n",
      "|    time_elapsed       | 219         |\n",
      "|    total_timesteps    | 67000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.94       |\n",
      "|    explained_variance | 0.409       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13399       |\n",
      "|    policy_loss        | 0.0636      |\n",
      "|    reward             | -0.00802249 |\n",
      "|    std                | 7.77        |\n",
      "|    value_loss         | 0.000262    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 305           |\n",
      "|    iterations         | 13500         |\n",
      "|    time_elapsed       | 220           |\n",
      "|    total_timesteps    | 67500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.97         |\n",
      "|    explained_variance | -0.0527       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 13499         |\n",
      "|    policy_loss        | -0.0349       |\n",
      "|    reward             | -0.0015086151 |\n",
      "|    std                | 7.91          |\n",
      "|    value_loss         | 7.66e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 305         |\n",
      "|    iterations         | 13600       |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 68000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.99       |\n",
      "|    explained_variance | 0.242       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13599       |\n",
      "|    policy_loss        | -0.208      |\n",
      "|    reward             | -0.05064864 |\n",
      "|    std                | 8.02        |\n",
      "|    value_loss         | 0.0272      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 305         |\n",
      "|    iterations         | 13700       |\n",
      "|    time_elapsed       | 224         |\n",
      "|    total_timesteps    | 68500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.02       |\n",
      "|    explained_variance | 0.0956      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 13699       |\n",
      "|    policy_loss        | -1.24       |\n",
      "|    reward             | 0.014277518 |\n",
      "|    std                | 8.1         |\n",
      "|    value_loss         | 0.0373      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 305        |\n",
      "|    iterations         | 13800      |\n",
      "|    time_elapsed       | 225        |\n",
      "|    total_timesteps    | 69000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.04      |\n",
      "|    explained_variance | 0.231      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 13799      |\n",
      "|    policy_loss        | 1.37       |\n",
      "|    reward             | 0.19643809 |\n",
      "|    std                | 8.18       |\n",
      "|    value_loss         | 0.0647     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 305          |\n",
      "|    iterations         | 13900        |\n",
      "|    time_elapsed       | 227          |\n",
      "|    total_timesteps    | 69500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.03        |\n",
      "|    explained_variance | -0.00615     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 13899        |\n",
      "|    policy_loss        | -1.32        |\n",
      "|    reward             | -0.025881952 |\n",
      "|    std                | 8.13         |\n",
      "|    value_loss         | 0.0385       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 306           |\n",
      "|    iterations         | 14000         |\n",
      "|    time_elapsed       | 228           |\n",
      "|    total_timesteps    | 70000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.06         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 13999         |\n",
      "|    policy_loss        | 0.0138        |\n",
      "|    reward             | -0.0036295576 |\n",
      "|    std                | 8.24          |\n",
      "|    value_loss         | 0.000146      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 14100       |\n",
      "|    time_elapsed       | 230         |\n",
      "|    total_timesteps    | 70500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.09       |\n",
      "|    explained_variance | 0.585       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14099       |\n",
      "|    policy_loss        | 0.0611      |\n",
      "|    reward             | 0.025829732 |\n",
      "|    std                | 8.37        |\n",
      "|    value_loss         | 0.000237    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 14200       |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 71000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.12       |\n",
      "|    explained_variance | -0.0222     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14199       |\n",
      "|    policy_loss        | 0.697       |\n",
      "|    reward             | -0.10385169 |\n",
      "|    std                | 8.5         |\n",
      "|    value_loss         | 0.0101      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 306        |\n",
      "|    iterations         | 14300      |\n",
      "|    time_elapsed       | 233        |\n",
      "|    total_timesteps    | 71500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.16      |\n",
      "|    explained_variance | 0.55       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 14299      |\n",
      "|    policy_loss        | -0.635     |\n",
      "|    reward             | 0.08531248 |\n",
      "|    std                | 8.67       |\n",
      "|    value_loss         | 0.00868    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 14400       |\n",
      "|    time_elapsed       | 234         |\n",
      "|    total_timesteps    | 72000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.2        |\n",
      "|    explained_variance | -0.000252   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14399       |\n",
      "|    policy_loss        | 0.219       |\n",
      "|    reward             | 0.122099474 |\n",
      "|    std                | 8.87        |\n",
      "|    value_loss         | 0.00286     |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 25\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 87195.76\n",
      "total_reward: 77195.76\n",
      "total_cost: 15.67\n",
      "total_trades: 5783\n",
      "Sharpe: 0.754\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 306           |\n",
      "|    iterations         | 14500         |\n",
      "|    time_elapsed       | 236           |\n",
      "|    total_timesteps    | 72500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.23         |\n",
      "|    explained_variance | 4.1e-05       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 14499         |\n",
      "|    policy_loss        | 0.0262        |\n",
      "|    reward             | -0.0071044266 |\n",
      "|    std                | 8.98          |\n",
      "|    value_loss         | 4.67e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 14600        |\n",
      "|    time_elapsed       | 238          |\n",
      "|    total_timesteps    | 73000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.25        |\n",
      "|    explained_variance | 0.559        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 14599        |\n",
      "|    policy_loss        | 0.0308       |\n",
      "|    reward             | -0.014122237 |\n",
      "|    std                | 9.08         |\n",
      "|    value_loss         | 0.000113     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 14700        |\n",
      "|    time_elapsed       | 239          |\n",
      "|    total_timesteps    | 73500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.3         |\n",
      "|    explained_variance | 7.75e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 14699        |\n",
      "|    policy_loss        | 0.352        |\n",
      "|    reward             | -0.030379672 |\n",
      "|    std                | 9.31         |\n",
      "|    value_loss         | 0.00291      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 14800       |\n",
      "|    time_elapsed       | 241         |\n",
      "|    total_timesteps    | 74000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.34       |\n",
      "|    explained_variance | 0.0285      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14799       |\n",
      "|    policy_loss        | -2.13       |\n",
      "|    reward             | -0.09984071 |\n",
      "|    std                | 9.5         |\n",
      "|    value_loss         | 0.0954      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 14900       |\n",
      "|    time_elapsed       | 242         |\n",
      "|    total_timesteps    | 74500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.33       |\n",
      "|    explained_variance | 0.184       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 14899       |\n",
      "|    policy_loss        | -0.821      |\n",
      "|    reward             | -0.06731014 |\n",
      "|    std                | 9.47        |\n",
      "|    value_loss         | 0.019       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 306        |\n",
      "|    iterations         | 15000      |\n",
      "|    time_elapsed       | 244        |\n",
      "|    total_timesteps    | 75000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.33      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 14999      |\n",
      "|    policy_loss        | 1.78       |\n",
      "|    reward             | -0.1438479 |\n",
      "|    std                | 9.44       |\n",
      "|    value_loss         | 0.115      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 15100       |\n",
      "|    time_elapsed       | 245         |\n",
      "|    total_timesteps    | 75500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.33       |\n",
      "|    explained_variance | -0.872      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15099       |\n",
      "|    policy_loss        | -1.2        |\n",
      "|    reward             | -0.00823249 |\n",
      "|    std                | 9.47        |\n",
      "|    value_loss         | 0.0283      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 15200        |\n",
      "|    time_elapsed       | 247          |\n",
      "|    total_timesteps    | 76000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.37        |\n",
      "|    explained_variance | -1.38        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 15199        |\n",
      "|    policy_loss        | 0.129        |\n",
      "|    reward             | 0.0051212637 |\n",
      "|    std                | 9.64         |\n",
      "|    value_loss         | 0.0007       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 15300      |\n",
      "|    time_elapsed       | 249        |\n",
      "|    total_timesteps    | 76500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.41      |\n",
      "|    explained_variance | 0.528      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 15299      |\n",
      "|    policy_loss        | 0.613      |\n",
      "|    reward             | 0.23558943 |\n",
      "|    std                | 9.85       |\n",
      "|    value_loss         | 0.00571    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 15400       |\n",
      "|    time_elapsed       | 250         |\n",
      "|    total_timesteps    | 77000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.41       |\n",
      "|    explained_variance | 0.47        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15399       |\n",
      "|    policy_loss        | 0.881       |\n",
      "|    reward             | 0.023338469 |\n",
      "|    std                | 9.82        |\n",
      "|    value_loss         | 0.0168      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 15500         |\n",
      "|    time_elapsed       | 252           |\n",
      "|    total_timesteps    | 77500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.45         |\n",
      "|    explained_variance | 0.0421        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 15499         |\n",
      "|    policy_loss        | 1.2           |\n",
      "|    reward             | -0.0038044022 |\n",
      "|    std                | 10            |\n",
      "|    value_loss         | 0.0832        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 15600        |\n",
      "|    time_elapsed       | 253          |\n",
      "|    total_timesteps    | 78000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.48        |\n",
      "|    explained_variance | 0.216        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 15599        |\n",
      "|    policy_loss        | 0.661        |\n",
      "|    reward             | 0.0053362427 |\n",
      "|    std                | 10.1         |\n",
      "|    value_loss         | 0.0713       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 15700        |\n",
      "|    time_elapsed       | 255          |\n",
      "|    total_timesteps    | 78500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.48        |\n",
      "|    explained_variance | 0.194        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 15699        |\n",
      "|    policy_loss        | -0.0455      |\n",
      "|    reward             | -0.012598932 |\n",
      "|    std                | 10.2         |\n",
      "|    value_loss         | 0.000115     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 15800       |\n",
      "|    time_elapsed       | 257         |\n",
      "|    total_timesteps    | 79000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.51       |\n",
      "|    explained_variance | 0.391       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15799       |\n",
      "|    policy_loss        | -0.00318    |\n",
      "|    reward             | 0.007838897 |\n",
      "|    std                | 10.3        |\n",
      "|    value_loss         | 6.37e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 15900       |\n",
      "|    time_elapsed       | 258         |\n",
      "|    total_timesteps    | 79500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.55       |\n",
      "|    explained_variance | 0.33        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 15899       |\n",
      "|    policy_loss        | -0.777      |\n",
      "|    reward             | -0.08434344 |\n",
      "|    std                | 10.5        |\n",
      "|    value_loss         | 0.0134      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 16000      |\n",
      "|    time_elapsed       | 260        |\n",
      "|    total_timesteps    | 80000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.56      |\n",
      "|    explained_variance | 0.478      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 15999      |\n",
      "|    policy_loss        | 0.138      |\n",
      "|    reward             | -0.0467901 |\n",
      "|    std                | 10.6       |\n",
      "|    value_loss         | 0.00116    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 16100        |\n",
      "|    time_elapsed       | 261          |\n",
      "|    total_timesteps    | 80500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.57        |\n",
      "|    explained_variance | 0.0361       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 16099        |\n",
      "|    policy_loss        | 0.87         |\n",
      "|    reward             | -0.044529982 |\n",
      "|    std                | 10.7         |\n",
      "|    value_loss         | 0.0166       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 16200       |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 81000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.59       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16199       |\n",
      "|    policy_loss        | -0.16       |\n",
      "|    reward             | -0.11432113 |\n",
      "|    std                | 10.8        |\n",
      "|    value_loss         | 0.00157     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 16300       |\n",
      "|    time_elapsed       | 264         |\n",
      "|    total_timesteps    | 81500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.61       |\n",
      "|    explained_variance | 0.632       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16299       |\n",
      "|    policy_loss        | -0.329      |\n",
      "|    reward             | -0.03264748 |\n",
      "|    std                | 10.9        |\n",
      "|    value_loss         | 0.00191     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 16400       |\n",
      "|    time_elapsed       | 266         |\n",
      "|    total_timesteps    | 82000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.65       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16399       |\n",
      "|    policy_loss        | 0.0724      |\n",
      "|    reward             | 0.015707357 |\n",
      "|    std                | 11.1        |\n",
      "|    value_loss         | 7.55e-05    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 307       |\n",
      "|    iterations         | 16500     |\n",
      "|    time_elapsed       | 268       |\n",
      "|    total_timesteps    | 82500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.68     |\n",
      "|    explained_variance | 0.0165    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 16499     |\n",
      "|    policy_loss        | -0.796    |\n",
      "|    reward             | 0.1573269 |\n",
      "|    std                | 11.3      |\n",
      "|    value_loss         | 0.0187    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 16600      |\n",
      "|    time_elapsed       | 269        |\n",
      "|    total_timesteps    | 83000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.67      |\n",
      "|    explained_variance | 0.207      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 16599      |\n",
      "|    policy_loss        | -0.902     |\n",
      "|    reward             | -0.1266682 |\n",
      "|    std                | 11.2       |\n",
      "|    value_loss         | 0.0138     |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 271      |\n",
      "|    total_timesteps    | 83500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.7     |\n",
      "|    explained_variance | 0.0053   |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | -0.497   |\n",
      "|    reward             | -0.11544 |\n",
      "|    std                | 11.4     |\n",
      "|    value_loss         | 0.0184   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 308       |\n",
      "|    iterations         | 16800     |\n",
      "|    time_elapsed       | 272       |\n",
      "|    total_timesteps    | 84000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.7      |\n",
      "|    explained_variance | 0.137     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 16799     |\n",
      "|    policy_loss        | -0.412    |\n",
      "|    reward             | 0.2862465 |\n",
      "|    std                | 11.3      |\n",
      "|    value_loss         | 0.00771   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 16900       |\n",
      "|    time_elapsed       | 274         |\n",
      "|    total_timesteps    | 84500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.7        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 16899       |\n",
      "|    policy_loss        | 0.284       |\n",
      "|    reward             | 0.021577388 |\n",
      "|    std                | 11.4        |\n",
      "|    value_loss         | 0.00216     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 17000        |\n",
      "|    time_elapsed       | 276          |\n",
      "|    total_timesteps    | 85000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.72        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 16999        |\n",
      "|    policy_loss        | 1.11         |\n",
      "|    reward             | -0.013517068 |\n",
      "|    std                | 11.5         |\n",
      "|    value_loss         | 0.0218       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 17100      |\n",
      "|    time_elapsed       | 277        |\n",
      "|    total_timesteps    | 85500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.76      |\n",
      "|    explained_variance | -0.00594   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 17099      |\n",
      "|    policy_loss        | 1.53       |\n",
      "|    reward             | 0.04416794 |\n",
      "|    std                | 11.7       |\n",
      "|    value_loss         | 0.058      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 17200       |\n",
      "|    time_elapsed       | 279         |\n",
      "|    total_timesteps    | 86000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.77       |\n",
      "|    explained_variance | 0.186       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17199       |\n",
      "|    policy_loss        | 2.99        |\n",
      "|    reward             | 0.038638726 |\n",
      "|    std                | 11.8        |\n",
      "|    value_loss         | 0.215       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 17300      |\n",
      "|    time_elapsed       | 281        |\n",
      "|    total_timesteps    | 86500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.77      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 17299      |\n",
      "|    policy_loss        | 1.81       |\n",
      "|    reward             | 0.28653333 |\n",
      "|    std                | 11.8       |\n",
      "|    value_loss         | 0.0757     |\n",
      "--------------------------------------\n",
      "day: 2896, episode: 30\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 302938.13\n",
      "total_reward: 292938.13\n",
      "total_cost: 61.20\n",
      "total_trades: 5765\n",
      "Sharpe: 1.017\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 17400         |\n",
      "|    time_elapsed       | 282           |\n",
      "|    total_timesteps    | 87000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.79         |\n",
      "|    explained_variance | -0.61         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 17399         |\n",
      "|    policy_loss        | -0.481        |\n",
      "|    reward             | -0.0073529906 |\n",
      "|    std                | 11.9          |\n",
      "|    value_loss         | 0.00401       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 17500        |\n",
      "|    time_elapsed       | 284          |\n",
      "|    total_timesteps    | 87500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.8         |\n",
      "|    explained_variance | 0.0224       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 17499        |\n",
      "|    policy_loss        | -0.0138      |\n",
      "|    reward             | -0.002896938 |\n",
      "|    std                | 11.9         |\n",
      "|    value_loss         | 0.000171     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 17600        |\n",
      "|    time_elapsed       | 286          |\n",
      "|    total_timesteps    | 88000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.82        |\n",
      "|    explained_variance | -0.105       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 17599        |\n",
      "|    policy_loss        | 0.346        |\n",
      "|    reward             | -0.014698944 |\n",
      "|    std                | 12.1         |\n",
      "|    value_loss         | 0.00256      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 17700       |\n",
      "|    time_elapsed       | 287         |\n",
      "|    total_timesteps    | 88500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.87       |\n",
      "|    explained_variance | -0.0045     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17699       |\n",
      "|    policy_loss        | 0.0372      |\n",
      "|    reward             | 0.045364697 |\n",
      "|    std                | 12.4        |\n",
      "|    value_loss         | 0.000467    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 17800         |\n",
      "|    time_elapsed       | 289           |\n",
      "|    total_timesteps    | 89000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.88         |\n",
      "|    explained_variance | 0.136         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 17799         |\n",
      "|    policy_loss        | -3.48         |\n",
      "|    reward             | -0.0018204765 |\n",
      "|    std                | 12.5          |\n",
      "|    value_loss         | 0.239         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 17900       |\n",
      "|    time_elapsed       | 291         |\n",
      "|    total_timesteps    | 89500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.87       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 17899       |\n",
      "|    policy_loss        | 0.381       |\n",
      "|    reward             | -0.03212299 |\n",
      "|    std                | 12.4        |\n",
      "|    value_loss         | 0.00339     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 18000         |\n",
      "|    time_elapsed       | 292           |\n",
      "|    total_timesteps    | 90000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.88         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 17999         |\n",
      "|    policy_loss        | 0.0369        |\n",
      "|    reward             | -0.0012267563 |\n",
      "|    std                | 12.5          |\n",
      "|    value_loss         | 0.000109      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 18100       |\n",
      "|    time_elapsed       | 294         |\n",
      "|    total_timesteps    | 90500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.91       |\n",
      "|    explained_variance | 0.502       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18099       |\n",
      "|    policy_loss        | -0.014      |\n",
      "|    reward             | 0.037035733 |\n",
      "|    std                | 12.7        |\n",
      "|    value_loss         | 4.17e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 18200        |\n",
      "|    time_elapsed       | 296          |\n",
      "|    total_timesteps    | 91000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.95        |\n",
      "|    explained_variance | 0.0229       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 18199        |\n",
      "|    policy_loss        | 0.773        |\n",
      "|    reward             | 0.0005336872 |\n",
      "|    std                | 12.9         |\n",
      "|    value_loss         | 0.0107       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 18300       |\n",
      "|    time_elapsed       | 297         |\n",
      "|    total_timesteps    | 91500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.98       |\n",
      "|    explained_variance | 0.149       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18299       |\n",
      "|    policy_loss        | 1.57        |\n",
      "|    reward             | 0.064357094 |\n",
      "|    std                | 13.1        |\n",
      "|    value_loss         | 0.0696      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 18400       |\n",
      "|    time_elapsed       | 299         |\n",
      "|    total_timesteps    | 92000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8          |\n",
      "|    explained_variance | 0.137       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18399       |\n",
      "|    policy_loss        | 1.21        |\n",
      "|    reward             | -0.04744097 |\n",
      "|    std                | 13.2        |\n",
      "|    value_loss         | 0.0596      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 18500       |\n",
      "|    time_elapsed       | 301         |\n",
      "|    total_timesteps    | 92500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.99       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18499       |\n",
      "|    policy_loss        | -0.271      |\n",
      "|    reward             | -0.19392015 |\n",
      "|    std                | 13.2        |\n",
      "|    value_loss         | 0.0387      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 18600      |\n",
      "|    time_elapsed       | 302        |\n",
      "|    total_timesteps    | 93000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.03      |\n",
      "|    explained_variance | 0.365      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 18599      |\n",
      "|    policy_loss        | 0.191      |\n",
      "|    reward             | 0.00418638 |\n",
      "|    std                | 13.4       |\n",
      "|    value_loss         | 0.00136    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 18700         |\n",
      "|    time_elapsed       | 304           |\n",
      "|    total_timesteps    | 93500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.05         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 18699         |\n",
      "|    policy_loss        | -0.0813       |\n",
      "|    reward             | -0.0047242725 |\n",
      "|    std                | 13.5          |\n",
      "|    value_loss         | 0.000209      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 18800      |\n",
      "|    time_elapsed       | 305        |\n",
      "|    total_timesteps    | 94000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.09      |\n",
      "|    explained_variance | -7.31e-05  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 18799      |\n",
      "|    policy_loss        | 0.499      |\n",
      "|    reward             | 0.22893004 |\n",
      "|    std                | 13.9       |\n",
      "|    value_loss         | 0.00686    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 18900       |\n",
      "|    time_elapsed       | 307         |\n",
      "|    total_timesteps    | 94500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.09       |\n",
      "|    explained_variance | 2.38e-06    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18899       |\n",
      "|    policy_loss        | 1.23        |\n",
      "|    reward             | -0.07908678 |\n",
      "|    std                | 13.8        |\n",
      "|    value_loss         | 0.0242      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 19000       |\n",
      "|    time_elapsed       | 308         |\n",
      "|    total_timesteps    | 95000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.1        |\n",
      "|    explained_variance | 4.17e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 18999       |\n",
      "|    policy_loss        | -1.67       |\n",
      "|    reward             | -0.16120258 |\n",
      "|    std                | 13.9        |\n",
      "|    value_loss         | 0.0589      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 19100       |\n",
      "|    time_elapsed       | 310         |\n",
      "|    total_timesteps    | 95500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.13       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19099       |\n",
      "|    policy_loss        | -3.71       |\n",
      "|    reward             | 0.101864435 |\n",
      "|    std                | 14.1        |\n",
      "|    value_loss         | 0.267       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 19200         |\n",
      "|    time_elapsed       | 312           |\n",
      "|    total_timesteps    | 96000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.14         |\n",
      "|    explained_variance | 0.347         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 19199         |\n",
      "|    policy_loss        | -0.556        |\n",
      "|    reward             | -0.0026666173 |\n",
      "|    std                | 14.1          |\n",
      "|    value_loss         | 0.005         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 19300       |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 96500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.16       |\n",
      "|    explained_variance | -0.182      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19299       |\n",
      "|    policy_loss        | 0.4         |\n",
      "|    reward             | 0.005155872 |\n",
      "|    std                | 14.3        |\n",
      "|    value_loss         | 0.00243     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 19400       |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 97000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.17       |\n",
      "|    explained_variance | 0.159       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19399       |\n",
      "|    policy_loss        | -0.0682     |\n",
      "|    reward             | 0.015528763 |\n",
      "|    std                | 14.4        |\n",
      "|    value_loss         | 0.00223     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 19500       |\n",
      "|    time_elapsed       | 317         |\n",
      "|    total_timesteps    | 97500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.2        |\n",
      "|    explained_variance | 0.554       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19499       |\n",
      "|    policy_loss        | 0.587       |\n",
      "|    reward             | -0.03660578 |\n",
      "|    std                | 14.6        |\n",
      "|    value_loss         | 0.00718     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 19600      |\n",
      "|    time_elapsed       | 319        |\n",
      "|    total_timesteps    | 98000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.22      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 19599      |\n",
      "|    policy_loss        | 1.61       |\n",
      "|    reward             | 0.20106868 |\n",
      "|    std                | 14.7       |\n",
      "|    value_loss         | 0.0442     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 19700        |\n",
      "|    time_elapsed       | 320          |\n",
      "|    total_timesteps    | 98500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.21        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 19699        |\n",
      "|    policy_loss        | -3.91        |\n",
      "|    reward             | 0.0029451463 |\n",
      "|    std                | 14.7         |\n",
      "|    value_loss         | 0.257        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 19800       |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 99000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.23       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19799       |\n",
      "|    policy_loss        | 0.025       |\n",
      "|    reward             | -0.03546417 |\n",
      "|    std                | 14.8        |\n",
      "|    value_loss         | 0.00015     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 19900       |\n",
      "|    time_elapsed       | 323         |\n",
      "|    total_timesteps    | 99500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.27       |\n",
      "|    explained_variance | 0.00957     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 19899       |\n",
      "|    policy_loss        | -0.0664     |\n",
      "|    reward             | -0.02594582 |\n",
      "|    std                | 15.1        |\n",
      "|    value_loss         | 0.000434    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 20000        |\n",
      "|    time_elapsed       | 325          |\n",
      "|    total_timesteps    | 100000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.31        |\n",
      "|    explained_variance | -0.235       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 19999        |\n",
      "|    policy_loss        | 0.86         |\n",
      "|    reward             | -0.004359317 |\n",
      "|    std                | 15.4         |\n",
      "|    value_loss         | 0.0163       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 20100      |\n",
      "|    time_elapsed       | 327        |\n",
      "|    total_timesteps    | 100500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.33      |\n",
      "|    explained_variance | 0.298      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 20099      |\n",
      "|    policy_loss        | 0.00127    |\n",
      "|    reward             | 0.17333508 |\n",
      "|    std                | 15.6       |\n",
      "|    value_loss         | 0.00309    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 20200       |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 101000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.34       |\n",
      "|    explained_variance | -0.0798     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20199       |\n",
      "|    policy_loss        | 2.69        |\n",
      "|    reward             | -0.53273916 |\n",
      "|    std                | 15.7        |\n",
      "|    value_loss         | 0.129       |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 35\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 172408.34\n",
      "total_reward: 162408.34\n",
      "total_cost: 21.86\n",
      "total_trades: 5784\n",
      "Sharpe: 0.972\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 20300         |\n",
      "|    time_elapsed       | 330           |\n",
      "|    total_timesteps    | 101500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.36         |\n",
      "|    explained_variance | -16.2         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 20299         |\n",
      "|    policy_loss        | -0.168        |\n",
      "|    reward             | 9.8838806e-05 |\n",
      "|    std                | 15.8          |\n",
      "|    value_loss         | 0.00187       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 20400         |\n",
      "|    time_elapsed       | 331           |\n",
      "|    total_timesteps    | 102000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.38         |\n",
      "|    explained_variance | -0.164        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 20399         |\n",
      "|    policy_loss        | -0.156        |\n",
      "|    reward             | -0.0054693106 |\n",
      "|    std                | 16            |\n",
      "|    value_loss         | 0.000404      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 20500         |\n",
      "|    time_elapsed       | 333           |\n",
      "|    total_timesteps    | 102500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.41         |\n",
      "|    explained_variance | 0.517         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 20499         |\n",
      "|    policy_loss        | 0.114         |\n",
      "|    reward             | -0.0021297685 |\n",
      "|    std                | 16.2          |\n",
      "|    value_loss         | 0.000219      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 20600      |\n",
      "|    time_elapsed       | 335        |\n",
      "|    total_timesteps    | 103000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.45      |\n",
      "|    explained_variance | 0.22       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 20599      |\n",
      "|    policy_loss        | 0.428      |\n",
      "|    reward             | -0.0396984 |\n",
      "|    std                | 16.6       |\n",
      "|    value_loss         | 0.00318    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 20700        |\n",
      "|    time_elapsed       | 336          |\n",
      "|    total_timesteps    | 103500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.46        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 20699        |\n",
      "|    policy_loss        | -0.347       |\n",
      "|    reward             | -0.058843512 |\n",
      "|    std                | 16.7         |\n",
      "|    value_loss         | 0.00381      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 20800         |\n",
      "|    time_elapsed       | 338           |\n",
      "|    total_timesteps    | 104000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.49         |\n",
      "|    explained_variance | 0.543         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 20799         |\n",
      "|    policy_loss        | 0.25          |\n",
      "|    reward             | -0.0069641876 |\n",
      "|    std                | 16.9          |\n",
      "|    value_loss         | 0.00162       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 20900       |\n",
      "|    time_elapsed       | 340         |\n",
      "|    total_timesteps    | 104500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.53       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 20899       |\n",
      "|    policy_loss        | -0.0446     |\n",
      "|    reward             | 0.013452117 |\n",
      "|    std                | 17.2        |\n",
      "|    value_loss         | 0.000112    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 21000         |\n",
      "|    time_elapsed       | 341           |\n",
      "|    total_timesteps    | 105000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.58         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 20999         |\n",
      "|    policy_loss        | 0.0653        |\n",
      "|    reward             | -0.0046144305 |\n",
      "|    std                | 17.7          |\n",
      "|    value_loss         | 0.000122      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 21100      |\n",
      "|    time_elapsed       | 343        |\n",
      "|    total_timesteps    | 105500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.64      |\n",
      "|    explained_variance | -0.0855    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 21099      |\n",
      "|    policy_loss        | 0.257      |\n",
      "|    reward             | 0.01302191 |\n",
      "|    std                | 18.3       |\n",
      "|    value_loss         | 0.00347    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 21200        |\n",
      "|    time_elapsed       | 344          |\n",
      "|    total_timesteps    | 106000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.65        |\n",
      "|    explained_variance | -0.0706      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 21199        |\n",
      "|    policy_loss        | -0.615       |\n",
      "|    reward             | -0.017649388 |\n",
      "|    std                | 18.3         |\n",
      "|    value_loss         | 0.00619      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 307       |\n",
      "|    iterations         | 21300     |\n",
      "|    time_elapsed       | 345       |\n",
      "|    total_timesteps    | 106500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.66     |\n",
      "|    explained_variance | 0.0989    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 21299     |\n",
      "|    policy_loss        | 0.615     |\n",
      "|    reward             | 0.1946931 |\n",
      "|    std                | 18.4      |\n",
      "|    value_loss         | 0.0243    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 21400       |\n",
      "|    time_elapsed       | 347         |\n",
      "|    total_timesteps    | 107000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.66       |\n",
      "|    explained_variance | 0.0302      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21399       |\n",
      "|    policy_loss        | 0.19        |\n",
      "|    reward             | -0.23470618 |\n",
      "|    std                | 18.4        |\n",
      "|    value_loss         | 0.00807     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 21500        |\n",
      "|    time_elapsed       | 349          |\n",
      "|    total_timesteps    | 107500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.68        |\n",
      "|    explained_variance | 0.578        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 21499        |\n",
      "|    policy_loss        | -0.178       |\n",
      "|    reward             | -0.011151454 |\n",
      "|    std                | 18.6         |\n",
      "|    value_loss         | 0.000425     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 21600       |\n",
      "|    time_elapsed       | 350         |\n",
      "|    total_timesteps    | 108000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.7        |\n",
      "|    explained_variance | -0.121      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21599       |\n",
      "|    policy_loss        | 0.0477      |\n",
      "|    reward             | 0.009726259 |\n",
      "|    std                | 18.8        |\n",
      "|    value_loss         | 0.000161    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 21700        |\n",
      "|    time_elapsed       | 352          |\n",
      "|    total_timesteps    | 108500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.73        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 21699        |\n",
      "|    policy_loss        | 0.0742       |\n",
      "|    reward             | -0.014492497 |\n",
      "|    std                | 19.1         |\n",
      "|    value_loss         | 0.00121      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 21800        |\n",
      "|    time_elapsed       | 354          |\n",
      "|    total_timesteps    | 109000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.79        |\n",
      "|    explained_variance | 0.241        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 21799        |\n",
      "|    policy_loss        | 1.2          |\n",
      "|    reward             | -0.012019853 |\n",
      "|    std                | 19.6         |\n",
      "|    value_loss         | 0.02         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 21900       |\n",
      "|    time_elapsed       | 355         |\n",
      "|    total_timesteps    | 109500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.84       |\n",
      "|    explained_variance | 0.085       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 21899       |\n",
      "|    policy_loss        | -0.772      |\n",
      "|    reward             | 0.035554897 |\n",
      "|    std                | 20.1        |\n",
      "|    value_loss         | 0.0085      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 22000      |\n",
      "|    time_elapsed       | 357        |\n",
      "|    total_timesteps    | 110000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.87      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 21999      |\n",
      "|    policy_loss        | 1.51       |\n",
      "|    reward             | 0.07995687 |\n",
      "|    std                | 20.4       |\n",
      "|    value_loss         | 0.0505     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 22100        |\n",
      "|    time_elapsed       | 359          |\n",
      "|    total_timesteps    | 110500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.88        |\n",
      "|    explained_variance | -0.181       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 22099        |\n",
      "|    policy_loss        | 0.0413       |\n",
      "|    reward             | -0.017126022 |\n",
      "|    std                | 20.5         |\n",
      "|    value_loss         | 0.000141     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 22200       |\n",
      "|    time_elapsed       | 360         |\n",
      "|    total_timesteps    | 111000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.91       |\n",
      "|    explained_variance | 0.521       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22199       |\n",
      "|    policy_loss        | -0.0185     |\n",
      "|    reward             | 0.030527554 |\n",
      "|    std                | 20.9        |\n",
      "|    value_loss         | 4e-05       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 22300         |\n",
      "|    time_elapsed       | 362           |\n",
      "|    total_timesteps    | 111500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.97         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 22299         |\n",
      "|    policy_loss        | 0.0735        |\n",
      "|    reward             | 0.00017379837 |\n",
      "|    std                | 21.4          |\n",
      "|    value_loss         | 0.00101       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 22400       |\n",
      "|    time_elapsed       | 363         |\n",
      "|    total_timesteps    | 112000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.98       |\n",
      "|    explained_variance | 0.0579      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22399       |\n",
      "|    policy_loss        | 1.27        |\n",
      "|    reward             | 0.051660545 |\n",
      "|    std                | 21.5        |\n",
      "|    value_loss         | 0.0251      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 22500       |\n",
      "|    time_elapsed       | 365         |\n",
      "|    total_timesteps    | 112500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.98       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22499       |\n",
      "|    policy_loss        | 0.355       |\n",
      "|    reward             | 0.058246907 |\n",
      "|    std                | 21.6        |\n",
      "|    value_loss         | 0.00533     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 22600        |\n",
      "|    time_elapsed       | 367          |\n",
      "|    total_timesteps    | 113000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.99        |\n",
      "|    explained_variance | -18.2        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 22599        |\n",
      "|    policy_loss        | 0.0396       |\n",
      "|    reward             | -0.015946217 |\n",
      "|    std                | 21.7         |\n",
      "|    value_loss         | 0.00134      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 22700        |\n",
      "|    time_elapsed       | 368          |\n",
      "|    total_timesteps    | 113500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.01        |\n",
      "|    explained_variance | 0.579        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 22699        |\n",
      "|    policy_loss        | 0.135        |\n",
      "|    reward             | -0.029917547 |\n",
      "|    std                | 21.9         |\n",
      "|    value_loss         | 0.000256     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 22800      |\n",
      "|    time_elapsed       | 370        |\n",
      "|    total_timesteps    | 114000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.06      |\n",
      "|    explained_variance | 0.399      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 22799      |\n",
      "|    policy_loss        | -0.0627    |\n",
      "|    reward             | 0.00982581 |\n",
      "|    std                | 22.5       |\n",
      "|    value_loss         | 0.00102    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 22900         |\n",
      "|    time_elapsed       | 371           |\n",
      "|    total_timesteps    | 114500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -9.09         |\n",
      "|    explained_variance | 0.0165        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 22899         |\n",
      "|    policy_loss        | -0.331        |\n",
      "|    reward             | 0.00035965728 |\n",
      "|    std                | 22.8          |\n",
      "|    value_loss         | 0.00182       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 23000       |\n",
      "|    time_elapsed       | 373         |\n",
      "|    total_timesteps    | 115000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.14       |\n",
      "|    explained_variance | 0.532       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 22999       |\n",
      "|    policy_loss        | -0.78       |\n",
      "|    reward             | -0.14830223 |\n",
      "|    std                | 23.4        |\n",
      "|    value_loss         | 0.0101      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 23100       |\n",
      "|    time_elapsed       | 375         |\n",
      "|    total_timesteps    | 115500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.19       |\n",
      "|    explained_variance | 0.042       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 23099       |\n",
      "|    policy_loss        | 4.64        |\n",
      "|    reward             | -0.28005853 |\n",
      "|    std                | 23.9        |\n",
      "|    value_loss         | 0.332       |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 40\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 112148.21\n",
      "total_reward: 102148.21\n",
      "total_cost: 20.15\n",
      "total_trades: 5788\n",
      "Sharpe: 0.796\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 23200         |\n",
      "|    time_elapsed       | 377           |\n",
      "|    total_timesteps    | 116000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -9.21         |\n",
      "|    explained_variance | -0.639        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 23199         |\n",
      "|    policy_loss        | -0.116        |\n",
      "|    reward             | -0.0030040806 |\n",
      "|    std                | 24.2          |\n",
      "|    value_loss         | 0.000293      |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 307       |\n",
      "|    iterations         | 23300     |\n",
      "|    time_elapsed       | 379       |\n",
      "|    total_timesteps    | 116500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.24     |\n",
      "|    explained_variance | 0.503     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 23299     |\n",
      "|    policy_loss        | 0.0809    |\n",
      "|    reward             | 0.0098135 |\n",
      "|    std                | 24.5      |\n",
      "|    value_loss         | 0.000129  |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 23400        |\n",
      "|    time_elapsed       | 380          |\n",
      "|    total_timesteps    | 117000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.28        |\n",
      "|    explained_variance | -0.0328      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23399        |\n",
      "|    policy_loss        | 0.635        |\n",
      "|    reward             | -0.010771391 |\n",
      "|    std                | 25           |\n",
      "|    value_loss         | 0.00839      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 23500       |\n",
      "|    time_elapsed       | 382         |\n",
      "|    total_timesteps    | 117500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.29       |\n",
      "|    explained_variance | 0.273       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 23499       |\n",
      "|    policy_loss        | -0.0462     |\n",
      "|    reward             | -0.03227331 |\n",
      "|    std                | 25.2        |\n",
      "|    value_loss         | 0.000222    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 23600       |\n",
      "|    time_elapsed       | 383         |\n",
      "|    total_timesteps    | 118000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.33       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 23599       |\n",
      "|    policy_loss        | 0.15        |\n",
      "|    reward             | 0.041957546 |\n",
      "|    std                | 25.8        |\n",
      "|    value_loss         | 0.00113     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 23700        |\n",
      "|    time_elapsed       | 385          |\n",
      "|    total_timesteps    | 118500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.35        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 23699        |\n",
      "|    policy_loss        | -0.416       |\n",
      "|    reward             | -0.012863092 |\n",
      "|    std                | 25.9         |\n",
      "|    value_loss         | 0.00231      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 23800         |\n",
      "|    time_elapsed       | 386           |\n",
      "|    total_timesteps    | 119000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -9.35         |\n",
      "|    explained_variance | -0.125        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 23799         |\n",
      "|    policy_loss        | 0.0398        |\n",
      "|    reward             | -0.0067473734 |\n",
      "|    std                | 25.9          |\n",
      "|    value_loss         | 0.000453      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 23900       |\n",
      "|    time_elapsed       | 388         |\n",
      "|    total_timesteps    | 119500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.37       |\n",
      "|    explained_variance | -0.223      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 23899       |\n",
      "|    policy_loss        | -0.155      |\n",
      "|    reward             | 0.004839527 |\n",
      "|    std                | 26.2        |\n",
      "|    value_loss         | 0.000329    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 24000      |\n",
      "|    time_elapsed       | 390        |\n",
      "|    total_timesteps    | 120000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.39      |\n",
      "|    explained_variance | 0.379      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 23999      |\n",
      "|    policy_loss        | -0.194     |\n",
      "|    reward             | 0.07557341 |\n",
      "|    std                | 26.4       |\n",
      "|    value_loss         | 0.000852   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 24100       |\n",
      "|    time_elapsed       | 391         |\n",
      "|    total_timesteps    | 120500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.43       |\n",
      "|    explained_variance | 0.29        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 24099       |\n",
      "|    policy_loss        | 1.17        |\n",
      "|    reward             | 0.036773358 |\n",
      "|    std                | 27          |\n",
      "|    value_loss         | 0.0218      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 24200        |\n",
      "|    time_elapsed       | 393          |\n",
      "|    total_timesteps    | 121000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.49        |\n",
      "|    explained_variance | 0.038        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 24199        |\n",
      "|    policy_loss        | 0.926        |\n",
      "|    reward             | -0.031507503 |\n",
      "|    std                | 27.9         |\n",
      "|    value_loss         | 0.0122       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 24300        |\n",
      "|    time_elapsed       | 394          |\n",
      "|    total_timesteps    | 121500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.49        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 24299        |\n",
      "|    policy_loss        | 1.37         |\n",
      "|    reward             | -0.036557775 |\n",
      "|    std                | 27.9         |\n",
      "|    value_loss         | 0.025        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 24400        |\n",
      "|    time_elapsed       | 396          |\n",
      "|    total_timesteps    | 122000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.51        |\n",
      "|    explained_variance | 0.177        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 24399        |\n",
      "|    policy_loss        | -0.223       |\n",
      "|    reward             | -0.009287823 |\n",
      "|    std                | 28.2         |\n",
      "|    value_loss         | 0.000655     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 24500       |\n",
      "|    time_elapsed       | 398         |\n",
      "|    total_timesteps    | 122500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.55       |\n",
      "|    explained_variance | 8.15e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 24499       |\n",
      "|    policy_loss        | -0.129      |\n",
      "|    reward             | -0.01189814 |\n",
      "|    std                | 28.7        |\n",
      "|    value_loss         | 0.000222    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 24600       |\n",
      "|    time_elapsed       | 399         |\n",
      "|    total_timesteps    | 123000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.57       |\n",
      "|    explained_variance | 0.544       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 24599       |\n",
      "|    policy_loss        | -0.104      |\n",
      "|    reward             | -0.04591049 |\n",
      "|    std                | 29          |\n",
      "|    value_loss         | 0.00123     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 24700        |\n",
      "|    time_elapsed       | 401          |\n",
      "|    total_timesteps    | 123500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.6         |\n",
      "|    explained_variance | -2.38e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 24699        |\n",
      "|    policy_loss        | -0.227       |\n",
      "|    reward             | -0.047060106 |\n",
      "|    std                | 29.4         |\n",
      "|    value_loss         | 0.00118      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 24800       |\n",
      "|    time_elapsed       | 403         |\n",
      "|    total_timesteps    | 124000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.61       |\n",
      "|    explained_variance | 0.105       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 24799       |\n",
      "|    policy_loss        | 0.442       |\n",
      "|    reward             | 0.036583573 |\n",
      "|    std                | 29.6        |\n",
      "|    value_loss         | 0.00925     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 307       |\n",
      "|    iterations         | 24900     |\n",
      "|    time_elapsed       | 404       |\n",
      "|    total_timesteps    | 124500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.64     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 24899     |\n",
      "|    policy_loss        | -0.925    |\n",
      "|    reward             | 0.0381089 |\n",
      "|    std                | 30        |\n",
      "|    value_loss         | 0.0132    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 25000        |\n",
      "|    time_elapsed       | 406          |\n",
      "|    total_timesteps    | 125000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.66        |\n",
      "|    explained_variance | -0.631       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 24999        |\n",
      "|    policy_loss        | -0.282       |\n",
      "|    reward             | -0.014556176 |\n",
      "|    std                | 30.4         |\n",
      "|    value_loss         | 0.00105      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 25100        |\n",
      "|    time_elapsed       | 407          |\n",
      "|    total_timesteps    | 125500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.7         |\n",
      "|    explained_variance | -0.604       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 25099        |\n",
      "|    policy_loss        | -0.0748      |\n",
      "|    reward             | 0.0020151646 |\n",
      "|    std                | 30.9         |\n",
      "|    value_loss         | 6.27e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 25200        |\n",
      "|    time_elapsed       | 409          |\n",
      "|    total_timesteps    | 126000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.74        |\n",
      "|    explained_variance | -0.787       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 25199        |\n",
      "|    policy_loss        | -0.301       |\n",
      "|    reward             | -0.009702906 |\n",
      "|    std                | 31.5         |\n",
      "|    value_loss         | 0.00103      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 25300      |\n",
      "|    time_elapsed       | 410        |\n",
      "|    total_timesteps    | 126500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.82      |\n",
      "|    explained_variance | 0.609      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 25299      |\n",
      "|    policy_loss        | 0.59       |\n",
      "|    reward             | 0.02142153 |\n",
      "|    std                | 32.8       |\n",
      "|    value_loss         | 0.00367    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 25400       |\n",
      "|    time_elapsed       | 412         |\n",
      "|    total_timesteps    | 127000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.88       |\n",
      "|    explained_variance | 0.000634    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25399       |\n",
      "|    policy_loss        | 0.121       |\n",
      "|    reward             | 0.011823206 |\n",
      "|    std                | 33.8        |\n",
      "|    value_loss         | 0.000161    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 25500        |\n",
      "|    time_elapsed       | 414          |\n",
      "|    total_timesteps    | 127500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.91        |\n",
      "|    explained_variance | -2.5         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 25499        |\n",
      "|    policy_loss        | 0.278        |\n",
      "|    reward             | -0.019793324 |\n",
      "|    std                | 34.4         |\n",
      "|    value_loss         | 0.00142      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 25600        |\n",
      "|    time_elapsed       | 415          |\n",
      "|    total_timesteps    | 128000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.95        |\n",
      "|    explained_variance | -1.66        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 25599        |\n",
      "|    policy_loss        | -0.256       |\n",
      "|    reward             | -0.004320223 |\n",
      "|    std                | 35.1         |\n",
      "|    value_loss         | 0.000645     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 25700       |\n",
      "|    time_elapsed       | 417         |\n",
      "|    total_timesteps    | 128500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10         |\n",
      "|    explained_variance | 0.386       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25699       |\n",
      "|    policy_loss        | -0.0943     |\n",
      "|    reward             | 0.021579407 |\n",
      "|    std                | 36.3        |\n",
      "|    value_loss         | 0.000943    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 25800       |\n",
      "|    time_elapsed       | 418         |\n",
      "|    total_timesteps    | 129000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.1       |\n",
      "|    explained_variance | 0.364       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 25799       |\n",
      "|    policy_loss        | -0.258      |\n",
      "|    reward             | -0.05580696 |\n",
      "|    std                | 37.2        |\n",
      "|    value_loss         | 0.00108     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 25900      |\n",
      "|    time_elapsed       | 420        |\n",
      "|    total_timesteps    | 129500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.1      |\n",
      "|    explained_variance | 2.99e-05   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 25899      |\n",
      "|    policy_loss        | -1.84      |\n",
      "|    reward             | 0.04360548 |\n",
      "|    std                | 37.9       |\n",
      "|    value_loss         | 0.0353     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 26000        |\n",
      "|    time_elapsed       | 422          |\n",
      "|    total_timesteps    | 130000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.1        |\n",
      "|    explained_variance | -0.000566    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 25999        |\n",
      "|    policy_loss        | -0.349       |\n",
      "|    reward             | -0.022034224 |\n",
      "|    std                | 38.3         |\n",
      "|    value_loss         | 0.0101       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2896, episode: 45\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 119200.97\n",
      "total_reward: 109200.97\n",
      "total_cost: 10.83\n",
      "total_trades: 5790\n",
      "Sharpe: 0.805\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 26100        |\n",
      "|    time_elapsed       | 424          |\n",
      "|    total_timesteps    | 130500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.2        |\n",
      "|    explained_variance | -3.35        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26099        |\n",
      "|    policy_loss        | 0.00413      |\n",
      "|    reward             | 0.0035589582 |\n",
      "|    std                | 39           |\n",
      "|    value_loss         | 0.000147     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 26200         |\n",
      "|    time_elapsed       | 425           |\n",
      "|    total_timesteps    | 131000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.2         |\n",
      "|    explained_variance | 0.803         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 26199         |\n",
      "|    policy_loss        | -0.0671       |\n",
      "|    reward             | -0.0017761132 |\n",
      "|    std                | 39.5          |\n",
      "|    value_loss         | 9.65e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 26300       |\n",
      "|    time_elapsed       | 427         |\n",
      "|    total_timesteps    | 131500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.2       |\n",
      "|    explained_variance | 0.401       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 26299       |\n",
      "|    policy_loss        | -0.116      |\n",
      "|    reward             | 0.011412377 |\n",
      "|    std                | 40.5        |\n",
      "|    value_loss         | 0.000467    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 26400        |\n",
      "|    time_elapsed       | 428          |\n",
      "|    total_timesteps    | 132000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.3        |\n",
      "|    explained_variance | 0.0919       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26399        |\n",
      "|    policy_loss        | -0.19        |\n",
      "|    reward             | 0.0014551254 |\n",
      "|    std                | 41.1         |\n",
      "|    value_loss         | 0.00121      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 26500       |\n",
      "|    time_elapsed       | 430         |\n",
      "|    total_timesteps    | 132500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.3       |\n",
      "|    explained_variance | 0.189       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 26499       |\n",
      "|    policy_loss        | -0.225      |\n",
      "|    reward             | 0.018727493 |\n",
      "|    std                | 41.5        |\n",
      "|    value_loss         | 0.00483     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 26600       |\n",
      "|    time_elapsed       | 432         |\n",
      "|    total_timesteps    | 133000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.3       |\n",
      "|    explained_variance | -0.0747     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 26599       |\n",
      "|    policy_loss        | 0.443       |\n",
      "|    reward             | -0.12967987 |\n",
      "|    std                | 42.1        |\n",
      "|    value_loss         | 0.0124      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 26700        |\n",
      "|    time_elapsed       | 434          |\n",
      "|    total_timesteps    | 133500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.3        |\n",
      "|    explained_variance | 0.166        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26699        |\n",
      "|    policy_loss        | -0.0375      |\n",
      "|    reward             | 0.0039677704 |\n",
      "|    std                | 42.7         |\n",
      "|    value_loss         | 0.000118     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 26800        |\n",
      "|    time_elapsed       | 435          |\n",
      "|    total_timesteps    | 134000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.4        |\n",
      "|    explained_variance | -3.66        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26799        |\n",
      "|    policy_loss        | -0.0058      |\n",
      "|    reward             | 0.0003844818 |\n",
      "|    std                | 43.2         |\n",
      "|    value_loss         | 9.3e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 26900        |\n",
      "|    time_elapsed       | 437          |\n",
      "|    total_timesteps    | 134500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.4        |\n",
      "|    explained_variance | 0.958        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 26899        |\n",
      "|    policy_loss        | -0.0138      |\n",
      "|    reward             | 0.0047540176 |\n",
      "|    std                | 44.1         |\n",
      "|    value_loss         | 3.88e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 27000       |\n",
      "|    time_elapsed       | 439         |\n",
      "|    total_timesteps    | 135000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 26999       |\n",
      "|    policy_loss        | 0.22        |\n",
      "|    reward             | 0.017013036 |\n",
      "|    std                | 45.3        |\n",
      "|    value_loss         | 0.00047     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 27100        |\n",
      "|    time_elapsed       | 441          |\n",
      "|    total_timesteps    | 135500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.5        |\n",
      "|    explained_variance | 0.00161      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27099        |\n",
      "|    policy_loss        | 0.384        |\n",
      "|    reward             | -0.024109391 |\n",
      "|    std                | 46.6         |\n",
      "|    value_loss         | 0.00215      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 27200        |\n",
      "|    time_elapsed       | 442          |\n",
      "|    total_timesteps    | 136000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27199        |\n",
      "|    policy_loss        | 0.0963       |\n",
      "|    reward             | -0.027171036 |\n",
      "|    std                | 47.4         |\n",
      "|    value_loss         | 0.00144      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 27300        |\n",
      "|    time_elapsed       | 444          |\n",
      "|    total_timesteps    | 136500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.6        |\n",
      "|    explained_variance | 0.00316      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27299        |\n",
      "|    policy_loss        | -0.542       |\n",
      "|    reward             | -0.060828917 |\n",
      "|    std                | 47.4         |\n",
      "|    value_loss         | 0.00409      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 27400        |\n",
      "|    time_elapsed       | 446          |\n",
      "|    total_timesteps    | 137000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.6        |\n",
      "|    explained_variance | 0.279        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27399        |\n",
      "|    policy_loss        | -0.232       |\n",
      "|    reward             | -0.013782226 |\n",
      "|    std                | 48.6         |\n",
      "|    value_loss         | 0.000543     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 27500        |\n",
      "|    time_elapsed       | 447          |\n",
      "|    total_timesteps    | 137500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.6        |\n",
      "|    explained_variance | 0.0162       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27499        |\n",
      "|    policy_loss        | -0.611       |\n",
      "|    reward             | -0.028155258 |\n",
      "|    std                | 49.8         |\n",
      "|    value_loss         | 0.00745      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 27600      |\n",
      "|    time_elapsed       | 449        |\n",
      "|    total_timesteps    | 138000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.7      |\n",
      "|    explained_variance | -0.0524    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 27599      |\n",
      "|    policy_loss        | 1.14       |\n",
      "|    reward             | 0.03962607 |\n",
      "|    std                | 50.4       |\n",
      "|    value_loss         | 0.0192     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 307       |\n",
      "|    iterations         | 27700     |\n",
      "|    time_elapsed       | 451       |\n",
      "|    total_timesteps    | 138500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -10.7     |\n",
      "|    explained_variance | -0.00195  |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 27699     |\n",
      "|    policy_loss        | 3.79      |\n",
      "|    reward             | 0.2068182 |\n",
      "|    std                | 49.9      |\n",
      "|    value_loss         | 0.132     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 27800      |\n",
      "|    time_elapsed       | 452        |\n",
      "|    total_timesteps    | 139000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.7      |\n",
      "|    explained_variance | -1.35e-05  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 27799      |\n",
      "|    policy_loss        | -1.02      |\n",
      "|    reward             | -0.1547487 |\n",
      "|    std                | 50.2       |\n",
      "|    value_loss         | 0.0239     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 27900        |\n",
      "|    time_elapsed       | 454          |\n",
      "|    total_timesteps    | 139500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.7        |\n",
      "|    explained_variance | 0.263        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 27899        |\n",
      "|    policy_loss        | 0.24         |\n",
      "|    reward             | -0.015684646 |\n",
      "|    std                | 50.6         |\n",
      "|    value_loss         | 0.00109      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 28000       |\n",
      "|    time_elapsed       | 456         |\n",
      "|    total_timesteps    | 140000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.7       |\n",
      "|    explained_variance | -0.135      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 27999       |\n",
      "|    policy_loss        | -0.00832    |\n",
      "|    reward             | 0.002033077 |\n",
      "|    std                | 51.3        |\n",
      "|    value_loss         | 0.00164     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 28100        |\n",
      "|    time_elapsed       | 457          |\n",
      "|    total_timesteps    | 140500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.7        |\n",
      "|    explained_variance | -0.151       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28099        |\n",
      "|    policy_loss        | -0.997       |\n",
      "|    reward             | 0.0040507256 |\n",
      "|    std                | 51.4         |\n",
      "|    value_loss         | 0.0121       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 28200        |\n",
      "|    time_elapsed       | 459          |\n",
      "|    total_timesteps    | 141000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.7        |\n",
      "|    explained_variance | -0.000317    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 28199        |\n",
      "|    policy_loss        | -0.922       |\n",
      "|    reward             | -0.014784516 |\n",
      "|    std                | 51.6         |\n",
      "|    value_loss         | 0.00965      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 306       |\n",
      "|    iterations         | 28300     |\n",
      "|    time_elapsed       | 461       |\n",
      "|    total_timesteps    | 141500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -10.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 28299     |\n",
      "|    policy_loss        | 0.7       |\n",
      "|    reward             | 0.2210481 |\n",
      "|    std                | 51.8      |\n",
      "|    value_loss         | 0.012     |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 306           |\n",
      "|    iterations         | 28400         |\n",
      "|    time_elapsed       | 462           |\n",
      "|    total_timesteps    | 142000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.7         |\n",
      "|    explained_variance | -4.16         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 28399         |\n",
      "|    policy_loss        | -0.583        |\n",
      "|    reward             | -0.0015755858 |\n",
      "|    std                | 52.2          |\n",
      "|    value_loss         | 0.00418       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 28500       |\n",
      "|    time_elapsed       | 464         |\n",
      "|    total_timesteps    | 142500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.8       |\n",
      "|    explained_variance | 0.625       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 28499       |\n",
      "|    policy_loss        | -0.0502     |\n",
      "|    reward             | -0.02830572 |\n",
      "|    std                | 52.8        |\n",
      "|    value_loss         | 8.48e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 306           |\n",
      "|    iterations         | 28600         |\n",
      "|    time_elapsed       | 466           |\n",
      "|    total_timesteps    | 143000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.8         |\n",
      "|    explained_variance | 0.0432        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 28599         |\n",
      "|    policy_loss        | 0.00806       |\n",
      "|    reward             | -0.0011213471 |\n",
      "|    std                | 53.7          |\n",
      "|    value_loss         | 2.44e-05      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 28700       |\n",
      "|    time_elapsed       | 468         |\n",
      "|    total_timesteps    | 143500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.9       |\n",
      "|    explained_variance | -0.244      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 28699       |\n",
      "|    policy_loss        | -0.0162     |\n",
      "|    reward             | 0.032261718 |\n",
      "|    std                | 55.6        |\n",
      "|    value_loss         | 0.000277    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 28800       |\n",
      "|    time_elapsed       | 469         |\n",
      "|    total_timesteps    | 144000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.9       |\n",
      "|    explained_variance | 0.277       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 28799       |\n",
      "|    policy_loss        | 0.666       |\n",
      "|    reward             | -0.02716656 |\n",
      "|    std                | 56.3        |\n",
      "|    value_loss         | 0.00474     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 28900       |\n",
      "|    time_elapsed       | 471         |\n",
      "|    total_timesteps    | 144500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 28899       |\n",
      "|    policy_loss        | 0.5         |\n",
      "|    reward             | 0.044631645 |\n",
      "|    std                | 57.4        |\n",
      "|    value_loss         | 0.004       |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 50\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 62151.86\n",
      "total_reward: 52151.86\n",
      "total_cost: 11.39\n",
      "total_trades: 5791\n",
      "Sharpe: 0.668\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 29000       |\n",
      "|    time_elapsed       | 473         |\n",
      "|    total_timesteps    | 145000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11         |\n",
      "|    explained_variance | 1.11e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 28999       |\n",
      "|    policy_loss        | 0.041       |\n",
      "|    reward             | 0.008282969 |\n",
      "|    std                | 58          |\n",
      "|    value_loss         | 3.69e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 306           |\n",
      "|    iterations         | 29100         |\n",
      "|    time_elapsed       | 474           |\n",
      "|    total_timesteps    | 145500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11           |\n",
      "|    explained_variance | 0.803         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 29099         |\n",
      "|    policy_loss        | -0.29         |\n",
      "|    reward             | -0.0019235363 |\n",
      "|    std                | 58.8          |\n",
      "|    value_loss         | 0.000737      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 29200       |\n",
      "|    time_elapsed       | 476         |\n",
      "|    total_timesteps    | 146000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11         |\n",
      "|    explained_variance | -0.0146     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 29199       |\n",
      "|    policy_loss        | 0.559       |\n",
      "|    reward             | 0.013284484 |\n",
      "|    std                | 59.6        |\n",
      "|    value_loss         | 0.00308     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 29300        |\n",
      "|    time_elapsed       | 478          |\n",
      "|    total_timesteps    | 146500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11          |\n",
      "|    explained_variance | 0.0657       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29299        |\n",
      "|    policy_loss        | -1.11        |\n",
      "|    reward             | 0.0136060715 |\n",
      "|    std                | 59.7         |\n",
      "|    value_loss         | 0.0109       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 29400        |\n",
      "|    time_elapsed       | 479          |\n",
      "|    total_timesteps    | 147000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.1        |\n",
      "|    explained_variance | 0.208        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29399        |\n",
      "|    policy_loss        | -1.66        |\n",
      "|    reward             | -0.025583524 |\n",
      "|    std                | 61.3         |\n",
      "|    value_loss         | 0.0261       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 306        |\n",
      "|    iterations         | 29500      |\n",
      "|    time_elapsed       | 481        |\n",
      "|    total_timesteps    | 147500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.1      |\n",
      "|    explained_variance | 0.0567     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 29499      |\n",
      "|    policy_loss        | -1.59      |\n",
      "|    reward             | 0.10183161 |\n",
      "|    std                | 61.8       |\n",
      "|    value_loss         | 0.0269     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 29600       |\n",
      "|    time_elapsed       | 483         |\n",
      "|    total_timesteps    | 148000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 29599       |\n",
      "|    policy_loss        | -0.108      |\n",
      "|    reward             | 0.017812828 |\n",
      "|    std                | 62.3        |\n",
      "|    value_loss         | 0.000179    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 29700        |\n",
      "|    time_elapsed       | 484          |\n",
      "|    total_timesteps    | 148500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.1        |\n",
      "|    explained_variance | 0.000211     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29699        |\n",
      "|    policy_loss        | 0.0867       |\n",
      "|    reward             | -0.028007247 |\n",
      "|    std                | 63           |\n",
      "|    value_loss         | 0.000232     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 29800       |\n",
      "|    time_elapsed       | 486         |\n",
      "|    total_timesteps    | 149000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 29799       |\n",
      "|    policy_loss        | 1.53        |\n",
      "|    reward             | -0.35792324 |\n",
      "|    std                | 63.3        |\n",
      "|    value_loss         | 0.0244      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 29900        |\n",
      "|    time_elapsed       | 487          |\n",
      "|    total_timesteps    | 149500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.1        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 29899        |\n",
      "|    policy_loss        | 2.15         |\n",
      "|    reward             | 0.0013991471 |\n",
      "|    std                | 63.5         |\n",
      "|    value_loss         | 0.0475       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 306        |\n",
      "|    iterations         | 30000      |\n",
      "|    time_elapsed       | 489        |\n",
      "|    total_timesteps    | 150000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.2      |\n",
      "|    explained_variance | 0.186      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 29999      |\n",
      "|    policy_loss        | -4.17      |\n",
      "|    reward             | 0.99316025 |\n",
      "|    std                | 64.1       |\n",
      "|    value_loss         | 0.165      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 30100       |\n",
      "|    time_elapsed       | 490         |\n",
      "|    total_timesteps    | 150500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30099       |\n",
      "|    policy_loss        | -7.93       |\n",
      "|    reward             | -0.29125717 |\n",
      "|    std                | 63.6        |\n",
      "|    value_loss         | 0.765       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 30200       |\n",
      "|    time_elapsed       | 492         |\n",
      "|    total_timesteps    | 151000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.1       |\n",
      "|    explained_variance | 0.363       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30199       |\n",
      "|    policy_loss        | -0.745      |\n",
      "|    reward             | 0.033208948 |\n",
      "|    std                | 63.7        |\n",
      "|    value_loss         | 0.00532     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 30300       |\n",
      "|    time_elapsed       | 493         |\n",
      "|    total_timesteps    | 151500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.2       |\n",
      "|    explained_variance | -0.0249     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30299       |\n",
      "|    policy_loss        | -0.071      |\n",
      "|    reward             | 0.007367022 |\n",
      "|    std                | 64.4        |\n",
      "|    value_loss         | 0.000117    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 30400       |\n",
      "|    time_elapsed       | 495         |\n",
      "|    total_timesteps    | 152000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.2       |\n",
      "|    explained_variance | 0.000253    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30399       |\n",
      "|    policy_loss        | -0.266      |\n",
      "|    reward             | -0.08667907 |\n",
      "|    std                | 66.1        |\n",
      "|    value_loss         | 0.00109     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 30500       |\n",
      "|    time_elapsed       | 497         |\n",
      "|    total_timesteps    | 152500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.3       |\n",
      "|    explained_variance | -0.0369     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30499       |\n",
      "|    policy_loss        | -0.105      |\n",
      "|    reward             | 0.029140418 |\n",
      "|    std                | 67.5        |\n",
      "|    value_loss         | 0.00067     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 30600        |\n",
      "|    time_elapsed       | 498          |\n",
      "|    total_timesteps    | 153000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 30599        |\n",
      "|    policy_loss        | -4.15        |\n",
      "|    reward             | -0.032187235 |\n",
      "|    std                | 68.8         |\n",
      "|    value_loss         | 0.15         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 30700       |\n",
      "|    time_elapsed       | 500         |\n",
      "|    total_timesteps    | 153500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30699       |\n",
      "|    policy_loss        | 0.615       |\n",
      "|    reward             | 0.010285114 |\n",
      "|    std                | 69.3        |\n",
      "|    value_loss         | 0.00682     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 306           |\n",
      "|    iterations         | 30800         |\n",
      "|    time_elapsed       | 502           |\n",
      "|    total_timesteps    | 154000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11.3         |\n",
      "|    explained_variance | -0.000117     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 30799         |\n",
      "|    policy_loss        | 0.268         |\n",
      "|    reward             | -0.0043311426 |\n",
      "|    std                | 70.2          |\n",
      "|    value_loss         | 0.000711      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 30900       |\n",
      "|    time_elapsed       | 503         |\n",
      "|    total_timesteps    | 154500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.4       |\n",
      "|    explained_variance | 0.211       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 30899       |\n",
      "|    policy_loss        | 0.287       |\n",
      "|    reward             | -0.01625542 |\n",
      "|    std                | 71.2        |\n",
      "|    value_loss         | 0.000786    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 31000        |\n",
      "|    time_elapsed       | 505          |\n",
      "|    total_timesteps    | 155000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.4        |\n",
      "|    explained_variance | -0.313       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 30999        |\n",
      "|    policy_loss        | -0.657       |\n",
      "|    reward             | 0.0014866134 |\n",
      "|    std                | 73.3         |\n",
      "|    value_loss         | 0.008        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 31100       |\n",
      "|    time_elapsed       | 507         |\n",
      "|    total_timesteps    | 155500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.5       |\n",
      "|    explained_variance | 0.000831    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 31099       |\n",
      "|    policy_loss        | 0.595       |\n",
      "|    reward             | 0.006769528 |\n",
      "|    std                | 75          |\n",
      "|    value_loss         | 0.00528     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 31200       |\n",
      "|    time_elapsed       | 508         |\n",
      "|    total_timesteps    | 156000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.5       |\n",
      "|    explained_variance | 0.674       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 31199       |\n",
      "|    policy_loss        | -0.115      |\n",
      "|    reward             | -0.03743132 |\n",
      "|    std                | 76.2        |\n",
      "|    value_loss         | 0.000526    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 306           |\n",
      "|    iterations         | 31300         |\n",
      "|    time_elapsed       | 510           |\n",
      "|    total_timesteps    | 156500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11.5         |\n",
      "|    explained_variance | -0.00577      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 31299         |\n",
      "|    policy_loss        | -0.332        |\n",
      "|    reward             | -0.0022767077 |\n",
      "|    std                | 77.8          |\n",
      "|    value_loss         | 0.00113       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 31400       |\n",
      "|    time_elapsed       | 512         |\n",
      "|    total_timesteps    | 157000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.6       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 31399       |\n",
      "|    policy_loss        | 0.185       |\n",
      "|    reward             | 0.005459244 |\n",
      "|    std                | 78.4        |\n",
      "|    value_loss         | 0.00026     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 31500       |\n",
      "|    time_elapsed       | 513         |\n",
      "|    total_timesteps    | 157500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.6       |\n",
      "|    explained_variance | -0.891      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 31499       |\n",
      "|    policy_loss        | -0.286      |\n",
      "|    reward             | 0.013065068 |\n",
      "|    std                | 79.6        |\n",
      "|    value_loss         | 0.000693    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 306           |\n",
      "|    iterations         | 31600         |\n",
      "|    time_elapsed       | 515           |\n",
      "|    total_timesteps    | 158000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11.6         |\n",
      "|    explained_variance | 0.0738        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 31599         |\n",
      "|    policy_loss        | 0.719         |\n",
      "|    reward             | -0.0015553386 |\n",
      "|    std                | 80.3          |\n",
      "|    value_loss         | 0.00915       |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 306       |\n",
      "|    iterations         | 31700     |\n",
      "|    time_elapsed       | 516       |\n",
      "|    total_timesteps    | 158500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -11.6     |\n",
      "|    explained_variance | 0.0157    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 31699     |\n",
      "|    policy_loss        | 1.49      |\n",
      "|    reward             | 0.0618249 |\n",
      "|    std                | 81.7      |\n",
      "|    value_loss         | 0.0206    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 306        |\n",
      "|    iterations         | 31800      |\n",
      "|    time_elapsed       | 518        |\n",
      "|    total_timesteps    | 159000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 31799      |\n",
      "|    policy_loss        | 2.93       |\n",
      "|    reward             | 0.17785858 |\n",
      "|    std                | 83.4       |\n",
      "|    value_loss         | 0.0682     |\n",
      "--------------------------------------\n",
      "day: 2896, episode: 55\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 126887.74\n",
      "total_reward: 116887.74\n",
      "total_cost: 18.66\n",
      "total_trades: 5790\n",
      "Sharpe: 0.814\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 31900       |\n",
      "|    time_elapsed       | 519         |\n",
      "|    total_timesteps    | 159500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.7       |\n",
      "|    explained_variance | -1.16       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 31899       |\n",
      "|    policy_loss        | -0.269      |\n",
      "|    reward             | 0.013118082 |\n",
      "|    std                | 84.5        |\n",
      "|    value_loss         | 0.000777    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 306           |\n",
      "|    iterations         | 32000         |\n",
      "|    time_elapsed       | 521           |\n",
      "|    total_timesteps    | 160000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11.7         |\n",
      "|    explained_variance | 0.615         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 31999         |\n",
      "|    policy_loss        | -0.0958       |\n",
      "|    reward             | -0.0152987465 |\n",
      "|    std                | 85.6          |\n",
      "|    value_loss         | 0.000101      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 32100       |\n",
      "|    time_elapsed       | 522         |\n",
      "|    total_timesteps    | 160500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.8       |\n",
      "|    explained_variance | 0.246       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 32099       |\n",
      "|    policy_loss        | 0.0974      |\n",
      "|    reward             | 0.010823439 |\n",
      "|    std                | 87.5        |\n",
      "|    value_loss         | 0.000199    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 32200        |\n",
      "|    time_elapsed       | 524          |\n",
      "|    total_timesteps    | 161000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.8        |\n",
      "|    explained_variance | 0.0102       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32199        |\n",
      "|    policy_loss        | -0.0108      |\n",
      "|    reward             | -0.014311282 |\n",
      "|    std                | 89.5         |\n",
      "|    value_loss         | 0.000105     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 32300        |\n",
      "|    time_elapsed       | 526          |\n",
      "|    total_timesteps    | 161500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.8        |\n",
      "|    explained_variance | 0.06         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32299        |\n",
      "|    policy_loss        | -0.932       |\n",
      "|    reward             | -0.004457979 |\n",
      "|    std                | 90.8         |\n",
      "|    value_loss         | 0.00845      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 32400        |\n",
      "|    time_elapsed       | 527          |\n",
      "|    total_timesteps    | 162000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.9        |\n",
      "|    explained_variance | 0.0837       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32399        |\n",
      "|    policy_loss        | -0.363       |\n",
      "|    reward             | -0.033793084 |\n",
      "|    std                | 91.5         |\n",
      "|    value_loss         | 0.00178      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 306         |\n",
      "|    iterations         | 32500       |\n",
      "|    time_elapsed       | 529         |\n",
      "|    total_timesteps    | 162500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.9       |\n",
      "|    explained_variance | 0.00148     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 32499       |\n",
      "|    policy_loss        | 0.0953      |\n",
      "|    reward             | -0.01392592 |\n",
      "|    std                | 92.3        |\n",
      "|    value_loss         | 0.000128    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 32600        |\n",
      "|    time_elapsed       | 531          |\n",
      "|    total_timesteps    | 163000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.9        |\n",
      "|    explained_variance | 0.516        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32599        |\n",
      "|    policy_loss        | -0.143       |\n",
      "|    reward             | 0.0033797533 |\n",
      "|    std                | 94.1         |\n",
      "|    value_loss         | 0.000221     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 32700        |\n",
      "|    time_elapsed       | 532          |\n",
      "|    total_timesteps    | 163500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.9        |\n",
      "|    explained_variance | -2.65        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 32699        |\n",
      "|    policy_loss        | 0.24         |\n",
      "|    reward             | -0.011190611 |\n",
      "|    std                | 94.9         |\n",
      "|    value_loss         | 0.000523     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 306           |\n",
      "|    iterations         | 32800         |\n",
      "|    time_elapsed       | 534           |\n",
      "|    total_timesteps    | 164000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 32799         |\n",
      "|    policy_loss        | -0.504        |\n",
      "|    reward             | -0.0048571215 |\n",
      "|    std                | 96.3          |\n",
      "|    value_loss         | 0.00202       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 32900       |\n",
      "|    time_elapsed       | 535         |\n",
      "|    total_timesteps    | 164500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12         |\n",
      "|    explained_variance | -0.0127     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 32899       |\n",
      "|    policy_loss        | 0.879       |\n",
      "|    reward             | 0.044504225 |\n",
      "|    std                | 96.8        |\n",
      "|    value_loss         | 0.00676     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 33000      |\n",
      "|    time_elapsed       | 537        |\n",
      "|    total_timesteps    | 165000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 32999      |\n",
      "|    policy_loss        | -3.37      |\n",
      "|    reward             | 0.15936719 |\n",
      "|    std                | 97.2       |\n",
      "|    value_loss         | 0.0996     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 33100        |\n",
      "|    time_elapsed       | 539          |\n",
      "|    total_timesteps    | 165500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12          |\n",
      "|    explained_variance | 0.418        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 33099        |\n",
      "|    policy_loss        | 0.115        |\n",
      "|    reward             | -0.006437067 |\n",
      "|    std                | 98.3         |\n",
      "|    value_loss         | 0.000115     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 33200       |\n",
      "|    time_elapsed       | 540         |\n",
      "|    total_timesteps    | 166000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12         |\n",
      "|    explained_variance | -1.38       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 33199       |\n",
      "|    policy_loss        | 0.13        |\n",
      "|    reward             | 0.008141226 |\n",
      "|    std                | 100         |\n",
      "|    value_loss         | 0.000144    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 33300      |\n",
      "|    time_elapsed       | 542        |\n",
      "|    total_timesteps    | 166500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.1      |\n",
      "|    explained_variance | 0.0174     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 33299      |\n",
      "|    policy_loss        | -0.0889    |\n",
      "|    reward             | 0.01762957 |\n",
      "|    std                | 101        |\n",
      "|    value_loss         | 0.000689   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 33400        |\n",
      "|    time_elapsed       | 543          |\n",
      "|    total_timesteps    | 167000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.1        |\n",
      "|    explained_variance | 0.14         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 33399        |\n",
      "|    policy_loss        | -0.85        |\n",
      "|    reward             | 0.0056584016 |\n",
      "|    std                | 105          |\n",
      "|    value_loss         | 0.00707      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 33500       |\n",
      "|    time_elapsed       | 545         |\n",
      "|    total_timesteps    | 167500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.2       |\n",
      "|    explained_variance | 0.0849      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 33499       |\n",
      "|    policy_loss        | -0.632      |\n",
      "|    reward             | -0.07371176 |\n",
      "|    std                | 107         |\n",
      "|    value_loss         | 0.00529     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 33600       |\n",
      "|    time_elapsed       | 547         |\n",
      "|    total_timesteps    | 168000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 33599       |\n",
      "|    policy_loss        | -0.377      |\n",
      "|    reward             | 0.022342285 |\n",
      "|    std                | 108         |\n",
      "|    value_loss         | 0.00498     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 33700        |\n",
      "|    time_elapsed       | 548          |\n",
      "|    total_timesteps    | 168500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.2        |\n",
      "|    explained_variance | 0.3          |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 33699        |\n",
      "|    policy_loss        | 0.0168       |\n",
      "|    reward             | 0.0010491158 |\n",
      "|    std                | 110          |\n",
      "|    value_loss         | 1.61e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 306          |\n",
      "|    iterations         | 33800        |\n",
      "|    time_elapsed       | 550          |\n",
      "|    total_timesteps    | 169000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.3        |\n",
      "|    explained_variance | 0.38         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 33799        |\n",
      "|    policy_loss        | 0.000496     |\n",
      "|    reward             | 0.0017458275 |\n",
      "|    std                | 112          |\n",
      "|    value_loss         | 8.38e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 306        |\n",
      "|    iterations         | 33900      |\n",
      "|    time_elapsed       | 552        |\n",
      "|    total_timesteps    | 169500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.3      |\n",
      "|    explained_variance | -0.394     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 33899      |\n",
      "|    policy_loss        | -0.0436    |\n",
      "|    reward             | 0.01009198 |\n",
      "|    std                | 116        |\n",
      "|    value_loss         | 8.52e-05   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 34000        |\n",
      "|    time_elapsed       | 553          |\n",
      "|    total_timesteps    | 170000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.4        |\n",
      "|    explained_variance | 0.00493      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 33999        |\n",
      "|    policy_loss        | 0.263        |\n",
      "|    reward             | -0.019415615 |\n",
      "|    std                | 120          |\n",
      "|    value_loss         | 0.000473     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 34100       |\n",
      "|    time_elapsed       | 555         |\n",
      "|    total_timesteps    | 170500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34099       |\n",
      "|    policy_loss        | -0.408      |\n",
      "|    reward             | -0.03933711 |\n",
      "|    std                | 124         |\n",
      "|    value_loss         | 0.000919    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 34200       |\n",
      "|    time_elapsed       | 556         |\n",
      "|    total_timesteps    | 171000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.5       |\n",
      "|    explained_variance | -2.24       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34199       |\n",
      "|    policy_loss        | 0.0328      |\n",
      "|    reward             | 0.018003298 |\n",
      "|    std                | 129         |\n",
      "|    value_loss         | 4.25e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 34300         |\n",
      "|    time_elapsed       | 558           |\n",
      "|    total_timesteps    | 171500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.6         |\n",
      "|    explained_variance | 0.57          |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 34299         |\n",
      "|    policy_loss        | -0.205        |\n",
      "|    reward             | -0.0035751283 |\n",
      "|    std                | 132           |\n",
      "|    value_loss         | 0.000299      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 34400        |\n",
      "|    time_elapsed       | 559          |\n",
      "|    total_timesteps    | 172000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.7        |\n",
      "|    explained_variance | 0.685        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 34399        |\n",
      "|    policy_loss        | -0.043       |\n",
      "|    reward             | 0.0043137907 |\n",
      "|    std                | 136          |\n",
      "|    value_loss         | 2.88e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 34500         |\n",
      "|    time_elapsed       | 561           |\n",
      "|    total_timesteps    | 172500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.7         |\n",
      "|    explained_variance | 0.287         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 34499         |\n",
      "|    policy_loss        | -0.223        |\n",
      "|    reward             | -0.0006443035 |\n",
      "|    std                | 142           |\n",
      "|    value_loss         | 0.00177       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 34600         |\n",
      "|    time_elapsed       | 562           |\n",
      "|    total_timesteps    | 173000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.8         |\n",
      "|    explained_variance | 0.189         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 34599         |\n",
      "|    policy_loss        | -0.727        |\n",
      "|    reward             | -0.0056137275 |\n",
      "|    std                | 146           |\n",
      "|    value_loss         | 0.00318       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 34700       |\n",
      "|    time_elapsed       | 564         |\n",
      "|    total_timesteps    | 173500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.8       |\n",
      "|    explained_variance | 0.427       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34699       |\n",
      "|    policy_loss        | 0.317       |\n",
      "|    reward             | -0.03237875 |\n",
      "|    std                | 147         |\n",
      "|    value_loss         | 0.000906    |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 60\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 42203.19\n",
      "total_reward: 32203.19\n",
      "total_cost: 23.89\n",
      "total_trades: 5788\n",
      "Sharpe: 0.576\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 34800       |\n",
      "|    time_elapsed       | 566         |\n",
      "|    total_timesteps    | 174000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.9       |\n",
      "|    explained_variance | 0.289       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34799       |\n",
      "|    policy_loss        | -0.0661     |\n",
      "|    reward             | 0.030358262 |\n",
      "|    std                | 151         |\n",
      "|    value_loss         | 0.000424    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 34900        |\n",
      "|    time_elapsed       | 567          |\n",
      "|    total_timesteps    | 174500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | 0.444        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 34899        |\n",
      "|    policy_loss        | -0.103       |\n",
      "|    reward             | 0.0049613407 |\n",
      "|    std                | 153          |\n",
      "|    value_loss         | 7.67e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 35000       |\n",
      "|    time_elapsed       | 569         |\n",
      "|    total_timesteps    | 175000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.9       |\n",
      "|    explained_variance | 0.144       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 34999       |\n",
      "|    policy_loss        | -0.555      |\n",
      "|    reward             | -0.07144201 |\n",
      "|    std                | 156         |\n",
      "|    value_loss         | 0.00236     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 35100       |\n",
      "|    time_elapsed       | 570         |\n",
      "|    total_timesteps    | 175500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13         |\n",
      "|    explained_variance | 0.0576      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35099       |\n",
      "|    policy_loss        | 1.43        |\n",
      "|    reward             | -0.16260228 |\n",
      "|    std                | 160         |\n",
      "|    value_loss         | 0.0174      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 35200       |\n",
      "|    time_elapsed       | 572         |\n",
      "|    total_timesteps    | 176000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13         |\n",
      "|    explained_variance | 0.174       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35199       |\n",
      "|    policy_loss        | -0.352      |\n",
      "|    reward             | 0.012152995 |\n",
      "|    std                | 162         |\n",
      "|    value_loss         | 0.0143      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 35300         |\n",
      "|    time_elapsed       | 574           |\n",
      "|    total_timesteps    | 176500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13           |\n",
      "|    explained_variance | 0.000469      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 35299         |\n",
      "|    policy_loss        | -0.292        |\n",
      "|    reward             | -0.0037671188 |\n",
      "|    std                | 162           |\n",
      "|    value_loss         | 0.0257        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 35400       |\n",
      "|    time_elapsed       | 575         |\n",
      "|    total_timesteps    | 177000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13         |\n",
      "|    explained_variance | 0.595       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35399       |\n",
      "|    policy_loss        | 0.407       |\n",
      "|    reward             | -0.01566404 |\n",
      "|    std                | 164         |\n",
      "|    value_loss         | 0.00123     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 35500        |\n",
      "|    time_elapsed       | 577          |\n",
      "|    total_timesteps    | 177500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.1        |\n",
      "|    explained_variance | 0.279        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 35499        |\n",
      "|    policy_loss        | 0.266        |\n",
      "|    reward             | -0.011648044 |\n",
      "|    std                | 166          |\n",
      "|    value_loss         | 0.000514     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 35600      |\n",
      "|    time_elapsed       | 579        |\n",
      "|    total_timesteps    | 178000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.1      |\n",
      "|    explained_variance | 0.232      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 35599      |\n",
      "|    policy_loss        | -1.27      |\n",
      "|    reward             | 0.14974996 |\n",
      "|    std                | 169        |\n",
      "|    value_loss         | 0.0147     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 35700      |\n",
      "|    time_elapsed       | 581        |\n",
      "|    total_timesteps    | 178500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.1      |\n",
      "|    explained_variance | 0.63       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 35699      |\n",
      "|    policy_loss        | 1.11       |\n",
      "|    reward             | 0.11163503 |\n",
      "|    std                | 170        |\n",
      "|    value_loss         | 0.00917    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 35800       |\n",
      "|    time_elapsed       | 582         |\n",
      "|    total_timesteps    | 179000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.1       |\n",
      "|    explained_variance | 0.535       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35799       |\n",
      "|    policy_loss        | -1.51       |\n",
      "|    reward             | 0.066733405 |\n",
      "|    std                | 170         |\n",
      "|    value_loss         | 0.0148      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 35900       |\n",
      "|    time_elapsed       | 584         |\n",
      "|    total_timesteps    | 179500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 35899       |\n",
      "|    policy_loss        | -1.77       |\n",
      "|    reward             | -0.14599045 |\n",
      "|    std                | 171         |\n",
      "|    value_loss         | 0.0313      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 36000        |\n",
      "|    time_elapsed       | 585          |\n",
      "|    total_timesteps    | 180000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.1        |\n",
      "|    explained_variance | 0.224        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 35999        |\n",
      "|    policy_loss        | -0.187       |\n",
      "|    reward             | 0.0030251697 |\n",
      "|    std                | 173          |\n",
      "|    value_loss         | 0.000666     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 36100        |\n",
      "|    time_elapsed       | 587          |\n",
      "|    total_timesteps    | 180500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.2        |\n",
      "|    explained_variance | 0.000427     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36099        |\n",
      "|    policy_loss        | 0.111        |\n",
      "|    reward             | -0.015238565 |\n",
      "|    std                | 176          |\n",
      "|    value_loss         | 7.78e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 36200       |\n",
      "|    time_elapsed       | 589         |\n",
      "|    total_timesteps    | 181000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.2       |\n",
      "|    explained_variance | -0.056      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36199       |\n",
      "|    policy_loss        | -0.00735    |\n",
      "|    reward             | 0.027951539 |\n",
      "|    std                | 180         |\n",
      "|    value_loss         | 0.000564    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 36300       |\n",
      "|    time_elapsed       | 590         |\n",
      "|    total_timesteps    | 181500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.3       |\n",
      "|    explained_variance | -0.00169    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36299       |\n",
      "|    policy_loss        | -0.948      |\n",
      "|    reward             | 0.043575197 |\n",
      "|    std                | 183         |\n",
      "|    value_loss         | 0.00578     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 36400       |\n",
      "|    time_elapsed       | 592         |\n",
      "|    total_timesteps    | 182000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.3       |\n",
      "|    explained_variance | 0.404       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36399       |\n",
      "|    policy_loss        | -1.11       |\n",
      "|    reward             | -0.07370495 |\n",
      "|    std                | 186         |\n",
      "|    value_loss         | 0.00896     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 36500       |\n",
      "|    time_elapsed       | 593         |\n",
      "|    total_timesteps    | 182500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 36499       |\n",
      "|    policy_loss        | -0.157      |\n",
      "|    reward             | -0.00790184 |\n",
      "|    std                | 187         |\n",
      "|    value_loss         | 0.00193     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 36600        |\n",
      "|    time_elapsed       | 595          |\n",
      "|    total_timesteps    | 183000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.3        |\n",
      "|    explained_variance | -0.255       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36599        |\n",
      "|    policy_loss        | -0.00643     |\n",
      "|    reward             | 0.0063300943 |\n",
      "|    std                | 190          |\n",
      "|    value_loss         | 5.65e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 36700        |\n",
      "|    time_elapsed       | 597          |\n",
      "|    total_timesteps    | 183500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | 0.736        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36699        |\n",
      "|    policy_loss        | 0.162        |\n",
      "|    reward             | -0.013423812 |\n",
      "|    std                | 194          |\n",
      "|    value_loss         | 0.000193     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 36800        |\n",
      "|    time_elapsed       | 598          |\n",
      "|    total_timesteps    | 184000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | -0.379       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36799        |\n",
      "|    policy_loss        | 0.143        |\n",
      "|    reward             | -0.010959334 |\n",
      "|    std                | 197          |\n",
      "|    value_loss         | 0.000724     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 36900        |\n",
      "|    time_elapsed       | 600          |\n",
      "|    total_timesteps    | 184500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | 0.14         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36899        |\n",
      "|    policy_loss        | 0.839        |\n",
      "|    reward             | -0.010838875 |\n",
      "|    std                | 201          |\n",
      "|    value_loss         | 0.0105       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 37000        |\n",
      "|    time_elapsed       | 601          |\n",
      "|    total_timesteps    | 185000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.5        |\n",
      "|    explained_variance | 0.629        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 36999        |\n",
      "|    policy_loss        | 0.512        |\n",
      "|    reward             | -0.052022856 |\n",
      "|    std                | 203          |\n",
      "|    value_loss         | 0.0023       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 37100         |\n",
      "|    time_elapsed       | 603           |\n",
      "|    total_timesteps    | 185500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.5         |\n",
      "|    explained_variance | -0.0922       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 37099         |\n",
      "|    policy_loss        | -0.11         |\n",
      "|    reward             | -0.0023959859 |\n",
      "|    std                | 206           |\n",
      "|    value_loss         | 0.000157      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 37200         |\n",
      "|    time_elapsed       | 605           |\n",
      "|    total_timesteps    | 186000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.5         |\n",
      "|    explained_variance | 0.191         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 37199         |\n",
      "|    policy_loss        | 0.379         |\n",
      "|    reward             | 0.00027353058 |\n",
      "|    std                | 210           |\n",
      "|    value_loss         | 0.00111       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 37300       |\n",
      "|    time_elapsed       | 606         |\n",
      "|    total_timesteps    | 186500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.6       |\n",
      "|    explained_variance | 0.309       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37299       |\n",
      "|    policy_loss        | -0.453      |\n",
      "|    reward             | 0.016137697 |\n",
      "|    std                | 214         |\n",
      "|    value_loss         | 0.00215     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 37400        |\n",
      "|    time_elapsed       | 608          |\n",
      "|    total_timesteps    | 187000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.6        |\n",
      "|    explained_variance | 0.08         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 37399        |\n",
      "|    policy_loss        | -0.441       |\n",
      "|    reward             | -0.021203063 |\n",
      "|    std                | 218          |\n",
      "|    value_loss         | 0.0011       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 37500       |\n",
      "|    time_elapsed       | 609         |\n",
      "|    total_timesteps    | 187500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.6       |\n",
      "|    explained_variance | 0.0534      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 37499       |\n",
      "|    policy_loss        | -3.44       |\n",
      "|    reward             | 0.022896942 |\n",
      "|    std                | 221         |\n",
      "|    value_loss         | 0.189       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 37600      |\n",
      "|    time_elapsed       | 611        |\n",
      "|    total_timesteps    | 188000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.7      |\n",
      "|    explained_variance | -1.42e-05  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 37599      |\n",
      "|    policy_loss        | -2.07      |\n",
      "|    reward             | 0.09452443 |\n",
      "|    std                | 226        |\n",
      "|    value_loss         | 0.0268     |\n",
      "--------------------------------------\n",
      "day: 2896, episode: 65\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 115412.12\n",
      "total_reward: 105412.12\n",
      "total_cost: 11.44\n",
      "total_trades: 5790\n",
      "Sharpe: 0.808\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 37700         |\n",
      "|    time_elapsed       | 612           |\n",
      "|    total_timesteps    | 188500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 37699         |\n",
      "|    policy_loss        | -0.176        |\n",
      "|    reward             | -0.0026421594 |\n",
      "|    std                | 228           |\n",
      "|    value_loss         | 0.000199      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 37800        |\n",
      "|    time_elapsed       | 614          |\n",
      "|    total_timesteps    | 189000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.7        |\n",
      "|    explained_variance | -0.1         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 37799        |\n",
      "|    policy_loss        | -0.122       |\n",
      "|    reward             | 0.0029376568 |\n",
      "|    std                | 230          |\n",
      "|    value_loss         | 0.000158     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 37900        |\n",
      "|    time_elapsed       | 616          |\n",
      "|    total_timesteps    | 189500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.7        |\n",
      "|    explained_variance | 0.199        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 37899        |\n",
      "|    policy_loss        | 0.701        |\n",
      "|    reward             | -0.006801357 |\n",
      "|    std                | 234          |\n",
      "|    value_loss         | 0.00338      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 38000        |\n",
      "|    time_elapsed       | 617          |\n",
      "|    total_timesteps    | 190000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.8        |\n",
      "|    explained_variance | 0.163        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 37999        |\n",
      "|    policy_loss        | 0.782        |\n",
      "|    reward             | -0.029301077 |\n",
      "|    std                | 238          |\n",
      "|    value_loss         | 0.00571      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 38100        |\n",
      "|    time_elapsed       | 619          |\n",
      "|    total_timesteps    | 190500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.8        |\n",
      "|    explained_variance | 0.0523       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 38099        |\n",
      "|    policy_loss        | 4.69         |\n",
      "|    reward             | -0.117130026 |\n",
      "|    std                | 241          |\n",
      "|    value_loss         | 0.137        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 38200      |\n",
      "|    time_elapsed       | 621        |\n",
      "|    total_timesteps    | 191000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.8      |\n",
      "|    explained_variance | 0.0138     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 38199      |\n",
      "|    policy_loss        | 3.57       |\n",
      "|    reward             | 0.09627438 |\n",
      "|    std                | 245        |\n",
      "|    value_loss         | 0.0648     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 38300       |\n",
      "|    time_elapsed       | 622         |\n",
      "|    total_timesteps    | 191500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.9       |\n",
      "|    explained_variance | -0.409      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38299       |\n",
      "|    policy_loss        | -0.00151    |\n",
      "|    reward             | 0.016298484 |\n",
      "|    std                | 247         |\n",
      "|    value_loss         | 0.000721    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 38400       |\n",
      "|    time_elapsed       | 624         |\n",
      "|    total_timesteps    | 192000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.9       |\n",
      "|    explained_variance | 0.578       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38399       |\n",
      "|    policy_loss        | 0.102       |\n",
      "|    reward             | 0.007903695 |\n",
      "|    std                | 252         |\n",
      "|    value_loss         | 9.76e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 38500      |\n",
      "|    time_elapsed       | 625        |\n",
      "|    total_timesteps    | 192500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.9      |\n",
      "|    explained_variance | 0.424      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 38499      |\n",
      "|    policy_loss        | -0.0258    |\n",
      "|    reward             | 0.09497506 |\n",
      "|    std                | 257        |\n",
      "|    value_loss         | 0.000196   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 38600         |\n",
      "|    time_elapsed       | 627           |\n",
      "|    total_timesteps    | 193000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14           |\n",
      "|    explained_variance | 0.586         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 38599         |\n",
      "|    policy_loss        | 1.3           |\n",
      "|    reward             | -0.0072553866 |\n",
      "|    std                | 261           |\n",
      "|    value_loss         | 0.00994       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 38700       |\n",
      "|    time_elapsed       | 629         |\n",
      "|    total_timesteps    | 193500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14         |\n",
      "|    explained_variance | 2.83e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 38699       |\n",
      "|    policy_loss        | -4.25       |\n",
      "|    reward             | -0.33914852 |\n",
      "|    std                | 262         |\n",
      "|    value_loss         | 0.0952      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 307       |\n",
      "|    iterations         | 38800     |\n",
      "|    time_elapsed       | 630       |\n",
      "|    total_timesteps    | 194000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14       |\n",
      "|    explained_variance | 2.09e-06  |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 38799     |\n",
      "|    policy_loss        | -1.66     |\n",
      "|    reward             | 0.1883196 |\n",
      "|    std                | 265       |\n",
      "|    value_loss         | 0.0538    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 38900        |\n",
      "|    time_elapsed       | 632          |\n",
      "|    total_timesteps    | 194500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14          |\n",
      "|    explained_variance | 0.303        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 38899        |\n",
      "|    policy_loss        | 0.247        |\n",
      "|    reward             | -0.027394569 |\n",
      "|    std                | 267          |\n",
      "|    value_loss         | 0.00074      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 39000        |\n",
      "|    time_elapsed       | 634          |\n",
      "|    total_timesteps    | 195000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14          |\n",
      "|    explained_variance | 0.0584       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 38999        |\n",
      "|    policy_loss        | -0.231       |\n",
      "|    reward             | 0.0035703667 |\n",
      "|    std                | 271          |\n",
      "|    value_loss         | 0.000446     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 39100       |\n",
      "|    time_elapsed       | 635         |\n",
      "|    total_timesteps    | 195500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.1       |\n",
      "|    explained_variance | -16.4       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 39099       |\n",
      "|    policy_loss        | -1          |\n",
      "|    reward             | 0.028009826 |\n",
      "|    std                | 278         |\n",
      "|    value_loss         | 0.00768     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 39200       |\n",
      "|    time_elapsed       | 637         |\n",
      "|    total_timesteps    | 196000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.1       |\n",
      "|    explained_variance | -1.09       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 39199       |\n",
      "|    policy_loss        | -0.104      |\n",
      "|    reward             | 0.009063181 |\n",
      "|    std                | 286         |\n",
      "|    value_loss         | 0.000153    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 39300       |\n",
      "|    time_elapsed       | 638         |\n",
      "|    total_timesteps    | 196500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 39299       |\n",
      "|    policy_loss        | -0.733      |\n",
      "|    reward             | 0.026615195 |\n",
      "|    std                | 297         |\n",
      "|    value_loss         | 0.00317     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 39400        |\n",
      "|    time_elapsed       | 640          |\n",
      "|    total_timesteps    | 197000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.2        |\n",
      "|    explained_variance | -0.245       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39399        |\n",
      "|    policy_loss        | -3.01        |\n",
      "|    reward             | -0.007982932 |\n",
      "|    std                | 298          |\n",
      "|    value_loss         | 0.0754       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 39500       |\n",
      "|    time_elapsed       | 642         |\n",
      "|    total_timesteps    | 197500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.3       |\n",
      "|    explained_variance | 0.498       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 39499       |\n",
      "|    policy_loss        | -0.0377     |\n",
      "|    reward             | 0.012741346 |\n",
      "|    std                | 305         |\n",
      "|    value_loss         | 2.48e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 39600       |\n",
      "|    time_elapsed       | 644         |\n",
      "|    total_timesteps    | 198000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.3       |\n",
      "|    explained_variance | 0.00553     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 39599       |\n",
      "|    policy_loss        | -0.203      |\n",
      "|    reward             | 0.026491327 |\n",
      "|    std                | 314         |\n",
      "|    value_loss         | 0.000428    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 39700        |\n",
      "|    time_elapsed       | 645          |\n",
      "|    total_timesteps    | 198500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.4        |\n",
      "|    explained_variance | 0.0215       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39699        |\n",
      "|    policy_loss        | 0.687        |\n",
      "|    reward             | -0.038920034 |\n",
      "|    std                | 318          |\n",
      "|    value_loss         | 0.00528      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 39800       |\n",
      "|    time_elapsed       | 647         |\n",
      "|    total_timesteps    | 199000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.4       |\n",
      "|    explained_variance | 0.46        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 39799       |\n",
      "|    policy_loss        | 2.95        |\n",
      "|    reward             | -0.21315885 |\n",
      "|    std                | 321         |\n",
      "|    value_loss         | 0.0424      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 39900      |\n",
      "|    time_elapsed       | 649        |\n",
      "|    total_timesteps    | 199500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.4      |\n",
      "|    explained_variance | -0.0214    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 39899      |\n",
      "|    policy_loss        | -3.56      |\n",
      "|    reward             | 0.39398614 |\n",
      "|    std                | 323        |\n",
      "|    value_loss         | 0.0751     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 40000        |\n",
      "|    time_elapsed       | 650          |\n",
      "|    total_timesteps    | 200000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.4        |\n",
      "|    explained_variance | 0.549        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 39999        |\n",
      "|    policy_loss        | -0.746       |\n",
      "|    reward             | 0.0011366601 |\n",
      "|    std                | 322          |\n",
      "|    value_loss         | 0.00305      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 40100         |\n",
      "|    time_elapsed       | 652           |\n",
      "|    total_timesteps    | 200500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.4         |\n",
      "|    explained_variance | -2.93         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 40099         |\n",
      "|    policy_loss        | -0.0859       |\n",
      "|    reward             | -0.0043036016 |\n",
      "|    std                | 326           |\n",
      "|    value_loss         | 0.000113      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 40200         |\n",
      "|    time_elapsed       | 653           |\n",
      "|    total_timesteps    | 201000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.4         |\n",
      "|    explained_variance | 0.416         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 40199         |\n",
      "|    policy_loss        | 0.48          |\n",
      "|    reward             | -0.0066824653 |\n",
      "|    std                | 333           |\n",
      "|    value_loss         | 0.00128       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 40300      |\n",
      "|    time_elapsed       | 655        |\n",
      "|    total_timesteps    | 201500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.5      |\n",
      "|    explained_variance | 0.132      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 40299      |\n",
      "|    policy_loss        | 0.344      |\n",
      "|    reward             | 0.01298542 |\n",
      "|    std                | 343        |\n",
      "|    value_loss         | 0.00105    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 40400        |\n",
      "|    time_elapsed       | 656          |\n",
      "|    total_timesteps    | 202000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.5        |\n",
      "|    explained_variance | 0.0615       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 40399        |\n",
      "|    policy_loss        | 0.103        |\n",
      "|    reward             | -0.062185943 |\n",
      "|    std                | 346          |\n",
      "|    value_loss         | 0.00117      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 307       |\n",
      "|    iterations         | 40500     |\n",
      "|    time_elapsed       | 658       |\n",
      "|    total_timesteps    | 202500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14.6     |\n",
      "|    explained_variance | 0.268     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 40499     |\n",
      "|    policy_loss        | 1.85      |\n",
      "|    reward             | 0.0253376 |\n",
      "|    std                | 352       |\n",
      "|    value_loss         | 0.0174    |\n",
      "-------------------------------------\n",
      "day: 2896, episode: 70\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 92587.15\n",
      "total_reward: 82587.15\n",
      "total_cost: 17.35\n",
      "total_trades: 5784\n",
      "Sharpe: 0.730\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 40600       |\n",
      "|    time_elapsed       | 659         |\n",
      "|    total_timesteps    | 203000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.6       |\n",
      "|    explained_variance | -1.05       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40599       |\n",
      "|    policy_loss        | -0.176      |\n",
      "|    reward             | 0.007866771 |\n",
      "|    std                | 353         |\n",
      "|    value_loss         | 0.000322    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 307            |\n",
      "|    iterations         | 40700          |\n",
      "|    time_elapsed       | 661            |\n",
      "|    total_timesteps    | 203500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -14.6          |\n",
      "|    explained_variance | -1.37          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 40699          |\n",
      "|    policy_loss        | 0.0497         |\n",
      "|    reward             | -0.00062887114 |\n",
      "|    std                | 359            |\n",
      "|    value_loss         | 2.59e-05       |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 307       |\n",
      "|    iterations         | 40800     |\n",
      "|    time_elapsed       | 663       |\n",
      "|    total_timesteps    | 204000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14.6     |\n",
      "|    explained_variance | 0.399     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 40799     |\n",
      "|    policy_loss        | -0.166    |\n",
      "|    reward             | 0.0180742 |\n",
      "|    std                | 368       |\n",
      "|    value_loss         | 0.000171  |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 40900        |\n",
      "|    time_elapsed       | 665          |\n",
      "|    total_timesteps    | 204500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.7        |\n",
      "|    explained_variance | 0.552        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 40899        |\n",
      "|    policy_loss        | 0.111        |\n",
      "|    reward             | -0.006046503 |\n",
      "|    std                | 376          |\n",
      "|    value_loss         | 0.000108     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 41000       |\n",
      "|    time_elapsed       | 666         |\n",
      "|    total_timesteps    | 205000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.7       |\n",
      "|    explained_variance | 0.0999      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 40999       |\n",
      "|    policy_loss        | -0.256      |\n",
      "|    reward             | 0.007302743 |\n",
      "|    std                | 386         |\n",
      "|    value_loss         | 0.000923    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 41100       |\n",
      "|    time_elapsed       | 668         |\n",
      "|    total_timesteps    | 205500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 41099       |\n",
      "|    policy_loss        | -0.243      |\n",
      "|    reward             | 0.039291557 |\n",
      "|    std                | 401         |\n",
      "|    value_loss         | 0.000324    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 41200       |\n",
      "|    time_elapsed       | 669         |\n",
      "|    total_timesteps    | 206000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.9       |\n",
      "|    explained_variance | 0.672       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 41199       |\n",
      "|    policy_loss        | 0.186       |\n",
      "|    reward             | 0.027679263 |\n",
      "|    std                | 417         |\n",
      "|    value_loss         | 0.000221    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 41300        |\n",
      "|    time_elapsed       | 671          |\n",
      "|    total_timesteps    | 206500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15          |\n",
      "|    explained_variance | 0.0752       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41299        |\n",
      "|    policy_loss        | 0.101        |\n",
      "|    reward             | 0.0030824023 |\n",
      "|    std                | 429          |\n",
      "|    value_loss         | 6.01e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 41400        |\n",
      "|    time_elapsed       | 673          |\n",
      "|    total_timesteps    | 207000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15          |\n",
      "|    explained_variance | 0.721        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41399        |\n",
      "|    policy_loss        | -0.164       |\n",
      "|    reward             | -0.009797706 |\n",
      "|    std                | 443          |\n",
      "|    value_loss         | 0.00014      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 41500         |\n",
      "|    time_elapsed       | 674           |\n",
      "|    total_timesteps    | 207500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.1         |\n",
      "|    explained_variance | 0.0508        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 41499         |\n",
      "|    policy_loss        | -0.111        |\n",
      "|    reward             | 0.00085820886 |\n",
      "|    std                | 459           |\n",
      "|    value_loss         | 0.00014       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 41600        |\n",
      "|    time_elapsed       | 676          |\n",
      "|    total_timesteps    | 208000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41599        |\n",
      "|    policy_loss        | 0.492        |\n",
      "|    reward             | -0.002647927 |\n",
      "|    std                | 465          |\n",
      "|    value_loss         | 0.00115      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 41700      |\n",
      "|    time_elapsed       | 677        |\n",
      "|    total_timesteps    | 208500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 41699      |\n",
      "|    policy_loss        | 1.58       |\n",
      "|    reward             | 0.04610241 |\n",
      "|    std                | 470        |\n",
      "|    value_loss         | 0.0115     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 41800        |\n",
      "|    time_elapsed       | 679          |\n",
      "|    total_timesteps    | 209000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.2        |\n",
      "|    explained_variance | 0.0226       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41799        |\n",
      "|    policy_loss        | 0.126        |\n",
      "|    reward             | -0.004642635 |\n",
      "|    std                | 480          |\n",
      "|    value_loss         | 0.000697     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 41900        |\n",
      "|    time_elapsed       | 680          |\n",
      "|    total_timesteps    | 209500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.2        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41899        |\n",
      "|    policy_loss        | 0.129        |\n",
      "|    reward             | -0.020374723 |\n",
      "|    std                | 487          |\n",
      "|    value_loss         | 0.00041      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 42000        |\n",
      "|    time_elapsed       | 682          |\n",
      "|    total_timesteps    | 210000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 41999        |\n",
      "|    policy_loss        | 1.53         |\n",
      "|    reward             | -0.057471514 |\n",
      "|    std                | 492          |\n",
      "|    value_loss         | 0.0102       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 42100       |\n",
      "|    time_elapsed       | 684         |\n",
      "|    total_timesteps    | 210500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.3       |\n",
      "|    explained_variance | 0.0472      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 42099       |\n",
      "|    policy_loss        | 1.2         |\n",
      "|    reward             | 0.014039857 |\n",
      "|    std                | 503         |\n",
      "|    value_loss         | 0.0219      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 42200      |\n",
      "|    time_elapsed       | 685        |\n",
      "|    total_timesteps    | 211000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.3      |\n",
      "|    explained_variance | 0.592      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 42199      |\n",
      "|    policy_loss        | -0.106     |\n",
      "|    reward             | 0.12896396 |\n",
      "|    std                | 507        |\n",
      "|    value_loss         | 0.00285    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 42300       |\n",
      "|    time_elapsed       | 687         |\n",
      "|    total_timesteps    | 211500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.3       |\n",
      "|    explained_variance | -0.0122     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 42299       |\n",
      "|    policy_loss        | -0.19       |\n",
      "|    reward             | 0.010497433 |\n",
      "|    std                | 507         |\n",
      "|    value_loss         | 0.000656    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 42400        |\n",
      "|    time_elapsed       | 689          |\n",
      "|    total_timesteps    | 212000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.3        |\n",
      "|    explained_variance | 0.219        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42399        |\n",
      "|    policy_loss        | -0.081       |\n",
      "|    reward             | -0.023075134 |\n",
      "|    std                | 511          |\n",
      "|    value_loss         | 0.000131     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 42500       |\n",
      "|    time_elapsed       | 690         |\n",
      "|    total_timesteps    | 212500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.3       |\n",
      "|    explained_variance | 0.335       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 42499       |\n",
      "|    policy_loss        | -0.0816     |\n",
      "|    reward             | 0.017169982 |\n",
      "|    std                | 518         |\n",
      "|    value_loss         | 0.000383    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 42600       |\n",
      "|    time_elapsed       | 692         |\n",
      "|    total_timesteps    | 213000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.4       |\n",
      "|    explained_variance | 0.13        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 42599       |\n",
      "|    policy_loss        | -0.434      |\n",
      "|    reward             | -0.01048139 |\n",
      "|    std                | 524         |\n",
      "|    value_loss         | 0.0014      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 42700      |\n",
      "|    time_elapsed       | 693        |\n",
      "|    total_timesteps    | 213500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.4      |\n",
      "|    explained_variance | 0.334      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 42699      |\n",
      "|    policy_loss        | -0.235     |\n",
      "|    reward             | 0.10658062 |\n",
      "|    std                | 536        |\n",
      "|    value_loss         | 0.0146     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 42800        |\n",
      "|    time_elapsed       | 695          |\n",
      "|    total_timesteps    | 214000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.4        |\n",
      "|    explained_variance | 0.0596       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 42799        |\n",
      "|    policy_loss        | 5.56         |\n",
      "|    reward             | -0.075956605 |\n",
      "|    std                | 532          |\n",
      "|    value_loss         | 0.278        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 42900       |\n",
      "|    time_elapsed       | 697         |\n",
      "|    total_timesteps    | 214500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.4       |\n",
      "|    explained_variance | -0.828      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 42899       |\n",
      "|    policy_loss        | -0.121      |\n",
      "|    reward             | 0.009490751 |\n",
      "|    std                | 530         |\n",
      "|    value_loss         | 0.000141    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 307            |\n",
      "|    iterations         | 43000          |\n",
      "|    time_elapsed       | 699            |\n",
      "|    total_timesteps    | 215000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -15.4          |\n",
      "|    explained_variance | -5.16          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 42999          |\n",
      "|    policy_loss        | 0.395          |\n",
      "|    reward             | -0.00014295807 |\n",
      "|    std                | 538            |\n",
      "|    value_loss         | 0.000852       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 43100       |\n",
      "|    time_elapsed       | 700         |\n",
      "|    total_timesteps    | 215500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43099       |\n",
      "|    policy_loss        | 0.0884      |\n",
      "|    reward             | 0.008393686 |\n",
      "|    std                | 550         |\n",
      "|    value_loss         | 6.74e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 43200       |\n",
      "|    time_elapsed       | 702         |\n",
      "|    total_timesteps    | 216000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.5       |\n",
      "|    explained_variance | 0.42        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43199       |\n",
      "|    policy_loss        | -0.0417     |\n",
      "|    reward             | -0.07050285 |\n",
      "|    std                | 563         |\n",
      "|    value_loss         | 3.06e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 43300       |\n",
      "|    time_elapsed       | 704         |\n",
      "|    total_timesteps    | 216500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.5       |\n",
      "|    explained_variance | -1.68e-05   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43299       |\n",
      "|    policy_loss        | 0.564       |\n",
      "|    reward             | 0.012701165 |\n",
      "|    std                | 573         |\n",
      "|    value_loss         | 0.00183     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 43400       |\n",
      "|    time_elapsed       | 705         |\n",
      "|    total_timesteps    | 217000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.5       |\n",
      "|    explained_variance | 0.00227     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43399       |\n",
      "|    policy_loss        | 0.356       |\n",
      "|    reward             | 0.023223262 |\n",
      "|    std                | 571         |\n",
      "|    value_loss         | 0.000558    |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 75\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 54012.80\n",
      "total_reward: 44012.80\n",
      "total_cost: 18.16\n",
      "total_trades: 5792\n",
      "Sharpe: 0.641\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 43500        |\n",
      "|    time_elapsed       | 707          |\n",
      "|    total_timesteps    | 217500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.5        |\n",
      "|    explained_variance | 0.0663       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 43499        |\n",
      "|    policy_loss        | 0.522        |\n",
      "|    reward             | -0.048408266 |\n",
      "|    std                | 575          |\n",
      "|    value_loss         | 0.00148      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 43600       |\n",
      "|    time_elapsed       | 708         |\n",
      "|    total_timesteps    | 218000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.6       |\n",
      "|    explained_variance | 0.0815      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 43599       |\n",
      "|    policy_loss        | -0.142      |\n",
      "|    reward             | 0.019960864 |\n",
      "|    std                | 579         |\n",
      "|    value_loss         | 0.000144    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 43700      |\n",
      "|    time_elapsed       | 710        |\n",
      "|    total_timesteps    | 218500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.6      |\n",
      "|    explained_variance | 0.0208     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 43699      |\n",
      "|    policy_loss        | 0.862      |\n",
      "|    reward             | 0.05722469 |\n",
      "|    std                | 596        |\n",
      "|    value_loss         | 0.00497    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 43800        |\n",
      "|    time_elapsed       | 712          |\n",
      "|    total_timesteps    | 219000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.7        |\n",
      "|    explained_variance | -0.00767     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 43799        |\n",
      "|    policy_loss        | -0.916       |\n",
      "|    reward             | -0.009265357 |\n",
      "|    std                | 608          |\n",
      "|    value_loss         | 0.00912      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 307       |\n",
      "|    iterations         | 43900     |\n",
      "|    time_elapsed       | 713       |\n",
      "|    total_timesteps    | 219500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.7     |\n",
      "|    explained_variance | 0.0855    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 43899     |\n",
      "|    policy_loss        | 2.23      |\n",
      "|    reward             | 0.1447376 |\n",
      "|    std                | 614       |\n",
      "|    value_loss         | 0.0329    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 44000      |\n",
      "|    time_elapsed       | 715        |\n",
      "|    total_timesteps    | 220000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.7      |\n",
      "|    explained_variance | -0.0595    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 43999      |\n",
      "|    policy_loss        | 4.97       |\n",
      "|    reward             | 0.26546428 |\n",
      "|    std                | 624        |\n",
      "|    value_loss         | 0.139      |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 307            |\n",
      "|    iterations         | 44100          |\n",
      "|    time_elapsed       | 717            |\n",
      "|    total_timesteps    | 220500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -15.7          |\n",
      "|    explained_variance | 0.317          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 44099          |\n",
      "|    policy_loss        | 0.687          |\n",
      "|    reward             | -0.00051174965 |\n",
      "|    std                | 628            |\n",
      "|    value_loss         | 0.00231        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 44200         |\n",
      "|    time_elapsed       | 718           |\n",
      "|    total_timesteps    | 221000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.8         |\n",
      "|    explained_variance | -1.31         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 44199         |\n",
      "|    policy_loss        | -0.181        |\n",
      "|    reward             | -0.0022130334 |\n",
      "|    std                | 637           |\n",
      "|    value_loss         | 0.00016       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 44300        |\n",
      "|    time_elapsed       | 720          |\n",
      "|    total_timesteps    | 221500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.8        |\n",
      "|    explained_variance | 0.764        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44299        |\n",
      "|    policy_loss        | 0.211        |\n",
      "|    reward             | 0.0043243235 |\n",
      "|    std                | 649          |\n",
      "|    value_loss         | 0.000206     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 44400        |\n",
      "|    time_elapsed       | 722          |\n",
      "|    total_timesteps    | 222000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.9        |\n",
      "|    explained_variance | -6.08e-06    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44399        |\n",
      "|    policy_loss        | -0.283       |\n",
      "|    reward             | 0.0041077877 |\n",
      "|    std                | 675          |\n",
      "|    value_loss         | 0.000789     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 44500       |\n",
      "|    time_elapsed       | 723         |\n",
      "|    total_timesteps    | 222500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.9       |\n",
      "|    explained_variance | 0.514       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44499       |\n",
      "|    policy_loss        | -0.23       |\n",
      "|    reward             | -0.01837174 |\n",
      "|    std                | 695         |\n",
      "|    value_loss         | 0.000224    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 44600        |\n",
      "|    time_elapsed       | 725          |\n",
      "|    total_timesteps    | 223000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16          |\n",
      "|    explained_variance | 0.195        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44599        |\n",
      "|    policy_loss        | -0.541       |\n",
      "|    reward             | -0.020598724 |\n",
      "|    std                | 719          |\n",
      "|    value_loss         | 0.00147      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 44700         |\n",
      "|    time_elapsed       | 726           |\n",
      "|    total_timesteps    | 223500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16           |\n",
      "|    explained_variance | -3.47         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 44699         |\n",
      "|    policy_loss        | -0.116        |\n",
      "|    reward             | -0.0062217736 |\n",
      "|    std                | 731           |\n",
      "|    value_loss         | 6.64e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 44800        |\n",
      "|    time_elapsed       | 728          |\n",
      "|    total_timesteps    | 224000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.1        |\n",
      "|    explained_variance | -0.000938    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 44799        |\n",
      "|    policy_loss        | -0.0822      |\n",
      "|    reward             | -0.009536288 |\n",
      "|    std                | 752          |\n",
      "|    value_loss         | 5.15e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 44900       |\n",
      "|    time_elapsed       | 730         |\n",
      "|    total_timesteps    | 224500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.1       |\n",
      "|    explained_variance | -0.0366     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44899       |\n",
      "|    policy_loss        | 0.585       |\n",
      "|    reward             | 0.002273098 |\n",
      "|    std                | 778         |\n",
      "|    value_loss         | 0.00187     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 45000       |\n",
      "|    time_elapsed       | 731         |\n",
      "|    total_timesteps    | 225000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.2       |\n",
      "|    explained_variance | 0.0459      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 44999       |\n",
      "|    policy_loss        | 0.144       |\n",
      "|    reward             | 0.057925757 |\n",
      "|    std                | 791         |\n",
      "|    value_loss         | 0.00165     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 45100        |\n",
      "|    time_elapsed       | 733          |\n",
      "|    total_timesteps    | 225500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.2        |\n",
      "|    explained_variance | 0.0305       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45099        |\n",
      "|    policy_loss        | 1.08         |\n",
      "|    reward             | -0.014719391 |\n",
      "|    std                | 796          |\n",
      "|    value_loss         | 0.00493      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 45200      |\n",
      "|    time_elapsed       | 735        |\n",
      "|    total_timesteps    | 226000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.2      |\n",
      "|    explained_variance | 0.514      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 45199      |\n",
      "|    policy_loss        | -0.095     |\n",
      "|    reward             | -0.0352429 |\n",
      "|    std                | 806        |\n",
      "|    value_loss         | 0.000249   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 45300        |\n",
      "|    time_elapsed       | 736          |\n",
      "|    total_timesteps    | 226500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.2        |\n",
      "|    explained_variance | 0.129        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45299        |\n",
      "|    policy_loss        | -0.785       |\n",
      "|    reward             | -0.010879715 |\n",
      "|    std                | 812          |\n",
      "|    value_loss         | 0.0031       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 45400       |\n",
      "|    time_elapsed       | 738         |\n",
      "|    total_timesteps    | 227000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.3       |\n",
      "|    explained_variance | 0.122       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 45399       |\n",
      "|    policy_loss        | 0.69        |\n",
      "|    reward             | 0.042534128 |\n",
      "|    std                | 820         |\n",
      "|    value_loss         | 0.00234     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 45500       |\n",
      "|    time_elapsed       | 740         |\n",
      "|    total_timesteps    | 227500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.3       |\n",
      "|    explained_variance | 0.0392      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 45499       |\n",
      "|    policy_loss        | -0.727      |\n",
      "|    reward             | 0.020499403 |\n",
      "|    std                | 828         |\n",
      "|    value_loss         | 0.00229     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 45600       |\n",
      "|    time_elapsed       | 741         |\n",
      "|    total_timesteps    | 228000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.3       |\n",
      "|    explained_variance | 0.0667      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 45599       |\n",
      "|    policy_loss        | -3.7        |\n",
      "|    reward             | 0.028266348 |\n",
      "|    std                | 838         |\n",
      "|    value_loss         | 0.064       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 45700      |\n",
      "|    time_elapsed       | 743        |\n",
      "|    total_timesteps    | 228500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.3      |\n",
      "|    explained_variance | 0.26       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 45699      |\n",
      "|    policy_loss        | -1.69      |\n",
      "|    reward             | 0.06291629 |\n",
      "|    std                | 849        |\n",
      "|    value_loss         | 0.016      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 45800       |\n",
      "|    time_elapsed       | 745         |\n",
      "|    total_timesteps    | 229000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.3       |\n",
      "|    explained_variance | 0.0875      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 45799       |\n",
      "|    policy_loss        | -0.141      |\n",
      "|    reward             | 0.008869532 |\n",
      "|    std                | 850         |\n",
      "|    value_loss         | 0.000297    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 45900        |\n",
      "|    time_elapsed       | 747          |\n",
      "|    total_timesteps    | 229500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.3        |\n",
      "|    explained_variance | 0.659        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45899        |\n",
      "|    policy_loss        | 0.116        |\n",
      "|    reward             | -0.014766862 |\n",
      "|    std                | 854          |\n",
      "|    value_loss         | 0.000139     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 46000        |\n",
      "|    time_elapsed       | 748          |\n",
      "|    total_timesteps    | 230000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.4        |\n",
      "|    explained_variance | -0.374       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 45999        |\n",
      "|    policy_loss        | -0.643       |\n",
      "|    reward             | -0.060395177 |\n",
      "|    std                | 873          |\n",
      "|    value_loss         | 0.00238      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 46100       |\n",
      "|    time_elapsed       | 750         |\n",
      "|    total_timesteps    | 230500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.4       |\n",
      "|    explained_variance | -1.25       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46099       |\n",
      "|    policy_loss        | -0.948      |\n",
      "|    reward             | 0.025282731 |\n",
      "|    std                | 889         |\n",
      "|    value_loss         | 0.00333     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 46200        |\n",
      "|    time_elapsed       | 752          |\n",
      "|    total_timesteps    | 231000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.4        |\n",
      "|    explained_variance | 0.0299       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46199        |\n",
      "|    policy_loss        | 2.14         |\n",
      "|    reward             | -0.036395837 |\n",
      "|    std                | 901          |\n",
      "|    value_loss         | 0.0204       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 46300      |\n",
      "|    time_elapsed       | 753        |\n",
      "|    total_timesteps    | 231500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.5      |\n",
      "|    explained_variance | 0.346      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 46299      |\n",
      "|    policy_loss        | 3.12       |\n",
      "|    reward             | 0.18287528 |\n",
      "|    std                | 915        |\n",
      "|    value_loss         | 0.0408     |\n",
      "--------------------------------------\n",
      "day: 2896, episode: 80\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 135727.68\n",
      "total_reward: 125727.68\n",
      "total_cost: 13.38\n",
      "total_trades: 5785\n",
      "Sharpe: 0.933\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 46400        |\n",
      "|    time_elapsed       | 755          |\n",
      "|    total_timesteps    | 232000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.5        |\n",
      "|    explained_variance | -0.821       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46399        |\n",
      "|    policy_loss        | -0.287       |\n",
      "|    reward             | 0.0015404628 |\n",
      "|    std                | 919          |\n",
      "|    value_loss         | 0.00042      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 46500        |\n",
      "|    time_elapsed       | 756          |\n",
      "|    total_timesteps    | 232500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.5        |\n",
      "|    explained_variance | -3.58e-06    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46499        |\n",
      "|    policy_loss        | -0.253       |\n",
      "|    reward             | 0.0032706128 |\n",
      "|    std                | 929          |\n",
      "|    value_loss         | 0.000261     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 46600        |\n",
      "|    time_elapsed       | 758          |\n",
      "|    total_timesteps    | 233000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.5        |\n",
      "|    explained_variance | -0.191       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46599        |\n",
      "|    policy_loss        | 2.89         |\n",
      "|    reward             | -0.046404753 |\n",
      "|    std                | 936          |\n",
      "|    value_loss         | 0.0454       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 46700      |\n",
      "|    time_elapsed       | 760        |\n",
      "|    total_timesteps    | 233500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.5      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 46699      |\n",
      "|    policy_loss        | 1.46       |\n",
      "|    reward             | 0.07510297 |\n",
      "|    std                | 948        |\n",
      "|    value_loss         | 0.0103     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 46800       |\n",
      "|    time_elapsed       | 761         |\n",
      "|    total_timesteps    | 234000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.6       |\n",
      "|    explained_variance | 0.0456      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 46799       |\n",
      "|    policy_loss        | 0.281       |\n",
      "|    reward             | -0.06848008 |\n",
      "|    std                | 968         |\n",
      "|    value_loss         | 0.00167     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 46900      |\n",
      "|    time_elapsed       | 763        |\n",
      "|    total_timesteps    | 234500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.6      |\n",
      "|    explained_variance | -3.81e-06  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 46899      |\n",
      "|    policy_loss        | 1.81       |\n",
      "|    reward             | 0.13980037 |\n",
      "|    std                | 954        |\n",
      "|    value_loss         | 0.0146     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 47000        |\n",
      "|    time_elapsed       | 765          |\n",
      "|    total_timesteps    | 235000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.6        |\n",
      "|    explained_variance | 0.775        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 46999        |\n",
      "|    policy_loss        | -0.14        |\n",
      "|    reward             | -0.039220903 |\n",
      "|    std                | 965          |\n",
      "|    value_loss         | 0.000194     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 47100        |\n",
      "|    time_elapsed       | 766          |\n",
      "|    total_timesteps    | 235500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.6        |\n",
      "|    explained_variance | 0.127        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47099        |\n",
      "|    policy_loss        | -0.347       |\n",
      "|    reward             | 0.0025172953 |\n",
      "|    std                | 983          |\n",
      "|    value_loss         | 0.0006       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 307            |\n",
      "|    iterations         | 47200          |\n",
      "|    time_elapsed       | 768            |\n",
      "|    total_timesteps    | 236000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -16.7          |\n",
      "|    explained_variance | -0.0793        |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 47199          |\n",
      "|    policy_loss        | 0.472          |\n",
      "|    reward             | -0.00024118119 |\n",
      "|    std                | 1.01e+03       |\n",
      "|    value_loss         | 0.000948       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 47300       |\n",
      "|    time_elapsed       | 769         |\n",
      "|    total_timesteps    | 236500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.7       |\n",
      "|    explained_variance | -0.161      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 47299       |\n",
      "|    policy_loss        | -0.325      |\n",
      "|    reward             | 0.018657623 |\n",
      "|    std                | 1.03e+03    |\n",
      "|    value_loss         | 0.000466    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 47400        |\n",
      "|    time_elapsed       | 771          |\n",
      "|    total_timesteps    | 237000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.8        |\n",
      "|    explained_variance | -0.109       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47399        |\n",
      "|    policy_loss        | -0.967       |\n",
      "|    reward             | -0.015298184 |\n",
      "|    std                | 1.07e+03     |\n",
      "|    value_loss         | 0.00509      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 47500        |\n",
      "|    time_elapsed       | 772          |\n",
      "|    total_timesteps    | 237500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47499        |\n",
      "|    policy_loss        | -0.893       |\n",
      "|    reward             | -0.028544856 |\n",
      "|    std                | 1.1e+03      |\n",
      "|    value_loss         | 0.00316      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 47600         |\n",
      "|    time_elapsed       | 774           |\n",
      "|    total_timesteps    | 238000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.9         |\n",
      "|    explained_variance | 0.115         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 47599         |\n",
      "|    policy_loss        | 0.0848        |\n",
      "|    reward             | -0.0006367025 |\n",
      "|    std                | 1.12e+03      |\n",
      "|    value_loss         | 7.35e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 47700        |\n",
      "|    time_elapsed       | 776          |\n",
      "|    total_timesteps    | 238500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.9        |\n",
      "|    explained_variance | -0.426       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47699        |\n",
      "|    policy_loss        | -0.0635      |\n",
      "|    reward             | 0.0043585435 |\n",
      "|    std                | 1.15e+03     |\n",
      "|    value_loss         | 0.00013      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 47800       |\n",
      "|    time_elapsed       | 777         |\n",
      "|    total_timesteps    | 239000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17         |\n",
      "|    explained_variance | -0.0189     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 47799       |\n",
      "|    policy_loss        | 0.527       |\n",
      "|    reward             | 0.020114075 |\n",
      "|    std                | 1.18e+03    |\n",
      "|    value_loss         | 0.00144     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 47900        |\n",
      "|    time_elapsed       | 779          |\n",
      "|    total_timesteps    | 239500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17          |\n",
      "|    explained_variance | 0.0914       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 47899        |\n",
      "|    policy_loss        | -0.532       |\n",
      "|    reward             | -0.046403807 |\n",
      "|    std                | 1.2e+03      |\n",
      "|    value_loss         | 0.00144      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 48000      |\n",
      "|    time_elapsed       | 780        |\n",
      "|    total_timesteps    | 240000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -17        |\n",
      "|    explained_variance | 0.102      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 47999      |\n",
      "|    policy_loss        | 1.21       |\n",
      "|    reward             | 0.04235068 |\n",
      "|    std                | 1.21e+03   |\n",
      "|    value_loss         | 0.00605    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 48100        |\n",
      "|    time_elapsed       | 782          |\n",
      "|    total_timesteps    | 240500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.1        |\n",
      "|    explained_variance | 0.0929       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48099        |\n",
      "|    policy_loss        | -0.633       |\n",
      "|    reward             | 0.0025568525 |\n",
      "|    std                | 1.23e+03     |\n",
      "|    value_loss         | 0.0015       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 48200        |\n",
      "|    time_elapsed       | 783          |\n",
      "|    total_timesteps    | 241000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.1        |\n",
      "|    explained_variance | 0.441        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48199        |\n",
      "|    policy_loss        | 0.176        |\n",
      "|    reward             | 0.0043364963 |\n",
      "|    std                | 1.25e+03     |\n",
      "|    value_loss         | 0.000122     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 48300        |\n",
      "|    time_elapsed       | 785          |\n",
      "|    total_timesteps    | 241500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.1        |\n",
      "|    explained_variance | -0.229       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48299        |\n",
      "|    policy_loss        | 0.183        |\n",
      "|    reward             | 0.0029884782 |\n",
      "|    std                | 1.28e+03     |\n",
      "|    value_loss         | 0.000162     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 48400        |\n",
      "|    time_elapsed       | 786          |\n",
      "|    total_timesteps    | 242000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.2        |\n",
      "|    explained_variance | 0.468        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48399        |\n",
      "|    policy_loss        | 0.17         |\n",
      "|    reward             | 0.0010096172 |\n",
      "|    std                | 1.32e+03     |\n",
      "|    value_loss         | 0.000152     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 48500        |\n",
      "|    time_elapsed       | 788          |\n",
      "|    total_timesteps    | 242500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.3        |\n",
      "|    explained_variance | 0.516        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48499        |\n",
      "|    policy_loss        | -1.29        |\n",
      "|    reward             | -0.009726974 |\n",
      "|    std                | 1.37e+03     |\n",
      "|    value_loss         | 0.00537      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 48600       |\n",
      "|    time_elapsed       | 789         |\n",
      "|    total_timesteps    | 243000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.3       |\n",
      "|    explained_variance | 0.0444      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48599       |\n",
      "|    policy_loss        | 0.985       |\n",
      "|    reward             | 0.033118762 |\n",
      "|    std                | 1.4e+03     |\n",
      "|    value_loss         | 0.0038      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 48700        |\n",
      "|    time_elapsed       | 791          |\n",
      "|    total_timesteps    | 243500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.4        |\n",
      "|    explained_variance | 0.118        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 48699        |\n",
      "|    policy_loss        | 0.5          |\n",
      "|    reward             | 0.0031715366 |\n",
      "|    std                | 1.44e+03     |\n",
      "|    value_loss         | 0.000886     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 48800       |\n",
      "|    time_elapsed       | 792         |\n",
      "|    total_timesteps    | 244000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.4       |\n",
      "|    explained_variance | 0.484       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48799       |\n",
      "|    policy_loss        | -0.172      |\n",
      "|    reward             | 0.037989385 |\n",
      "|    std                | 1.48e+03    |\n",
      "|    value_loss         | 0.000177    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 48900      |\n",
      "|    time_elapsed       | 794        |\n",
      "|    total_timesteps    | 244500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -17.5      |\n",
      "|    explained_variance | 0.086      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 48899      |\n",
      "|    policy_loss        | 2.9        |\n",
      "|    reward             | 0.06576608 |\n",
      "|    std                | 1.51e+03   |\n",
      "|    value_loss         | 0.0301     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 49000       |\n",
      "|    time_elapsed       | 796         |\n",
      "|    total_timesteps    | 245000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.5       |\n",
      "|    explained_variance | 0.3         |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 48999       |\n",
      "|    policy_loss        | -1.22       |\n",
      "|    reward             | -0.01457184 |\n",
      "|    std                | 1.53e+03    |\n",
      "|    value_loss         | 0.00809     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 49100       |\n",
      "|    time_elapsed       | 797         |\n",
      "|    total_timesteps    | 245500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.5       |\n",
      "|    explained_variance | 1.98e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49099       |\n",
      "|    policy_loss        | -6.32       |\n",
      "|    reward             | -0.03153812 |\n",
      "|    std                | 1.53e+03    |\n",
      "|    value_loss         | 0.139       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 49200        |\n",
      "|    time_elapsed       | 799          |\n",
      "|    total_timesteps    | 246000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.5        |\n",
      "|    explained_variance | 0.0915       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 49199        |\n",
      "|    policy_loss        | -0.472       |\n",
      "|    reward             | -0.026887225 |\n",
      "|    std                | 1.54e+03     |\n",
      "|    value_loss         | 0.0133       |\n",
      "----------------------------------------\n",
      "day: 2896, episode: 85\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 151941.21\n",
      "total_reward: 141941.21\n",
      "total_cost: 14.96\n",
      "total_trades: 5787\n",
      "Sharpe: 0.847\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 49300       |\n",
      "|    time_elapsed       | 801         |\n",
      "|    total_timesteps    | 246500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.5       |\n",
      "|    explained_variance | -15.5       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49299       |\n",
      "|    policy_loss        | -0.0975     |\n",
      "|    reward             | 0.008113744 |\n",
      "|    std                | 1.56e+03    |\n",
      "|    value_loss         | 7.2e-05     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 49400         |\n",
      "|    time_elapsed       | 803           |\n",
      "|    total_timesteps    | 247000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -17.6         |\n",
      "|    explained_variance | 0.718         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 49399         |\n",
      "|    policy_loss        | 0.112         |\n",
      "|    reward             | -0.0035722137 |\n",
      "|    std                | 1.59e+03      |\n",
      "|    value_loss         | 4.42e-05      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 49500       |\n",
      "|    time_elapsed       | 805         |\n",
      "|    total_timesteps    | 247500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.6       |\n",
      "|    explained_variance | 0.746       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49499       |\n",
      "|    policy_loss        | 0.213       |\n",
      "|    reward             | 0.021651758 |\n",
      "|    std                | 1.61e+03    |\n",
      "|    value_loss         | 0.000187    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 49600       |\n",
      "|    time_elapsed       | 806         |\n",
      "|    total_timesteps    | 248000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49599       |\n",
      "|    policy_loss        | 0.27        |\n",
      "|    reward             | 0.011411033 |\n",
      "|    std                | 1.65e+03    |\n",
      "|    value_loss         | 0.000414    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 49700       |\n",
      "|    time_elapsed       | 808         |\n",
      "|    total_timesteps    | 248500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.7       |\n",
      "|    explained_variance | 0.271       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49699       |\n",
      "|    policy_loss        | 0.0112      |\n",
      "|    reward             | 0.031129554 |\n",
      "|    std                | 1.7e+03     |\n",
      "|    value_loss         | 0.000718    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 49800        |\n",
      "|    time_elapsed       | 809          |\n",
      "|    total_timesteps    | 249000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.7        |\n",
      "|    explained_variance | 0.0504       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 49799        |\n",
      "|    policy_loss        | -3.2         |\n",
      "|    reward             | -0.018284595 |\n",
      "|    std                | 1.71e+03     |\n",
      "|    value_loss         | 0.0458       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 49900        |\n",
      "|    time_elapsed       | 811          |\n",
      "|    total_timesteps    | 249500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.8        |\n",
      "|    explained_variance | -0.000147    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 49899        |\n",
      "|    policy_loss        | 1.08         |\n",
      "|    reward             | 0.0044361674 |\n",
      "|    std                | 1.75e+03     |\n",
      "|    value_loss         | 0.00592      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 50000       |\n",
      "|    time_elapsed       | 812         |\n",
      "|    total_timesteps    | 250000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.8       |\n",
      "|    explained_variance | 0.255       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 49999       |\n",
      "|    policy_loss        | 0.0217      |\n",
      "|    reward             | 0.020098668 |\n",
      "|    std                | 1.8e+03     |\n",
      "|    value_loss         | 3.64e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 50100       |\n",
      "|    time_elapsed       | 814         |\n",
      "|    total_timesteps    | 250500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.9       |\n",
      "|    explained_variance | 0.0571      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50099       |\n",
      "|    policy_loss        | -0.0957     |\n",
      "|    reward             | -0.06433427 |\n",
      "|    std                | 1.83e+03    |\n",
      "|    value_loss         | 0.00204     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 50200       |\n",
      "|    time_elapsed       | 815         |\n",
      "|    total_timesteps    | 251000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.9       |\n",
      "|    explained_variance | 0.195       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50199       |\n",
      "|    policy_loss        | -3.27       |\n",
      "|    reward             | -0.13313584 |\n",
      "|    std                | 1.85e+03    |\n",
      "|    value_loss         | 0.035       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 50300      |\n",
      "|    time_elapsed       | 817        |\n",
      "|    total_timesteps    | 251500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -17.9      |\n",
      "|    explained_variance | 0.139      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 50299      |\n",
      "|    policy_loss        | -2.27      |\n",
      "|    reward             | -0.2552749 |\n",
      "|    std                | 1.86e+03   |\n",
      "|    value_loss         | 0.0489     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 50400       |\n",
      "|    time_elapsed       | 818         |\n",
      "|    total_timesteps    | 252000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -17.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50399       |\n",
      "|    policy_loss        | 1.47        |\n",
      "|    reward             | 0.010986426 |\n",
      "|    std                | 1.83e+03    |\n",
      "|    value_loss         | 0.0149      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 50500        |\n",
      "|    time_elapsed       | 820          |\n",
      "|    total_timesteps    | 252500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50499        |\n",
      "|    policy_loss        | 0.306        |\n",
      "|    reward             | 0.0037502407 |\n",
      "|    std                | 1.86e+03     |\n",
      "|    value_loss         | 0.00163      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 50600        |\n",
      "|    time_elapsed       | 821          |\n",
      "|    total_timesteps    | 253000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -17.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50599        |\n",
      "|    policy_loss        | 0.608        |\n",
      "|    reward             | 0.0070350054 |\n",
      "|    std                | 1.89e+03     |\n",
      "|    value_loss         | 0.00265      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 50700        |\n",
      "|    time_elapsed       | 823          |\n",
      "|    total_timesteps    | 253500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18          |\n",
      "|    explained_variance | 0.352        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50699        |\n",
      "|    policy_loss        | -3.41        |\n",
      "|    reward             | 0.0136597995 |\n",
      "|    std                | 1.95e+03     |\n",
      "|    value_loss         | 0.039        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 50800       |\n",
      "|    time_elapsed       | 825         |\n",
      "|    total_timesteps    | 254000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18         |\n",
      "|    explained_variance | 0.198       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 50799       |\n",
      "|    policy_loss        | 2.23        |\n",
      "|    reward             | -0.03546819 |\n",
      "|    std                | 1.98e+03    |\n",
      "|    value_loss         | 0.0305      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 50900      |\n",
      "|    time_elapsed       | 827        |\n",
      "|    total_timesteps    | 254500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18        |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 50899      |\n",
      "|    policy_loss        | -2.19      |\n",
      "|    reward             | -0.1547963 |\n",
      "|    std                | 2e+03      |\n",
      "|    value_loss         | 0.0192     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 51000        |\n",
      "|    time_elapsed       | 828          |\n",
      "|    total_timesteps    | 255000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.1        |\n",
      "|    explained_variance | -0.0655      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 50999        |\n",
      "|    policy_loss        | -0.826       |\n",
      "|    reward             | -0.003596802 |\n",
      "|    std                | 2.04e+03     |\n",
      "|    value_loss         | 0.00264      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 51100       |\n",
      "|    time_elapsed       | 830         |\n",
      "|    total_timesteps    | 255500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.1       |\n",
      "|    explained_variance | 0.113       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51099       |\n",
      "|    policy_loss        | 0.197       |\n",
      "|    reward             | 0.003008883 |\n",
      "|    std                | 2.07e+03    |\n",
      "|    value_loss         | 0.000135    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 51200         |\n",
      "|    time_elapsed       | 831           |\n",
      "|    total_timesteps    | 256000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.1         |\n",
      "|    explained_variance | -1.27         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 51199         |\n",
      "|    policy_loss        | 0.0354        |\n",
      "|    reward             | -0.0049662185 |\n",
      "|    std                | 2.11e+03      |\n",
      "|    value_loss         | 4.76e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 51300        |\n",
      "|    time_elapsed       | 833          |\n",
      "|    total_timesteps    | 256500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51299        |\n",
      "|    policy_loss        | -0.337       |\n",
      "|    reward             | -0.005831068 |\n",
      "|    std                | 2.17e+03     |\n",
      "|    value_loss         | 0.00032      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 51400        |\n",
      "|    time_elapsed       | 835          |\n",
      "|    total_timesteps    | 257000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.3        |\n",
      "|    explained_variance | 0.518        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51399        |\n",
      "|    policy_loss        | 0.821        |\n",
      "|    reward             | 0.0041623674 |\n",
      "|    std                | 2.25e+03     |\n",
      "|    value_loss         | 0.00214      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 51500        |\n",
      "|    time_elapsed       | 836          |\n",
      "|    total_timesteps    | 257500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51499        |\n",
      "|    policy_loss        | 0.926        |\n",
      "|    reward             | -0.011730112 |\n",
      "|    std                | 2.3e+03      |\n",
      "|    value_loss         | 0.00296      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 51600        |\n",
      "|    time_elapsed       | 838          |\n",
      "|    total_timesteps    | 258000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51599        |\n",
      "|    policy_loss        | 0.0345       |\n",
      "|    reward             | -0.008462157 |\n",
      "|    std                | 2.32e+03     |\n",
      "|    value_loss         | 0.000127     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 51700      |\n",
      "|    time_elapsed       | 840        |\n",
      "|    total_timesteps    | 258500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.4      |\n",
      "|    explained_variance | -0.254     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 51699      |\n",
      "|    policy_loss        | -0.189     |\n",
      "|    reward             | 0.01860919 |\n",
      "|    std                | 2.39e+03   |\n",
      "|    value_loss         | 0.000135   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 51800       |\n",
      "|    time_elapsed       | 841         |\n",
      "|    total_timesteps    | 259000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 51799       |\n",
      "|    policy_loss        | 0.167       |\n",
      "|    reward             | 0.022945093 |\n",
      "|    std                | 2.46e+03    |\n",
      "|    value_loss         | 0.00025     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 51900        |\n",
      "|    time_elapsed       | 843          |\n",
      "|    total_timesteps    | 259500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.5        |\n",
      "|    explained_variance | 0.88         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 51899        |\n",
      "|    policy_loss        | 0.19         |\n",
      "|    reward             | -0.014733683 |\n",
      "|    std                | 2.52e+03     |\n",
      "|    value_loss         | 0.000148     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 52000      |\n",
      "|    time_elapsed       | 844        |\n",
      "|    total_timesteps    | 260000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.5      |\n",
      "|    explained_variance | 0.00681    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 51999      |\n",
      "|    policy_loss        | 1.54       |\n",
      "|    reward             | 0.10605254 |\n",
      "|    std                | 2.53e+03   |\n",
      "|    value_loss         | 0.0101     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 52100       |\n",
      "|    time_elapsed       | 846         |\n",
      "|    total_timesteps    | 260500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.5       |\n",
      "|    explained_variance | 0.109       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52099       |\n",
      "|    policy_loss        | -2.91       |\n",
      "|    reward             | 0.060209803 |\n",
      "|    std                | 2.56e+03    |\n",
      "|    value_loss         | 0.027       |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 90\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 87333.71\n",
      "total_reward: 77333.71\n",
      "total_cost: 12.32\n",
      "total_trades: 5791\n",
      "Sharpe: 0.760\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 52200       |\n",
      "|    time_elapsed       | 848         |\n",
      "|    total_timesteps    | 261000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.6       |\n",
      "|    explained_variance | 0.438       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52199       |\n",
      "|    policy_loss        | -0.036      |\n",
      "|    reward             | 0.016898094 |\n",
      "|    std                | 2.58e+03    |\n",
      "|    value_loss         | 4.75e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 52300        |\n",
      "|    time_elapsed       | 849          |\n",
      "|    total_timesteps    | 261500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.6        |\n",
      "|    explained_variance | 0.557        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52299        |\n",
      "|    policy_loss        | -0.254       |\n",
      "|    reward             | 0.0051646912 |\n",
      "|    std                | 2.63e+03     |\n",
      "|    value_loss         | 0.000253     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 52400       |\n",
      "|    time_elapsed       | 851         |\n",
      "|    total_timesteps    | 262000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.6       |\n",
      "|    explained_variance | -0.306      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52399       |\n",
      "|    policy_loss        | -0.502      |\n",
      "|    reward             | 0.015354673 |\n",
      "|    std                | 2.68e+03    |\n",
      "|    value_loss         | 0.000828    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 52500       |\n",
      "|    time_elapsed       | 853         |\n",
      "|    total_timesteps    | 262500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52499       |\n",
      "|    policy_loss        | -0.782      |\n",
      "|    reward             | -0.09176943 |\n",
      "|    std                | 2.76e+03    |\n",
      "|    value_loss         | 0.00208     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 52600        |\n",
      "|    time_elapsed       | 855          |\n",
      "|    total_timesteps    | 263000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.7        |\n",
      "|    explained_variance | -0.114       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52599        |\n",
      "|    policy_loss        | 0.84         |\n",
      "|    reward             | -0.016055685 |\n",
      "|    std                | 2.81e+03     |\n",
      "|    value_loss         | 0.00443      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 52700      |\n",
      "|    time_elapsed       | 856        |\n",
      "|    total_timesteps    | 263500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -18.7      |\n",
      "|    explained_variance | 0.224      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 52699      |\n",
      "|    policy_loss        | 2.87       |\n",
      "|    reward             | 0.19477035 |\n",
      "|    std                | 2.84e+03   |\n",
      "|    value_loss         | 0.0334     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 52800        |\n",
      "|    time_elapsed       | 858          |\n",
      "|    total_timesteps    | 264000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -18.8        |\n",
      "|    explained_variance | 1.1e-05      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 52799        |\n",
      "|    policy_loss        | 0.796        |\n",
      "|    reward             | -0.016414104 |\n",
      "|    std                | 2.88e+03     |\n",
      "|    value_loss         | 0.00228      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 52900       |\n",
      "|    time_elapsed       | 860         |\n",
      "|    total_timesteps    | 264500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.8       |\n",
      "|    explained_variance | -0.155      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52899       |\n",
      "|    policy_loss        | 0.128       |\n",
      "|    reward             | 0.024741845 |\n",
      "|    std                | 2.94e+03    |\n",
      "|    value_loss         | 0.00013     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 53000       |\n",
      "|    time_elapsed       | 861         |\n",
      "|    total_timesteps    | 265000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -18.8       |\n",
      "|    explained_variance | 0.545       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 52999       |\n",
      "|    policy_loss        | 0.212       |\n",
      "|    reward             | 0.016747069 |\n",
      "|    std                | 3e+03       |\n",
      "|    value_loss         | 0.00022     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 53100         |\n",
      "|    time_elapsed       | 863           |\n",
      "|    total_timesteps    | 265500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -18.9         |\n",
      "|    explained_variance | -6.68         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 53099         |\n",
      "|    policy_loss        | 0.419         |\n",
      "|    reward             | -0.0057895374 |\n",
      "|    std                | 3.12e+03      |\n",
      "|    value_loss         | 0.000721      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 53200      |\n",
      "|    time_elapsed       | 865        |\n",
      "|    total_timesteps    | 266000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19        |\n",
      "|    explained_variance | 0.197      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 53199      |\n",
      "|    policy_loss        | -0.281     |\n",
      "|    reward             | 0.06979851 |\n",
      "|    std                | 3.2e+03    |\n",
      "|    value_loss         | 0.00116    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 53300      |\n",
      "|    time_elapsed       | 866        |\n",
      "|    total_timesteps    | 266500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 53299      |\n",
      "|    policy_loss        | 2.1        |\n",
      "|    reward             | 0.06971126 |\n",
      "|    std                | 3.24e+03   |\n",
      "|    value_loss         | 0.015      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 53400         |\n",
      "|    time_elapsed       | 868           |\n",
      "|    total_timesteps    | 267000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19           |\n",
      "|    explained_variance | -0.0524       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 53399         |\n",
      "|    policy_loss        | -0.154        |\n",
      "|    reward             | -0.0036152287 |\n",
      "|    std                | 3.31e+03      |\n",
      "|    value_loss         | 7.28e-05      |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                 |                 |\n",
      "|    fps                | 307             |\n",
      "|    iterations         | 53500           |\n",
      "|    time_elapsed       | 870             |\n",
      "|    total_timesteps    | 267500          |\n",
      "| train/                |                 |\n",
      "|    entropy_loss       | -19.1           |\n",
      "|    explained_variance | 0.297           |\n",
      "|    learning_rate      | 0.001           |\n",
      "|    n_updates          | 53499           |\n",
      "|    policy_loss        | 0.182           |\n",
      "|    reward             | -0.000118846896 |\n",
      "|    std                | 3.4e+03         |\n",
      "|    value_loss         | 0.000168        |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 53600        |\n",
      "|    time_elapsed       | 871          |\n",
      "|    total_timesteps    | 268000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.2        |\n",
      "|    explained_variance | 0.0999       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 53599        |\n",
      "|    policy_loss        | 0.2          |\n",
      "|    reward             | -0.012831344 |\n",
      "|    std                | 3.55e+03     |\n",
      "|    value_loss         | 0.000313     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 53700      |\n",
      "|    time_elapsed       | 873        |\n",
      "|    total_timesteps    | 268500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.3      |\n",
      "|    explained_variance | 0.55       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 53699      |\n",
      "|    policy_loss        | -0.85      |\n",
      "|    reward             | 0.03315454 |\n",
      "|    std                | 3.72e+03   |\n",
      "|    value_loss         | 0.00216    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 53800         |\n",
      "|    time_elapsed       | 875           |\n",
      "|    total_timesteps    | 269000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.4         |\n",
      "|    explained_variance | 0.807         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 53799         |\n",
      "|    policy_loss        | -0.877        |\n",
      "|    reward             | -0.0046407166 |\n",
      "|    std                | 3.89e+03      |\n",
      "|    value_loss         | 0.00214       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 53900        |\n",
      "|    time_elapsed       | 876          |\n",
      "|    total_timesteps    | 269500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.5        |\n",
      "|    explained_variance | 0.167        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 53899        |\n",
      "|    policy_loss        | -0.202       |\n",
      "|    reward             | 0.0048278384 |\n",
      "|    std                | 4.06e+03     |\n",
      "|    value_loss         | 0.000202     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 54000      |\n",
      "|    time_elapsed       | 878        |\n",
      "|    total_timesteps    | 270000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.5      |\n",
      "|    explained_variance | 0.139      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 53999      |\n",
      "|    policy_loss        | -0.309     |\n",
      "|    reward             | 0.01633801 |\n",
      "|    std                | 4.16e+03   |\n",
      "|    value_loss         | 0.000455   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 54100        |\n",
      "|    time_elapsed       | 880          |\n",
      "|    total_timesteps    | 270500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.6        |\n",
      "|    explained_variance | -0.0337      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 54099        |\n",
      "|    policy_loss        | -0.399       |\n",
      "|    reward             | 0.0049280813 |\n",
      "|    std                | 4.3e+03      |\n",
      "|    value_loss         | 0.000475     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 54200        |\n",
      "|    time_elapsed       | 881          |\n",
      "|    total_timesteps    | 271000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.7        |\n",
      "|    explained_variance | 0.416        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 54199        |\n",
      "|    policy_loss        | 0.481        |\n",
      "|    reward             | 0.0025760788 |\n",
      "|    std                | 4.51e+03     |\n",
      "|    value_loss         | 0.000877     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 54300      |\n",
      "|    time_elapsed       | 883        |\n",
      "|    total_timesteps    | 271500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.7      |\n",
      "|    explained_variance | 0.801      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 54299      |\n",
      "|    policy_loss        | -0.573     |\n",
      "|    reward             | 0.02447039 |\n",
      "|    std                | 4.65e+03   |\n",
      "|    value_loss         | 0.000982   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 54400      |\n",
      "|    time_elapsed       | 885        |\n",
      "|    total_timesteps    | 272000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -19.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 54399      |\n",
      "|    policy_loss        | 0.269      |\n",
      "|    reward             | 0.03690043 |\n",
      "|    std                | 4.78e+03   |\n",
      "|    value_loss         | 0.000283   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 54500        |\n",
      "|    time_elapsed       | 886          |\n",
      "|    total_timesteps    | 272500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.8        |\n",
      "|    explained_variance | -0.0152      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 54499        |\n",
      "|    policy_loss        | 0.139        |\n",
      "|    reward             | 0.0008829315 |\n",
      "|    std                | 4.9e+03      |\n",
      "|    value_loss         | 6.36e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 54600         |\n",
      "|    time_elapsed       | 888           |\n",
      "|    total_timesteps    | 273000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -19.9         |\n",
      "|    explained_variance | -0.00106      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 54599         |\n",
      "|    policy_loss        | -0.143        |\n",
      "|    reward             | -0.0031048714 |\n",
      "|    std                | 5.04e+03      |\n",
      "|    value_loss         | 6.57e-05      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 54700        |\n",
      "|    time_elapsed       | 890          |\n",
      "|    total_timesteps    | 273500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -19.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 54699        |\n",
      "|    policy_loss        | -0.0316      |\n",
      "|    reward             | -0.029274814 |\n",
      "|    std                | 5.18e+03     |\n",
      "|    value_loss         | 0.00018      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 54800       |\n",
      "|    time_elapsed       | 891         |\n",
      "|    total_timesteps    | 274000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20         |\n",
      "|    explained_variance | 0.0877      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 54799       |\n",
      "|    policy_loss        | -0.402      |\n",
      "|    reward             | 0.014614772 |\n",
      "|    std                | 5.4e+03     |\n",
      "|    value_loss         | 0.000426    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 54900        |\n",
      "|    time_elapsed       | 893          |\n",
      "|    total_timesteps    | 274500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.1        |\n",
      "|    explained_variance | 0.142        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 54899        |\n",
      "|    policy_loss        | 1.06         |\n",
      "|    reward             | 0.0030751862 |\n",
      "|    std                | 5.59e+03     |\n",
      "|    value_loss         | 0.00421      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 55000       |\n",
      "|    time_elapsed       | 894         |\n",
      "|    total_timesteps    | 275000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.2       |\n",
      "|    explained_variance | 0.472       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 54999       |\n",
      "|    policy_loss        | -0.239      |\n",
      "|    reward             | 0.068813376 |\n",
      "|    std                | 5.78e+03    |\n",
      "|    value_loss         | 0.000192    |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 95\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 46864.77\n",
      "total_reward: 36864.77\n",
      "total_cost: 10.22\n",
      "total_trades: 5786\n",
      "Sharpe: 0.606\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 55100       |\n",
      "|    time_elapsed       | 896         |\n",
      "|    total_timesteps    | 275500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.2       |\n",
      "|    explained_variance | 0.0469      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 55099       |\n",
      "|    policy_loss        | 0.362       |\n",
      "|    reward             | 0.009184095 |\n",
      "|    std                | 5.88e+03    |\n",
      "|    value_loss         | 0.000607    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 55200       |\n",
      "|    time_elapsed       | 898         |\n",
      "|    total_timesteps    | 276000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.2       |\n",
      "|    explained_variance | 0.631       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 55199       |\n",
      "|    policy_loss        | 0.492       |\n",
      "|    reward             | 0.020263217 |\n",
      "|    std                | 5.96e+03    |\n",
      "|    value_loss         | 0.000633    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 55300         |\n",
      "|    time_elapsed       | 899           |\n",
      "|    total_timesteps    | 276500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.3         |\n",
      "|    explained_variance | 0.495         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 55299         |\n",
      "|    policy_loss        | -0.02         |\n",
      "|    reward             | -0.0059614615 |\n",
      "|    std                | 6.05e+03      |\n",
      "|    value_loss         | 0.000536      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 55400        |\n",
      "|    time_elapsed       | 901          |\n",
      "|    total_timesteps    | 277000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.3        |\n",
      "|    explained_variance | 0.677        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55399        |\n",
      "|    policy_loss        | 0.561        |\n",
      "|    reward             | -0.015460475 |\n",
      "|    std                | 6.22e+03     |\n",
      "|    value_loss         | 0.00115      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 55500        |\n",
      "|    time_elapsed       | 902          |\n",
      "|    total_timesteps    | 277500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.3        |\n",
      "|    explained_variance | -0.0191      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55499        |\n",
      "|    policy_loss        | -1.49        |\n",
      "|    reward             | -0.004475316 |\n",
      "|    std                | 6.29e+03     |\n",
      "|    value_loss         | 0.00717      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 55600      |\n",
      "|    time_elapsed       | 904        |\n",
      "|    total_timesteps    | 278000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 55599      |\n",
      "|    policy_loss        | -7.26      |\n",
      "|    reward             | 0.10452813 |\n",
      "|    std                | 6.28e+03   |\n",
      "|    value_loss         | 0.128      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 55700        |\n",
      "|    time_elapsed       | 906          |\n",
      "|    total_timesteps    | 278500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.3        |\n",
      "|    explained_variance | 0.0437       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55699        |\n",
      "|    policy_loss        | 0.915        |\n",
      "|    reward             | -0.021403963 |\n",
      "|    std                | 6.33e+03     |\n",
      "|    value_loss         | 0.00274      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 55800       |\n",
      "|    time_elapsed       | 907         |\n",
      "|    total_timesteps    | 279000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 55799       |\n",
      "|    policy_loss        | -0.321      |\n",
      "|    reward             | 0.041005764 |\n",
      "|    std                | 6.41e+03    |\n",
      "|    value_loss         | 0.000272    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 55900       |\n",
      "|    time_elapsed       | 909         |\n",
      "|    total_timesteps    | 279500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.4       |\n",
      "|    explained_variance | 0.22        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 55899       |\n",
      "|    policy_loss        | -1.03       |\n",
      "|    reward             | -0.07482301 |\n",
      "|    std                | 6.56e+03    |\n",
      "|    value_loss         | 0.00412     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 56000        |\n",
      "|    time_elapsed       | 910          |\n",
      "|    total_timesteps    | 280000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.4        |\n",
      "|    explained_variance | 0.606        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 55999        |\n",
      "|    policy_loss        | -1.86        |\n",
      "|    reward             | 0.0005554611 |\n",
      "|    std                | 6.66e+03     |\n",
      "|    value_loss         | 0.0106       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 56100      |\n",
      "|    time_elapsed       | 912        |\n",
      "|    total_timesteps    | 280500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.5      |\n",
      "|    explained_variance | 0.0598     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 56099      |\n",
      "|    policy_loss        | -0.175     |\n",
      "|    reward             | 0.02501518 |\n",
      "|    std                | 6.82e+03   |\n",
      "|    value_loss         | 0.00818    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 56200         |\n",
      "|    time_elapsed       | 913           |\n",
      "|    total_timesteps    | 281000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.5         |\n",
      "|    explained_variance | -0.203        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 56199         |\n",
      "|    policy_loss        | -1.89         |\n",
      "|    reward             | -0.0009971313 |\n",
      "|    std                | 6.74e+03      |\n",
      "|    value_loss         | 0.0145        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 56300       |\n",
      "|    time_elapsed       | 915         |\n",
      "|    total_timesteps    | 281500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.5       |\n",
      "|    explained_variance | 0.353       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56299       |\n",
      "|    policy_loss        | -0.175      |\n",
      "|    reward             | 0.016202137 |\n",
      "|    std                | 6.8e+03     |\n",
      "|    value_loss         | 0.000167    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 56400        |\n",
      "|    time_elapsed       | 916          |\n",
      "|    total_timesteps    | 282000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.5        |\n",
      "|    explained_variance | -2.38e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 56399        |\n",
      "|    policy_loss        | 0.554        |\n",
      "|    reward             | -0.012842292 |\n",
      "|    std                | 6.92e+03     |\n",
      "|    value_loss         | 0.000973     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 56500      |\n",
      "|    time_elapsed       | 918        |\n",
      "|    total_timesteps    | 282500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -20.5      |\n",
      "|    explained_variance | -0.0259    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 56499      |\n",
      "|    policy_loss        | 0.842      |\n",
      "|    reward             | 0.13902164 |\n",
      "|    std                | 6.97e+03   |\n",
      "|    value_loss         | 0.00209    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 56600        |\n",
      "|    time_elapsed       | 919          |\n",
      "|    total_timesteps    | 283000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.6        |\n",
      "|    explained_variance | -0.155       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 56599        |\n",
      "|    policy_loss        | -0.249       |\n",
      "|    reward             | -0.088479616 |\n",
      "|    std                | 7.09e+03     |\n",
      "|    value_loss         | 0.00129      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 56700       |\n",
      "|    time_elapsed       | 921         |\n",
      "|    total_timesteps    | 283500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.6       |\n",
      "|    explained_variance | 0.0635      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56699       |\n",
      "|    policy_loss        | -3.48       |\n",
      "|    reward             | -0.16197513 |\n",
      "|    std                | 7.16e+03    |\n",
      "|    value_loss         | 0.035       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 56800        |\n",
      "|    time_elapsed       | 923          |\n",
      "|    total_timesteps    | 284000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.6        |\n",
      "|    explained_variance | 0.755        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 56799        |\n",
      "|    policy_loss        | -1.07        |\n",
      "|    reward             | 0.0030984066 |\n",
      "|    std                | 7.2e+03      |\n",
      "|    value_loss         | 0.00274      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 56900       |\n",
      "|    time_elapsed       | 924         |\n",
      "|    total_timesteps    | 284500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.6       |\n",
      "|    explained_variance | 0.616       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56899       |\n",
      "|    policy_loss        | 0.275       |\n",
      "|    reward             | 0.004247002 |\n",
      "|    std                | 7.29e+03    |\n",
      "|    value_loss         | 0.000337    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 57000       |\n",
      "|    time_elapsed       | 926         |\n",
      "|    total_timesteps    | 285000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.7       |\n",
      "|    explained_variance | 0.295       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 56999       |\n",
      "|    policy_loss        | -0.314      |\n",
      "|    reward             | 0.005443856 |\n",
      "|    std                | 7.47e+03    |\n",
      "|    value_loss         | 0.000948    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 57100       |\n",
      "|    time_elapsed       | 927         |\n",
      "|    total_timesteps    | 285500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.7       |\n",
      "|    explained_variance | 0.144       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57099       |\n",
      "|    policy_loss        | -0.642      |\n",
      "|    reward             | 0.024085207 |\n",
      "|    std                | 7.56e+03    |\n",
      "|    value_loss         | 0.00139     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 57200       |\n",
      "|    time_elapsed       | 929         |\n",
      "|    total_timesteps    | 286000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.7       |\n",
      "|    explained_variance | -0.000636   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57199       |\n",
      "|    policy_loss        | 1.31        |\n",
      "|    reward             | -0.04287084 |\n",
      "|    std                | 7.6e+03     |\n",
      "|    value_loss         | 0.00715     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 57300         |\n",
      "|    time_elapsed       | 931           |\n",
      "|    total_timesteps    | 286500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -20.8         |\n",
      "|    explained_variance | 0.0275        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 57299         |\n",
      "|    policy_loss        | -2.28         |\n",
      "|    reward             | -0.0072028595 |\n",
      "|    std                | 7.79e+03      |\n",
      "|    value_loss         | 0.02          |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 57400       |\n",
      "|    time_elapsed       | 932         |\n",
      "|    total_timesteps    | 287000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57399       |\n",
      "|    policy_loss        | -0.388      |\n",
      "|    reward             | 0.011673431 |\n",
      "|    std                | 7.9e+03     |\n",
      "|    value_loss         | 0.0004      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 57500        |\n",
      "|    time_elapsed       | 934          |\n",
      "|    total_timesteps    | 287500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.8        |\n",
      "|    explained_variance | -0.0309      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57499        |\n",
      "|    policy_loss        | 0.115        |\n",
      "|    reward             | -0.005900928 |\n",
      "|    std                | 7.99e+03     |\n",
      "|    value_loss         | 7.04e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 57600        |\n",
      "|    time_elapsed       | 935          |\n",
      "|    total_timesteps    | 288000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.9        |\n",
      "|    explained_variance | 0.841        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57599        |\n",
      "|    policy_loss        | -0.246       |\n",
      "|    reward             | -0.008318131 |\n",
      "|    std                | 8.16e+03     |\n",
      "|    value_loss         | 0.00018      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 57700       |\n",
      "|    time_elapsed       | 937         |\n",
      "|    total_timesteps    | 288500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -20.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57699       |\n",
      "|    policy_loss        | -0.126      |\n",
      "|    reward             | 0.008365713 |\n",
      "|    std                | 8.38e+03    |\n",
      "|    value_loss         | 0.000119    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 57800        |\n",
      "|    time_elapsed       | 938          |\n",
      "|    total_timesteps    | 289000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -20.9        |\n",
      "|    explained_variance | 0.271        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 57799        |\n",
      "|    policy_loss        | 0.0454       |\n",
      "|    reward             | -0.020790111 |\n",
      "|    std                | 8.51e+03     |\n",
      "|    value_loss         | 0.00359      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 57900       |\n",
      "|    time_elapsed       | 940         |\n",
      "|    total_timesteps    | 289500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21         |\n",
      "|    explained_variance | 0.0344      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 57899       |\n",
      "|    policy_loss        | 0.793       |\n",
      "|    reward             | 0.041528538 |\n",
      "|    std                | 8.72e+03    |\n",
      "|    value_loss         | 0.00609     |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 100\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 65675.30\n",
      "total_reward: 55675.30\n",
      "total_cost: 18.93\n",
      "total_trades: 5790\n",
      "Sharpe: 0.699\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 58000      |\n",
      "|    time_elapsed       | 942        |\n",
      "|    total_timesteps    | 290000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21        |\n",
      "|    explained_variance | 0.018      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 57999      |\n",
      "|    policy_loss        | -0.825     |\n",
      "|    reward             | 0.03169491 |\n",
      "|    std                | 8.98e+03   |\n",
      "|    value_loss         | 0.00191    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 58100        |\n",
      "|    time_elapsed       | 943          |\n",
      "|    total_timesteps    | 290500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 58099        |\n",
      "|    policy_loss        | 1.43         |\n",
      "|    reward             | 0.0022051907 |\n",
      "|    std                | 9.09e+03     |\n",
      "|    value_loss         | 0.00491      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 58200        |\n",
      "|    time_elapsed       | 945          |\n",
      "|    total_timesteps    | 291000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 58199        |\n",
      "|    policy_loss        | -0.0419      |\n",
      "|    reward             | -0.049575433 |\n",
      "|    std                | 9.28e+03     |\n",
      "|    value_loss         | 0.000636     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 58300       |\n",
      "|    time_elapsed       | 946         |\n",
      "|    total_timesteps    | 291500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58299       |\n",
      "|    policy_loss        | 0.307       |\n",
      "|    reward             | 0.029946774 |\n",
      "|    std                | 9.33e+03    |\n",
      "|    value_loss         | 0.00935     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 58400      |\n",
      "|    time_elapsed       | 948        |\n",
      "|    total_timesteps    | 292000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.2      |\n",
      "|    explained_variance | 0.0629     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 58399      |\n",
      "|    policy_loss        | -3.01      |\n",
      "|    reward             | -0.1555225 |\n",
      "|    std                | 9.49e+03   |\n",
      "|    value_loss         | 0.0347     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 58500       |\n",
      "|    time_elapsed       | 949         |\n",
      "|    total_timesteps    | 292500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.2       |\n",
      "|    explained_variance | 0.0208      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58499       |\n",
      "|    policy_loss        | -7.91       |\n",
      "|    reward             | -0.06839694 |\n",
      "|    std                | 9.57e+03    |\n",
      "|    value_loss         | 0.148       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 58600       |\n",
      "|    time_elapsed       | 951         |\n",
      "|    total_timesteps    | 293000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.2       |\n",
      "|    explained_variance | 0.149       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58599       |\n",
      "|    policy_loss        | 1.24        |\n",
      "|    reward             | 0.019611463 |\n",
      "|    std                | 9.73e+03    |\n",
      "|    value_loss         | 0.00291     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 308           |\n",
      "|    iterations         | 58700         |\n",
      "|    time_elapsed       | 952           |\n",
      "|    total_timesteps    | 293500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 58699         |\n",
      "|    policy_loss        | -0.354        |\n",
      "|    reward             | -0.0031452107 |\n",
      "|    std                | 9.87e+03      |\n",
      "|    value_loss         | 0.000483      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 58800        |\n",
      "|    time_elapsed       | 954          |\n",
      "|    total_timesteps    | 294000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.3        |\n",
      "|    explained_variance | 0.908        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 58799        |\n",
      "|    policy_loss        | 0.0218       |\n",
      "|    reward             | -0.004114091 |\n",
      "|    std                | 1e+04        |\n",
      "|    value_loss         | 1.96e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 58900       |\n",
      "|    time_elapsed       | 956         |\n",
      "|    total_timesteps    | 294500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.3       |\n",
      "|    explained_variance | 0.651       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 58899       |\n",
      "|    policy_loss        | -0.132      |\n",
      "|    reward             | 0.007235165 |\n",
      "|    std                | 1.02e+04    |\n",
      "|    value_loss         | 7.46e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 59000         |\n",
      "|    time_elapsed       | 958           |\n",
      "|    total_timesteps    | 295000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.3         |\n",
      "|    explained_variance | -2.38e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 58999         |\n",
      "|    policy_loss        | -0.206        |\n",
      "|    reward             | -0.0029336526 |\n",
      "|    std                | 1.04e+04      |\n",
      "|    value_loss         | 0.00184       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 59100         |\n",
      "|    time_elapsed       | 959           |\n",
      "|    total_timesteps    | 295500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.3         |\n",
      "|    explained_variance | -0.817        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 59099         |\n",
      "|    policy_loss        | -15.9         |\n",
      "|    reward             | -0.0002208346 |\n",
      "|    std                | 1.04e+04      |\n",
      "|    value_loss         | 0.543         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 59200         |\n",
      "|    time_elapsed       | 961           |\n",
      "|    total_timesteps    | 296000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.4         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 59199         |\n",
      "|    policy_loss        | 0.34          |\n",
      "|    reward             | -0.0026731777 |\n",
      "|    std                | 1.06e+04      |\n",
      "|    value_loss         | 0.000287      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 59300       |\n",
      "|    time_elapsed       | 963         |\n",
      "|    total_timesteps    | 296500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.4       |\n",
      "|    explained_variance | 0.264       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 59299       |\n",
      "|    policy_loss        | -0.303      |\n",
      "|    reward             | 0.009790405 |\n",
      "|    std                | 1.09e+04    |\n",
      "|    value_loss         | 0.000311    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 59400       |\n",
      "|    time_elapsed       | 964         |\n",
      "|    total_timesteps    | 297000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.5       |\n",
      "|    explained_variance | 1.83e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 59399       |\n",
      "|    policy_loss        | 0.745       |\n",
      "|    reward             | 0.002252668 |\n",
      "|    std                | 1.11e+04    |\n",
      "|    value_loss         | 0.00136     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 59500       |\n",
      "|    time_elapsed       | 966         |\n",
      "|    total_timesteps    | 297500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.5       |\n",
      "|    explained_variance | 0.141       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 59499       |\n",
      "|    policy_loss        | 0.797       |\n",
      "|    reward             | 0.047443632 |\n",
      "|    std                | 1.15e+04    |\n",
      "|    value_loss         | 0.00429     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 59600      |\n",
      "|    time_elapsed       | 967        |\n",
      "|    total_timesteps    | 298000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.6      |\n",
      "|    explained_variance | 0.0455     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 59599      |\n",
      "|    policy_loss        | -3.57      |\n",
      "|    reward             | 0.20901299 |\n",
      "|    std                | 1.16e+04   |\n",
      "|    value_loss         | 0.0564     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 59700        |\n",
      "|    time_elapsed       | 969          |\n",
      "|    total_timesteps    | 298500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.6        |\n",
      "|    explained_variance | -0.00252     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 59699        |\n",
      "|    policy_loss        | -0.282       |\n",
      "|    reward             | -0.013566704 |\n",
      "|    std                | 1.18e+04     |\n",
      "|    value_loss         | 0.000214     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 59800        |\n",
      "|    time_elapsed       | 971          |\n",
      "|    total_timesteps    | 299000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.6        |\n",
      "|    explained_variance | -0.00283     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 59799        |\n",
      "|    policy_loss        | -0.166       |\n",
      "|    reward             | 0.0035832897 |\n",
      "|    std                | 1.19e+04     |\n",
      "|    value_loss         | 0.000537     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 59900        |\n",
      "|    time_elapsed       | 973          |\n",
      "|    total_timesteps    | 299500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.7        |\n",
      "|    explained_variance | 0.343        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 59899        |\n",
      "|    policy_loss        | 0.383        |\n",
      "|    reward             | -0.007166935 |\n",
      "|    std                | 1.23e+04     |\n",
      "|    value_loss         | 0.000699     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 60000         |\n",
      "|    time_elapsed       | 974           |\n",
      "|    total_timesteps    | 300000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -21.7         |\n",
      "|    explained_variance | -2.16e-05     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 59999         |\n",
      "|    policy_loss        | 0.402         |\n",
      "|    reward             | 0.00022941895 |\n",
      "|    std                | 1.26e+04      |\n",
      "|    value_loss         | 0.000417      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 60100      |\n",
      "|    time_elapsed       | 976        |\n",
      "|    total_timesteps    | 300500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -21.8      |\n",
      "|    explained_variance | 0.512      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 60099      |\n",
      "|    policy_loss        | -0.108     |\n",
      "|    reward             | 0.02012081 |\n",
      "|    std                | 1.32e+04   |\n",
      "|    value_loss         | 0.000268   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 307       |\n",
      "|    iterations         | 60200     |\n",
      "|    time_elapsed       | 977       |\n",
      "|    total_timesteps    | 301000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -21.8     |\n",
      "|    explained_variance | 0.354     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 60199     |\n",
      "|    policy_loss        | -0.0332   |\n",
      "|    reward             | 0.0433931 |\n",
      "|    std                | 1.33e+04  |\n",
      "|    value_loss         | 0.00041   |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 60300        |\n",
      "|    time_elapsed       | 979          |\n",
      "|    total_timesteps    | 301500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.9        |\n",
      "|    explained_variance | 0.212        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60299        |\n",
      "|    policy_loss        | -0.0153      |\n",
      "|    reward             | -0.004942164 |\n",
      "|    std                | 1.38e+04     |\n",
      "|    value_loss         | 2.4e-06      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 60400       |\n",
      "|    time_elapsed       | 981         |\n",
      "|    total_timesteps    | 302000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 60399       |\n",
      "|    policy_loss        | 0.0755      |\n",
      "|    reward             | 0.005539654 |\n",
      "|    std                | 1.41e+04    |\n",
      "|    value_loss         | 3.91e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 60500        |\n",
      "|    time_elapsed       | 982          |\n",
      "|    total_timesteps    | 302500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22          |\n",
      "|    explained_variance | 0.274        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60499        |\n",
      "|    policy_loss        | 0.0301       |\n",
      "|    reward             | -0.002272943 |\n",
      "|    std                | 1.46e+04     |\n",
      "|    value_loss         | 0.000382     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 60600        |\n",
      "|    time_elapsed       | 984          |\n",
      "|    total_timesteps    | 303000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.1        |\n",
      "|    explained_variance | 0.133        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 60599        |\n",
      "|    policy_loss        | 0.646        |\n",
      "|    reward             | 0.0054249857 |\n",
      "|    std                | 1.5e+04      |\n",
      "|    value_loss         | 0.00144      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 60700      |\n",
      "|    time_elapsed       | 985        |\n",
      "|    total_timesteps    | 303500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.1      |\n",
      "|    explained_variance | 0.208      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 60699      |\n",
      "|    policy_loss        | -1.61      |\n",
      "|    reward             | 0.08291887 |\n",
      "|    std                | 1.52e+04   |\n",
      "|    value_loss         | 0.0232     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 307        |\n",
      "|    iterations         | 60800      |\n",
      "|    time_elapsed       | 987        |\n",
      "|    total_timesteps    | 304000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.1      |\n",
      "|    explained_variance | 6.56e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 60799      |\n",
      "|    policy_loss        | 1.99       |\n",
      "|    reward             | 0.03769254 |\n",
      "|    std                | 1.54e+04   |\n",
      "|    value_loss         | 0.00943    |\n",
      "--------------------------------------\n",
      "day: 2896, episode: 105\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 82231.50\n",
      "total_reward: 72231.50\n",
      "total_cost: 11.07\n",
      "total_trades: 5792\n",
      "Sharpe: 0.715\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 60900       |\n",
      "|    time_elapsed       | 988         |\n",
      "|    total_timesteps    | 304500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.1       |\n",
      "|    explained_variance | 0.198       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 60899       |\n",
      "|    policy_loss        | 0.335       |\n",
      "|    reward             | 0.008046804 |\n",
      "|    std                | 1.55e+04    |\n",
      "|    value_loss         | 0.000411    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 307         |\n",
      "|    iterations         | 61000       |\n",
      "|    time_elapsed       | 990         |\n",
      "|    total_timesteps    | 305000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.2       |\n",
      "|    explained_variance | 1.6e-05     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 60999       |\n",
      "|    policy_loss        | -0.53       |\n",
      "|    reward             | 0.010623962 |\n",
      "|    std                | 1.58e+04    |\n",
      "|    value_loss         | 0.000652    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 307          |\n",
      "|    iterations         | 61100        |\n",
      "|    time_elapsed       | 991          |\n",
      "|    total_timesteps    | 305500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61099        |\n",
      "|    policy_loss        | -0.188       |\n",
      "|    reward             | -0.009166449 |\n",
      "|    std                | 1.62e+04     |\n",
      "|    value_loss         | 0.000165     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 307           |\n",
      "|    iterations         | 61200         |\n",
      "|    time_elapsed       | 993           |\n",
      "|    total_timesteps    | 306000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 61199         |\n",
      "|    policy_loss        | -1.62         |\n",
      "|    reward             | 0.00073652115 |\n",
      "|    std                | 1.68e+04      |\n",
      "|    value_loss         | 0.00562       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 61300        |\n",
      "|    time_elapsed       | 995          |\n",
      "|    total_timesteps    | 306500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61299        |\n",
      "|    policy_loss        | 1.86         |\n",
      "|    reward             | 0.0064544557 |\n",
      "|    std                | 1.73e+04     |\n",
      "|    value_loss         | 0.0082       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 61400       |\n",
      "|    time_elapsed       | 996         |\n",
      "|    total_timesteps    | 307000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 61399       |\n",
      "|    policy_loss        | 0.83        |\n",
      "|    reward             | 0.022430433 |\n",
      "|    std                | 1.77e+04    |\n",
      "|    value_loss         | 0.00451     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 61500        |\n",
      "|    time_elapsed       | 998          |\n",
      "|    total_timesteps    | 307500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.4        |\n",
      "|    explained_variance | 0.146        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61499        |\n",
      "|    policy_loss        | -0.982       |\n",
      "|    reward             | -0.010834399 |\n",
      "|    std                | 1.79e+04     |\n",
      "|    value_loss         | 0.00207      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 308        |\n",
      "|    iterations         | 61600      |\n",
      "|    time_elapsed       | 999        |\n",
      "|    total_timesteps    | 308000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.4      |\n",
      "|    explained_variance | 0.00822    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 61599      |\n",
      "|    policy_loss        | -0.887     |\n",
      "|    reward             | 0.00978612 |\n",
      "|    std                | 1.81e+04   |\n",
      "|    value_loss         | 0.0018     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 61700       |\n",
      "|    time_elapsed       | 1001        |\n",
      "|    total_timesteps    | 308500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.5       |\n",
      "|    explained_variance | 0.0219      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 61699       |\n",
      "|    policy_loss        | -2.48       |\n",
      "|    reward             | 0.018629532 |\n",
      "|    std                | 1.87e+04    |\n",
      "|    value_loss         | 0.0179      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 61800        |\n",
      "|    time_elapsed       | 1002         |\n",
      "|    total_timesteps    | 309000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.6        |\n",
      "|    explained_variance | 0.0542       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61799        |\n",
      "|    policy_loss        | 7.01         |\n",
      "|    reward             | -0.019494927 |\n",
      "|    std                | 1.91e+04     |\n",
      "|    value_loss         | 0.1          |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 61900        |\n",
      "|    time_elapsed       | 1004         |\n",
      "|    total_timesteps    | 309500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 61899        |\n",
      "|    policy_loss        | 2.19         |\n",
      "|    reward             | -0.036488954 |\n",
      "|    std                | 1.92e+04     |\n",
      "|    value_loss         | 0.016        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 62000       |\n",
      "|    time_elapsed       | 1005        |\n",
      "|    total_timesteps    | 310000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.6       |\n",
      "|    explained_variance | -0.431      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 61999       |\n",
      "|    policy_loss        | -0.785      |\n",
      "|    reward             | 0.008969962 |\n",
      "|    std                | 1.91e+04    |\n",
      "|    value_loss         | 0.00173     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 62100       |\n",
      "|    time_elapsed       | 1007        |\n",
      "|    total_timesteps    | 310500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.6       |\n",
      "|    explained_variance | 0.379       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 62099       |\n",
      "|    policy_loss        | -0.0474     |\n",
      "|    reward             | 0.033968303 |\n",
      "|    std                | 1.94e+04    |\n",
      "|    value_loss         | 2.76e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 62200       |\n",
      "|    time_elapsed       | 1008        |\n",
      "|    total_timesteps    | 311000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.6       |\n",
      "|    explained_variance | 0.567       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 62199       |\n",
      "|    policy_loss        | -0.48       |\n",
      "|    reward             | 0.017250318 |\n",
      "|    std                | 1.98e+04    |\n",
      "|    value_loss         | 0.000698    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 62300        |\n",
      "|    time_elapsed       | 1010         |\n",
      "|    total_timesteps    | 311500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62299        |\n",
      "|    policy_loss        | -0.553       |\n",
      "|    reward             | 0.0067429347 |\n",
      "|    std                | 2.01e+04     |\n",
      "|    value_loss         | 0.000911     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 62400        |\n",
      "|    time_elapsed       | 1011         |\n",
      "|    total_timesteps    | 312000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.7        |\n",
      "|    explained_variance | 0.134        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62399        |\n",
      "|    policy_loss        | 0.288        |\n",
      "|    reward             | -0.012795159 |\n",
      "|    std                | 2.04e+04     |\n",
      "|    value_loss         | 0.00308      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 308        |\n",
      "|    iterations         | 62500      |\n",
      "|    time_elapsed       | 1013       |\n",
      "|    total_timesteps    | 312500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.7      |\n",
      "|    explained_variance | 0.0407     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 62499      |\n",
      "|    policy_loss        | 2.84       |\n",
      "|    reward             | 0.01400927 |\n",
      "|    std                | 2.05e+04   |\n",
      "|    value_loss         | 0.0585     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 62600        |\n",
      "|    time_elapsed       | 1014         |\n",
      "|    total_timesteps    | 313000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.7        |\n",
      "|    explained_variance | 0.404        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62599        |\n",
      "|    policy_loss        | 0.211        |\n",
      "|    reward             | 0.0070073586 |\n",
      "|    std                | 2.04e+04     |\n",
      "|    value_loss         | 0.000114     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 62700        |\n",
      "|    time_elapsed       | 1016         |\n",
      "|    total_timesteps    | 313500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.7        |\n",
      "|    explained_variance | 0.548        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 62699        |\n",
      "|    policy_loss        | 0.00354      |\n",
      "|    reward             | -0.019674512 |\n",
      "|    std                | 2.08e+04     |\n",
      "|    value_loss         | 3.16e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 62800       |\n",
      "|    time_elapsed       | 1017        |\n",
      "|    total_timesteps    | 314000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 62799       |\n",
      "|    policy_loss        | 0.0326      |\n",
      "|    reward             | 0.012280509 |\n",
      "|    std                | 2.13e+04    |\n",
      "|    value_loss         | 4.2e-05     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 308           |\n",
      "|    iterations         | 62900         |\n",
      "|    time_elapsed       | 1019          |\n",
      "|    total_timesteps    | 314500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.8         |\n",
      "|    explained_variance | 0.106         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 62899         |\n",
      "|    policy_loss        | -0.79         |\n",
      "|    reward             | -0.0058886604 |\n",
      "|    std                | 2.15e+04      |\n",
      "|    value_loss         | 0.00162       |\n",
      "-----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 308      |\n",
      "|    iterations         | 63000    |\n",
      "|    time_elapsed       | 1021     |\n",
      "|    total_timesteps    | 315000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -22.8    |\n",
      "|    explained_variance | 0.395    |\n",
      "|    learning_rate      | 0.001    |\n",
      "|    n_updates          | 62999    |\n",
      "|    policy_loss        | 1.25     |\n",
      "|    reward             | 0.180193 |\n",
      "|    std                | 2.21e+04 |\n",
      "|    value_loss         | 0.00431  |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 308        |\n",
      "|    iterations         | 63100      |\n",
      "|    time_elapsed       | 1022       |\n",
      "|    total_timesteps    | 315500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -22.9      |\n",
      "|    explained_variance | 0.00136    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 63099      |\n",
      "|    policy_loss        | 1.93       |\n",
      "|    reward             | 0.21997285 |\n",
      "|    std                | 2.25e+04   |\n",
      "|    value_loss         | 0.00783    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 63200       |\n",
      "|    time_elapsed       | 1024        |\n",
      "|    total_timesteps    | 316000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -22.9       |\n",
      "|    explained_variance | 6.43e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63199       |\n",
      "|    policy_loss        | -0.0133     |\n",
      "|    reward             | 0.025188282 |\n",
      "|    std                | 2.28e+04    |\n",
      "|    value_loss         | 2.9e-05     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 63300        |\n",
      "|    time_elapsed       | 1025         |\n",
      "|    total_timesteps    | 316500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63299        |\n",
      "|    policy_loss        | -0.0347      |\n",
      "|    reward             | -0.011277664 |\n",
      "|    std                | 2.32e+04     |\n",
      "|    value_loss         | 7.96e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 63400        |\n",
      "|    time_elapsed       | 1027         |\n",
      "|    total_timesteps    | 317000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23          |\n",
      "|    explained_variance | 0.0898       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63399        |\n",
      "|    policy_loss        | -0.545       |\n",
      "|    reward             | 0.0087342635 |\n",
      "|    std                | 2.38e+04     |\n",
      "|    value_loss         | 0.000647     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 63500        |\n",
      "|    time_elapsed       | 1028         |\n",
      "|    total_timesteps    | 317500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63499        |\n",
      "|    policy_loss        | -0.0168      |\n",
      "|    reward             | -0.010988899 |\n",
      "|    std                | 2.43e+04     |\n",
      "|    value_loss         | 0.000441     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 63600       |\n",
      "|    time_elapsed       | 1030        |\n",
      "|    total_timesteps    | 318000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.1       |\n",
      "|    explained_variance | 0.0362      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 63599       |\n",
      "|    policy_loss        | 1.45        |\n",
      "|    reward             | 0.061281823 |\n",
      "|    std                | 2.45e+04    |\n",
      "|    value_loss         | 0.00545     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 308        |\n",
      "|    iterations         | 63700      |\n",
      "|    time_elapsed       | 1032       |\n",
      "|    total_timesteps    | 318500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.1      |\n",
      "|    explained_variance | 0.873      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 63699      |\n",
      "|    policy_loss        | 2.36       |\n",
      "|    reward             | 0.17843981 |\n",
      "|    std                | 2.48e+04   |\n",
      "|    value_loss         | 0.0111     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2896, episode: 110\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 63573.69\n",
      "total_reward: 53573.69\n",
      "total_cost: 10.48\n",
      "total_trades: 5792\n",
      "Sharpe: 0.672\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 63800        |\n",
      "|    time_elapsed       | 1033         |\n",
      "|    total_timesteps    | 319000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.1        |\n",
      "|    explained_variance | 0.0719       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63799        |\n",
      "|    policy_loss        | -0.566       |\n",
      "|    reward             | 0.0038215993 |\n",
      "|    std                | 2.51e+04     |\n",
      "|    value_loss         | 0.00117      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 63900        |\n",
      "|    time_elapsed       | 1035         |\n",
      "|    total_timesteps    | 319500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.1        |\n",
      "|    explained_variance | 0.000496     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63899        |\n",
      "|    policy_loss        | 0.329        |\n",
      "|    reward             | 0.0057217167 |\n",
      "|    std                | 2.57e+04     |\n",
      "|    value_loss         | 0.000301     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 64000        |\n",
      "|    time_elapsed       | 1036         |\n",
      "|    total_timesteps    | 320000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.2        |\n",
      "|    explained_variance | 0.199        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 63999        |\n",
      "|    policy_loss        | -1.57        |\n",
      "|    reward             | -0.012104615 |\n",
      "|    std                | 2.64e+04     |\n",
      "|    value_loss         | 0.00496      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 64100       |\n",
      "|    time_elapsed       | 1038        |\n",
      "|    total_timesteps    | 320500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.3       |\n",
      "|    explained_variance | -0.159      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 64099       |\n",
      "|    policy_loss        | -2.68       |\n",
      "|    reward             | 0.033594444 |\n",
      "|    std                | 2.73e+04    |\n",
      "|    value_loss         | 0.0197      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 64200        |\n",
      "|    time_elapsed       | 1039         |\n",
      "|    total_timesteps    | 321000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.3        |\n",
      "|    explained_variance | 0.132        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 64199        |\n",
      "|    policy_loss        | 2.43         |\n",
      "|    reward             | -0.046752717 |\n",
      "|    std                | 2.72e+04     |\n",
      "|    value_loss         | 0.0119       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 308        |\n",
      "|    iterations         | 64300      |\n",
      "|    time_elapsed       | 1041       |\n",
      "|    total_timesteps    | 321500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.3      |\n",
      "|    explained_variance | 0.407      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 64299      |\n",
      "|    policy_loss        | 0.93       |\n",
      "|    reward             | 0.08345852 |\n",
      "|    std                | 2.75e+04   |\n",
      "|    value_loss         | 0.00413    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 64400       |\n",
      "|    time_elapsed       | 1043        |\n",
      "|    total_timesteps    | 322000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.3       |\n",
      "|    explained_variance | 0.118       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 64399       |\n",
      "|    policy_loss        | -0.122      |\n",
      "|    reward             | 0.001522259 |\n",
      "|    std                | 2.78e+04    |\n",
      "|    value_loss         | 5.63e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 308           |\n",
      "|    iterations         | 64500         |\n",
      "|    time_elapsed       | 1044          |\n",
      "|    total_timesteps    | 322500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.3         |\n",
      "|    explained_variance | 0.284         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 64499         |\n",
      "|    policy_loss        | 0.385         |\n",
      "|    reward             | -0.0013503624 |\n",
      "|    std                | 2.85e+04      |\n",
      "|    value_loss         | 0.000358      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 64600       |\n",
      "|    time_elapsed       | 1046        |\n",
      "|    total_timesteps    | 323000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.4       |\n",
      "|    explained_variance | -0.0337     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 64599       |\n",
      "|    policy_loss        | 0.452       |\n",
      "|    reward             | -0.02210913 |\n",
      "|    std                | 2.92e+04    |\n",
      "|    value_loss         | 0.00075     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 64700       |\n",
      "|    time_elapsed       | 1047        |\n",
      "|    total_timesteps    | 323500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.4       |\n",
      "|    explained_variance | 0.00157     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 64699       |\n",
      "|    policy_loss        | 1.57        |\n",
      "|    reward             | -0.09496861 |\n",
      "|    std                | 2.95e+04    |\n",
      "|    value_loss         | 0.00525     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 64800       |\n",
      "|    time_elapsed       | 1049        |\n",
      "|    total_timesteps    | 324000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.5       |\n",
      "|    explained_variance | 2.06e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 64799       |\n",
      "|    policy_loss        | 0.562       |\n",
      "|    reward             | -0.02642294 |\n",
      "|    std                | 3.01e+04    |\n",
      "|    value_loss         | 0.00181     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 308           |\n",
      "|    iterations         | 64900         |\n",
      "|    time_elapsed       | 1051          |\n",
      "|    total_timesteps    | 324500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.5         |\n",
      "|    explained_variance | 0.0116        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 64899         |\n",
      "|    policy_loss        | -0.474        |\n",
      "|    reward             | -0.0066697183 |\n",
      "|    std                | 3.07e+04      |\n",
      "|    value_loss         | 0.000542      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 65000        |\n",
      "|    time_elapsed       | 1052         |\n",
      "|    total_timesteps    | 325000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.5        |\n",
      "|    explained_variance | -0.0117      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 64999        |\n",
      "|    policy_loss        | -0.837       |\n",
      "|    reward             | -0.009234992 |\n",
      "|    std                | 3.12e+04     |\n",
      "|    value_loss         | 0.0021       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 65100        |\n",
      "|    time_elapsed       | 1054         |\n",
      "|    total_timesteps    | 325500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.6        |\n",
      "|    explained_variance | 0.0949       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65099        |\n",
      "|    policy_loss        | 0.799        |\n",
      "|    reward             | -0.010377249 |\n",
      "|    std                | 3.16e+04     |\n",
      "|    value_loss         | 0.00167      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 308       |\n",
      "|    iterations         | 65200     |\n",
      "|    time_elapsed       | 1055      |\n",
      "|    total_timesteps    | 326000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -23.6     |\n",
      "|    explained_variance | 0.0404    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 65199     |\n",
      "|    policy_loss        | -1.47     |\n",
      "|    reward             | 0.0084644 |\n",
      "|    std                | 3.24e+04  |\n",
      "|    value_loss         | 0.006     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 65300       |\n",
      "|    time_elapsed       | 1057        |\n",
      "|    total_timesteps    | 326500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.7       |\n",
      "|    explained_variance | 0.26        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 65299       |\n",
      "|    policy_loss        | -2.06       |\n",
      "|    reward             | -0.06304553 |\n",
      "|    std                | 3.31e+04    |\n",
      "|    value_loss         | 0.0165      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 308       |\n",
      "|    iterations         | 65400     |\n",
      "|    time_elapsed       | 1058      |\n",
      "|    total_timesteps    | 327000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -23.7     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 65399     |\n",
      "|    policy_loss        | 0.78      |\n",
      "|    reward             | 0.2648398 |\n",
      "|    std                | 3.39e+04  |\n",
      "|    value_loss         | 0.0203    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 65500        |\n",
      "|    time_elapsed       | 1060         |\n",
      "|    total_timesteps    | 327500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65499        |\n",
      "|    policy_loss        | -0.588       |\n",
      "|    reward             | -0.017484263 |\n",
      "|    std                | 3.44e+04     |\n",
      "|    value_loss         | 0.000683     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 65600       |\n",
      "|    time_elapsed       | 1062        |\n",
      "|    total_timesteps    | 328000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.8       |\n",
      "|    explained_variance | 0.000264    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 65599       |\n",
      "|    policy_loss        | -0.276      |\n",
      "|    reward             | 0.014313514 |\n",
      "|    std                | 3.51e+04    |\n",
      "|    value_loss         | 0.000196    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 65700       |\n",
      "|    time_elapsed       | 1063        |\n",
      "|    total_timesteps    | 328500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.8       |\n",
      "|    explained_variance | -0.46       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 65699       |\n",
      "|    policy_loss        | -3.24       |\n",
      "|    reward             | -0.11542979 |\n",
      "|    std                | 3.54e+04    |\n",
      "|    value_loss         | 0.0192      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 65800        |\n",
      "|    time_elapsed       | 1065         |\n",
      "|    total_timesteps    | 329000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.8        |\n",
      "|    explained_variance | 7.86e-05     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 65799        |\n",
      "|    policy_loss        | 1.68         |\n",
      "|    reward             | -0.043853503 |\n",
      "|    std                | 3.53e+04     |\n",
      "|    value_loss         | 0.00825      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 65900       |\n",
      "|    time_elapsed       | 1066        |\n",
      "|    total_timesteps    | 329500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.8       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 65899       |\n",
      "|    policy_loss        | 8.79        |\n",
      "|    reward             | 0.008867477 |\n",
      "|    std                | 3.51e+04    |\n",
      "|    value_loss         | 0.167       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 66000       |\n",
      "|    time_elapsed       | 1068        |\n",
      "|    total_timesteps    | 330000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 65999       |\n",
      "|    policy_loss        | 2.41        |\n",
      "|    reward             | 0.036077634 |\n",
      "|    std                | 3.54e+04    |\n",
      "|    value_loss         | 0.0358      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 66100        |\n",
      "|    time_elapsed       | 1069         |\n",
      "|    total_timesteps    | 330500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.8        |\n",
      "|    explained_variance | -0.0608      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 66099        |\n",
      "|    policy_loss        | -1.69        |\n",
      "|    reward             | -0.005429489 |\n",
      "|    std                | 3.56e+04     |\n",
      "|    value_loss         | 0.00595      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 66200       |\n",
      "|    time_elapsed       | 1071        |\n",
      "|    total_timesteps    | 331000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.8       |\n",
      "|    explained_variance | 0.189       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66199       |\n",
      "|    policy_loss        | -0.335      |\n",
      "|    reward             | 0.022946114 |\n",
      "|    std                | 3.61e+04    |\n",
      "|    value_loss         | 0.000437    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 66300       |\n",
      "|    time_elapsed       | 1072        |\n",
      "|    total_timesteps    | 331500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.9       |\n",
      "|    explained_variance | -0.0236     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66299       |\n",
      "|    policy_loss        | 3.82        |\n",
      "|    reward             | -0.07769481 |\n",
      "|    std                | 3.68e+04    |\n",
      "|    value_loss         | 0.0755      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 66400      |\n",
      "|    time_elapsed       | 1074       |\n",
      "|    total_timesteps    | 332000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 66399      |\n",
      "|    policy_loss        | -1.07      |\n",
      "|    reward             | 0.04152223 |\n",
      "|    std                | 3.68e+04   |\n",
      "|    value_loss         | 0.00549    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 66500      |\n",
      "|    time_elapsed       | 1076       |\n",
      "|    total_timesteps    | 332500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 66499      |\n",
      "|    policy_loss        | -1.56      |\n",
      "|    reward             | 0.12776516 |\n",
      "|    std                | 3.66e+04   |\n",
      "|    value_loss         | 0.00467    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 66600      |\n",
      "|    time_elapsed       | 1077       |\n",
      "|    total_timesteps    | 333000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -23.9      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 66599      |\n",
      "|    policy_loss        | 10.5       |\n",
      "|    reward             | -0.1776326 |\n",
      "|    std                | 3.7e+04    |\n",
      "|    value_loss         | 0.229      |\n",
      "--------------------------------------\n",
      "day: 2896, episode: 115\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 204614.41\n",
      "total_reward: 194614.41\n",
      "total_cost: 36.74\n",
      "total_trades: 5788\n",
      "Sharpe: 0.983\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 66700       |\n",
      "|    time_elapsed       | 1079        |\n",
      "|    total_timesteps    | 333500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -23.9       |\n",
      "|    explained_variance | -0.228      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66699       |\n",
      "|    policy_loss        | -1.29       |\n",
      "|    reward             | 0.019111326 |\n",
      "|    std                | 3.74e+04    |\n",
      "|    value_loss         | 0.0042      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 309           |\n",
      "|    iterations         | 66800         |\n",
      "|    time_elapsed       | 1080          |\n",
      "|    total_timesteps    | 334000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.9         |\n",
      "|    explained_variance | -2.02         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 66799         |\n",
      "|    policy_loss        | -0.392        |\n",
      "|    reward             | -0.0018130344 |\n",
      "|    std                | 3.79e+04      |\n",
      "|    value_loss         | 0.000394      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 66900      |\n",
      "|    time_elapsed       | 1082       |\n",
      "|    total_timesteps    | 334500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24        |\n",
      "|    explained_variance | -1.6       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 66899      |\n",
      "|    policy_loss        | -1.31      |\n",
      "|    reward             | 0.01557419 |\n",
      "|    std                | 3.87e+04   |\n",
      "|    value_loss         | 0.00572    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 67000       |\n",
      "|    time_elapsed       | 1085        |\n",
      "|    total_timesteps    | 335000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24         |\n",
      "|    explained_variance | 0.0092      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 66999       |\n",
      "|    policy_loss        | 0.173       |\n",
      "|    reward             | -0.04648928 |\n",
      "|    std                | 3.88e+04    |\n",
      "|    value_loss         | 0.000343    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 67100        |\n",
      "|    time_elapsed       | 1086         |\n",
      "|    total_timesteps    | 335500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24          |\n",
      "|    explained_variance | 0.215        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67099        |\n",
      "|    policy_loss        | 0.21         |\n",
      "|    reward             | 0.0016919419 |\n",
      "|    std                | 3.91e+04     |\n",
      "|    value_loss         | 0.000757     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 308        |\n",
      "|    iterations         | 67200      |\n",
      "|    time_elapsed       | 1088       |\n",
      "|    total_timesteps    | 336000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24        |\n",
      "|    explained_variance | 0.926      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 67199      |\n",
      "|    policy_loss        | -1.38      |\n",
      "|    reward             | 0.13461645 |\n",
      "|    std                | 3.91e+04   |\n",
      "|    value_loss         | 0.00359    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 67300       |\n",
      "|    time_elapsed       | 1089        |\n",
      "|    total_timesteps    | 336500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 67299       |\n",
      "|    policy_loss        | -0.487      |\n",
      "|    reward             | 0.012126953 |\n",
      "|    std                | 3.98e+04    |\n",
      "|    value_loss         | 0.00049     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 67400        |\n",
      "|    time_elapsed       | 1091         |\n",
      "|    total_timesteps    | 337000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67399        |\n",
      "|    policy_loss        | 0.0659       |\n",
      "|    reward             | 0.0143859675 |\n",
      "|    std                | 4.06e+04     |\n",
      "|    value_loss         | 5.67e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 67500       |\n",
      "|    time_elapsed       | 1092        |\n",
      "|    total_timesteps    | 337500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.1       |\n",
      "|    explained_variance | 2.44e-06    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 67499       |\n",
      "|    policy_loss        | 1.61        |\n",
      "|    reward             | -0.04413672 |\n",
      "|    std                | 4.21e+04    |\n",
      "|    value_loss         | 0.00662     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 67600       |\n",
      "|    time_elapsed       | 1094        |\n",
      "|    total_timesteps    | 338000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.2       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 67599       |\n",
      "|    policy_loss        | 1.85        |\n",
      "|    reward             | -0.08395317 |\n",
      "|    std                | 4.33e+04    |\n",
      "|    value_loss         | 0.00749     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 67700        |\n",
      "|    time_elapsed       | 1095         |\n",
      "|    total_timesteps    | 338500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.2        |\n",
      "|    explained_variance | 0.196        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67699        |\n",
      "|    policy_loss        | -1.53        |\n",
      "|    reward             | -0.032823525 |\n",
      "|    std                | 4.34e+04     |\n",
      "|    value_loss         | 0.0137       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 67800       |\n",
      "|    time_elapsed       | 1097        |\n",
      "|    total_timesteps    | 339000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.2       |\n",
      "|    explained_variance | -0.132      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 67799       |\n",
      "|    policy_loss        | -0.982      |\n",
      "|    reward             | 0.014565605 |\n",
      "|    std                | 4.36e+04    |\n",
      "|    value_loss         | 0.0022      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 308          |\n",
      "|    iterations         | 67900        |\n",
      "|    time_elapsed       | 1098         |\n",
      "|    total_timesteps    | 339500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.2        |\n",
      "|    explained_variance | -1.48        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 67899        |\n",
      "|    policy_loss        | -0.547       |\n",
      "|    reward             | 0.0022417523 |\n",
      "|    std                | 4.42e+04     |\n",
      "|    value_loss         | 0.000717     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 68000       |\n",
      "|    time_elapsed       | 1100        |\n",
      "|    total_timesteps    | 340000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 67999       |\n",
      "|    policy_loss        | 0.419       |\n",
      "|    reward             | 0.016717093 |\n",
      "|    std                | 4.51e+04    |\n",
      "|    value_loss         | 0.000485    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 68100       |\n",
      "|    time_elapsed       | 1101        |\n",
      "|    total_timesteps    | 340500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.3       |\n",
      "|    explained_variance | 0.268       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68099       |\n",
      "|    policy_loss        | 0.886       |\n",
      "|    reward             | 0.009529072 |\n",
      "|    std                | 4.66e+04    |\n",
      "|    value_loss         | 0.00161     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 68200       |\n",
      "|    time_elapsed       | 1103        |\n",
      "|    total_timesteps    | 341000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.4       |\n",
      "|    explained_variance | 0.3         |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68199       |\n",
      "|    policy_loss        | -1.47       |\n",
      "|    reward             | 0.016546398 |\n",
      "|    std                | 4.75e+04    |\n",
      "|    value_loss         | 0.00747     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 308         |\n",
      "|    iterations         | 68300       |\n",
      "|    time_elapsed       | 1105        |\n",
      "|    total_timesteps    | 341500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.4       |\n",
      "|    explained_variance | 0.0149      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68299       |\n",
      "|    policy_loss        | -1.23       |\n",
      "|    reward             | 0.054799743 |\n",
      "|    std                | 4.8e+04     |\n",
      "|    value_loss         | 0.00588     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 309           |\n",
      "|    iterations         | 68400         |\n",
      "|    time_elapsed       | 1106          |\n",
      "|    total_timesteps    | 342000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.4         |\n",
      "|    explained_variance | -0.0317       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 68399         |\n",
      "|    policy_loss        | 0.0373        |\n",
      "|    reward             | -0.0063999207 |\n",
      "|    std                | 4.88e+04      |\n",
      "|    value_loss         | 5.73e-06      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 68500       |\n",
      "|    time_elapsed       | 1108        |\n",
      "|    total_timesteps    | 342500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.5       |\n",
      "|    explained_variance | -0.421      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68499       |\n",
      "|    policy_loss        | 0.0318      |\n",
      "|    reward             | 0.005631005 |\n",
      "|    std                | 4.98e+04    |\n",
      "|    value_loss         | 2.24e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 68600       |\n",
      "|    time_elapsed       | 1109        |\n",
      "|    total_timesteps    | 343000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.5       |\n",
      "|    explained_variance | -8.67       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 68599       |\n",
      "|    policy_loss        | -0.32       |\n",
      "|    reward             | 0.001689917 |\n",
      "|    std                | 5.1e+04     |\n",
      "|    value_loss         | 0.000339    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 68700        |\n",
      "|    time_elapsed       | 1111         |\n",
      "|    total_timesteps    | 343500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.6        |\n",
      "|    explained_variance | -26          |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 68699        |\n",
      "|    policy_loss        | -0.497       |\n",
      "|    reward             | -0.029906062 |\n",
      "|    std                | 5.28e+04     |\n",
      "|    value_loss         | 0.000575     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 68800        |\n",
      "|    time_elapsed       | 1112         |\n",
      "|    total_timesteps    | 344000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.6        |\n",
      "|    explained_variance | 0.331        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 68799        |\n",
      "|    policy_loss        | -0.392       |\n",
      "|    reward             | -0.019415846 |\n",
      "|    std                | 5.43e+04     |\n",
      "|    value_loss         | 0.000553     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 68900        |\n",
      "|    time_elapsed       | 1114         |\n",
      "|    total_timesteps    | 344500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.7        |\n",
      "|    explained_variance | 0.111        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 68899        |\n",
      "|    policy_loss        | 0.104        |\n",
      "|    reward             | 0.0045514503 |\n",
      "|    std                | 5.62e+04     |\n",
      "|    value_loss         | 0.000264     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 69000        |\n",
      "|    time_elapsed       | 1116         |\n",
      "|    total_timesteps    | 345000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.7        |\n",
      "|    explained_variance | -0.268       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 68999        |\n",
      "|    policy_loss        | -0.0431      |\n",
      "|    reward             | -0.004646921 |\n",
      "|    std                | 5.74e+04     |\n",
      "|    value_loss         | 1.26e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 309           |\n",
      "|    iterations         | 69100         |\n",
      "|    time_elapsed       | 1117          |\n",
      "|    total_timesteps    | 345500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -24.8         |\n",
      "|    explained_variance | -1.61e-05     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 69099         |\n",
      "|    policy_loss        | 0.0511        |\n",
      "|    reward             | -0.0041509857 |\n",
      "|    std                | 5.95e+04      |\n",
      "|    value_loss         | 7.95e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 69200        |\n",
      "|    time_elapsed       | 1119         |\n",
      "|    total_timesteps    | 346000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69199        |\n",
      "|    policy_loss        | 0.129        |\n",
      "|    reward             | -0.057503045 |\n",
      "|    std                | 6.06e+04     |\n",
      "|    value_loss         | 0.000702     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 69300       |\n",
      "|    time_elapsed       | 1121        |\n",
      "|    total_timesteps    | 346500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -24.9       |\n",
      "|    explained_variance | 0.278       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 69299       |\n",
      "|    policy_loss        | -1.62       |\n",
      "|    reward             | 0.034879703 |\n",
      "|    std                | 6.11e+04    |\n",
      "|    value_loss         | 0.00475     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 69400      |\n",
      "|    time_elapsed       | 1122       |\n",
      "|    total_timesteps    | 347000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24.9      |\n",
      "|    explained_variance | -9.54e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 69399      |\n",
      "|    policy_loss        | -0.235     |\n",
      "|    reward             | 0.10293069 |\n",
      "|    std                | 6.21e+04   |\n",
      "|    value_loss         | 0.00172    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 69500      |\n",
      "|    time_elapsed       | 1124       |\n",
      "|    total_timesteps    | 347500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -24.9      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 69499      |\n",
      "|    policy_loss        | -4.76      |\n",
      "|    reward             | 0.14101918 |\n",
      "|    std                | 6.13e+04   |\n",
      "|    value_loss         | 0.198      |\n",
      "--------------------------------------\n",
      "day: 2896, episode: 120\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 96038.46\n",
      "total_reward: 86038.46\n",
      "total_cost: 13.83\n",
      "total_trades: 5789\n",
      "Sharpe: 0.737\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 69600        |\n",
      "|    time_elapsed       | 1126         |\n",
      "|    total_timesteps    | 348000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.9        |\n",
      "|    explained_variance | -0.308       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69599        |\n",
      "|    policy_loss        | 0.376        |\n",
      "|    reward             | -0.008503762 |\n",
      "|    std                | 6.23e+04     |\n",
      "|    value_loss         | 0.000808     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 69700        |\n",
      "|    time_elapsed       | 1127         |\n",
      "|    total_timesteps    | 348500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.9        |\n",
      "|    explained_variance | -4.31        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69699        |\n",
      "|    policy_loss        | 0.0409       |\n",
      "|    reward             | -0.005649897 |\n",
      "|    std                | 6.32e+04     |\n",
      "|    value_loss         | 5e-05        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 69800       |\n",
      "|    time_elapsed       | 1129        |\n",
      "|    total_timesteps    | 349000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25         |\n",
      "|    explained_variance | -0.0481     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 69799       |\n",
      "|    policy_loss        | -0.917      |\n",
      "|    reward             | 0.099213295 |\n",
      "|    std                | 6.48e+04    |\n",
      "|    value_loss         | 0.00176     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 69900        |\n",
      "|    time_elapsed       | 1130         |\n",
      "|    total_timesteps    | 349500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25          |\n",
      "|    explained_variance | 0.518        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 69899        |\n",
      "|    policy_loss        | 0.204        |\n",
      "|    reward             | 0.0049610976 |\n",
      "|    std                | 6.58e+04     |\n",
      "|    value_loss         | 0.00212      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 70000       |\n",
      "|    time_elapsed       | 1132        |\n",
      "|    total_timesteps    | 350000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.1       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 69999       |\n",
      "|    policy_loss        | 1.34        |\n",
      "|    reward             | 0.075855605 |\n",
      "|    std                | 6.72e+04    |\n",
      "|    value_loss         | 0.00695     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 70100       |\n",
      "|    time_elapsed       | 1133        |\n",
      "|    total_timesteps    | 350500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.1       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70099       |\n",
      "|    policy_loss        | 0.9         |\n",
      "|    reward             | 0.019108688 |\n",
      "|    std                | 6.77e+04    |\n",
      "|    value_loss         | 0.0028      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 70200       |\n",
      "|    time_elapsed       | 1135        |\n",
      "|    total_timesteps    | 351000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.1       |\n",
      "|    explained_variance | 0.00159     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70199       |\n",
      "|    policy_loss        | 0.843       |\n",
      "|    reward             | 0.027781337 |\n",
      "|    std                | 6.86e+04    |\n",
      "|    value_loss         | 0.00124     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 70300        |\n",
      "|    time_elapsed       | 1136         |\n",
      "|    total_timesteps    | 351500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70299        |\n",
      "|    policy_loss        | 0.0974       |\n",
      "|    reward             | -0.008525867 |\n",
      "|    std                | 6.97e+04     |\n",
      "|    value_loss         | 2.75e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 70400        |\n",
      "|    time_elapsed       | 1138         |\n",
      "|    total_timesteps    | 352000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.2        |\n",
      "|    explained_variance | 0.0841       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70399        |\n",
      "|    policy_loss        | -0.844       |\n",
      "|    reward             | -0.008268613 |\n",
      "|    std                | 7.15e+04     |\n",
      "|    value_loss         | 0.00143      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 70500      |\n",
      "|    time_elapsed       | 1139       |\n",
      "|    total_timesteps    | 352500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.2      |\n",
      "|    explained_variance | 0.002      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 70499      |\n",
      "|    policy_loss        | -0.162     |\n",
      "|    reward             | 0.01285381 |\n",
      "|    std                | 7.34e+04   |\n",
      "|    value_loss         | 0.000409   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 70600       |\n",
      "|    time_elapsed       | 1141        |\n",
      "|    total_timesteps    | 353000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.3       |\n",
      "|    explained_variance | 0.368       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70599       |\n",
      "|    policy_loss        | -0.0815     |\n",
      "|    reward             | 0.031121677 |\n",
      "|    std                | 7.6e+04     |\n",
      "|    value_loss         | 0.00028     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 70700       |\n",
      "|    time_elapsed       | 1143        |\n",
      "|    total_timesteps    | 353500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 70699       |\n",
      "|    policy_loss        | -2.21       |\n",
      "|    reward             | 0.029354306 |\n",
      "|    std                | 7.69e+04    |\n",
      "|    value_loss         | 0.00848     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 70800        |\n",
      "|    time_elapsed       | 1144         |\n",
      "|    total_timesteps    | 354000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70799        |\n",
      "|    policy_loss        | -0.679       |\n",
      "|    reward             | -0.022468708 |\n",
      "|    std                | 7.86e+04     |\n",
      "|    value_loss         | 0.00114      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 70900        |\n",
      "|    time_elapsed       | 1146         |\n",
      "|    total_timesteps    | 354500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70899        |\n",
      "|    policy_loss        | -0.382       |\n",
      "|    reward             | -0.013765925 |\n",
      "|    std                | 7.99e+04     |\n",
      "|    value_loss         | 0.000302     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 71000        |\n",
      "|    time_elapsed       | 1147         |\n",
      "|    total_timesteps    | 355000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.4        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 70999        |\n",
      "|    policy_loss        | -2.64        |\n",
      "|    reward             | -0.017306678 |\n",
      "|    std                | 8.15e+04     |\n",
      "|    value_loss         | 0.0136       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 71100       |\n",
      "|    time_elapsed       | 1149        |\n",
      "|    total_timesteps    | 355500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 71099       |\n",
      "|    policy_loss        | 0.17        |\n",
      "|    reward             | 0.023806501 |\n",
      "|    std                | 8.19e+04    |\n",
      "|    value_loss         | 0.0066      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 71200      |\n",
      "|    time_elapsed       | 1151       |\n",
      "|    total_timesteps    | 356000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.5      |\n",
      "|    explained_variance | -0.000741  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 71199      |\n",
      "|    policy_loss        | 7.71       |\n",
      "|    reward             | -0.5438779 |\n",
      "|    std                | 8.3e+04    |\n",
      "|    value_loss         | 0.132      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 71300       |\n",
      "|    time_elapsed       | 1152        |\n",
      "|    total_timesteps    | 356500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 71299       |\n",
      "|    policy_loss        | 0.118       |\n",
      "|    reward             | 0.030999655 |\n",
      "|    std                | 8.36e+04    |\n",
      "|    value_loss         | 0.000174    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 309           |\n",
      "|    iterations         | 71400         |\n",
      "|    time_elapsed       | 1154          |\n",
      "|    total_timesteps    | 357000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.5         |\n",
      "|    explained_variance | 0.83          |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 71399         |\n",
      "|    policy_loss        | 0.994         |\n",
      "|    reward             | 0.00055540696 |\n",
      "|    std                | 8.45e+04      |\n",
      "|    value_loss         | 0.00168       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 71500      |\n",
      "|    time_elapsed       | 1155       |\n",
      "|    total_timesteps    | 357500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.6      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 71499      |\n",
      "|    policy_loss        | 0.367      |\n",
      "|    reward             | 0.02545525 |\n",
      "|    std                | 8.67e+04   |\n",
      "|    value_loss         | 0.000906   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 71600      |\n",
      "|    time_elapsed       | 1156       |\n",
      "|    total_timesteps    | 358000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.6      |\n",
      "|    explained_variance | 0.21       |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 71599      |\n",
      "|    policy_loss        | 3.41       |\n",
      "|    reward             | 0.07357041 |\n",
      "|    std                | 8.78e+04   |\n",
      "|    value_loss         | 0.0208     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 71700        |\n",
      "|    time_elapsed       | 1158         |\n",
      "|    total_timesteps    | 358500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.6        |\n",
      "|    explained_variance | 0.332        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 71699        |\n",
      "|    policy_loss        | 0.0622       |\n",
      "|    reward             | -0.045087244 |\n",
      "|    std                | 8.9e+04      |\n",
      "|    value_loss         | 0.0297       |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 309       |\n",
      "|    iterations         | 71800     |\n",
      "|    time_elapsed       | 1159      |\n",
      "|    total_timesteps    | 359000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -25.6     |\n",
      "|    explained_variance | 0.127     |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 71799     |\n",
      "|    policy_loss        | -9.12     |\n",
      "|    reward             | 0.5408797 |\n",
      "|    std                | 9.03e+04  |\n",
      "|    value_loss         | 0.242     |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 309           |\n",
      "|    iterations         | 71900         |\n",
      "|    time_elapsed       | 1161          |\n",
      "|    total_timesteps    | 359500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 71899         |\n",
      "|    policy_loss        | 0.521         |\n",
      "|    reward             | 0.00087353704 |\n",
      "|    std                | 9.09e+04      |\n",
      "|    value_loss         | 0.000508      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 72000        |\n",
      "|    time_elapsed       | 1163         |\n",
      "|    total_timesteps    | 360000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.7        |\n",
      "|    explained_variance | 0.765        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 71999        |\n",
      "|    policy_loss        | -0.472       |\n",
      "|    reward             | -0.019774001 |\n",
      "|    std                | 9.23e+04     |\n",
      "|    value_loss         | 0.000445     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 72100      |\n",
      "|    time_elapsed       | 1164       |\n",
      "|    total_timesteps    | 360500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -25.7      |\n",
      "|    explained_variance | -1.17      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 72099      |\n",
      "|    policy_loss        | 0.267      |\n",
      "|    reward             | 0.04333636 |\n",
      "|    std                | 9.34e+04   |\n",
      "|    value_loss         | 0.00053    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 72200       |\n",
      "|    time_elapsed       | 1166        |\n",
      "|    total_timesteps    | 361000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.8       |\n",
      "|    explained_variance | -0.876      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 72199       |\n",
      "|    policy_loss        | -0.723      |\n",
      "|    reward             | 0.042375304 |\n",
      "|    std                | 9.54e+04    |\n",
      "|    value_loss         | 0.00123     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 72300       |\n",
      "|    time_elapsed       | 1167        |\n",
      "|    total_timesteps    | 361500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.8       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 72299       |\n",
      "|    policy_loss        | -0.659      |\n",
      "|    reward             | 0.010794329 |\n",
      "|    std                | 9.71e+04    |\n",
      "|    value_loss         | 0.00168     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 72400        |\n",
      "|    time_elapsed       | 1169         |\n",
      "|    total_timesteps    | 362000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.8        |\n",
      "|    explained_variance | 0.144        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72399        |\n",
      "|    policy_loss        | -3.92        |\n",
      "|    reward             | -0.042967416 |\n",
      "|    std                | 9.79e+04     |\n",
      "|    value_loss         | 0.0363       |\n",
      "----------------------------------------\n",
      "day: 2896, episode: 125\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 81397.47\n",
      "total_reward: 71397.47\n",
      "total_cost: 15.41\n",
      "total_trades: 5791\n",
      "Sharpe: 0.740\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 309           |\n",
      "|    iterations         | 72500         |\n",
      "|    time_elapsed       | 1170          |\n",
      "|    total_timesteps    | 362500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.8         |\n",
      "|    explained_variance | 0.0107        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 72499         |\n",
      "|    policy_loss        | 1.24          |\n",
      "|    reward             | -0.0148816975 |\n",
      "|    std                | 9.93e+04      |\n",
      "|    value_loss         | 0.00493       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 72600        |\n",
      "|    time_elapsed       | 1172         |\n",
      "|    total_timesteps    | 363000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72599        |\n",
      "|    policy_loss        | 0.0293       |\n",
      "|    reward             | 0.0033273755 |\n",
      "|    std                | 1e+05        |\n",
      "|    value_loss         | 0.000146     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 72700        |\n",
      "|    time_elapsed       | 1173         |\n",
      "|    total_timesteps    | 363500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.9        |\n",
      "|    explained_variance | 0.178        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72699        |\n",
      "|    policy_loss        | 2.63         |\n",
      "|    reward             | -0.031094186 |\n",
      "|    std                | 1.01e+05     |\n",
      "|    value_loss         | 0.0182       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 72800        |\n",
      "|    time_elapsed       | 1175         |\n",
      "|    total_timesteps    | 364000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -25.9        |\n",
      "|    explained_variance | 0.535        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 72799        |\n",
      "|    policy_loss        | -0.446       |\n",
      "|    reward             | -0.020153064 |\n",
      "|    std                | 1.02e+05     |\n",
      "|    value_loss         | 0.0107       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 72900       |\n",
      "|    time_elapsed       | 1176        |\n",
      "|    total_timesteps    | 364500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.9       |\n",
      "|    explained_variance | 0.421       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 72899       |\n",
      "|    policy_loss        | 3.19        |\n",
      "|    reward             | 0.024414968 |\n",
      "|    std                | 1.03e+05    |\n",
      "|    value_loss         | 0.0248      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 73000       |\n",
      "|    time_elapsed       | 1178        |\n",
      "|    total_timesteps    | 365000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.9       |\n",
      "|    explained_variance | 0.279       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 72999       |\n",
      "|    policy_loss        | -0.315      |\n",
      "|    reward             | -0.16247301 |\n",
      "|    std                | 1.03e+05    |\n",
      "|    value_loss         | 0.0293      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 73100       |\n",
      "|    time_elapsed       | 1180        |\n",
      "|    total_timesteps    | 365500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -25.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73099       |\n",
      "|    policy_loss        | -0.313      |\n",
      "|    reward             | 0.017068852 |\n",
      "|    std                | 1.04e+05    |\n",
      "|    value_loss         | 0.000255    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 73200       |\n",
      "|    time_elapsed       | 1181        |\n",
      "|    total_timesteps    | 366000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26         |\n",
      "|    explained_variance | -0.333      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73199       |\n",
      "|    policy_loss        | 0.826       |\n",
      "|    reward             | 0.026389785 |\n",
      "|    std                | 1.06e+05    |\n",
      "|    value_loss         | 0.00143     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 73300       |\n",
      "|    time_elapsed       | 1183        |\n",
      "|    total_timesteps    | 366500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26         |\n",
      "|    explained_variance | 0.534       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73299       |\n",
      "|    policy_loss        | -2.86       |\n",
      "|    reward             | 0.047020707 |\n",
      "|    std                | 1.08e+05    |\n",
      "|    value_loss         | 0.0121      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 73400       |\n",
      "|    time_elapsed       | 1184        |\n",
      "|    total_timesteps    | 367000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26         |\n",
      "|    explained_variance | -0.0266     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73399       |\n",
      "|    policy_loss        | -2.36       |\n",
      "|    reward             | -0.11235721 |\n",
      "|    std                | 1.09e+05    |\n",
      "|    value_loss         | 0.0085      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 73500       |\n",
      "|    time_elapsed       | 1186        |\n",
      "|    total_timesteps    | 367500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.1       |\n",
      "|    explained_variance | 0.387       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 73499       |\n",
      "|    policy_loss        | -0.743      |\n",
      "|    reward             | 0.071369626 |\n",
      "|    std                | 1.1e+05     |\n",
      "|    value_loss         | 0.00253     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 73600        |\n",
      "|    time_elapsed       | 1187         |\n",
      "|    total_timesteps    | 368000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.1        |\n",
      "|    explained_variance | 0.0226       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 73599        |\n",
      "|    policy_loss        | -0.592       |\n",
      "|    reward             | -0.010681022 |\n",
      "|    std                | 1.12e+05     |\n",
      "|    value_loss         | 0.00056      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 73700        |\n",
      "|    time_elapsed       | 1189         |\n",
      "|    total_timesteps    | 368500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.1        |\n",
      "|    explained_variance | 0.209        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 73699        |\n",
      "|    policy_loss        | -0.0754      |\n",
      "|    reward             | -0.012523211 |\n",
      "|    std                | 1.14e+05     |\n",
      "|    value_loss         | 0.000104     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 73800      |\n",
      "|    time_elapsed       | 1190       |\n",
      "|    total_timesteps    | 369000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.2      |\n",
      "|    explained_variance | -6.82e-05  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 73799      |\n",
      "|    policy_loss        | -0.688     |\n",
      "|    reward             | 0.05624882 |\n",
      "|    std                | 1.16e+05   |\n",
      "|    value_loss         | 0.000968   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 73900        |\n",
      "|    time_elapsed       | 1192         |\n",
      "|    total_timesteps    | 369500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.2        |\n",
      "|    explained_variance | 0.67         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 73899        |\n",
      "|    policy_loss        | -2.04        |\n",
      "|    reward             | -0.022216445 |\n",
      "|    std                | 1.18e+05     |\n",
      "|    value_loss         | 0.00688      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 309           |\n",
      "|    iterations         | 74000         |\n",
      "|    time_elapsed       | 1193          |\n",
      "|    total_timesteps    | 370000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.2         |\n",
      "|    explained_variance | 0.121         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 73999         |\n",
      "|    policy_loss        | -4.44         |\n",
      "|    reward             | -0.0063891127 |\n",
      "|    std                | 1.2e+05       |\n",
      "|    value_loss         | 0.0375        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 74100       |\n",
      "|    time_elapsed       | 1195        |\n",
      "|    total_timesteps    | 370500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 74099       |\n",
      "|    policy_loss        | -1.07       |\n",
      "|    reward             | 0.058827966 |\n",
      "|    std                | 1.2e+05     |\n",
      "|    value_loss         | 0.0121      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 74200        |\n",
      "|    time_elapsed       | 1196         |\n",
      "|    total_timesteps    | 371000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.2        |\n",
      "|    explained_variance | -0.00015     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 74199        |\n",
      "|    policy_loss        | -0.113       |\n",
      "|    reward             | 0.0057687094 |\n",
      "|    std                | 1.21e+05     |\n",
      "|    value_loss         | 6.16e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 74300       |\n",
      "|    time_elapsed       | 1198        |\n",
      "|    total_timesteps    | 371500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.3       |\n",
      "|    explained_variance | -0.00104    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 74299       |\n",
      "|    policy_loss        | 0.098       |\n",
      "|    reward             | 0.009282409 |\n",
      "|    std                | 1.22e+05    |\n",
      "|    value_loss         | 5.74e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 74400       |\n",
      "|    time_elapsed       | 1199        |\n",
      "|    total_timesteps    | 372000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 74399       |\n",
      "|    policy_loss        | 3.62        |\n",
      "|    reward             | -0.03206426 |\n",
      "|    std                | 1.24e+05    |\n",
      "|    value_loss         | 0.0239      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 74500      |\n",
      "|    time_elapsed       | 1201       |\n",
      "|    total_timesteps    | 372500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.3      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 74499      |\n",
      "|    policy_loss        | -2.94      |\n",
      "|    reward             | 0.06705247 |\n",
      "|    std                | 1.26e+05   |\n",
      "|    value_loss         | 0.0131     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 74600      |\n",
      "|    time_elapsed       | 1203       |\n",
      "|    total_timesteps    | 373000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.4      |\n",
      "|    explained_variance | 0.127      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 74599      |\n",
      "|    policy_loss        | 2.49       |\n",
      "|    reward             | 0.11051643 |\n",
      "|    std                | 1.28e+05   |\n",
      "|    value_loss         | 0.0129     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 74700      |\n",
      "|    time_elapsed       | 1204       |\n",
      "|    total_timesteps    | 373500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -26.3      |\n",
      "|    explained_variance | -0.171     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 74699      |\n",
      "|    policy_loss        | 3.06       |\n",
      "|    reward             | 0.07940569 |\n",
      "|    std                | 1.27e+05   |\n",
      "|    value_loss         | 0.0197     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 74800        |\n",
      "|    time_elapsed       | 1206         |\n",
      "|    total_timesteps    | 374000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 74799        |\n",
      "|    policy_loss        | -0.00243     |\n",
      "|    reward             | -0.005216189 |\n",
      "|    std                | 1.28e+05     |\n",
      "|    value_loss         | 1.62e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 74900        |\n",
      "|    time_elapsed       | 1207         |\n",
      "|    total_timesteps    | 374500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.4        |\n",
      "|    explained_variance | 0.467        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 74899        |\n",
      "|    policy_loss        | 0.284        |\n",
      "|    reward             | 0.0046147224 |\n",
      "|    std                | 1.3e+05      |\n",
      "|    value_loss         | 0.000148     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 75000        |\n",
      "|    time_elapsed       | 1209         |\n",
      "|    total_timesteps    | 375000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.4        |\n",
      "|    explained_variance | 0.357        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 74999        |\n",
      "|    policy_loss        | -0.0567      |\n",
      "|    reward             | 0.0004532364 |\n",
      "|    std                | 1.33e+05     |\n",
      "|    value_loss         | 0.000218     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 75100        |\n",
      "|    time_elapsed       | 1210         |\n",
      "|    total_timesteps    | 375500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 75099        |\n",
      "|    policy_loss        | -0.217       |\n",
      "|    reward             | -0.012294726 |\n",
      "|    std                | 1.36e+05     |\n",
      "|    value_loss         | 0.000149     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 75200       |\n",
      "|    time_elapsed       | 1212        |\n",
      "|    total_timesteps    | 376000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75199       |\n",
      "|    policy_loss        | -1.01       |\n",
      "|    reward             | 0.008093664 |\n",
      "|    std                | 1.38e+05    |\n",
      "|    value_loss         | 0.00195     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 75300       |\n",
      "|    time_elapsed       | 1213        |\n",
      "|    total_timesteps    | 376500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.5       |\n",
      "|    explained_variance | 0.481       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75299       |\n",
      "|    policy_loss        | -2.04       |\n",
      "|    reward             | -0.07297258 |\n",
      "|    std                | 1.41e+05    |\n",
      "|    value_loss         | 0.0103      |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 130\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 53842.31\n",
      "total_reward: 43842.31\n",
      "total_cost: 16.91\n",
      "total_trades: 5790\n",
      "Sharpe: 0.641\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 75400        |\n",
      "|    time_elapsed       | 1215         |\n",
      "|    total_timesteps    | 377000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.6        |\n",
      "|    explained_variance | 0.435        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 75399        |\n",
      "|    policy_loss        | 0.0749       |\n",
      "|    reward             | -0.016267527 |\n",
      "|    std                | 1.43e+05     |\n",
      "|    value_loss         | 6.55e-05     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 75500       |\n",
      "|    time_elapsed       | 1216        |\n",
      "|    total_timesteps    | 377500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.6       |\n",
      "|    explained_variance | -0.00394    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75499       |\n",
      "|    policy_loss        | -0.409      |\n",
      "|    reward             | 0.024265885 |\n",
      "|    std                | 1.45e+05    |\n",
      "|    value_loss         | 0.000244    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 75600        |\n",
      "|    time_elapsed       | 1218         |\n",
      "|    total_timesteps    | 378000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.7        |\n",
      "|    explained_variance | 0.393        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 75599        |\n",
      "|    policy_loss        | -0.432       |\n",
      "|    reward             | -0.051316153 |\n",
      "|    std                | 1.5e+05      |\n",
      "|    value_loss         | 0.00347      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 75700        |\n",
      "|    time_elapsed       | 1220         |\n",
      "|    total_timesteps    | 378500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.7        |\n",
      "|    explained_variance | 0.404        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 75699        |\n",
      "|    policy_loss        | -2.35        |\n",
      "|    reward             | -0.026261296 |\n",
      "|    std                | 1.51e+05     |\n",
      "|    value_loss         | 0.0199       |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 310       |\n",
      "|    iterations         | 75800     |\n",
      "|    time_elapsed       | 1221      |\n",
      "|    total_timesteps    | 379000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -26.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 75799     |\n",
      "|    policy_loss        | -1.29     |\n",
      "|    reward             | 0.0582657 |\n",
      "|    std                | 1.51e+05  |\n",
      "|    value_loss         | 0.00421   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 75900       |\n",
      "|    time_elapsed       | 1223        |\n",
      "|    total_timesteps    | 379500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.7       |\n",
      "|    explained_variance | -2.12e-05   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75899       |\n",
      "|    policy_loss        | 4.32        |\n",
      "|    reward             | 0.120204106 |\n",
      "|    std                | 1.51e+05    |\n",
      "|    value_loss         | 0.0465      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 76000       |\n",
      "|    time_elapsed       | 1225        |\n",
      "|    total_timesteps    | 380000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.7       |\n",
      "|    explained_variance | 0.348       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 75999       |\n",
      "|    policy_loss        | 0.0765      |\n",
      "|    reward             | 0.008206956 |\n",
      "|    std                | 1.53e+05    |\n",
      "|    value_loss         | 3.99e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 76100        |\n",
      "|    time_elapsed       | 1226         |\n",
      "|    total_timesteps    | 380500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.7        |\n",
      "|    explained_variance | 0.12         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76099        |\n",
      "|    policy_loss        | 0.359        |\n",
      "|    reward             | -0.011512911 |\n",
      "|    std                | 1.55e+05     |\n",
      "|    value_loss         | 0.000198     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 76200       |\n",
      "|    time_elapsed       | 1228        |\n",
      "|    total_timesteps    | 381000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -26.8       |\n",
      "|    explained_variance | -2.05       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 76199       |\n",
      "|    policy_loss        | 0.487       |\n",
      "|    reward             | -0.01743866 |\n",
      "|    std                | 1.59e+05    |\n",
      "|    value_loss         | 0.00032     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 76300         |\n",
      "|    time_elapsed       | 1229          |\n",
      "|    total_timesteps    | 381500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -26.8         |\n",
      "|    explained_variance | 3.13e-05      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 76299         |\n",
      "|    policy_loss        | -0.332        |\n",
      "|    reward             | -5.956192e-05 |\n",
      "|    std                | 1.63e+05      |\n",
      "|    value_loss         | 0.000219      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 76400        |\n",
      "|    time_elapsed       | 1231         |\n",
      "|    total_timesteps    | 382000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.9        |\n",
      "|    explained_variance | 0.627        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76399        |\n",
      "|    policy_loss        | -0.212       |\n",
      "|    reward             | -0.006458657 |\n",
      "|    std                | 1.69e+05     |\n",
      "|    value_loss         | 6.86e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 76500        |\n",
      "|    time_elapsed       | 1232         |\n",
      "|    total_timesteps    | 382500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.9        |\n",
      "|    explained_variance | -0.0841      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 76499        |\n",
      "|    policy_loss        | -1.13        |\n",
      "|    reward             | 0.0070171757 |\n",
      "|    std                | 1.71e+05     |\n",
      "|    value_loss         | 0.00184      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 76600         |\n",
      "|    time_elapsed       | 1234          |\n",
      "|    total_timesteps    | 383000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27           |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 76599         |\n",
      "|    policy_loss        | 0.354         |\n",
      "|    reward             | -0.0044474266 |\n",
      "|    std                | 1.75e+05      |\n",
      "|    value_loss         | 0.000202      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 76700       |\n",
      "|    time_elapsed       | 1235        |\n",
      "|    total_timesteps    | 383500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27         |\n",
      "|    explained_variance | 0.0506      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 76699       |\n",
      "|    policy_loss        | 0.0209      |\n",
      "|    reward             | 0.014704602 |\n",
      "|    std                | 1.79e+05    |\n",
      "|    value_loss         | 8.57e-05    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 76800       |\n",
      "|    time_elapsed       | 1237        |\n",
      "|    total_timesteps    | 384000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.1       |\n",
      "|    explained_variance | -0.0133     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 76799       |\n",
      "|    policy_loss        | 1.91        |\n",
      "|    reward             | 0.020285932 |\n",
      "|    std                | 1.86e+05    |\n",
      "|    value_loss         | 0.00555     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 76900       |\n",
      "|    time_elapsed       | 1239        |\n",
      "|    total_timesteps    | 384500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.1       |\n",
      "|    explained_variance | 0.423       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 76899       |\n",
      "|    policy_loss        | 3.78        |\n",
      "|    reward             | 0.065339476 |\n",
      "|    std                | 1.9e+05     |\n",
      "|    value_loss         | 0.0195      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 77000       |\n",
      "|    time_elapsed       | 1240        |\n",
      "|    total_timesteps    | 385000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.1       |\n",
      "|    explained_variance | 0.00213     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 76999       |\n",
      "|    policy_loss        | -0.478      |\n",
      "|    reward             | -0.09463933 |\n",
      "|    std                | 1.89e+05    |\n",
      "|    value_loss         | 0.00377     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 77100        |\n",
      "|    time_elapsed       | 1242         |\n",
      "|    total_timesteps    | 385500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.2        |\n",
      "|    explained_variance | -5.89        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77099        |\n",
      "|    policy_loss        | 0.679        |\n",
      "|    reward             | 0.0027359996 |\n",
      "|    std                | 1.91e+05     |\n",
      "|    value_loss         | 0.00153      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 77200       |\n",
      "|    time_elapsed       | 1243        |\n",
      "|    total_timesteps    | 386000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.2       |\n",
      "|    explained_variance | 0.387       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 77199       |\n",
      "|    policy_loss        | 0.562       |\n",
      "|    reward             | 0.015102311 |\n",
      "|    std                | 1.94e+05    |\n",
      "|    value_loss         | 0.000527    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 77300        |\n",
      "|    time_elapsed       | 1245         |\n",
      "|    total_timesteps    | 386500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.2        |\n",
      "|    explained_variance | 0.0743       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77299        |\n",
      "|    policy_loss        | 0.0486       |\n",
      "|    reward             | -0.048779905 |\n",
      "|    std                | 2e+05        |\n",
      "|    value_loss         | 0.00013      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 77400        |\n",
      "|    time_elapsed       | 1246         |\n",
      "|    total_timesteps    | 387000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.3        |\n",
      "|    explained_variance | 0.0744       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77399        |\n",
      "|    policy_loss        | 1.13         |\n",
      "|    reward             | -0.006311729 |\n",
      "|    std                | 2.02e+05     |\n",
      "|    value_loss         | 0.00254      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 77500      |\n",
      "|    time_elapsed       | 1248       |\n",
      "|    total_timesteps    | 387500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27.3      |\n",
      "|    explained_variance | -0.103     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 77499      |\n",
      "|    policy_loss        | -2.03      |\n",
      "|    reward             | 0.33442006 |\n",
      "|    std                | 2.04e+05   |\n",
      "|    value_loss         | 0.0125     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 77600      |\n",
      "|    time_elapsed       | 1249       |\n",
      "|    total_timesteps    | 388000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27.3      |\n",
      "|    explained_variance | 0.207      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 77599      |\n",
      "|    policy_loss        | -5.39      |\n",
      "|    reward             | 0.29140836 |\n",
      "|    std                | 2.01e+05   |\n",
      "|    value_loss         | 0.0527     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 77700         |\n",
      "|    time_elapsed       | 1251          |\n",
      "|    total_timesteps    | 388500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.3         |\n",
      "|    explained_variance | -19.4         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 77699         |\n",
      "|    policy_loss        | 1.86          |\n",
      "|    reward             | -0.0052036336 |\n",
      "|    std                | 2.03e+05      |\n",
      "|    value_loss         | 0.00746       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 77800         |\n",
      "|    time_elapsed       | 1252          |\n",
      "|    total_timesteps    | 389000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 77799         |\n",
      "|    policy_loss        | 0.381         |\n",
      "|    reward             | -0.0060676984 |\n",
      "|    std                | 2.07e+05      |\n",
      "|    value_loss         | 0.000453      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 77900       |\n",
      "|    time_elapsed       | 1254        |\n",
      "|    total_timesteps    | 389500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.3       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 77899       |\n",
      "|    policy_loss        | 2.4         |\n",
      "|    reward             | -0.02199508 |\n",
      "|    std                | 2.09e+05    |\n",
      "|    value_loss         | 0.00957     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 78000        |\n",
      "|    time_elapsed       | 1255         |\n",
      "|    total_timesteps    | 390000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 77999        |\n",
      "|    policy_loss        | 0.0915       |\n",
      "|    reward             | -0.010285944 |\n",
      "|    std                | 2.14e+05     |\n",
      "|    value_loss         | 0.00185      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 78100        |\n",
      "|    time_elapsed       | 1257         |\n",
      "|    total_timesteps    | 390500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.4        |\n",
      "|    explained_variance | 0.39         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 78099        |\n",
      "|    policy_loss        | -3.65        |\n",
      "|    reward             | -0.043690752 |\n",
      "|    std                | 2.21e+05     |\n",
      "|    value_loss         | 0.0202       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 78200      |\n",
      "|    time_elapsed       | 1258       |\n",
      "|    total_timesteps    | 391000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27.5      |\n",
      "|    explained_variance | 0.263      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 78199      |\n",
      "|    policy_loss        | -7.94      |\n",
      "|    reward             | 0.10618593 |\n",
      "|    std                | 2.22e+05   |\n",
      "|    value_loss         | 0.0865     |\n",
      "--------------------------------------\n",
      "day: 2896, episode: 135\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 69377.88\n",
      "total_reward: 59377.88\n",
      "total_cost: 10.35\n",
      "total_trades: 5792\n",
      "Sharpe: 0.687\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 78300        |\n",
      "|    time_elapsed       | 1260         |\n",
      "|    total_timesteps    | 391500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.5        |\n",
      "|    explained_variance | 0.214        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 78299        |\n",
      "|    policy_loss        | -1           |\n",
      "|    reward             | 0.0097742025 |\n",
      "|    std                | 2.25e+05     |\n",
      "|    value_loss         | 0.00221      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 78400       |\n",
      "|    time_elapsed       | 1261        |\n",
      "|    total_timesteps    | 392000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.5       |\n",
      "|    explained_variance | 0.0807      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78399       |\n",
      "|    policy_loss        | -0.843      |\n",
      "|    reward             | 0.015841074 |\n",
      "|    std                | 2.26e+05    |\n",
      "|    value_loss         | 0.00248     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 78500       |\n",
      "|    time_elapsed       | 1263        |\n",
      "|    total_timesteps    | 392500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.5       |\n",
      "|    explained_variance | 0.448       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78499       |\n",
      "|    policy_loss        | 5.12        |\n",
      "|    reward             | -0.35589445 |\n",
      "|    std                | 2.31e+05    |\n",
      "|    value_loss         | 0.0352      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 310       |\n",
      "|    iterations         | 78600     |\n",
      "|    time_elapsed       | 1265      |\n",
      "|    total_timesteps    | 393000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.5     |\n",
      "|    explained_variance | 3.87e-06  |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 78599     |\n",
      "|    policy_loss        | -7.67     |\n",
      "|    reward             | 0.1790318 |\n",
      "|    std                | 2.33e+05  |\n",
      "|    value_loss         | 0.0868    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 78700      |\n",
      "|    time_elapsed       | 1266       |\n",
      "|    total_timesteps    | 393500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27.5      |\n",
      "|    explained_variance | 0.846      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 78699      |\n",
      "|    policy_loss        | 3.31       |\n",
      "|    reward             | 0.16184892 |\n",
      "|    std                | 2.32e+05   |\n",
      "|    value_loss         | 0.0203     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 78800       |\n",
      "|    time_elapsed       | 1268        |\n",
      "|    total_timesteps    | 394000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.6       |\n",
      "|    explained_variance | -0.585      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78799       |\n",
      "|    policy_loss        | -39.7       |\n",
      "|    reward             | 0.019764207 |\n",
      "|    std                | 2.34e+05    |\n",
      "|    value_loss         | 3.75        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 78900       |\n",
      "|    time_elapsed       | 1269        |\n",
      "|    total_timesteps    | 394500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 78899       |\n",
      "|    policy_loss        | -0.151      |\n",
      "|    reward             | 0.012316129 |\n",
      "|    std                | 2.37e+05    |\n",
      "|    value_loss         | 0.000121    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 79000        |\n",
      "|    time_elapsed       | 1271         |\n",
      "|    total_timesteps    | 395000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 78999        |\n",
      "|    policy_loss        | -0.739       |\n",
      "|    reward             | -0.008307752 |\n",
      "|    std                | 2.41e+05     |\n",
      "|    value_loss         | 0.00107      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 310       |\n",
      "|    iterations         | 79100     |\n",
      "|    time_elapsed       | 1272      |\n",
      "|    total_timesteps    | 395500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -27.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 79099     |\n",
      "|    policy_loss        | 1.35      |\n",
      "|    reward             | 0.0301929 |\n",
      "|    std                | 2.45e+05  |\n",
      "|    value_loss         | 0.00306   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 79200       |\n",
      "|    time_elapsed       | 1274        |\n",
      "|    total_timesteps    | 396000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.7       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79199       |\n",
      "|    policy_loss        | -2.65       |\n",
      "|    reward             | -0.03334663 |\n",
      "|    std                | 2.49e+05    |\n",
      "|    value_loss         | 0.011       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 79300      |\n",
      "|    time_elapsed       | 1275       |\n",
      "|    total_timesteps    | 396500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27.7      |\n",
      "|    explained_variance | 0.000748   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 79299      |\n",
      "|    policy_loss        | -17.7      |\n",
      "|    reward             | 0.28095013 |\n",
      "|    std                | 2.5e+05    |\n",
      "|    value_loss         | 0.44       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 79400         |\n",
      "|    time_elapsed       | 1277          |\n",
      "|    total_timesteps    | 397000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.7         |\n",
      "|    explained_variance | -1.07         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 79399         |\n",
      "|    policy_loss        | -0.399        |\n",
      "|    reward             | -0.0089559825 |\n",
      "|    std                | 2.53e+05      |\n",
      "|    value_loss         | 0.000411      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 79500       |\n",
      "|    time_elapsed       | 1278        |\n",
      "|    total_timesteps    | 397500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.7       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79499       |\n",
      "|    policy_loss        | -0.0517     |\n",
      "|    reward             | 0.015449317 |\n",
      "|    std                | 2.56e+05    |\n",
      "|    value_loss         | 0.000113    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 79600      |\n",
      "|    time_elapsed       | 1280       |\n",
      "|    total_timesteps    | 398000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27.8      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 79599      |\n",
      "|    policy_loss        | -0.141     |\n",
      "|    reward             | 0.15068674 |\n",
      "|    std                | 2.59e+05   |\n",
      "|    value_loss         | 0.000202   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 79700       |\n",
      "|    time_elapsed       | 1282        |\n",
      "|    total_timesteps    | 398500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79699       |\n",
      "|    policy_loss        | -0.362      |\n",
      "|    reward             | -0.07618253 |\n",
      "|    std                | 2.64e+05    |\n",
      "|    value_loss         | 0.00144     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 79800       |\n",
      "|    time_elapsed       | 1284        |\n",
      "|    total_timesteps    | 399000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.8       |\n",
      "|    explained_variance | 0.0665      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79799       |\n",
      "|    policy_loss        | -4.38       |\n",
      "|    reward             | -0.07637016 |\n",
      "|    std                | 2.69e+05    |\n",
      "|    value_loss         | 0.032       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 79900       |\n",
      "|    time_elapsed       | 1286        |\n",
      "|    total_timesteps    | 399500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.8       |\n",
      "|    explained_variance | 0.161       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 79899       |\n",
      "|    policy_loss        | 0.688       |\n",
      "|    reward             | -0.07702822 |\n",
      "|    std                | 2.66e+05    |\n",
      "|    value_loss         | 0.0208      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 80000      |\n",
      "|    time_elapsed       | 1287       |\n",
      "|    total_timesteps    | 400000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -27.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 79999      |\n",
      "|    policy_loss        | -0.852     |\n",
      "|    reward             | 0.03819464 |\n",
      "|    std                | 2.7e+05    |\n",
      "|    value_loss         | 0.000978   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 80100       |\n",
      "|    time_elapsed       | 1289        |\n",
      "|    total_timesteps    | 400500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27.9       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80099       |\n",
      "|    policy_loss        | 0.141       |\n",
      "|    reward             | 0.010199595 |\n",
      "|    std                | 2.75e+05    |\n",
      "|    value_loss         | 3.08e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 80200        |\n",
      "|    time_elapsed       | 1290         |\n",
      "|    total_timesteps    | 401000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 80199        |\n",
      "|    policy_loss        | 0.165        |\n",
      "|    reward             | -0.010770741 |\n",
      "|    std                | 2.81e+05     |\n",
      "|    value_loss         | 0.000252     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 80300         |\n",
      "|    time_elapsed       | 1292          |\n",
      "|    total_timesteps    | 401500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28           |\n",
      "|    explained_variance | 0.348         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 80299         |\n",
      "|    policy_loss        | 0.402         |\n",
      "|    reward             | -0.0046846177 |\n",
      "|    std                | 2.88e+05      |\n",
      "|    value_loss         | 0.000381      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 80400      |\n",
      "|    time_elapsed       | 1293       |\n",
      "|    total_timesteps    | 402000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28        |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 80399      |\n",
      "|    policy_loss        | 3.6        |\n",
      "|    reward             | 0.04907071 |\n",
      "|    std                | 2.94e+05   |\n",
      "|    value_loss         | 0.0225     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 80500       |\n",
      "|    time_elapsed       | 1295        |\n",
      "|    total_timesteps    | 402500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28         |\n",
      "|    explained_variance | 0.335       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80499       |\n",
      "|    policy_loss        | 2.87        |\n",
      "|    reward             | 0.017234726 |\n",
      "|    std                | 2.96e+05    |\n",
      "|    value_loss         | 0.0115      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 80600       |\n",
      "|    time_elapsed       | 1297        |\n",
      "|    total_timesteps    | 403000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28         |\n",
      "|    explained_variance | 0.855       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80599       |\n",
      "|    policy_loss        | -0.18       |\n",
      "|    reward             | 0.004067154 |\n",
      "|    std                | 2.99e+05    |\n",
      "|    value_loss         | 0.0001      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 80700       |\n",
      "|    time_elapsed       | 1298        |\n",
      "|    total_timesteps    | 403500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.1       |\n",
      "|    explained_variance | -0.0859     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80699       |\n",
      "|    policy_loss        | -0.885      |\n",
      "|    reward             | 0.007931672 |\n",
      "|    std                | 3.04e+05    |\n",
      "|    value_loss         | 0.00127     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 80800        |\n",
      "|    time_elapsed       | 1300         |\n",
      "|    total_timesteps    | 404000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.1        |\n",
      "|    explained_variance | -0.0742      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 80799        |\n",
      "|    policy_loss        | 0.483        |\n",
      "|    reward             | -0.015377465 |\n",
      "|    std                | 3.07e+05     |\n",
      "|    value_loss         | 0.000701     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 80900       |\n",
      "|    time_elapsed       | 1301        |\n",
      "|    total_timesteps    | 404500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.1       |\n",
      "|    explained_variance | 0.156       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 80899       |\n",
      "|    policy_loss        | -4.55       |\n",
      "|    reward             | -0.02483382 |\n",
      "|    std                | 3.1e+05     |\n",
      "|    value_loss         | 0.0402      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 81000        |\n",
      "|    time_elapsed       | 1303         |\n",
      "|    total_timesteps    | 405000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.1        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 80999        |\n",
      "|    policy_loss        | 8.11         |\n",
      "|    reward             | 0.0028920814 |\n",
      "|    std                | 3.12e+05     |\n",
      "|    value_loss         | 0.112        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 81100      |\n",
      "|    time_elapsed       | 1305       |\n",
      "|    total_timesteps    | 405500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.1      |\n",
      "|    explained_variance | 0.591      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 81099      |\n",
      "|    policy_loss        | -4.21      |\n",
      "|    reward             | 0.12989505 |\n",
      "|    std                | 3.08e+05   |\n",
      "|    value_loss         | 0.0264     |\n",
      "--------------------------------------\n",
      "day: 2896, episode: 140\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 125965.04\n",
      "total_reward: 115965.04\n",
      "total_cost: 38.33\n",
      "total_trades: 5789\n",
      "Sharpe: 0.809\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 81200         |\n",
      "|    time_elapsed       | 1306          |\n",
      "|    total_timesteps    | 406000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.1         |\n",
      "|    explained_variance | -0.308        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 81199         |\n",
      "|    policy_loss        | 0.248         |\n",
      "|    reward             | -0.0005115847 |\n",
      "|    std                | 3.12e+05      |\n",
      "|    value_loss         | 0.000347      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 81300        |\n",
      "|    time_elapsed       | 1308         |\n",
      "|    total_timesteps    | 406500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.2        |\n",
      "|    explained_variance | 0.192        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 81299        |\n",
      "|    policy_loss        | 0.626        |\n",
      "|    reward             | -0.008328651 |\n",
      "|    std                | 3.19e+05     |\n",
      "|    value_loss         | 0.000914     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 81400        |\n",
      "|    time_elapsed       | 1309         |\n",
      "|    total_timesteps    | 407000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.3        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 81399        |\n",
      "|    policy_loss        | -0.2         |\n",
      "|    reward             | -0.020604238 |\n",
      "|    std                | 3.31e+05     |\n",
      "|    value_loss         | 0.000537     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 81500         |\n",
      "|    time_elapsed       | 1311          |\n",
      "|    total_timesteps    | 407500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.3         |\n",
      "|    explained_variance | 0.00829       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 81499         |\n",
      "|    policy_loss        | 0.491         |\n",
      "|    reward             | -0.0027325493 |\n",
      "|    std                | 3.38e+05      |\n",
      "|    value_loss         | 0.00182       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 81600         |\n",
      "|    time_elapsed       | 1312          |\n",
      "|    total_timesteps    | 408000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 81599         |\n",
      "|    policy_loss        | 2.12          |\n",
      "|    reward             | 0.00050121004 |\n",
      "|    std                | 3.48e+05      |\n",
      "|    value_loss         | 0.00589       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 81700         |\n",
      "|    time_elapsed       | 1313          |\n",
      "|    total_timesteps    | 408500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 81699         |\n",
      "|    policy_loss        | -0.527        |\n",
      "|    reward             | -0.0065579154 |\n",
      "|    std                | 3.5e+05       |\n",
      "|    value_loss         | 0.000475      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 81800         |\n",
      "|    time_elapsed       | 1315          |\n",
      "|    total_timesteps    | 409000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.4         |\n",
      "|    explained_variance | 0.361         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 81799         |\n",
      "|    policy_loss        | 0.309         |\n",
      "|    reward             | -0.0028402763 |\n",
      "|    std                | 3.57e+05      |\n",
      "|    value_loss         | 0.000161      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 81900       |\n",
      "|    time_elapsed       | 1317        |\n",
      "|    total_timesteps    | 409500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.4       |\n",
      "|    explained_variance | 0.112       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 81899       |\n",
      "|    policy_loss        | 0.493       |\n",
      "|    reward             | -0.03525089 |\n",
      "|    std                | 3.65e+05    |\n",
      "|    value_loss         | 0.000347    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 82000       |\n",
      "|    time_elapsed       | 1318        |\n",
      "|    total_timesteps    | 410000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.5       |\n",
      "|    explained_variance | 0.0586      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 81999       |\n",
      "|    policy_loss        | 0.903       |\n",
      "|    reward             | 0.024133813 |\n",
      "|    std                | 3.74e+05    |\n",
      "|    value_loss         | 0.00125     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 82100      |\n",
      "|    time_elapsed       | 1320       |\n",
      "|    total_timesteps    | 410500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.5      |\n",
      "|    explained_variance | 5.74e-05   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 82099      |\n",
      "|    policy_loss        | 0.284      |\n",
      "|    reward             | 0.03239489 |\n",
      "|    std                | 3.8e+05    |\n",
      "|    value_loss         | 0.00271    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 82200        |\n",
      "|    time_elapsed       | 1322         |\n",
      "|    total_timesteps    | 411000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.6        |\n",
      "|    explained_variance | 0.011        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82199        |\n",
      "|    policy_loss        | 0.588        |\n",
      "|    reward             | -0.076558456 |\n",
      "|    std                | 3.88e+05     |\n",
      "|    value_loss         | 0.00949      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 82300       |\n",
      "|    time_elapsed       | 1323        |\n",
      "|    total_timesteps    | 411500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.6       |\n",
      "|    explained_variance | 0.0846      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 82299       |\n",
      "|    policy_loss        | 0.221       |\n",
      "|    reward             | 0.009015613 |\n",
      "|    std                | 3.89e+05    |\n",
      "|    value_loss         | 0.000138    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 82400        |\n",
      "|    time_elapsed       | 1325         |\n",
      "|    total_timesteps    | 412000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.6        |\n",
      "|    explained_variance | 0.552        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82399        |\n",
      "|    policy_loss        | 0.126        |\n",
      "|    reward             | -0.016292889 |\n",
      "|    std                | 3.94e+05     |\n",
      "|    value_loss         | 3.26e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 82500        |\n",
      "|    time_elapsed       | 1326         |\n",
      "|    total_timesteps    | 412500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.6        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82499        |\n",
      "|    policy_loss        | -1.15        |\n",
      "|    reward             | -0.036008947 |\n",
      "|    std                | 4.01e+05     |\n",
      "|    value_loss         | 0.00162      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 82600      |\n",
      "|    time_elapsed       | 1328       |\n",
      "|    total_timesteps    | 413000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.6      |\n",
      "|    explained_variance | 0.148      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 82599      |\n",
      "|    policy_loss        | -2.4       |\n",
      "|    reward             | 0.06527386 |\n",
      "|    std                | 4.03e+05   |\n",
      "|    value_loss         | 0.00992    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 82700       |\n",
      "|    time_elapsed       | 1330        |\n",
      "|    total_timesteps    | 413500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.7       |\n",
      "|    explained_variance | 0.0773      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 82699       |\n",
      "|    policy_loss        | 1.87        |\n",
      "|    reward             | -0.14092207 |\n",
      "|    std                | 4.07e+05    |\n",
      "|    value_loss         | 0.00567     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 310       |\n",
      "|    iterations         | 82800     |\n",
      "|    time_elapsed       | 1331      |\n",
      "|    total_timesteps    | 414000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -28.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 82799     |\n",
      "|    policy_loss        | 4.71      |\n",
      "|    reward             | 0.1665656 |\n",
      "|    std                | 4.19e+05  |\n",
      "|    value_loss         | 0.0318    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 82900        |\n",
      "|    time_elapsed       | 1333         |\n",
      "|    total_timesteps    | 414500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.7        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82899        |\n",
      "|    policy_loss        | -0.396       |\n",
      "|    reward             | -0.011461176 |\n",
      "|    std                | 4.24e+05     |\n",
      "|    value_loss         | 0.000516     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 83000        |\n",
      "|    time_elapsed       | 1335         |\n",
      "|    total_timesteps    | 415000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.8        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 82999        |\n",
      "|    policy_loss        | -1.64        |\n",
      "|    reward             | -0.029730817 |\n",
      "|    std                | 4.31e+05     |\n",
      "|    value_loss         | 0.0032       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 83100       |\n",
      "|    time_elapsed       | 1336        |\n",
      "|    total_timesteps    | 415500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -28.8       |\n",
      "|    explained_variance | 0.118       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83099       |\n",
      "|    policy_loss        | 1.11        |\n",
      "|    reward             | 0.006855227 |\n",
      "|    std                | 4.35e+05    |\n",
      "|    value_loss         | 0.00268     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 83200      |\n",
      "|    time_elapsed       | 1338       |\n",
      "|    total_timesteps    | 416000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.8      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 83199      |\n",
      "|    policy_loss        | 1.67       |\n",
      "|    reward             | 0.02708491 |\n",
      "|    std                | 4.41e+05   |\n",
      "|    value_loss         | 0.00511    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 83300      |\n",
      "|    time_elapsed       | 1340       |\n",
      "|    total_timesteps    | 416500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 83299      |\n",
      "|    policy_loss        | -0.258     |\n",
      "|    reward             | 0.11460412 |\n",
      "|    std                | 4.45e+05   |\n",
      "|    value_loss         | 0.00233    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 83400      |\n",
      "|    time_elapsed       | 1341       |\n",
      "|    total_timesteps    | 417000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -28.9      |\n",
      "|    explained_variance | 0.484      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 83399      |\n",
      "|    policy_loss        | -18.3      |\n",
      "|    reward             | -0.2888782 |\n",
      "|    std                | 4.53e+05   |\n",
      "|    value_loss         | 0.418      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 83500        |\n",
      "|    time_elapsed       | 1343         |\n",
      "|    total_timesteps    | 417500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -28.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 83499        |\n",
      "|    policy_loss        | 0.242        |\n",
      "|    reward             | 0.0038860366 |\n",
      "|    std                | 4.55e+05     |\n",
      "|    value_loss         | 0.000181     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 83600         |\n",
      "|    time_elapsed       | 1345          |\n",
      "|    total_timesteps    | 418000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.9         |\n",
      "|    explained_variance | -0.225        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 83599         |\n",
      "|    policy_loss        | 0.332         |\n",
      "|    reward             | -0.0050628153 |\n",
      "|    std                | 4.62e+05      |\n",
      "|    value_loss         | 0.000251      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 83700        |\n",
      "|    time_elapsed       | 1346         |\n",
      "|    total_timesteps    | 418500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29          |\n",
      "|    explained_variance | 0.574        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 83699        |\n",
      "|    policy_loss        | -1.01        |\n",
      "|    reward             | -0.023767598 |\n",
      "|    std                | 4.73e+05     |\n",
      "|    value_loss         | 0.0057       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 83800       |\n",
      "|    time_elapsed       | 1348        |\n",
      "|    total_timesteps    | 419000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29         |\n",
      "|    explained_variance | 0.418       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83799       |\n",
      "|    policy_loss        | -1.71       |\n",
      "|    reward             | 0.122546524 |\n",
      "|    std                | 4.81e+05    |\n",
      "|    value_loss         | 0.00785     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 83900       |\n",
      "|    time_elapsed       | 1349        |\n",
      "|    total_timesteps    | 419500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29         |\n",
      "|    explained_variance | 0.0223      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83899       |\n",
      "|    policy_loss        | 11.8        |\n",
      "|    reward             | 0.010302445 |\n",
      "|    std                | 4.84e+05    |\n",
      "|    value_loss         | 0.174       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 84000       |\n",
      "|    time_elapsed       | 1351        |\n",
      "|    total_timesteps    | 420000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 83999       |\n",
      "|    policy_loss        | 2.87        |\n",
      "|    reward             | -0.17697564 |\n",
      "|    std                | 4.95e+05    |\n",
      "|    value_loss         | 0.0138      |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 145\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 131283.38\n",
      "total_reward: 121283.38\n",
      "total_cost: 10.34\n",
      "total_trades: 5790\n",
      "Sharpe: 0.819\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 84100       |\n",
      "|    time_elapsed       | 1353        |\n",
      "|    total_timesteps    | 420500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.1       |\n",
      "|    explained_variance | 0.204       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 84099       |\n",
      "|    policy_loss        | -0.873      |\n",
      "|    reward             | 0.023570022 |\n",
      "|    std                | 5.01e+05    |\n",
      "|    value_loss         | 0.00121     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 84200      |\n",
      "|    time_elapsed       | 1354       |\n",
      "|    total_timesteps    | 421000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 84199      |\n",
      "|    policy_loss        | 0.453      |\n",
      "|    reward             | 0.03182043 |\n",
      "|    std                | 5.09e+05   |\n",
      "|    value_loss         | 0.000443   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 84300       |\n",
      "|    time_elapsed       | 1356        |\n",
      "|    total_timesteps    | 421500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 84299       |\n",
      "|    policy_loss        | 1.84        |\n",
      "|    reward             | -0.03460134 |\n",
      "|    std                | 5.21e+05    |\n",
      "|    value_loss         | 0.00425     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 84400       |\n",
      "|    time_elapsed       | 1357        |\n",
      "|    total_timesteps    | 422000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 84399       |\n",
      "|    policy_loss        | -1.94       |\n",
      "|    reward             | 0.012758016 |\n",
      "|    std                | 5.36e+05    |\n",
      "|    value_loss         | 0.00487     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 84500        |\n",
      "|    time_elapsed       | 1359         |\n",
      "|    total_timesteps    | 422500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.3        |\n",
      "|    explained_variance | -0.0259      |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84499        |\n",
      "|    policy_loss        | 1.3          |\n",
      "|    reward             | -0.028468164 |\n",
      "|    std                | 5.46e+05     |\n",
      "|    value_loss         | 0.00234      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 84600      |\n",
      "|    time_elapsed       | 1360       |\n",
      "|    total_timesteps    | 423000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29.3      |\n",
      "|    explained_variance | 5.96e-07   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 84599      |\n",
      "|    policy_loss        | -1.1       |\n",
      "|    reward             | 0.00713686 |\n",
      "|    std                | 5.55e+05   |\n",
      "|    value_loss         | 0.00192    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 84700        |\n",
      "|    time_elapsed       | 1362         |\n",
      "|    total_timesteps    | 423500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84699        |\n",
      "|    policy_loss        | -0.414       |\n",
      "|    reward             | -0.011106221 |\n",
      "|    std                | 5.68e+05     |\n",
      "|    value_loss         | 0.000265     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 84800        |\n",
      "|    time_elapsed       | 1364         |\n",
      "|    total_timesteps    | 424000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84799        |\n",
      "|    policy_loss        | 0.229        |\n",
      "|    reward             | 0.0096876845 |\n",
      "|    std                | 5.76e+05     |\n",
      "|    value_loss         | 0.000141     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 84900        |\n",
      "|    time_elapsed       | 1365         |\n",
      "|    total_timesteps    | 424500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.4        |\n",
      "|    explained_variance | 0.326        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 84899        |\n",
      "|    policy_loss        | -1.42        |\n",
      "|    reward             | 0.0037404338 |\n",
      "|    std                | 5.93e+05     |\n",
      "|    value_loss         | 0.00262      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 85000       |\n",
      "|    time_elapsed       | 1367        |\n",
      "|    total_timesteps    | 425000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.5       |\n",
      "|    explained_variance | 0.314       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 84999       |\n",
      "|    policy_loss        | -0.662      |\n",
      "|    reward             | 0.039471388 |\n",
      "|    std                | 6.16e+05    |\n",
      "|    value_loss         | 0.000876    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 85100       |\n",
      "|    time_elapsed       | 1369        |\n",
      "|    total_timesteps    | 425500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.5       |\n",
      "|    explained_variance | 0.0469      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85099       |\n",
      "|    policy_loss        | 0.751       |\n",
      "|    reward             | -0.12205203 |\n",
      "|    std                | 6.2e+05     |\n",
      "|    value_loss         | 0.00595     |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 310            |\n",
      "|    iterations         | 85200          |\n",
      "|    time_elapsed       | 1371           |\n",
      "|    total_timesteps    | 426000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -29.5          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 85199          |\n",
      "|    policy_loss        | -0.0621        |\n",
      "|    reward             | -0.00048733407 |\n",
      "|    std                | 6.3e+05        |\n",
      "|    value_loss         | 1.31e-05       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 85300       |\n",
      "|    time_elapsed       | 1372        |\n",
      "|    total_timesteps    | 426500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.6       |\n",
      "|    explained_variance | 0.305       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85299       |\n",
      "|    policy_loss        | -0.185      |\n",
      "|    reward             | 0.001182324 |\n",
      "|    std                | 6.43e+05    |\n",
      "|    value_loss         | 3.88e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 85400       |\n",
      "|    time_elapsed       | 1374        |\n",
      "|    total_timesteps    | 427000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.6       |\n",
      "|    explained_variance | 0.116       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85399       |\n",
      "|    policy_loss        | -0.618      |\n",
      "|    reward             | -0.02078037 |\n",
      "|    std                | 6.65e+05    |\n",
      "|    value_loss         | 0.000634    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 85500       |\n",
      "|    time_elapsed       | 1375        |\n",
      "|    total_timesteps    | 427500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.7       |\n",
      "|    explained_variance | -0.887      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85499       |\n",
      "|    policy_loss        | -0.764      |\n",
      "|    reward             | 0.006229248 |\n",
      "|    std                | 6.91e+05    |\n",
      "|    value_loss         | 0.000883    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 85600         |\n",
      "|    time_elapsed       | 1377          |\n",
      "|    total_timesteps    | 428000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.8         |\n",
      "|    explained_variance | 0.0111        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 85599         |\n",
      "|    policy_loss        | 0.508         |\n",
      "|    reward             | -0.0072552576 |\n",
      "|    std                | 7.09e+05      |\n",
      "|    value_loss         | 0.0011        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 85700       |\n",
      "|    time_elapsed       | 1379        |\n",
      "|    total_timesteps    | 428500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.8       |\n",
      "|    explained_variance | 0.0677      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85699       |\n",
      "|    policy_loss        | -2.78       |\n",
      "|    reward             | 0.101101644 |\n",
      "|    std                | 7.14e+05    |\n",
      "|    value_loss         | 0.00951     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 85800       |\n",
      "|    time_elapsed       | 1380        |\n",
      "|    total_timesteps    | 429000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 85799       |\n",
      "|    policy_loss        | -0.656      |\n",
      "|    reward             | 0.018233886 |\n",
      "|    std                | 7.23e+05    |\n",
      "|    value_loss         | 0.000713    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 85900        |\n",
      "|    time_elapsed       | 1382         |\n",
      "|    total_timesteps    | 429500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -29.8        |\n",
      "|    explained_variance | 0.161        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 85899        |\n",
      "|    policy_loss        | 0.339        |\n",
      "|    reward             | -0.017196268 |\n",
      "|    std                | 7.36e+05     |\n",
      "|    value_loss         | 0.000276     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 86000      |\n",
      "|    time_elapsed       | 1384       |\n",
      "|    total_timesteps    | 430000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -29.9      |\n",
      "|    explained_variance | -0.00854   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 85999      |\n",
      "|    policy_loss        | 0.531      |\n",
      "|    reward             | 0.03218307 |\n",
      "|    std                | 7.52e+05   |\n",
      "|    value_loss         | 0.000578   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 86100       |\n",
      "|    time_elapsed       | 1385        |\n",
      "|    total_timesteps    | 430500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 86099       |\n",
      "|    policy_loss        | -1.45       |\n",
      "|    reward             | 0.027665433 |\n",
      "|    std                | 7.62e+05    |\n",
      "|    value_loss         | 0.00359     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 86200       |\n",
      "|    time_elapsed       | 1387        |\n",
      "|    total_timesteps    | 431000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -29.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 86199       |\n",
      "|    policy_loss        | -2.03       |\n",
      "|    reward             | 0.040235527 |\n",
      "|    std                | 7.75e+05    |\n",
      "|    value_loss         | 0.00869     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 86300      |\n",
      "|    time_elapsed       | 1389       |\n",
      "|    total_timesteps    | 431500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 86299      |\n",
      "|    policy_loss        | 0.0726     |\n",
      "|    reward             | -0.6097969 |\n",
      "|    std                | 7.85e+05   |\n",
      "|    value_loss         | 0.0247     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 86400        |\n",
      "|    time_elapsed       | 1390         |\n",
      "|    total_timesteps    | 432000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30          |\n",
      "|    explained_variance | 0.0127       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 86399        |\n",
      "|    policy_loss        | -1.51        |\n",
      "|    reward             | -0.014174377 |\n",
      "|    std                | 7.97e+05     |\n",
      "|    value_loss         | 0.00388      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 86500       |\n",
      "|    time_elapsed       | 1392        |\n",
      "|    total_timesteps    | 432500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30         |\n",
      "|    explained_variance | 0.581       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 86499       |\n",
      "|    policy_loss        | 0.377       |\n",
      "|    reward             | 0.007812914 |\n",
      "|    std                | 8.05e+05    |\n",
      "|    value_loss         | 0.000209    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 86600         |\n",
      "|    time_elapsed       | 1393          |\n",
      "|    total_timesteps    | 433000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.1         |\n",
      "|    explained_variance | 0.494         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 86599         |\n",
      "|    policy_loss        | 0.355         |\n",
      "|    reward             | -0.0019386524 |\n",
      "|    std                | 8.22e+05      |\n",
      "|    value_loss         | 0.000261      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 86700        |\n",
      "|    time_elapsed       | 1395         |\n",
      "|    total_timesteps    | 433500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.1        |\n",
      "|    explained_variance | 8.17e-06     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 86699        |\n",
      "|    policy_loss        | -1.46        |\n",
      "|    reward             | -0.003001598 |\n",
      "|    std                | 8.46e+05     |\n",
      "|    value_loss         | 0.00242      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 86800         |\n",
      "|    time_elapsed       | 1397          |\n",
      "|    total_timesteps    | 434000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.2         |\n",
      "|    explained_variance | -0.132        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 86799         |\n",
      "|    policy_loss        | -0.579        |\n",
      "|    reward             | -0.0012095016 |\n",
      "|    std                | 8.63e+05      |\n",
      "|    value_loss         | 0.0008        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 86900       |\n",
      "|    time_elapsed       | 1399        |\n",
      "|    total_timesteps    | 434500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.2       |\n",
      "|    explained_variance | -0.275      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 86899       |\n",
      "|    policy_loss        | 0.606       |\n",
      "|    reward             | 0.038413882 |\n",
      "|    std                | 8.73e+05    |\n",
      "|    value_loss         | 0.000781    |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 150\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 30708.55\n",
      "total_reward: 20708.55\n",
      "total_cost: 21.55\n",
      "total_trades: 4335\n",
      "Sharpe: 0.467\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 87000       |\n",
      "|    time_elapsed       | 1401        |\n",
      "|    total_timesteps    | 435000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.2       |\n",
      "|    explained_variance | 0.00489     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 86999       |\n",
      "|    policy_loss        | -0.208      |\n",
      "|    reward             | 0.022280341 |\n",
      "|    std                | 8.81e+05    |\n",
      "|    value_loss         | 0.000138    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 87100        |\n",
      "|    time_elapsed       | 1402         |\n",
      "|    total_timesteps    | 435500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 87099        |\n",
      "|    policy_loss        | -0.651       |\n",
      "|    reward             | -0.022870045 |\n",
      "|    std                | 8.96e+05     |\n",
      "|    value_loss         | 0.000483     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 87200       |\n",
      "|    time_elapsed       | 1404        |\n",
      "|    total_timesteps    | 436000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.3       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87199       |\n",
      "|    policy_loss        | 2.07        |\n",
      "|    reward             | -0.20539318 |\n",
      "|    std                | 9.12e+05    |\n",
      "|    value_loss         | 0.0152      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 87300       |\n",
      "|    time_elapsed       | 1405        |\n",
      "|    total_timesteps    | 436500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.3       |\n",
      "|    explained_variance | 0.419       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87299       |\n",
      "|    policy_loss        | -2.41       |\n",
      "|    reward             | 0.058893424 |\n",
      "|    std                | 9.13e+05    |\n",
      "|    value_loss         | 0.0137      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 87400       |\n",
      "|    time_elapsed       | 1407        |\n",
      "|    total_timesteps    | 437000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.3       |\n",
      "|    explained_variance | 0.375       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87399       |\n",
      "|    policy_loss        | 1.98        |\n",
      "|    reward             | 0.047169708 |\n",
      "|    std                | 9.01e+05    |\n",
      "|    value_loss         | 0.0372      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 87500         |\n",
      "|    time_elapsed       | 1409          |\n",
      "|    total_timesteps    | 437500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.3         |\n",
      "|    explained_variance | -0.0358       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 87499         |\n",
      "|    policy_loss        | -1.6          |\n",
      "|    reward             | -0.0013032486 |\n",
      "|    std                | 9.14e+05      |\n",
      "|    value_loss         | 0.00408       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 87600        |\n",
      "|    time_elapsed       | 1410         |\n",
      "|    total_timesteps    | 438000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.3        |\n",
      "|    explained_variance | 0.907        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 87599        |\n",
      "|    policy_loss        | -0.378       |\n",
      "|    reward             | -0.010266944 |\n",
      "|    std                | 9.2e+05      |\n",
      "|    value_loss         | 0.000204     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 87700       |\n",
      "|    time_elapsed       | 1412        |\n",
      "|    total_timesteps    | 438500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87699       |\n",
      "|    policy_loss        | 0.0959      |\n",
      "|    reward             | 0.004344806 |\n",
      "|    std                | 9.36e+05    |\n",
      "|    value_loss         | 3.19e-05    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 310            |\n",
      "|    iterations         | 87800          |\n",
      "|    time_elapsed       | 1413           |\n",
      "|    total_timesteps    | 439000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -30.4          |\n",
      "|    explained_variance | 0.601          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 87799          |\n",
      "|    policy_loss        | 0.658          |\n",
      "|    reward             | -0.00072647707 |\n",
      "|    std                | 9.58e+05       |\n",
      "|    value_loss         | 0.000527       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 87900       |\n",
      "|    time_elapsed       | 1415        |\n",
      "|    total_timesteps    | 439500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.4       |\n",
      "|    explained_variance | 0.616       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87899       |\n",
      "|    policy_loss        | -0.703      |\n",
      "|    reward             | -0.02872228 |\n",
      "|    std                | 9.84e+05    |\n",
      "|    value_loss         | 0.00206     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 88000       |\n",
      "|    time_elapsed       | 1416        |\n",
      "|    total_timesteps    | 440000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.5       |\n",
      "|    explained_variance | 0.0573      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 87999       |\n",
      "|    policy_loss        | -0.103      |\n",
      "|    reward             | 0.097325236 |\n",
      "|    std                | 1e+06       |\n",
      "|    value_loss         | 0.000456    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 88100        |\n",
      "|    time_elapsed       | 1418         |\n",
      "|    total_timesteps    | 440500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.5        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88099        |\n",
      "|    policy_loss        | 0.446        |\n",
      "|    reward             | 0.0075574247 |\n",
      "|    std                | 1.01e+06     |\n",
      "|    value_loss         | 0.00021      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 88200        |\n",
      "|    time_elapsed       | 1419         |\n",
      "|    total_timesteps    | 441000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.5        |\n",
      "|    explained_variance | 0.126        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88199        |\n",
      "|    policy_loss        | 0.0287       |\n",
      "|    reward             | -0.016480887 |\n",
      "|    std                | 1.03e+06     |\n",
      "|    value_loss         | 1.75e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 88300      |\n",
      "|    time_elapsed       | 1421       |\n",
      "|    total_timesteps    | 441500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -30.6      |\n",
      "|    explained_variance | 0.0886     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 88299      |\n",
      "|    policy_loss        | 0.36       |\n",
      "|    reward             | 0.02556544 |\n",
      "|    std                | 1.06e+06   |\n",
      "|    value_loss         | 0.00042    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 88400         |\n",
      "|    time_elapsed       | 1422          |\n",
      "|    total_timesteps    | 442000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.6         |\n",
      "|    explained_variance | 0.129         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 88399         |\n",
      "|    policy_loss        | 0.762         |\n",
      "|    reward             | -0.0040970766 |\n",
      "|    std                | 1.06e+06      |\n",
      "|    value_loss         | 0.000761      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 88500        |\n",
      "|    time_elapsed       | 1424         |\n",
      "|    total_timesteps    | 442500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.6        |\n",
      "|    explained_variance | 0.49         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88499        |\n",
      "|    policy_loss        | 1.68         |\n",
      "|    reward             | -0.028570764 |\n",
      "|    std                | 1.07e+06     |\n",
      "|    value_loss         | 0.00509      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 88600        |\n",
      "|    time_elapsed       | 1425         |\n",
      "|    total_timesteps    | 443000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.7        |\n",
      "|    explained_variance | 0.000185     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88599        |\n",
      "|    policy_loss        | 3.24         |\n",
      "|    reward             | -0.043554094 |\n",
      "|    std                | 1.1e+06      |\n",
      "|    value_loss         | 0.0129       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 88700         |\n",
      "|    time_elapsed       | 1427          |\n",
      "|    total_timesteps    | 443500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.7         |\n",
      "|    explained_variance | 0.000119      |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 88699         |\n",
      "|    policy_loss        | -0.34         |\n",
      "|    reward             | -0.0021082344 |\n",
      "|    std                | 1.11e+06      |\n",
      "|    value_loss         | 0.000138      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 88800        |\n",
      "|    time_elapsed       | 1428         |\n",
      "|    total_timesteps    | 444000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88799        |\n",
      "|    policy_loss        | -0.502       |\n",
      "|    reward             | 0.0010424443 |\n",
      "|    std                | 1.13e+06     |\n",
      "|    value_loss         | 0.000303     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 88900        |\n",
      "|    time_elapsed       | 1430         |\n",
      "|    total_timesteps    | 444500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.8        |\n",
      "|    explained_variance | 0.0277       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 88899        |\n",
      "|    policy_loss        | -2.81        |\n",
      "|    reward             | 0.0038609314 |\n",
      "|    std                | 1.18e+06     |\n",
      "|    value_loss         | 0.0107       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 89000       |\n",
      "|    time_elapsed       | 1432        |\n",
      "|    total_timesteps    | 445000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 88999       |\n",
      "|    policy_loss        | -2.75       |\n",
      "|    reward             | 0.022426255 |\n",
      "|    std                | 1.21e+06    |\n",
      "|    value_loss         | 0.00832     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 89100       |\n",
      "|    time_elapsed       | 1433        |\n",
      "|    total_timesteps    | 445500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.9       |\n",
      "|    explained_variance | 0.479       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 89099       |\n",
      "|    policy_loss        | 4.84        |\n",
      "|    reward             | 0.002898468 |\n",
      "|    std                | 1.24e+06    |\n",
      "|    value_loss         | 0.0289      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 89200       |\n",
      "|    time_elapsed       | 1435        |\n",
      "|    total_timesteps    | 446000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 89199       |\n",
      "|    policy_loss        | 6.21        |\n",
      "|    reward             | -0.22753121 |\n",
      "|    std                | 1.26e+06    |\n",
      "|    value_loss         | 0.0557      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 89300       |\n",
      "|    time_elapsed       | 1437        |\n",
      "|    total_timesteps    | 446500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.9       |\n",
      "|    explained_variance | 0.0972      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 89299       |\n",
      "|    policy_loss        | 2.39        |\n",
      "|    reward             | 0.051214132 |\n",
      "|    std                | 1.27e+06    |\n",
      "|    value_loss         | 0.00807     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 89400       |\n",
      "|    time_elapsed       | 1438        |\n",
      "|    total_timesteps    | 447000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -30.9       |\n",
      "|    explained_variance | 0.139       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 89399       |\n",
      "|    policy_loss        | -0.541      |\n",
      "|    reward             | 0.027575148 |\n",
      "|    std                | 1.28e+06    |\n",
      "|    value_loss         | 0.000386    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 310            |\n",
      "|    iterations         | 89500          |\n",
      "|    time_elapsed       | 1440           |\n",
      "|    total_timesteps    | 447500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -31            |\n",
      "|    explained_variance | 1.19e-07       |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 89499          |\n",
      "|    policy_loss        | -2.79          |\n",
      "|    reward             | -0.00037693672 |\n",
      "|    std                | 1.3e+06        |\n",
      "|    value_loss         | 0.00874        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 89600         |\n",
      "|    time_elapsed       | 1442          |\n",
      "|    total_timesteps    | 448000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31           |\n",
      "|    explained_variance | 0.781         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 89599         |\n",
      "|    policy_loss        | 3.1           |\n",
      "|    reward             | -0.0014066513 |\n",
      "|    std                | 1.32e+06      |\n",
      "|    value_loss         | 0.0105        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 89700        |\n",
      "|    time_elapsed       | 1444         |\n",
      "|    total_timesteps    | 448500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31          |\n",
      "|    explained_variance | 0.11         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 89699        |\n",
      "|    policy_loss        | 0.219        |\n",
      "|    reward             | -0.019273777 |\n",
      "|    std                | 1.35e+06     |\n",
      "|    value_loss         | 0.00141      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 89800      |\n",
      "|    time_elapsed       | 1446       |\n",
      "|    total_timesteps    | 449000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.1      |\n",
      "|    explained_variance | -0.00339   |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 89799      |\n",
      "|    policy_loss        | 1.31       |\n",
      "|    reward             | 0.05185873 |\n",
      "|    std                | 1.35e+06   |\n",
      "|    value_loss         | 0.00221    |\n",
      "--------------------------------------\n",
      "day: 2896, episode: 155\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 83820.15\n",
      "total_reward: 73820.15\n",
      "total_cost: 26.60\n",
      "total_trades: 5788\n",
      "Sharpe: 0.810\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 89900       |\n",
      "|    time_elapsed       | 1448        |\n",
      "|    total_timesteps    | 449500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 89899       |\n",
      "|    policy_loss        | 0.0962      |\n",
      "|    reward             | 0.011328763 |\n",
      "|    std                | 1.37e+06    |\n",
      "|    value_loss         | 7.83e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 90000        |\n",
      "|    time_elapsed       | 1450         |\n",
      "|    total_timesteps    | 450000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 89999        |\n",
      "|    policy_loss        | -0.923       |\n",
      "|    reward             | -0.011239975 |\n",
      "|    std                | 1.41e+06     |\n",
      "|    value_loss         | 0.000947     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 90100         |\n",
      "|    time_elapsed       | 1452          |\n",
      "|    total_timesteps    | 450500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.2         |\n",
      "|    explained_variance | 0.179         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 90099         |\n",
      "|    policy_loss        | -0.0981       |\n",
      "|    reward             | -0.0128083825 |\n",
      "|    std                | 1.45e+06      |\n",
      "|    value_loss         | 0.000299      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 90200        |\n",
      "|    time_elapsed       | 1454         |\n",
      "|    total_timesteps    | 451000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.3        |\n",
      "|    explained_variance | 0.497        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 90199        |\n",
      "|    policy_loss        | -0.0975      |\n",
      "|    reward             | -0.013482527 |\n",
      "|    std                | 1.5e+06      |\n",
      "|    value_loss         | 0.000148     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 90300       |\n",
      "|    time_elapsed       | 1455        |\n",
      "|    total_timesteps    | 451500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.3       |\n",
      "|    explained_variance | 0.69        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90299       |\n",
      "|    policy_loss        | -0.674      |\n",
      "|    reward             | 0.026413685 |\n",
      "|    std                | 1.56e+06    |\n",
      "|    value_loss         | 0.000671    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 310            |\n",
      "|    iterations         | 90400          |\n",
      "|    time_elapsed       | 1457           |\n",
      "|    total_timesteps    | 452000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -31.4          |\n",
      "|    explained_variance | 0.378          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 90399          |\n",
      "|    policy_loss        | -0.87          |\n",
      "|    reward             | -0.00039560624 |\n",
      "|    std                | 1.59e+06       |\n",
      "|    value_loss         | 0.000911       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 90500         |\n",
      "|    time_elapsed       | 1459          |\n",
      "|    total_timesteps    | 452500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.4         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 90499         |\n",
      "|    policy_loss        | -0.869        |\n",
      "|    reward             | -0.0067213387 |\n",
      "|    std                | 1.63e+06      |\n",
      "|    value_loss         | 0.000865      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 90600        |\n",
      "|    time_elapsed       | 1460         |\n",
      "|    total_timesteps    | 453000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.5        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 90599        |\n",
      "|    policy_loss        | -0.386       |\n",
      "|    reward             | 0.0074344133 |\n",
      "|    std                | 1.69e+06     |\n",
      "|    value_loss         | 0.000184     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 310       |\n",
      "|    iterations         | 90700     |\n",
      "|    time_elapsed       | 1462      |\n",
      "|    total_timesteps    | 453500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -31.6     |\n",
      "|    explained_variance | -1.55e-06 |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 90699     |\n",
      "|    policy_loss        | -0.653    |\n",
      "|    reward             | 0.0368574 |\n",
      "|    std                | 1.75e+06  |\n",
      "|    value_loss         | 0.00118   |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 90800        |\n",
      "|    time_elapsed       | 1463         |\n",
      "|    total_timesteps    | 454000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.6        |\n",
      "|    explained_variance | 0.0302       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 90799        |\n",
      "|    policy_loss        | 0.357        |\n",
      "|    reward             | -0.025618404 |\n",
      "|    std                | 1.78e+06     |\n",
      "|    value_loss         | 0.000738     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 90900       |\n",
      "|    time_elapsed       | 1465        |\n",
      "|    total_timesteps    | 454500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 90899       |\n",
      "|    policy_loss        | 2.92        |\n",
      "|    reward             | 0.047385763 |\n",
      "|    std                | 1.8e+06     |\n",
      "|    value_loss         | 0.0145      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 91000         |\n",
      "|    time_elapsed       | 1467          |\n",
      "|    total_timesteps    | 455000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 90999         |\n",
      "|    policy_loss        | 0.194         |\n",
      "|    reward             | -0.0074326624 |\n",
      "|    std                | 1.81e+06      |\n",
      "|    value_loss         | 5.83e-05      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 91100       |\n",
      "|    time_elapsed       | 1468        |\n",
      "|    total_timesteps    | 455500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.7       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 91099       |\n",
      "|    policy_loss        | -0.0617     |\n",
      "|    reward             | 0.009111933 |\n",
      "|    std                | 1.83e+06    |\n",
      "|    value_loss         | 0.000101    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 91200       |\n",
      "|    time_elapsed       | 1470        |\n",
      "|    total_timesteps    | 456000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 91199       |\n",
      "|    policy_loss        | 0.055       |\n",
      "|    reward             | 0.008638617 |\n",
      "|    std                | 1.87e+06    |\n",
      "|    value_loss         | 5.91e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 91300        |\n",
      "|    time_elapsed       | 1472         |\n",
      "|    total_timesteps    | 456500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.7        |\n",
      "|    explained_variance | 0.249        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91299        |\n",
      "|    policy_loss        | -0.435       |\n",
      "|    reward             | -0.011572884 |\n",
      "|    std                | 1.89e+06     |\n",
      "|    value_loss         | 0.00083      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 91400       |\n",
      "|    time_elapsed       | 1473        |\n",
      "|    total_timesteps    | 457000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.7       |\n",
      "|    explained_variance | 0.182       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 91399       |\n",
      "|    policy_loss        | 1.59        |\n",
      "|    reward             | 0.009392524 |\n",
      "|    std                | 1.9e+06     |\n",
      "|    value_loss         | 0.00362     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 91500       |\n",
      "|    time_elapsed       | 1475        |\n",
      "|    total_timesteps    | 457500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.7       |\n",
      "|    explained_variance | 0.205       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 91499       |\n",
      "|    policy_loss        | -0.433      |\n",
      "|    reward             | -0.05662455 |\n",
      "|    std                | 1.91e+06    |\n",
      "|    value_loss         | 0.0079      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 91600        |\n",
      "|    time_elapsed       | 1476         |\n",
      "|    total_timesteps    | 458000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.8        |\n",
      "|    explained_variance | 0.222        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91599        |\n",
      "|    policy_loss        | 0.227        |\n",
      "|    reward             | -0.012611537 |\n",
      "|    std                | 1.95e+06     |\n",
      "|    value_loss         | 0.000172     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 91700        |\n",
      "|    time_elapsed       | 1478         |\n",
      "|    total_timesteps    | 458500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91699        |\n",
      "|    policy_loss        | 0.108        |\n",
      "|    reward             | -0.008453452 |\n",
      "|    std                | 1.98e+06     |\n",
      "|    value_loss         | 0.000554     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 91800      |\n",
      "|    time_elapsed       | 1479       |\n",
      "|    total_timesteps    | 459000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -31.8      |\n",
      "|    explained_variance | 0.0883     |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 91799      |\n",
      "|    policy_loss        | -2         |\n",
      "|    reward             | -0.0703487 |\n",
      "|    std                | 2.01e+06   |\n",
      "|    value_loss         | 0.00422    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 91900       |\n",
      "|    time_elapsed       | 1481        |\n",
      "|    total_timesteps    | 459500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.9       |\n",
      "|    explained_variance | 0.00286     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 91899       |\n",
      "|    policy_loss        | 2.22        |\n",
      "|    reward             | 0.008698014 |\n",
      "|    std                | 2.01e+06    |\n",
      "|    value_loss         | 0.00501     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 92000        |\n",
      "|    time_elapsed       | 1482         |\n",
      "|    total_timesteps    | 460000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.8        |\n",
      "|    explained_variance | 0.426        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 91999        |\n",
      "|    policy_loss        | -0.212       |\n",
      "|    reward             | -0.017650157 |\n",
      "|    std                | 2.01e+06     |\n",
      "|    value_loss         | 0.000662     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 92100       |\n",
      "|    time_elapsed       | 1484        |\n",
      "|    total_timesteps    | 460500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -31.9       |\n",
      "|    explained_variance | 0.0978      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 92099       |\n",
      "|    policy_loss        | 3.62        |\n",
      "|    reward             | 0.008329418 |\n",
      "|    std                | 2.03e+06    |\n",
      "|    value_loss         | 0.0417      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 92200        |\n",
      "|    time_elapsed       | 1486         |\n",
      "|    total_timesteps    | 461000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92199        |\n",
      "|    policy_loss        | -1.63        |\n",
      "|    reward             | -0.031734843 |\n",
      "|    std                | 2.05e+06     |\n",
      "|    value_loss         | 0.00279      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 310          |\n",
      "|    iterations         | 92300        |\n",
      "|    time_elapsed       | 1487         |\n",
      "|    total_timesteps    | 461500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -31.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 92299        |\n",
      "|    policy_loss        | 0.39         |\n",
      "|    reward             | 0.0019829723 |\n",
      "|    std                | 2.08e+06     |\n",
      "|    value_loss         | 0.00016      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 310           |\n",
      "|    iterations         | 92400         |\n",
      "|    time_elapsed       | 1489          |\n",
      "|    total_timesteps    | 462000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32           |\n",
      "|    explained_variance | -0.0693       |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 92399         |\n",
      "|    policy_loss        | 0.664         |\n",
      "|    reward             | -0.0026354687 |\n",
      "|    std                | 2.12e+06      |\n",
      "|    value_loss         | 0.00117       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 92500       |\n",
      "|    time_elapsed       | 1491        |\n",
      "|    total_timesteps    | 462500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32         |\n",
      "|    explained_variance | -0.93       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 92499       |\n",
      "|    policy_loss        | -0.805      |\n",
      "|    reward             | 0.008319419 |\n",
      "|    std                | 2.18e+06    |\n",
      "|    value_loss         | 0.00112     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 92600      |\n",
      "|    time_elapsed       | 1492       |\n",
      "|    total_timesteps    | 463000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.1      |\n",
      "|    explained_variance | 0.847      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 92599      |\n",
      "|    policy_loss        | 0.0178     |\n",
      "|    reward             | 0.06323031 |\n",
      "|    std                | 2.27e+06   |\n",
      "|    value_loss         | 0.000139   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 92700      |\n",
      "|    time_elapsed       | 1494       |\n",
      "|    total_timesteps    | 463500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.1      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 92699      |\n",
      "|    policy_loss        | 3.06       |\n",
      "|    reward             | 0.06053864 |\n",
      "|    std                | 2.32e+06   |\n",
      "|    value_loss         | 0.0114     |\n",
      "--------------------------------------\n",
      "day: 2896, episode: 160\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 61007.70\n",
      "total_reward: 51007.70\n",
      "total_cost: 21.76\n",
      "total_trades: 5791\n",
      "Sharpe: 0.677\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 92800       |\n",
      "|    time_elapsed       | 1495        |\n",
      "|    total_timesteps    | 464000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.1       |\n",
      "|    explained_variance | 7.66e-05    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 92799       |\n",
      "|    policy_loss        | 0.0559      |\n",
      "|    reward             | 0.027814155 |\n",
      "|    std                | 2.32e+06    |\n",
      "|    value_loss         | 0.000291    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 310       |\n",
      "|    iterations         | 92900     |\n",
      "|    time_elapsed       | 1497      |\n",
      "|    total_timesteps    | 464500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.2     |\n",
      "|    explained_variance | 0.0685    |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 92899     |\n",
      "|    policy_loss        | -0.676    |\n",
      "|    reward             | 0.0441395 |\n",
      "|    std                | 2.35e+06  |\n",
      "|    value_loss         | 0.00227   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 310         |\n",
      "|    iterations         | 93000       |\n",
      "|    time_elapsed       | 1499        |\n",
      "|    total_timesteps    | 465000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.2       |\n",
      "|    explained_variance | 0.211       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 92999       |\n",
      "|    policy_loss        | -10.3       |\n",
      "|    reward             | -0.15792565 |\n",
      "|    std                | 2.36e+06    |\n",
      "|    value_loss         | 0.152       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 310        |\n",
      "|    iterations         | 93100      |\n",
      "|    time_elapsed       | 1501       |\n",
      "|    total_timesteps    | 465500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 93099      |\n",
      "|    policy_loss        | -21.1      |\n",
      "|    reward             | 0.40120065 |\n",
      "|    std                | 2.34e+06   |\n",
      "|    value_loss         | 0.462      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 93200       |\n",
      "|    time_elapsed       | 1503        |\n",
      "|    total_timesteps    | 466000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.1       |\n",
      "|    explained_variance | 0.22        |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93199       |\n",
      "|    policy_loss        | -15.2       |\n",
      "|    reward             | -0.22516699 |\n",
      "|    std                | 2.34e+06    |\n",
      "|    value_loss         | 0.256       |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 309            |\n",
      "|    iterations         | 93300          |\n",
      "|    time_elapsed       | 1505           |\n",
      "|    total_timesteps    | 466500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -32.2          |\n",
      "|    explained_variance | -31.6          |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 93299          |\n",
      "|    policy_loss        | -9.72          |\n",
      "|    reward             | -0.00011566334 |\n",
      "|    std                | 2.38e+06       |\n",
      "|    value_loss         | 0.112          |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 93400       |\n",
      "|    time_elapsed       | 1507        |\n",
      "|    total_timesteps    | 467000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.2       |\n",
      "|    explained_variance | -12.2       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93399       |\n",
      "|    policy_loss        | 0.315       |\n",
      "|    reward             | -0.00481346 |\n",
      "|    std                | 2.41e+06    |\n",
      "|    value_loss         | 0.000669    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 309           |\n",
      "|    iterations         | 93500         |\n",
      "|    time_elapsed       | 1509          |\n",
      "|    total_timesteps    | 467500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.2         |\n",
      "|    explained_variance | 0.0353        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 93499         |\n",
      "|    policy_loss        | -0.253        |\n",
      "|    reward             | -0.0007076546 |\n",
      "|    std                | 2.45e+06      |\n",
      "|    value_loss         | 0.000121      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 93600        |\n",
      "|    time_elapsed       | 1510         |\n",
      "|    total_timesteps    | 468000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.3        |\n",
      "|    explained_variance | -0.221       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 93599        |\n",
      "|    policy_loss        | 1.09         |\n",
      "|    reward             | 0.0064389147 |\n",
      "|    std                | 2.5e+06      |\n",
      "|    value_loss         | 0.00331      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 93700       |\n",
      "|    time_elapsed       | 1512        |\n",
      "|    total_timesteps    | 468500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.3       |\n",
      "|    explained_variance | 0.514       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93699       |\n",
      "|    policy_loss        | -3.57       |\n",
      "|    reward             | -0.13005188 |\n",
      "|    std                | 2.55e+06    |\n",
      "|    value_loss         | 0.015       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 93800        |\n",
      "|    time_elapsed       | 1514         |\n",
      "|    total_timesteps    | 469000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.3        |\n",
      "|    explained_variance | 3.04e-06     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 93799        |\n",
      "|    policy_loss        | -0.422       |\n",
      "|    reward             | -0.112673506 |\n",
      "|    std                | 2.58e+06     |\n",
      "|    value_loss         | 0.00331      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 93900       |\n",
      "|    time_elapsed       | 1516        |\n",
      "|    total_timesteps    | 469500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93899       |\n",
      "|    policy_loss        | 0.6         |\n",
      "|    reward             | 0.014537956 |\n",
      "|    std                | 2.59e+06    |\n",
      "|    value_loss         | 0.000388    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 94000       |\n",
      "|    time_elapsed       | 1518        |\n",
      "|    total_timesteps    | 470000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 93999       |\n",
      "|    policy_loss        | 0.314       |\n",
      "|    reward             | 0.010851814 |\n",
      "|    std                | 2.64e+06    |\n",
      "|    value_loss         | 0.000306    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 94100        |\n",
      "|    time_elapsed       | 1519         |\n",
      "|    total_timesteps    | 470500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.4        |\n",
      "|    explained_variance | -0.674       |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 94099        |\n",
      "|    policy_loss        | -0.306       |\n",
      "|    reward             | -0.007743997 |\n",
      "|    std                | 2.7e+06      |\n",
      "|    value_loss         | 0.000681     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 94200      |\n",
      "|    time_elapsed       | 1521       |\n",
      "|    total_timesteps    | 471000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.5      |\n",
      "|    explained_variance | 0.462      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 94199      |\n",
      "|    policy_loss        | -0.441     |\n",
      "|    reward             | 0.04372119 |\n",
      "|    std                | 2.77e+06   |\n",
      "|    value_loss         | 0.000751   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 94300      |\n",
      "|    time_elapsed       | 1522       |\n",
      "|    total_timesteps    | 471500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 94299      |\n",
      "|    policy_loss        | 2.45       |\n",
      "|    reward             | -0.0417224 |\n",
      "|    std                | 2.81e+06   |\n",
      "|    value_loss         | 0.00649    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 94400        |\n",
      "|    time_elapsed       | 1524         |\n",
      "|    total_timesteps    | 472000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.5        |\n",
      "|    explained_variance | -2.15e-06    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 94399        |\n",
      "|    policy_loss        | 2.22         |\n",
      "|    reward             | -0.020107985 |\n",
      "|    std                | 2.86e+06     |\n",
      "|    value_loss         | 0.0064       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 94500        |\n",
      "|    time_elapsed       | 1525         |\n",
      "|    total_timesteps    | 472500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 94499        |\n",
      "|    policy_loss        | -0.306       |\n",
      "|    reward             | -0.006641183 |\n",
      "|    std                | 2.91e+06     |\n",
      "|    value_loss         | 0.000229     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 94600       |\n",
      "|    time_elapsed       | 1527        |\n",
      "|    total_timesteps    | 473000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.6       |\n",
      "|    explained_variance | 0.366       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94599       |\n",
      "|    policy_loss        | 0.383       |\n",
      "|    reward             | 0.007575722 |\n",
      "|    std                | 2.97e+06    |\n",
      "|    value_loss         | 0.000168    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 94700       |\n",
      "|    time_elapsed       | 1529        |\n",
      "|    total_timesteps    | 473500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.6       |\n",
      "|    explained_variance | -1.15       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94699       |\n",
      "|    policy_loss        | 0.452       |\n",
      "|    reward             | 0.002225605 |\n",
      "|    std                | 3.04e+06    |\n",
      "|    value_loss         | 0.000412    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 309           |\n",
      "|    iterations         | 94800         |\n",
      "|    time_elapsed       | 1530          |\n",
      "|    total_timesteps    | 474000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.7         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 94799         |\n",
      "|    policy_loss        | 0.543         |\n",
      "|    reward             | -0.0049243364 |\n",
      "|    std                | 3.13e+06      |\n",
      "|    value_loss         | 0.000358      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 94900       |\n",
      "|    time_elapsed       | 1532        |\n",
      "|    total_timesteps    | 474500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.8       |\n",
      "|    explained_variance | 3.34e-06    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94899       |\n",
      "|    policy_loss        | 1.46        |\n",
      "|    reward             | -0.06985292 |\n",
      "|    std                | 3.24e+06    |\n",
      "|    value_loss         | 0.00195     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 95000       |\n",
      "|    time_elapsed       | 1533        |\n",
      "|    total_timesteps    | 475000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.8       |\n",
      "|    explained_variance | 0.496       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 94999       |\n",
      "|    policy_loss        | 1.94        |\n",
      "|    reward             | -0.04269415 |\n",
      "|    std                | 3.3e+06     |\n",
      "|    value_loss         | 0.00476     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 95100        |\n",
      "|    time_elapsed       | 1535         |\n",
      "|    total_timesteps    | 475500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -32.8        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 95099        |\n",
      "|    policy_loss        | 0.792        |\n",
      "|    reward             | -0.031151284 |\n",
      "|    std                | 3.31e+06     |\n",
      "|    value_loss         | 0.00101      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 95200       |\n",
      "|    time_elapsed       | 1536        |\n",
      "|    total_timesteps    | 476000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 95199       |\n",
      "|    policy_loss        | -1.53       |\n",
      "|    reward             | 0.026407821 |\n",
      "|    std                | 3.39e+06    |\n",
      "|    value_loss         | 0.00252     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 95300       |\n",
      "|    time_elapsed       | 1538        |\n",
      "|    total_timesteps    | 476500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 95299       |\n",
      "|    policy_loss        | 0.536       |\n",
      "|    reward             | 0.010094043 |\n",
      "|    std                | 3.45e+06    |\n",
      "|    value_loss         | 0.00259     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 309       |\n",
      "|    iterations         | 95400     |\n",
      "|    time_elapsed       | 1539      |\n",
      "|    total_timesteps    | 477000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -32.9     |\n",
      "|    explained_variance | -0.0132   |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 95399     |\n",
      "|    policy_loss        | 1.38      |\n",
      "|    reward             | 0.0321489 |\n",
      "|    std                | 3.5e+06   |\n",
      "|    value_loss         | 0.00516   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 95500      |\n",
      "|    time_elapsed       | 1541       |\n",
      "|    total_timesteps    | 477500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -32.9      |\n",
      "|    explained_variance | 0.497      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 95499      |\n",
      "|    policy_loss        | -6.53      |\n",
      "|    reward             | -0.1460634 |\n",
      "|    std                | 3.52e+06   |\n",
      "|    value_loss         | 0.0411     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 95600       |\n",
      "|    time_elapsed       | 1542        |\n",
      "|    total_timesteps    | 478000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -32.9       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 95599       |\n",
      "|    policy_loss        | -10.9       |\n",
      "|    reward             | -0.15168446 |\n",
      "|    std                | 3.54e+06    |\n",
      "|    value_loss         | 0.118       |\n",
      "---------------------------------------\n",
      "day: 2896, episode: 165\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 159452.71\n",
      "total_reward: 149452.71\n",
      "total_cost: 51.94\n",
      "total_trades: 5785\n",
      "Sharpe: 0.953\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 309           |\n",
      "|    iterations         | 95700         |\n",
      "|    time_elapsed       | 1544          |\n",
      "|    total_timesteps    | 478500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.9         |\n",
      "|    explained_variance | -0.167        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 95699         |\n",
      "|    policy_loss        | 0.26          |\n",
      "|    reward             | -0.0025205808 |\n",
      "|    std                | 3.56e+06      |\n",
      "|    value_loss         | 0.000334      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 95800      |\n",
      "|    time_elapsed       | 1546       |\n",
      "|    total_timesteps    | 479000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 95799      |\n",
      "|    policy_loss        | -0.00541   |\n",
      "|    reward             | 0.00923998 |\n",
      "|    std                | 3.61e+06   |\n",
      "|    value_loss         | 0.00014    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 95900        |\n",
      "|    time_elapsed       | 1548         |\n",
      "|    total_timesteps    | 479500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33          |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 95899        |\n",
      "|    policy_loss        | 1.4          |\n",
      "|    reward             | 0.0122520095 |\n",
      "|    std                | 3.69e+06     |\n",
      "|    value_loss         | 0.00254      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 96000       |\n",
      "|    time_elapsed       | 1549        |\n",
      "|    total_timesteps    | 480000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.1       |\n",
      "|    explained_variance | -0.0254     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 95999       |\n",
      "|    policy_loss        | -1.41       |\n",
      "|    reward             | 0.036382683 |\n",
      "|    std                | 3.76e+06    |\n",
      "|    value_loss         | 0.00189     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 96100      |\n",
      "|    time_elapsed       | 1551       |\n",
      "|    total_timesteps    | 480500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.1      |\n",
      "|    explained_variance | -0.0292    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 96099      |\n",
      "|    policy_loss        | -8.14      |\n",
      "|    reward             | 0.18369041 |\n",
      "|    std                | 3.77e+06   |\n",
      "|    value_loss         | 0.0639     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 309           |\n",
      "|    iterations         | 96200         |\n",
      "|    time_elapsed       | 1553          |\n",
      "|    total_timesteps    | 481000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.1         |\n",
      "|    explained_variance | -0.211        |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 96199         |\n",
      "|    policy_loss        | -0.757        |\n",
      "|    reward             | -0.0013708447 |\n",
      "|    std                | 3.81e+06      |\n",
      "|    value_loss         | 0.00142       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 96300        |\n",
      "|    time_elapsed       | 1554         |\n",
      "|    total_timesteps    | 481500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 96299        |\n",
      "|    policy_loss        | 0.594        |\n",
      "|    reward             | -0.001740688 |\n",
      "|    std                | 3.85e+06     |\n",
      "|    value_loss         | 0.000356     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 96400        |\n",
      "|    time_elapsed       | 1556         |\n",
      "|    total_timesteps    | 482000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.1        |\n",
      "|    explained_variance | -0.00049     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 96399        |\n",
      "|    policy_loss        | -0.339       |\n",
      "|    reward             | 0.0024102295 |\n",
      "|    std                | 3.89e+06     |\n",
      "|    value_loss         | 0.000266     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 96500      |\n",
      "|    time_elapsed       | 1558       |\n",
      "|    total_timesteps    | 482500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.2      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 96499      |\n",
      "|    policy_loss        | -1.08      |\n",
      "|    reward             | 0.06685822 |\n",
      "|    std                | 4.01e+06   |\n",
      "|    value_loss         | 0.00266    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 96600       |\n",
      "|    time_elapsed       | 1559        |\n",
      "|    total_timesteps    | 483000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.2       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 96599       |\n",
      "|    policy_loss        | 6.21        |\n",
      "|    reward             | -0.11209184 |\n",
      "|    std                | 4.11e+06    |\n",
      "|    value_loss         | 0.0401      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 96700       |\n",
      "|    time_elapsed       | 1561        |\n",
      "|    total_timesteps    | 483500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.3       |\n",
      "|    explained_variance | 0.0789      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 96699       |\n",
      "|    policy_loss        | -0.493      |\n",
      "|    reward             | -0.13580672 |\n",
      "|    std                | 4.22e+06    |\n",
      "|    value_loss         | 0.00216     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 96800       |\n",
      "|    time_elapsed       | 1563        |\n",
      "|    total_timesteps    | 484000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.3       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 96799       |\n",
      "|    policy_loss        | 0.374       |\n",
      "|    reward             | -0.02629768 |\n",
      "|    std                | 4.22e+06    |\n",
      "|    value_loss         | 0.000142    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 96900        |\n",
      "|    time_elapsed       | 1564         |\n",
      "|    total_timesteps    | 484500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.3        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 96899        |\n",
      "|    policy_loss        | 0.317        |\n",
      "|    reward             | 0.0058490317 |\n",
      "|    std                | 4.28e+06     |\n",
      "|    value_loss         | 0.00042      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 97000      |\n",
      "|    time_elapsed       | 1566       |\n",
      "|    total_timesteps    | 485000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 96999      |\n",
      "|    policy_loss        | -0.711     |\n",
      "|    reward             | 0.12822443 |\n",
      "|    std                | 4.32e+06   |\n",
      "|    value_loss         | 0.000466   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 97100       |\n",
      "|    time_elapsed       | 1568        |\n",
      "|    total_timesteps    | 485500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97099       |\n",
      "|    policy_loss        | 0.525       |\n",
      "|    reward             | 0.044183444 |\n",
      "|    std                | 4.29e+06    |\n",
      "|    value_loss         | 0.00129     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 309       |\n",
      "|    iterations         | 97200     |\n",
      "|    time_elapsed       | 1570      |\n",
      "|    total_timesteps    | 486000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -33.3     |\n",
      "|    explained_variance | -0.0121   |\n",
      "|    learning_rate      | 0.001     |\n",
      "|    n_updates          | 97199     |\n",
      "|    policy_loss        | -8.61     |\n",
      "|    reward             | 0.0735032 |\n",
      "|    std                | 4.3e+06   |\n",
      "|    value_loss         | 0.0775    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 97300      |\n",
      "|    time_elapsed       | 1572       |\n",
      "|    total_timesteps    | 486500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.4      |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 97299      |\n",
      "|    policy_loss        | 3.22       |\n",
      "|    reward             | 0.12368906 |\n",
      "|    std                | 4.35e+06   |\n",
      "|    value_loss         | 0.0451     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 97400        |\n",
      "|    time_elapsed       | 1573         |\n",
      "|    total_timesteps    | 487000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.4        |\n",
      "|    explained_variance | 6.38e-06     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97399        |\n",
      "|    policy_loss        | -0.35        |\n",
      "|    reward             | -0.040745545 |\n",
      "|    std                | 4.36e+06     |\n",
      "|    value_loss         | 0.000251     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 97500        |\n",
      "|    time_elapsed       | 1575         |\n",
      "|    total_timesteps    | 487500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97499        |\n",
      "|    policy_loss        | -0.926       |\n",
      "|    reward             | -0.014542164 |\n",
      "|    std                | 4.38e+06     |\n",
      "|    value_loss         | 0.00104      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 97600       |\n",
      "|    time_elapsed       | 1577        |\n",
      "|    total_timesteps    | 488000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97599       |\n",
      "|    policy_loss        | 2.25        |\n",
      "|    reward             | -0.09217711 |\n",
      "|    std                | 4.42e+06    |\n",
      "|    value_loss         | 0.0112      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 97700       |\n",
      "|    time_elapsed       | 1579        |\n",
      "|    total_timesteps    | 488500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.4       |\n",
      "|    explained_variance | -0.0917     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97699       |\n",
      "|    policy_loss        | 4.37        |\n",
      "|    reward             | -0.06773005 |\n",
      "|    std                | 4.52e+06    |\n",
      "|    value_loss         | 0.0187      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 97800        |\n",
      "|    time_elapsed       | 1580         |\n",
      "|    total_timesteps    | 489000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 97799        |\n",
      "|    policy_loss        | -13.2        |\n",
      "|    reward             | 0.0004105568 |\n",
      "|    std                | 4.53e+06     |\n",
      "|    value_loss         | 0.221        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 97900       |\n",
      "|    time_elapsed       | 1582        |\n",
      "|    total_timesteps    | 489500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97899       |\n",
      "|    policy_loss        | 1.06        |\n",
      "|    reward             | -0.06632792 |\n",
      "|    std                | 4.63e+06    |\n",
      "|    value_loss         | 0.0741      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 98000       |\n",
      "|    time_elapsed       | 1583        |\n",
      "|    total_timesteps    | 490000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.5       |\n",
      "|    explained_variance | -0.0859     |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 97999       |\n",
      "|    policy_loss        | -0.554      |\n",
      "|    reward             | -0.04217027 |\n",
      "|    std                | 4.69e+06    |\n",
      "|    value_loss         | 0.00138     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 309           |\n",
      "|    iterations         | 98100         |\n",
      "|    time_elapsed       | 1585          |\n",
      "|    total_timesteps    | 490500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 98099         |\n",
      "|    policy_loss        | -0.217        |\n",
      "|    reward             | -0.0012476104 |\n",
      "|    std                | 4.78e+06      |\n",
      "|    value_loss         | 8.01e-05      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 98200      |\n",
      "|    time_elapsed       | 1587       |\n",
      "|    total_timesteps    | 491000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.6      |\n",
      "|    explained_variance | 0.289      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 98199      |\n",
      "|    policy_loss        | 0.357      |\n",
      "|    reward             | 0.01909657 |\n",
      "|    std                | 4.89e+06   |\n",
      "|    value_loss         | 0.000457   |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 309            |\n",
      "|    iterations         | 98300          |\n",
      "|    time_elapsed       | 1588           |\n",
      "|    total_timesteps    | 491500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -33.6          |\n",
      "|    explained_variance | 0.64           |\n",
      "|    learning_rate      | 0.001          |\n",
      "|    n_updates          | 98299          |\n",
      "|    policy_loss        | -0.198         |\n",
      "|    reward             | -0.00086368865 |\n",
      "|    std                | 4.95e+06       |\n",
      "|    value_loss         | 0.000242       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 98400        |\n",
      "|    time_elapsed       | 1590         |\n",
      "|    total_timesteps    | 492000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.7        |\n",
      "|    explained_variance | 0.422        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98399        |\n",
      "|    policy_loss        | 1.12         |\n",
      "|    reward             | -0.021905486 |\n",
      "|    std                | 5.02e+06     |\n",
      "|    value_loss         | 0.00207      |\n",
      "----------------------------------------\n",
      "day: 2896, episode: 170\n",
      "begin_total_asset: 10000.00\n",
      "end_total_asset: 53790.33\n",
      "total_reward: 43790.33\n",
      "total_cost: 17.45\n",
      "total_trades: 5785\n",
      "Sharpe: 0.645\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 309           |\n",
      "|    iterations         | 98500         |\n",
      "|    time_elapsed       | 1591          |\n",
      "|    total_timesteps    | 492500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.7         |\n",
      "|    explained_variance | 0.258         |\n",
      "|    learning_rate      | 0.001         |\n",
      "|    n_updates          | 98499         |\n",
      "|    policy_loss        | -1.71         |\n",
      "|    reward             | -0.0013533201 |\n",
      "|    std                | 5.19e+06      |\n",
      "|    value_loss         | 0.0609        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 98600        |\n",
      "|    time_elapsed       | 1593         |\n",
      "|    total_timesteps    | 493000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.8        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98599        |\n",
      "|    policy_loss        | -0.0299      |\n",
      "|    reward             | -0.012184465 |\n",
      "|    std                | 5.27e+06     |\n",
      "|    value_loss         | 3.56e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 98700        |\n",
      "|    time_elapsed       | 1595         |\n",
      "|    total_timesteps    | 493500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.8        |\n",
      "|    explained_variance | 0.266        |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 98699        |\n",
      "|    policy_loss        | 0.244        |\n",
      "|    reward             | -0.022805652 |\n",
      "|    std                | 5.39e+06     |\n",
      "|    value_loss         | 0.000113     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 98800       |\n",
      "|    time_elapsed       | 1596        |\n",
      "|    total_timesteps    | 494000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.9       |\n",
      "|    explained_variance | 4.17e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 98799       |\n",
      "|    policy_loss        | -0.0406     |\n",
      "|    reward             | 0.052586015 |\n",
      "|    std                | 5.58e+06    |\n",
      "|    value_loss         | 0.000213    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 98900      |\n",
      "|    time_elapsed       | 1598       |\n",
      "|    total_timesteps    | 494500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -33.9      |\n",
      "|    explained_variance | 0.183      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 98899      |\n",
      "|    policy_loss        | -5.88      |\n",
      "|    reward             | -0.0565169 |\n",
      "|    std                | 5.62e+06   |\n",
      "|    value_loss         | 0.0428     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 99000       |\n",
      "|    time_elapsed       | 1599        |\n",
      "|    total_timesteps    | 495000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -33.9       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 98999       |\n",
      "|    policy_loss        | -32.7       |\n",
      "|    reward             | 0.020108044 |\n",
      "|    std                | 5.72e+06    |\n",
      "|    value_loss         | 1.01        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 99100        |\n",
      "|    time_elapsed       | 1601         |\n",
      "|    total_timesteps    | 495500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -33.9        |\n",
      "|    explained_variance | 0.25         |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99099        |\n",
      "|    policy_loss        | 0.244        |\n",
      "|    reward             | 0.0070111207 |\n",
      "|    std                | 5.78e+06     |\n",
      "|    value_loss         | 0.000108     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 99200        |\n",
      "|    time_elapsed       | 1602         |\n",
      "|    total_timesteps    | 496000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99199        |\n",
      "|    policy_loss        | 0.0409       |\n",
      "|    reward             | -0.015929472 |\n",
      "|    std                | 5.84e+06     |\n",
      "|    value_loss         | 2.27e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 99300        |\n",
      "|    time_elapsed       | 1604         |\n",
      "|    total_timesteps    | 496500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34          |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99299        |\n",
      "|    policy_loss        | -0.354       |\n",
      "|    reward             | 0.0077872267 |\n",
      "|    std                | 5.95e+06     |\n",
      "|    value_loss         | 0.000171     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 99400       |\n",
      "|    time_elapsed       | 1605        |\n",
      "|    total_timesteps    | 497000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.1       |\n",
      "|    explained_variance | -0.117      |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99399       |\n",
      "|    policy_loss        | -0.197      |\n",
      "|    reward             | 0.024752023 |\n",
      "|    std                | 6.12e+06    |\n",
      "|    value_loss         | 0.000975    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 99500       |\n",
      "|    time_elapsed       | 1607        |\n",
      "|    total_timesteps    | 497500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.1       |\n",
      "|    explained_variance | 0.208       |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99499       |\n",
      "|    policy_loss        | -6.13       |\n",
      "|    reward             | -0.06315777 |\n",
      "|    std                | 6.22e+06    |\n",
      "|    value_loss         | 0.0395      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 309          |\n",
      "|    iterations         | 99600        |\n",
      "|    time_elapsed       | 1609         |\n",
      "|    total_timesteps    | 498000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -34.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.001        |\n",
      "|    n_updates          | 99599        |\n",
      "|    policy_loss        | -4.5         |\n",
      "|    reward             | -0.039418213 |\n",
      "|    std                | 6.28e+06     |\n",
      "|    value_loss         | 0.0177       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 99700      |\n",
      "|    time_elapsed       | 1610       |\n",
      "|    total_timesteps    | 498500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -34.2      |\n",
      "|    explained_variance | -1.02      |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 99699      |\n",
      "|    policy_loss        | -0.447     |\n",
      "|    reward             | 0.02177023 |\n",
      "|    std                | 6.43e+06   |\n",
      "|    value_loss         | 0.00091    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 99800       |\n",
      "|    time_elapsed       | 1612        |\n",
      "|    total_timesteps    | 499000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99799       |\n",
      "|    policy_loss        | 0.0216      |\n",
      "|    reward             | 0.017148206 |\n",
      "|    std                | 6.54e+06    |\n",
      "|    value_loss         | 4.55e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 309         |\n",
      "|    iterations         | 99900       |\n",
      "|    time_elapsed       | 1614        |\n",
      "|    total_timesteps    | 499500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -34.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.001       |\n",
      "|    n_updates          | 99899       |\n",
      "|    policy_loss        | 2.25        |\n",
      "|    reward             | -0.10603644 |\n",
      "|    std                | 6.67e+06    |\n",
      "|    value_loss         | 0.00573     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 309        |\n",
      "|    iterations         | 100000     |\n",
      "|    time_elapsed       | 1615       |\n",
      "|    total_timesteps    | 500000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -34.2      |\n",
      "|    explained_variance | 3.6e-05    |\n",
      "|    learning_rate      | 0.001      |\n",
      "|    n_updates          | 99999      |\n",
      "|    policy_loss        | 3.8        |\n",
      "|    reward             | 0.14487857 |\n",
      "|    std                | 6.73e+06   |\n",
      "|    value_loss         | 0.0124     |\n",
      "--------------------------------------\n",
      "======A2C Validation from:  2021-10-04 to  2022-01-03\n",
      "A2C Sharpe Ratio:  0.4179865901390689\n",
      "======Best Model Retraining from:  2010-04-01 to  2022-01-03\n",
      "======Trading from:  2022-01-03 to  2022-04-04\n",
      "[[257.98364   155.68901   642.6515      0.         20.          0.9646755\n",
      "   27.117754  161.1815    680.7989    148.02783   546.651      49.942398\n",
      "   67.752      30.670864   91.113716    4.2563453  53.900658  154.06818\n",
      "  587.7529    154.93849   549.4282   ]]\n",
      "Ensemble Strategy took:  104.75487138827641  minutes\n"
     ]
    }
   ],
   "source": [
    "# df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n",
    "#                                                  PPO_model_kwargs,\n",
    "#                                                  DDPG_model_kwargs,\n",
    "#                                                  timesteps_dict)\n",
    "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n",
    "                                                 None,\n",
    "                                                 None,\n",
    "                                                 timesteps_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "-0qd8acMtj1f",
    "outputId": "b5d9cb94-51a9-4569-a9a8-7e18f1139f4e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iter</th>\n",
       "      <th>Val Start</th>\n",
       "      <th>Val End</th>\n",
       "      <th>Model Used</th>\n",
       "      <th>A2C Sharpe</th>\n",
       "      <th>PPO Sharpe</th>\n",
       "      <th>DDPG Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.208676</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>2021-07-06</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.27937</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>2021-07-06</td>\n",
       "      <td>2021-10-04</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.152678</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315</td>\n",
       "      <td>2021-10-04</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.417987</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Iter   Val Start     Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n",
       "0  126  2021-01-04  2021-04-06        A2C   0.208676          0           0\n",
       "1  189  2021-04-06  2021-07-06        A2C    0.27937          0           0\n",
       "2  252  2021-07-06  2021-10-04        A2C   0.152678          0           0\n",
       "3  315  2021-10-04  2022-01-03        A2C   0.417987          0           0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "X4JKB--8tj1g"
   },
   "outputs": [],
   "source": [
    "unique_trade_date = processed[(processed.date > TEST_START_DATE)&(processed.date <= TEST_END_DATE)].date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9mKF7GGtj1g",
    "outputId": "8b89807b-ff71-4902-dd45-1f9111788cbb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio:  1.0561624945227917\n"
     ]
    }
   ],
   "source": [
    "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\n",
    "\n",
    "df_account_value=pd.DataFrame()\n",
    "for i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n",
    "    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n",
    "    df_account_value = df_account_value.append(temp,ignore_index=True)\n",
    "sharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\n",
    "print('Sharpe Ratio: ',sharpe)\n",
    "df_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "oyosyW7_tj1g",
    "outputId": "d2dc62c2-e2a0-48fc-8183-0399d1b27f53"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_value</th>\n",
       "      <th>date</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>datadate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9931.040119</td>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>-0.006896</td>\n",
       "      <td>2021-04-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10006.012014</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10064.609410</td>\n",
       "      <td>2021-04-09</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>2021-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10022.651085</td>\n",
       "      <td>2021-04-12</td>\n",
       "      <td>-0.004169</td>\n",
       "      <td>2021-04-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_value        date  daily_return    datadate\n",
       "0   10000.000000  2021-04-06           NaN  2021-04-06\n",
       "1    9931.040119  2021-04-07     -0.006896  2021-04-07\n",
       "2   10006.012014  2021-04-08      0.007549  2021-04-08\n",
       "3   10064.609410  2021-04-09      0.005856  2021-04-09\n",
       "4   10022.651085  2021-04-12     -0.004169  2021-04-12"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "wLsRdw2Ctj1h",
    "outputId": "9a874df9-2c5f-423c-8fd2-8966aab63fc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAAsTAAALEwEAmpwYAABITUlEQVR4nO2deXxc5Xnvv8+skkb7LltescEL2AYMmDWEHQKFLE0haaENDU0DbdLcNiVJb9KmSZvc3LS52Who4gJtAklICCRAWA1mMeAFg228yatWa99mNDOamff+MeeMRrJkjZbRaHm+n48+mnnnLO/xyOd3nuV9HjHGoCiKosxtHJmegKIoipJ5VAwURVEUFQNFURRFxUBRFEVBxUBRFEVBxUBRFEUhBTEQkY0i0iwiu5PG/llE3hWRnSLyrIjMs8YvF5Eua3yniHw5aZ/rRGS/iNSIyL1J40tE5E1r/Oci4pnsi1QURVFOTSqWwQPAdUPGvmWMWWOMWQf8Dvhy0mevGGPWWT9fBRARJ/AD4HpgFXCbiKyytv8m8O/GmGVAB3DneC9GURRFGR+jioExZjPQPmSsO+mtDxht5dr5QI0x5rAxJgw8AtwsIgJcATxqbfcgcEtqU1cURVEmC9d4dxSRrwO3A13A+5M+ulBE3gEagL81xuwB5gO1SdvUARcAJUCnMSaSND4/lfOXlpaaxYsXj3f6iqIoc5Lt27e3GmPKho6PWwyMMV8CviQiXwDuAb4C7AAWGWN6ReQG4DfA8vGeYygichdwF8DChQvZtm3bZB1aURRlTiAix4Ybn4xsop8CH4a4+8gY02u9fgpwi0gpUA8sSNqn2hprAwpFxDVkfFiMMfcbY9YbY9aXlZ0kbIqiKMo4GZcYiEjy0/7NwD5rvNKKAyAi51vHbwO2AsutzCEPcCvwhIlXydsEfMQ61h3A4+OZk6IoijJ+RnUTicjDwOVAqYjUEXcH3SAiZwAx4BjwKWvzjwB/KSIRoA+41brhR0TkHuAZwAlstGIJAH8PPCIiXwPeBn4yWRenKIqipIbM1BLW69evNxozUBRFGRsist0Ys37ouK5AVhRFUVQMFEVRFBUDRVEUBRUDRVGmiCOtfl7a35zpaSgjoGKgKMqU8P0Xa/iL/95OOBLL9FSUYVAxUBRlSqjtCBCKxNhyuI07H9jKkVZ/pqekJKFioCjKlFDf0QfAvzy5lxf2NfPivsEuo/6oWgyZRMVAUZS00x+N0dgVF4P9J3oAqGnuTXy+/Vg7q7/8TGIbZepRMVAUJe00dgaJGfC4Bm45h5LEYOvRDsLRGA2dKgaZQsVAUZS0U9cRAODa1ZUArK0uoKZlQAxsYQiEo1M/OQVQMVAUZQqos+IFf3PVcp6452JuWjuPdn+Ydn8YICEMKgaZY9z9DBRFUVKltiOAQ2BBcQ5up4O23rgIHGrppSinKGEZ9KkYZAwVA0VR0k5dRx9VBdm4nXFnxLLyXAAeeO0ox9sCdAfjzQ7VMsgcKgaKoqSduo4A84uyE+/nF2aTn+XiyV2NPLmrMTEeCEeG212ZAjRmoChK2qnr6GNBUU7ivcMhPH7PJTz8yQ24nZIYVzdR5lAxUBQlrYQjMZq6g1QnWQYAS0p9XHhaCX95+TKqi7JxO4VAv4pBplAxUBQlrTR09mEMJ4mBzd9ctZyX/+79ZLudahlkkJTEQEQ2ikiziOxOGvtnEXlXRHaKyLMiMs8aFxH5rojUWJ+fk7TPHSJy0Pq5I2n8XBHZZe3zXbuPsqIoMx87rbQ6yU2UjIjgdAg5HpfGDDJIqpbBA8B1Q8a+ZYxZY4xZB/wO+LI1fj2w3Pq5C7gPQESKifdPvgA4H/iKiBRZ+9wHfDJpv6HnUhRlhmIvOFtQPLxlYJPjcWo2UQZJSQyMMZuB9iFj3UlvfYDdTPlm4CET5w2gUESqgGuB54wx7caYDuA54Drrs3xjzBsm3pD5IeCWiVyUoijTh7qOPpwOoTI/65TbZXvUTZRJJpRaKiJfB24HuoD3W8PzgdqkzeqssVON1w0zrijKLKC2I0BVQRYu56mfPdUyyCwTCiAbY75kjFkA/BS4Z3KmNDIicpeIbBORbS0tLek+naIok0BdR9+IweNksj0uzSbKIJOVTfRT4MPW63pgQdJn1dbYqcarhxk/CWPM/caY9caY9WVlZZM0dUVR0kldR2DQGoORyHE76dMAcsYYtxiIyPKktzcD+6zXTwC3W1lFG4AuY0wj8AxwjYgUWYHja4BnrM+6RWSDlUV0O/D4eOelKMr0Idgf5UR3aNDq45FQN1FmSSlmICIPA5cDpSJSRzwr6AYROQOIAceAT1mbPwXcANQAAeDPAIwx7SLyz8BWa7uvGmPsoPSniWcsZQNPWz+Kosxw7EyiRSWjWwYaQM4sKYmBMea2YYZ/MsK2Brh7hM82AhuHGd8GnJnKXBRFmTkca4uLwcJi36jbqmWQWXQFsqIoacMWg9QsAxd9/VFiMTPqtsrko2KgKEraON4ewOdxUuLzjLptjscJQDCi1kEmUDFQFCVtHGvzs7DERyoVZmwxUFdRZlAxUBQlbRxrD7CoeHQXEUC2Oy4GGkTODCoGiqKkhWjMUNfel1K8ACDHE89nUcsgM6gYKIqSFpq6g4SjMRamLAa2m0gXniXT0NlHcApWZqsYKIqSFg409QCwtDQ3pe2zPeomGkokGuPa72zmx68cTvu5VAwURUkLr9a04nE5OHthYUrbawD5ZBq7gvQEI9Q096b9XCoGiqKkhddqWjlvcRFZVmB4NBJioMXqEtjrNBq6gmk/l4qBMufYcbxDFzalmeaeIPuaerh4WWnK+2RbAWR/SGMGNsfa/QA0qRgoyuSyq66LD/3wdR5/Z9jCuMokseVQGwCXLku9unB5nhePy8HhlvS7RGYKxy3LoKkrmPYHGBUDZU7x5pH4TeqVA60Znsns5sCJHpwOYWVVXsr7uJ0OVlbmsau+K40zm1nYbqJwNEabP5zWc6kYKHOKbUc7AHj9UBs/2FTDj14+lOEZzU7qOvpS6m42lLOqC9hT361uPItj7QHczvjq7cauvrSeS8VAmTMYY9h2rINst5Om7iDfemY/9718iKjeeCadVLubDeWs+QX0hCIcbfOnYVYzC2MMx9v8rFtQCEBDZ3rjBioGypzheHuA1t4Qf7xhYWKsM9DPngZ1S0w2qXY3G8pZ8wsB1FUEtPnD+MNRNiwtAdQyUJRJY8fxuIvow+dWc+OaKr584yoANr56hM8+8raufJ0kQpF4d7PqcYjB8opcvC4Hu1UM2NvYDcA5i4rwuhw0pjmjSMVAmdU8/NZxatvjQbj3GrrxuhwsK8vl+x87h09csoRVVfn8ZmcDv9nZwN7GngzPdnZguzPG4yZyOx3MK8xO+41vJvDivma8LgcblpRQVZBFfWeGLQMR2SgizSKyO2nsWyKyT0TeFZHHRKTQGl8sIn0istP6+Y+kfc4VkV0iUiMi37X6HSMixSLynIgctH4XpeE6lTlIhz/MF369ix9sqgFgX1MPyytyBwU1P7CmKvG6rTc05XOcjditLscjBgD52W66+vonc0ozDmMML+xt5qLTSsj2OFlTXcjz753gvYbutJ0zFcvgAeC6IWPPAWcaY9YAB4AvJH12yBizzvr5VNL4fcAngeXWj33Me4EXjDHLgRes94oyYY5bFsHze5uJxQz7mnpYUZk/aJtPX34aL/3t5QBpT92bzcRihn95ai9HWv3UdcSfYKtTLF09lAIVAw61+DneHuDKlRUAfPmmVRTmuLnn4R1EorG0nHNUMTDGbAbah4w9a4yxHaxvANWnOoaIVAH5xpg3rB7JDwG3WB/fDDxovX4waVxRJsQxSwxae0O8fKCFlp4QKyoH572LCFWFWYBaBhOhvrOP+zcf5undjdR39OFyCBV53nEdq1DFgF/vqEMErlhRDkBprpd/+oPVHG7x8/s9TWk552TEDD4BPJ30fomIvC0iL4vIpdbYfKAuaZs6awygwhjTaL1uAiomYU6KkogVOAS+9+JBgJMsAwCvy0lelovWXrUMxoIxJrEeoKk77uNv7QlT1xGgchxrDGzmumXQGQjz0JZj3HBWFfMKB1xtV6+qZEmpj//cfJj4M/XkMiExEJEvARHgp9ZQI7DQGHM28DngZyJy8v++EbCshhGvUkTuEpFtIrKtpaVlAjNX5gLH2wKU5nq5YkU5O453ArBihBWxJT5Pwk205VAbv32nYaqmOWP5wq93sfSLT/Ho9rpE7ZzW3hBN3UGqCrLGfdyCbDfdff1zduHZf285Rm8owl9fsXzQuNMh/PmlS3inrot36iY/22rcYiAifwrcCHzcuoljjAkZY9qs19uBQ8DpQD2DXUnV1hjACcuNZLuTmkc6pzHmfmPMemPM+rKy1GueKHOTY+1+FpXk8O2PruPM+fnML8ymNHd410VJrjfhJvr2s/v5m5/v5Jfbarnxe6/QkOYsjpnKztpOAD7/6DscbY0vEmvtDdHcHaI8f2JiEDPQO0dTfQ8297KoJIczKk9+cPnwOdX8/K4NrK0umPTzjksMROQ64PPAHxhjAknjZSLitF4vJR4oPmy5gbpFZIOVRXQ78Li12xPAHdbrO5LGFWVC1Lb3sbA4h4JsN49+6iIe+/RFI25b4vPQ1hsmGjO819hNJGb4u0ffZXd9N+9YNz1leGIG3joaDyu29oY40R2kIm9iYgDQFZibrqJAOJpoATqULLeTC5aWYCVjTiqppJY+DGwBzhCROhG5E/g+kAc8NySF9DLgXRHZCTwKfMoYYwefPw38GKghbjHYcYZvAFeLyEHgKuu9okyIcCRGQ1cfC6yMliy385RPqyW5Xtr8IY609hIIRzl/cTFeV/y/R3LOeyxmEqmTc52eYCQRkN9+LL6gr7a9D384SkX++ILHAAU5lhjM0bhBIBxJ9HaYSoaXnySMMbcNM/yTEbb9FfCrET7bBpw5zHgbcOVo81CUsVDXEcAYWJRiemNprod2f5h3auO+2K/esprTy/NY+eXfD3ITfef5A3z3xRr+ZMMivnLTqnEHSWcDPcF+LjythH1NPYnuZH1WY5qKCbqJYC6LQZS8rFFvzZPO3P1LVmY1dsD49IrUSiiX+DzETLw7l71K2eEQ5iethj3a6uc/Xj7M/MJs/vuNY2w+OHeTGIwx9IYiVBVkDRuHKZ+IZTDHxaAvHM2IZaBioMxKnt7VyPzCbM6cn1oyW4l1Q3v5QAsrq/ITT/xVhVk0WAXC/uPlQ7icwvc+djYALT1zd11CIBwlZiDX62JJadz6WlA8kAaplsH4CfRHRowZpBMVA2XW0R3s55WDrVx/ZmXKgbaSXA8QX4W8ftFARZSqgmwarVo72451cOHSEs6wrI2OGRzgfKe2k9drxt/gpycYz/TJy3KzuMQHwOqqgQwXFYPxEwhFyVbLQFEmzuNv1xOOxrj+rKrRN7ZIdnXc/f5lidfzCrM50ROk3R/mUEsv6xYUkuNx4nYKnTNYDL742C6+9Jvdo284Ar2h+LXnZrlYXBoXA9sK83mc5HrH/2Rr//vOWTEIR/FNxwCyoswkdtd38bUn93L+kmLOtpqCpMKCohzWLSjk7vcvo8jnSYzPK8jCGHj+vRMYA2sXFCIiFOZ46AzMzBXLJ7qD7GnoxuUQItHYuILg3QnLwMVSSwzOqi4EoGICC84gXiLEXoW8q66L7286iCD8zdWnD5t7P5uIxQx9/VGyM+AmUjFQZhU/2FRDrtfFDz9+Dg5H6rnY2R4nv7n74pPGq6xyAE/tjldMWWvd8Aqz3TPWMti0L76uMxIzNHYFE+m3Y6HXFgOvi0uWlfKdP1rHpctKyXI7JrTGwCY/281jO+r55bZa8rPctPnDrJ6XP+vFwM7G0gCyokyQmuZezllUNOJK47Eyz3rKfeVgK0tLfYkc+KIcD519M9MyeHHfwCJ/u+H6WEmOGbidDm45ez4Oh7CwOIfFpeOrVpqMx+mgrz/KaWW5PP+59+FxOvBb6auzGTtFV8VAUSZANGY41hZIuC0mg/lF2WS5HURjhqtWDdRQLMiZmZaBPxThlYOtXGlVw7TLfI+V5JhBMg994gLuvX7lxCYJHGrpBeDrHzyLIp+HHK9zTnSi67PEINutMQNFGTcNnX2EozGWTKIY5HhcvPi/LsfjcgyyNopy3Oyqm3li8PvdTfT1R7nrsqW8crCVY+3jazzfkxQzSKZygvECmx987BxqO/o418rs8nlc9IZmvxgE+uPX6JtAAH68qBgos4YjVrG0yRQDYFAZYZvCHA8dMzCA/KsddSwszuH8JcVUF2VzfBxuoljMJMTAl6ZA5zWrKwe993mdBEKz303kt64xE6mlKgbKrCFdYjAcBdluQpEYwf4oWRkw6cdKfzTGvz61jy2H2/jMlcsRERaW5Iw5ZtDcHeTy//sSC4pyyPW6cI4hSD8RfF4X/lnsJjLG8MOXDiXWWORk4G9KYwbKrOFIqx+fx0nZODtsjYWinHj66UyJGzy75wQbXzvCh8+p5pOXLgXidZuOtwfG1Chl+7EOAuEo+0/0TGgtwVjxeVz4Z7GbqKUnxLee2c/P3jwOoCuQFWUiHGn1s6TMl5byvkMptLKKZoqrqNaqtPqPf7A64Y+uLMimNxRJZLCkwu6GgaYqU1lMLcfjHNM8Zxp1VjFEO6Cf41XLQFHGxdFWP28f7+C0stwpOZ8tBtPdMmjuCdLcE6Sxs4+8LNegp3n7Zj6WJ+5d9d2J10MzidJJrnd2B5Dtyrj2NU7LEtaKMt0JRaL8ycY3cTkd/NUVy0bfYRIozLbdRNPHMghHYgQjUfKz3Imxzz6yE4cIOR7nSa0obTHoCUUoT+H4xhh213fhcToIR2PkJZ0n3cRTS2evZTC0m16OW91EijJmDp7opba9j6/ctIpl5VOzQrXIZ1kG06h+zv99dj/Xf+cVItFYYmxfUw97G7tp6g5SWTA4K8q2EuzMoNFo7IrXaLr2zHimT94siBkYY/jzB7fy4r4Tk37sVDjRHeTxnfU0dAYHjWuhOkUZBwebewBYPS+1ctWTwYBlMH3E4FBzL/Wdfbx5JN5csDMQpt0fps0fpqa5N7Ga2sZ+su9NUQz2NMRdRH94brW1/xSKgddFKBIbJHSTQWegn+f3NvPG4fbRN04DD205ymce2cnWowPndzsFj2vqb82ptL3cKCLNIrI7aexbIrJPRN4VkcdEpDDpsy+ISI2I7BeRa5PGr7PGakTk3qTxJSLypjX+cxEZqBKmKClw8EQvLoewqCT9KaU22R4nHpdjWpWkaLb6KzyxswEYSLWFeJmDoQvCbMvAXk08Gk1WX4cVVXnceckSrlldMcoek4ftQ5/skhR246KeYGZE/VBz/DuyhRYys/oYUrMMHgCuGzL2HHCmMWYNcAD4AoCIrAJuBVZb+/xQRJwi4gR+AFwPrAJus7YF+Cbw78aYZUAHcOeErkiZcxxs7mVJqQ/3FLegzPNOr3RHu9nO07sbCUdig8QAGDlmkKJl0O6P3zCLcjz87xtXccWKqRMDW7gmuyTFie64GHSn+G8w2Rxu7U28LrGq5WYirRRSEANjzGagfcjYs8YY+1/vDaDaen0z8IgxJmSMOQLUAOdbPzXGmMPGmDDwCHCzxHMArwAetfZ/ELhlYpekzDVqmntZXjE1WUTJ5Ga5UnaxpJtYzNDaG+L0ily6gxG2Hm3nSKsfh8TdDsCEYwYdgTD5Wa4pF12AHO/YM59SwbYMuqc49nPnA1v54Us1HE1a9LfOKrmeiUwimJyYwSeAp63X84HapM/qrLGRxkuAziRhsccVJSWC/VGOtfmnLHCczHSql9MRCBOJGW5eNx+P08Gmfc0cbvWzoDgn4T4bGjOwU0NTvYY2f5hiX2a8uHazF/8kl6SwXV+pCuJk8dqhVn708mHCkViiXWhCDDKwxgAmKAYi8iUgAvx0cqYz6vnuEpFtIrKtpWXuNiNXBjjS6idmYFl5ZiyDqb6JjIQdL1hc4uOCpcW8dKCFIy1+lpT6ElVch8YM3E4HWW5HymLQkUkxSJNl0JRwE02dZRAIRwj2xxKd3P70oiW4HML7zigDMpNWChMQAxH5U+BG4ONmYD17PbAgabNqa2yk8TagUERcQ8aHxRhzvzFmvTFmfVlZ2Xinrswi/ueNY4jAWfMLRt94ksmbRguh7HhBWZ6X959RTk1zL/tP9LCsLJfzFhezqCRn2HUBuV53yoKWWcvAEoO0BZCn7nts6x2cdHDLunns+sdrWVNdSF6WKyNppTBOMRCR64DPA39gjEmudPUEcKuIeEVkCbAceAvYCiy3Moc8xIPMT1gisgn4iLX/HcDj47sUZa7xek0rP33zOHdevGRKitMNJTdr+oiBbRmU53m5ZnUFJT4PN62p4i8vP40/v3QJL/6vy4fdLy/LlXImTWYtg/gNcrwB5P5ojI/95xu8ebht0HjTCNlEtWOs2TQW2v0DYlCY46bY50kIwOISH+VTUFtrOEa1R0TkYeByoFRE6oCvEM8e8gLPWXVg3jDGfMoYs0dEfgG8R9x9dLcxJmod5x7gGcAJbDTG7LFO8ffAIyLyNeBt4CeTeH3KLObFfc14XQ7+9tozMnL+XO/0CSAnWwY+r4vt//vqQZ87RyjXlGqZB2MM7f7woP7QU4nPO7b4xlDqO/p4/VAbFy8r5YKlJYlx200U7I8RjsTwuBw0dQV537c28b3bzuEDa6omPvkh2GJw1coK5hdmDaql9ZM71uN1ZcYyGFUMjDG3DTM84g3bGPN14OvDjD8FPDXM+GHi2UaKMiba/GFKc70ZKyGdm+WiZ5pYBi09IXwe55ibouSlmBHlD0cJR2OJ9Mepxs6wGW9Pg4auwbV/7Nc9wQhVBVk0dgXpCfZTkuulpSdEzMCWw61pEYM2Swz+940rT1obU54/Oc2BxoOuQFZmLHExyNwaxTyvi3Ak/kSZaZp7guMq3Z2qZdBh3cDs0t1TjZ17P17LoNEq95AsfLaLaHlFPBPNXmtgn2Nnbee4zjUa7f64FZcpl9tIaKE6ZcbS1huiIoNPUrlJGS4e19T/xw72R/nuCwfZfLCFY20BVlaOvRxHqhlR9tNsSYbE1+kQst3j74Nsu4OSs5GarbHl5blsPtCSiBvY59jX2ENfODrpAd02fxiP0zGl/SBSQS0DZcbSnsGAJkCuXdsnQ66ih7Yc5YcvHSLHEy9Nfd6SojEfI887OID841cOc/dPd5y0XaYtA4gHkcebTWRXBU1267X0xp/Q7bLnPUMsg0jMDOrfMFm098b/bqei78ZYmF7SpCgpYoyhrTecsSdVGPsK3skkFIny41eOcNFpJfzskxvGfRw7I8oYg4jw3HsnePt4J9GYGdTSMmEZ+DKT6QLxIHJzdzAx17Fgp5AmWwZ20P20srjf3l6FnLywbefxTs5bXDzuOf/Hy4fYsLQksaAMMv8QMxJqGSgzkp5QhHA0RmkGb055Y1zBOx5+83Y9H//xGyelOf72nUaae0L85eWnTej4eVluYgb6+uM3wMOtfsLR2En19ROWgW/qehgM5YIlxTy/t5l/+M3u0Tcegi0Gyd9Vc08Ir8vB/KL4CmBb1G3B8LgcHGnzMxa2Hm3nv7ccBeIPLN96Zj8/31o7aJs2f2YfYkZCxUCZkbRbC3cy6iYaY9XPsWKM4fubanitpu2kQmovH2ihPM/LJctKJ3SOxDUEI3QH+xNPy0eH3ASng5/7Xz+0hmtXV/DUrsYx79toZxMFB1sGZXnexGI8exWy34oZVBVkJVYJp8rDbx3n288dAOICG40Z6joCg7ZRy0BRJpE2KyMjo26iMVb9HCs7jndQ0xyvamlX1zzS6qfDH+bNw21csLRkwn5n27rpDkY43DIgAMkF1ADqO/uoKPBm1M/tdAjLy/PoDkbGtCCsLxxN9J3oDQ0jBl4XIgPZRP5QhGy3k8Icz5gL2HUF+hMd2ey/i/qOwVZWW29oWoqBxgyUGUmrZRmU5mbOTZQ7wYVQo5HsXmjqCrK8PJdb798S9533hLhgyfh92Tb2NTy/98SgG9TRIeWvD7f0srR06us/DSU/20U0ZvCHoylbKfYag9JczxA3UZAlpT4cDiHXMxBI7w1F8XldFGS7x9zWtLOvn3AkRn80lhCDus4+YjGDwyEE+6P4w9GM/t2OhFoGyozi9ZpW+qOxxCrOaeEmSoNl0BuK8Lt3G9mwNH7Db+oOcrw9wInuUOIJ3v5sIpy/pJi11QV84+l9/MtTe3E5hNPKfBxLchMZYzjS6mdp2dSX/BhKQXbcpTMW940d/1hWnksgHHfdwIBlAJCf7aa7L/49BsIRfF4nBdnuMVsGtngEwtGE8IQjMVqtzCXbQslkVtZIqBgoM4aa5h4+9uM3eWxHPW29mV+4k+NxIpIey+CpdxsJhKP81RXLATjRFWTH8Q4gng5amutJpEROhLwsN7+5+2I+dPZ8OgP9LCzJYVl57qDGOCe6QwTC0UT100ySb/v3x3CTPngi7mpba2X0+MMRwpEYHYF+yvPi61TyslwDMYNQBJ/HRUG2a8wxg66+gWMkp+zWdgxeAZ07hS1DU2X6zUhRRsD2n++s68TrcpDndWWsFAWAiJDrTU8Z659vq2VpmY+LTiuhKMdNU3eQlt54yYmH79qAPxSZNP+9iHDvDSt49r0TnF6ex6LSHDbtayEaMzhkoBvX0kkQn4kyHstgf1MPJT4PS6zSDzuOdSRiMAnLIGvACugNRci13ER2fCKVf2tjTOLJPxCODLIY6zv7OHdRUSJTyZehyqSnQsVAmTHYQc3d9V0sLvFRPA3S89JRxrqmuZftxzr4wvUrEBEq8rM40R2kqTvI2gWFnJmGct3leVk8+pcXkp/l5tWDrYSjMY62+bnzga1kW6UgMlEZdij52WO3DPad6OGMyrxE3aavPbk38WBRljvgJrKzfvyhKCW5Hgqy3URjht5QZNjy30MJhKNELBeUPxQd9JCQOLaVqZSp1panQt1EyozBDmrua+xhb2M3lRksRWGTmxUP5gb7J6/O/i+31eJ0CB88J970r7Igi8OtfvY29nDOwrGvMk6VFZX5zCvMZmVVvKzFb99p4GhbgL2N3WS7ndPi33uslkEsZjh4oofTK/ISrpnDLQN9h8vzvYnjJhadhSOJAPJI59p2tJ0HXjtCKDLwvXcmbecPRxKrnT0uB3WWm8gutOfLUDezU6FioMwY7Nz3cDTGweZeblw7L8MzirsZNh9o4brvbJ7wsXbVdXHj917hZ28d54oV5Ql/dmV+Fodb/ERjhkuXT2xdQSqcXpmLyyH8IimbabGVdZNpEjGDFF1ztR0BAuEoKyrzEgH/WFJWqu0mKsh2D/L353pOLQb/74WD/ONv3+Mj921JBKSTM48CoWjCTbSsLDchBrZlMNbqslPB9JuRoozAsbYA5y4qYvuxDnI8Tm5Zl3kx+H+3ns23nz3Aw28dp2OC9f5/t6uB9xq6ycty82cXLU6M28X45hdmT6g0Qqp4XU6Wleeyr6kHn8fJX7zvtIz1MRhKXlZ8TUCqlsG+ph4AzqjMGxRfuvOSJSwuyaGqIL76uDDHjT8cpT8awx+KkuN1JlxSw53LfjDZVd9Fmz9Eh78/UQUVLMsg2E+Ox8ni0pzEPOxSF75p6CaafjNSlGHoC0dp7Apy63kLqe/o49rVFSn5cdNNaa6XK1eU8/BbxznS5p/QTXPb0Q7WLSjk15++eNC43bv4lrPnTdnT+ap5+exr6mH1/AL++srlU3LOVHA44kH7VGMGhyyX0OkVeYM6jK1fVMT1Zw30Kki2AvzheAB5IHNpsBUSjsSo7+hjaZmPwy1+mrtDfPi+1wf14bZTS3O9LqqLcnhhbzPGmERF1Ew1vT8V6iZSZgTH2+MBuCVlPp757GX8w42rMjyjARZbgdWhC7XGQrA/yq66rmGf/NdWF1KZn8VH1y8YZs/0sHpegXXuqe8tPRpjyf/v7ovgcTnweV2DFqktKM456ZgQX+ltDINiBkPPdbw9QMzAuupCIF7PKRSJsaehO7GN32qck5floroom1AkRmtvOGEZ5GQwC24kVAyUGYEd9FtckkNBjhu3c/r86S4szsEhDMrNHyu76rsIR2Ocu+jkAPGqefm88cUrT+qKlU7OsjKW1iZV25wu5Ge5E2sCRiMQjiS6pCX76RcUDS8GdukIn9dFQc7wbiJb9NctLBz0fvB5o/SEIuRmuZlfGHdF1XUECIQjZLkduKbR36/NqDMSkY0i0iwiu5PG/lBE9ohITETWJ40vFpE+Edlp/fxH0mfnisguEakRke+KlbgrIsUi8pyIHLR+py9dQpmxvLS/BZ/HyelWV6rphMfloLooZ0JisPVoO8CwYpAJzltcxI9vX891qyszPZWTSA72joY/FE345z0uBx6Xg7ysgRu9jR0fsFcr+zxOcj0uHMPEJ+x4gV2WOvl7t89hxwzys+JuIoC6jj56rQVt05FU5OkB4LohY7uBDwHDpVAcMsass34+lTR+H/BJYLn1Yx/zXuAFY8xy4AXrvaIkCEdi/H5PE1evqsjoIrNTsaTUNyExeL2mjeXluZRMk5o1IsJVqyqm5RNsfrbrJD/+SCRbBhBfFzLUKoABy6DBCgL7vC4cDiF/GOE50uqnINudcA8mf+8F2W5yva5ENlGu15UokV3X0UcgHJ2W8QJIQQyMMZuB9iFje40x+1M9iYhUAfnGmDdMvNzgQ8At1sc3Aw9arx9MGlcUAF471EpXXz83rsl89tBILCn1cbTVP6ZqmjZ94ShvHW3nstPL0jCz2ceYLINwlJwk91CRzzPs4rmCIZaBHV8oyHbT5g8lSntD3DJYXOojz+vC6ZBB5b4Ls93keJz4w5FEADnX66Iox019ZyBR6mI6kg7ZXyIib4vIyyJyqTU2H6hL2qbOGgOoMMbYBcqbgIqRDiwid4nINhHZ1tLSMukTV6Ynz+5pItfr4tLT059jP16WlPrwh6M0J900UuWNI22EIzEVgxTJz0pdDPrCkUGlH75329l88QMrT9puqBjY1kSwP8pTu5q4/FubaO6JWw3H2wMsLslBRMjPciVKULidQmGOG5/HlRRAjh93flF2wjKYjmsMYPLFoBFYaIw5G/gc8DMRSblLt2U1jPhoZYy53xiz3hizvqxM/+PMFV4/1MaGpSV4XdPTvAY42womvrx/7A8pmw+04HU5JqUk9VygINtNX3+UcCQ26rb+UHRQ6YeVVfmJgG4yHpeDbLeThs74Dd+2DFZUxm9fff1RNr56FIDWnnCijEWhVX00z+tiTXUhC4pyyPE66Q1ZloG16rm6MCcRM8iZhnWJYJLFwBgTMsa0Wa+3A4eA04F6oDpp02prDOCE5Uay3UnNkzknZWbT0NnHsbYAF55WkumpnJKz5hewsDiH377bMOZ9Nx9o4YKlJdM2HjLdSNQnSiGjyC5HnQoF2fGCgE6HMM8SjG9/dC1vfOFKbjiriv954xjN3UH6+qOJuli2RVHk87DxT8/jn285E5/HRXN33ELMt8WgKJu6jjnkJhKRMhFxWq+XEg8UH7bcQN0issHKIrodeNza7QngDuv1HUnjisKWQ20AXLh0eouBiPCBNVW8fqht0OKm2vYAH/3RlkQ9+6HUdQQ41OLnsikoMzFbsMuWJ/87j4Q/HE25KFyhlWG0smqgqF1prpfKgiz+cP0CekMRXq1pjc/BsgjsfYpy3BRku/F5XeR4nImqqLaFMa8wm2B/jPrOvpkbQBaRh4EtwBkiUicid4rIB0WkDrgQeFJEnrE2vwx4V0R2Ao8CnzLG2MHnTwM/BmqIWwxPW+PfAK4WkYPAVdZ7ZQ5ztNXPzd9/lQdeO8KTuxopynGzonL6pZQO5YYzq4jGDK8cHHAVbdrfzFtH2tl2tGPYfTYfiN9c3qfxgpSxW52OJLDJBEKRlMtF2xbH+kUnu+vmWavA7bIStiAVJlkGNj6vK1E7ybYcbEsjEI5OW8tg1FkZY24b4aPHhtn2V8CvRjjONuDMYcbbgCtHm4cyd/jak+/xTl0X79R1AfCnFy2eFkXSRsPuBNaYVKNmd338GoY2mLfZfKCFqoKsQaUMlFNjt4xs6z21ZRCLGQL9g7OJToV9416/+OS1HnbRwL2N8VXGtiDZMYPkzmXJMQF7JXd10UCcYroGkKfnrJQ5y+93N/H83mb+/roVrKkuoCjHw8qq6W8VAAkXQXIa4u76+M3jSMvJYtAfjfHaoVY+cFZVRhvNzzQGxODUlkEwEo2XlkjRMig4hWWQn+3C43IkWQYDfRBgsBjYN/uyPC8LiuMiMC8paD0dG9uAioEyjdi0r5m/engHa6oL+MQli6d19tBIlOZ6E2IQikQ5cCJ+8zgyjGXwWk0rPcEIV64cMZtaGYbCbDcOgdZRLINEHaAUn8QvXlaCPxRJFAZMRkQoz/MmSlEnYgbZAzEDG9syOHtBYULki3LcZLkdBPtjKc9nqpl+ywuVOUlvKMLnf/Uuy8vz+O87L5iRQgDxp0FbDA409RKJGQqy3cOuTv7du43keV1cNo3XT0xHHA6h2OelzX9qyyBRITTFLK0Pnl3NfX987oifl1u9D1wOIT87fkNPBJCTYgZ2hzPbRQRxMbGtg+lqGagYKNOCH2yqoaUnxL986KyEuT4TKcv1JgKbuxvi8YLrz6ykpSc0qD1mOBLjmT1NXL26YsYKXyYpzfWkbBlMVlcxO25Q5PMknvgHsokGxMDuerd2weCKr/b6hukaM1AxUDLOpv3N/OjlQ3zk3OpE8a+ZSlmelxZLDJ7Y2cC8gqzEyuLk6pa76jvpCUa4ZtX0KwQ3EyjN9Y4aMwhMcr9hu0VmcdKNf1lZHnleF2dUDiQA/O01Z/DPN68+KUNsXoEtBtNT/FUMlIzS4Q/z1z97mxWV+Xz15tWZns6EKcvz0hnoZ2dtJ1sOt3HHRYsTtXCSXUW273lZeeabzM9ESlKwDALhybYMLDFIcgktLMlh1z9dy7LygSSHIp+HP7lw8UlJAbabaLLEabKZnrNS5gyPbK2lJxTh3/5o7bT9TzIW7J663352PzkeJ7eetxCv24EI1DQPNGK3yx7YbReVsVHiy4BlYLmJ7NXHY2VeYXz/GbvOQFHSwe93N/Jfrx3laJufC5eWJGrAzHTsmjWvHGzlprXzEnXzF5f4ONjck9iuobMvsWJVGTsluR784Sh94SjZIwRkJ7vfcJnlJioZZ2vTa1ZXUtvRN21TpfUvUZly2v1hvvDrXXT19RMz8NWbT1qLOGMpzRvoR3BRUj2l0ytyEznqEBeDecMUTFNSwxbd1t7QSS0sbSa733CFHUDOGZ8YFGS7+dzVp0/KXNKBioEy5Xzn+QP0BCM8cc8lRGOGNdOwz+54KRtBDM6oyOO5904Q7I+S5XZS39k3aFWqMjbsFcBt/vCIYuAPT65lML8wG6/LweLS4c8309EAspJW9jZ28/BbxweNvbC3matXVXDm/ALWJi3MmQ2UWjepeQVZLEy6SZ1emUfMwCGrl7NaBhPD7gjXeor+EYFQBBHIck/Oba4gx81Lf3c5f7B2/ugbz0BUDJS0svHVI3zxsV2JHPv6zj7qO/s4f5bW7ve6nJTnebl0edkgkTvD6t184EQPvaEI3cGIisEEsNM7OwIjZxT5raJwk/mwUVWQjXMG1MkaD+omUtJKTUsvxsB7Dd2cv6SYbVbj9/MWz04xAHj4rg2U+gb3Ml5c6sPjjNe2OdNamVo1TNkDJTUKffHAvN1lbDiG9j9WTo1aBkraMMZwyEqnfLeuE4C3jrST63Wxsmp2ZA8Nx2lluYksIhu308HSMh81J3qpt1orDtdxS0kNu//wKS2D0PRtMTkdUTFQ0kZLbyhR190u5bz1aDvnLCqatab2qVha5uNwqz8hBlUqBuNGRCjMdtN5il7IgXCEbO0elzIqBkraONQcX3FbkO3m3fouOgNhDpzo5fxh6sXPBZaW5nK8PcDu+m58HidV+eommgiFOW46T2EZdPX1JwrKKaOjYqCkjRorc+aGs6o40urn5QPxDmCzOV5wKk4r9xGNGZ7d08SqefkzomHPdKYox0OH/2TLIBKNAXExKMwe35qAuUgqbS83ikiziOxOGvtDEdkjIjERWT9k+y+ISI2I7BeRa5PGr7PGakTk3qTxJSLypjX+cxHRb28aU9cR4MevHOa/XjuS+E83Eoeae/F5nNy8bh7GwLefPYDH6WDtDC9GN16WlsaLmbX5w4PKGyvjozDHc1LMoCvQz5p/epbNB1ro6uuf0RVwp5pULIMHgOuGjO0GPgRsTh4UkVXArcBqa58fiohTRJzAD4DrgVXAbda2AN8E/t0YswzoAO4c36UoU8FXHt/D157cyz/99j0+88jOUwrC3sZulpblcsGSYk4r83G8PcCa6gKy5qgf126LCbB63uwNoE8VRTnuk7KJmrqDBMJR9jf10BnoPymQr4zMqGJgjNkMtA8Z22uM2T/M5jcDjxhjQsaYI0ANcL71U2OMOWyMCQOPADdLPAH4CuBRa/8HgVvGezFK+nmnrosPnT2fL96wgid3NfLL7XXDblfbHuCto+1cfkY83/5PNiwCYP0cdREB5GW5EyuUz5yvlsFEKfKdbBnY61kauvoIRWJqGYyByY4ZzAdqk97XWWMjjZcAncaYyJDxYRGRu0Rkm4hsa2lpmdSJK6PT3B2ktTfEWdUFfPLSpaypLuC+lw4Nax08svU4Atx2/kIAPnxuNVevquCWs+dN8aynF6eV+fC4HCwrzx19Y+WUFOa4CUVi9FllJ2BADOzeESoGqTOjAsjGmPuNMeuNMevLyspG30GZVOzOXWfOL0BEuOf9yzjeHuCTD21jV11XYjt/KMLPt9ZyxYqKxCrbvCw3/3n7+llTnXS8fPDs+fzxBYtwO2fUf71pSdEwq5D9lhgcUTEYM5Odd1UPLEh6X22NMcJ4G1AoIi7LOkjeXpliYjHDozvq+MBZVYnFOpFojF/vqOft2g4C4SgiJBaMXbWygr+4bCk/31bLZx55m+c/9z4cDuFHLx+itTfMX16+NJOXMy35o/MWZnoKswa7GX1HIJx46Oi11rXUWs2DVAxSZ7LF4AngZyLyb8A8YDnwFiDAchFZQvxmfyvwMWOMEZFNwEeIxxHuAB6f5DkpKbL5YAuff/Rd6jv6+Bur1O7/e+Eg33uxBhEwBpaW+si1hMLhEL5ww0pWVuXz2Z/v5JWaVlbPy+f+Vw5z09p5nLto7sYHlPRTaFkGXUlBZNtNFI0ZQMVgLKSSWvowsAU4Q0TqROROEfmgiNQBFwJPisgzAMaYPcAvgPeA3wN3G2Oi1lP/PcAzwF7gF9a2AH8PfE5EaojHEH4yuZeopMoze5oA+NlbxwlHYhxq6eVHLx/mlnXz+OVfXIjLIZw1TLnp68+qpDTXw0OvH+WNw20E+2PcecmSqZ6+Msco8tmWwYAY2G4im0LNJkqZUS0DY8xtI3z02Ajbfx34+jDjTwFPDTN+mHi2kZJB4ouhTjC/MJv6zj5+v6eJF/eewONy8KUPrKIsz8svP3UhlcMUV/O6nHzonGo2vnqE8vwsPC4Hq2Zx7SFlejBczKB3iBioZZA6GsVSgHjNoDZ/mC/csIKlZT7+7dn9PLWriQ+fMz+RDnn2wqIRe/ZetryMSMzw6x11rJ6Xj8elf1pKerGf+jtPIQZ5WSoGqaKFOxQAXj3YitMhXH5GOS6Hg0/9z3YAPnbBopT2X7+4CK/LQSgSY90cXWGsTC1elxOfx0m7/+SYAUBelmtOFkQcL/r4pgDw5pE2zpxfQK7XxbWrK7jotBIuXV7KGZWpNe/OcjsTDWtUDJSpojjXQ7t/oNtZcsxAXURjQy0DhWB/lHdqu/jTixcD8fLAD37ifMb6TPW+08t4taaVcxbOzaqkytRT7PPS5h/sJirKcdMR6Nfg8RhRMZgjHGvzk+t1JXrH9oYifOS+11lc4uOiZSWEozEuSGpFOZ5FUbdfuJjzFheP2KBcUSabEp+Hpq5g4n1vKMLC4hw6Al1qGYwRdRPNEf7sv7by9Sf3Jt4/8NoR9jX18GpNK19+fA8isH6C6wI8rrlbkVTJDCU+D+3+5BXIUaqLchBRN9FYUctgDhCNGY61BxIZPjtrO7l/82GuWlnOt/9wHRtfO4IxRis8KjOOeMwgTGtviOPtAXqCEfKzXVTkZVGep82DxoKKwRygtTdENGY43Ornt+808FcPv01hjpu/u3YFBTnuxGpjRZlplPg8hKMxvvH0Pn73bgPGgM/j4n/+/HyKfd5MT29GoWIwB2iweu6GIzE2vnaE0lwvL/3d5YmyEooyU7Fv+G8daSfYH6+em5vlYll5allwygAaM5gDJAfY3j7eyXmLi1QIlFlBiS++Cvl4eyAxpn/b40PFYJayr6mbbz+7n+5gPw1JYgBw7iJN/VRmByW5J3fJ9akYjAv9V5ulfO+FGp7c1chjb9dzwZISvC4HeVluWntDKgbKrKHYd7IYqGUwPvRfbRYSikR5aX8zaxcU8k5tJ83dDcwvyqYi30tPsF+bsSuzhpKkIHFBtpuuvn4Vg3GibqJZyOuH2vCHo3z2yuVU5mcRjsaozM/i4xcs4q+uWKZF5JRZQ7bHSbbbCcAVK8oBdRONF70rzEKe2d1EjsfJhVZ9IYCqwixuWjuPe65YnuHZKcrkUpLroSDbnXB/qmUwPvRfbZaxt7GbX26v46Prq8lyO7ns9DJ+ub2OqmH6ECjKbKA010tprpeb1syjMxBOubiiMhgVg1nGlx/fTWG2m89fuwKI9xko8XlYU12Y2YkpSpr4hw+sxOEQCnLcavlOgFTaXm4UkWYR2Z00Viwiz4nIQet3kTV+uYh0ichO6+fLSftcJyL7RaRGRO5NGl8iIm9a4z8XkZPTA5SUCEdibD/Wwa3nL6DIyrIoyHGz7R+u4trVlRmenaKkh/WLi7VS7iSQSszgAeC6IWP3Ai8YY5YDL1jvbV4xxqyzfr4KICJO4AfA9cAq4DYRWWVt/03g340xy4AO4M7xXsxcp6krSMzAohLfoHERbfChKMqpGVUMjDGbgfYhwzcDD1qvHwRuGeUw5wM1xpjDxpgw8Ahws8TvUlcAj47hWMoI1HbEV2FWFw3fmlJRFGUkxptNVGGMabReNwEVSZ9dKCLviMjTIrLaGpsP1CZtU2eNlQCdxpjIkPFhEZG7RGSbiGxraWkZ59RnL3WWGCwo0n4CiqKMjQmnlhpjDGCstzuARcaYtcD3gN9M9PhDznW/MWa9MWZ9WVnZZB56VlDX0YfTIZo5pCjKmBmvGJwQkSoA63czgDGm2xjTa71+CnCLSClQDyxI2r/aGmsDCkXENWRcGQe17QEq87NwjaNLmaIoc5vx3jWeAO6wXt8BPA4gIpVWHAAROd86fhuwFVhuZQ55gFuBJyyrYhPwkaHHUsZOXUcfC4o1XqAoythJJbX0YWALcIaI1InIncA3gKtF5CBwlfUe4jf13SLyDvBd4FYTJwLcAzwD7AV+YYzZY+3z98DnRKSGeAzhJ5N3eXOL2o4A1RovUBRlHIy66MwYc9sIH105zLbfB74/wnGeAp4aZvww8WwjZQKEIlFOdIc0k0hRlHGhzuVZwqFmPwCLStQyUBRl7KgYzBI27W8G4KLTSjM8E0VRZiIqBjOE/miMvnB00Fhzd5DW3hAAz713grXVBVTka1qpoihjR8VghvClx3Zx0/dfJZ6AFefTP93Bp3+6g+aeIDtrO7lqZcUpjqAoijIyWrV0BtDuD/ObtxsIR2PsaejmzPkFxGKGPQ3dBCNRfvrGcQCuXq1ioCjK+FDLYBz812tH+NHLh6bsfL/eUUc4GkMEntnTBEB9Zx99/VGMge9vquGs+QWsqMyfsjkpijK7UMtgjIQiUf7tuQMYA3928ZIpaSH5+M4Gzl5YSJbLye/ebeSaVZU09wQBcAhEY4aPX7Aw7fNQFGX2opbBGNl8oJWeYITeUIS3jgwt5poe6jv7WD0vnz9YN48jrX5u+v6rfH9TDQC3nD2fwhw3N62dNyVzURRldqKWwRj57TsNFOa46QtHeX7vCS5Znt5Uzkg0RkcgTInPy63nLWD9oiJu3/gWbx/vpCLfy7988Cy6+/q1CbiiKBNCLYMxYIxh075mrl1VycXLSnlh34m0n7M9EMYYKM31ICIsr8jjQ+fEq3yfXpFHlttJuaaTKooyQVQMRqA3FCEWM4PG2vxhekIRVlTlcdFpJdS29yXy/NNFW28YgJJcb2LsI+fGC8AuL9fG34qiTA4qBsPQHezn4m+8yENbjg4ar20faB5jZ+7sb+pJ61wSYuAbaA29pNTHfR8/hz+/dElaz60oytxBxWAYnny3ka6+ft6p6xo0ftwSg4UlOayoij+V70u3GPjjlkdpnnfQ+PVnVTGvUIvSKYoyOagYWNQ097DlUBsAv9peB8Dhlt5B29R19AHxHsOluV5Kc73sa+xO67xaLcug1OcdZUtFUZTxo2Jg8U+/fY9P/c92jrX52Xasg2y3k8Mt/kHlH463BSjN9ZLjiWfurKjMS7tl0NobwuUQ8rM1W0hRlPShYkA8fXPHsQ66+vr50ebDANx6/gJ6QhFakgLEtR2BQZ3EVlTmceBED+81dBOJxtIyt7beECVWJpGiKEq6mNNiYIzhgdeO8OK+ZvxWRdBfbK1lYXEO7z+jHIDDLf7E9sfbAyxI6iS2oiqfUCTGDd99hYe31qZljm298TUGiqIo6SQlMRCRjSLSLCK7k8aKReQ5ETlo/S6yxkVEvisiNSLyroick7TPHdb2B0XkjqTxc0Vkl7XPd2WKHoPfONzOP/72Pf76kbcByPO6iMQMlywvZUmpDxgQg/5ojMauIAuLB8Tg+jMr+btrz2BeQRab9jWnZY6t/vBJwWNFUZTJJlXL4AHguiFj9wIvGGOWAy9Y7wGuB5ZbP3cB90FcPICvABcQb3P5FVtArG0+mbTf0HOlhUe2xqt9BvtjVBdlc/mKuDVw2fJS5hdm43U5ONLaS7A/ytd+9x7RmBkkBj6vi7vfv4yrVlWw5VAboUh02PNMhLbeEKVJaaWKoijpICUxMMZsBoYW4rkZeNB6/SBwS9L4QybOG0ChiFQB1wLPGWPajTEdwHPAddZn+caYN0w8WvtQ0rEmnc5AmPcauunwh3l6VxO3nb+ApaU+3nd6GVevqqAox82Fp5XicAhLSn3sa+rhp28e58Etx/jg2fOHrQF02fIy+vqjbD/WMalzNcbQasUMFEVR0slEUlQqjDGN1usmwC6mPx9IdqDXWWOnGq8bZjwt3PXQdnpCEW6/cBHhaIw/3rCIr9y0GpdDcDkd3LSmKhGs3bC0hEe2HicaMywt8/Hvf7Ru2GNuOK0El0N4+UDLSW0ntx/rIC/LxekVqa8W3rS/mW8+vY9sj5Ngf4zyPC03oShKepmUALL1RG9G3XCCiMhdIrJNRLa1tLSM6xjXnVnJ3sZuNr56hAXF2ayqyifL7cTldNjnSGz7vtPLCPbHeP1QGxefordwrtfFJctLefzthpOyiv7qZzv416f2jmmOj+2o53h7AGPgM1cu54/OXzCm/RVFUcbKRMTghOXiwfptR1DrgeS7V7U1dqrx6mHGT8IYc78xZr0xZn1ZWdm4Jn3DWVWIwMHmXq5ZVXnKlM0LlhYn+hVcvOzU1UlvO38hTd1BXto/IFINnX00dAWp7+wb0xy3H+vg8jPK+M3dF/M3V59OfpZ7TPsriqKMlYmIwROAnRF0B/B40vjtVlbRBqDLcic9A1wjIkVW4Pga4Bnrs24R2WBlEd2edKxJp7Igi/MWFQNw9apTt4nM8bi4YEkxDoELl5acctsrVpRTnudNBKWBRAyhoTOY8vwau/qo7+zjXGuOiqIoU0FKMQMReRi4HCgVkTriWUHfAH4hIncCx4CPWps/BdwA1AAB4M8AjDHtIvLPwFZru68aY+yg9KeJZyxlA09bP2njE5csxuUU1i8qGnXbz1y5nCtXlFOQc+qnc7fTwZUry3lmzwmiMcOL+5p543C8vEVvKEJ3sH/UJ/zjbQE27Y8bWKnMTVEUZbJISQyMMbeN8NGVw2xrgLtHOM5GYOMw49uAM1OZy2Rw3ZlVXHdmVUrbrl9czPrFqT2lLy3Npd1fy5O7Gvnrh+NrF0TAmLjLKL/y1GLwR/dvobErSLbbyap52s9YUZSpY06vQJ5slpbFF6r97p2GxNiGJXH3UuMorqLeUCSxqO2PNyzE7dSvRlGUqUOrn00i9qrllw60ML8wm29+eA2leR6u+84rNHSdOohs90r4/HVncOMa7WesKMrUomIwiSwozsHlEMKRGCsq87hkeSnRmMHpEBpGyShKbpyjKIoy1agvYhJxOx2JchV28xunQ6jMzxrVTZRonFOsYqAoytSjYjDJ2HGDlVUDAeB5hVmjrjWo6+gj1+uicJSsJUVRlHSgYjDJ2HEDu0cywLzCbHYc7+Cj/7GFYH+8mN2WQ22JzmoQdxNVF2Vr3wJFUTKCxgwmmRvXzKOrrz8hCgCfuHgJ7f4wrxxspbY9wPKKPL7yxG66+yK8du8VOB1CbUeARSW+UxxZURQlfahlMMmsXVDI//nIWpwOGTT26cuXAdDSEyLYH+VQi5+m7iBvHmnDGENte58GjxVFyRgqBlNEmdWgpqU3xL6mHqKxeF2/x99uoLU3TF9/dFBLTUVRlKlExWCKSIhBT4j3GroBOH9xMU/vbmRvY/z9WMpcK4qiTCYqBlNEfpYLj8tBS0+IPQ1d5Ge5+MP11XQHI/zWWrGcnIGkKIoylWgAeYoQEcpyvbT0hDjc6mfVvHzOXhgvRvfbdxuoKsiiWNtbKoqSIdQymELK8rw0dQfZ19TNqqoClpb6yMtyEeyPsUqtAkVRMoiKwRRSlufl7eOdBPtjrJ6Xj8MhrFtQCKBVShVFySgqBlNIaa6XPmvR2er58Zv/2bYYqGWgKEoGUTGYQuyMIo/LwWlluQBctaqCBcXZnLtYm9koipI5NIA8hdhicEZFXqJfwZrqQl75/BWZnJaiKMrELAMR+YyI7BaRPSLyWWvsH0WkXkR2Wj83JG3/BRGpEZH9InJt0vh11liNiNw7kTlNZ8py42KwWuMDiqJMM8ZtGYjImcAngfOBMPB7Efmd9fG/G2P+75DtVwG3AquBecDzInK69fEPgKuBOmCriDxhjHlvvHObrtiWgYqBoijTjYm4iVYCbxpjAgAi8jLwoVNsfzPwiDEmBBwRkRriQgJQY4w5bB3nEWvbWScGZ80v4K7LlnLDWan1X1YURZkqJuIm2g1cKiIlIpID3AAssD67R0TeFZGNImJHRucDtUn711ljI43POjwuB1+8YSUllrtIURRlujBuMTDG7AW+CTwL/B7YCUSB+4DTgHVAI/DtiU7SRkTuEpFtIrKtpaVlsg6rKIoy55lQANkY8xNjzLnGmMuADuCAMeaEMSZqjIkB/8mAK6ieAcsBoNoaG2l8uPPdb4xZb4xZX1ZWNpGpK4qiKElMNJuo3Pq9kHi84GcikuwQ/yBxdxLAE8CtIuIVkSXAcuAtYCuwXESWiIiHeJD5iYnMS1EURRkbE11n8CsRKQH6gbuNMZ0i8j0RWQcY4CjwFwDGmD0i8gvigeGItX0UQETuAZ4BnMBGY8yeCc5LURRFGQNijMn0HMbF+vXrzbZt2zI9DUVRlBmFiGw3xqwfOq7lKBRFURQVA0VRFEXFQFEURWEGxwxEpAU4Ns7dS4HWSZzOTGCuXfNcu17Qa54LTMb1LjLGnJSbP2PFYCKIyLbhAiizmbl2zXPtekGveS6QzutVN5GiKIqiYqAoiqLMXTG4P9MTyABz7Zrn2vWCXvNcIG3XOydjBoqiKMpg5qploCiKoiQx58RgLrTYFJGjIrLLaju6zRorFpHnROSg9btotONMZ6xeGc0isjtpbNhrlDjftb7zd0XknMzNfPyMcM1jbjM7UxCRBSKySUTes1rrfsYan5Xf8ymud2q+Y2PMnPkhXgjvELAU8ADvAKsyPa80XOdRoHTI2P8B7rVe3wt8M9PznOA1XgacA+we7RqJN156GhBgA/EOfRm/hkm65n8E/naYbVdZf99eYIn1d+/M9DWM8XqrgHOs13nAAeu6ZuX3fIrrnZLveK5ZBudjtdg0xoQBu8XmXOBm4EHr9YPALZmbysQxxmwG2ocMj3SNNwMPmThvAIVDSq3PCEa45pFItJk1xhwBktvMzgiMMY3GmB3W6x5gL/EuiLPyez7F9Y7EpH7Hc00M5kqLTQM8KyLbReQua6zCGNNovW4CKjIztbQy0jXO9u99LG1mZyQishg4G3iTOfA9D7lemILveK6JwVzhEmPMOcD1wN0iclnyhyZuY87qNLK5cI0WaWszO10QkVzgV8BnjTHdyZ/Nxu95mOudku94rolByi02ZzLGmHrrdzPwGHHT8YRtMlu/mzM3w7Qx0jXO2u/djL3N7IxCRNzEb4w/Ncb82hqetd/zcNc7Vd/xXBODWd9iU0R8IpJnvwauId569AngDmuzO4DHMzPDtDLSNT4B3G5lm2wAupLcDDOacbSZnTGIiAA/AfYaY/4t6aNZ+T2PdL1T9h1nOoI+1T/EMw4OEI+8fynT80nD9S0lnmHwDrDHvkagBHgBOAg8DxRneq4TvM6HiZvM/cR9pXeOdI3Es0t+YH3nu4D1mZ7/JF7zf1vX9K51c6hK2v5L1jXvB67P9PzHcb2XEHcBvQvstH5umK3f8ymud0q+Y12BrCiKosw5N5GiKIoyDCoGiqIoioqBoiiKomKgKIqioGKgKIqioGKgKIqioGKgKIqioGKgKIqiAP8f3qpZlaYwko8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df_account_value.account_value.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr2zX7ZxNyFQ"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nzkr9yv-AdV_",
    "outputId": "b419a565-8c15-47d8-f66c-00f81c3c526d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return          0.249467\n",
      "Cumulative returns     0.249467\n",
      "Annual volatility      0.238682\n",
      "Sharpe ratio           1.056162\n",
      "Calmar ratio           1.216109\n",
      "Stability              0.499041\n",
      "Max drawdown          -0.205136\n",
      "Omega ratio            1.194526\n",
      "Sortino ratio          1.530006\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.911589\n",
      "Daily value at risk   -0.029071\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DiHhM1YkoCel",
    "outputId": "903ef035-f9f4-4678-d18a-1516254eaf3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Baseline Stats===========\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (251, 8)\n",
      "Annual return          0.112517\n",
      "Cumulative returns     0.112046\n",
      "Annual volatility      0.149492\n",
      "Sharpe ratio           0.790765\n",
      "Calmar ratio           0.862325\n",
      "Stability              0.388079\n",
      "Max drawdown          -0.130481\n",
      "Omega ratio            1.139645\n",
      "Sortino ratio          1.131726\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.856084\n",
      "Daily value at risk   -0.018365\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^GSPC\", \n",
    "        start = df_account_value.loc[0,'date'],\n",
    "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U6Suru3h1jc"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HggausPRoCem",
    "outputId": "e61a64e0-58ed-4490-b19a-78bd4f76e666",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Compare to DJIA===========\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (251, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Worst drawdown periods</th>\n",
       "      <th>Net drawdown in %</th>\n",
       "      <th>Peak date</th>\n",
       "      <th>Valley date</th>\n",
       "      <th>Recovery date</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.51</td>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>2022-01-21</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.53</td>\n",
       "      <td>2021-09-03</td>\n",
       "      <td>2021-10-12</td>\n",
       "      <td>2021-12-21</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.27</td>\n",
       "      <td>2021-04-26</td>\n",
       "      <td>2021-05-12</td>\n",
       "      <td>2021-05-28</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.32</td>\n",
       "      <td>2021-04-16</td>\n",
       "      <td>2021-04-20</td>\n",
       "      <td>2021-04-23</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.98</td>\n",
       "      <td>2021-07-12</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>2021-07-23</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Stress Events</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New Normal</th>\n",
       "      <td>0.10%</td>\n",
       "      <td>-4.18%</td>\n",
       "      <td>4.50%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x5184 with 13 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot(df_account_value, \n",
    "              baseline_ticker = '^GSPC', \n",
    "              baseline_start = df_account_value.loc[0,'date'],\n",
    "              baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBQx4bVQFi-a"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FinRL_Ensemble_StockTrading_ICAIF_2020.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "a1dc24e770f11933509167a1c29cdaaeb86ecb8b4614cc65da123615b71c0aa2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
